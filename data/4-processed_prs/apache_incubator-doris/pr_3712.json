{"pr_number": 3712, "pr_title": "[Spark load][Fe 1/5] Add spark etl job config", "pr_createdAt": "2020-05-28T07:51:14Z", "pr_url": "https://github.com/apache/incubator-doris/pull/3712", "timeline": [{"oid": "c7800abf89ec74ffbdb716e858b2ad721e34b59c", "url": "https://github.com/apache/incubator-doris/commit/c7800abf89ec74ffbdb716e858b2ad721e34b59c", "message": "Add spark etl job config", "committedDate": "2020-05-28T07:36:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTY1OTAwMA==", "url": "https://github.com/apache/incubator-doris/pull/3712#discussion_r431659000", "bodyText": "Add a field defined_expr, and default is empty. This is for materialized view 2.0, which column may has expr definition.", "author": "morningman", "createdAt": "2020-05-28T08:13:54Z", "path": "fe/src/main/java/org/apache/doris/load/loadv2/etl/EtlJobConfig.java", "diffHunk": "@@ -0,0 +1,487 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2.etl;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.gson.FieldNamingPolicy;\n+import com.google.gson.Gson;\n+import com.google.gson.GsonBuilder;\n+\n+import java.io.Serializable;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+\n+/** jobconfig.json file format\n+ * {\n+ * \t\"tables\": {\n+ * \t\t10014: {\n+ * \t\t\t\"indexes\": [{\n+ * \t\t\t    \"index_id\": 10014,\n+ * \t\t\t\t\"columns\": [{\n+ * \t\t\t\t    \"column_name\": \"k1\",\n+ * \t\t\t\t    \"column_type\": \"SMALLINT\",\n+ * \t\t\t\t    \"is_key\": true,\n+ * \t\t\t\t    \"is_allow_null\": true,", "originalCommit": "c7800abf89ec74ffbdb716e858b2ad721e34b59c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTY1OTQyNQ==", "url": "https://github.com/apache/incubator-doris/pull/3712#discussion_r431659425", "bodyText": "How about adding a version fields for further extension?", "author": "morningman", "createdAt": "2020-05-28T08:14:38Z", "path": "fe/src/main/java/org/apache/doris/load/loadv2/etl/EtlJobConfig.java", "diffHunk": "@@ -0,0 +1,487 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2.etl;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.gson.FieldNamingPolicy;\n+import com.google.gson.Gson;\n+import com.google.gson.GsonBuilder;\n+\n+import java.io.Serializable;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+\n+/** jobconfig.json file format\n+ * {", "originalCommit": "c7800abf89ec74ffbdb716e858b2ad721e34b59c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTY2MDc3Ng==", "url": "https://github.com/apache/incubator-doris/pull/3712#discussion_r431660776", "bodyText": "Add \"version\" field for further extension?", "author": "morningman", "createdAt": "2020-05-28T08:17:00Z", "path": "fe/src/main/java/org/apache/doris/load/loadv2/etl/EtlJobConfig.java", "diffHunk": "@@ -0,0 +1,487 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2.etl;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.gson.FieldNamingPolicy;\n+import com.google.gson.Gson;\n+import com.google.gson.GsonBuilder;\n+\n+import java.io.Serializable;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+\n+/** jobconfig.json file format\n+ * {\n+ * \t\"tables\": {\n+ * \t\t10014: {\n+ * \t\t\t\"indexes\": [{\n+ * \t\t\t    \"index_id\": 10014,\n+ * \t\t\t\t\"columns\": [{\n+ * \t\t\t\t    \"column_name\": \"k1\",\n+ * \t\t\t\t    \"column_type\": \"SMALLINT\",\n+ * \t\t\t\t    \"is_key\": true,\n+ * \t\t\t\t    \"is_allow_null\": true,\n+ * \t\t\t\t    \"aggregation_type\": \"NONE\"\n+ *                }, {\n+ * \t\t\t\t\t\"column_name\": \"k2\",\n+ * \t\t\t\t    \"column_type\": \"VARCHAR\",\n+ * \t\t\t\t    \"string_length\": 20,\n+ * \t\t\t\t\t\"is_key\": true,\n+ * \t\t\t\t    \"is_allow_null\": true,\n+ * \t\t\t\t\t\"aggregation_type\": \"NONE\"\n+ *                }, {\n+ * \t\t\t\t\t\"column_name\": \"v\",\n+ * \t\t\t\t    \"column_type\": \"BIGINT\",\n+ * \t\t\t\t\t\"is_key\": false,\n+ * \t\t\t\t    \"is_allow_null\": false,\n+ * \t\t\t\t\t\"aggregation_type\": \"NONE\"\n+ *              }],\n+ * \t\t\t\t\"schema_hash\": 1294206574,\n+ * \t\t\t    \"index_type\": \"DUPLICATE\",\n+ * \t\t\t    \"is_base_index\": true\n+ *            }, {\n+ * \t\t\t    \"index_id\": 10017,\n+ * \t\t\t\t\"columns\": [{\n+ * \t\t\t\t    \"column_name\": \"k1\",\n+ * \t\t\t\t    \"column_type\": \"SMALLINT\",\n+ * \t\t\t\t\t\"is_key\": true,\n+ * \t\t\t\t    \"is_allow_null\": true,\n+ * \t\t\t\t\t\"aggregation_type\": \"NONE\"\n+ *                }, {\n+ * \t\t\t\t\t\"column_name\": \"v\",\n+ * \t\t\t\t    \"column_type\": \"BIGINT\",\n+ * \t\t\t\t\t\"is_key\": false,\n+ * \t\t\t\t    \"is_allow_null\": false,\n+ * \t\t\t\t\t\"aggregation_type\": \"SUM\"\n+ *              }],\n+ * \t\t\t\t\"schema_hash\": 1294206575,\n+ * \t\t\t    \"index_type\": \"AGGREGATE\",\n+ * \t\t\t    \"is_base_index\": false\n+ *          }],\n+ * \t\t\t\"partition_info\": {\n+ * \t\t\t\t\"partition_type\": \"RANGE\",\n+ * \t\t\t\t\"partition_column_refs\": [\"k1\"],\n+ *              \"distribution_column_refs\": [\"k2\"],\n+ * \t\t\t\t\"partitions\": [{\n+ * \t\t\t\t    \"partition_id\": 10020,\n+ * \t\t\t\t\t\"start_keys\": [-100],\n+ * \t\t\t\t\t\"end_keys\": [10],\n+ * \t\t\t\t\t\"is_max_partition\": false,\n+ * \t\t\t\t\t\"bucket_num\": 3\n+ *                }, {\n+ *                  \"partition_id\": 10021,\n+ *                  \"start_keys\": [10],\n+ *                  \"end_keys\": [100],\n+ *                  \"is_max_partition\": false,\n+ *  \t\t\t\t\"bucket_num\": 3\n+ *              }]\n+ *          },\n+ * \t\t\t\"file_groups\": [{\n+ * \t\t        \"partitions\": [10020],\n+ * \t\t\t\t\"file_paths\": [\"hdfs://hdfs_host:port/user/palo/test/file\"],\n+ * \t\t\t\t\"file_field_names\": [\"tmp_k1\", \"k2\"],\n+ * \t\t\t\t\"value_separator\": \",\",\n+ * \t\t\t    \"line_delimiter\": \"\\n\",\n+ * \t\t\t\t\"column_mappings\": {\n+ * \t\t\t\t\t\"k1\": {\n+ * \t\t\t\t\t\t\"function_name\": \"strftime\",\n+ * \t\t\t\t\t\t\"args\": [\"%Y-%m-%d %H:%M:%S\", \"tmp_k1\"]\n+ *                   }\n+ *              },\n+ * \t\t\t\t\"where\": \"k2 > 10\",\n+ * \t\t\t\t\"is_negative\": false,\n+ * \t\t\t\t\"hive_table_name\": \"hive_db.table\"\n+ *          }]\n+ *      }\n+ *  },\n+ * \t\"output_path\": \"hdfs://hdfs_host:port/user/output/10003/label1/1582599203397\",\n+ * \t\"output_file_pattern\": \"label1.%d.%d.%d.%d.%d.parquet\",\n+ * \t\"label\": \"label0\",\n+ * \t\"properties\": {\n+ * \t    \"strict_mode\": false,\n+ * \t    \"timezone\": \"Asia/Shanghai\"\n+ * \t}\n+ * }\n+ */\n+public class EtlJobConfig implements Serializable {\n+    // global dict\n+    public static final String GLOBAL_DICT_TABLE_NAME = \"doris_global_dict_table_%d\";\n+    public static final String DISTINCT_KEY_TABLE_NAME = \"doris_distinct_key_table_%d_%s\";\n+    public static final String DORIS_INTERMEDIATE_HIVE_TABLE_NAME = \"doris_intermediate_hive_table_%d_%s\";\n+\n+    // hdfsEtlPath/jobs/dbId/loadLabel/PendingTaskSignature\n+    private static final String ETL_OUTPUT_PATH_FORMAT = \"%s/jobs/%d/%s/%d\";\n+    private static final String ETL_OUTPUT_FILE_NAME_DESC = \"label.tableId.partitionId.indexId.bucket.schemaHash.parquet\";", "originalCommit": "c7800abf89ec74ffbdb716e858b2ad721e34b59c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjIwNTcxNg==", "url": "https://github.com/apache/incubator-doris/pull/3712#discussion_r432205716", "bodyText": "Why this class should implement Serializable?\nI think it is OK to convert to and from JSON.", "author": "imay", "createdAt": "2020-05-29T01:13:59Z", "path": "fe/src/main/java/org/apache/doris/load/loadv2/etl/EtlJobConfig.java", "diffHunk": "@@ -0,0 +1,487 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2.etl;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.gson.FieldNamingPolicy;\n+import com.google.gson.Gson;\n+import com.google.gson.GsonBuilder;\n+\n+import java.io.Serializable;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+\n+/** jobconfig.json file format\n+ * {\n+ * \t\"tables\": {\n+ * \t\t10014: {\n+ * \t\t\t\"indexes\": [{\n+ * \t\t\t    \"index_id\": 10014,\n+ * \t\t\t\t\"columns\": [{\n+ * \t\t\t\t    \"column_name\": \"k1\",\n+ * \t\t\t\t    \"column_type\": \"SMALLINT\",\n+ * \t\t\t\t    \"is_key\": true,\n+ * \t\t\t\t    \"is_allow_null\": true,\n+ * \t\t\t\t    \"aggregation_type\": \"NONE\"\n+ *                }, {\n+ * \t\t\t\t\t\"column_name\": \"k2\",\n+ * \t\t\t\t    \"column_type\": \"VARCHAR\",\n+ * \t\t\t\t    \"string_length\": 20,\n+ * \t\t\t\t\t\"is_key\": true,\n+ * \t\t\t\t    \"is_allow_null\": true,\n+ * \t\t\t\t\t\"aggregation_type\": \"NONE\"\n+ *                }, {\n+ * \t\t\t\t\t\"column_name\": \"v\",\n+ * \t\t\t\t    \"column_type\": \"BIGINT\",\n+ * \t\t\t\t\t\"is_key\": false,\n+ * \t\t\t\t    \"is_allow_null\": false,\n+ * \t\t\t\t\t\"aggregation_type\": \"NONE\"\n+ *              }],\n+ * \t\t\t\t\"schema_hash\": 1294206574,\n+ * \t\t\t    \"index_type\": \"DUPLICATE\",\n+ * \t\t\t    \"is_base_index\": true\n+ *            }, {\n+ * \t\t\t    \"index_id\": 10017,\n+ * \t\t\t\t\"columns\": [{\n+ * \t\t\t\t    \"column_name\": \"k1\",\n+ * \t\t\t\t    \"column_type\": \"SMALLINT\",\n+ * \t\t\t\t\t\"is_key\": true,\n+ * \t\t\t\t    \"is_allow_null\": true,\n+ * \t\t\t\t\t\"aggregation_type\": \"NONE\"\n+ *                }, {\n+ * \t\t\t\t\t\"column_name\": \"v\",\n+ * \t\t\t\t    \"column_type\": \"BIGINT\",\n+ * \t\t\t\t\t\"is_key\": false,\n+ * \t\t\t\t    \"is_allow_null\": false,\n+ * \t\t\t\t\t\"aggregation_type\": \"SUM\"\n+ *              }],\n+ * \t\t\t\t\"schema_hash\": 1294206575,\n+ * \t\t\t    \"index_type\": \"AGGREGATE\",\n+ * \t\t\t    \"is_base_index\": false\n+ *          }],\n+ * \t\t\t\"partition_info\": {\n+ * \t\t\t\t\"partition_type\": \"RANGE\",\n+ * \t\t\t\t\"partition_column_refs\": [\"k1\"],\n+ *              \"distribution_column_refs\": [\"k2\"],\n+ * \t\t\t\t\"partitions\": [{\n+ * \t\t\t\t    \"partition_id\": 10020,\n+ * \t\t\t\t\t\"start_keys\": [-100],\n+ * \t\t\t\t\t\"end_keys\": [10],\n+ * \t\t\t\t\t\"is_max_partition\": false,\n+ * \t\t\t\t\t\"bucket_num\": 3\n+ *                }, {\n+ *                  \"partition_id\": 10021,\n+ *                  \"start_keys\": [10],\n+ *                  \"end_keys\": [100],\n+ *                  \"is_max_partition\": false,\n+ *  \t\t\t\t\"bucket_num\": 3\n+ *              }]\n+ *          },\n+ * \t\t\t\"file_groups\": [{\n+ * \t\t        \"partitions\": [10020],\n+ * \t\t\t\t\"file_paths\": [\"hdfs://hdfs_host:port/user/palo/test/file\"],\n+ * \t\t\t\t\"file_field_names\": [\"tmp_k1\", \"k2\"],\n+ * \t\t\t\t\"value_separator\": \",\",\n+ * \t\t\t    \"line_delimiter\": \"\\n\",\n+ * \t\t\t\t\"column_mappings\": {\n+ * \t\t\t\t\t\"k1\": {\n+ * \t\t\t\t\t\t\"function_name\": \"strftime\",\n+ * \t\t\t\t\t\t\"args\": [\"%Y-%m-%d %H:%M:%S\", \"tmp_k1\"]\n+ *                   }\n+ *              },\n+ * \t\t\t\t\"where\": \"k2 > 10\",\n+ * \t\t\t\t\"is_negative\": false,\n+ * \t\t\t\t\"hive_table_name\": \"hive_db.table\"\n+ *          }]\n+ *      }\n+ *  },\n+ * \t\"output_path\": \"hdfs://hdfs_host:port/user/output/10003/label1/1582599203397\",\n+ * \t\"output_file_pattern\": \"label1.%d.%d.%d.%d.%d.parquet\",\n+ * \t\"label\": \"label0\",\n+ * \t\"properties\": {\n+ * \t    \"strict_mode\": false,\n+ * \t    \"timezone\": \"Asia/Shanghai\"\n+ * \t}\n+ * }\n+ */\n+public class EtlJobConfig implements Serializable {", "originalCommit": "c7800abf89ec74ffbdb716e858b2ad721e34b59c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjk0NjIzNQ==", "url": "https://github.com/apache/incubator-doris/pull/3712#discussion_r432946235", "bodyText": "etl job failed if not implements Serializable interface. failed message: org.apache.spark.SparkException: Task not serializable, object not serializable", "author": "wyb", "createdAt": "2020-05-31T13:16:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjIwNTcxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjIwNzA4OQ==", "url": "https://github.com/apache/incubator-doris/pull/3712#discussion_r432207089", "bodyText": "If the variable name is changed, the serialized JSON will change.\nIs there some method to seprate the variable name and serialized field name?", "author": "imay", "createdAt": "2020-05-29T01:19:59Z", "path": "fe/src/main/java/org/apache/doris/load/loadv2/etl/EtlJobConfig.java", "diffHunk": "@@ -0,0 +1,487 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2.etl;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.gson.FieldNamingPolicy;\n+import com.google.gson.Gson;\n+import com.google.gson.GsonBuilder;\n+\n+import java.io.Serializable;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+\n+/** jobconfig.json file format\n+ * {\n+ * \t\"tables\": {\n+ * \t\t10014: {\n+ * \t\t\t\"indexes\": [{\n+ * \t\t\t    \"index_id\": 10014,\n+ * \t\t\t\t\"columns\": [{\n+ * \t\t\t\t    \"column_name\": \"k1\",\n+ * \t\t\t\t    \"column_type\": \"SMALLINT\",\n+ * \t\t\t\t    \"is_key\": true,\n+ * \t\t\t\t    \"is_allow_null\": true,\n+ * \t\t\t\t    \"aggregation_type\": \"NONE\"\n+ *                }, {\n+ * \t\t\t\t\t\"column_name\": \"k2\",\n+ * \t\t\t\t    \"column_type\": \"VARCHAR\",\n+ * \t\t\t\t    \"string_length\": 20,\n+ * \t\t\t\t\t\"is_key\": true,\n+ * \t\t\t\t    \"is_allow_null\": true,\n+ * \t\t\t\t\t\"aggregation_type\": \"NONE\"\n+ *                }, {\n+ * \t\t\t\t\t\"column_name\": \"v\",\n+ * \t\t\t\t    \"column_type\": \"BIGINT\",\n+ * \t\t\t\t\t\"is_key\": false,\n+ * \t\t\t\t    \"is_allow_null\": false,\n+ * \t\t\t\t\t\"aggregation_type\": \"NONE\"\n+ *              }],\n+ * \t\t\t\t\"schema_hash\": 1294206574,\n+ * \t\t\t    \"index_type\": \"DUPLICATE\",\n+ * \t\t\t    \"is_base_index\": true\n+ *            }, {\n+ * \t\t\t    \"index_id\": 10017,\n+ * \t\t\t\t\"columns\": [{\n+ * \t\t\t\t    \"column_name\": \"k1\",\n+ * \t\t\t\t    \"column_type\": \"SMALLINT\",\n+ * \t\t\t\t\t\"is_key\": true,\n+ * \t\t\t\t    \"is_allow_null\": true,\n+ * \t\t\t\t\t\"aggregation_type\": \"NONE\"\n+ *                }, {\n+ * \t\t\t\t\t\"column_name\": \"v\",\n+ * \t\t\t\t    \"column_type\": \"BIGINT\",\n+ * \t\t\t\t\t\"is_key\": false,\n+ * \t\t\t\t    \"is_allow_null\": false,\n+ * \t\t\t\t\t\"aggregation_type\": \"SUM\"\n+ *              }],\n+ * \t\t\t\t\"schema_hash\": 1294206575,\n+ * \t\t\t    \"index_type\": \"AGGREGATE\",\n+ * \t\t\t    \"is_base_index\": false\n+ *          }],\n+ * \t\t\t\"partition_info\": {\n+ * \t\t\t\t\"partition_type\": \"RANGE\",\n+ * \t\t\t\t\"partition_column_refs\": [\"k1\"],\n+ *              \"distribution_column_refs\": [\"k2\"],\n+ * \t\t\t\t\"partitions\": [{\n+ * \t\t\t\t    \"partition_id\": 10020,\n+ * \t\t\t\t\t\"start_keys\": [-100],\n+ * \t\t\t\t\t\"end_keys\": [10],\n+ * \t\t\t\t\t\"is_max_partition\": false,\n+ * \t\t\t\t\t\"bucket_num\": 3\n+ *                }, {\n+ *                  \"partition_id\": 10021,\n+ *                  \"start_keys\": [10],\n+ *                  \"end_keys\": [100],\n+ *                  \"is_max_partition\": false,\n+ *  \t\t\t\t\"bucket_num\": 3\n+ *              }]\n+ *          },\n+ * \t\t\t\"file_groups\": [{\n+ * \t\t        \"partitions\": [10020],\n+ * \t\t\t\t\"file_paths\": [\"hdfs://hdfs_host:port/user/palo/test/file\"],\n+ * \t\t\t\t\"file_field_names\": [\"tmp_k1\", \"k2\"],\n+ * \t\t\t\t\"value_separator\": \",\",\n+ * \t\t\t    \"line_delimiter\": \"\\n\",\n+ * \t\t\t\t\"column_mappings\": {\n+ * \t\t\t\t\t\"k1\": {\n+ * \t\t\t\t\t\t\"function_name\": \"strftime\",\n+ * \t\t\t\t\t\t\"args\": [\"%Y-%m-%d %H:%M:%S\", \"tmp_k1\"]\n+ *                   }\n+ *              },\n+ * \t\t\t\t\"where\": \"k2 > 10\",\n+ * \t\t\t\t\"is_negative\": false,\n+ * \t\t\t\t\"hive_table_name\": \"hive_db.table\"\n+ *          }]\n+ *      }\n+ *  },\n+ * \t\"output_path\": \"hdfs://hdfs_host:port/user/output/10003/label1/1582599203397\",\n+ * \t\"output_file_pattern\": \"label1.%d.%d.%d.%d.%d.parquet\",\n+ * \t\"label\": \"label0\",\n+ * \t\"properties\": {\n+ * \t    \"strict_mode\": false,\n+ * \t    \"timezone\": \"Asia/Shanghai\"\n+ * \t}\n+ * }\n+ */\n+public class EtlJobConfig implements Serializable {\n+    // global dict\n+    public static final String GLOBAL_DICT_TABLE_NAME = \"doris_global_dict_table_%d\";\n+    public static final String DISTINCT_KEY_TABLE_NAME = \"doris_distinct_key_table_%d_%s\";\n+    public static final String DORIS_INTERMEDIATE_HIVE_TABLE_NAME = \"doris_intermediate_hive_table_%d_%s\";\n+\n+    // hdfsEtlPath/jobs/dbId/loadLabel/PendingTaskSignature\n+    private static final String ETL_OUTPUT_PATH_FORMAT = \"%s/jobs/%d/%s/%d\";\n+    private static final String ETL_OUTPUT_FILE_NAME_DESC = \"label.tableId.partitionId.indexId.bucket.schemaHash.parquet\";\n+    // tableId.partitionId.indexId.bucket.schemaHash\n+    public static final String ETL_OUTPUT_FILE_NAME_NO_LABEL_SUFFIX_FORMAT = \"%d.%d.%d.%d.%d\";\n+    public static final String ETL_OUTPUT_FILE_FORMAT = \"parquet\";\n+\n+    // dpp result\n+    public static final String DPP_RESULT_NAME = \"dpp_result.json\";\n+\n+    public Map<Long, EtlTable> tables;\n+    public String outputPath;\n+    public String outputFilePattern;\n+    public String label;\n+    public EtlJobProperty properties;", "originalCommit": "c7800abf89ec74ffbdb716e858b2ad721e34b59c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "798c0a74ab0e4d2343ec2a88af07fff85dcf7b0d", "url": "https://github.com/apache/incubator-doris/commit/798c0a74ab0e4d2343ec2a88af07fff85dcf7b0d", "message": "Update etl job config", "committedDate": "2020-05-31T15:09:49Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzI1NjI5MA==", "url": "https://github.com/apache/incubator-doris/pull/3712#discussion_r433256290", "bodyText": "You forgot to update the comment with the new format of json", "author": "morningman", "createdAt": "2020-06-01T14:08:38Z", "path": "fe/src/main/java/org/apache/doris/load/loadv2/etl/EtlJobConfig.java", "diffHunk": "@@ -0,0 +1,548 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2.etl;\n+\n+import org.apache.doris.persist.gson.GsonUtils;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.gson.Gson;\n+import com.google.gson.GsonBuilder;\n+import com.google.gson.annotations.SerializedName;\n+\n+import java.io.Serializable;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+\n+/** jobconfig.json file format", "originalCommit": "798c0a74ab0e4d2343ec2a88af07fff85dcf7b0d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzI5MDM3OA==", "url": "https://github.com/apache/incubator-doris/pull/3712#discussion_r433290378", "bodyText": "why not make it a private static?", "author": "imay", "createdAt": "2020-06-01T15:06:15Z", "path": "fe/src/main/java/org/apache/doris/load/loadv2/etl/EtlJobConfig.java", "diffHunk": "@@ -0,0 +1,548 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2.etl;\n+\n+import org.apache.doris.persist.gson.GsonUtils;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.gson.Gson;\n+import com.google.gson.GsonBuilder;\n+import com.google.gson.annotations.SerializedName;\n+\n+import java.io.Serializable;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+\n+/** jobconfig.json file format\n+{\n+    \"tables\": {\n+        10014: {\n+            \"indexes\": [{\n+                \"indexId\": 10014,\n+                \"columns\": [{\n+                    \"columnName\": \"k1\",\n+                    \"columnType\": \"SMALLINT\",\n+                    \"isKey\": true,\n+                    \"isAllowNull\": true,\n+                    \"aggregationType\": \"NONE\"\n+                }, {\n+                    \"columnName\": \"k2\",\n+                    \"columnType\": \"VARCHAR\",\n+                    \"stringLength\": 20,\n+                    \"isKey\": true,\n+                    \"isAllowNull\": true,\n+                    \"aggregationType\": \"NONE\"\n+                }, {\n+                    \"columnName\": \"v\",\n+                    \"columnType\": \"BIGINT\",\n+                    \"isKey\": false,\n+                    \"isAllowNull\": false,\n+                    \"aggregationType\": \"NONE\"\n+                }],\n+                \"schemaHash\": 1294206574,\n+                \"indexType\": \"DUPLICATE\",\n+                \"isBaseIndex\": true\n+            }, {\n+                \"indexId\": 10017,\n+                \"columns\": [{\n+                    \"columnName\": \"k1\",\n+                    \"columnType\": \"SMALLINT\",\n+                    \"isKey\": true,\n+                    \"isAllowNull\": true,\n+                    \"aggregationType\": \"NONE\"\n+                }, {\n+                    \"columnName\": \"v\",\n+                    \"columnType\": \"BIGINT\",\n+                    \"isKey\": false,\n+                    \"isAllowNull\": false,\n+                    \"aggregationType\": \"BITMAP_UNION\",\n+                    \"defineExpr\": \"to_bitmap(v)\"\n+                }],\n+                \"schemaHash\": 1294206575,\n+                \"indexType\": \"AGGREGATE\",\n+                \"isBaseIndex\": false\n+            }],\n+            \"partitionInfo\": {\n+                \"partitionType\": \"RANGE\",\n+                \"partitionColumnRefs\": [\"k1\"],\n+                \"distributionColumnRefs\": [\"k2\"],\n+ \t            \"partitions\": [{\n+                    \"partitionId\": 10020,\n+                    \"startKeys\": [-100],\n+                    \"endKeys\": [10],\n+                    \"isMaxPartition\": false,\n+                    \"bucketNum\": 3\n+                }, {\n+                    \"partitionId\": 10021,\n+                    \"startKeys\": [10],\n+                    \"endKeys\": [100],\n+                    \"isMaxPartition\": false,\n+                    \"bucketNum\": 3\n+                }]\n+            },\n+            \"fileGroups\": [{\n+                \"partitions\": [10020],\n+                \"filePaths\": [\"hdfs://hdfs_host:port/user/palo/test/file\"],\n+                \"fileFieldNames\": [\"tmp_k1\", \"k2\"],\n+                \"valueSeparator\": \",\",\n+                \"lineDelimiter\": \"\\n\",\n+                \"columnMappings\": {\n+                    \"k1\": {\n+                        \"functionName\": \"strftime\",\n+                        \"args\": [\"%Y-%m-%d %H:%M:%S\", \"tmp_k1\"]\n+                    }\n+                },\n+                \"where\": \"k2 > 10\",\n+                \"isNegative\": false,\n+                \"hiveTableName\": \"hive_db.table\"\n+            }]\n+        }\n+    },\n+    \"outputPath\": \"hdfs://hdfs_host:port/user/output/10003/label1/1582599203397\",\n+    \"outputFilePattern\": \"label1.%d.%d.%d.%d.%d.parquet\",\n+    \"label\": \"label0\",\n+    \"properties\": {\n+        \"strictMode\": false,\n+        \"timezone\": \"Asia/Shanghai\"\n+    },\n+    \"version\": \"V1\"\n+}\n+ */\n+public class EtlJobConfig implements Serializable {\n+    // global dict\n+    public static final String GLOBAL_DICT_TABLE_NAME = \"doris_global_dict_table_%d\";\n+    public static final String DISTINCT_KEY_TABLE_NAME = \"doris_distinct_key_table_%d_%s\";\n+    public static final String DORIS_INTERMEDIATE_HIVE_TABLE_NAME = \"doris_intermediate_hive_table_%d_%s\";\n+\n+    // hdfsEtlPath/jobs/dbId/loadLabel/PendingTaskSignature\n+    private static final String ETL_OUTPUT_PATH_FORMAT = \"%s/jobs/%d/%s/%d\";\n+    private static final String ETL_OUTPUT_FILE_NAME_DESC = \"label.tableId.partitionId.indexId.bucket.schemaHash.parquet\";\n+    // tableId.partitionId.indexId.bucket.schemaHash\n+    public static final String ETL_OUTPUT_FILE_NAME_NO_LABEL_SUFFIX_FORMAT = \"%d.%d.%d.%d.%d\";\n+    public static final String ETL_OUTPUT_FILE_FORMAT = \"parquet\";\n+\n+    // dpp result\n+    public static final String DPP_RESULT_NAME = \"dpp_result.json\";\n+\n+    @SerializedName(value = \"tables\")\n+    public Map<Long, EtlTable> tables;\n+    @SerializedName(value = \"outputPath\")\n+    public String outputPath;\n+    @SerializedName(value = \"outputFilePattern\")\n+    public String outputFilePattern;\n+    @SerializedName(value = \"label\")\n+    public String label;\n+    @SerializedName(value = \"properties\")\n+    public EtlJobProperty properties;\n+    @SerializedName(value = \"version\")\n+    public Version version;\n+\n+    public EtlJobConfig(Map<Long, EtlTable> tables, String outputFilePattern, String label, EtlJobProperty properties) {\n+        this.tables = tables;\n+        // set outputPath when submit etl job\n+        this.outputPath = null;\n+        this.outputFilePattern = outputFilePattern;\n+        this.label = label;\n+        this.properties = properties;\n+        this.version = Version.V1;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return \"EtlJobConfig{\" +\n+                \"tables=\" + tables +\n+                \", outputPath='\" + outputPath + '\\'' +\n+                \", outputFilePattern='\" + outputFilePattern + '\\'' +\n+                \", label='\" + label + '\\'' +\n+                \", properties=\" + properties +\n+                \", version=\" + version +\n+                '}';\n+    }\n+\n+    public String getOutputPath() {\n+        return outputPath;\n+    }\n+\n+    public static String getOutputPath(String hdfsEtlPath, long dbId, String loadLabel, long taskSignature) {\n+        return String.format(ETL_OUTPUT_PATH_FORMAT, hdfsEtlPath, dbId, loadLabel, taskSignature);\n+    }\n+\n+    public static String getDppResultFilePath(String outputPath) {\n+        return outputPath + \"/\" + DPP_RESULT_NAME;\n+    }\n+\n+    public static String getTabletMetaStr(String filePath) throws Exception {\n+        // ETL_OUTPUT_FILE_NAME_DESC\n+        String fileName = filePath.substring(filePath.lastIndexOf(\"/\") + 1);\n+        String[] fileNameArr = fileName.split(\"\\\\.\");\n+        if (fileNameArr.length != ETL_OUTPUT_FILE_NAME_DESC.split(\"\\\\.\").length) {\n+            throw new Exception(\"etl output file name error, format: \" + ETL_OUTPUT_FILE_NAME_DESC\n+                                        + \", name: \" + fileName);\n+        }\n+\n+        // tableId.partitionId.indexId.bucket.schemaHash\n+        return fileName.substring(fileName.indexOf(\".\") + 1, fileName.lastIndexOf(\".\"));\n+    }\n+\n+    public String configToJson() {\n+        GsonBuilder gsonBuilder = new GsonBuilder();\n+        gsonBuilder.addDeserializationExclusionStrategy(new GsonUtils.HiddenAnnotationExclusionStrategy());\n+        Gson gson = gsonBuilder.create();\n+        return gson.toJson(this);\n+    }\n+\n+    public static EtlJobConfig configFromJson(String jsonConfig) {\n+        GsonBuilder gsonBuilder = new GsonBuilder();\n+        Gson gson = gsonBuilder.create();\n+        return gson.fromJson(jsonConfig, EtlJobConfig.class);\n+    }\n+\n+    public static class EtlJobProperty implements Serializable {\n+        @SerializedName(value = \"strictMode\")\n+        public boolean strictMode;\n+        @SerializedName(value = \"timezone\")\n+        public String timezone;\n+\n+        @Override\n+        public String toString() {\n+            return \"EtlJobProperty{\" +\n+                    \"strictMode=\" + strictMode +\n+                    \", timezone='\" + timezone + '\\'' +\n+                    '}';\n+        }\n+    }\n+\n+    public static enum Version {\n+        V1\n+    }\n+\n+    public static class EtlTable implements Serializable {\n+        @SerializedName(value = \"indexes\")\n+        public List<EtlIndex> indexes;\n+        @SerializedName(value = \"partitionInfo\")\n+        public EtlPartitionInfo partitionInfo;\n+        @SerializedName(value = \"fileGroups\")\n+        public List<EtlFileGroup> fileGroups;\n+\n+        public EtlTable(List<EtlIndex> etlIndexes, EtlPartitionInfo etlPartitionInfo) {\n+            this.indexes = etlIndexes;\n+            this.partitionInfo = etlPartitionInfo;\n+            this.fileGroups = Lists.newArrayList();\n+        }\n+\n+        public void addFileGroup(EtlFileGroup etlFileGroup) {\n+            fileGroups.add(etlFileGroup);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"EtlTable{\" +\n+                    \"indexes=\" + indexes +\n+                    \", partitionInfo=\" + partitionInfo +\n+                    \", fileGroups=\" + fileGroups +\n+                    '}';\n+        }\n+    }\n+\n+    public static class EtlColumn implements Serializable {\n+        @SerializedName(value = \"columnName\")\n+        public String columnName;\n+        @SerializedName(value = \"columnType\")\n+        public String columnType;\n+        @SerializedName(value = \"isAllowNull\")\n+        public boolean isAllowNull;\n+        @SerializedName(value = \"isKey\")\n+        public boolean isKey;\n+        @SerializedName(value = \"aggregationType\")\n+        public String aggregationType;\n+        @SerializedName(value = \"defaultValue\")\n+        public String defaultValue;\n+        @SerializedName(value = \"stringLength\")\n+        public int stringLength;\n+        @SerializedName(value = \"precision\")\n+        public int precision;\n+        @SerializedName(value = \"scale\")\n+        public int scale;\n+        @SerializedName(value = \"defineExpr\")\n+        public String defineExpr;\n+\n+        // for unit test\n+        public EtlColumn() { }\n+\n+        public EtlColumn(String columnName, String columnType, boolean isAllowNull, boolean isKey,\n+                         String aggregationType, String defaultValue, int stringLength, int precision, int scale) {\n+            this.columnName = columnName;\n+            this.columnType = columnType;\n+            this.isAllowNull = isAllowNull;\n+            this.isKey = isKey;\n+            this.aggregationType = aggregationType;\n+            this.defaultValue = defaultValue;\n+            this.stringLength = stringLength;\n+            this.precision = precision;\n+            this.scale = scale;\n+            this.defineExpr = null;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"EtlColumn{\" +\n+                    \"columnName='\" + columnName + '\\'' +\n+                    \", columnType='\" + columnType + '\\'' +\n+                    \", isAllowNull=\" + isAllowNull +\n+                    \", isKey=\" + isKey +\n+                    \", aggregationType='\" + aggregationType + '\\'' +\n+                    \", defaultValue='\" + defaultValue + '\\'' +\n+                    \", stringLength=\" + stringLength +\n+                    \", precision=\" + precision +\n+                    \", scale=\" + scale +\n+                    \", defineExpr='\" + defineExpr + '\\'' +\n+                    '}';\n+        }\n+    }\n+\n+    public static class EtlIndexComparator implements Comparator<EtlIndex> {\n+        @Override\n+        public int compare(EtlIndex a, EtlIndex b) {\n+            int diff = a.columns.size() - b.columns.size();\n+            if (diff == 0) {\n+                return 0;\n+            } else if (diff > 0) {\n+                return 1;\n+            } else {\n+                return -1;\n+            }\n+        }\n+    }\n+\n+    public static class EtlIndex implements Serializable {\n+        @SerializedName(value = \"indexId\")\n+        public long indexId;\n+        @SerializedName(value = \"columns\")\n+        public List<EtlColumn> columns;\n+        @SerializedName(value = \"schemaHash\")\n+        public int schemaHash;\n+        @SerializedName(value = \"indexType\")\n+        public String indexType;\n+        @SerializedName(value = \"isBaseIndex\")\n+        public boolean isBaseIndex;\n+\n+        public EtlIndex(long indexId, List<EtlColumn> etlColumns, int schemaHash,\n+                        String indexType, boolean isBaseIndex) {\n+            this.indexId = indexId;\n+            this.columns =  etlColumns;\n+            this.schemaHash = schemaHash;\n+            this.indexType = indexType;\n+            this.isBaseIndex = isBaseIndex;\n+        }\n+\n+        public EtlColumn getColumn(String name) {\n+            for (EtlColumn column : columns) {\n+                if (column.columnName.equals(name)) {\n+                    return column;\n+                }\n+            }\n+            return null;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"EtlIndex{\" +\n+                    \"indexId=\" + indexId +\n+                    \", columns=\" + columns +\n+                    \", schemaHash=\" + schemaHash +\n+                    \", indexType='\" + indexType + '\\'' +\n+                    \", isBaseIndex=\" + isBaseIndex +\n+                    '}';\n+        }\n+    }\n+\n+    public static class EtlPartitionInfo implements Serializable {\n+        @SerializedName(value = \"partitionType\")\n+        public String partitionType;\n+        @SerializedName(value = \"partitionColumnRefs\")\n+        public List<String> partitionColumnRefs;\n+        @SerializedName(value = \"distributionColumnRefs\")\n+        public List<String> distributionColumnRefs;\n+        @SerializedName(value = \"partitions\")\n+        public List<EtlPartition> partitions;\n+\n+        public EtlPartitionInfo(String partitionType, List<String> partitionColumnRefs,\n+                                List<String> distributionColumnRefs, List<EtlPartition> etlPartitions) {\n+            this.partitionType = partitionType;\n+            this.partitionColumnRefs = partitionColumnRefs;\n+            this.distributionColumnRefs = distributionColumnRefs;\n+            this.partitions = etlPartitions;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"EtlPartitionInfo{\" +\n+                    \"partitionType='\" + partitionType + '\\'' +\n+                    \", partitionColumnRefs=\" + partitionColumnRefs +\n+                    \", distributionColumnRefs=\" + distributionColumnRefs +\n+                    \", partitions=\" + partitions +\n+                    '}';\n+        }\n+    }\n+\n+    public static class EtlPartition implements Serializable {\n+        @SerializedName(value = \"partitionId\")\n+        public long partitionId;\n+        @SerializedName(value = \"startKeys\")\n+        public List<Object> startKeys;\n+        @SerializedName(value = \"endKeys\")\n+        public List<Object> endKeys;\n+        @SerializedName(value = \"isMaxPartition\")\n+        public boolean isMaxPartition;\n+        @SerializedName(value = \"bucketNum\")\n+        public int bucketNum;\n+\n+        public EtlPartition(long partitionId, List<Object> startKeys, List<Object> endKeys,\n+                            boolean isMaxPartition, int bucketNum) {\n+            this.partitionId = partitionId;\n+            this.startKeys = startKeys;\n+            this.endKeys = endKeys;\n+            this.isMaxPartition = isMaxPartition;\n+            this.bucketNum = bucketNum;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"EtlPartition{\" +\n+                    \"partitionId=\" + partitionId +\n+                    \", startKeys=\" + startKeys +\n+                    \", endKeys=\" + endKeys +\n+                    \", isMaxPartition=\" + isMaxPartition +\n+                    \", bucketNum=\" + bucketNum +\n+                    '}';\n+        }\n+    }\n+\n+    public static class EtlFileGroup implements Serializable {\n+        @SerializedName(value = \"filePaths\")\n+        public List<String> filePaths;\n+        @SerializedName(value = \"fileFieldNames\")\n+        public List<String> fileFieldNames;\n+        @SerializedName(value = \"columnsFromPath\")\n+        public List<String> columnsFromPath;\n+        @SerializedName(value = \"columnSeparator\")\n+        public String columnSeparator;\n+        @SerializedName(value = \"lineDelimiter\")\n+        public String lineDelimiter;\n+        @SerializedName(value = \"isNegative\")\n+        public boolean isNegative;\n+        @SerializedName(value = \"fileFormat\")\n+        public String fileFormat;\n+        @SerializedName(value = \"columnMappings\")\n+        public Map<String, EtlColumnMapping> columnMappings;\n+        @SerializedName(value = \"where\")\n+        public String where;\n+        @SerializedName(value = \"partitions\")\n+        public List<Long> partitions;\n+        @SerializedName(value = \"hiveTableName\")\n+        public String hiveTableName;\n+\n+        public EtlFileGroup(List<String> filePaths, List<String> fileFieldNames, List<String> columnsFromPath,\n+                            String columnSeparator, String lineDelimiter, boolean isNegative, String fileFormat,\n+                            Map<String, EtlColumnMapping> columnMappings, String where, List<Long> partitions) {\n+            this.filePaths = filePaths;\n+            this.fileFieldNames = fileFieldNames;\n+            this.columnsFromPath = columnsFromPath;\n+            this.columnSeparator = columnSeparator;\n+            this.lineDelimiter = lineDelimiter;\n+            this.isNegative = isNegative;\n+            this.fileFormat = fileFormat;\n+            this.columnMappings = columnMappings;\n+            this.where = where;\n+            this.partitions = partitions;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"EtlFileGroup{\" +\n+                    \"filePaths=\" + filePaths +\n+                    \", fileFieldNames=\" + fileFieldNames +\n+                    \", columnsFromPath=\" + columnsFromPath +\n+                    \", columnSeparator='\" + columnSeparator + '\\'' +\n+                    \", lineDelimiter='\" + lineDelimiter + '\\'' +\n+                    \", isNegative=\" + isNegative +\n+                    \", fileFormat='\" + fileFormat + '\\'' +\n+                    \", columnMappings=\" + columnMappings +\n+                    \", where='\" + where + '\\'' +\n+                    \", partitions=\" + partitions +\n+                    \", hiveTableName='\" + hiveTableName + '\\'' +\n+                    '}';\n+        }\n+    }\n+\n+    public static class EtlColumnMapping implements Serializable {\n+        @SerializedName(value = \"functionName\")\n+        public String functionName;\n+        @SerializedName(value = \"args\")\n+        public List<String> args;\n+        @SerializedName(value = \"expr\")\n+        public String expr;\n+        public Map<String, String> functionMap =", "originalCommit": "798c0a74ab0e4d2343ec2a88af07fff85dcf7b0d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzI5MTA4MQ==", "url": "https://github.com/apache/incubator-doris/pull/3712#discussion_r433291081", "bodyText": "better to add comment for this class, make it easy to understand the relation between functionName and expr", "author": "imay", "createdAt": "2020-06-01T15:07:27Z", "path": "fe/src/main/java/org/apache/doris/load/loadv2/etl/EtlJobConfig.java", "diffHunk": "@@ -0,0 +1,548 @@\n+// Licensed to the Apache Software Foundation (ASF) under one\n+// or more contributor license agreements.  See the NOTICE file\n+// distributed with this work for additional information\n+// regarding copyright ownership.  The ASF licenses this file\n+// to you under the Apache License, Version 2.0 (the\n+// \"License\"); you may not use this file except in compliance\n+// with the License.  You may obtain a copy of the License at\n+//\n+//   http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing,\n+// software distributed under the License is distributed on an\n+// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+// KIND, either express or implied.  See the License for the\n+// specific language governing permissions and limitations\n+// under the License.\n+\n+package org.apache.doris.load.loadv2.etl;\n+\n+import org.apache.doris.persist.gson.GsonUtils;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.gson.Gson;\n+import com.google.gson.GsonBuilder;\n+import com.google.gson.annotations.SerializedName;\n+\n+import java.io.Serializable;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+\n+/** jobconfig.json file format\n+{\n+    \"tables\": {\n+        10014: {\n+            \"indexes\": [{\n+                \"indexId\": 10014,\n+                \"columns\": [{\n+                    \"columnName\": \"k1\",\n+                    \"columnType\": \"SMALLINT\",\n+                    \"isKey\": true,\n+                    \"isAllowNull\": true,\n+                    \"aggregationType\": \"NONE\"\n+                }, {\n+                    \"columnName\": \"k2\",\n+                    \"columnType\": \"VARCHAR\",\n+                    \"stringLength\": 20,\n+                    \"isKey\": true,\n+                    \"isAllowNull\": true,\n+                    \"aggregationType\": \"NONE\"\n+                }, {\n+                    \"columnName\": \"v\",\n+                    \"columnType\": \"BIGINT\",\n+                    \"isKey\": false,\n+                    \"isAllowNull\": false,\n+                    \"aggregationType\": \"NONE\"\n+                }],\n+                \"schemaHash\": 1294206574,\n+                \"indexType\": \"DUPLICATE\",\n+                \"isBaseIndex\": true\n+            }, {\n+                \"indexId\": 10017,\n+                \"columns\": [{\n+                    \"columnName\": \"k1\",\n+                    \"columnType\": \"SMALLINT\",\n+                    \"isKey\": true,\n+                    \"isAllowNull\": true,\n+                    \"aggregationType\": \"NONE\"\n+                }, {\n+                    \"columnName\": \"v\",\n+                    \"columnType\": \"BIGINT\",\n+                    \"isKey\": false,\n+                    \"isAllowNull\": false,\n+                    \"aggregationType\": \"BITMAP_UNION\",\n+                    \"defineExpr\": \"to_bitmap(v)\"\n+                }],\n+                \"schemaHash\": 1294206575,\n+                \"indexType\": \"AGGREGATE\",\n+                \"isBaseIndex\": false\n+            }],\n+            \"partitionInfo\": {\n+                \"partitionType\": \"RANGE\",\n+                \"partitionColumnRefs\": [\"k1\"],\n+                \"distributionColumnRefs\": [\"k2\"],\n+ \t            \"partitions\": [{\n+                    \"partitionId\": 10020,\n+                    \"startKeys\": [-100],\n+                    \"endKeys\": [10],\n+                    \"isMaxPartition\": false,\n+                    \"bucketNum\": 3\n+                }, {\n+                    \"partitionId\": 10021,\n+                    \"startKeys\": [10],\n+                    \"endKeys\": [100],\n+                    \"isMaxPartition\": false,\n+                    \"bucketNum\": 3\n+                }]\n+            },\n+            \"fileGroups\": [{\n+                \"partitions\": [10020],\n+                \"filePaths\": [\"hdfs://hdfs_host:port/user/palo/test/file\"],\n+                \"fileFieldNames\": [\"tmp_k1\", \"k2\"],\n+                \"valueSeparator\": \",\",\n+                \"lineDelimiter\": \"\\n\",\n+                \"columnMappings\": {\n+                    \"k1\": {\n+                        \"functionName\": \"strftime\",\n+                        \"args\": [\"%Y-%m-%d %H:%M:%S\", \"tmp_k1\"]\n+                    }\n+                },\n+                \"where\": \"k2 > 10\",\n+                \"isNegative\": false,\n+                \"hiveTableName\": \"hive_db.table\"\n+            }]\n+        }\n+    },\n+    \"outputPath\": \"hdfs://hdfs_host:port/user/output/10003/label1/1582599203397\",\n+    \"outputFilePattern\": \"label1.%d.%d.%d.%d.%d.parquet\",\n+    \"label\": \"label0\",\n+    \"properties\": {\n+        \"strictMode\": false,\n+        \"timezone\": \"Asia/Shanghai\"\n+    },\n+    \"version\": \"V1\"\n+}\n+ */\n+public class EtlJobConfig implements Serializable {\n+    // global dict\n+    public static final String GLOBAL_DICT_TABLE_NAME = \"doris_global_dict_table_%d\";\n+    public static final String DISTINCT_KEY_TABLE_NAME = \"doris_distinct_key_table_%d_%s\";\n+    public static final String DORIS_INTERMEDIATE_HIVE_TABLE_NAME = \"doris_intermediate_hive_table_%d_%s\";\n+\n+    // hdfsEtlPath/jobs/dbId/loadLabel/PendingTaskSignature\n+    private static final String ETL_OUTPUT_PATH_FORMAT = \"%s/jobs/%d/%s/%d\";\n+    private static final String ETL_OUTPUT_FILE_NAME_DESC = \"label.tableId.partitionId.indexId.bucket.schemaHash.parquet\";\n+    // tableId.partitionId.indexId.bucket.schemaHash\n+    public static final String ETL_OUTPUT_FILE_NAME_NO_LABEL_SUFFIX_FORMAT = \"%d.%d.%d.%d.%d\";\n+    public static final String ETL_OUTPUT_FILE_FORMAT = \"parquet\";\n+\n+    // dpp result\n+    public static final String DPP_RESULT_NAME = \"dpp_result.json\";\n+\n+    @SerializedName(value = \"tables\")\n+    public Map<Long, EtlTable> tables;\n+    @SerializedName(value = \"outputPath\")\n+    public String outputPath;\n+    @SerializedName(value = \"outputFilePattern\")\n+    public String outputFilePattern;\n+    @SerializedName(value = \"label\")\n+    public String label;\n+    @SerializedName(value = \"properties\")\n+    public EtlJobProperty properties;\n+    @SerializedName(value = \"version\")\n+    public Version version;\n+\n+    public EtlJobConfig(Map<Long, EtlTable> tables, String outputFilePattern, String label, EtlJobProperty properties) {\n+        this.tables = tables;\n+        // set outputPath when submit etl job\n+        this.outputPath = null;\n+        this.outputFilePattern = outputFilePattern;\n+        this.label = label;\n+        this.properties = properties;\n+        this.version = Version.V1;\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return \"EtlJobConfig{\" +\n+                \"tables=\" + tables +\n+                \", outputPath='\" + outputPath + '\\'' +\n+                \", outputFilePattern='\" + outputFilePattern + '\\'' +\n+                \", label='\" + label + '\\'' +\n+                \", properties=\" + properties +\n+                \", version=\" + version +\n+                '}';\n+    }\n+\n+    public String getOutputPath() {\n+        return outputPath;\n+    }\n+\n+    public static String getOutputPath(String hdfsEtlPath, long dbId, String loadLabel, long taskSignature) {\n+        return String.format(ETL_OUTPUT_PATH_FORMAT, hdfsEtlPath, dbId, loadLabel, taskSignature);\n+    }\n+\n+    public static String getDppResultFilePath(String outputPath) {\n+        return outputPath + \"/\" + DPP_RESULT_NAME;\n+    }\n+\n+    public static String getTabletMetaStr(String filePath) throws Exception {\n+        // ETL_OUTPUT_FILE_NAME_DESC\n+        String fileName = filePath.substring(filePath.lastIndexOf(\"/\") + 1);\n+        String[] fileNameArr = fileName.split(\"\\\\.\");\n+        if (fileNameArr.length != ETL_OUTPUT_FILE_NAME_DESC.split(\"\\\\.\").length) {\n+            throw new Exception(\"etl output file name error, format: \" + ETL_OUTPUT_FILE_NAME_DESC\n+                                        + \", name: \" + fileName);\n+        }\n+\n+        // tableId.partitionId.indexId.bucket.schemaHash\n+        return fileName.substring(fileName.indexOf(\".\") + 1, fileName.lastIndexOf(\".\"));\n+    }\n+\n+    public String configToJson() {\n+        GsonBuilder gsonBuilder = new GsonBuilder();\n+        gsonBuilder.addDeserializationExclusionStrategy(new GsonUtils.HiddenAnnotationExclusionStrategy());\n+        Gson gson = gsonBuilder.create();\n+        return gson.toJson(this);\n+    }\n+\n+    public static EtlJobConfig configFromJson(String jsonConfig) {\n+        GsonBuilder gsonBuilder = new GsonBuilder();\n+        Gson gson = gsonBuilder.create();\n+        return gson.fromJson(jsonConfig, EtlJobConfig.class);\n+    }\n+\n+    public static class EtlJobProperty implements Serializable {\n+        @SerializedName(value = \"strictMode\")\n+        public boolean strictMode;\n+        @SerializedName(value = \"timezone\")\n+        public String timezone;\n+\n+        @Override\n+        public String toString() {\n+            return \"EtlJobProperty{\" +\n+                    \"strictMode=\" + strictMode +\n+                    \", timezone='\" + timezone + '\\'' +\n+                    '}';\n+        }\n+    }\n+\n+    public static enum Version {\n+        V1\n+    }\n+\n+    public static class EtlTable implements Serializable {\n+        @SerializedName(value = \"indexes\")\n+        public List<EtlIndex> indexes;\n+        @SerializedName(value = \"partitionInfo\")\n+        public EtlPartitionInfo partitionInfo;\n+        @SerializedName(value = \"fileGroups\")\n+        public List<EtlFileGroup> fileGroups;\n+\n+        public EtlTable(List<EtlIndex> etlIndexes, EtlPartitionInfo etlPartitionInfo) {\n+            this.indexes = etlIndexes;\n+            this.partitionInfo = etlPartitionInfo;\n+            this.fileGroups = Lists.newArrayList();\n+        }\n+\n+        public void addFileGroup(EtlFileGroup etlFileGroup) {\n+            fileGroups.add(etlFileGroup);\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"EtlTable{\" +\n+                    \"indexes=\" + indexes +\n+                    \", partitionInfo=\" + partitionInfo +\n+                    \", fileGroups=\" + fileGroups +\n+                    '}';\n+        }\n+    }\n+\n+    public static class EtlColumn implements Serializable {\n+        @SerializedName(value = \"columnName\")\n+        public String columnName;\n+        @SerializedName(value = \"columnType\")\n+        public String columnType;\n+        @SerializedName(value = \"isAllowNull\")\n+        public boolean isAllowNull;\n+        @SerializedName(value = \"isKey\")\n+        public boolean isKey;\n+        @SerializedName(value = \"aggregationType\")\n+        public String aggregationType;\n+        @SerializedName(value = \"defaultValue\")\n+        public String defaultValue;\n+        @SerializedName(value = \"stringLength\")\n+        public int stringLength;\n+        @SerializedName(value = \"precision\")\n+        public int precision;\n+        @SerializedName(value = \"scale\")\n+        public int scale;\n+        @SerializedName(value = \"defineExpr\")\n+        public String defineExpr;\n+\n+        // for unit test\n+        public EtlColumn() { }\n+\n+        public EtlColumn(String columnName, String columnType, boolean isAllowNull, boolean isKey,\n+                         String aggregationType, String defaultValue, int stringLength, int precision, int scale) {\n+            this.columnName = columnName;\n+            this.columnType = columnType;\n+            this.isAllowNull = isAllowNull;\n+            this.isKey = isKey;\n+            this.aggregationType = aggregationType;\n+            this.defaultValue = defaultValue;\n+            this.stringLength = stringLength;\n+            this.precision = precision;\n+            this.scale = scale;\n+            this.defineExpr = null;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"EtlColumn{\" +\n+                    \"columnName='\" + columnName + '\\'' +\n+                    \", columnType='\" + columnType + '\\'' +\n+                    \", isAllowNull=\" + isAllowNull +\n+                    \", isKey=\" + isKey +\n+                    \", aggregationType='\" + aggregationType + '\\'' +\n+                    \", defaultValue='\" + defaultValue + '\\'' +\n+                    \", stringLength=\" + stringLength +\n+                    \", precision=\" + precision +\n+                    \", scale=\" + scale +\n+                    \", defineExpr='\" + defineExpr + '\\'' +\n+                    '}';\n+        }\n+    }\n+\n+    public static class EtlIndexComparator implements Comparator<EtlIndex> {\n+        @Override\n+        public int compare(EtlIndex a, EtlIndex b) {\n+            int diff = a.columns.size() - b.columns.size();\n+            if (diff == 0) {\n+                return 0;\n+            } else if (diff > 0) {\n+                return 1;\n+            } else {\n+                return -1;\n+            }\n+        }\n+    }\n+\n+    public static class EtlIndex implements Serializable {\n+        @SerializedName(value = \"indexId\")\n+        public long indexId;\n+        @SerializedName(value = \"columns\")\n+        public List<EtlColumn> columns;\n+        @SerializedName(value = \"schemaHash\")\n+        public int schemaHash;\n+        @SerializedName(value = \"indexType\")\n+        public String indexType;\n+        @SerializedName(value = \"isBaseIndex\")\n+        public boolean isBaseIndex;\n+\n+        public EtlIndex(long indexId, List<EtlColumn> etlColumns, int schemaHash,\n+                        String indexType, boolean isBaseIndex) {\n+            this.indexId = indexId;\n+            this.columns =  etlColumns;\n+            this.schemaHash = schemaHash;\n+            this.indexType = indexType;\n+            this.isBaseIndex = isBaseIndex;\n+        }\n+\n+        public EtlColumn getColumn(String name) {\n+            for (EtlColumn column : columns) {\n+                if (column.columnName.equals(name)) {\n+                    return column;\n+                }\n+            }\n+            return null;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"EtlIndex{\" +\n+                    \"indexId=\" + indexId +\n+                    \", columns=\" + columns +\n+                    \", schemaHash=\" + schemaHash +\n+                    \", indexType='\" + indexType + '\\'' +\n+                    \", isBaseIndex=\" + isBaseIndex +\n+                    '}';\n+        }\n+    }\n+\n+    public static class EtlPartitionInfo implements Serializable {\n+        @SerializedName(value = \"partitionType\")\n+        public String partitionType;\n+        @SerializedName(value = \"partitionColumnRefs\")\n+        public List<String> partitionColumnRefs;\n+        @SerializedName(value = \"distributionColumnRefs\")\n+        public List<String> distributionColumnRefs;\n+        @SerializedName(value = \"partitions\")\n+        public List<EtlPartition> partitions;\n+\n+        public EtlPartitionInfo(String partitionType, List<String> partitionColumnRefs,\n+                                List<String> distributionColumnRefs, List<EtlPartition> etlPartitions) {\n+            this.partitionType = partitionType;\n+            this.partitionColumnRefs = partitionColumnRefs;\n+            this.distributionColumnRefs = distributionColumnRefs;\n+            this.partitions = etlPartitions;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"EtlPartitionInfo{\" +\n+                    \"partitionType='\" + partitionType + '\\'' +\n+                    \", partitionColumnRefs=\" + partitionColumnRefs +\n+                    \", distributionColumnRefs=\" + distributionColumnRefs +\n+                    \", partitions=\" + partitions +\n+                    '}';\n+        }\n+    }\n+\n+    public static class EtlPartition implements Serializable {\n+        @SerializedName(value = \"partitionId\")\n+        public long partitionId;\n+        @SerializedName(value = \"startKeys\")\n+        public List<Object> startKeys;\n+        @SerializedName(value = \"endKeys\")\n+        public List<Object> endKeys;\n+        @SerializedName(value = \"isMaxPartition\")\n+        public boolean isMaxPartition;\n+        @SerializedName(value = \"bucketNum\")\n+        public int bucketNum;\n+\n+        public EtlPartition(long partitionId, List<Object> startKeys, List<Object> endKeys,\n+                            boolean isMaxPartition, int bucketNum) {\n+            this.partitionId = partitionId;\n+            this.startKeys = startKeys;\n+            this.endKeys = endKeys;\n+            this.isMaxPartition = isMaxPartition;\n+            this.bucketNum = bucketNum;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"EtlPartition{\" +\n+                    \"partitionId=\" + partitionId +\n+                    \", startKeys=\" + startKeys +\n+                    \", endKeys=\" + endKeys +\n+                    \", isMaxPartition=\" + isMaxPartition +\n+                    \", bucketNum=\" + bucketNum +\n+                    '}';\n+        }\n+    }\n+\n+    public static class EtlFileGroup implements Serializable {\n+        @SerializedName(value = \"filePaths\")\n+        public List<String> filePaths;\n+        @SerializedName(value = \"fileFieldNames\")\n+        public List<String> fileFieldNames;\n+        @SerializedName(value = \"columnsFromPath\")\n+        public List<String> columnsFromPath;\n+        @SerializedName(value = \"columnSeparator\")\n+        public String columnSeparator;\n+        @SerializedName(value = \"lineDelimiter\")\n+        public String lineDelimiter;\n+        @SerializedName(value = \"isNegative\")\n+        public boolean isNegative;\n+        @SerializedName(value = \"fileFormat\")\n+        public String fileFormat;\n+        @SerializedName(value = \"columnMappings\")\n+        public Map<String, EtlColumnMapping> columnMappings;\n+        @SerializedName(value = \"where\")\n+        public String where;\n+        @SerializedName(value = \"partitions\")\n+        public List<Long> partitions;\n+        @SerializedName(value = \"hiveTableName\")\n+        public String hiveTableName;\n+\n+        public EtlFileGroup(List<String> filePaths, List<String> fileFieldNames, List<String> columnsFromPath,\n+                            String columnSeparator, String lineDelimiter, boolean isNegative, String fileFormat,\n+                            Map<String, EtlColumnMapping> columnMappings, String where, List<Long> partitions) {\n+            this.filePaths = filePaths;\n+            this.fileFieldNames = fileFieldNames;\n+            this.columnsFromPath = columnsFromPath;\n+            this.columnSeparator = columnSeparator;\n+            this.lineDelimiter = lineDelimiter;\n+            this.isNegative = isNegative;\n+            this.fileFormat = fileFormat;\n+            this.columnMappings = columnMappings;\n+            this.where = where;\n+            this.partitions = partitions;\n+        }\n+\n+        @Override\n+        public String toString() {\n+            return \"EtlFileGroup{\" +\n+                    \"filePaths=\" + filePaths +\n+                    \", fileFieldNames=\" + fileFieldNames +\n+                    \", columnsFromPath=\" + columnsFromPath +\n+                    \", columnSeparator='\" + columnSeparator + '\\'' +\n+                    \", lineDelimiter='\" + lineDelimiter + '\\'' +\n+                    \", isNegative=\" + isNegative +\n+                    \", fileFormat='\" + fileFormat + '\\'' +\n+                    \", columnMappings=\" + columnMappings +\n+                    \", where='\" + where + '\\'' +\n+                    \", partitions=\" + partitions +\n+                    \", hiveTableName='\" + hiveTableName + '\\'' +\n+                    '}';\n+        }\n+    }\n+\n+    public static class EtlColumnMapping implements Serializable {\n+        @SerializedName(value = \"functionName\")\n+        public String functionName;\n+        @SerializedName(value = \"args\")\n+        public List<String> args;\n+        @SerializedName(value = \"expr\")\n+        public String expr;", "originalCommit": "798c0a74ab0e4d2343ec2a88af07fff85dcf7b0d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e162b6e8392b4f4fc12f3f1c8b438b8a89075b43", "url": "https://github.com/apache/incubator-doris/commit/e162b6e8392b4f4fc12f3f1c8b438b8a89075b43", "message": "Add file pattern version and some comments", "committedDate": "2020-06-02T07:29:53Z", "type": "commit"}]}