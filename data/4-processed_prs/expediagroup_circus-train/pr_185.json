{"pr_number": 185, "pr_title": "Full overwrite replication", "pr_createdAt": "2020-05-12T16:29:54Z", "pr_url": "https://github.com/ExpediaGroup/circus-train/pull/185", "timeline": [{"oid": "642932ca0c112d47a59db88ffe8da96e6ca18ac8", "url": "https://github.com/ExpediaGroup/circus-train/commit/642932ca0c112d47a59db88ffe8da96e6ca18ac8", "message": "Added new replication mode to overwrite tables", "committedDate": "2020-05-05T15:49:13Z", "type": "commit"}, {"oid": "068a9d5254716512e9b991ac851ba6e856a131c0", "url": "https://github.com/ExpediaGroup/circus-train/commit/068a9d5254716512e9b991ac851ba6e856a131c0", "message": "Updating changelog", "committedDate": "2020-05-05T15:53:21Z", "type": "commit"}, {"oid": "eb4d269b0148cd47c47c1846820f04555da75bc6", "url": "https://github.com/ExpediaGroup/circus-train/commit/eb4d269b0148cd47c47c1846820f04555da75bc6", "message": "Added integration tests", "committedDate": "2020-05-12T14:16:22Z", "type": "commit"}, {"oid": "77c6564f7ff0b36066f3796103817d1a9756d258", "url": "https://github.com/ExpediaGroup/circus-train/commit/77c6564f7ff0b36066f3796103817d1a9756d258", "message": "Added more tests", "committedDate": "2020-05-12T14:42:06Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4MDcwOA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423880708", "bodyText": "I think this and the added case in the other switch statement needs some tests", "author": "max-jacobs", "createdAt": "2020-05-12T16:44:15Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/ReplicationFactoryImpl.java", "diffHunk": "@@ -107,6 +107,7 @@ private Replication createPartitionedTableReplication(\n       replication = new PartitionedTableMetadataMirrorReplication(sourceDatabaseName, sourceTableName,\n           partitionPredicate, source, replica, eventIdFactory, replicaDatabaseName, replicaTableName);\n       break;\n+    case FULL_OVERWRITE:", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4NzE3Ng==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423887176", "bodyText": "Would recommend moving this method to the DropTableService. Also, on a full overwrite I imagine we will want to delete the current data (right?), but if we're using Beekeeper drop table events will be ignored (unless we add the param to allow drop table events). But even if we do this, we won't want to schedule the table path because then Beekeeper will delete any new data that is added after the delete - Beekeeper doesn't yet go to the Metastore to only schedule the current partitions for deletion on a table drop.\nWe probably want to do an alter all the individual partitions to make sure they're deleted and not the new data? Not sure, is that possible?", "author": "max-jacobs", "createdAt": "2020-05-12T16:53:57Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -426,4 +436,25 @@ public TableAndStatistics getTableAndStatistics(TableReplication tableReplicatio\n     return super.getTableAndStatistics(tableReplication.getReplicaDatabaseName(),\n         tableReplication.getReplicaTableName());\n   }\n+\n+  private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName) {", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkyMDU4MA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423920580", "bodyText": "If the old replica is dropped, and then later the new replica is recreated, and all new data and partitions are put in a new ctp-... folder, won't Beekeeper eventually find and delete all the old ctp paths from the old (dropped) version of the table?  Or what am I missing?", "author": "barnharts4", "createdAt": "2020-05-12T17:47:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4NzE3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDM0NzMxOA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r424347318", "bodyText": "Spoke with the team, we think that this is true for unpartitioned tables, but for partitioned tables the table path doesn't include the event id, the partition paths do instead. So we can't do a drop without first making sure that Beekeeper isn't listening otherwise we'll lose all the new data too.", "author": "max-jacobs", "createdAt": "2020-05-13T10:52:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4NzE3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4Nzk5NQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423887995", "bodyText": "think you need a fail here to make sure this throws an exception", "author": "max-jacobs", "createdAt": "2020-05-12T16:55:05Z", "path": "circus-train-core/src/test/java/com/hotels/bdp/circustrain/core/replica/ReplicaTest.java", "diffHunk": "@@ -323,6 +327,60 @@ public void validateReplicaTableMetadataMirrorOnExistingMetadataUpdateTableFails\n     }\n   }\n \n+  @Test\n+  public void validateReplicaTableMetadataMirrorOnExistingFullOverwriteReplicationTableFails()\n+    throws TException, IOException {\n+    try {\n+      existingReplicaTable.putToParameters(REPLICATION_EVENT.parameterName(), \"previousEventId\");\n+      existingReplicaTable.putToParameters(REPLICATION_MODE.parameterName(), FULL_OVERWRITE.name());\n+      tableReplication.setReplicationMode(METADATA_MIRROR);\n+      replica = newReplica(tableReplication);\n+      replica.validateReplicaTable(DB_NAME, TABLE_NAME);\n+      fail(\"Should have thrown InvalidReplicationModeException\");\n+    } catch (InvalidReplicationModeException e) {\n+      // Check that nothing was written to the metastore\n+      verify(mockMetaStoreClient).getTable(DB_NAME, TABLE_NAME);\n+      verify(mockMetaStoreClient).close();\n+      verifyNoMoreInteractions(mockMetaStoreClient);\n+    }\n+  }\n+\n+  @Test\n+  public void validateFullOverwriteReplicationOnExistingTableSucceeds() throws TException {\n+    existingReplicaTable.putToParameters(REPLICATION_EVENT.parameterName(), \"previousEventId\");\n+    existingReplicaTable.putToParameters(REPLICATION_MODE.parameterName(), FULL.name());\n+    tableReplication.setReplicationMode(FULL_OVERWRITE);\n+\n+    replica\n+        .updateMetadata(EVENT_ID, tableAndStatistics,\n+            new PartitionsAndStatistics(sourceTable.getPartitionKeys(), Collections.<Partition>emptyList(),\n+                Collections.<String, List<ColumnStatisticsObj>>emptyMap()),\n+            DB_NAME, TABLE_NAME, mockReplicaLocationManager);\n+    verify(alterTableService).alterTable(eq(mockMetaStoreClient), eq(existingReplicaTable), any(Table.class));\n+    verify(mockMetaStoreClient).updateTableColumnStatistics(columnStatistics);\n+    verify(mockReplicaLocationManager, never()).addCleanUpLocation(anyString(), any(Path.class));\n+  }\n+\n+  @Test\n+  public void validateFullOverwriteReplicationWithoutExistingTableFails() throws MetaException, TException {\n+    try {\n+    when(mockMetaStoreClient.tableExists(DB_NAME, TABLE_NAME)).thenReturn(false);\n+\n+    tableReplication.setReplicationMode(FULL_OVERWRITE);\n+    replica\n+        .updateMetadata(EVENT_ID, tableAndStatistics,\n+            new PartitionsAndStatistics(sourceTable.getPartitionKeys(), Collections.<Partition>emptyList(),\n+                Collections.<String, List<ColumnStatisticsObj>>emptyMap()),\n+            DB_NAME, TABLE_NAME, mockReplicaLocationManager);\n+", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4OTAyNA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423889024", "bodyText": "I think at some point we should think about removing all these duplicated yaml files and building them programmatically, just an idea", "author": "max-jacobs", "createdAt": "2020-05-12T16:56:39Z", "path": "circus-train-integration-tests/src/test/data/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest/partitioned-single-table-full-overwrite.yml", "diffHunk": "@@ -0,0 +1,9 @@\n+table-replications:", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA0NDU3NQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425044575", "bodyText": "The intention initially was for the integration tests to read in the yaml to ensure the yaml conversion code etc. is working. I don't think we envisioned there being this many integration tests, ideally we should only add them to test things that can't be tested in any other way.", "author": "massdosage", "createdAt": "2020-05-14T10:47:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4OTAyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA3OTc1Mw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425079753", "bodyText": "Yep understood, we could have a couple of template yaml files, and create temp files from these for each test on the fly", "author": "max-jacobs", "createdAt": "2020-05-14T11:56:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4OTAyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA4NTA3Ng==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425085076", "bodyText": "Adrian suggested that I add an integration test class for the replication modes, so that will remove all these duplicated files \ud83d\udc4d", "author": "JayGreeeen", "createdAt": "2020-05-14T12:06:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4OTAyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTEwMDIzNA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425100234", "bodyText": "I think a separate task could be to evaluate the existing integration tests, clean them up so we have the minimal necessary and we could look into templated files as part of that. I'd suggest a separate PR though.", "author": "massdosage", "createdAt": "2020-05-14T12:33:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg4OTAyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkyMjM2Mw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r423922363", "bodyText": "Is throwing a No replica table exception necessary here?  What does it buy us?  If a warning were logged here instead, then wouldn't the FULL_OVERWRITE proceed just as a normal FULL operation, and the end result would be just what the user wanted?", "author": "barnharts4", "createdAt": "2020-05-12T17:50:39Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -426,4 +436,25 @@ public TableAndStatistics getTableAndStatistics(TableReplication tableReplicatio\n     return super.getTableAndStatistics(tableReplication.getReplicaDatabaseName(),\n         tableReplication.getReplicaTableName());\n   }\n+\n+  private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName) {\n+    LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table.\");\n+    try {\n+      if (client.tableExists(replicaDatabaseName, replicaTableName)) {\n+        client.dropTable(replicaDatabaseName, replicaTableName);\n+      } else {\n+        throw new MetaStoreClientException(\"No replica table '\"\n+            + replicaDatabaseName\n+            + \".\"\n+            + replicaTableName\n+            + \"' found, cannot overwrite. Rerun with a different table name or change replication mode to \"\n+            + FULL.name()\n+            + \".\");\n+      }", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNjA5Ng==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r424526096", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private void setupRelicaParameters(Table replicaTable) {\n          \n          \n            \n              private void setupReplicaParameters(Table replicaTable) {", "author": "abhimanyugupta07", "createdAt": "2020-05-13T15:24:40Z", "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -850,6 +851,123 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable with additional columns\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    TestUtils\n+        .createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_PARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        List<Partition> partitions = replicaCatalog\n+            .client()\n+            .listPartitions(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, (short) 50);\n+        assertThat(partitions.size(), is(2));\n+        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n+        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void unpartitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    TestUtils\n+        .createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE,\n+            replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_UNPARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctt-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n+    setupRelicaParameters(replicaTable);\n+    if (partitioned) {\n+      addPartitionsToReplica(replicaTable, replicaLocation);\n+    }\n+  }\n+\n+  private void setupRelicaParameters(Table replicaTable) {", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUyNzg5Mw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r424527893", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                setupRelicaParameters(replicaTable);\n          \n          \n            \n                setupReplicaParameters(replicaTable);", "author": "abhimanyugupta07", "createdAt": "2020-05-13T15:27:08Z", "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -850,6 +851,123 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable with additional columns\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    TestUtils\n+        .createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_PARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        List<Partition> partitions = replicaCatalog\n+            .client()\n+            .listPartitions(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, (short) 50);\n+        assertThat(partitions.size(), is(2));\n+        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n+        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void unpartitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    TestUtils\n+        .createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE,\n+            replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_UNPARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctt-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n+    setupRelicaParameters(replicaTable);", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUzMDM4OQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r424530389", "bodyText": "This function is not just setting params but also adding two new columns to the table. Splitting this function up would be better.", "author": "abhimanyugupta07", "createdAt": "2020-05-13T15:30:06Z", "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainHdfsHdfsIntegrationTest.java", "diffHunk": "@@ -850,6 +851,123 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable with additional columns\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    TestUtils\n+        .createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_PARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        List<Partition> partitions = replicaCatalog\n+            .client()\n+            .listPartitions(DATABASE, TARGET_PARTITIONED_MANAGED_TABLE, (short) 50);\n+        assertThat(partitions.size(), is(2));\n+        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n+        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void unpartitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedUnpartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    LOG.info(\">>>> Table {} \", sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    // creating replicaTable\n+    final URI replicaLocation = toUri(replicaWarehouseUri, DATABASE, SOURCE_MANAGED_UNPARTITIONED_TABLE);\n+    TestUtils\n+        .createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE,\n+            replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_MANAGED_TABLE);\n+        assertThat(hiveTable.getDbName(), is(DATABASE));\n+        assertThat(hiveTable.getTableName(), is(TARGET_UNPARTITIONED_MANAGED_TABLE));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctt-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(isExternalTable(hiveTable), is(true));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n+    setupRelicaParameters(replicaTable);\n+    if (partitioned) {\n+      addPartitionsToReplica(replicaTable, replicaLocation);\n+    }\n+  }\n+\n+  private void setupRelicaParameters(Table replicaTable) {", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDUzMzcxNQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r424533715", "bodyText": "same comments here. Typo and splitting up.", "author": "abhimanyugupta07", "createdAt": "2020-05-13T15:34:37Z", "path": "circus-train-integration-tests/src/test/java/com/hotels/bdp/circustrain/integration/CircusTrainS3S3IntegrationTest.java", "diffHunk": "@@ -273,4 +282,139 @@ public void checkAssertion() throws Exception {\n     runner.run(config.getAbsolutePath());\n   }\n \n+  @Test\n+  public void partitionedTableFullOverwrite() throws Exception {\n+    helper.createManagedPartitionedTable(toUri(sourceWarehouseUri, DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE));\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, SOURCE_MANAGED_PARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    final URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, TARGET_PARTITIONED_TABLE);\n+    TestUtils.createPartitionedTable(replicaCatalog.client(), DATABASE, TARGET_PARTITIONED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_TABLE);\n+\n+    // setting up parameters, additional columns and partitions\n+    setupReplicaTable(replicaTable, true, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"partitioned-single-table-full-overwrite-replication.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .copierOption(S3S3CopierOptions.Keys.S3_ENDPOINT_URI.keyName(), s3Proxy.getUri().toString())\n+        .sourceConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n+        .replicaConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n+        .replicaConfigurationProperty(ACCESS_KEY, s3Proxy.getAccessKey())\n+        .replicaConfigurationProperty(SECRET_KEY, s3Proxy.getSecretKey())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_PARTITIONED_TABLE);\n+        URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, TARGET_PARTITIONED_TABLE);\n+        assertThat(hiveTable.getSd().getLocation(), is(replicaLocation.toString()));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_EVENT.parameterName()), startsWith(\"ctp-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        List<Partition> partitions = replicaCatalog\n+            .client()\n+            .listPartitions(DATABASE, TARGET_PARTITIONED_TABLE, (short) -1);\n+        assertThat(partitions.size(), is(2));\n+        assertThat(partitions.get(0).getValues(), is(Arrays.asList(\"Asia\", \"China\")));\n+        assertThat(partitions.get(1).getValues(), is(Arrays.asList(\"Europe\", \"UK\")));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  @Test\n+  public void unpartitionedTableFullOverwrite() throws Exception {\n+    final URI sourceTableLocation = toUri(\"s3a://source/\", DATABASE, UNPARTITIONED_TABLE);\n+    TestUtils.createUnpartitionedTable(sourceCatalog.client(), DATABASE, UNPARTITIONED_TABLE, sourceTableLocation);\n+    // adjusting the sourceTable, mimicking the change we want to update\n+    Table sourceTable = sourceCatalog.client().getTable(DATABASE, UNPARTITIONED_TABLE);\n+    sourceTable.putToParameters(\"paramToUpdate\", \"updated\");\n+    sourceCatalog.client().alter_table(sourceTable.getDbName(), sourceTable.getTableName(), sourceTable);\n+\n+    final File dataFile = temporaryFolder.newFile();\n+    FileUtils.writeStringToFile(dataFile, \"1\\trob\\tbristol\\n2\\tsam\\ttoronto\\n\");\n+    String fileKey = String.format(\"%s/%s/%s\", DATABASE, UNPARTITIONED_TABLE, PART_00000);\n+    s3Client.putObject(\"source\", fileKey, dataFile);\n+\n+    // creating replicaTable\n+    final URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, UNPARTITIONED_TABLE);\n+    TestUtils.createUnpartitionedTable(replicaCatalog.client(), DATABASE, TARGET_UNPARTITIONED_TABLE, replicaLocation);\n+    Table replicaTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_TABLE);\n+    // setting up parameters and additional columns\n+    setupReplicaTable(replicaTable, false, replicaLocation);\n+    replicaCatalog.client().alter_table(replicaTable.getDbName(), replicaTable.getTableName(), replicaTable);\n+\n+    exit.expectSystemExitWithStatus(0);\n+    File config = dataFolder.getFile(\"unpartitioned-single-table-full-overwrite-replication.yml\");\n+    CircusTrainRunner runner = CircusTrainRunner\n+        .builder(DATABASE, sourceWarehouseUri, replicaWarehouseUri, housekeepingDbLocation)\n+        .sourceMetaStore(sourceCatalog.getThriftConnectionUri(), sourceCatalog.connectionURL(),\n+            sourceCatalog.driverClassName())\n+        .replicaMetaStore(replicaCatalog.getThriftConnectionUri())\n+        .copierOption(S3S3CopierOptions.Keys.S3_ENDPOINT_URI.keyName(), s3Proxy.getUri().toString())\n+        .sourceConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n+        .replicaConfigurationProperty(ENDPOINT, s3Proxy.getUri().toString())\n+        .replicaConfigurationProperty(ACCESS_KEY, s3Proxy.getAccessKey())\n+        .replicaConfigurationProperty(SECRET_KEY, s3Proxy.getSecretKey())\n+        .build();\n+    exit.checkAssertionAfterwards(new Assertion() {\n+      @Override\n+      public void checkAssertion() throws Exception {\n+        Table hiveTable = replicaCatalog.client().getTable(DATABASE, TARGET_UNPARTITIONED_TABLE);\n+        String eventId = hiveTable.getParameters().get(REPLICATION_EVENT.parameterName());\n+        URI replicaLocation = toUri(\"s3a://replica/\", DATABASE, TARGET_UNPARTITIONED_TABLE + \"/\" + eventId);\n+        assertThat(hiveTable.getSd().getLocation(), is(replicaLocation.toString()));\n+        assertThat(eventId, startsWith(\"ctt-\"));\n+        assertThat(hiveTable.getParameters().get(REPLICATION_MODE.parameterName()), is(\"FULL_OVERWRITE\"));\n+        assertThat(hiveTable.getParameters().get(\"paramToUpdate\"), is(\"updated\"));\n+        assertThat(hiveTable.getSd().getCols(), is(DATA_COLUMNS));\n+\n+        // Assert files copied from source\n+        List<S3ObjectSummary> replicaFiles = TestUtils.listObjects(s3Client, \"replica\");\n+        assertThat(replicaFiles.size(), is(1));\n+        assertThat(replicaFiles.get(0).getSize(), is(dataFile.length()));\n+        String fileKey = String\n+            .format(\"%s/%s/%s/%s\", DATABASE, TARGET_UNPARTITIONED_TABLE, eventId, PART_00000);\n+        assertThat(replicaFiles.get(0).getKey(), is(fileKey));\n+      }\n+    });\n+    runner.run(config.getAbsolutePath());\n+  }\n+\n+  private void setupReplicaTable(Table replicaTable, boolean partitioned, URI replicaLocation) throws Exception {\n+    setupRelicaParameters(replicaTable);\n+    if (partitioned) {\n+      addPartitionsToReplica(replicaTable, replicaLocation);\n+    }\n+  }\n+\n+  private void setupRelicaParameters(Table replicaTable) {", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA0MTYyMw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425041623", "bodyText": "Let's go with 16.2.0 as the version number as this is a new feature.", "author": "massdosage", "createdAt": "2020-05-14T10:41:44Z", "path": "CHANGELOG.md", "diffHunk": "@@ -2,6 +2,9 @@\n ### Changed\n * Changed version of `hive.version` to `2.3.7` (was `2.3.2`). This allows Circus Train to be used on JDK>=9.\n \n+### Added\n+* Replication mode `FULL_OVERWRITE` to overwrite a previously replicated table. Useful for incompatible schema changes. ", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA0MjAwNg==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425042006", "bodyText": "Good spot ;)", "author": "massdosage", "createdAt": "2020-05-14T10:42:29Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -346,12 +351,12 @@ public void validateReplicaTable(String replicaDatabaseName, String replicaTable\n       Optional<Table> oldReplicaTable = getTable(client, replicaDatabaseName, replicaTableName);\n       if (oldReplicaTable.isPresent()) {\n         LOG.debug(\"Existing table found, checking that it is a valid replica.\");\n-        determinValidityOfReplica(replicationMode, oldReplicaTable.get());\n+        determineValidityOfReplica(replicationMode, oldReplicaTable.get());", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA0MjQwNA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425042404", "bodyText": "Move this up to below FULL - they feel more \"related\" and I don't think we use the ordering of this enum for anything.", "author": "massdosage", "createdAt": "2020-05-14T10:43:12Z", "path": "circus-train-api/src/main/java/com/hotels/bdp/circustrain/api/conf/ReplicationMode.java", "diffHunk": "@@ -19,6 +19,8 @@\n \n   FULL,\n   METADATA_MIRROR,\n-  METADATA_UPDATE;\n+  METADATA_UPDATE,\n+  FULL_OVERWRITE;", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA0NzM0Nw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425047347", "bodyText": "Having looked through the above I'm not sure we need to add these tests to all combinations of HDFS and S3 as they probably don't really test anything new in each of them right? Perhaps create a new CircusTrainReplicationModeIntegrationTest and then put the two tests into that and have it use S3 to S3 for the location on each side (as that's becoming the most used file system on both sides now).\nAt some point we should review the other integration tests and see if there is other overlap that isn't needed that can be refactored out to reduce the number of these.", "author": "massdosage", "createdAt": "2020-05-14T10:52:41Z", "path": "circus-train-integration-tests/src/test/data/com/hotels/bdp/circustrain/integration/CircusTrainS3S3IntegrationTest/unpartitioned-single-table-full-overwrite-replication.yml", "diffHunk": "@@ -0,0 +1,10 @@\n+table-replications:", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA1ODA1OA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425058058", "bodyText": "Yeah it felt pretty repetitive, this sounds like a better idea \ud83d\udc4d", "author": "JayGreeeen", "createdAt": "2020-05-14T11:13:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTA0NzM0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTEzMTY4NA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r425131684", "bodyText": "This call is a \"new\" addition of the hive API I'm not sure if we use it anywhere else but if we do it is ok but if we don't better to avoid using it as it's not always there on old client.\nBetter to just do the\nTry\ndropTable() \nCatch(NoSuchObjectException e) {\n//nothing to drop table doesn't exist etc.....\n}", "author": "patduin", "createdAt": "2020-05-14T13:22:35Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -426,4 +436,25 @@ public TableAndStatistics getTableAndStatistics(TableReplication tableReplicatio\n     return super.getTableAndStatistics(tableReplication.getReplicaDatabaseName(),\n         tableReplication.getReplicaTableName());\n   }\n+\n+  private void dropReplicaTable(CloseableMetaStoreClient client, String replicaDatabaseName, String replicaTableName) {\n+    LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table.\");\n+    try {\n+      if (client.tableExists(replicaDatabaseName, replicaTableName)) {", "originalCommit": "77c6564f7ff0b36066f3796103817d1a9756d258", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "7f25cff5174805a209500a7cffcb7faf4fe121ff", "url": "https://github.com/ExpediaGroup/circus-train/commit/7f25cff5174805a209500a7cffcb7faf4fe121ff", "message": "Created integration test for new replication mode.", "committedDate": "2020-05-28T11:58:55Z", "type": "commit"}, {"oid": "bb0d8dc12554a6194e6031889b5b78681826737f", "url": "https://github.com/ExpediaGroup/circus-train/commit/bb0d8dc12554a6194e6031889b5b78681826737f", "message": "Cleaning up", "committedDate": "2020-05-28T12:02:24Z", "type": "commit"}, {"oid": "b623630151a38a8a703747896485d295add8b627", "url": "https://github.com/ExpediaGroup/circus-train/commit/b623630151a38a8a703747896485d295add8b627", "message": "Added tests for switch case, and removed comments", "committedDate": "2020-05-28T12:09:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434461002", "bodyText": "I think the TException could be thrown for other reasons too, like network problems etc. So perhaps it would be better to have a try/catch for TException that retrhrows a MetaStoreClientException like in some of the blocks below, and then introduce a \"does table exist\" check in the code (maybe in the service?) and if it doesn't then it just silently continues without throwing an exception (as this is fine, there's no need to drop the replica if it doesn't exist).", "author": "massdosage", "createdAt": "2020-06-03T10:15:58Z", "path": "circus-train-core/src/main/java/com/hotels/bdp/circustrain/core/replica/Replica.java", "diffHunk": "@@ -302,6 +304,16 @@ public void updateMetadata(\n     LOG.info(\"Updating replica table metadata.\");\n     TableAndStatistics replicaTable = tableFactory\n         .newReplicaTable(eventId, sourceTable, replicaDatabaseName, replicaTableName, tableLocation, replicationMode);\n+\n+    if (replicationMode == FULL_OVERWRITE) {\n+      LOG.debug(\"Replication mode: FULL_OVERWRITE. Dropping existing replica table and its data.\");\n+      DropTableService dropTableService = new DropTableService();\n+      try {\n+        dropTableService.removeTableParamsAndDrop(client, replicaDatabaseName, replicaTableName);\n+      } catch (TException e) {\n+        LOG.info(\"No replica table '\" + replicaDatabaseName + \".\" + replicaTableName + \"' found. Nothing to delete.\");", "originalCommit": "b623630151a38a8a703747896485d295add8b627", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2Mzg0OA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434463848", "bodyText": "NoSuchObjectException is the one that get's throw if the table/db doesn't exist", "author": "patduin", "createdAt": "2020-06-03T10:21:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2NjYyMw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434466623", "bodyText": "OK, so we could have a more specific catch block for that here, or do we want to change the service to not throw that and silently continue? Do we have other cases that use it where we want that exception thrown?", "author": "massdosage", "createdAt": "2020-06-03T10:26:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2NjkzMg==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434466932", "bodyText": "Yeah I also realised this. I have fixed it in the other branch I have for deleting data so its now:\n} catch (Exception e) {\n   LOG.info(\"Replica table '\" + replicaDatabaseName + \".\" + replicaTableName + \"' was not dropped.\");\n}\n\nAnd in the drop table service it catches the NoSuchObj exception and logs that the table wasnt found.", "author": "JayGreeeen", "createdAt": "2020-06-03T10:27:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ3MDMyMA==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434470320", "bodyText": "Do you want to update this branch too? The plan is to merge the branches in separately right? First this one to get the \"drop metadata\" changes in and then the other one gets the \"drop file data\" changes.", "author": "massdosage", "createdAt": "2020-06-03T10:33:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ3NDYxNQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434474615", "bodyText": "Yeah thats the plan. Will update this one with those logs \ud83d\udc4d", "author": "JayGreeeen", "createdAt": "2020-06-03T10:41:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ4MDU1NQ==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434480555", "bodyText": "I think it is ok that the DropTableService swallows the NoSuchObjectE. But then I agree with Adrian this block should catch and rethrow MetaStoreClientException. Don't log anything that's not up to this class to silently ignore this.", "author": "patduin", "createdAt": "2020-06-03T10:54:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ5NjcxMw==", "url": "https://github.com/ExpediaGroup/circus-train/pull/185#discussion_r434496713", "bodyText": "Thats a good point. Will log the NoSuchObj inside the dropTableService, and here will throw a MetaStoreClientExc in the catch.", "author": "JayGreeeen", "createdAt": "2020-06-03T11:27:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDQ2MTAwMg=="}], "type": "inlineReview"}, {"oid": "54e16b0e8dd4e90cb193bae8f74d3e6d724d3920", "url": "https://github.com/ExpediaGroup/circus-train/commit/54e16b0e8dd4e90cb193bae8f74d3e6d724d3920", "message": "Changing log messages", "committedDate": "2020-06-03T10:43:20Z", "type": "commit"}, {"oid": "c985f96cb80fc03446388ef88e8e364b9c577d8a", "url": "https://github.com/ExpediaGroup/circus-train/commit/c985f96cb80fc03446388ef88e8e364b9c577d8a", "message": "Removing log to throw metastore client exception instead", "committedDate": "2020-06-03T11:28:03Z", "type": "commit"}]}