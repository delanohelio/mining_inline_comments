{"pr_number": 1189, "pr_title": "Revised type cache", "pr_createdAt": "2020-01-23T15:59:23Z", "pr_url": "https://github.com/DataDog/dd-trace-java/pull/1189", "timeline": [{"oid": "17af9b752cec09fbc200e498883ed52c2efb7c54", "url": "https://github.com/DataDog/dd-trace-java/commit/17af9b752cec09fbc200e498883ed52c2efb7c54", "message": "Fix typo in test name", "committedDate": "2020-01-23T15:40:48Z", "type": "commit"}, {"oid": "726236bd64d76da9770df52022b89bf623d880a2", "url": "https://github.com/DataDog/dd-trace-java/commit/726236bd64d76da9770df52022b89bf623d880a2", "message": "Type cache overhaul\n\nThis change overhauls the core type cache\n\nThe new approach aims to achieve several things...\n1 - cache is strictly bounded -- no variance for number of classes of ClassLoaders\n2 - cache is significantly smaller\n3 - cache doesn't compromise start-up time\n4 - primary eviction policy isn't driven by time\n5 - primary eviction policy isn't driven by GC\n\nThere are some slight compromises here.\nIn practice, start-up does increase slightly in a memory rich environment; however, start-up improves considerably in a memory poor environment.\n\nThe basic approcach is to have a single unified Guava cache for all ClassLoaders -- nominally keyed a composite of ClassLoader & class name\n\nThe ByteBuddy CacheProvider are simply thin wrappers around the Guava cache associated to a particular ClassLoader\n\nHowever rather than having a large number of WeakReferences floating around.  The cache assigns an ID to each ClassLoader.\n\nTo further avoid, consuming memory the cache only preserves a small map of Loader / ID assignments.  This means a ClassLoader may have more than one active ID.\n\nThis introduce the possibility for ID exhaustion.  That unlikely case is handle by retiring the internal CacheInstance and starting anew.", "committedDate": "2020-01-23T15:55:16Z", "type": "commit"}, {"oid": "984d77e44ce0de96df6b7fe00cc7210deb360c94", "url": "https://github.com/DataDog/dd-trace-java/commit/984d77e44ce0de96df6b7fe00cc7210deb360c94", "message": "googleJavaFormat & codeNarc", "committedDate": "2020-01-23T16:15:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIzNTAwNA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r370235004", "bodyText": "This looks like there's two typos with cacheInstance.", "author": "tylerbenson", "createdAt": "2020-01-23T16:49:41Z", "path": "dd-java-agent/agent-tooling/src/main/java/datadog/trace/agent/tooling/DDCachingPoolStrategy.java", "diffHunk": "@@ -1,146 +1,282 @@\n package datadog.trace.agent.tooling;\n \n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.BOOTSTRAP_CLASSLOADER;\n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.skipClassLoader;\n import static net.bytebuddy.agent.builder.AgentBuilder.PoolStrategy;\n \n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n-import datadog.trace.bootstrap.WeakMap;\n-import java.security.SecureClassLoader;\n import java.util.concurrent.Callable;\n import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n import net.bytebuddy.description.type.TypeDescription;\n import net.bytebuddy.dynamic.ClassFileLocator;\n import net.bytebuddy.pool.TypePool;\n \n /**\n- * Custom Pool strategy.\n+ * NEW (Jan 2020) Custom Pool strategy.\n  *\n- * <p>Here we are using WeakMap.Provider as the backing ClassLoader -> CacheProvider lookup.\n+ * <ul>\n+ *   Uses a Guava Cache directly...\n+ *   <li>better control over locking than WeakMap.Provider\n+ *   <li>provides direct control over concurrency level\n+ *   <li>initial and maximum capacity\n+ * </ul>\n  *\n- * <p>We also use our bootstrap proxy when matching against the bootstrap loader.\n+ * <ul>\n+ *   There two core parts to the cache...\n+ *   <li>a cache of ID assignments for ClassLoaders\n+ *   <li>a single cache of TypeResolutions for all ClassLoaders - keyed by a custom composite key\n+ *       that combines loader ID & name\n+ * </ul>\n  *\n- * <p>The CacheProvider is a custom implementation that uses guava's cache to expire and limit size.\n+ * <p>This design was chosen to create a single limited size cache that can be adjusted for the\n+ * entire application -- without having to create a large number of WeakReference objects.\n  *\n- * <p>By evicting from the cache we are able to reduce the memory overhead of the agent for apps\n- * that have many classes.\n+ * <p>The ID assignment mostly assigns a single ID to each ClassLoader, but the maximumSize\n+ * restriction means that an evicted ClassLoader could be assigned another ID later on.\n  *\n- * <p>See eviction policy below.\n+ * <p>For the validity of the cache, the important part is that ID assignment guarantees that no two\n+ * ClassLoaders share the same ID.\n+ *\n+ * <p>NOTE: As an additional safe-guard, a new CacheInstance can be created if the original loader\n+ * ID sequence is exhausted.\n  */\n-public class DDCachingPoolStrategy\n-    implements PoolStrategy, WeakMap.ValueSupplier<ClassLoader, TypePool.CacheProvider> {\n+@Slf4j\n+public class DDCachingPoolStrategy implements PoolStrategy {\n+  /**\n+   * Most of the logic exists in CacheInstance This volatile + exhaustion checking is defense\n+   * against loader ID exhaustion\n+   */\n+  volatile CacheInstance cacheInstance = new CacheInstance();\n \n-  // Need this because we can't put null into the typePoolCache map.\n-  private static final ClassLoader BOOTSTRAP_CLASSLOADER_PLACEHOLDER =\n-      new SecureClassLoader(null) {};\n+  @Override\n+  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n+    CacheInstance cacheInstance = this.cacheInstance;\n \n-  private final WeakMap<ClassLoader, TypePool.CacheProvider> typePoolCache =\n-      WeakMap.Provider.newWeakMap();\n-  private final Cleaner cleaner;\n+    TypePool typePool = cacheInstance.typePool(classFileLocator, classLoader);", "originalCommit": "984d77e44ce0de96df6b7fe00cc7210deb360c94", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI0NTIxMQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r370245211", "bodyText": "Can you be more specific?", "author": "dougqh", "createdAt": "2020-01-23T17:08:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIzNTAwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDcxMjI0Mg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r370712242", "bodyText": "Never mind.  I guess it rendered really weird the first time I viewed it.  Looks fine now.", "author": "tylerbenson", "createdAt": "2020-01-24T16:05:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIzNTAwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIzNTUzOA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r370235538", "bodyText": "odd log message. is this intentional?", "author": "tylerbenson", "createdAt": "2020-01-23T16:50:39Z", "path": "dd-java-agent/agent-tooling/src/main/java/datadog/trace/agent/tooling/DDCachingPoolStrategy.java", "diffHunk": "@@ -1,146 +1,282 @@\n package datadog.trace.agent.tooling;\n \n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.BOOTSTRAP_CLASSLOADER;\n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.skipClassLoader;\n import static net.bytebuddy.agent.builder.AgentBuilder.PoolStrategy;\n \n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n-import datadog.trace.bootstrap.WeakMap;\n-import java.security.SecureClassLoader;\n import java.util.concurrent.Callable;\n import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n import net.bytebuddy.description.type.TypeDescription;\n import net.bytebuddy.dynamic.ClassFileLocator;\n import net.bytebuddy.pool.TypePool;\n \n /**\n- * Custom Pool strategy.\n+ * NEW (Jan 2020) Custom Pool strategy.\n  *\n- * <p>Here we are using WeakMap.Provider as the backing ClassLoader -> CacheProvider lookup.\n+ * <ul>\n+ *   Uses a Guava Cache directly...\n+ *   <li>better control over locking than WeakMap.Provider\n+ *   <li>provides direct control over concurrency level\n+ *   <li>initial and maximum capacity\n+ * </ul>\n  *\n- * <p>We also use our bootstrap proxy when matching against the bootstrap loader.\n+ * <ul>\n+ *   There two core parts to the cache...\n+ *   <li>a cache of ID assignments for ClassLoaders\n+ *   <li>a single cache of TypeResolutions for all ClassLoaders - keyed by a custom composite key\n+ *       that combines loader ID & name\n+ * </ul>\n  *\n- * <p>The CacheProvider is a custom implementation that uses guava's cache to expire and limit size.\n+ * <p>This design was chosen to create a single limited size cache that can be adjusted for the\n+ * entire application -- without having to create a large number of WeakReference objects.\n  *\n- * <p>By evicting from the cache we are able to reduce the memory overhead of the agent for apps\n- * that have many classes.\n+ * <p>The ID assignment mostly assigns a single ID to each ClassLoader, but the maximumSize\n+ * restriction means that an evicted ClassLoader could be assigned another ID later on.\n  *\n- * <p>See eviction policy below.\n+ * <p>For the validity of the cache, the important part is that ID assignment guarantees that no two\n+ * ClassLoaders share the same ID.\n+ *\n+ * <p>NOTE: As an additional safe-guard, a new CacheInstance can be created if the original loader\n+ * ID sequence is exhausted.\n  */\n-public class DDCachingPoolStrategy\n-    implements PoolStrategy, WeakMap.ValueSupplier<ClassLoader, TypePool.CacheProvider> {\n+@Slf4j\n+public class DDCachingPoolStrategy implements PoolStrategy {\n+  /**\n+   * Most of the logic exists in CacheInstance This volatile + exhaustion checking is defense\n+   * against loader ID exhaustion\n+   */\n+  volatile CacheInstance cacheInstance = new CacheInstance();\n \n-  // Need this because we can't put null into the typePoolCache map.\n-  private static final ClassLoader BOOTSTRAP_CLASSLOADER_PLACEHOLDER =\n-      new SecureClassLoader(null) {};\n+  @Override\n+  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n+    CacheInstance cacheInstance = this.cacheInstance;\n \n-  private final WeakMap<ClassLoader, TypePool.CacheProvider> typePoolCache =\n-      WeakMap.Provider.newWeakMap();\n-  private final Cleaner cleaner;\n+    TypePool typePool = cacheInstance.typePool(classFileLocator, classLoader);\n+    if (cacheInstance.exhaustedLoaderIdSeq()) {\n+      // If the loader ID sequence is exhausted, drop the prior cache & start over\n+      // The ID space is so large that this shouldn't occur\n+      log.error(\"cacheInstance exhausted - rebuilding cache\");", "originalCommit": "984d77e44ce0de96df6b7fe00cc7210deb360c94", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI0NDcxNw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r370244717", "bodyText": "Yes, very much so.  To create a single unified cache while not using lots of WeakReferences, the scheme relies on assigning IDs to ClassLoaders.\nThis is done through AtomicLong that acts as an ID sequence that theoretically can be exhausted.  In practice, I don't expect there to be enough ClassLoaders for that to ever occur, thus the error.\nHowever, I have taken the precaution of making this code safe even in the event of ID exhaustion.\nThe code comments, commit message, and tests are intended to make the overall scheme a bit more clear.  If I need to add more, please let me know.", "author": "dougqh", "createdAt": "2020-01-23T17:07:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIzNTUzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMzMDM1Ng==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r370330356", "bodyText": "I'm not entirely happy with this because at the point of ID exhaustion.  There's a chance that multiple CacheInstances will be allocated in quick succession as multiple threads observe the exhaustion.\nI don't think that's a huge issue, since I don't expect to exhaust the ID sequence ever.\nBut I think I'll add some additional locking + an additional check in this rare path just to be safe.", "author": "dougqh", "createdAt": "2020-01-23T20:10:33Z", "path": "dd-java-agent/agent-tooling/src/main/java/datadog/trace/agent/tooling/DDCachingPoolStrategy.java", "diffHunk": "@@ -1,146 +1,283 @@\n package datadog.trace.agent.tooling;\n \n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.BOOTSTRAP_CLASSLOADER;\n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.skipClassLoader;\n import static net.bytebuddy.agent.builder.AgentBuilder.PoolStrategy;\n \n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n-import datadog.trace.bootstrap.WeakMap;\n-import java.security.SecureClassLoader;\n import java.util.concurrent.Callable;\n import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n import net.bytebuddy.description.type.TypeDescription;\n import net.bytebuddy.dynamic.ClassFileLocator;\n import net.bytebuddy.pool.TypePool;\n \n /**\n- * Custom Pool strategy.\n+ * NEW (Jan 2020) Custom Pool strategy.\n  *\n- * <p>Here we are using WeakMap.Provider as the backing ClassLoader -> CacheProvider lookup.\n+ * <ul>\n+ *   Uses a Guava Cache directly...\n+ *   <li>better control over locking than WeakMap.Provider\n+ *   <li>provides direct control over concurrency level\n+ *   <li>initial and maximum capacity\n+ * </ul>\n  *\n- * <p>We also use our bootstrap proxy when matching against the bootstrap loader.\n+ * <ul>\n+ *   There two core parts to the cache...\n+ *   <li>a cache of ID assignments for ClassLoaders\n+ *   <li>a single cache of TypeResolutions for all ClassLoaders - keyed by a custom composite key\n+ *       that combines loader ID & name\n+ * </ul>\n  *\n- * <p>The CacheProvider is a custom implementation that uses guava's cache to expire and limit size.\n+ * <p>This design was chosen to create a single limited size cache that can be adjusted\n+ * for the entire application -- without having to create a large number of WeakReference objects.\n  *\n- * <p>By evicting from the cache we are able to reduce the memory overhead of the agent for apps\n- * that have many classes.\n+ * <p>The ID assignment mostly assigns a single ID to each ClassLoader, but the maximumSize\n+ * restriction means that an evicted ClassLoader could be assigned another ID later on.\n  *\n- * <p>See eviction policy below.\n+ * <p>For the validity of the cache, the important part is that ID assignment guarantees that\n+ * no two ClassLoaders share the same ID.\n+ *\n+ * <p>NOTE: As an additional safe-guard, a new CacheInstance can be created if the original loader ID\n+ * sequence is exhausted.\n  */\n-public class DDCachingPoolStrategy\n-    implements PoolStrategy, WeakMap.ValueSupplier<ClassLoader, TypePool.CacheProvider> {\n+@Slf4j\n+public class DDCachingPoolStrategy implements PoolStrategy {\n+  /**\n+   * Most of the logic exists in CacheInstance This volatile + exhaustion checking is defense\n+   * against loader ID exhaustion\n+   */\n+  volatile CacheInstance cacheInstance = new CacheInstance();\n \n-  // Need this because we can't put null into the typePoolCache map.\n-  private static final ClassLoader BOOTSTRAP_CLASSLOADER_PLACEHOLDER =\n-      new SecureClassLoader(null) {};\n+  @Override\n+  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n+    CacheInstance cacheInstance = this.cacheInstance;\n \n-  private final WeakMap<ClassLoader, TypePool.CacheProvider> typePoolCache =\n-      WeakMap.Provider.newWeakMap();\n-  private final Cleaner cleaner;\n+    TypePool typePool = cacheInstance.typePool(classFileLocator, classLoader);\n+    if (cacheInstance.exhaustedLoaderIdSeq()) {\n+      // If the loader ID sequence is exhausted, drop the prior cache & start over\n+      // The ID space is so large that this shouldn't occur\n+      log.error(\"cacheInstance exhausted - rebuilding cache\");\n \n-  public DDCachingPoolStrategy(final Cleaner cleaner) {\n-    this.cleaner = cleaner;\n+      this.cacheInstance = new CacheInstance();", "originalCommit": "726236bd64d76da9770df52022b89bf623d880a2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4OTg2MA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r371389860", "bodyText": "Replaced ID scheme -- no longer applicable", "author": "dougqh", "createdAt": "2020-01-27T17:51:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMzMDM1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDMzMTg5NA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r370331894", "bodyText": "I've currently sized the cache based on start-up performance tests with a Spring application.\nSince we might something larger in some apps, I'll probably add a Spec object and make the size configurable.", "author": "dougqh", "createdAt": "2020-01-23T20:14:14Z", "path": "dd-java-agent/agent-tooling/src/main/java/datadog/trace/agent/tooling/DDCachingPoolStrategy.java", "diffHunk": "@@ -1,146 +1,283 @@\n package datadog.trace.agent.tooling;\n \n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.BOOTSTRAP_CLASSLOADER;\n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.skipClassLoader;\n import static net.bytebuddy.agent.builder.AgentBuilder.PoolStrategy;\n \n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n-import datadog.trace.bootstrap.WeakMap;\n-import java.security.SecureClassLoader;\n import java.util.concurrent.Callable;\n import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n import net.bytebuddy.description.type.TypeDescription;\n import net.bytebuddy.dynamic.ClassFileLocator;\n import net.bytebuddy.pool.TypePool;\n \n /**\n- * Custom Pool strategy.\n+ * NEW (Jan 2020) Custom Pool strategy.\n  *\n- * <p>Here we are using WeakMap.Provider as the backing ClassLoader -> CacheProvider lookup.\n+ * <ul>\n+ *   Uses a Guava Cache directly...\n+ *   <li>better control over locking than WeakMap.Provider\n+ *   <li>provides direct control over concurrency level\n+ *   <li>initial and maximum capacity\n+ * </ul>\n  *\n- * <p>We also use our bootstrap proxy when matching against the bootstrap loader.\n+ * <ul>\n+ *   There two core parts to the cache...\n+ *   <li>a cache of ID assignments for ClassLoaders\n+ *   <li>a single cache of TypeResolutions for all ClassLoaders - keyed by a custom composite key\n+ *       that combines loader ID & name\n+ * </ul>\n  *\n- * <p>The CacheProvider is a custom implementation that uses guava's cache to expire and limit size.\n+ * <p>This design was chosen to create a single limited size cache that can be adjusted\n+ * for the entire application -- without having to create a large number of WeakReference objects.\n  *\n- * <p>By evicting from the cache we are able to reduce the memory overhead of the agent for apps\n- * that have many classes.\n+ * <p>The ID assignment mostly assigns a single ID to each ClassLoader, but the maximumSize\n+ * restriction means that an evicted ClassLoader could be assigned another ID later on.\n  *\n- * <p>See eviction policy below.\n+ * <p>For the validity of the cache, the important part is that ID assignment guarantees that\n+ * no two ClassLoaders share the same ID.\n+ *\n+ * <p>NOTE: As an additional safe-guard, a new CacheInstance can be created if the original loader ID\n+ * sequence is exhausted.\n  */\n-public class DDCachingPoolStrategy\n-    implements PoolStrategy, WeakMap.ValueSupplier<ClassLoader, TypePool.CacheProvider> {\n+@Slf4j\n+public class DDCachingPoolStrategy implements PoolStrategy {\n+  /**\n+   * Most of the logic exists in CacheInstance This volatile + exhaustion checking is defense\n+   * against loader ID exhaustion\n+   */\n+  volatile CacheInstance cacheInstance = new CacheInstance();\n \n-  // Need this because we can't put null into the typePoolCache map.\n-  private static final ClassLoader BOOTSTRAP_CLASSLOADER_PLACEHOLDER =\n-      new SecureClassLoader(null) {};\n+  @Override\n+  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n+    CacheInstance cacheInstance = this.cacheInstance;\n \n-  private final WeakMap<ClassLoader, TypePool.CacheProvider> typePoolCache =\n-      WeakMap.Provider.newWeakMap();\n-  private final Cleaner cleaner;\n+    TypePool typePool = cacheInstance.typePool(classFileLocator, classLoader);\n+    if (cacheInstance.exhaustedLoaderIdSeq()) {\n+      // If the loader ID sequence is exhausted, drop the prior cache & start over\n+      // The ID space is so large that this shouldn't occur\n+      log.error(\"cacheInstance exhausted - rebuilding cache\");\n \n-  public DDCachingPoolStrategy(final Cleaner cleaner) {\n-    this.cleaner = cleaner;\n+      this.cacheInstance = new CacheInstance();\n+    }\n+    return typePool;\n   }\n \n-  @Override\n-  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n-    final ClassLoader key =\n-        BOOTSTRAP_CLASSLOADER == classLoader ? BOOTSTRAP_CLASSLOADER_PLACEHOLDER : classLoader;\n-    final TypePool.CacheProvider cache = typePoolCache.computeIfAbsent(key, this);\n+  /*\n+   * CacheInstance embodies the core of the cache.  In general, we only\n+   * expect a single CacheInstance object to ever be created.\n+   *\n+   * However, CacheInstance does provide an extra layer of protection\n+   * against loaderIdSeq exhaustion.  If ever the loaderIdSeq of\n+   * CacheInstance is exhausted, then DDCachingPoolStrategy.typePool\n+   * will detect that and discard the CacheInstance.\n+   *\n+   * At that time, a new CacheInstance with a fresh sequence will\n+   * be created in its place.\n+   */\n+  private static final class CacheInstance {\n+    static final int CONCURRENCY_LEVEL = 8;", "originalCommit": "726236bd64d76da9770df52022b89bf623d880a2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIzODMyNA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r370238324", "bodyText": "why minus 10?", "author": "tylerbenson", "createdAt": "2020-01-23T16:55:32Z", "path": "dd-java-agent/agent-tooling/src/main/java/datadog/trace/agent/tooling/DDCachingPoolStrategy.java", "diffHunk": "@@ -1,146 +1,282 @@\n package datadog.trace.agent.tooling;\n \n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.BOOTSTRAP_CLASSLOADER;\n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.skipClassLoader;\n import static net.bytebuddy.agent.builder.AgentBuilder.PoolStrategy;\n \n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n-import datadog.trace.bootstrap.WeakMap;\n-import java.security.SecureClassLoader;\n import java.util.concurrent.Callable;\n import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n import net.bytebuddy.description.type.TypeDescription;\n import net.bytebuddy.dynamic.ClassFileLocator;\n import net.bytebuddy.pool.TypePool;\n \n /**\n- * Custom Pool strategy.\n+ * NEW (Jan 2020) Custom Pool strategy.\n  *\n- * <p>Here we are using WeakMap.Provider as the backing ClassLoader -> CacheProvider lookup.\n+ * <ul>\n+ *   Uses a Guava Cache directly...\n+ *   <li>better control over locking than WeakMap.Provider\n+ *   <li>provides direct control over concurrency level\n+ *   <li>initial and maximum capacity\n+ * </ul>\n  *\n- * <p>We also use our bootstrap proxy when matching against the bootstrap loader.\n+ * <ul>\n+ *   There two core parts to the cache...\n+ *   <li>a cache of ID assignments for ClassLoaders\n+ *   <li>a single cache of TypeResolutions for all ClassLoaders - keyed by a custom composite key\n+ *       that combines loader ID & name\n+ * </ul>\n  *\n- * <p>The CacheProvider is a custom implementation that uses guava's cache to expire and limit size.\n+ * <p>This design was chosen to create a single limited size cache that can be adjusted for the\n+ * entire application -- without having to create a large number of WeakReference objects.\n  *\n- * <p>By evicting from the cache we are able to reduce the memory overhead of the agent for apps\n- * that have many classes.\n+ * <p>The ID assignment mostly assigns a single ID to each ClassLoader, but the maximumSize\n+ * restriction means that an evicted ClassLoader could be assigned another ID later on.\n  *\n- * <p>See eviction policy below.\n+ * <p>For the validity of the cache, the important part is that ID assignment guarantees that no two\n+ * ClassLoaders share the same ID.\n+ *\n+ * <p>NOTE: As an additional safe-guard, a new CacheInstance can be created if the original loader\n+ * ID sequence is exhausted.\n  */\n-public class DDCachingPoolStrategy\n-    implements PoolStrategy, WeakMap.ValueSupplier<ClassLoader, TypePool.CacheProvider> {\n+@Slf4j\n+public class DDCachingPoolStrategy implements PoolStrategy {\n+  /**\n+   * Most of the logic exists in CacheInstance This volatile + exhaustion checking is defense\n+   * against loader ID exhaustion\n+   */\n+  volatile CacheInstance cacheInstance = new CacheInstance();\n \n-  // Need this because we can't put null into the typePoolCache map.\n-  private static final ClassLoader BOOTSTRAP_CLASSLOADER_PLACEHOLDER =\n-      new SecureClassLoader(null) {};\n+  @Override\n+  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n+    CacheInstance cacheInstance = this.cacheInstance;\n \n-  private final WeakMap<ClassLoader, TypePool.CacheProvider> typePoolCache =\n-      WeakMap.Provider.newWeakMap();\n-  private final Cleaner cleaner;\n+    TypePool typePool = cacheInstance.typePool(classFileLocator, classLoader);\n+    if (cacheInstance.exhaustedLoaderIdSeq()) {\n+      // If the loader ID sequence is exhausted, drop the prior cache & start over\n+      // The ID space is so large that this shouldn't occur\n+      log.error(\"cacheInstance exhausted - rebuilding cache\");\n \n-  public DDCachingPoolStrategy(final Cleaner cleaner) {\n-    this.cleaner = cleaner;\n+      this.cacheInstance = new CacheInstance();\n+    }\n+    return typePool;\n   }\n \n-  @Override\n-  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n-    final ClassLoader key =\n-        BOOTSTRAP_CLASSLOADER == classLoader ? BOOTSTRAP_CLASSLOADER_PLACEHOLDER : classLoader;\n-    final TypePool.CacheProvider cache = typePoolCache.computeIfAbsent(key, this);\n+  /*\n+   * CacheInstance embodies the core of the cache.  In general, we only\n+   * expect a single CacheInstance object to ever be created.\n+   *\n+   * However, CacheInstance does provide an extra layer of protection\n+   * against loaderIdSeq exhaustion.  If ever the loaderIdSeq of\n+   * CacheInstance is exhausted, then DDCachingPoolStrategy.typePool\n+   * will detect that and discard the CacheInstance.\n+   *\n+   * At that time, a new CacheInstance with a fresh sequence will\n+   * be created in its place.\n+   */\n+  private static final class CacheInstance {\n+    static final int CONCURRENCY_LEVEL = 8;\n+    static final int LOADER_CAPACITY = 64;\n+    static final int TYPE_CAPACITY = 64;\n \n-    return new TypePool.Default.WithLazyResolution(\n-        cache, classFileLocator, TypePool.Default.ReaderMode.FAST);\n-  }\n+    static final long BOOTSTRAP_ID = Long.MIN_VALUE;\n+    static final long START_ID = BOOTSTRAP_ID + 1;\n+    static final long LIMIT_ID = Long.MAX_VALUE - 10;", "originalCommit": "984d77e44ce0de96df6b7fe00cc7210deb360c94", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4OTE0OA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r371389148", "bodyText": "Since I got rid of the ID sequence, it is moot.\nBut the basic reason was just paranoia leaving a little buffer on the end.\nAlthough, the real key to correctness was manually doing CAS increment loop rather than using incrementAndGet.", "author": "dougqh", "createdAt": "2020-01-27T17:50:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIzODMyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIzOTM3Mw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r370239373", "bodyText": "With groovy you can still test private methods.  I suggest marking things as private where it make sense.", "author": "tylerbenson", "createdAt": "2020-01-23T16:57:22Z", "path": "dd-java-agent/agent-tooling/src/main/java/datadog/trace/agent/tooling/DDCachingPoolStrategy.java", "diffHunk": "@@ -1,146 +1,282 @@\n package datadog.trace.agent.tooling;\n \n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.BOOTSTRAP_CLASSLOADER;\n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.skipClassLoader;\n import static net.bytebuddy.agent.builder.AgentBuilder.PoolStrategy;\n \n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n-import datadog.trace.bootstrap.WeakMap;\n-import java.security.SecureClassLoader;\n import java.util.concurrent.Callable;\n import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n import net.bytebuddy.description.type.TypeDescription;\n import net.bytebuddy.dynamic.ClassFileLocator;\n import net.bytebuddy.pool.TypePool;\n \n /**\n- * Custom Pool strategy.\n+ * NEW (Jan 2020) Custom Pool strategy.\n  *\n- * <p>Here we are using WeakMap.Provider as the backing ClassLoader -> CacheProvider lookup.\n+ * <ul>\n+ *   Uses a Guava Cache directly...\n+ *   <li>better control over locking than WeakMap.Provider\n+ *   <li>provides direct control over concurrency level\n+ *   <li>initial and maximum capacity\n+ * </ul>\n  *\n- * <p>We also use our bootstrap proxy when matching against the bootstrap loader.\n+ * <ul>\n+ *   There two core parts to the cache...\n+ *   <li>a cache of ID assignments for ClassLoaders\n+ *   <li>a single cache of TypeResolutions for all ClassLoaders - keyed by a custom composite key\n+ *       that combines loader ID & name\n+ * </ul>\n  *\n- * <p>The CacheProvider is a custom implementation that uses guava's cache to expire and limit size.\n+ * <p>This design was chosen to create a single limited size cache that can be adjusted for the\n+ * entire application -- without having to create a large number of WeakReference objects.\n  *\n- * <p>By evicting from the cache we are able to reduce the memory overhead of the agent for apps\n- * that have many classes.\n+ * <p>The ID assignment mostly assigns a single ID to each ClassLoader, but the maximumSize\n+ * restriction means that an evicted ClassLoader could be assigned another ID later on.\n  *\n- * <p>See eviction policy below.\n+ * <p>For the validity of the cache, the important part is that ID assignment guarantees that no two\n+ * ClassLoaders share the same ID.\n+ *\n+ * <p>NOTE: As an additional safe-guard, a new CacheInstance can be created if the original loader\n+ * ID sequence is exhausted.\n  */\n-public class DDCachingPoolStrategy\n-    implements PoolStrategy, WeakMap.ValueSupplier<ClassLoader, TypePool.CacheProvider> {\n+@Slf4j\n+public class DDCachingPoolStrategy implements PoolStrategy {\n+  /**\n+   * Most of the logic exists in CacheInstance This volatile + exhaustion checking is defense\n+   * against loader ID exhaustion\n+   */\n+  volatile CacheInstance cacheInstance = new CacheInstance();\n \n-  // Need this because we can't put null into the typePoolCache map.\n-  private static final ClassLoader BOOTSTRAP_CLASSLOADER_PLACEHOLDER =\n-      new SecureClassLoader(null) {};\n+  @Override\n+  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n+    CacheInstance cacheInstance = this.cacheInstance;\n \n-  private final WeakMap<ClassLoader, TypePool.CacheProvider> typePoolCache =\n-      WeakMap.Provider.newWeakMap();\n-  private final Cleaner cleaner;\n+    TypePool typePool = cacheInstance.typePool(classFileLocator, classLoader);\n+    if (cacheInstance.exhaustedLoaderIdSeq()) {\n+      // If the loader ID sequence is exhausted, drop the prior cache & start over\n+      // The ID space is so large that this shouldn't occur\n+      log.error(\"cacheInstance exhausted - rebuilding cache\");\n \n-  public DDCachingPoolStrategy(final Cleaner cleaner) {\n-    this.cleaner = cleaner;\n+      this.cacheInstance = new CacheInstance();\n+    }\n+    return typePool;\n   }\n \n-  @Override\n-  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n-    final ClassLoader key =\n-        BOOTSTRAP_CLASSLOADER == classLoader ? BOOTSTRAP_CLASSLOADER_PLACEHOLDER : classLoader;\n-    final TypePool.CacheProvider cache = typePoolCache.computeIfAbsent(key, this);\n+  /*\n+   * CacheInstance embodies the core of the cache.  In general, we only\n+   * expect a single CacheInstance object to ever be created.\n+   *\n+   * However, CacheInstance does provide an extra layer of protection\n+   * against loaderIdSeq exhaustion.  If ever the loaderIdSeq of\n+   * CacheInstance is exhausted, then DDCachingPoolStrategy.typePool\n+   * will detect that and discard the CacheInstance.\n+   *\n+   * At that time, a new CacheInstance with a fresh sequence will\n+   * be created in its place.\n+   */\n+  private static final class CacheInstance {\n+    static final int CONCURRENCY_LEVEL = 8;\n+    static final int LOADER_CAPACITY = 64;\n+    static final int TYPE_CAPACITY = 64;\n \n-    return new TypePool.Default.WithLazyResolution(\n-        cache, classFileLocator, TypePool.Default.ReaderMode.FAST);\n-  }\n+    static final long BOOTSTRAP_ID = Long.MIN_VALUE;\n+    static final long START_ID = BOOTSTRAP_ID + 1;\n+    static final long LIMIT_ID = Long.MAX_VALUE - 10;\n \n-  @Override\n-  public TypePool.CacheProvider get(final ClassLoader key) {\n-    if (BOOTSTRAP_CLASSLOADER_PLACEHOLDER != key && skipClassLoader().matches(key)) {\n-      // Don't bother creating a cache for a classloader that won't match.\n-      // (avoiding a lot of DelegatingClassLoader instances)\n-      // This is primarily an optimization.\n-      return TypePool.CacheProvider.NoOp.INSTANCE;\n-    } else {\n-      return EvictingCacheProvider.withObjectType(cleaner, 1, TimeUnit.MINUTES);\n+    static final long EXHAUSTED_ID = LIMIT_ID;\n+\n+    // Many things are package visible for testing purposes --", "originalCommit": "984d77e44ce0de96df6b7fe00cc7210deb360c94", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4OTY4NQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r371389685", "bodyText": "So groovy allows private methods but not private fields?\nAnyway, I don't want to generate synthetic accessors either, so I'll probably leave most things visible.", "author": "dougqh", "createdAt": "2020-01-27T17:51:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIzOTM3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDgzNjAxMw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r370836013", "bodyText": "Why use this algorithm?  Maybe add a comment?", "author": "tylerbenson", "createdAt": "2020-01-24T20:50:03Z", "path": "dd-java-agent/agent-tooling/src/main/java/datadog/trace/agent/tooling/DDCachingPoolStrategy.java", "diffHunk": "@@ -1,146 +1,282 @@\n package datadog.trace.agent.tooling;\n \n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.BOOTSTRAP_CLASSLOADER;\n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.skipClassLoader;\n import static net.bytebuddy.agent.builder.AgentBuilder.PoolStrategy;\n \n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n-import datadog.trace.bootstrap.WeakMap;\n-import java.security.SecureClassLoader;\n import java.util.concurrent.Callable;\n import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n import net.bytebuddy.description.type.TypeDescription;\n import net.bytebuddy.dynamic.ClassFileLocator;\n import net.bytebuddy.pool.TypePool;\n \n /**\n- * Custom Pool strategy.\n+ * NEW (Jan 2020) Custom Pool strategy.\n  *\n- * <p>Here we are using WeakMap.Provider as the backing ClassLoader -> CacheProvider lookup.\n+ * <ul>\n+ *   Uses a Guava Cache directly...\n+ *   <li>better control over locking than WeakMap.Provider\n+ *   <li>provides direct control over concurrency level\n+ *   <li>initial and maximum capacity\n+ * </ul>\n  *\n- * <p>We also use our bootstrap proxy when matching against the bootstrap loader.\n+ * <ul>\n+ *   There two core parts to the cache...\n+ *   <li>a cache of ID assignments for ClassLoaders\n+ *   <li>a single cache of TypeResolutions for all ClassLoaders - keyed by a custom composite key\n+ *       that combines loader ID & name\n+ * </ul>\n  *\n- * <p>The CacheProvider is a custom implementation that uses guava's cache to expire and limit size.\n+ * <p>This design was chosen to create a single limited size cache that can be adjusted for the\n+ * entire application -- without having to create a large number of WeakReference objects.\n  *\n- * <p>By evicting from the cache we are able to reduce the memory overhead of the agent for apps\n- * that have many classes.\n+ * <p>The ID assignment mostly assigns a single ID to each ClassLoader, but the maximumSize\n+ * restriction means that an evicted ClassLoader could be assigned another ID later on.\n  *\n- * <p>See eviction policy below.\n+ * <p>For the validity of the cache, the important part is that ID assignment guarantees that no two\n+ * ClassLoaders share the same ID.\n+ *\n+ * <p>NOTE: As an additional safe-guard, a new CacheInstance can be created if the original loader\n+ * ID sequence is exhausted.\n  */\n-public class DDCachingPoolStrategy\n-    implements PoolStrategy, WeakMap.ValueSupplier<ClassLoader, TypePool.CacheProvider> {\n+@Slf4j\n+public class DDCachingPoolStrategy implements PoolStrategy {\n+  /**\n+   * Most of the logic exists in CacheInstance This volatile + exhaustion checking is defense\n+   * against loader ID exhaustion\n+   */\n+  volatile CacheInstance cacheInstance = new CacheInstance();\n \n-  // Need this because we can't put null into the typePoolCache map.\n-  private static final ClassLoader BOOTSTRAP_CLASSLOADER_PLACEHOLDER =\n-      new SecureClassLoader(null) {};\n+  @Override\n+  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n+    CacheInstance cacheInstance = this.cacheInstance;\n \n-  private final WeakMap<ClassLoader, TypePool.CacheProvider> typePoolCache =\n-      WeakMap.Provider.newWeakMap();\n-  private final Cleaner cleaner;\n+    TypePool typePool = cacheInstance.typePool(classFileLocator, classLoader);\n+    if (cacheInstance.exhaustedLoaderIdSeq()) {\n+      // If the loader ID sequence is exhausted, drop the prior cache & start over\n+      // The ID space is so large that this shouldn't occur\n+      log.error(\"cacheInstance exhausted - rebuilding cache\");\n \n-  public DDCachingPoolStrategy(final Cleaner cleaner) {\n-    this.cleaner = cleaner;\n+      this.cacheInstance = new CacheInstance();\n+    }\n+    return typePool;\n   }\n \n-  @Override\n-  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n-    final ClassLoader key =\n-        BOOTSTRAP_CLASSLOADER == classLoader ? BOOTSTRAP_CLASSLOADER_PLACEHOLDER : classLoader;\n-    final TypePool.CacheProvider cache = typePoolCache.computeIfAbsent(key, this);\n+  /*\n+   * CacheInstance embodies the core of the cache.  In general, we only\n+   * expect a single CacheInstance object to ever be created.\n+   *\n+   * However, CacheInstance does provide an extra layer of protection\n+   * against loaderIdSeq exhaustion.  If ever the loaderIdSeq of\n+   * CacheInstance is exhausted, then DDCachingPoolStrategy.typePool\n+   * will detect that and discard the CacheInstance.\n+   *\n+   * At that time, a new CacheInstance with a fresh sequence will\n+   * be created in its place.\n+   */\n+  private static final class CacheInstance {\n+    static final int CONCURRENCY_LEVEL = 8;\n+    static final int LOADER_CAPACITY = 64;\n+    static final int TYPE_CAPACITY = 64;\n \n-    return new TypePool.Default.WithLazyResolution(\n-        cache, classFileLocator, TypePool.Default.ReaderMode.FAST);\n-  }\n+    static final long BOOTSTRAP_ID = Long.MIN_VALUE;\n+    static final long START_ID = BOOTSTRAP_ID + 1;\n+    static final long LIMIT_ID = Long.MAX_VALUE - 10;\n \n-  @Override\n-  public TypePool.CacheProvider get(final ClassLoader key) {\n-    if (BOOTSTRAP_CLASSLOADER_PLACEHOLDER != key && skipClassLoader().matches(key)) {\n-      // Don't bother creating a cache for a classloader that won't match.\n-      // (avoiding a lot of DelegatingClassLoader instances)\n-      // This is primarily an optimization.\n-      return TypePool.CacheProvider.NoOp.INSTANCE;\n-    } else {\n-      return EvictingCacheProvider.withObjectType(cleaner, 1, TimeUnit.MINUTES);\n+    static final long EXHAUSTED_ID = LIMIT_ID;\n+\n+    // Many things are package visible for testing purposes --\n+    // others to avoid creation of synthetic accessors\n+\n+    /**\n+     * Cache of recent loaderIds: guarantee is that no two loaders are given the same ID; however, a\n+     * loader may be given more than one ID if it falls out the cache.\n+     */\n+    final Cache<ClassLoader, Long> loaderIdCache =\n+        CacheBuilder.newBuilder()\n+            .weakKeys()\n+            .concurrencyLevel(CONCURRENCY_LEVEL)\n+            .initialCapacity(LOADER_CAPACITY / 2)\n+            .maximumSize(LOADER_CAPACITY)\n+            .build();\n+\n+    /**\n+     * Single shared Type.Resolution cache -- uses a composite key of loader ID & class name The\n+     * initial capacity is set to the maximum capacity to avoid expansion overhead.\n+     */\n+    final Cache<TypeCacheKey, TypePool.Resolution> sharedResolutionCache =\n+        CacheBuilder.newBuilder()\n+            .softValues()\n+            .concurrencyLevel(CONCURRENCY_LEVEL)\n+            .initialCapacity(TYPE_CAPACITY)\n+            .maximumSize(TYPE_CAPACITY)\n+            .build();\n+\n+    /**\n+     * ID sequence for loaders -- BOOTSTRAP_ID is reserved -- starts higher at START_ID Sequence\n+     * proceeds up until LIMIT_ID at which the sequence and this cacheInstance are considered to be\n+     * exhausted\n+     */\n+    final AtomicLong loaderIdSeq = new AtomicLong(START_ID);\n+\n+    /** Fast path for bootstrap */\n+    final SharedResolutionCacheAdapter bootstrapCacheProvider =\n+        new SharedResolutionCacheAdapter(BOOTSTRAP_ID, sharedResolutionCache);\n+\n+    private final Callable<Long> provisionIdCallable =\n+        new Callable<Long>() {\n+          @Override\n+          public final Long call() throws Exception {\n+            return provisionId();\n+          }\n+        };\n+\n+    final TypePool typePool(\n+        final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n+      if (classLoader == null) {\n+        return createCachingTypePool(bootstrapCacheProvider, classFileLocator);\n+      }\n+\n+      Long existingId = loaderIdCache.getIfPresent(classLoader);\n+      if (existingId != null) {\n+        return createCachingTypePool(existingId, classFileLocator);\n+      }\n+\n+      if (exhaustedLoaderIdSeq()) {\n+        return createNonCachingTypePool(classFileLocator);\n+      }\n+\n+      long provisionedId = 0;\n+      try {\n+        provisionedId = loaderIdCache.get(classLoader, this.provisionIdCallable);\n+      } catch (ExecutionException e) {\n+        log.error(\"unexpected exception\", e);\n+\n+        return createNonCachingTypePool(classFileLocator);\n+      }\n+      if (provisionedId == EXHAUSTED_ID) {\n+        return createNonCachingTypePool(classFileLocator);\n+      } else {\n+        return createCachingTypePool(provisionedId, classFileLocator);\n+      }\n     }\n-  }\n \n-  private static class EvictingCacheProvider implements TypePool.CacheProvider {\n+    final boolean exhaustedLoaderIdSeq() {\n+      return (loaderIdSeq.get() >= LIMIT_ID);\n+    }\n \n-    /** A map containing all cached resolutions by their names. */\n-    private final Cache<String, TypePool.Resolution> cache;\n+    final long provisionId() {\n+      do {\n+        long curId = loaderIdSeq.get();\n+        if (curId >= LIMIT_ID) return EXHAUSTED_ID;\n \n-    /** Creates a new simple cache. */\n-    private EvictingCacheProvider(\n-        final Cleaner cleaner, final long expireDuration, final TimeUnit unit) {\n-      cache =\n-          CacheBuilder.newBuilder()\n-              .initialCapacity(100) // Per classloader, so we want a small default.\n-              .maximumSize(5000)\n-              .softValues()\n-              .expireAfterAccess(expireDuration, unit)\n-              .build();\n+        long newId = curId + 1;\n+        boolean acquired = loaderIdSeq.compareAndSet(curId, newId);\n+        if (acquired) return newId;\n+      } while (!Thread.currentThread().isInterrupted());\n \n-      /*\n-       * The cache only does cleanup on occasional reads and writes.\n-       * We want to ensure this happens more regularly, so we schedule a thread to do run cleanup manually.\n-       */\n-      cleaner.scheduleCleaning(cache, CacheCleaner.CLEANER, expireDuration, unit);\n+      return EXHAUSTED_ID;\n     }\n \n-    private static EvictingCacheProvider withObjectType(\n-        final Cleaner cleaner, final long expireDuration, final TimeUnit unit) {\n-      final EvictingCacheProvider cacheProvider =\n-          new EvictingCacheProvider(cleaner, expireDuration, unit);\n-      cacheProvider.register(\n-          Object.class.getName(), new TypePool.Resolution.Simple(TypeDescription.OBJECT));\n-      return cacheProvider;\n+    private final TypePool createNonCachingTypePool(final ClassFileLocator classFileLocator) {\n+      return new TypePool.Default.WithLazyResolution(\n+          TypePool.CacheProvider.NoOp.INSTANCE, classFileLocator, TypePool.Default.ReaderMode.FAST);\n     }\n \n-    @Override\n-    public TypePool.Resolution find(final String name) {\n-      return cache.getIfPresent(name);\n+    private final TypePool.CacheProvider createCacheProvider(final long loaderId) {\n+      return new SharedResolutionCacheAdapter(loaderId, sharedResolutionCache);\n     }\n \n-    @Override\n-    public TypePool.Resolution register(final String name, final TypePool.Resolution resolution) {\n-      try {\n-        return cache.get(name, new ResolutionProvider(resolution));\n-      } catch (final ExecutionException e) {\n-        return resolution;\n-      }\n+    private final TypePool createCachingTypePool(\n+        final long loaderId, final ClassFileLocator classFileLocator) {\n+      return new TypePool.Default.WithLazyResolution(\n+          createCacheProvider(loaderId), classFileLocator, TypePool.Default.ReaderMode.FAST);\n+    }\n+\n+    private final TypePool createCachingTypePool(\n+        final TypePool.CacheProvider cacheProvider, final ClassFileLocator classFileLocator) {\n+      return new TypePool.Default.WithLazyResolution(\n+          cacheProvider, classFileLocator, TypePool.Default.ReaderMode.FAST);\n+    }\n+\n+    final long approximateSize() {\n+      return sharedResolutionCache.size();\n+    }\n+  }\n+\n+  /**\n+   * TypeCacheKey is key for the sharedResolutionCache. It is a mix of a cacheId/loaderId & a type\n+   * name.\n+   */\n+  static final class TypeCacheKey {\n+    private final long cacheId;\n+    private final String name;\n+\n+    private final int hashCode;\n+\n+    TypeCacheKey(final long cacheId, final String name) {\n+      this.cacheId = cacheId;\n+      this.name = name;\n+\n+      hashCode = (int) (31 * cacheId) ^ name.hashCode();", "originalCommit": "984d77e44ce0de96df6b7fe00cc7210deb360c94", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4ODQyNQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r371388425", "bodyText": "No particular reason -- just a variation on FNV", "author": "dougqh", "createdAt": "2020-01-27T17:48:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDgzNjAxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDgzODMyNg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r370838326", "bodyText": "Pointing out that we are still using weak keys on the classloader, but I don't see any way to avoid that.", "author": "tylerbenson", "createdAt": "2020-01-24T20:56:21Z", "path": "dd-java-agent/agent-tooling/src/main/java/datadog/trace/agent/tooling/DDCachingPoolStrategy.java", "diffHunk": "@@ -1,146 +1,282 @@\n package datadog.trace.agent.tooling;\n \n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.BOOTSTRAP_CLASSLOADER;\n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.skipClassLoader;\n import static net.bytebuddy.agent.builder.AgentBuilder.PoolStrategy;\n \n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n-import datadog.trace.bootstrap.WeakMap;\n-import java.security.SecureClassLoader;\n import java.util.concurrent.Callable;\n import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n import net.bytebuddy.description.type.TypeDescription;\n import net.bytebuddy.dynamic.ClassFileLocator;\n import net.bytebuddy.pool.TypePool;\n \n /**\n- * Custom Pool strategy.\n+ * NEW (Jan 2020) Custom Pool strategy.\n  *\n- * <p>Here we are using WeakMap.Provider as the backing ClassLoader -> CacheProvider lookup.\n+ * <ul>\n+ *   Uses a Guava Cache directly...\n+ *   <li>better control over locking than WeakMap.Provider\n+ *   <li>provides direct control over concurrency level\n+ *   <li>initial and maximum capacity\n+ * </ul>\n  *\n- * <p>We also use our bootstrap proxy when matching against the bootstrap loader.\n+ * <ul>\n+ *   There two core parts to the cache...\n+ *   <li>a cache of ID assignments for ClassLoaders\n+ *   <li>a single cache of TypeResolutions for all ClassLoaders - keyed by a custom composite key\n+ *       that combines loader ID & name\n+ * </ul>\n  *\n- * <p>The CacheProvider is a custom implementation that uses guava's cache to expire and limit size.\n+ * <p>This design was chosen to create a single limited size cache that can be adjusted for the\n+ * entire application -- without having to create a large number of WeakReference objects.\n  *\n- * <p>By evicting from the cache we are able to reduce the memory overhead of the agent for apps\n- * that have many classes.\n+ * <p>The ID assignment mostly assigns a single ID to each ClassLoader, but the maximumSize\n+ * restriction means that an evicted ClassLoader could be assigned another ID later on.\n  *\n- * <p>See eviction policy below.\n+ * <p>For the validity of the cache, the important part is that ID assignment guarantees that no two\n+ * ClassLoaders share the same ID.\n+ *\n+ * <p>NOTE: As an additional safe-guard, a new CacheInstance can be created if the original loader\n+ * ID sequence is exhausted.\n  */\n-public class DDCachingPoolStrategy\n-    implements PoolStrategy, WeakMap.ValueSupplier<ClassLoader, TypePool.CacheProvider> {\n+@Slf4j\n+public class DDCachingPoolStrategy implements PoolStrategy {\n+  /**\n+   * Most of the logic exists in CacheInstance This volatile + exhaustion checking is defense\n+   * against loader ID exhaustion\n+   */\n+  volatile CacheInstance cacheInstance = new CacheInstance();\n \n-  // Need this because we can't put null into the typePoolCache map.\n-  private static final ClassLoader BOOTSTRAP_CLASSLOADER_PLACEHOLDER =\n-      new SecureClassLoader(null) {};\n+  @Override\n+  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n+    CacheInstance cacheInstance = this.cacheInstance;\n \n-  private final WeakMap<ClassLoader, TypePool.CacheProvider> typePoolCache =\n-      WeakMap.Provider.newWeakMap();\n-  private final Cleaner cleaner;\n+    TypePool typePool = cacheInstance.typePool(classFileLocator, classLoader);\n+    if (cacheInstance.exhaustedLoaderIdSeq()) {\n+      // If the loader ID sequence is exhausted, drop the prior cache & start over\n+      // The ID space is so large that this shouldn't occur\n+      log.error(\"cacheInstance exhausted - rebuilding cache\");\n \n-  public DDCachingPoolStrategy(final Cleaner cleaner) {\n-    this.cleaner = cleaner;\n+      this.cacheInstance = new CacheInstance();\n+    }\n+    return typePool;\n   }\n \n-  @Override\n-  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n-    final ClassLoader key =\n-        BOOTSTRAP_CLASSLOADER == classLoader ? BOOTSTRAP_CLASSLOADER_PLACEHOLDER : classLoader;\n-    final TypePool.CacheProvider cache = typePoolCache.computeIfAbsent(key, this);\n+  /*\n+   * CacheInstance embodies the core of the cache.  In general, we only\n+   * expect a single CacheInstance object to ever be created.\n+   *\n+   * However, CacheInstance does provide an extra layer of protection\n+   * against loaderIdSeq exhaustion.  If ever the loaderIdSeq of\n+   * CacheInstance is exhausted, then DDCachingPoolStrategy.typePool\n+   * will detect that and discard the CacheInstance.\n+   *\n+   * At that time, a new CacheInstance with a fresh sequence will\n+   * be created in its place.\n+   */\n+  private static final class CacheInstance {\n+    static final int CONCURRENCY_LEVEL = 8;\n+    static final int LOADER_CAPACITY = 64;\n+    static final int TYPE_CAPACITY = 64;\n \n-    return new TypePool.Default.WithLazyResolution(\n-        cache, classFileLocator, TypePool.Default.ReaderMode.FAST);\n-  }\n+    static final long BOOTSTRAP_ID = Long.MIN_VALUE;\n+    static final long START_ID = BOOTSTRAP_ID + 1;\n+    static final long LIMIT_ID = Long.MAX_VALUE - 10;\n \n-  @Override\n-  public TypePool.CacheProvider get(final ClassLoader key) {\n-    if (BOOTSTRAP_CLASSLOADER_PLACEHOLDER != key && skipClassLoader().matches(key)) {\n-      // Don't bother creating a cache for a classloader that won't match.\n-      // (avoiding a lot of DelegatingClassLoader instances)\n-      // This is primarily an optimization.\n-      return TypePool.CacheProvider.NoOp.INSTANCE;\n-    } else {\n-      return EvictingCacheProvider.withObjectType(cleaner, 1, TimeUnit.MINUTES);\n+    static final long EXHAUSTED_ID = LIMIT_ID;\n+\n+    // Many things are package visible for testing purposes --\n+    // others to avoid creation of synthetic accessors\n+\n+    /**\n+     * Cache of recent loaderIds: guarantee is that no two loaders are given the same ID; however, a\n+     * loader may be given more than one ID if it falls out the cache.\n+     */\n+    final Cache<ClassLoader, Long> loaderIdCache =\n+        CacheBuilder.newBuilder()\n+            .weakKeys()", "originalCommit": "984d77e44ce0de96df6b7fe00cc7210deb360c94", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4NzcwMg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r371387702", "bodyText": "The only way would be push the ID into the ClassLoader itself -- or inject a Meta info class into each ClassLoader.", "author": "dougqh", "createdAt": "2020-01-27T17:47:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDgzODMyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDgzODUyNw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r370838527", "bodyText": "Just pointing out that you're still using softValues.", "author": "tylerbenson", "createdAt": "2020-01-24T20:56:55Z", "path": "dd-java-agent/agent-tooling/src/main/java/datadog/trace/agent/tooling/DDCachingPoolStrategy.java", "diffHunk": "@@ -1,146 +1,282 @@\n package datadog.trace.agent.tooling;\n \n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.BOOTSTRAP_CLASSLOADER;\n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.skipClassLoader;\n import static net.bytebuddy.agent.builder.AgentBuilder.PoolStrategy;\n \n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n-import datadog.trace.bootstrap.WeakMap;\n-import java.security.SecureClassLoader;\n import java.util.concurrent.Callable;\n import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n import net.bytebuddy.description.type.TypeDescription;\n import net.bytebuddy.dynamic.ClassFileLocator;\n import net.bytebuddy.pool.TypePool;\n \n /**\n- * Custom Pool strategy.\n+ * NEW (Jan 2020) Custom Pool strategy.\n  *\n- * <p>Here we are using WeakMap.Provider as the backing ClassLoader -> CacheProvider lookup.\n+ * <ul>\n+ *   Uses a Guava Cache directly...\n+ *   <li>better control over locking than WeakMap.Provider\n+ *   <li>provides direct control over concurrency level\n+ *   <li>initial and maximum capacity\n+ * </ul>\n  *\n- * <p>We also use our bootstrap proxy when matching against the bootstrap loader.\n+ * <ul>\n+ *   There two core parts to the cache...\n+ *   <li>a cache of ID assignments for ClassLoaders\n+ *   <li>a single cache of TypeResolutions for all ClassLoaders - keyed by a custom composite key\n+ *       that combines loader ID & name\n+ * </ul>\n  *\n- * <p>The CacheProvider is a custom implementation that uses guava's cache to expire and limit size.\n+ * <p>This design was chosen to create a single limited size cache that can be adjusted for the\n+ * entire application -- without having to create a large number of WeakReference objects.\n  *\n- * <p>By evicting from the cache we are able to reduce the memory overhead of the agent for apps\n- * that have many classes.\n+ * <p>The ID assignment mostly assigns a single ID to each ClassLoader, but the maximumSize\n+ * restriction means that an evicted ClassLoader could be assigned another ID later on.\n  *\n- * <p>See eviction policy below.\n+ * <p>For the validity of the cache, the important part is that ID assignment guarantees that no two\n+ * ClassLoaders share the same ID.\n+ *\n+ * <p>NOTE: As an additional safe-guard, a new CacheInstance can be created if the original loader\n+ * ID sequence is exhausted.\n  */\n-public class DDCachingPoolStrategy\n-    implements PoolStrategy, WeakMap.ValueSupplier<ClassLoader, TypePool.CacheProvider> {\n+@Slf4j\n+public class DDCachingPoolStrategy implements PoolStrategy {\n+  /**\n+   * Most of the logic exists in CacheInstance This volatile + exhaustion checking is defense\n+   * against loader ID exhaustion\n+   */\n+  volatile CacheInstance cacheInstance = new CacheInstance();\n \n-  // Need this because we can't put null into the typePoolCache map.\n-  private static final ClassLoader BOOTSTRAP_CLASSLOADER_PLACEHOLDER =\n-      new SecureClassLoader(null) {};\n+  @Override\n+  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n+    CacheInstance cacheInstance = this.cacheInstance;\n \n-  private final WeakMap<ClassLoader, TypePool.CacheProvider> typePoolCache =\n-      WeakMap.Provider.newWeakMap();\n-  private final Cleaner cleaner;\n+    TypePool typePool = cacheInstance.typePool(classFileLocator, classLoader);\n+    if (cacheInstance.exhaustedLoaderIdSeq()) {\n+      // If the loader ID sequence is exhausted, drop the prior cache & start over\n+      // The ID space is so large that this shouldn't occur\n+      log.error(\"cacheInstance exhausted - rebuilding cache\");\n \n-  public DDCachingPoolStrategy(final Cleaner cleaner) {\n-    this.cleaner = cleaner;\n+      this.cacheInstance = new CacheInstance();\n+    }\n+    return typePool;\n   }\n \n-  @Override\n-  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n-    final ClassLoader key =\n-        BOOTSTRAP_CLASSLOADER == classLoader ? BOOTSTRAP_CLASSLOADER_PLACEHOLDER : classLoader;\n-    final TypePool.CacheProvider cache = typePoolCache.computeIfAbsent(key, this);\n+  /*\n+   * CacheInstance embodies the core of the cache.  In general, we only\n+   * expect a single CacheInstance object to ever be created.\n+   *\n+   * However, CacheInstance does provide an extra layer of protection\n+   * against loaderIdSeq exhaustion.  If ever the loaderIdSeq of\n+   * CacheInstance is exhausted, then DDCachingPoolStrategy.typePool\n+   * will detect that and discard the CacheInstance.\n+   *\n+   * At that time, a new CacheInstance with a fresh sequence will\n+   * be created in its place.\n+   */\n+  private static final class CacheInstance {\n+    static final int CONCURRENCY_LEVEL = 8;\n+    static final int LOADER_CAPACITY = 64;\n+    static final int TYPE_CAPACITY = 64;\n \n-    return new TypePool.Default.WithLazyResolution(\n-        cache, classFileLocator, TypePool.Default.ReaderMode.FAST);\n-  }\n+    static final long BOOTSTRAP_ID = Long.MIN_VALUE;\n+    static final long START_ID = BOOTSTRAP_ID + 1;\n+    static final long LIMIT_ID = Long.MAX_VALUE - 10;\n \n-  @Override\n-  public TypePool.CacheProvider get(final ClassLoader key) {\n-    if (BOOTSTRAP_CLASSLOADER_PLACEHOLDER != key && skipClassLoader().matches(key)) {\n-      // Don't bother creating a cache for a classloader that won't match.\n-      // (avoiding a lot of DelegatingClassLoader instances)\n-      // This is primarily an optimization.\n-      return TypePool.CacheProvider.NoOp.INSTANCE;\n-    } else {\n-      return EvictingCacheProvider.withObjectType(cleaner, 1, TimeUnit.MINUTES);\n+    static final long EXHAUSTED_ID = LIMIT_ID;\n+\n+    // Many things are package visible for testing purposes --\n+    // others to avoid creation of synthetic accessors\n+\n+    /**\n+     * Cache of recent loaderIds: guarantee is that no two loaders are given the same ID; however, a\n+     * loader may be given more than one ID if it falls out the cache.\n+     */\n+    final Cache<ClassLoader, Long> loaderIdCache =\n+        CacheBuilder.newBuilder()\n+            .weakKeys()\n+            .concurrencyLevel(CONCURRENCY_LEVEL)\n+            .initialCapacity(LOADER_CAPACITY / 2)\n+            .maximumSize(LOADER_CAPACITY)\n+            .build();\n+\n+    /**\n+     * Single shared Type.Resolution cache -- uses a composite key of loader ID & class name The\n+     * initial capacity is set to the maximum capacity to avoid expansion overhead.\n+     */\n+    final Cache<TypeCacheKey, TypePool.Resolution> sharedResolutionCache =\n+        CacheBuilder.newBuilder()\n+            .softValues()", "originalCommit": "984d77e44ce0de96df6b7fe00cc7210deb360c94", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4NjcwMw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r371386703", "bodyText": "Yes, that was a deliberate choice.  I think they are unnecessary at this point, but for now, I kept them just to be safe.", "author": "dougqh", "createdAt": "2020-01-27T17:45:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDgzODUyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg0MTIwMQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r370841201", "bodyText": "One problem I see with this new shared cache is if a classloader gets GC'd, the associated resolution classes won't be automatically cleared out. It seems they would actually stay there until evicted by the cache's size constraints.", "author": "tylerbenson", "createdAt": "2020-01-24T21:04:21Z", "path": "dd-java-agent/agent-tooling/src/main/java/datadog/trace/agent/tooling/DDCachingPoolStrategy.java", "diffHunk": "@@ -1,146 +1,282 @@\n package datadog.trace.agent.tooling;\n \n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.BOOTSTRAP_CLASSLOADER;\n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.skipClassLoader;\n import static net.bytebuddy.agent.builder.AgentBuilder.PoolStrategy;\n \n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n-import datadog.trace.bootstrap.WeakMap;\n-import java.security.SecureClassLoader;\n import java.util.concurrent.Callable;\n import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n import net.bytebuddy.description.type.TypeDescription;\n import net.bytebuddy.dynamic.ClassFileLocator;\n import net.bytebuddy.pool.TypePool;\n \n /**\n- * Custom Pool strategy.\n+ * NEW (Jan 2020) Custom Pool strategy.\n  *\n- * <p>Here we are using WeakMap.Provider as the backing ClassLoader -> CacheProvider lookup.\n+ * <ul>\n+ *   Uses a Guava Cache directly...\n+ *   <li>better control over locking than WeakMap.Provider\n+ *   <li>provides direct control over concurrency level\n+ *   <li>initial and maximum capacity\n+ * </ul>\n  *\n- * <p>We also use our bootstrap proxy when matching against the bootstrap loader.\n+ * <ul>\n+ *   There two core parts to the cache...\n+ *   <li>a cache of ID assignments for ClassLoaders\n+ *   <li>a single cache of TypeResolutions for all ClassLoaders - keyed by a custom composite key\n+ *       that combines loader ID & name\n+ * </ul>\n  *\n- * <p>The CacheProvider is a custom implementation that uses guava's cache to expire and limit size.\n+ * <p>This design was chosen to create a single limited size cache that can be adjusted for the\n+ * entire application -- without having to create a large number of WeakReference objects.\n  *\n- * <p>By evicting from the cache we are able to reduce the memory overhead of the agent for apps\n- * that have many classes.\n+ * <p>The ID assignment mostly assigns a single ID to each ClassLoader, but the maximumSize\n+ * restriction means that an evicted ClassLoader could be assigned another ID later on.\n  *\n- * <p>See eviction policy below.\n+ * <p>For the validity of the cache, the important part is that ID assignment guarantees that no two\n+ * ClassLoaders share the same ID.\n+ *\n+ * <p>NOTE: As an additional safe-guard, a new CacheInstance can be created if the original loader\n+ * ID sequence is exhausted.\n  */\n-public class DDCachingPoolStrategy\n-    implements PoolStrategy, WeakMap.ValueSupplier<ClassLoader, TypePool.CacheProvider> {\n+@Slf4j\n+public class DDCachingPoolStrategy implements PoolStrategy {\n+  /**\n+   * Most of the logic exists in CacheInstance This volatile + exhaustion checking is defense\n+   * against loader ID exhaustion\n+   */\n+  volatile CacheInstance cacheInstance = new CacheInstance();\n \n-  // Need this because we can't put null into the typePoolCache map.\n-  private static final ClassLoader BOOTSTRAP_CLASSLOADER_PLACEHOLDER =\n-      new SecureClassLoader(null) {};\n+  @Override\n+  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n+    CacheInstance cacheInstance = this.cacheInstance;\n \n-  private final WeakMap<ClassLoader, TypePool.CacheProvider> typePoolCache =\n-      WeakMap.Provider.newWeakMap();\n-  private final Cleaner cleaner;\n+    TypePool typePool = cacheInstance.typePool(classFileLocator, classLoader);\n+    if (cacheInstance.exhaustedLoaderIdSeq()) {\n+      // If the loader ID sequence is exhausted, drop the prior cache & start over\n+      // The ID space is so large that this shouldn't occur\n+      log.error(\"cacheInstance exhausted - rebuilding cache\");\n \n-  public DDCachingPoolStrategy(final Cleaner cleaner) {\n-    this.cleaner = cleaner;\n+      this.cacheInstance = new CacheInstance();\n+    }\n+    return typePool;\n   }\n \n-  @Override\n-  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n-    final ClassLoader key =\n-        BOOTSTRAP_CLASSLOADER == classLoader ? BOOTSTRAP_CLASSLOADER_PLACEHOLDER : classLoader;\n-    final TypePool.CacheProvider cache = typePoolCache.computeIfAbsent(key, this);\n+  /*\n+   * CacheInstance embodies the core of the cache.  In general, we only\n+   * expect a single CacheInstance object to ever be created.\n+   *\n+   * However, CacheInstance does provide an extra layer of protection\n+   * against loaderIdSeq exhaustion.  If ever the loaderIdSeq of\n+   * CacheInstance is exhausted, then DDCachingPoolStrategy.typePool\n+   * will detect that and discard the CacheInstance.\n+   *\n+   * At that time, a new CacheInstance with a fresh sequence will\n+   * be created in its place.\n+   */\n+  private static final class CacheInstance {\n+    static final int CONCURRENCY_LEVEL = 8;\n+    static final int LOADER_CAPACITY = 64;\n+    static final int TYPE_CAPACITY = 64;\n \n-    return new TypePool.Default.WithLazyResolution(\n-        cache, classFileLocator, TypePool.Default.ReaderMode.FAST);\n-  }\n+    static final long BOOTSTRAP_ID = Long.MIN_VALUE;\n+    static final long START_ID = BOOTSTRAP_ID + 1;\n+    static final long LIMIT_ID = Long.MAX_VALUE - 10;\n \n-  @Override\n-  public TypePool.CacheProvider get(final ClassLoader key) {\n-    if (BOOTSTRAP_CLASSLOADER_PLACEHOLDER != key && skipClassLoader().matches(key)) {\n-      // Don't bother creating a cache for a classloader that won't match.\n-      // (avoiding a lot of DelegatingClassLoader instances)\n-      // This is primarily an optimization.\n-      return TypePool.CacheProvider.NoOp.INSTANCE;\n-    } else {\n-      return EvictingCacheProvider.withObjectType(cleaner, 1, TimeUnit.MINUTES);\n+    static final long EXHAUSTED_ID = LIMIT_ID;\n+\n+    // Many things are package visible for testing purposes --\n+    // others to avoid creation of synthetic accessors\n+\n+    /**\n+     * Cache of recent loaderIds: guarantee is that no two loaders are given the same ID; however, a\n+     * loader may be given more than one ID if it falls out the cache.\n+     */\n+    final Cache<ClassLoader, Long> loaderIdCache =\n+        CacheBuilder.newBuilder()\n+            .weakKeys()\n+            .concurrencyLevel(CONCURRENCY_LEVEL)\n+            .initialCapacity(LOADER_CAPACITY / 2)\n+            .maximumSize(LOADER_CAPACITY)\n+            .build();\n+\n+    /**\n+     * Single shared Type.Resolution cache -- uses a composite key of loader ID & class name The\n+     * initial capacity is set to the maximum capacity to avoid expansion overhead.\n+     */\n+    final Cache<TypeCacheKey, TypePool.Resolution> sharedResolutionCache =", "originalCommit": "984d77e44ce0de96df6b7fe00cc7210deb360c94", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4NTY1Nw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r371385657", "bodyText": "That's true, but I don't think it is necessarily a problem.\nIf that ClassLoader goes cold, then those cache entries will also go cold.\nIf the cache needs to hold new entries, then those abandoned entries  should be evicted.\nI think a more useful eviction addition would be to dump the cache, once ClassLoader activity slows regardless of whether the ClassLoaders are still reachable or not.", "author": "dougqh", "createdAt": "2020-01-27T17:43:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg0MTIwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg0MzE1Nw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r370843157", "bodyText": "Alternate proposal... combine the two caches into a single cache and replace the cacheId with a weak classloader instance.  That would keep everything in a single cache and remove the extra level of indirection to get the cacheId.", "author": "tylerbenson", "createdAt": "2020-01-24T21:09:50Z", "path": "dd-java-agent/agent-tooling/src/main/java/datadog/trace/agent/tooling/DDCachingPoolStrategy.java", "diffHunk": "@@ -1,146 +1,282 @@\n package datadog.trace.agent.tooling;\n \n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.BOOTSTRAP_CLASSLOADER;\n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.skipClassLoader;\n import static net.bytebuddy.agent.builder.AgentBuilder.PoolStrategy;\n \n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n-import datadog.trace.bootstrap.WeakMap;\n-import java.security.SecureClassLoader;\n import java.util.concurrent.Callable;\n import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import lombok.extern.slf4j.Slf4j;\n import net.bytebuddy.description.type.TypeDescription;\n import net.bytebuddy.dynamic.ClassFileLocator;\n import net.bytebuddy.pool.TypePool;\n \n /**\n- * Custom Pool strategy.\n+ * NEW (Jan 2020) Custom Pool strategy.\n  *\n- * <p>Here we are using WeakMap.Provider as the backing ClassLoader -> CacheProvider lookup.\n+ * <ul>\n+ *   Uses a Guava Cache directly...\n+ *   <li>better control over locking than WeakMap.Provider\n+ *   <li>provides direct control over concurrency level\n+ *   <li>initial and maximum capacity\n+ * </ul>\n  *\n- * <p>We also use our bootstrap proxy when matching against the bootstrap loader.\n+ * <ul>\n+ *   There two core parts to the cache...\n+ *   <li>a cache of ID assignments for ClassLoaders\n+ *   <li>a single cache of TypeResolutions for all ClassLoaders - keyed by a custom composite key\n+ *       that combines loader ID & name\n+ * </ul>\n  *\n- * <p>The CacheProvider is a custom implementation that uses guava's cache to expire and limit size.\n+ * <p>This design was chosen to create a single limited size cache that can be adjusted for the\n+ * entire application -- without having to create a large number of WeakReference objects.\n  *\n- * <p>By evicting from the cache we are able to reduce the memory overhead of the agent for apps\n- * that have many classes.\n+ * <p>The ID assignment mostly assigns a single ID to each ClassLoader, but the maximumSize\n+ * restriction means that an evicted ClassLoader could be assigned another ID later on.\n  *\n- * <p>See eviction policy below.\n+ * <p>For the validity of the cache, the important part is that ID assignment guarantees that no two\n+ * ClassLoaders share the same ID.\n+ *\n+ * <p>NOTE: As an additional safe-guard, a new CacheInstance can be created if the original loader\n+ * ID sequence is exhausted.\n  */\n-public class DDCachingPoolStrategy\n-    implements PoolStrategy, WeakMap.ValueSupplier<ClassLoader, TypePool.CacheProvider> {\n+@Slf4j\n+public class DDCachingPoolStrategy implements PoolStrategy {\n+  /**\n+   * Most of the logic exists in CacheInstance This volatile + exhaustion checking is defense\n+   * against loader ID exhaustion\n+   */\n+  volatile CacheInstance cacheInstance = new CacheInstance();\n \n-  // Need this because we can't put null into the typePoolCache map.\n-  private static final ClassLoader BOOTSTRAP_CLASSLOADER_PLACEHOLDER =\n-      new SecureClassLoader(null) {};\n+  @Override\n+  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n+    CacheInstance cacheInstance = this.cacheInstance;\n \n-  private final WeakMap<ClassLoader, TypePool.CacheProvider> typePoolCache =\n-      WeakMap.Provider.newWeakMap();\n-  private final Cleaner cleaner;\n+    TypePool typePool = cacheInstance.typePool(classFileLocator, classLoader);\n+    if (cacheInstance.exhaustedLoaderIdSeq()) {\n+      // If the loader ID sequence is exhausted, drop the prior cache & start over\n+      // The ID space is so large that this shouldn't occur\n+      log.error(\"cacheInstance exhausted - rebuilding cache\");\n \n-  public DDCachingPoolStrategy(final Cleaner cleaner) {\n-    this.cleaner = cleaner;\n+      this.cacheInstance = new CacheInstance();\n+    }\n+    return typePool;\n   }\n \n-  @Override\n-  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n-    final ClassLoader key =\n-        BOOTSTRAP_CLASSLOADER == classLoader ? BOOTSTRAP_CLASSLOADER_PLACEHOLDER : classLoader;\n-    final TypePool.CacheProvider cache = typePoolCache.computeIfAbsent(key, this);\n+  /*\n+   * CacheInstance embodies the core of the cache.  In general, we only\n+   * expect a single CacheInstance object to ever be created.\n+   *\n+   * However, CacheInstance does provide an extra layer of protection\n+   * against loaderIdSeq exhaustion.  If ever the loaderIdSeq of\n+   * CacheInstance is exhausted, then DDCachingPoolStrategy.typePool\n+   * will detect that and discard the CacheInstance.\n+   *\n+   * At that time, a new CacheInstance with a fresh sequence will\n+   * be created in its place.\n+   */\n+  private static final class CacheInstance {\n+    static final int CONCURRENCY_LEVEL = 8;\n+    static final int LOADER_CAPACITY = 64;\n+    static final int TYPE_CAPACITY = 64;\n \n-    return new TypePool.Default.WithLazyResolution(\n-        cache, classFileLocator, TypePool.Default.ReaderMode.FAST);\n-  }\n+    static final long BOOTSTRAP_ID = Long.MIN_VALUE;\n+    static final long START_ID = BOOTSTRAP_ID + 1;\n+    static final long LIMIT_ID = Long.MAX_VALUE - 10;\n \n-  @Override\n-  public TypePool.CacheProvider get(final ClassLoader key) {\n-    if (BOOTSTRAP_CLASSLOADER_PLACEHOLDER != key && skipClassLoader().matches(key)) {\n-      // Don't bother creating a cache for a classloader that won't match.\n-      // (avoiding a lot of DelegatingClassLoader instances)\n-      // This is primarily an optimization.\n-      return TypePool.CacheProvider.NoOp.INSTANCE;\n-    } else {\n-      return EvictingCacheProvider.withObjectType(cleaner, 1, TimeUnit.MINUTES);\n+    static final long EXHAUSTED_ID = LIMIT_ID;\n+\n+    // Many things are package visible for testing purposes --\n+    // others to avoid creation of synthetic accessors\n+\n+    /**\n+     * Cache of recent loaderIds: guarantee is that no two loaders are given the same ID; however, a\n+     * loader may be given more than one ID if it falls out the cache.\n+     */\n+    final Cache<ClassLoader, Long> loaderIdCache =\n+        CacheBuilder.newBuilder()\n+            .weakKeys()\n+            .concurrencyLevel(CONCURRENCY_LEVEL)\n+            .initialCapacity(LOADER_CAPACITY / 2)\n+            .maximumSize(LOADER_CAPACITY)\n+            .build();\n+\n+    /**\n+     * Single shared Type.Resolution cache -- uses a composite key of loader ID & class name The\n+     * initial capacity is set to the maximum capacity to avoid expansion overhead.\n+     */\n+    final Cache<TypeCacheKey, TypePool.Resolution> sharedResolutionCache =\n+        CacheBuilder.newBuilder()\n+            .softValues()\n+            .concurrencyLevel(CONCURRENCY_LEVEL)\n+            .initialCapacity(TYPE_CAPACITY)\n+            .maximumSize(TYPE_CAPACITY)\n+            .build();\n+\n+    /**\n+     * ID sequence for loaders -- BOOTSTRAP_ID is reserved -- starts higher at START_ID Sequence\n+     * proceeds up until LIMIT_ID at which the sequence and this cacheInstance are considered to be\n+     * exhausted\n+     */\n+    final AtomicLong loaderIdSeq = new AtomicLong(START_ID);\n+\n+    /** Fast path for bootstrap */\n+    final SharedResolutionCacheAdapter bootstrapCacheProvider =\n+        new SharedResolutionCacheAdapter(BOOTSTRAP_ID, sharedResolutionCache);\n+\n+    private final Callable<Long> provisionIdCallable =\n+        new Callable<Long>() {\n+          @Override\n+          public final Long call() throws Exception {\n+            return provisionId();\n+          }\n+        };\n+\n+    final TypePool typePool(\n+        final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n+      if (classLoader == null) {\n+        return createCachingTypePool(bootstrapCacheProvider, classFileLocator);\n+      }\n+\n+      Long existingId = loaderIdCache.getIfPresent(classLoader);\n+      if (existingId != null) {\n+        return createCachingTypePool(existingId, classFileLocator);\n+      }\n+\n+      if (exhaustedLoaderIdSeq()) {\n+        return createNonCachingTypePool(classFileLocator);\n+      }\n+\n+      long provisionedId = 0;\n+      try {\n+        provisionedId = loaderIdCache.get(classLoader, this.provisionIdCallable);\n+      } catch (ExecutionException e) {\n+        log.error(\"unexpected exception\", e);\n+\n+        return createNonCachingTypePool(classFileLocator);\n+      }\n+      if (provisionedId == EXHAUSTED_ID) {\n+        return createNonCachingTypePool(classFileLocator);\n+      } else {\n+        return createCachingTypePool(provisionedId, classFileLocator);\n+      }\n     }\n-  }\n \n-  private static class EvictingCacheProvider implements TypePool.CacheProvider {\n+    final boolean exhaustedLoaderIdSeq() {\n+      return (loaderIdSeq.get() >= LIMIT_ID);\n+    }\n \n-    /** A map containing all cached resolutions by their names. */\n-    private final Cache<String, TypePool.Resolution> cache;\n+    final long provisionId() {\n+      do {\n+        long curId = loaderIdSeq.get();\n+        if (curId >= LIMIT_ID) return EXHAUSTED_ID;\n \n-    /** Creates a new simple cache. */\n-    private EvictingCacheProvider(\n-        final Cleaner cleaner, final long expireDuration, final TimeUnit unit) {\n-      cache =\n-          CacheBuilder.newBuilder()\n-              .initialCapacity(100) // Per classloader, so we want a small default.\n-              .maximumSize(5000)\n-              .softValues()\n-              .expireAfterAccess(expireDuration, unit)\n-              .build();\n+        long newId = curId + 1;\n+        boolean acquired = loaderIdSeq.compareAndSet(curId, newId);\n+        if (acquired) return newId;\n+      } while (!Thread.currentThread().isInterrupted());\n \n-      /*\n-       * The cache only does cleanup on occasional reads and writes.\n-       * We want to ensure this happens more regularly, so we schedule a thread to do run cleanup manually.\n-       */\n-      cleaner.scheduleCleaning(cache, CacheCleaner.CLEANER, expireDuration, unit);\n+      return EXHAUSTED_ID;\n     }\n \n-    private static EvictingCacheProvider withObjectType(\n-        final Cleaner cleaner, final long expireDuration, final TimeUnit unit) {\n-      final EvictingCacheProvider cacheProvider =\n-          new EvictingCacheProvider(cleaner, expireDuration, unit);\n-      cacheProvider.register(\n-          Object.class.getName(), new TypePool.Resolution.Simple(TypeDescription.OBJECT));\n-      return cacheProvider;\n+    private final TypePool createNonCachingTypePool(final ClassFileLocator classFileLocator) {\n+      return new TypePool.Default.WithLazyResolution(\n+          TypePool.CacheProvider.NoOp.INSTANCE, classFileLocator, TypePool.Default.ReaderMode.FAST);\n     }\n \n-    @Override\n-    public TypePool.Resolution find(final String name) {\n-      return cache.getIfPresent(name);\n+    private final TypePool.CacheProvider createCacheProvider(final long loaderId) {\n+      return new SharedResolutionCacheAdapter(loaderId, sharedResolutionCache);\n     }\n \n-    @Override\n-    public TypePool.Resolution register(final String name, final TypePool.Resolution resolution) {\n-      try {\n-        return cache.get(name, new ResolutionProvider(resolution));\n-      } catch (final ExecutionException e) {\n-        return resolution;\n-      }\n+    private final TypePool createCachingTypePool(\n+        final long loaderId, final ClassFileLocator classFileLocator) {\n+      return new TypePool.Default.WithLazyResolution(\n+          createCacheProvider(loaderId), classFileLocator, TypePool.Default.ReaderMode.FAST);\n+    }\n+\n+    private final TypePool createCachingTypePool(\n+        final TypePool.CacheProvider cacheProvider, final ClassFileLocator classFileLocator) {\n+      return new TypePool.Default.WithLazyResolution(\n+          cacheProvider, classFileLocator, TypePool.Default.ReaderMode.FAST);\n+    }\n+\n+    final long approximateSize() {\n+      return sharedResolutionCache.size();\n+    }\n+  }\n+\n+  /**\n+   * TypeCacheKey is key for the sharedResolutionCache. It is a mix of a cacheId/loaderId & a type\n+   * name.\n+   */\n+  static final class TypeCacheKey {\n+    private final long cacheId;\n+    private final String name;\n+\n+    private final int hashCode;\n+\n+    TypeCacheKey(final long cacheId, final String name) {\n+      this.cacheId = cacheId;\n+      this.name = name;\n+\n+      hashCode = (int) (31 * cacheId) ^ name.hashCode();\n     }\n \n     @Override\n-    public void clear() {\n-      cache.invalidateAll();\n+    public final int hashCode() {\n+      return hashCode;\n     }\n \n-    public long size() {\n-      return cache.size();\n+    @Override\n+    public boolean equals(final Object obj) {\n+      if (!(obj instanceof TypeCacheKey)) return false;\n+\n+      TypeCacheKey that = (TypeCacheKey) obj;\n+      return (cacheId == that.cacheId) && name.equals(that.name);\n     }\n+  }\n \n-    private static class CacheCleaner implements Cleaner.Adapter<Cache> {\n-      private static final CacheCleaner CLEANER = new CacheCleaner();\n+  static final class SharedResolutionCacheAdapter implements TypePool.CacheProvider {\n+    private static final String OBJECT_NAME = \"java.lang.Object\";\n+    private static final TypePool.Resolution OBJECT_RESOLUTION =\n+        new TypePool.Resolution.Simple(TypeDescription.OBJECT);\n \n-      @Override\n-      public void clean(final Cache target) {\n-        target.cleanUp();\n-      }\n+    private final long cacheId;", "originalCommit": "984d77e44ce0de96df6b7fe00cc7210deb360c94", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTM4NjEyMQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r371386121", "bodyText": "The latest version dumps the IDs in favor of normalized WeakReference instances.  That achieves the same benefits without the complexity ID assignment and ID exhaustion.", "author": "dougqh", "createdAt": "2020-01-27T17:44:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDg0MzE1Nw=="}], "type": "inlineReview"}, {"oid": "cf877f67e5fa67656857c59395c3c1fbde0ef0a6", "url": "https://github.com/DataDog/dd-trace-java/commit/cf877f67e5fa67656857c59395c3c1fbde0ef0a6", "message": "Working around muzzle quirk\n\nMuzzle doesn't like creation of SecureClassLoader-s, so switching to a URLClassLoader for my placeholder loader in tests", "committedDate": "2020-01-27T14:47:36Z", "type": "commit"}, {"oid": "fb871611b5b827d88a8400c96b6f31a071c2abbb", "url": "https://github.com/DataDog/dd-trace-java/commit/fb871611b5b827d88a8400c96b6f31a071c2abbb", "message": "Replacing ID generation with WeakReference reuse\n\nFirst pass at replacing ID generation with WeakReference reuse\n\nIn this first version, the Cache<ClassLoader, ID> was replaced with Cache<ClassLoader, WeakReference<ClassLoader>>.\n\nThe core cache is still of Cache<TypeCacheKey, TypePool.Resolution> and TypeCacheKey logically remains a composite key of ClassLoader, class name.\n\nThe removal of ID assignment means ID exhaustion is no longer na issue, so there's never a need to rebuild the cache.  For that reason, CacheInstance has removed and the core caching logic has been moved into DDCachingPoolStrategy.\n\nWhile TypeCacheKey remains conceptually the same, the internals have changed somewhat.  The TypeCacheKey now has 3 core fields...\n- loaderHash\n- loadeRef\n- class name\n\nSince loader refs are recycled, the fast path for key equivalence can use reference equivalence of the reference objects.\n\nThis change ripples through the CacheProvider-s which also have to store loaderHash and loaderRef.\n\nIt may be worth going a step further and switching to a Cache<Loader, TypePool> as well.  That still avoid the creation of many WeakReference-s, since the underlying CacheProvider will hold a canonical WeakReference per ClassLoader.", "committedDate": "2020-01-27T17:03:44Z", "type": "commit"}, {"oid": "d50f901f3993cbfddb4e8b1abf8cf01880ae6adc", "url": "https://github.com/DataDog/dd-trace-java/commit/d50f901f3993cbfddb4e8b1abf8cf01880ae6adc", "message": "googleJavaFormat, codeNarcTest, and test reliability", "committedDate": "2020-01-27T17:34:39Z", "type": "commit"}, {"oid": "4c7a0ba7a7ca60918b927ca59a315ec1044eb7f4", "url": "https://github.com/DataDog/dd-trace-java/commit/4c7a0ba7a7ca60918b927ca59a315ec1044eb7f4", "message": "Fixing muzzle?\n\nMuzzlePlugin groovy checks that no threads are spawned because this holds the ClassLoader live.\n\nThis was breaking with the caching change because the cache no longer uses the Cleaner service.\n\nThis caused a problem because the Thread behind the cleaner is created lazily when the first task is created, but without the cache the creation was delayed.\n\nTo solve this, I addressed the original cause of the leak.  The newly created Thread automatically inherits the contextClassLoader of its parent, but that's unnecessary for a cleaner thread.\n\nSo I changed the ThreadFactory for cleaner to explicitly null out the contextClassLoader.\n\nWe should probably null out contextClassLoader in other thread factories and also reduce our use of contextClassLoaders in general, but that will left to another PR.", "committedDate": "2020-01-27T22:14:17Z", "type": "commit"}, {"oid": "176f826a440c9557ec933d7d62c90c1aa416de09", "url": "https://github.com/DataDog/dd-trace-java/commit/176f826a440c9557ec933d7d62c90c1aa416de09", "message": "Adjusting approximateSize check to be more reliable", "committedDate": "2020-01-27T22:44:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE1MjkyMg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r373152922", "bodyText": "This seems to be out of date with the latest changes.", "author": "tylerbenson", "createdAt": "2020-01-30T19:37:34Z", "path": "dd-java-agent/agent-tooling/src/main/java/datadog/trace/agent/tooling/DDCachingPoolStrategy.java", "diffHunk": "@@ -1,146 +1,237 @@\n package datadog.trace.agent.tooling;\n \n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.BOOTSTRAP_CLASSLOADER;\n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.skipClassLoader;\n import static net.bytebuddy.agent.builder.AgentBuilder.PoolStrategy;\n \n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n-import datadog.trace.bootstrap.WeakMap;\n-import java.security.SecureClassLoader;\n-import java.util.concurrent.Callable;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n+import java.lang.ref.WeakReference;\n+import lombok.extern.slf4j.Slf4j;\n import net.bytebuddy.description.type.TypeDescription;\n import net.bytebuddy.dynamic.ClassFileLocator;\n import net.bytebuddy.pool.TypePool;\n \n /**\n- * Custom Pool strategy.\n+ * NEW (Jan 2020) Custom Pool strategy.\n  *\n- * <p>Here we are using WeakMap.Provider as the backing ClassLoader -> CacheProvider lookup.\n+ * <ul>\n+ *   Uses a Guava Cache directly...\n+ *   <li>better control over locking than WeakMap.Provider\n+ *   <li>provides direct control over concurrency level\n+ *   <li>initial and maximum capacity\n+ * </ul>\n  *\n- * <p>We also use our bootstrap proxy when matching against the bootstrap loader.\n+ * <ul>\n+ *   There two core parts to the cache...\n+ *   <li>a cache of ID assignments for ClassLoaders", "originalCommit": "176f826a440c9557ec933d7d62c90c1aa416de09", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE2NzIyMA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r373167220", "bodyText": "Good catch, I'll fix that.", "author": "dougqh", "createdAt": "2020-01-30T20:07:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE1MjkyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE1NjIyOQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r373156229", "bodyText": "use the build(CacheLoader) method instead and you won't need the null check below.", "author": "tylerbenson", "createdAt": "2020-01-30T19:44:34Z", "path": "dd-java-agent/agent-tooling/src/main/java/datadog/trace/agent/tooling/DDCachingPoolStrategy.java", "diffHunk": "@@ -1,146 +1,237 @@\n package datadog.trace.agent.tooling;\n \n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.BOOTSTRAP_CLASSLOADER;\n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.skipClassLoader;\n import static net.bytebuddy.agent.builder.AgentBuilder.PoolStrategy;\n \n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n-import datadog.trace.bootstrap.WeakMap;\n-import java.security.SecureClassLoader;\n-import java.util.concurrent.Callable;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n+import java.lang.ref.WeakReference;\n+import lombok.extern.slf4j.Slf4j;\n import net.bytebuddy.description.type.TypeDescription;\n import net.bytebuddy.dynamic.ClassFileLocator;\n import net.bytebuddy.pool.TypePool;\n \n /**\n- * Custom Pool strategy.\n+ * NEW (Jan 2020) Custom Pool strategy.\n  *\n- * <p>Here we are using WeakMap.Provider as the backing ClassLoader -> CacheProvider lookup.\n+ * <ul>\n+ *   Uses a Guava Cache directly...\n+ *   <li>better control over locking than WeakMap.Provider\n+ *   <li>provides direct control over concurrency level\n+ *   <li>initial and maximum capacity\n+ * </ul>\n  *\n- * <p>We also use our bootstrap proxy when matching against the bootstrap loader.\n+ * <ul>\n+ *   There two core parts to the cache...\n+ *   <li>a cache of ID assignments for ClassLoaders\n+ *   <li>a single cache of TypeResolutions for all ClassLoaders - keyed by a custom composite key\n+ *       that combines loader ID & name\n+ * </ul>\n  *\n- * <p>The CacheProvider is a custom implementation that uses guava's cache to expire and limit size.\n+ * <p>This design was chosen to create a single limited size cache that can be adjusted for the\n+ * entire application -- without having to create a large number of WeakReference objects.\n  *\n- * <p>By evicting from the cache we are able to reduce the memory overhead of the agent for apps\n- * that have many classes.\n+ * <p>The ID assignment mostly assigns a single ID to each ClassLoader, but the maximumSize\n+ * restriction means that an evicted ClassLoader could be assigned another ID later on.\n  *\n- * <p>See eviction policy below.\n+ * <p>For the validity of the cache, the important part is that ID assignment guarantees that no two\n+ * ClassLoaders share the same ID.\n+ *\n+ * <p>NOTE: As an additional safe-guard, a new CacheInstance can be created if the original loader\n+ * ID sequence is exhausted.\n  */\n-public class DDCachingPoolStrategy\n-    implements PoolStrategy, WeakMap.ValueSupplier<ClassLoader, TypePool.CacheProvider> {\n+@Slf4j\n+public class DDCachingPoolStrategy implements PoolStrategy {\n+  // Many things are package visible for testing purposes --\n+  // others to avoid creation of synthetic accessors\n+\n+  static final int CONCURRENCY_LEVEL = 8;\n+  static final int LOADER_CAPACITY = 64;\n+  static final int TYPE_CAPACITY = 64;\n+\n+  static final int BOOTSTRAP_HASH = 0;\n+\n+  /**\n+   * Cache of recent ClassLoader WeakReferences; used to...\n+   *\n+   * <ul>\n+   *   <li>Reduced number of WeakReferences created\n+   *   <li>Allow for quick fast path equivalence check of composite keys\n+   * </ul>\n+   */\n+  final Cache<ClassLoader, WeakReference<ClassLoader>> loaderRefCache =\n+      CacheBuilder.newBuilder()\n+          .weakKeys()\n+          .concurrencyLevel(CONCURRENCY_LEVEL)\n+          .initialCapacity(LOADER_CAPACITY / 2)\n+          .maximumSize(LOADER_CAPACITY)\n+          .build();", "originalCommit": "176f826a440c9557ec933d7d62c90c1aa416de09", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE2OTAzOQ==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r373169039", "bodyText": "Not using CacheLoader was a deliberate choice, I deliberately chose to keep the critical section as short as possible by doing the WeakReference construction outside.\nAdmittedly, this is debatable choice because it does risk creating extra WeakReferences.", "author": "dougqh", "createdAt": "2020-01-30T20:11:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE1NjIyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzIzMzIyMw==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r373233223", "bodyText": "In that case, it might be good to explain your reasoning in a comment or risk someone else making this change later.", "author": "tylerbenson", "createdAt": "2020-01-30T22:41:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE1NjIyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE1Njg1Mg==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r373156852", "bodyText": "This method is no longer used.", "author": "tylerbenson", "createdAt": "2020-01-30T19:45:48Z", "path": "dd-java-agent/agent-tooling/src/main/java/datadog/trace/agent/tooling/DDCachingPoolStrategy.java", "diffHunk": "@@ -1,146 +1,237 @@\n package datadog.trace.agent.tooling;\n \n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.BOOTSTRAP_CLASSLOADER;\n-import static datadog.trace.agent.tooling.ClassLoaderMatcher.skipClassLoader;\n import static net.bytebuddy.agent.builder.AgentBuilder.PoolStrategy;\n \n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n-import datadog.trace.bootstrap.WeakMap;\n-import java.security.SecureClassLoader;\n-import java.util.concurrent.Callable;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.TimeUnit;\n+import java.lang.ref.WeakReference;\n+import lombok.extern.slf4j.Slf4j;\n import net.bytebuddy.description.type.TypeDescription;\n import net.bytebuddy.dynamic.ClassFileLocator;\n import net.bytebuddy.pool.TypePool;\n \n /**\n- * Custom Pool strategy.\n+ * NEW (Jan 2020) Custom Pool strategy.\n  *\n- * <p>Here we are using WeakMap.Provider as the backing ClassLoader -> CacheProvider lookup.\n+ * <ul>\n+ *   Uses a Guava Cache directly...\n+ *   <li>better control over locking than WeakMap.Provider\n+ *   <li>provides direct control over concurrency level\n+ *   <li>initial and maximum capacity\n+ * </ul>\n  *\n- * <p>We also use our bootstrap proxy when matching against the bootstrap loader.\n+ * <ul>\n+ *   There two core parts to the cache...\n+ *   <li>a cache of ID assignments for ClassLoaders\n+ *   <li>a single cache of TypeResolutions for all ClassLoaders - keyed by a custom composite key\n+ *       that combines loader ID & name\n+ * </ul>\n  *\n- * <p>The CacheProvider is a custom implementation that uses guava's cache to expire and limit size.\n+ * <p>This design was chosen to create a single limited size cache that can be adjusted for the\n+ * entire application -- without having to create a large number of WeakReference objects.\n  *\n- * <p>By evicting from the cache we are able to reduce the memory overhead of the agent for apps\n- * that have many classes.\n+ * <p>The ID assignment mostly assigns a single ID to each ClassLoader, but the maximumSize\n+ * restriction means that an evicted ClassLoader could be assigned another ID later on.\n  *\n- * <p>See eviction policy below.\n+ * <p>For the validity of the cache, the important part is that ID assignment guarantees that no two\n+ * ClassLoaders share the same ID.\n+ *\n+ * <p>NOTE: As an additional safe-guard, a new CacheInstance can be created if the original loader\n+ * ID sequence is exhausted.\n  */\n-public class DDCachingPoolStrategy\n-    implements PoolStrategy, WeakMap.ValueSupplier<ClassLoader, TypePool.CacheProvider> {\n+@Slf4j\n+public class DDCachingPoolStrategy implements PoolStrategy {\n+  // Many things are package visible for testing purposes --\n+  // others to avoid creation of synthetic accessors\n+\n+  static final int CONCURRENCY_LEVEL = 8;\n+  static final int LOADER_CAPACITY = 64;\n+  static final int TYPE_CAPACITY = 64;\n+\n+  static final int BOOTSTRAP_HASH = 0;\n+\n+  /**\n+   * Cache of recent ClassLoader WeakReferences; used to...\n+   *\n+   * <ul>\n+   *   <li>Reduced number of WeakReferences created\n+   *   <li>Allow for quick fast path equivalence check of composite keys\n+   * </ul>\n+   */\n+  final Cache<ClassLoader, WeakReference<ClassLoader>> loaderRefCache =\n+      CacheBuilder.newBuilder()\n+          .weakKeys()\n+          .concurrencyLevel(CONCURRENCY_LEVEL)\n+          .initialCapacity(LOADER_CAPACITY / 2)\n+          .maximumSize(LOADER_CAPACITY)\n+          .build();\n+\n+  /**\n+   * Single shared Type.Resolution cache -- uses a composite key -- conceptually of loader & name\n+   */\n+  final Cache<TypeCacheKey, TypePool.Resolution> sharedResolutionCache =\n+      CacheBuilder.newBuilder()\n+          .softValues()\n+          .concurrencyLevel(CONCURRENCY_LEVEL)\n+          .initialCapacity(TYPE_CAPACITY)\n+          .maximumSize(TYPE_CAPACITY)\n+          .build();\n+\n+  /** Fast path for bootstrap */\n+  final SharedResolutionCacheAdapter bootstrapCacheProvider =\n+      new SharedResolutionCacheAdapter(BOOTSTRAP_HASH, null, sharedResolutionCache);\n \n-  // Need this because we can't put null into the typePoolCache map.\n-  private static final ClassLoader BOOTSTRAP_CLASSLOADER_PLACEHOLDER =\n-      new SecureClassLoader(null) {};\n+  @Override\n+  public final TypePool typePool(\n+      final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n+    if (classLoader == null) {\n+      return createCachingTypePool(bootstrapCacheProvider, classFileLocator);\n+    }\n \n-  private final WeakMap<ClassLoader, TypePool.CacheProvider> typePoolCache =\n-      WeakMap.Provider.newWeakMap();\n-  private final Cleaner cleaner;\n+    WeakReference<ClassLoader> loaderRef = loaderRefCache.getIfPresent(classLoader);\n+\n+    if (loaderRef == null) {\n+      loaderRef = new WeakReference<>(classLoader);\n+      loaderRefCache.put(classLoader, loaderRef);\n+    }\n \n-  public DDCachingPoolStrategy(final Cleaner cleaner) {\n-    this.cleaner = cleaner;\n+    int loaderHash = classLoader.hashCode();\n+    return createCachingTypePool(loaderHash, loaderRef, classFileLocator);\n   }\n \n-  @Override\n-  public TypePool typePool(final ClassFileLocator classFileLocator, final ClassLoader classLoader) {\n-    final ClassLoader key =\n-        BOOTSTRAP_CLASSLOADER == classLoader ? BOOTSTRAP_CLASSLOADER_PLACEHOLDER : classLoader;\n-    final TypePool.CacheProvider cache = typePoolCache.computeIfAbsent(key, this);\n+  private final TypePool createNonCachingTypePool(final ClassFileLocator classFileLocator) {", "originalCommit": "176f826a440c9557ec933d7d62c90c1aa416de09", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE2OTE1MA==", "url": "https://github.com/DataDog/dd-trace-java/pull/1189#discussion_r373169150", "bodyText": "Yes, you are right.  I'll get rid of it.", "author": "dougqh", "createdAt": "2020-01-30T20:11:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE1Njg1Mg=="}], "type": "inlineReview"}, {"oid": "0f095f0adbafb52b745f439de6fc1f9ce1864e0e", "url": "https://github.com/DataDog/dd-trace-java/commit/0f095f0adbafb52b745f439de6fc1f9ce1864e0e", "message": "Final clean-up\n\n- Removed unused method from earlier version\n- Corrected previously overlooked comments that were remnant of prior version", "committedDate": "2020-01-30T22:44:24Z", "type": "commit"}, {"oid": "235a6470fb0afd7bd317179644e66294cfd825fc", "url": "https://github.com/DataDog/dd-trace-java/commit/235a6470fb0afd7bd317179644e66294cfd825fc", "message": "googleJavaFormat", "committedDate": "2020-01-30T22:45:40Z", "type": "commit"}, {"oid": "faeb0694240c564e272abe1a6fb7021cf1887b7f", "url": "https://github.com/DataDog/dd-trace-java/commit/faeb0694240c564e272abe1a6fb7021cf1887b7f", "message": "Adjusting capacity check again", "committedDate": "2020-01-30T23:08:49Z", "type": "commit"}]}