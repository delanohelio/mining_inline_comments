{"pr_number": 1446, "pr_title": "Fix ConcurrentModificationException in DeleteFileIndex", "pr_createdAt": "2020-09-13T20:17:41Z", "pr_url": "https://github.com/apache/iceberg/pull/1446", "timeline": [{"oid": "c2782de3560da907556b92d9853c8c03050b0595", "url": "https://github.com/apache/iceberg/commit/c2782de3560da907556b92d9853c8c03050b0595", "message": "Fix ConcurrentModificationException in DeleteFileIndex.", "committedDate": "2020-09-13T20:08:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgxNDA4Nw==", "url": "https://github.com/apache/iceberg/pull/1446#discussion_r487814087", "bodyText": "So I see that there are multple places where ParallelIterator class is synchronized or otherwise blocking. However, from my reading of the rest of the class at least, it seems that we can submit two tasks per worker.\nIs there any way we can avoid blocking on futures indefinitely in a loop, like for example possibly somehow joining the currently running futures and then throwing as sooon as one of them throws an exception. Perhaps there's something I'm missing that makes this less of a concern than it seems initially. If that's the case, could we possibly add a comment indicating why it's not a concern?\nI'm just thinking out loud here, but to me, Future.get usually feels like a code smell.\nThough I'm supportive if this will fix flaky tests. And if there's no concern, then that's great. If there is concern, my feeling is that maybe it's best to fix the flaky tests and then open an issue to be sure to come back to this to have ParallelIterable be more... well, parallel. But again, I might be missing something that makes it more parallel than it seems to me at first glance.", "author": "kbendick", "createdAt": "2020-09-14T10:36:04Z", "path": "core/src/main/java/org/apache/iceberg/util/ParallelIterable.java", "diffHunk": "@@ -98,6 +99,22 @@ private boolean checkTasks() {\n \n       for (int i = 0; i < taskFutures.length; i += 1) {\n         if (taskFutures[i] == null || taskFutures[i].isDone()) {\n+          if (taskFutures[i] != null) {\n+            // check for task failure and re-throw any exception\n+            try {\n+              taskFutures[i].get();", "originalCommit": "c2782de3560da907556b92d9853c8c03050b0595", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgxNTY5MA==", "url": "https://github.com/apache/iceberg/pull/1446#discussion_r487815690", "bodyText": "Possibly CompletableFuture would make sense here?", "author": "kbendick", "createdAt": "2020-09-14T10:39:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgxNDA4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODEwMjY4NA==", "url": "https://github.com/apache/iceberg/pull/1446#discussion_r488102684", "bodyText": "This class is used to parallelize operations that are consumed from a single thread, and primarily for scan planning where we need to scan lots of manifest files (the bottleneck) but split and combine them into tasks (quick). We want the reads to operate in parallel, but the consumer thread should not have additional concerns.\nIn addition, this class attempts to avoid running the back-end tasks too quickly and accumulating too many results in memory. If the consumer stops calling next, then we should also not submit more tasks. This avoids large memory costs in scan planning for limit queries in Presto.\nTo avoid submitting tasks that are unnecessary and to avoid using an additional monitor thread, this class manages task submission in the Iterator methods called by the consumer. Those methods are synchronized so that monitoring the task futures is a safe operation, which should not add much overhead because we expect a single consumer thread.\nI'm not quite sure why you'd think that Future.get is a code smell. Isn't that the correct way to get the result of the future?", "author": "rdblue", "createdAt": "2020-09-14T17:26:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgxNDA4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMwODAwNg==", "url": "https://github.com/apache/iceberg/pull/1446#discussion_r488308006", "bodyText": "It is definitely the appropriate way to get the result from a future, but I'm used to blocking on all of them or on a batch of them at one time (say 2 or so at one time) via some kind of join. However, this is absolutly just because I reviewed this when I was too tired. I should have definitely waited until I had fresh eyes to consider. I completely overlooked the part where you have taskFutures[i].isDone(). So that's totally my bad.\nBut now that you explain how this class is utilized, in particular that the consumer is single threaded, I better understand why this is written the way it is.\nI do very much appreciate you taking the time to explain to me how the class is utilized:\n\nThe single threaded consumer\nThe avoidance of large memory costs in scan planning for presto, particularly with limit queries.\nAs well as the fact that the consumer might stop calling next.\n\nI had mistakenly assumed that by this point in time, the iterator would definitely iterate over all manifests.\nTo further explain what I had thinking (since you graciously took the time to explain this classes utilization in detail), what I would have expected would be to loop over two of them or N of them, then await (via a join or some call to .get) on N at once. But looking at it again after getting more rest, I can see where I was mistaken. Especially since you have the check for taskFutures[i].isDone(). So I do apologize for leaving this review when I should have probably slept on it and then looked at it again with fresh eyes.\nAgain, thanks for taking the time to help me better understand this classes utilization and the unique concerns of various query engines. I don't have much presto experience, so this was definitely enlightening.\nThanks @rdblue!", "author": "kbendick", "createdAt": "2020-09-15T00:18:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgxNDA4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMwODI4OA==", "url": "https://github.com/apache/iceberg/pull/1446#discussion_r488308288", "bodyText": "You can also mark this comment thread as outdated or otherwise close it how you want. I don't seem to have the ability to do that.", "author": "kbendick", "createdAt": "2020-09-15T00:19:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzgxNDA4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAwODY1Mw==", "url": "https://github.com/apache/iceberg/pull/1446#discussion_r488008653", "bodyText": "My only question on this PR is whether we should switch to using a Caffeine loading cache here? I just notice in some places we do that, and in others we just use the concurrent map.", "author": "RussellSpitzer", "createdAt": "2020-09-14T15:09:19Z", "path": "core/src/main/java/org/apache/iceberg/DeleteFileIndex.java", "diffHunk": "@@ -76,7 +76,7 @@\n     ImmutableMap.Builder<Integer, Types.StructType> builder = ImmutableMap.builder();\n     specsById.forEach((specId, spec) -> builder.put(specId, spec.partitionType()));\n     this.partitionTypeById = builder.build();\n-    this.wrapperById = Maps.newHashMap();\n+    this.wrapperById = Maps.newConcurrentMap();", "originalCommit": "c2782de3560da907556b92d9853c8c03050b0595", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODA5MTA5MQ==", "url": "https://github.com/apache/iceberg/pull/1446#discussion_r488091091", "bodyText": "Is there an advantage to using a Caffeine cache here? I think it most cases, we use a cache when we need more features than just computeIfAbsent, like invalidation and expiration. We should probably prefer using standard JVM classes to libraries like Caffeine where possible.", "author": "rdblue", "createdAt": "2020-09-14T17:07:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAwODY1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODEzMDA1Nw==", "url": "https://github.com/apache/iceberg/pull/1446#discussion_r488130057", "bodyText": "My only preference is that it lets you set the \"ifAbsent\" method as default, so you don't actually have to call computeIfAbsent when getting. But I have no preference, just the usage in ManifestGroup doesn't use invalidation or expiration so I was wondering if there was a reason.", "author": "RussellSpitzer", "createdAt": "2020-09-14T18:15:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAwODY1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM0MzU1OQ==", "url": "https://github.com/apache/iceberg/pull/1446#discussion_r488343559", "bodyText": "The one quirk to be aware of is that computeIfAbsent is pessimistic whereas Caffeine's is optimistic. This doesn't mean to prefer it over standard JDK classes, but does that boilerplate optimization which may matter if a hotspot.\nCHM in v8 finds the hashbin, locks it, searches for the entry, and compute if absent. If the entry is found then it has the cost of a putIfAbsent, which similarly blocks on writes. In v9+ the compute method optimistically avoids locking if the first bin entry is the desired one but if not then it locks and searches. This has a modest gain, but still overhead for hot keys.\nAs Caffeine is a cache, it leans towards the entry being present. Therefore it does an get, validates the entry if found (e.g. expiration), and fallback to a compute if absent. This means that a cache hit is lock-free while a miss is slightly penalized, but by a few nanos as it will most often do expensive I/O so insignificant.\nYou can see this behavior for yourself in the benchmarks. So while no reason to use Caffeine, it's a subtle quirk to be aware of in your own usages of CHM.", "author": "ben-manes", "createdAt": "2020-09-15T02:24:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAwODY1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODc1Mzc5MA==", "url": "https://github.com/apache/iceberg/pull/1446#discussion_r488753790", "bodyText": "Thanks for the info! That definitely the case for this usage since it will be set once read many. I'll definitely consider this in future cache/map situations", "author": "RussellSpitzer", "createdAt": "2020-09-15T15:20:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAwODY1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgyMTU4OQ==", "url": "https://github.com/apache/iceberg/pull/1446#discussion_r488821589", "bodyText": "Thanks for the great context, @ben-manes!\nI still expect IO to dominate the cost of planning, but we should certainly keep this behavior in mind in the future. I'd be for changing this (and possibly other places) over to a cache, but let's keep this PR focused since it fixes the current flaky test bug.", "author": "rdblue", "createdAt": "2020-09-15T17:00:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAwODY1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgyNDIwMw==", "url": "https://github.com/apache/iceberg/pull/1446#discussion_r488824203", "bodyText": "Just to clarify you can do the optimization directly, but may want to comment as it first appears unnecessary.\nV value = map.get(key);\nif (value == null) {\n  value = map.computeIfAbsent(key, mappingFunction);\n}\nreturn value;", "author": "ben-manes", "createdAt": "2020-09-15T17:05:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAwODY1Mw=="}], "type": "inlineReview"}]}