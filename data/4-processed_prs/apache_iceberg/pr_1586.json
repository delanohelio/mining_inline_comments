{"pr_number": 1586, "pr_title": "Flink: support specifying user-provided hive-site.xml for hive catalog.", "pr_createdAt": "2020-10-12T14:07:27Z", "pr_url": "https://github.com/apache/iceberg/pull/1586", "timeline": [{"oid": "8664b9f8c5ea4d2054592f33f8d37efe21fad22f", "url": "https://github.com/apache/iceberg/commit/8664b9f8c5ea4d2054592f33f8d37efe21fad22f", "message": "Flink: support specifying user-provided hive-site.xml for hive catalog.", "committedDate": "2020-10-13T13:38:57Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzk2NTQwOQ==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r503965409", "bodyText": "The user can choose to set warehouse property or load hive-site.xml when creating the iceberg catalog.  If use the former,  the warehouse path may be different with the hive metastore, that means it will create files under the user specified directory.\nIf use the hive-site.xml,  then it should be the same configuration as the metastore.", "author": "openinx", "createdAt": "2020-10-13T13:46:44Z", "path": "flink/src/main/java/org/apache/iceberg/flink/CatalogLoader.java", "diffHunk": "@@ -38,8 +40,13 @@ static CatalogLoader hadoop(String name, Configuration hadoopConf, String wareho\n     return new HadoopCatalogLoader(name, hadoopConf, warehouseLocation);\n   }\n \n-  static CatalogLoader hive(String name, Configuration hadoopConf, String uri, int clientPoolSize) {\n-    return new HiveCatalogLoader(name, hadoopConf, uri, clientPoolSize);\n+  static CatalogLoader hive(String name, Configuration hadoopConf, String uri, String warehouse, int clientPoolSize) {", "originalCommit": "8664b9f8c5ea4d2054592f33f8d37efe21fad22f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDQ1MDI4Ng==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r504450286", "bodyText": "Moving those tow method inside this super class, because the newly introduced unit test TestFlinkHiveCatalog  would use them.", "author": "openinx", "createdAt": "2020-10-14T07:11:23Z", "path": "flink/src/test/java/org/apache/iceberg/flink/FlinkTestBase.java", "diffHunk": "@@ -53,4 +64,36 @@ public static void stopMetastore() {\n     flinkCatalogs.values().forEach(Catalog::close);\n     flinkCatalogs.clear();\n   }\n+\n+  protected TableEnvironment getTableEnv() {", "originalCommit": "eb7fe6f4b1dcf891952181d985d4fabdd5df71b3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "12f0a5b0b5488f17e94e3217dd9b8410ca1cbff0", "url": "https://github.com/apache/iceberg/commit/12f0a5b0b5488f17e94e3217dd9b8410ca1cbff0", "message": "Rebase to master", "committedDate": "2020-10-15T10:22:43Z", "type": "forcePushed"}, {"oid": "423eecbdac3840c14a8a9114c4f61996f7f0865a", "url": "https://github.com/apache/iceberg/commit/423eecbdac3840c14a8a9114c4f61996f7f0865a", "message": "Flink: support specifying user-provided hive-site.xml for hive catalog.", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "2aba22991fc8f4c3e0f8112ef27ed8fb6e8df813", "url": "https://github.com/apache/iceberg/commit/2aba22991fc8f4c3e0f8112ef27ed8fb6e8df813", "message": "Loading hive config from classpath if neccessary.", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "dd9d1c84ea4b26d04ca039013984bbe59dd2a17f", "url": "https://github.com/apache/iceberg/commit/dd9d1c84ea4b26d04ca039013984bbe59dd2a17f", "message": "Fix the broken unit tests.", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "2602e4882c9a830db75bf4397b940dae3e6d9c02", "url": "https://github.com/apache/iceberg/commit/2602e4882c9a830db75bf4397b940dae3e6d9c02", "message": "Revert \"Fix the broken unit tests.\"\n\nThis reverts commit ef87f5378f8e4e3982f25ae5a74e83eb4b3938de.", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "6dec7b10ef8187ba404aaa4b1328775c7bd8c12c", "url": "https://github.com/apache/iceberg/commit/6dec7b10ef8187ba404aaa4b1328775c7bd8c12c", "message": "Fix the broken unit tests", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "342c3eca8f4cfd1230b0e1f23d36edc97569dceb", "url": "https://github.com/apache/iceberg/commit/342c3eca8f4cfd1230b0e1f23d36edc97569dceb", "message": "Checkstyle issues", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "2166bdfde3920afec8002d25351ac3056e57ff85", "url": "https://github.com/apache/iceberg/commit/2166bdfde3920afec8002d25351ac3056e57ff85", "message": "Add document", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "7c3c59410620295e3b99edfc66c8c81ae19cb185", "url": "https://github.com/apache/iceberg/commit/7c3c59410620295e3b99edfc66c8c81ae19cb185", "message": "Rebase to master", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "12b742cc44a8c63c4b3451d61c6f5b2508288014", "url": "https://github.com/apache/iceberg/commit/12b742cc44a8c63c4b3451d61c6f5b2508288014", "message": "Fix the broken unit tests", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "51b6abb4bc7ff664bd0f9725ffc0808a363bc402", "url": "https://github.com/apache/iceberg/commit/51b6abb4bc7ff664bd0f9725ffc0808a363bc402", "message": "Checkstyle issues", "committedDate": "2020-10-19T10:09:43Z", "type": "commit"}, {"oid": "de034032848848aaafdab978c251d7a7024a7b11", "url": "https://github.com/apache/iceberg/commit/de034032848848aaafdab978c251d7a7024a7b11", "message": "Set the thrift pool size.", "committedDate": "2020-10-19T10:12:56Z", "type": "commit"}, {"oid": "de034032848848aaafdab978c251d7a7024a7b11", "url": "https://github.com/apache/iceberg/commit/de034032848848aaafdab978c251d7a7024a7b11", "message": "Set the thrift pool size.", "committedDate": "2020-10-19T10:12:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODgyMTI0Mg==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r508821242", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * `warehouse`: The hive warehouse location, users would need to specify this path if them don't set the `hive-conf-dir` (The path where we load `hive-site.xml`).\n          \n          \n            \n            * `warehouse`: The Hive warehouse location, users shouldy specify this path if they don't set the `hive-conf-dir` to a location containing a `hive-site.xml` configuration file.", "author": "massdosage", "createdAt": "2020-10-20T20:33:51Z", "path": "site/docs/flink.md", "diffHunk": "@@ -106,6 +120,8 @@ CREATE CATALOG hive_catalog WITH (\n * `uri`: The Hive metastore's thrift URI. (Required)\n * `clients`: The Hive metastore client pool size, default value is 2. (Optional)\n * `property-version`: Version number to describe the property version. This property can be used for backwards compatibility in case the property format changes. The currently property version is `1`. (Optional)\n+* `warehouse`: The hive warehouse location, users would need to specify this path if them don't set the `hive-conf-dir` (The path where we load `hive-site.xml`).", "originalCommit": "de034032848848aaafdab978c251d7a7024a7b11", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODgyMjIzNA==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r508822234", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * `hive-conf-dir`: Directory path to load the `hive-site.xml`.\n          \n          \n            \n            * `hive-conf-dir`: Path to a directory containing a`hive-site.xml` configuration file which will be used to provide custom Hive configuration values.", "author": "massdosage", "createdAt": "2020-10-20T20:35:32Z", "path": "site/docs/flink.md", "diffHunk": "@@ -106,6 +120,8 @@ CREATE CATALOG hive_catalog WITH (\n * `uri`: The Hive metastore's thrift URI. (Required)\n * `clients`: The Hive metastore client pool size, default value is 2. (Optional)\n * `property-version`: Version number to describe the property version. This property can be used for backwards compatibility in case the property format changes. The currently property version is `1`. (Optional)\n+* `warehouse`: The hive warehouse location, users would need to specify this path if them don't set the `hive-conf-dir` (The path where we load `hive-site.xml`).\n+* `hive-conf-dir`: Directory path to load the `hive-site.xml`.", "originalCommit": "de034032848848aaafdab978c251d7a7024a7b11", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODgyMzc0NA==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r508823744", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            We could also just specify the `warehouse` property (without specifying any hive configuration path) to initialize the hive catalog: \n          \n          \n            \n            Alternatively one can instead set just the `warehouse` property (without specifying a Hive configuration directory) to initialize the Hive catalog:", "author": "massdosage", "createdAt": "2020-10-20T20:38:18Z", "path": "site/docs/flink.md", "diffHunk": "@@ -97,7 +97,21 @@ CREATE CATALOG hive_catalog WITH (\n   'catalog-type'='hive',\n   'uri'='thrift://localhost:9083',\n   'clients'='5',\n-  'property-version'='1'\n+  'property-version'='1',\n+  'hive-conf-dir'='/opt/hive/conf'\n+);\n+```\n+\n+We could also just specify the `warehouse` property (without specifying any hive configuration path) to initialize the hive catalog: ", "originalCommit": "de034032848848aaafdab978c251d7a7024a7b11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk0NzAyMg==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r508947022", "bodyText": "Thanks for the change,  I will accept it. @massdosage  !", "author": "openinx", "createdAt": "2020-10-21T02:13:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODgyMzc0NA=="}], "type": "inlineReview"}, {"oid": "c15399ff0553f4ce374550e6c7e08195870eb667", "url": "https://github.com/apache/iceberg/commit/c15399ff0553f4ce374550e6c7e08195870eb667", "message": "Update site/docs/flink.md\n\nCo-authored-by: Adrian Woodhead <massdosage@gmail.com>", "committedDate": "2020-10-21T02:13:36Z", "type": "commit"}, {"oid": "c23e16fd3f6548d358fb4e8c378f7cd96b2c8886", "url": "https://github.com/apache/iceberg/commit/c23e16fd3f6548d358fb4e8c378f7cd96b2c8886", "message": "Addressing the comments.", "committedDate": "2020-10-21T02:31:42Z", "type": "commit"}, {"oid": "38b83b2654a87a61bb5fccb14eca0667d08bdf83", "url": "https://github.com/apache/iceberg/commit/38b83b2654a87a61bb5fccb14eca0667d08bdf83", "message": "Precheck for the existence of hive-conf-dir", "committedDate": "2020-10-21T02:42:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1MzQ2MQ==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509453461", "bodyText": "Why did this change? Needing to increase the number of threads used by the Hive MetaStore is a red flag that this may be leaking Hive connections. In cases where all of the connections are handled by a ClientPool, we should not need to increase the number of handler threads. This helps us avoid leaks because we catch them in testing rather than at runtime.", "author": "rdblue", "createdAt": "2020-10-21T17:03:17Z", "path": "flink/src/test/java/org/apache/iceberg/flink/FlinkTestBase.java", "diffHunk": "@@ -34,23 +40,53 @@\n   private static TestHiveMetastore metastore = null;\n   protected static HiveConf hiveConf = null;\n   protected static HiveCatalog catalog = null;\n-  protected static ConcurrentMap<String, Catalog> flinkCatalogs;\n+\n+  private volatile TableEnvironment tEnv = null;\n \n   @BeforeClass\n   public static void startMetastore() {\n     FlinkTestBase.metastore = new TestHiveMetastore();\n-    metastore.start();\n+    metastore.start(15);", "originalCommit": "38b83b2654a87a61bb5fccb14eca0667d08bdf83", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1NDI2Nw==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509854267", "bodyText": "I thought the hive handlers were not enough in the TestFlinkCatalogDatabase  test suite, but today I checked the logs carefully, it's indeed a connection leak issue.   The catalog connection would be closed only when unregistering the catalog, means executing the sql DROP CATALOG test_catalog.  I found we did not release the connection after a test case finished.   No need to increase the handler number here, just need to provide Before/After to create/release connection, pls see f2740c6.", "author": "openinx", "createdAt": "2020-10-22T03:13:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1MzQ2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1Njc4MQ==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509456781", "bodyText": "Style nit: we typically add an empty line after control flow statements. This removes one and doesn't add one after the new if.", "author": "rdblue", "createdAt": "2020-10-21T17:08:37Z", "path": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalog.java", "diffHunk": "@@ -72,13 +72,19 @@ public HiveCatalog(Configuration conf) {\n   }\n \n   public HiveCatalog(String name, String uri, int clientPoolSize, Configuration conf) {\n+    this(name, uri, null, clientPoolSize, conf);\n+  }\n+\n+  public HiveCatalog(String name, String uri, String warehouse, int clientPoolSize, Configuration conf) {\n     this.name = name;\n     this.conf = new Configuration(conf);\n     // before building the client pool, overwrite the configuration's URIs if the argument is non-null\n     if (uri != null) {\n       this.conf.set(HiveConf.ConfVars.METASTOREURIS.varname, uri);\n     }\n-\n+    if (warehouse != null) {\n+      this.conf.set(HiveConf.ConfVars.METASTOREWAREHOUSE.varname, warehouse);\n+    }", "originalCommit": "38b83b2654a87a61bb5fccb14eca0667d08bdf83", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1Nzc1MQ==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509457751", "bodyText": "Why not keep this location as a field in the HiveCatalog instead of storing it in conf? Then the default logic would only need to be run once.", "author": "rdblue", "createdAt": "2020-10-21T17:10:07Z", "path": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveCatalog.java", "diffHunk": "@@ -72,13 +72,19 @@ public HiveCatalog(Configuration conf) {\n   }\n \n   public HiveCatalog(String name, String uri, int clientPoolSize, Configuration conf) {\n+    this(name, uri, null, clientPoolSize, conf);\n+  }\n+\n+  public HiveCatalog(String name, String uri, String warehouse, int clientPoolSize, Configuration conf) {\n     this.name = name;\n     this.conf = new Configuration(conf);\n     // before building the client pool, overwrite the configuration's URIs if the argument is non-null\n     if (uri != null) {\n       this.conf.set(HiveConf.ConfVars.METASTOREURIS.varname, uri);\n     }\n-\n+    if (warehouse != null) {\n+      this.conf.set(HiveConf.ConfVars.METASTOREWAREHOUSE.varname, warehouse);", "originalCommit": "38b83b2654a87a61bb5fccb14eca0667d08bdf83", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0MzY1Mg==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509843652", "bodyText": "As we discussed in this comment,   we could set warehouse string or hive-conf-dir to get the hive warehouse.   If use a local field,  then in getWarehouseLocation,  we would check the local field first and then read the hiveConf ?  I want to unify the parse path so I  put this key-value into hiveConf (It's a deep-cloned conf, so should not affect the origin conf).", "author": "openinx", "createdAt": "2020-10-22T02:33:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1Nzc1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1MDQyNw==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509850427", "bodyText": "Yes, It can be handled in the same way as URIs.", "author": "JingsongLi", "createdAt": "2020-10-22T02:58:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1Nzc1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE2MjEzMg==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r511162132", "bodyText": "I think handling this the same way that we handle the URI makes sense. We set the URI because we need to pass it back into Hive to connect, which I don't think applies to the warehouse path, but handling both the same way is reasonable.", "author": "rdblue", "createdAt": "2020-10-23T21:25:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ1Nzc1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ2MjQ1OA==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509462458", "bodyText": "A small clarification: this implies that the use of hive-site.xml and warehouse are alternatives, but they aren't. You may want to use warehouse from the Hive site, or you may want to use other settings from hive-site.xml with a custom warehouse location. I think this should document the two options separately.\nFor documenting options, I think we will want to rely more on the option list below because copying the SQL block each time creates a long doc. I would have one simple example for each catalog type with the options we recommend for it (Hive: uri, warehouse, and property-version; Hadoop: warehouse, property-version) and a refer to the options list to document clients and hive-conf-dir.", "author": "rdblue", "createdAt": "2020-10-21T17:14:47Z", "path": "site/docs/flink.md", "diffHunk": "@@ -97,7 +97,21 @@ CREATE CATALOG hive_catalog WITH (\n   'catalog-type'='hive',\n   'uri'='thrift://localhost:9083',\n   'clients'='5',\n-  'property-version'='1'\n+  'property-version'='1',\n+  'hive-conf-dir'='/opt/hive/conf'\n+);\n+```\n+\n+Alternatively one can instead set just the `warehouse` property (without specifying a Hive configuration directory) to initialize the Hive catalog:", "originalCommit": "38b83b2654a87a61bb5fccb14eca0667d08bdf83", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTgzOTUzMQ==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509839531", "bodyText": "Well, let me make this more clear.", "author": "openinx", "createdAt": "2020-10-22T02:18:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ2MjQ1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ2MzkwNA==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509463904", "bodyText": "I think we support reads in batch mode, right?", "author": "rdblue", "createdAt": "2020-10-21T17:16:18Z", "path": "site/docs/flink.md", "diffHunk": "@@ -293,4 +309,4 @@ There are some features that we do not yet support in the current flink iceberg\n * Don't support creating iceberg table with computed column.\n * Don't support creating iceberg table with watermark.\n * Don't support adding columns, removing columns, renaming columns, changing columns. [FLINK-19062](https://issues.apache.org/jira/browse/FLINK-19062) is tracking this.\n-* Don't support flink read iceberg table in batch or streaming mode. [#1346](https://github.com/apache/iceberg/pull/1346) and [#1293](https://github.com/apache/iceberg/pull/1293) are tracking this. \n\\ No newline at end of file\n+* Don't support flink read iceberg table in batch or streaming mode. [#1346](https://github.com/apache/iceberg/pull/1346) and [#1293](https://github.com/apache/iceberg/pull/1293) are tracking this.", "originalCommit": "38b83b2654a87a61bb5fccb14eca0667d08bdf83", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTgzOTQyNg==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509839426", "bodyText": "Yes, that's right.", "author": "openinx", "createdAt": "2020-10-22T02:18:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTQ2MzkwNA=="}], "type": "inlineReview"}, {"oid": "7fdda77ee9942d3a26239498741a12b078c004df", "url": "https://github.com/apache/iceberg/commit/7fdda77ee9942d3a26239498741a12b078c004df", "message": "Addressing the comment from Ryan", "committedDate": "2020-10-22T02:40:45Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1MDg0OA==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509850848", "bodyText": "Maybe I missed something. Why not load hive-conf into hadoopConf here?", "author": "JingsongLi", "createdAt": "2020-10-22T03:00:28Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalogFactory.java", "diffHunk": "@@ -71,12 +72,16 @@ protected CatalogLoader createCatalogLoader(String name, Map<String, String> pro\n     String catalogType = properties.getOrDefault(ICEBERG_CATALOG_TYPE, \"hive\");\n     switch (catalogType) {\n       case \"hive\":\n-        int clientPoolSize = Integer.parseInt(properties.getOrDefault(HIVE_CLIENT_POOL_SIZE, \"2\"));\n+        // The values of properties 'uri', 'warehouse', 'hive-conf-dir' are allowed to be null, in that case it will\n+        // fallback to parse those values from hadoop configuration which is loaded from classpath.\n         String uri = properties.get(HIVE_URI);\n-        return CatalogLoader.hive(name, hadoopConf, uri, clientPoolSize);\n+        String warehouse = properties.get(WAREHOUSE_LOCATION);\n+        int clientPoolSize = Integer.parseInt(properties.getOrDefault(HIVE_CLIENT_POOL_SIZE, \"2\"));\n+        String hiveConfDir = properties.get(HIVE_CONF_DIR);\n+        return CatalogLoader.hive(name, hadoopConf, uri, warehouse, clientPoolSize, hiveConfDir);", "originalCommit": "7fdda77ee9942d3a26239498741a12b078c004df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg2MzM3MA==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509863370", "bodyText": "Oh, I almost forgot that the loadCatalog would be executed at task manager side for flink.   we should merge hive conf into hadoop conf before initializing the catalog loader, so that we won't miss to load a non-existed path in task manager node.", "author": "openinx", "createdAt": "2020-10-22T03:50:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1MDg0OA=="}], "type": "inlineReview"}, {"oid": "f2740c6cf4f7aa5e090a4b3df60e853aaa140e38", "url": "https://github.com/apache/iceberg/commit/f2740c6cf4f7aa5e090a4b3df60e853aaa140e38", "message": "Fix the hive connection leak issues", "committedDate": "2020-10-22T03:04:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1MTg2MA==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509851860", "bodyText": "(maybe it should be discussed elsewhere) we don't need to tell users configure this property-version", "author": "JingsongLi", "createdAt": "2020-10-22T03:04:19Z", "path": "site/docs/flink.md", "diffHunk": "@@ -97,15 +97,20 @@ CREATE CATALOG hive_catalog WITH (\n   'catalog-type'='hive',\n   'uri'='thrift://localhost:9083',\n   'clients'='5',\n-  'property-version'='1'\n+  'property-version'='1',", "originalCommit": "7fdda77ee9942d3a26239498741a12b078c004df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg2NDMyMw==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509864323", "bodyText": "Seems we could remove it from the example,  it's not a necessary property ( The options description has mentioned that).", "author": "openinx", "createdAt": "2020-10-22T03:53:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1MTg2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1MjgyMA==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509852820", "bodyText": "The document doesn't look clear enough. Actually, there are three options:\n-Configure URI and warehouse\n-Configure hive-conf-dir\n-The resource of class path contains hive conf\nUsers can choose one of them", "author": "JingsongLi", "createdAt": "2020-10-22T03:08:04Z", "path": "site/docs/flink.md", "diffHunk": "@@ -97,15 +97,20 @@ CREATE CATALOG hive_catalog WITH (\n   'catalog-type'='hive',\n   'uri'='thrift://localhost:9083',\n   'clients'='5',\n-  'property-version'='1'\n+  'property-version'='1',\n+  'warehouse'='hdfs://nn:8020/warehouse/path'\n );\n ```\n \n+We must set `hive-conf-dir` property to get the custom warehouse location by specifying the hive configuration directory where to load the `hive-site.xml`, if we don't provide the `warehouse` property explicitly.", "originalCommit": "7fdda77ee9942d3a26239498741a12b078c004df", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1MzQ5NA==", "url": "https://github.com/apache/iceberg/pull/1586#discussion_r509853494", "bodyText": "NIT: use hiveConf.get(HiveConf.ConfVars.METASTOREWAREHOUSE.varname) instead of null.", "author": "JingsongLi", "createdAt": "2020-10-22T03:10:25Z", "path": "flink/src/test/java/org/apache/iceberg/flink/source/TestFlinkInputFormatReaderDeletes.java", "diffHunk": "@@ -107,7 +107,7 @@ protected StructLikeSet rowSet(String name, Table testTable, String... columns)\n     RowType rowType = FlinkSchemaUtil.convert(projected);\n     CatalogLoader hiveCatalogLoader = CatalogLoader.hive(catalog.name(),\n         hiveConf,\n-        hiveConf.get(HiveConf.ConfVars.METASTOREURIS.varname),\n+        hiveConf.get(HiveConf.ConfVars.METASTOREURIS.varname), null,", "originalCommit": "7fdda77ee9942d3a26239498741a12b078c004df", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "247f5d769b6dde6f26f2a361ce8507e87b91934e", "url": "https://github.com/apache/iceberg/commit/247f5d769b6dde6f26f2a361ce8507e87b91934e", "message": "Loading hive-site configuration when initialize the Iceberg catalog loader.", "committedDate": "2020-10-22T03:46:33Z", "type": "commit"}, {"oid": "4ad9aafa55f80dd74abd3d65c2adf4ca42b6b242", "url": "https://github.com/apache/iceberg/commit/4ad9aafa55f80dd74abd3d65c2adf4ca42b6b242", "message": "Make the document more clear", "committedDate": "2020-10-22T04:08:39Z", "type": "commit"}]}