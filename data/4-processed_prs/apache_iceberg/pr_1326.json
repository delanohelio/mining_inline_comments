{"pr_number": 1326, "pr_title": "Hive: Filter pushdown", "pr_createdAt": "2020-08-12T13:14:56Z", "pr_url": "https://github.com/apache/iceberg/pull/1326", "timeline": [{"oid": "e2007c1d354f46fb26186e71a81df989de6d4c4d", "url": "https://github.com/apache/iceberg/commit/e2007c1d354f46fb26186e71a81df989de6d4c4d", "message": "Add filter factory", "committedDate": "2020-07-27T16:24:32Z", "type": "commit"}, {"oid": "f97e408c1645285fc8f06c565d06a9d69c2e703e", "url": "https://github.com/apache/iceberg/commit/f97e408c1645285fc8f06c565d06a9d69c2e703e", "message": "Fix type conversions", "committedDate": "2020-08-12T12:42:09Z", "type": "commit"}, {"oid": "03729f414d48373cfa23c24e91861afea1f838db", "url": "https://github.com/apache/iceberg/commit/03729f414d48373cfa23c24e91861afea1f838db", "message": "Add tests", "committedDate": "2020-08-12T13:00:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTI5ODMwMw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469298303", "bodyText": "This comment seems to be at odds with the exception being thrown? It looks like in the hive code it just does nothing? Maybe I'm reading it wrong.", "author": "RussellSpitzer", "createdAt": "2020-08-12T14:23:57Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(tree.getChildren().get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        //We are unsure of how the CONSTANT case works, so using the approach of:\n+        //https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/read/\n+        // ParquetFilterPredicateConverter.java#L116", "originalCommit": "03729f414d48373cfa23c24e91861afea1f838db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM3NzcyOA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469377728", "bodyText": "Ah yes, thanks for the spot - I changed the approach here during another review and didn't remove the comment. Will remove :)", "author": "cmathiesen", "createdAt": "2020-08-12T16:12:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTI5ODMwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTMwMTE4Ng==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469301186", "bodyText": "I'm new to this code, so I wonder when reading this why we was to get the literal as a list if getLiteral is null? Does having getLiteral() returning null mean that there is a collection type?", "author": "RussellSpitzer", "createdAt": "2020-08-12T14:27:42Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(tree.getChildren().get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        //We are unsure of how the CONSTANT case works, so using the approach of:\n+        //https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/read/\n+        // ParquetFilterPredicateConverter.java#L116\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToIcebergType(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToIcebergType(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToIcebergType(leaf));\n+      case IN:\n+        return in(column, (List) leafToIcebergType(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leaf.getLiteralList();\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToIcebergType(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+        return leaf.getLiteral() != null ? leaf.getLiteral() : leaf.getLiteralList();", "originalCommit": "03729f414d48373cfa23c24e91861afea1f838db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM3NzE2MA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469377160", "bodyText": "Yeah, that's sort of whats going on. It looks like you'd only be using getLiteralList if the operator for the leaf was IN or BETWEEN, and then getLiteral for all other operator types. It would either be one or the other, so it seemed easiest to check for a null rather than calling getOperator and having cases to switch through all the different operators, if that makes sense", "author": "cmathiesen", "createdAt": "2020-08-12T16:11:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTMwMTE4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTMwMjk4NA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469302984", "bodyText": "Not a big deal but I tend to make constants for numbers that can be misread like this, MILLION or MICROS_PER_SECOND", "author": "RussellSpitzer", "createdAt": "2020-08-12T14:30:09Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(tree.getChildren().get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        //We are unsure of how the CONSTANT case works, so using the approach of:\n+        //https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/read/\n+        // ParquetFilterPredicateConverter.java#L116\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToIcebergType(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToIcebergType(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToIcebergType(leaf));\n+      case IN:\n+        return in(column, (List) leafToIcebergType(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leaf.getLiteralList();\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToIcebergType(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+        return leaf.getLiteral() != null ? leaf.getLiteral() : leaf.getLiteralList();\n+      case FLOAT:\n+        return leaf.getLiteral() != null ? leaf.getLiteral() : leaf.getLiteralList();\n+      case STRING:\n+        return leaf.getLiteral() != null ? leaf.getLiteral() : leaf.getLiteralList();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        if (leaf.getLiteral() != null) {\n+          return ((Timestamp) leaf.getLiteral()).toLocalDateTime().toLocalDate().toEpochDay();\n+        } else {\n+          //But not when retrieving the literalList\n+          List<Object> icebergValues = leaf.getLiteralList();\n+          icebergValues.replaceAll(value -> ((Date) value).toLocalDate().toEpochDay());\n+          return icebergValues;\n+        }\n+      case DECIMAL:\n+        if (leaf.getLiteral() != null) {\n+          return BigDecimal.valueOf(((HiveDecimalWritable) leaf.getLiteral()).doubleValue());\n+        } else {\n+          List<Object> icebergValues = leaf.getLiteralList();\n+          icebergValues.replaceAll(value -> BigDecimal.valueOf(((HiveDecimalWritable) value).doubleValue()));\n+          return icebergValues;\n+        }\n+      case TIMESTAMP:\n+        if (leaf.getLiteral() != null) {\n+          Timestamp timestamp = (Timestamp) leaf.getLiteral();\n+          return timestamp.toInstant().getEpochSecond() * 1000000 + timestamp.getNanos() / 1000;", "originalCommit": "03729f414d48373cfa23c24e91861afea1f838db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM3ODE5OA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469378198", "bodyText": "A very good point, I'll update these!", "author": "cmathiesen", "createdAt": "2020-08-12T16:12:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTMwMjk4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTMxMTUzNQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469311535", "bodyText": "I think we should probably have tests for all the filter literal types here, It seems like we are only checking Longs?  Especially given the special code around other specific types.", "author": "RussellSpitzer", "createdAt": "2020-08-12T14:41:54Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,191 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+", "originalCommit": "03729f414d48373cfa23c24e91861afea1f838db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQwMTczMA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469401730", "bodyText": "I agree we should tests as many types as we can. We also don't need to test every predicate for every type. I think it's fine to test each predicate with a long and then to test each type with equals, for example.", "author": "rdblue", "createdAt": "2020-08-12T16:52:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTMxMTUzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTM5NTkyMQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469395921", "bodyText": "Should this be childNodes.get(0)?", "author": "rdblue", "createdAt": "2020-08-12T16:42:22Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(tree.getChildren().get(0), leaves));", "originalCommit": "03729f414d48373cfa23c24e91861afea1f838db", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQwMjQ2OA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r469402468", "bodyText": "I think it would be better to split this into two methods: one for a single literal and one for a list of literals. Returning either one as Object doesn't allow us to make sure we're calling getLiteralList for the correct predicates.", "author": "rdblue", "createdAt": "2020-08-12T16:53:23Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(tree.getChildren().get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        //We are unsure of how the CONSTANT case works, so using the approach of:\n+        //https://github.com/apache/hive/blob/master/ql/src/java/org/apache/hadoop/hive/ql/io/parquet/read/\n+        // ParquetFilterPredicateConverter.java#L116\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToIcebergType(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToIcebergType(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToIcebergType(leaf));\n+      case IN:\n+        return in(column, (List) leafToIcebergType(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leaf.getLiteralList();\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToIcebergType(PredicateLeaf leaf) {", "originalCommit": "03729f414d48373cfa23c24e91861afea1f838db", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b34300aea4e768240a1b39f35b01c58a0fe7ca22", "url": "https://github.com/apache/iceberg/commit/b34300aea4e768240a1b39f35b01c58a0fe7ca22", "message": "Add more tests and change literalList method", "committedDate": "2020-08-13T17:21:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQ3OTc3NQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472479775", "bodyText": "nit: empty line", "author": "rdsr", "createdAt": "2020-08-18T20:40:22Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+", "originalCommit": "b34300aea4e768240a1b39f35b01c58a0fe7ca22", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUwODkxMw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472508913", "bodyText": "nit: to b consistent with MICROS_PER_SECOND maybe we can rename NANOSECS_PER_MICROSEC to NANOS_PER_MICROSEC", "author": "rdsr", "createdAt": "2020-08-18T21:40:12Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOSECS_PER_MICROSEC = 1000;", "originalCommit": "b34300aea4e768240a1b39f35b01c58a0fe7ca22", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQyNzM0Nw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473427347", "bodyText": "What about using TimeUnit for the conversion and get rid of those variables altogether?", "author": "guilload", "createdAt": "2020-08-19T23:22:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUwODkxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUxMDg1MQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472510851", "bodyText": "seems like leafToLiteral can be called only once and its result used in the switch branches", "author": "rdsr", "createdAt": "2020-08-18T21:44:38Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOSECS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));", "originalCommit": "b34300aea4e768240a1b39f35b01c58a0fe7ca22", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkyMjMyNw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472922327", "bodyText": "seems like leafToLiteral can be called only once and its result used in the switch branches\n\nBut leafToLiteral isn't used in all the switch branches (e.g. IN and BETWEEN use leafToLiteralList, IS_NULL doesn't use it at all) so we'd be calling it for nothing in those cases. I think it's fine as is?", "author": "massdosage", "createdAt": "2020-08-19T10:20:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUxMDg1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzA1MDM1Mg==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473050352", "bodyText": "yea, that sounds good.", "author": "rdsr", "createdAt": "2020-08-19T13:58:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUxMDg1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUxMTg0NA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472511844", "bodyText": "nit: seems like UnuspportedOperationExp is more suitable here", "author": "rdsr", "createdAt": "2020-08-18T21:46:47Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOSECS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());", "originalCommit": "b34300aea4e768240a1b39f35b01c58a0fe7ca22", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMDE4NA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472530184", "bodyText": "I'm unsure if this is correct. I think here, the scale of the BigDecimal will always be 0. Irrespective of the underlying data", "author": "rdsr", "createdAt": "2020-08-18T22:32:41Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOSECS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return ((Timestamp) leaf.getLiteral()).toLocalDateTime().toLocalDate().toEpochDay();\n+      case DECIMAL:\n+        return BigDecimal.valueOf(((HiveDecimalWritable) leaf.getLiteral()).doubleValue());", "originalCommit": "b34300aea4e768240a1b39f35b01c58a0fe7ca22", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzIyMjQ3Nw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473222477", "bodyText": "Yes, this is not correct because it discards the scale and precision.\nThis should follow the examples from ORC, which also convert decimals: https://github.com/apache/iceberg/blob/master/data/src/main/java/org/apache/iceberg/data/orc/GenericOrcReaders.java#L163", "author": "rdblue", "createdAt": "2020-08-19T18:00:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMDE4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMTY1Mg==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472531652", "bodyText": "nit: I think it is clearer to not modify the returned list but to use standard idioms like leaf.getLiteralList().stream().map ... or Lists.transform(..)", "author": "rdsr", "createdAt": "2020-08-18T22:36:57Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOSECS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return ((Timestamp) leaf.getLiteral()).toLocalDateTime().toLocalDate().toEpochDay();\n+      case DECIMAL:\n+        return BigDecimal.valueOf(((HiveDecimalWritable) leaf.getLiteral()).doubleValue());\n+      case TIMESTAMP:\n+        Timestamp timestamp = (Timestamp) leaf.getLiteral();\n+        return timestamp.toInstant().getEpochSecond() * MICROS_PER_SECOND +\n+                timestamp.getNanos() / NANOSECS_PER_MICROSEC;\n+      default:\n+        throw new IllegalStateException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        List<Object> dateValues = leaf.getLiteralList();\n+        dateValues.replaceAll(value -> ((Date) value).toLocalDate().toEpochDay());\n+        return dateValues;\n+      case DECIMAL:\n+        List<Object> decimalValues = leaf.getLiteralList();", "originalCommit": "b34300aea4e768240a1b39f35b01c58a0fe7ca22", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMTcyOA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472531728", "bodyText": "same.", "author": "rdsr", "createdAt": "2020-08-18T22:37:10Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOSECS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return ((Timestamp) leaf.getLiteral()).toLocalDateTime().toLocalDate().toEpochDay();\n+      case DECIMAL:\n+        return BigDecimal.valueOf(((HiveDecimalWritable) leaf.getLiteral()).doubleValue());\n+      case TIMESTAMP:\n+        Timestamp timestamp = (Timestamp) leaf.getLiteral();\n+        return timestamp.toInstant().getEpochSecond() * MICROS_PER_SECOND +\n+                timestamp.getNanos() / NANOSECS_PER_MICROSEC;\n+      default:\n+        throw new IllegalStateException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        List<Object> dateValues = leaf.getLiteralList();\n+        dateValues.replaceAll(value -> ((Date) value).toLocalDate().toEpochDay());\n+        return dateValues;\n+      case DECIMAL:\n+        List<Object> decimalValues = leaf.getLiteralList();\n+        decimalValues.replaceAll(value -> BigDecimal.valueOf(((HiveDecimalWritable) value).doubleValue()));\n+        return decimalValues;\n+      case TIMESTAMP:\n+        List<Object> timestampValues = leaf.getLiteralList();\n+        timestampValues.replaceAll(value -> ((Timestamp) value).toInstant().getEpochSecond() * MICROS_PER_SECOND +", "originalCommit": "b34300aea4e768240a1b39f35b01c58a0fe7ca22", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMTc5Nw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472531797", "bodyText": "nit: better to throw unsupportedexception", "author": "rdsr", "createdAt": "2020-08-18T22:37:24Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOSECS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new IllegalStateException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return ((Timestamp) leaf.getLiteral()).toLocalDateTime().toLocalDate().toEpochDay();\n+      case DECIMAL:\n+        return BigDecimal.valueOf(((HiveDecimalWritable) leaf.getLiteral()).doubleValue());\n+      case TIMESTAMP:\n+        Timestamp timestamp = (Timestamp) leaf.getLiteral();\n+        return timestamp.toInstant().getEpochSecond() * MICROS_PER_SECOND +\n+                timestamp.getNanos() / NANOSECS_PER_MICROSEC;\n+      default:\n+        throw new IllegalStateException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        List<Object> dateValues = leaf.getLiteralList();\n+        dateValues.replaceAll(value -> ((Date) value).toLocalDate().toEpochDay());\n+        return dateValues;\n+      case DECIMAL:\n+        List<Object> decimalValues = leaf.getLiteralList();\n+        decimalValues.replaceAll(value -> BigDecimal.valueOf(((HiveDecimalWritable) value).doubleValue()));\n+        return decimalValues;\n+      case TIMESTAMP:\n+        List<Object> timestampValues = leaf.getLiteralList();\n+        timestampValues.replaceAll(value -> ((Timestamp) value).toInstant().getEpochSecond() * MICROS_PER_SECOND +\n+                ((Timestamp) value).getNanos() / NANOSECS_PER_MICROSEC);\n+        return timestampValues;\n+      default:\n+        throw new IllegalStateException(\"Unknown type: \" + leaf.getType());", "originalCommit": "b34300aea4e768240a1b39f35b01c58a0fe7ca22", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjU5MQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472532591", "bodyText": "I don't think getSplits is the right method to set the translated Iceberg expr in jobconf. I think this should go in IcebergStorageHandler . @guilload what do you think?", "author": "rdsr", "createdAt": "2020-08-18T22:39:42Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergInputFormat.java", "diffHunk": "@@ -51,6 +58,17 @@\n \n     forwardConfigSettings(job);\n \n+    //Convert Hive filter to Iceberg filter\n+    String hiveFilter = job.get(TableScanDesc.FILTER_EXPR_CONF_STR);", "originalCommit": "b34300aea4e768240a1b39f35b01c58a0fe7ca22", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjg5NjU2NQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472896565", "bodyText": "Yeah I think you're right here, and I was initially attempting to do it that way too but I was having some trouble finding the correct method of doing that. I attempted to update the conf in decomposePredicate but the way I was doing it caused some bugs where the value I was setting wasn't getting reset between queries if one query had a filter (and decomposePredicate would get called) and the next didn't (so decomposePredicate doesn't get called). And in the other methods like configureJobConf, the filter information wasn't available so it couldn't be set.\nI would really appreciate some input on this, I may have missed something with how the StorageHandler works with Hive!", "author": "cmathiesen", "createdAt": "2020-08-19T09:34:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjU5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzIyNDM3NQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473224375", "bodyText": "@omalley, any input on where the filter pushdown should go?", "author": "rdblue", "createdAt": "2020-08-19T18:04:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjU5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzMxMzgyNQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473313825", "bodyText": "The most common places to put it are:\n\ngetSplits - to filter the splits aggressively\ngetRecordReader - to filter the records while reading\n\nThe information is being set by HiveInputFormat.pushFilters, but looking through the various paths to get there I think you need to stick to those.", "author": "omalley", "createdAt": "2020-08-19T20:56:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjU5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQzNTY1Ng==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473435656", "bodyText": "I came to the same conclusion when trying to implement projection pushdown in the storage handler.\nUnfortunately as @cmathiesen stated, the job config is not yet populated with the projected columns and the filter expression when the storage handler \"hooks\" such as configureJobConf are called. So the right entry points for implementing PPD are getSplits and  getRecordReader.\nHowever, there's another catch. The JobConf objects passed in getSplits and getRecordReader are actually not the same and the filter expression set in getSplits (L#53 in HiveIcebergInputFormat)  is no longer available when getRecordReader  is subsequently called.\nSince in the storage handler we don't decompose the filter expression, Hive applies the whole thing anyway and this can't be caught in the test suite but we need to set the filter expression both in getSplits and getRecordReader to get to a complete PPD implementation.", "author": "guilload", "createdAt": "2020-08-19T23:34:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjU5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQ0MzQyMA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473443420", "bodyText": "Can't the record reader use the residuals that are present in each task produced by getSplits? I don't think we need to get the filter twice as long as getSplits is using it and creating tasks with residuals.", "author": "rdblue", "createdAt": "2020-08-19T23:45:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjU5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQ3MDk5MA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473470990", "bodyText": "Oh very good point. Tasks do carry the residual filter.", "author": "guilload", "createdAt": "2020-08-20T00:26:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjU5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQ4NjYxOA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473486618", "bodyText": "and looking at the code, the underlying MR input format already does the right thing and passes the residual filter from the task down to the reader. Great! My comment is only relevant for projection pushdown then. My bad.", "author": "guilload", "createdAt": "2020-08-20T00:51:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjU5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjI2OTQzNw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r476269437", "bodyText": "That makes sense. Seems like we cannot do this for predicate and projection pushdown in StorageHandler itself.", "author": "rdsr", "createdAt": "2020-08-25T08:25:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjU5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjgyNQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472532825", "bodyText": "@cmathiesen the latest HiveIcebergInputFormat has changed substantially. Can you please rebase?", "author": "rdsr", "createdAt": "2020-08-18T22:40:17Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergInputFormat.java", "diffHunk": "@@ -51,6 +58,17 @@\n \n     forwardConfigSettings(job);", "originalCommit": "b34300aea4e768240a1b39f35b01c58a0fe7ca22", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mjk5MTkzMA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472991930", "bodyText": "rebase\n\nShouldn't we be following the Golden Rule of Rebasing and not do this on public branches? It has the potential to cause all kinds of inconsistencies on other people's checkouts. Surely we should be doing merge? It all gets squash merged at the end so having a pristine history isn't worth the downsides of inconsistencies IHMO.", "author": "massdosage", "createdAt": "2020-08-19T12:31:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjgyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzIxNTg3MQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473215871", "bodyText": "I think that either rebasing or merging master into a PR is okay.\nAs a reviewer, I don't really consider PR branches to be public because github handles force-pushes well. If I have a PR checked out, I also don't mind resetting to the PR's current state because I like keeping history clean.\nThat said, if you're sharing a PR branch between people that can be disruptive, so I think it is up to the author and collaborators whether to merge or to rebase to stay up to date with master.\nIs that reasonable?", "author": "rdblue", "createdAt": "2020-08-19T17:49:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjgyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI4ODA2MA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473288060", "bodyText": "That sounds reasonable as long as the PR is rebased to master before it is committed. Having a linear history makes things much much easier to track where a change happened.", "author": "omalley", "createdAt": "2020-08-19T20:06:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjgyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI5NzkwNQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473297905", "bodyText": "Agreed. We always merge by squashing the entire PR into a commit, so we do get a linear history in master.", "author": "rdblue", "createdAt": "2020-08-19T20:25:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUzMjgyNQ=="}], "type": "inlineReview"}, {"oid": "45197f058034c61f9fe6da6a96ecb0775fec9422", "url": "https://github.com/apache/iceberg/commit/45197f058034c61f9fe6da6a96ecb0775fec9422", "message": "Add filter factory", "committedDate": "2020-08-19T09:54:38Z", "type": "commit"}, {"oid": "a1f67acf16fd7700027fcd1466bb86a1c5b4da16", "url": "https://github.com/apache/iceberg/commit/a1f67acf16fd7700027fcd1466bb86a1c5b4da16", "message": "Fix type conversions", "committedDate": "2020-08-19T09:54:38Z", "type": "commit"}, {"oid": "6c908763037bb04ef78a266e5636b1f67e0eb1d7", "url": "https://github.com/apache/iceberg/commit/6c908763037bb04ef78a266e5636b1f67e0eb1d7", "message": "Add tests", "committedDate": "2020-08-19T09:54:38Z", "type": "commit"}, {"oid": "e53592d1d51a31e88153a33f2b550b0fd3901c61", "url": "https://github.com/apache/iceberg/commit/e53592d1d51a31e88153a33f2b550b0fd3901c61", "message": "Add more tests and change literalList method", "committedDate": "2020-08-19T09:54:38Z", "type": "commit"}, {"oid": "9f3d5984bb27881e638283e7a71963f60e557625", "url": "https://github.com/apache/iceberg/commit/9f3d5984bb27881e638283e7a71963f60e557625", "message": "Use stream.map() and nit cleanup", "committedDate": "2020-08-19T09:54:38Z", "type": "commit"}, {"oid": "cf7551d0039490a7c1d24b3219fcfcea0cc824a5", "url": "https://github.com/apache/iceberg/commit/cf7551d0039490a7c1d24b3219fcfcea0cc824a5", "message": "Fix merge conflicts", "committedDate": "2020-08-19T10:12:11Z", "type": "commit"}, {"oid": "4b8ca3eb6c56080d899273d9a2cdbbcae8b3dcf5", "url": "https://github.com/apache/iceberg/commit/4b8ca3eb6c56080d899273d9a2cdbbcae8b3dcf5", "message": "PR review changes", "committedDate": "2020-08-19T10:28:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkyOTkwNw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472929907", "bodyText": "@cmathiesen I think something went wrong with your rebase/merge from master, there's a lot of stuff in here now which shouldn't be.", "author": "massdosage", "createdAt": "2020-08-19T10:34:01Z", "path": "api/src/main/java/org/apache/iceberg/ContentFile.java", "diffHunk": "@@ -102,6 +102,18 @@\n    */\n   List<Long> splitOffsets();\n \n+  /**", "originalCommit": "4b8ca3eb6c56080d899273d9a2cdbbcae8b3dcf5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkzMTAzNg==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r472931036", "bodyText": "Yeah, trying to sort it out! :L", "author": "cmathiesen", "createdAt": "2020-08-19T10:35:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjkyOTkwNw=="}], "type": "inlineReview"}, {"oid": "4b8ca3eb6c56080d899273d9a2cdbbcae8b3dcf5", "url": "https://github.com/apache/iceberg/commit/4b8ca3eb6c56080d899273d9a2cdbbcae8b3dcf5", "message": "PR review changes", "committedDate": "2020-08-19T10:28:04Z", "type": "forcePushed"}, {"oid": "d64a1dcbfc02f5cf78c9ed8d251c1422c7174a43", "url": "https://github.com/apache/iceberg/commit/d64a1dcbfc02f5cf78c9ed8d251c1422c7174a43", "message": "Merge branch 'master' into hive-filter-pushdown", "committedDate": "2020-08-19T12:23:42Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzAwNDU0OQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473004549", "bodyText": "@rdblue @rdsr I added tests for the Date and Timestamp types but when these are run I get errors like:\njava.lang.IllegalArgumentException: Cannot create expression literal from java.time.LocalDate: 2015-11-12\n\tat org.apache.iceberg.expressions.Literals.from(Literals.java:83)\n\tat org.apache.iceberg.expressions.UnboundPredicate.<init>(UnboundPredicate.java:39)\n\tat org.apache.iceberg.expressions.Expressions.equal(Expressions.java:159)\n        at org.apache.iceberg.mr.hive.TestHiveIcebergFilterFactory.testDateType(TestHiveIcebergFilterFactory.java:211)\n\nI noticed here in another test that Date's etc.  are actually passed as Strings - is that the correct option to be using in this case?", "author": "cmathiesen", "createdAt": "2020-08-19T12:52:16Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgumentFactory;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestHiveIcebergFilterFactory {\n+\n+  @Test\n+  public void testEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testNotEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startNot().equals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    Not expected = (Not) Expressions.not(Expressions.equal(\"salary\", 3000L));\n+    Not actual = (Not) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    UnboundPredicate childExpressionActual = (UnboundPredicate) actual.child();\n+    UnboundPredicate childExpressionExpected = Expressions.equal(\"salary\", 3000L);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.child().op(), expected.child().op());\n+    assertEquals(childExpressionActual.ref().name(), childExpressionExpected.ref().name());\n+    assertEquals(childExpressionActual.literal(), childExpressionExpected.literal());\n+  }\n+\n+  @Test\n+  public void testLessThanOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().lessThan(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.lessThan(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.literal(), expected.literal());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testLessThanEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().lessThanEquals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.lessThanOrEqual(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testInOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().in(\"salary\", PredicateLeaf.Type.LONG, 3000L, 4000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.in(\"salary\", 3000L, 4000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.literals(), expected.literals());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testBetweenOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder\n+        .startAnd()\n+        .between(\"salary\", PredicateLeaf.Type.LONG, 3000L, 4000L).end().build();\n+\n+    And expected = (And) Expressions.and(Expressions.greaterThanOrEqual(\"salary\", 3000L),\n+        Expressions.lessThanOrEqual(\"salary\", 3000L));\n+    And actual = (And) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.left().op(), expected.left().op());\n+    assertEquals(actual.right().op(), expected.right().op());\n+  }\n+\n+  @Test\n+  public void testIsNullOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().isNull(\"salary\", PredicateLeaf.Type.LONG).end().build();\n+\n+    UnboundPredicate expected = Expressions.isNull(\"salary\");\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testAndOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder\n+        .startAnd()\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 3000L)\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 4000L)\n+        .end().build();\n+\n+    And expected = (And) Expressions\n+        .and(Expressions.equal(\"salary\", 3000L), Expressions.equal(\"salary\", 4000L));\n+    And actual = (And) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.left().op(), expected.left().op());\n+    assertEquals(actual.right().op(), expected.right().op());\n+  }\n+\n+  @Test\n+  public void testOrOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder\n+        .startOr()\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 3000L)\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 4000L)\n+        .end().build();\n+\n+    Or expected = (Or) Expressions\n+        .or(Expressions.equal(\"salary\", 3000L), Expressions.equal(\"salary\", 4000L));\n+    Or actual = (Or) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.left().op(), expected.left().op());\n+    assertEquals(actual.right().op(), expected.right().op());\n+  }\n+\n+  @Test\n+  public void testStringType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"string\", PredicateLeaf.Type.STRING, \"Joe\").end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"string\", \"Joe\");\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testFloatType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"float\", PredicateLeaf.Type.FLOAT, 1200D).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"float\", 1200D);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testBooleanType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"boolean\", PredicateLeaf.Type.BOOLEAN, true).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"boolean\", true);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  /*@Test\n+  public void testDateType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"date\", PredicateLeaf.Type.DATE,\n+            Date.valueOf(\"2015-11-12\")).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"date\", LocalDate.of(2015,11,12));", "originalCommit": "d64a1dcbfc02f5cf78c9ed8d251c1422c7174a43", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzIxNjk3Mw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473216973", "bodyText": "Yes, it is a good idea to use a string instead of passing a LocalDate. The intent was to avoid tying the API to date/time representations from a specific library.", "author": "rdblue", "createdAt": "2020-08-19T17:51:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzAwNDU0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzIxNzgxMw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473217813", "bodyText": "Do we need to validate that there are only two literals here, or is this reliable?", "author": "rdblue", "createdAt": "2020-08-19T17:52:56Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);", "originalCommit": "d64a1dcbfc02f5cf78c9ed8d251c1422c7174a43", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYzOTAxOA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r474639018", "bodyText": "I believe that we can expect there to be 2, as we're using the BETWEEN operator and Hive wouldn't accept more than 2 arguments", "author": "cmathiesen", "createdAt": "2020-08-21T11:29:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzIxNzgxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzIyMzY5OQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r473223699", "bodyText": "Could these cases share the conversion logic between leafToLiteral and leafToLiteralList? That way if we need to fix something it is always applied to both cases.", "author": "rdblue", "createdAt": "2020-08-19T18:03:04Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+  private static final int MICROS_PER_SECOND = 1000000;\n+  private static final int NANOS_PER_MICROSEC = 1000;\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return ((Timestamp) leaf.getLiteral()).toLocalDateTime().toLocalDate().toEpochDay();\n+      case DECIMAL:\n+        return BigDecimal.valueOf(((HiveDecimalWritable) leaf.getLiteral()).doubleValue());\n+      case TIMESTAMP:\n+        Timestamp timestamp = (Timestamp) leaf.getLiteral();\n+        return timestamp.toInstant().getEpochSecond() * MICROS_PER_SECOND +\n+                timestamp.getNanos() / NANOS_PER_MICROSEC;\n+      default:\n+        throw new IllegalStateException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        return leaf.getLiteralList().stream().map(value -> ((Date) value).toLocalDate().toEpochDay())\n+                .collect(Collectors.toList());\n+      case DECIMAL:\n+        return leaf.getLiteralList().stream()\n+                .map(value -> BigDecimal.valueOf(((HiveDecimalWritable) value).doubleValue()))\n+                .collect(Collectors.toList());", "originalCommit": "d64a1dcbfc02f5cf78c9ed8d251c1422c7174a43", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "81fb5cbac1071261797d864ee2b444e65c434a11", "url": "https://github.com/apache/iceberg/commit/81fb5cbac1071261797d864ee2b444e65c434a11", "message": "Conversion methods and fix date/timestamp tests", "committedDate": "2020-08-21T11:22:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDYzOTY3Mw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r474639673", "bodyText": "I found a small quirk with the Hive Date type where if you call getLiteral you get a Timestamp back and if you call getLiteralList you get Date objects, which is why there are 2 separate methods for DATE", "author": "cmathiesen", "createdAt": "2020-08-21T11:30:39Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return timestampToDateString((Timestamp) leaf.getLiteral());\n+      case DECIMAL:\n+        return hiveDecimalToBigDecimal((HiveDecimalWritable) leaf.getLiteral());\n+      case TIMESTAMP:\n+        return timestampToTimestampString((Timestamp) leaf.getLiteral());\n+\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        return leaf.getLiteralList().stream().map(value -> dateToString((Date) value))", "originalCommit": "81fb5cbac1071261797d864ee2b444e65c434a11", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgwNDU0Mg==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r474804542", "bodyText": "This shouldn't convert to a string. Instead, it should convert the Timestamp value directly to microseconds from the unix epoch. String conversion in expressions is only for convenience in tests and for people using the API directly with generics. If an engine passes a predicate, we don't want to needlessly convert to string and back because it is much, much more likely to corrupt the value.", "author": "rdblue", "createdAt": "2020-08-21T16:32:47Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -140,18 +137,34 @@ private static Object leafToLiteral(PredicateLeaf leaf) {\n       case STRING:\n         return leaf.getLiteralList();\n       case DATE:\n-        return leaf.getLiteralList().stream().map(value -> ((Date) value).toLocalDate().toEpochDay())\n+        return leaf.getLiteralList().stream().map(value -> dateToString((Date) value))\n                 .collect(Collectors.toList());\n       case DECIMAL:\n         return leaf.getLiteralList().stream()\n-                .map(value -> BigDecimal.valueOf(((HiveDecimalWritable) value).doubleValue()))\n+                .map(value -> hiveDecimalToBigDecimal((HiveDecimalWritable) value))\n                 .collect(Collectors.toList());\n       case TIMESTAMP:\n         return leaf.getLiteralList().stream()\n-                .map(value -> ((Timestamp) value).toInstant().getEpochSecond() * MICROS_PER_SECOND +\n-                        ((Timestamp) value).getNanos() / NANOS_PER_MICROSEC).collect(Collectors.toList());\n+                .map(value -> timestampToTimestampString((Timestamp) value))", "originalCommit": "81fb5cbac1071261797d864ee2b444e65c434a11", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUwODIwNg==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r475508206", "bodyText": "Ah sure, thank you for explaining that, I think I misunderstood what to do from the last comment - should hopefully be fixed now :)", "author": "cmathiesen", "createdAt": "2020-08-24T10:34:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgwNDU0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgwNDgxOQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r474804819", "bodyText": "I don't think we want to convert to String here, either. Can you use the same logic from ORC?", "author": "rdblue", "createdAt": "2020-08-21T16:33:24Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -140,18 +137,34 @@ private static Object leafToLiteral(PredicateLeaf leaf) {\n       case STRING:\n         return leaf.getLiteralList();\n       case DATE:\n-        return leaf.getLiteralList().stream().map(value -> ((Date) value).toLocalDate().toEpochDay())\n+        return leaf.getLiteralList().stream().map(value -> dateToString((Date) value))\n                 .collect(Collectors.toList());\n       case DECIMAL:\n         return leaf.getLiteralList().stream()\n-                .map(value -> BigDecimal.valueOf(((HiveDecimalWritable) value).doubleValue()))\n+                .map(value -> hiveDecimalToBigDecimal((HiveDecimalWritable) value))\n                 .collect(Collectors.toList());\n       case TIMESTAMP:\n         return leaf.getLiteralList().stream()\n-                .map(value -> ((Timestamp) value).toInstant().getEpochSecond() * MICROS_PER_SECOND +\n-                        ((Timestamp) value).getNanos() / NANOS_PER_MICROSEC).collect(Collectors.toList());\n+                .map(value -> timestampToTimestampString((Timestamp) value))\n+                .collect(Collectors.toList());\n       default:\n-        throw new IllegalStateException(\"Unknown type: \" + leaf.getType());\n+        throw new UnsupportedOperationException(\"Unknown type: \" + leaf.getType());\n     }\n   }\n+\n+  private static String timestampToDateString(Timestamp timestamp) {\n+    return timestamp.toLocalDateTime().toLocalDate().toString();\n+  }\n+\n+  private static String dateToString(Date date) {\n+    return date.toLocalDate().toString();\n+  }\n+\n+  private static BigDecimal hiveDecimalToBigDecimal(HiveDecimalWritable hiveDecimalWritable) {\n+    return new BigDecimal(hiveDecimalWritable.toString()).setScale(hiveDecimalWritable.scale());", "originalCommit": "81fb5cbac1071261797d864ee2b444e65c434a11", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTE5NjIyNg==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r475196226", "bodyText": "HiveIcebergFilterFactory.generateFilterExpression might throw UnsupportedOperationException.\nMaybe it would be good to catch the exception and continue without filters in case if there is an error.\nHive runs the filters later anyway, so it will not cause issue.", "author": "pvary", "createdAt": "2020-08-23T09:30:44Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergInputFormat.java", "diffHunk": "@@ -36,6 +43,16 @@\n \n   @Override\n   public InputSplit[] getSplits(JobConf job, int numSplits) throws IOException {\n+    //Convert Hive filter to Iceberg filter\n+    String hiveFilter = job.get(TableScanDesc.FILTER_EXPR_CONF_STR);\n+    if (hiveFilter != null) {\n+      ExprNodeGenericFuncDesc exprNodeDesc = SerializationUtilities\n+              .deserializeObject(hiveFilter, ExprNodeGenericFuncDesc.class);\n+      SearchArgument sarg = ConvertAstToSearchArg.create(job, exprNodeDesc);\n+      Expression filter = HiveIcebergFilterFactory.generateFilterExpression(sarg);", "originalCommit": "81fb5cbac1071261797d864ee2b444e65c434a11", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "4396672bf858e5e5edbf0cda24930fda3d96501e", "url": "https://github.com/apache/iceberg/commit/4396672bf858e5e5edbf0cda24930fda3d96501e", "message": "Correct timestamp and decimal conversion", "committedDate": "2020-08-24T10:33:33Z", "type": "commit"}, {"oid": "848a3aba235f6e91017f7d4590efeadc7626ec24", "url": "https://github.com/apache/iceberg/commit/848a3aba235f6e91017f7d4590efeadc7626ec24", "message": "Change log message to warn", "committedDate": "2020-08-24T18:40:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyNjk2Ng==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r475826966", "bodyText": "This seems odd to me. Why not call TimeUnit.SECONDS.toMicros(timestamp.toInstant().getEpochSecond())? Using the toMicros function to get the conversion factor, but not actually using it for conversion is strange.", "author": "rdblue", "createdAt": "2020-08-24T18:54:49Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return timestampToDateString((Timestamp) leaf.getLiteral());\n+      case DECIMAL:\n+        return hiveDecimalToBigDecimal((HiveDecimalWritable) leaf.getLiteral());\n+      case TIMESTAMP:\n+        return timestampToUnixEpoch((Timestamp) leaf.getLiteral());\n+\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        return leaf.getLiteralList().stream().map(value -> dateToString((Date) value))\n+                .collect(Collectors.toList());\n+      case DECIMAL:\n+        return leaf.getLiteralList().stream()\n+                .map(value -> hiveDecimalToBigDecimal((HiveDecimalWritable) value))\n+                .collect(Collectors.toList());\n+      case TIMESTAMP:\n+        return leaf.getLiteralList().stream()\n+                .map(value -> timestampToUnixEpoch((Timestamp) value))\n+                .collect(Collectors.toList());\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static String timestampToDateString(Timestamp timestamp) {\n+    return timestamp.toLocalDateTime().toLocalDate().toString();\n+  }\n+\n+  private static String dateToString(Date date) {\n+    return date.toLocalDate().toString();\n+  }\n+\n+  private static BigDecimal hiveDecimalToBigDecimal(HiveDecimalWritable hiveDecimalWritable) {\n+    return hiveDecimalWritable.getHiveDecimal().bigDecimalValue().setScale(hiveDecimalWritable.scale());\n+  }\n+\n+  private static long timestampToUnixEpoch(Timestamp timestamp) {\n+    return timestamp.toInstant().getEpochSecond() * TimeUnit.SECONDS.toMicros(1) +\n+            timestamp.getNanos() / TimeUnit.MICROSECONDS.toNanos(1);", "originalCommit": "848a3aba235f6e91017f7d4590efeadc7626ec24", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjI2ODc2Ng==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r476268766", "bodyText": "+1, similarly for timestamp.getNanos() / TimeUnit.MICROSECONDS.toNanos(1) -TimeUnit.NANOSECONDS.toMicros(timestamp.getNanos())", "author": "rdsr", "createdAt": "2020-08-25T08:24:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyNjk2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjI4MTM0Mw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r476281343", "bodyText": "Ah yep, probably should have spotted that one \ud83d\ude05", "author": "cmathiesen", "createdAt": "2020-08-25T08:44:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyNjk2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyNzI2OA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r475827268", "bodyText": "Dates need to be converted directly to a value and not a string also. You can use DateTimeUtil if you need.", "author": "rdblue", "createdAt": "2020-08-24T18:55:18Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {}\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());\n+  }\n+\n+  /**\n+   * Recursive method to traverse down the ExpressionTree to evaluate each expression and its leaf nodes.\n+   * @param tree Current ExpressionTree where the 'top' node is being evaluated.\n+   * @param leaves List of all leaf nodes within the tree.\n+   * @return Expression that is translated from the Hive SearchArgument.\n+   */\n+  private static Expression translate(ExpressionTree tree, List<PredicateLeaf> leaves) {\n+    List<ExpressionTree> childNodes = tree.getChildren();\n+    switch (tree.getOperator()) {\n+      case OR:\n+        Expression orResult = Expressions.alwaysFalse();\n+        for (ExpressionTree child : childNodes) {\n+          orResult = or(orResult, translate(child, leaves));\n+        }\n+        return orResult;\n+      case AND:\n+        Expression result = Expressions.alwaysTrue();\n+        for (ExpressionTree child : childNodes) {\n+          result = and(result, translate(child, leaves));\n+        }\n+        return result;\n+      case NOT:\n+        return not(translate(childNodes.get(0), leaves));\n+      case LEAF:\n+        return translateLeaf(leaves.get(tree.getLeaf()));\n+      case CONSTANT:\n+        throw new UnsupportedOperationException(\"CONSTANT operator is not supported\");\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + tree.getOperator());\n+    }\n+  }\n+\n+  /**\n+   * Translate leaf nodes from Hive operator to Iceberg operator.\n+   * @param leaf Leaf node\n+   * @return Expression fully translated from Hive PredicateLeaf\n+   */\n+  private static Expression translateLeaf(PredicateLeaf leaf) {\n+    String column = leaf.getColumnName();\n+    switch (leaf.getOperator()) {\n+      case EQUALS:\n+        return equal(column, leafToLiteral(leaf));\n+      case LESS_THAN:\n+        return lessThan(column, leafToLiteral(leaf));\n+      case LESS_THAN_EQUALS:\n+        return lessThanOrEqual(column, leafToLiteral(leaf));\n+      case IN:\n+        return in(column, leafToLiteralList(leaf));\n+      case BETWEEN:\n+        List<Object> icebergLiterals = leafToLiteralList(leaf);\n+        return and(greaterThanOrEqual(column, icebergLiterals.get(0)),\n+                lessThanOrEqual(column, icebergLiterals.get(1)));\n+      case IS_NULL:\n+        return isNull(column);\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown operator: \" + leaf.getOperator());\n+    }\n+  }\n+\n+  private static Object leafToLiteral(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case STRING:\n+      case FLOAT:\n+        return leaf.getLiteral();\n+      case DATE:\n+        //Hive converts a Date type to a Timestamp internally when retrieving literal\n+        return timestampToDateString((Timestamp) leaf.getLiteral());\n+      case DECIMAL:\n+        return hiveDecimalToBigDecimal((HiveDecimalWritable) leaf.getLiteral());\n+      case TIMESTAMP:\n+        return timestampToUnixEpoch((Timestamp) leaf.getLiteral());\n+\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static List<Object> leafToLiteralList(PredicateLeaf leaf) {\n+    switch (leaf.getType()) {\n+      case LONG:\n+      case BOOLEAN:\n+      case FLOAT:\n+      case STRING:\n+        return leaf.getLiteralList();\n+      case DATE:\n+        return leaf.getLiteralList().stream().map(value -> dateToString((Date) value))\n+                .collect(Collectors.toList());\n+      case DECIMAL:\n+        return leaf.getLiteralList().stream()\n+                .map(value -> hiveDecimalToBigDecimal((HiveDecimalWritable) value))\n+                .collect(Collectors.toList());\n+      case TIMESTAMP:\n+        return leaf.getLiteralList().stream()\n+                .map(value -> timestampToUnixEpoch((Timestamp) value))\n+                .collect(Collectors.toList());\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown type: \" + leaf.getType());\n+    }\n+  }\n+\n+  private static String timestampToDateString(Timestamp timestamp) {\n+    return timestamp.toLocalDateTime().toLocalDate().toString();", "originalCommit": "848a3aba235f6e91017f7d4590efeadc7626ec24", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyODE2NA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r475828164", "bodyText": "I think this expression should use an integer value instead of a String.", "author": "rdblue", "createdAt": "2020-08-24T18:56:56Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,243 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgumentFactory;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestHiveIcebergFilterFactory {\n+\n+  @Test\n+  public void testEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testNotEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startNot().equals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    Not expected = (Not) Expressions.not(Expressions.equal(\"salary\", 3000L));\n+    Not actual = (Not) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    UnboundPredicate childExpressionActual = (UnboundPredicate) actual.child();\n+    UnboundPredicate childExpressionExpected = Expressions.equal(\"salary\", 3000L);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.child().op(), expected.child().op());\n+    assertEquals(childExpressionActual.ref().name(), childExpressionExpected.ref().name());\n+    assertEquals(childExpressionActual.literal(), childExpressionExpected.literal());\n+  }\n+\n+  @Test\n+  public void testLessThanOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().lessThan(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.lessThan(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.literal(), expected.literal());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testLessThanEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().lessThanEquals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.lessThanOrEqual(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testInOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().in(\"salary\", PredicateLeaf.Type.LONG, 3000L, 4000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.in(\"salary\", 3000L, 4000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.literals(), expected.literals());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testBetweenOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder\n+        .startAnd()\n+        .between(\"salary\", PredicateLeaf.Type.LONG, 3000L, 4000L).end().build();\n+\n+    And expected = (And) Expressions.and(Expressions.greaterThanOrEqual(\"salary\", 3000L),\n+        Expressions.lessThanOrEqual(\"salary\", 3000L));\n+    And actual = (And) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.left().op(), expected.left().op());\n+    assertEquals(actual.right().op(), expected.right().op());\n+  }\n+\n+  @Test\n+  public void testIsNullOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().isNull(\"salary\", PredicateLeaf.Type.LONG).end().build();\n+\n+    UnboundPredicate expected = Expressions.isNull(\"salary\");\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testAndOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder\n+        .startAnd()\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 3000L)\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 4000L)\n+        .end().build();\n+\n+    And expected = (And) Expressions\n+        .and(Expressions.equal(\"salary\", 3000L), Expressions.equal(\"salary\", 4000L));\n+    And actual = (And) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.left().op(), expected.left().op());\n+    assertEquals(actual.right().op(), expected.right().op());\n+  }\n+\n+  @Test\n+  public void testOrOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder\n+        .startOr()\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 3000L)\n+        .equals(\"salary\", PredicateLeaf.Type.LONG, 4000L)\n+        .end().build();\n+\n+    Or expected = (Or) Expressions\n+        .or(Expressions.equal(\"salary\", 3000L), Expressions.equal(\"salary\", 4000L));\n+    Or actual = (Or) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.left().op(), expected.left().op());\n+    assertEquals(actual.right().op(), expected.right().op());\n+  }\n+\n+  @Test\n+  public void testStringType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"string\", PredicateLeaf.Type.STRING, \"Joe\").end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"string\", \"Joe\");\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testFloatType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"float\", PredicateLeaf.Type.FLOAT, 1200D).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"float\", 1200D);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testBooleanType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"boolean\", PredicateLeaf.Type.BOOLEAN, true).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"boolean\", true);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testDateType() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"date\", PredicateLeaf.Type.DATE,\n+            Date.valueOf(\"2015-11-12\")).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"date\", \"2015-11-12\");", "originalCommit": "848a3aba235f6e91017f7d4590efeadc7626ec24", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjI3NTM0Nw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r476275347", "bodyText": "Do we need a test using HiveRunner ? Since Hive stores the table's schema in lowercase I think we might have to support a case insensitive match on the iceberg side.\ncc @pvary, @guilload", "author": "rdsr", "createdAt": "2020-08-25T08:34:43Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestHiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,243 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgumentFactory;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestHiveIcebergFilterFactory {\n+\n+  @Test\n+  public void testEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().equals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.equal(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testNotEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startNot().equals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    Not expected = (Not) Expressions.not(Expressions.equal(\"salary\", 3000L));\n+    Not actual = (Not) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    UnboundPredicate childExpressionActual = (UnboundPredicate) actual.child();\n+    UnboundPredicate childExpressionExpected = Expressions.equal(\"salary\", 3000L);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.child().op(), expected.child().op());\n+    assertEquals(childExpressionActual.ref().name(), childExpressionExpected.ref().name());\n+    assertEquals(childExpressionActual.literal(), childExpressionExpected.literal());\n+  }\n+\n+  @Test\n+  public void testLessThanOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().lessThan(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.lessThan(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.literal(), expected.literal());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testLessThanEqualsOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().lessThanEquals(\"salary\", PredicateLeaf.Type.LONG, 3000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.lessThanOrEqual(\"salary\", 3000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testInOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().in(\"salary\", PredicateLeaf.Type.LONG, 3000L, 4000L).end().build();\n+\n+    UnboundPredicate expected = Expressions.in(\"salary\", 3000L, 4000L);\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.literals(), expected.literals());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testBetweenOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder\n+        .startAnd()\n+        .between(\"salary\", PredicateLeaf.Type.LONG, 3000L, 4000L).end().build();\n+\n+    And expected = (And) Expressions.and(Expressions.greaterThanOrEqual(\"salary\", 3000L),\n+        Expressions.lessThanOrEqual(\"salary\", 3000L));\n+    And actual = (And) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.left().op(), expected.left().op());\n+    assertEquals(actual.right().op(), expected.right().op());\n+  }\n+\n+  @Test\n+  public void testIsNullOperand() {\n+    SearchArgument.Builder builder = SearchArgumentFactory.newBuilder();\n+    SearchArgument arg = builder.startAnd().isNull(\"salary\", PredicateLeaf.Type.LONG).end().build();\n+\n+    UnboundPredicate expected = Expressions.isNull(\"salary\");\n+    UnboundPredicate actual = (UnboundPredicate) HiveIcebergFilterFactory.generateFilterExpression(arg);\n+\n+    assertEquals(actual.op(), expected.op());\n+    assertEquals(actual.ref().name(), expected.ref().name());\n+  }\n+\n+  @Test\n+  public void testAndOperand() {", "originalCommit": "848a3aba235f6e91017f7d4590efeadc7626ec24", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ5NDUyNg==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r476494526", "bodyText": "We definitely need to test for the lowercase column names, since Hive uses that. It might worth to do it for the InputFormat checks as well. On the other hand I am not sure if HiveRunner helps here or not.", "author": "pvary", "createdAt": "2020-08-25T14:30:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjI3NTM0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODQzMzQ2Mw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r478433463", "bodyText": "I've been working on a HiveRunner test to see what happens in this case:\nI've got an Iceberg table with a schema like:\nprivate static final Schema STOCK_LIST_SCHEMA = new Schema(\n          required(1, \"ITEM_ID\", Types.LongType.get()),\n          required(2, \"ITEM_COUNT\", Types.LongType.get())\n  );\n\nIf I run a regular query either like SELECT ITEM_ID from default.stock_table or SELECT item_id from default.stock_table then this error occurs:\nCaused by: java.lang.RuntimeException: cannot find field item_id from [org.apache.iceberg.mr.hive.serde.objectinspector.IcebergRecordObjectInspector$IcebergRecordStructField@c0fc462a, org.apache.iceberg.mr.hive.serde.objectinspector.IcebergRecordObjectInspector$IcebergRecordStructField@275a564e]\nat org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorUtils.getStandardStructFieldRef(ObjectInspectorUtils.java:523)\nat org.apache.iceberg.mr.hive.serde.objectinspector.IcebergRecordObjectInspector.getStructFieldRef(IcebergRecordObjectInspector.java:68)\nat org.apache.hadoop.hive.ql.exec.ExprNodeColumnEvaluator.initialize(ExprNodeColumnEvaluator.java:56)\nat org.apache.hadoop.hive.ql.exec.Operator.initEvaluators(Operator.java:1033)\nat org.apache.hadoop.hive.ql.exec.Operator.initEvaluatorsAndReturnStruct(Operator.java:1059)\nat org.apache.hadoop.hive.ql.exec.SelectOperator.initializeOp(SelectOperator.java:75)\nat org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:366)\nat org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:556)\nat org.apache.hadoop.hive.ql.exec.Operator.initializeChildren(Operator.java:508)\nat org.apache.hadoop.hive.ql.exec.Operator.initialize(Operator.java:376)\nat org.apache.hadoop.hive.ql.exec.FetchTask.initialize(FetchTask.java:88)\n... 29 more\n\nwhich looks like the case sensitivity issues @rdsr mentioned.\nI haven't pushed this test yet but I can do so if others want to reproduce the issue (I've just added a test to HiveIcebergStorageHandlerBaseTest).\nWhere would be the best place to put in a fix for this? This also doesn't rely on predicate pushdown so it could be done in another PR if needed", "author": "cmathiesen", "createdAt": "2020-08-27T13:49:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjI3NTM0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MzEzNQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r478663135", "bodyText": "That doesn't look like a pushdown problem, so I'd open a separate PR to fix it and add the tests.", "author": "rdblue", "createdAt": "2020-08-27T20:01:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjI3NTM0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODk3NDY3Nw==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r478974677", "bodyText": "Sure, sounds good! I think I've addressed all the other comments on this PR so do you have time for another review? @rdblue @rdsr", "author": "cmathiesen", "createdAt": "2020-08-28T08:59:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjI3NTM0Nw=="}], "type": "inlineReview"}, {"oid": "db95c5cd0f3adeb876590bc18d380923f5a27f74", "url": "https://github.com/apache/iceberg/commit/db95c5cd0f3adeb876590bc18d380923f5a27f74", "message": "Change date conversions", "committedDate": "2020-08-25T08:43:14Z", "type": "commit"}, {"oid": "b6752247deca9161f84132f64939518b218727c0", "url": "https://github.com/apache/iceberg/commit/b6752247deca9161f84132f64939518b218727c0", "message": "timeunit nanos to micros", "committedDate": "2020-08-25T08:46:03Z", "type": "commit"}, {"oid": "e97a461fd77344073e70881a7a4f106267d80f70", "url": "https://github.com/apache/iceberg/commit/e97a461fd77344073e70881a7a4f106267d80f70", "message": "fix faulty timestamp test", "committedDate": "2020-08-26T15:04:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI3ODE5NA==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r478278194", "bodyText": "Maybe logging would be nice here minimally on DEBUG level, but maybe on INFO level, like:\nLOG.info(\"Translated sarg=[{}] to expression=[{}]\", sarg, expression);\n\nNot sure about the toString implementations, but the general idea would be to see what went in and what came out.\nAlso we can add this later, just noting here so we do not forget :D", "author": "pvary", "createdAt": "2020-08-27T09:20:55Z", "path": "mr/src/main/java/org/apache/iceberg/mr/hive/HiveIcebergFilterFactory.java", "diffHunk": "@@ -0,0 +1,168 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.hive.ql.io.sarg.ExpressionTree;\n+import org.apache.hadoop.hive.ql.io.sarg.PredicateLeaf;\n+import org.apache.hadoop.hive.ql.io.sarg.SearchArgument;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.util.DateTimeUtil;\n+\n+import static org.apache.iceberg.expressions.Expressions.and;\n+import static org.apache.iceberg.expressions.Expressions.equal;\n+import static org.apache.iceberg.expressions.Expressions.greaterThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.in;\n+import static org.apache.iceberg.expressions.Expressions.isNull;\n+import static org.apache.iceberg.expressions.Expressions.lessThan;\n+import static org.apache.iceberg.expressions.Expressions.lessThanOrEqual;\n+import static org.apache.iceberg.expressions.Expressions.not;\n+import static org.apache.iceberg.expressions.Expressions.or;\n+\n+\n+public class HiveIcebergFilterFactory {\n+\n+  private HiveIcebergFilterFactory() {\n+  }\n+\n+  public static Expression generateFilterExpression(SearchArgument sarg) {\n+    return translate(sarg.getExpression(), sarg.getLeaves());", "originalCommit": "e97a461fd77344073e70881a7a4f106267d80f70", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MjM3NQ==", "url": "https://github.com/apache/iceberg/pull/1326#discussion_r478662375", "bodyText": "Pushed filters are logged in the scan, so the translated expression is already logged. I assume that Hive also logs the filters that it is pushing, so I don't think this is necessary.", "author": "rdblue", "createdAt": "2020-08-27T19:59:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI3ODE5NA=="}], "type": "inlineReview"}, {"oid": "cfadba5bf8e691e48d3ea492faa9e7d7822e3891", "url": "https://github.com/apache/iceberg/commit/cfadba5bf8e691e48d3ea492faa9e7d7822e3891", "message": "Fix date and timestamp conversion.", "committedDate": "2020-08-30T00:59:55Z", "type": "commit"}, {"oid": "614781ee46e4af2dd4e4bb69f36d0528081f8dc5", "url": "https://github.com/apache/iceberg/commit/614781ee46e4af2dd4e4bb69f36d0528081f8dc5", "message": "Merge pull request #16 from rdblue/pr-1326-hive-ppd\n\nFix date and timestamp conversion", "committedDate": "2020-08-31T14:49:18Z", "type": "commit"}, {"oid": "ef5b050dfb902950585b26cd01a0e2e8162dd9af", "url": "https://github.com/apache/iceberg/commit/ef5b050dfb902950585b26cd01a0e2e8162dd9af", "message": "Remove unused import", "committedDate": "2020-08-31T15:13:50Z", "type": "commit"}]}