{"pr_number": 1514, "pr_title": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT", "pr_createdAt": "2020-09-26T01:00:08Z", "pr_url": "https://github.com/apache/iceberg/pull/1514", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI1MTAwNg==", "url": "https://github.com/apache/iceberg/pull/1514#discussion_r496251006", "bodyText": "There is no equals and hashCode implementation for CharSequence, so it can't be used reliably as a map key to deduplicate.\nAlso, the only thing you need from the file instance is the key metadata, so you could keep a map of string path to key metadata, like this:\n    Map<String, ByteBuffer> keyMetadata = Maps.newHashMap();\n    task.files().stream()\n        .flatMap(fileScanTask -> Stream.concat(Stream.of(fileScanTask.file()), fileScanTask.deletes().stream()))\n        .forEach(file -> keyMetadata.put(file.path().toString(), file.keyMetadata()));\n    Stream<EncryptedInputFile> encrypted = keyMetadata.entrySet().stream()\n        .map(entry -> EncryptedFiles.encryptedInput(io.newInputFile(entry.getKey()), entry.getValue()));", "author": "rdblue", "createdAt": "2020-09-28T21:44:39Z", "path": "spark/src/main/java/org/apache/iceberg/spark/source/BaseDataReader.java", "diffHunk": "@@ -58,9 +60,12 @@\n \n   BaseDataReader(CombinedScanTask task, FileIO io, EncryptionManager encryptionManager) {\n     this.tasks = task.files().iterator();\n-    Stream<EncryptedInputFile> encrypted = task.files().stream()\n-        .flatMap(fileScanTask -> Stream.concat(Stream.of(fileScanTask.file()), fileScanTask.deletes().stream()))\n-        .map(file -> EncryptedFiles.encryptedInput(io.newInputFile(file.path().toString()), file.keyMetadata()));\n+    Map<CharSequence, DeleteFile> uniqueDeleteFileMap = Maps.newHashMap();", "originalCommit": "e2fa9ac689d8776526a0d754a09878f5a0b668bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI1OTg2NA==", "url": "https://github.com/apache/iceberg/pull/1514#discussion_r496259864", "bodyText": "I actually started with deduping both DataFile and DeleteFile, but thought of keeping it just for DeleteFile, to not touch other workflows. will follow your recommendation. Thanks!", "author": "mehtaashish23", "createdAt": "2020-09-28T21:58:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjI1MTAwNg=="}], "type": "inlineReview"}, {"oid": "d89f92d11d1268bc180916d10d762221966c793d", "url": "https://github.com/apache/iceberg/commit/d89f92d11d1268bc180916d10d762221966c793d", "message": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT", "committedDate": "2020-10-05T17:19:18Z", "type": "commit"}, {"oid": "e60d3ab2f7bbebd7f6632b5bf7f24c42170b3e6a", "url": "https://github.com/apache/iceberg/commit/e60d3ab2f7bbebd7f6632b5bf7f24c42170b3e6a", "message": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT\n\nReview Feedback", "committedDate": "2020-10-05T17:25:37Z", "type": "commit"}, {"oid": "f8195893dc53ff2067b8da55fbc533a23dcb3224", "url": "https://github.com/apache/iceberg/commit/f8195893dc53ff2067b8da55fbc533a23dcb3224", "message": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT\n\nResolving conflict", "committedDate": "2020-10-05T18:23:23Z", "type": "commit"}, {"oid": "f8195893dc53ff2067b8da55fbc533a23dcb3224", "url": "https://github.com/apache/iceberg/commit/f8195893dc53ff2067b8da55fbc533a23dcb3224", "message": "Issue-1511: Read errors out with multiple DeleteFile entries after UPSERT\n\nResolving conflict", "committedDate": "2020-10-05T18:23:23Z", "type": "forcePushed"}]}