{"pr_number": 1946, "pr_title": "Avro metrics support: create MetricsAwareDatumWriter and some refactors for Avro", "pr_createdAt": "2020-12-16T22:34:50Z", "pr_url": "https://github.com/apache/iceberg/pull/1946", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NTE3Mg==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r545555172", "bodyText": "Does Schema need to be fully qualified?", "author": "rdblue", "createdAt": "2020-12-18T03:47:21Z", "path": "core/src/main/java/org/apache/iceberg/avro/AvroFileAppender.java", "diffHunk": "@@ -27,22 +27,31 @@\n import org.apache.avro.file.DataFileWriter;\n import org.apache.avro.io.DatumWriter;\n import org.apache.iceberg.Metrics;\n+import org.apache.iceberg.MetricsConfig;\n import org.apache.iceberg.exceptions.RuntimeIOException;\n import org.apache.iceberg.io.FileAppender;\n import org.apache.iceberg.io.OutputFile;\n import org.apache.iceberg.io.PositionOutputStream;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n \n class AvroFileAppender<D> implements FileAppender<D> {\n   private PositionOutputStream stream = null;\n   private DataFileWriter<D> writer = null;\n+  private MetricsAwareDatumWriter<?> metricsAwareDatumWriter = null;\n+  private org.apache.iceberg.Schema icebergSchema;\n+  private MetricsConfig metricsConfig;\n   private long numRecords = 0L;\n+  private boolean isClosed = false;\n \n-  AvroFileAppender(Schema schema, OutputFile file,\n-                   Function<Schema, DatumWriter<?>> createWriterFunc,\n+  AvroFileAppender(org.apache.iceberg.Schema icebergSchema, Schema schema, OutputFile file,", "originalCommit": "394a34c4aeaa090a701b241592d168fb4e869958", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjA4NTcyMg==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r546085722", "bodyText": "I think here I'm adding iceberg schema to the constructor, in addition to an avro Schema, so we need to fully qualify one of them. The reason to add the iceberg schema is to avoid converting Avro schema back to Iceberg one when using it to evaluating metrics modes, but I guess we can directly input Iceberg schema in constructor and let constructor to do the conversion to Avro schema. Do you have a recommendation?", "author": "yyanyy", "createdAt": "2020-12-18T20:54:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NTE3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjE0MTUzMQ==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r546141531", "bodyText": "I just didn't see that Avro's Schema is already imported. This should be fine.", "author": "rdblue", "createdAt": "2020-12-18T23:15:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NTE3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NTc4MQ==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r545555781", "bodyText": "Why change this to Object rather than ByteBuffer? Seems like conversion to ByteBuffer would be cleaner if this was done in each writer because the writer already has its type because it is going to call the right method on the encoder.", "author": "rdblue", "createdAt": "2020-12-18T03:49:33Z", "path": "api/src/main/java/org/apache/iceberg/FieldMetrics.java", "diffHunk": "@@ -30,15 +28,15 @@\n   private final long valueCount;\n   private final long nullValueCount;\n   private final long nanValueCount;\n-  private final ByteBuffer lowerBound;\n-  private final ByteBuffer upperBound;\n+  private final Object lowerBound;\n+  private final Object upperBound;", "originalCommit": "394a34c4aeaa090a701b241592d168fb4e869958", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjA4NTc4NA==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r546085784", "bodyText": "I think if we convert this to ByteBuffer now we may still need to check type when doing truncation (based on metrics mode), and I think string with non-unicode characters will not vend the same result if truncated by BinaryUtil.truncateBinary, so we will either convert the byte buffer back to char sequence and use UnicodeUtil.truncateString or create a new BinaryUtil.truncateString. Whereas if we do conversion later when evaluating metrics, I think the code needed for the conversion itself isn't that bad since we know the type of the field, and that's the reason for me to do this change.\nBut one thing that may worth noting is that for the current approach, in order ensure the Conversions.toByteBuffer could work, for certain writers I have to make sure the min/max from the value writers return the type that Conversions.toByteBuffer knows how to translate, if the data type in write is not of that type (that is, usage of this method). I think we still need to maintain a similar function for translation in each value writer if we return bytebuffer for bounds in field metrics, but it will directly translate input data type to byte buffer instead of doing two hops, and that might be easier to understand.", "author": "yyanyy", "createdAt": "2020-12-18T20:54:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NTc4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjE0MjMxMw==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r546142313", "bodyText": "I guess I was thinking that truncation would happen when FieldMetrics is constructed, in the leaf writers. If that's not the case, then I think it makes sense to do the conversion later.\nIf the conversion happens later, then I think this class should be parameterized. I never like to have classes that track just Object. We should at least guarantee that both lower and upper bounds are the same type, for example.", "author": "rdblue", "createdAt": "2020-12-18T23:18:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NTc4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjE0NTUzNw==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r546145537", "bodyText": "I was mostly following the pattern of ORC and Parquet to evaluate metrics mode when collecting metrics (which has to be since the file formats collects stats themselves), but I think there's nothing prevent us from ingesting metrics mode during value writers creation, it will just make the visitor pattern a little bit more complicated. I'll give it a try, and thanks for bringing up this idea!\nI guess for now I'll revert the change to FieldMetrics in this PR and include it in the next one that updates value writers if we need to change it. Hopefully that doesn't add too much to the next PR!", "author": "yyanyy", "createdAt": "2020-12-18T23:31:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NTc4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NTkwMA==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r545555900", "bodyText": "Other method names are plural. Could we use unsignedByteArrays()?", "author": "rdblue", "createdAt": "2020-12-18T03:50:00Z", "path": "api/src/main/java/org/apache/iceberg/types/Comparators.java", "diffHunk": "@@ -157,6 +157,10 @@ public int compare(List<T> o1, List<T> o2) {\n     return UnsignedByteBufComparator.INSTANCE;\n   }\n \n+  public static Comparator<byte[]> unsignedByteArray() {", "originalCommit": "394a34c4aeaa090a701b241592d168fb4e869958", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NjUxOQ==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r545556519", "bodyText": "This is going to break existing uses of createWriterFunc in projects that build on Iceberg. I think this should keep the old parameter and just check whether the implementation is MetricsAwareDatumWriter in the appender to return metrics.", "author": "rdblue", "createdAt": "2020-12-18T03:52:21Z", "path": "core/src/main/java/org/apache/iceberg/avro/Avro.java", "diffHunk": "@@ -123,7 +127,7 @@ public WriteBuilder named(String newName) {\n       return this;\n     }\n \n-    public WriteBuilder createWriterFunc(Function<Schema, DatumWriter<?>> writerFunction) {\n+    public WriteBuilder createWriterFunc(Function<Schema, MetricsAwareDatumWriter<?>> writerFunction) {", "originalCommit": "394a34c4aeaa090a701b241592d168fb4e869958", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjA4NTk1Mw==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r546085953", "bodyText": "Sounds good, I didn't think of the case where people have their own implementation of these interfaces so I totally missed this. Will update and keep in mind!", "author": "yyanyy", "createdAt": "2020-12-18T20:54:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU1NjUxOQ=="}], "type": "inlineReview"}, {"oid": "6b6a15acb992826b3f40fe8235ff4196b138af3c", "url": "https://github.com/apache/iceberg/commit/6b6a15acb992826b3f40fe8235ff4196b138af3c", "message": "create MetricsAwareDatumWriter and some refactors for Avro", "committedDate": "2021-01-05T20:37:35Z", "type": "commit"}, {"oid": "6b6a15acb992826b3f40fe8235ff4196b138af3c", "url": "https://github.com/apache/iceberg/commit/6b6a15acb992826b3f40fe8235ff4196b138af3c", "message": "create MetricsAwareDatumWriter and some refactors for Avro", "committedDate": "2021-01-05T20:37:35Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTM5NTYzMQ==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r555395631", "bodyText": "nit: \"the shorter seq is first\" is a bit confusing to me, maybe \"is smaller\" is a better word.", "author": "jackye1995", "createdAt": "2021-01-11T23:03:18Z", "path": "api/src/main/java/org/apache/iceberg/types/Comparators.java", "diffHunk": "@@ -272,6 +276,30 @@ public int compare(ByteBuffer buf1, ByteBuffer buf2) {\n     }\n   }\n \n+  private static class UnsignedByteArrayComparator implements Comparator<byte[]> {\n+    private static final UnsignedByteArrayComparator INSTANCE = new UnsignedByteArrayComparator();\n+\n+    private UnsignedByteArrayComparator() {\n+    }\n+\n+    @Override\n+    public int compare(byte[] array1, byte[] array2) {\n+      int len = Math.min(array1.length, array2.length);\n+\n+      // find the first difference and return\n+      for (int i = 0; i < len; i += 1) {\n+        // Conversion to int is what Byte.toUnsignedInt would do\n+        int cmp = Integer.compare(((int) array1[i]) & 0xff, ((int) array2[i]) & 0xff);\n+        if (cmp != 0) {\n+          return cmp;\n+        }\n+      }\n+\n+      // if there are no differences, then the shorter seq is first", "originalCommit": "6b6a15acb992826b3f40fe8235ff4196b138af3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1ba8097e7965e7cdfaaf1f605552e4c27a4a0fb6", "url": "https://github.com/apache/iceberg/commit/1ba8097e7965e7cdfaaf1f605552e4c27a4a0fb6", "message": "minor comment update", "committedDate": "2021-01-12T02:28:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTA2MjQyNQ==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r569062425", "bodyText": "This should also include metrics from the rowWriter, right?", "author": "rdblue", "createdAt": "2021-02-03T01:53:46Z", "path": "core/src/main/java/org/apache/iceberg/avro/Avro.java", "diffHunk": "@@ -363,6 +378,11 @@ public void write(PositionDelete<D> delete, Encoder out) throws IOException {\n       POS_WRITER.write(delete.pos(), out);\n       rowWriter.write(delete.row(), out);\n     }\n+\n+    @Override\n+    public Stream<FieldMetrics> metrics() {\n+      return Stream.concat(PATH_WRITER.metrics(), POS_WRITER.metrics());", "originalCommit": "1ba8097e7965e7cdfaaf1f605552e4c27a4a0fb6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTA2ODA1MQ==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r569068051", "bodyText": "This can be fixed in a follow-up.", "author": "rdblue", "createdAt": "2021-02-03T02:00:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTA2MjQyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTA2NDIxOA==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r569064218", "bodyText": "Nit: Does this need a newline? I think it would all fit.", "author": "rdblue", "createdAt": "2021-02-03T01:56:01Z", "path": "core/src/main/java/org/apache/iceberg/avro/AvroFileAppender.java", "diffHunk": "@@ -57,7 +66,10 @@ public void add(D datum) {\n \n   @Override\n   public Metrics metrics() {\n-    return new Metrics(numRecords, null, null, null);\n+    Preconditions.checkState(isClosed,\n+        \"Cannot return metrics while appending to an open file.\");", "originalCommit": "1ba8097e7965e7cdfaaf1f605552e4c27a4a0fb6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2OTA2NTU1NA==", "url": "https://github.com/apache/iceberg/pull/1946#discussion_r569065554", "bodyText": "Minor: I don't think this needs to be a MetricsAwareDatumWriter, right? It isn't in the type signature, so we should name it just datumWriter.", "author": "rdblue", "createdAt": "2021-02-03T01:57:48Z", "path": "core/src/main/java/org/apache/iceberg/avro/AvroFileAppender.java", "diffHunk": "@@ -77,15 +89,16 @@ public void close() throws IOException {\n     if (writer != null) {\n       writer.close();\n       this.writer = null;\n+      isClosed = true;\n     }\n   }\n \n   @SuppressWarnings(\"unchecked\")\n   private static <D> DataFileWriter<D> newAvroWriter(\n-      Schema schema, PositionOutputStream stream, Function<Schema, DatumWriter<?>> createWriterFunc,\n+      Schema schema, PositionOutputStream stream, DatumWriter<?> metricsAwareDatumWriter,\n       CodecFactory codec, Map<String, String> metadata) throws IOException {\n     DataFileWriter<D> writer = new DataFileWriter<>(\n-        (DatumWriter<D>) createWriterFunc.apply(schema));\n+        (DatumWriter<D>) metricsAwareDatumWriter);", "originalCommit": "1ba8097e7965e7cdfaaf1f605552e4c27a4a0fb6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}