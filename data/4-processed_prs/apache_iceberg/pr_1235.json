{"pr_number": 1235, "pr_title": "avro: Abstract AvroWithPartnerSchemaVisitor", "pr_createdAt": "2020-07-23T04:12:12Z", "pr_url": "https://github.com/apache/iceberg/pull/1235", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTkyMTAzMw==", "url": "https://github.com/apache/iceberg/pull/1235#discussion_r459921033", "bodyText": "So the difference between this sub field visit and the previous sub field visit is:  we use the different methods to get the data type of inner field.   I think we don't need both the structFieldTypeById and structFieldTypes,   is it possible to abstract them to be one method and then we could remove the if (visitor.schemaEvolution()) {} else {...} finally ?", "author": "openinx", "createdAt": "2020-07-24T08:32:21Z", "path": "core/src/main/java/org/apache/iceberg/avro/AvroWithPartnerSchemaVisitor.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.avro;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import org.apache.avro.Schema;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+\n+/**\n+ * A abstract avro schema visitor with partner type. This class is for both reading and writing:\n+ * - For reading, the avro schema could evolve into the partner type. (schema evolution)\n+ * - For writing, the avro schema should be consistent with partner type.\n+ *\n+ * @param <P> Partner type.\n+ * @param <T> Return T.\n+ */\n+public abstract class AvroWithPartnerSchemaVisitor<P, T> {\n+\n+  public static <P, T> T visit(P partner, Schema schema, AvroWithPartnerSchemaVisitor<P, T> visitor) {\n+    switch (schema.getType()) {\n+      case RECORD:\n+        return visitRecord(partner, schema, visitor);\n+\n+      case UNION:\n+        return visitUnion(partner, schema, visitor);\n+\n+      case ARRAY:\n+        return visitArray(partner, schema, visitor);\n+\n+      case MAP:\n+        P keyType = visitor.mapKeyType(partner);\n+        Preconditions.checkArgument(\n+            visitor.isValidMapKey(keyType),\n+            \"Invalid map: %s is not a string\", keyType);\n+        return visitor.map(partner, schema, visit(visitor.mapValueType(partner), schema.getValueType(), visitor));\n+\n+      default:\n+        return visitor.primitive(partner, schema);\n+    }\n+  }\n+\n+  // ---------------------------------- Static helpers ---------------------------------------------\n+\n+  private static <P, T> T visitRecord(P struct, Schema record, AvroWithPartnerSchemaVisitor<P, T> visitor) {\n+    // check to make sure this hasn't been visited before\n+    String name = record.getFullName();\n+    Preconditions.checkState(!visitor.recordLevels.contains(name),\n+        \"Cannot process recursive Avro record %s\", name);\n+    List<Schema.Field> fields = record.getFields();\n+    visitor.recordLevels.push(name);\n+\n+    List<String> names = Lists.newArrayListWithExpectedSize(fields.size());\n+    List<T> results = Lists.newArrayListWithExpectedSize(fields.size());\n+\n+    if (visitor.schemaEvolution()) {\n+      for (Schema.Field field : fields) {\n+        int fieldId = AvroSchemaUtil.getFieldId(field);\n+        names.add(field.name());\n+        results.add(visit(visitor.structFieldTypeById(struct, fieldId), field.schema(), visitor));\n+      }\n+    } else {\n+      String[] fieldNames = visitor.structFieldNames(struct);\n+      P[] fieldTypes = visitor.structFieldTypes(struct);\n+      Preconditions.checkArgument(fieldTypes.length == fields.size(),\n+          \"Structs do not match: %s != %s\", struct, record);\n+      for (int i = 0; i < fieldTypes.length; i += 1) {\n+        String fieldName = fieldNames[i];\n+        Schema.Field field = fields.get(i);\n+        Preconditions.checkArgument(AvroSchemaUtil.makeCompatibleName(fieldName).equals(field.name()),\n+            \"Structs do not match: field %s != %s\", fieldName, field.name());\n+        results.add(visit(fieldTypes[i], field.schema(), visitor));", "originalCommit": "f1fd7d1b3407655009812382a5011b183b55d2a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTM1NDI5Nw==", "url": "https://github.com/apache/iceberg/pull/1235#discussion_r461354297", "bodyText": "The core difference is matching up schemas by ID or not.", "author": "JingsongLi", "createdAt": "2020-07-28T06:45:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTkyMTAzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDU3MDc1NQ==", "url": "https://github.com/apache/iceberg/pull/1235#discussion_r460570755", "bodyText": "If this defined isNullType, then the visit method could do these checks instead:\n  if (isNullType(mapType)) {\n    return nullType();\n  } else {\n    return mapValueType(mapType);\n  }", "author": "rdblue", "createdAt": "2020-07-26T20:37:35Z", "path": "core/src/main/java/org/apache/iceberg/avro/AvroSchemaWithTypeVisitor.java", "diffHunk": "@@ -19,117 +19,57 @@\n \n package org.apache.iceberg.avro;\n \n-import java.util.Deque;\n-import java.util.List;\n import org.apache.avro.Schema;\n-import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n-import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n import org.apache.iceberg.types.Type;\n import org.apache.iceberg.types.Types;\n \n-public abstract class AvroSchemaWithTypeVisitor<T> {\n+/**\n+ * Avro {@link Schema} with expected Iceberg schema visitor. See {@link #schemaEvolution}, this class is for schema\n+ * evolution reading. The avro schema can evolve into the expected Iceberg type.\n+ */\n+public abstract class AvroSchemaWithTypeVisitor<T> extends AvroWithPartnerSchemaVisitor<Type, T> {\n   public static <T> T visit(org.apache.iceberg.Schema iSchema, Schema schema, AvroSchemaWithTypeVisitor<T> visitor) {\n     return visit(iSchema.asStruct(), schema, visitor);\n   }\n \n-  public static <T> T visit(Type iType, Schema schema, AvroSchemaWithTypeVisitor<T> visitor) {\n-    switch (schema.getType()) {\n-      case RECORD:\n-        return visitRecord(iType != null ? iType.asStructType() : null, schema, visitor);\n-\n-      case UNION:\n-        return visitUnion(iType, schema, visitor);\n-\n-      case ARRAY:\n-        return visitArray(iType, schema, visitor);\n-\n-      case MAP:\n-        Types.MapType map = iType != null ? iType.asMapType() : null;\n-        return visitor.map(map, schema,\n-            visit(map != null ? map.valueType() : null, schema.getValueType(), visitor));\n-\n-      default:\n-        return visitor.primitive(iType != null ? iType.asPrimitiveType() : null, schema);\n-    }\n-  }\n-\n-  private static <T> T visitRecord(Types.StructType struct, Schema record, AvroSchemaWithTypeVisitor<T> visitor) {\n-    // check to make sure this hasn't been visited before\n-    String name = record.getFullName();\n-    Preconditions.checkState(!visitor.recordLevels.contains(name),\n-        \"Cannot process recursive Avro record %s\", name);\n-\n-    visitor.recordLevels.push(name);\n-\n-    List<Schema.Field> fields = record.getFields();\n-    List<String> names = Lists.newArrayListWithExpectedSize(fields.size());\n-    List<T> results = Lists.newArrayListWithExpectedSize(fields.size());\n-    for (Schema.Field field : fields) {\n-      int fieldId = AvroSchemaUtil.getFieldId(field);\n-      Types.NestedField iField = struct != null ? struct.field(fieldId) : null;\n-      names.add(field.name());\n-      results.add(visit(iField != null ? iField.type() : null, field.schema(), visitor));\n-    }\n-\n-    visitor.recordLevels.pop();\n-\n-    return visitor.record(struct, record, names, results);\n-  }\n-\n-  private static <T> T visitUnion(Type type, Schema union, AvroSchemaWithTypeVisitor<T> visitor) {\n-    List<Schema> types = union.getTypes();\n-    List<T> options = Lists.newArrayListWithExpectedSize(types.size());\n-    for (Schema branch : types) {\n-      if (branch.getType() == Schema.Type.NULL) {\n-        options.add(visit((Type) null, branch, visitor));\n-      } else {\n-        options.add(visit(type, branch, visitor));\n-      }\n-    }\n-    return visitor.union(type, union, options);\n+  @Override\n+  public boolean schemaEvolution() {\n+    return true;\n   }\n \n-  private static <T> T visitArray(Type type, Schema array, AvroSchemaWithTypeVisitor<T> visitor) {\n-    if (array.getLogicalType() instanceof LogicalMap || (type != null && type.isMapType())) {\n-      Preconditions.checkState(\n-          AvroSchemaUtil.isKeyValueSchema(array.getElementType()),\n-          \"Cannot visit invalid logical map type: %s\", array);\n-      Types.MapType map = type != null ? type.asMapType() : null;\n-      List<Schema.Field> keyValueFields = array.getElementType().getFields();\n-      return visitor.map(map, array,\n-          visit(map != null ? map.keyType() : null, keyValueFields.get(0).schema(), visitor),\n-          visit(map != null ? map.valueType() : null, keyValueFields.get(1).schema(), visitor));\n-\n-    } else {\n-      Types.ListType list = type != null ? type.asListType() : null;\n-      return visitor.array(list, array,\n-          visit(list != null ? list.elementType() : null, array.getElementType(), visitor));\n-    }\n+  @Override\n+  public boolean isMapType(Type type) {\n+    return type != null && type.isMapType();\n   }\n \n-  private Deque<String> recordLevels = Lists.newLinkedList();\n-\n-  public T record(Types.StructType iStruct, Schema record, List<String> names, List<T> fields) {\n-    return null;\n+  @Override\n+  public boolean isValidMapKey(Type type) {\n+    return type == null || type instanceof Types.StringType;\n   }\n \n-  public T union(Type iType, Schema union, List<T> options) {\n-    return null;\n+  @Override\n+  public Type arrayElementType(Type arrayType) {\n+    return arrayType == null ? null : arrayType.asListType().elementType();\n   }\n \n-  public T array(Types.ListType iList, Schema array, T element) {\n-    return null;\n+  @Override\n+  public Type mapKeyType(Type mapType) {\n+    return mapType == null ? null : mapType.asMapType().keyType();\n   }\n \n-  public T map(Types.MapType iMap, Schema map, T key, T value) {\n-    return null;\n+  @Override\n+  public Type mapValueType(Type mapType) {\n+    return mapType == null ? null : mapType.asMapType().valueType();", "originalCommit": "f1fd7d1b3407655009812382a5011b183b55d2a9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDU4MTI0MQ==", "url": "https://github.com/apache/iceberg/pull/1235#discussion_r460581241", "bodyText": "I like that this standardizes the logic to traverse a schema with a partner, but I don't think that it makes sense to mix the two cases together into a single class for a few reasons:\n\nThe meaning of schemaEvolution is hard to understand. The case where the schemas must have the same structure is more related to when we don't have IDs for one type of schema, like Spark. In that case, we rely on the structure matching exactly and are guaranteed that because both schemas are derived from the same Iceberg schema. We prefer to match up schemas by ID, even for the write path, but require it for the read path (because of evolution as you correctly noted).\nIt isn't clear which methods should be implemented for a visitor. Even if we added documentation, that's not going to be as easy to understand as having two types, one for traversing by IDs and the other for traversing by structure.\nThere isn't much benefit to sharing because record visiting is very different between cases. The union, array, and map methods aren't very complicated.\n\nI think it would be better to have the two cases broken out into AvroWithPartnerByIDVisitor and AvroWithPartnerByStructureVisitor. Then it is clear what needs to be implemented in both cases and there is no schemaEvolution flag.", "author": "rdblue", "createdAt": "2020-07-26T22:28:33Z", "path": "core/src/main/java/org/apache/iceberg/avro/AvroWithPartnerSchemaVisitor.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.avro;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import org.apache.avro.Schema;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+\n+/**\n+ * A abstract avro schema visitor with partner type. This class is for both reading and writing:\n+ * - For reading, the avro schema could evolve into the partner type. (schema evolution)\n+ * - For writing, the avro schema should be consistent with partner type.\n+ *\n+ * @param <P> Partner type.\n+ * @param <T> Return T.", "originalCommit": "f1fd7d1b3407655009812382a5011b183b55d2a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTMzNTUwMQ==", "url": "https://github.com/apache/iceberg/pull/1235#discussion_r461335501", "bodyText": "+1\nI also tangled for a long time, it is more confusing to put them together by force.", "author": "JingsongLi", "createdAt": "2020-07-28T05:55:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDU4MTI0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDU4MTU3Mg==", "url": "https://github.com/apache/iceberg/pull/1235#discussion_r460581572", "bodyText": "Arrays are a bit difficult to work with. For the structure-based traversal, how about combining structFieldNames and structFieldTypes into a single method indexed by position in the struct?\n  Pair<String, P> fieldNameAndType(P structType, int pos);\nThat corresponds to the fieldType(int id) for the id-based lookup.", "author": "rdblue", "createdAt": "2020-07-26T22:31:36Z", "path": "core/src/main/java/org/apache/iceberg/avro/AvroWithPartnerSchemaVisitor.java", "diffHunk": "@@ -0,0 +1,188 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.avro;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import org.apache.avro.Schema;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+\n+/**\n+ * A abstract avro schema visitor with partner type. This class is for both reading and writing:\n+ * - For reading, the avro schema could evolve into the partner type. (schema evolution)\n+ * - For writing, the avro schema should be consistent with partner type.\n+ *\n+ * @param <P> Partner type.\n+ * @param <T> Return T.\n+ */\n+public abstract class AvroWithPartnerSchemaVisitor<P, T> {\n+\n+  public static <P, T> T visit(P partner, Schema schema, AvroWithPartnerSchemaVisitor<P, T> visitor) {\n+    switch (schema.getType()) {\n+      case RECORD:\n+        return visitRecord(partner, schema, visitor);\n+\n+      case UNION:\n+        return visitUnion(partner, schema, visitor);\n+\n+      case ARRAY:\n+        return visitArray(partner, schema, visitor);\n+\n+      case MAP:\n+        P keyType = visitor.mapKeyType(partner);\n+        Preconditions.checkArgument(\n+            visitor.isValidMapKey(keyType),\n+            \"Invalid map: %s is not a string\", keyType);\n+        return visitor.map(partner, schema, visit(visitor.mapValueType(partner), schema.getValueType(), visitor));\n+\n+      default:\n+        return visitor.primitive(partner, schema);\n+    }\n+  }\n+\n+  // ---------------------------------- Static helpers ---------------------------------------------\n+\n+  private static <P, T> T visitRecord(P struct, Schema record, AvroWithPartnerSchemaVisitor<P, T> visitor) {\n+    // check to make sure this hasn't been visited before\n+    String name = record.getFullName();\n+    Preconditions.checkState(!visitor.recordLevels.contains(name),\n+        \"Cannot process recursive Avro record %s\", name);\n+    List<Schema.Field> fields = record.getFields();\n+    visitor.recordLevels.push(name);\n+\n+    List<String> names = Lists.newArrayListWithExpectedSize(fields.size());\n+    List<T> results = Lists.newArrayListWithExpectedSize(fields.size());\n+\n+    if (visitor.schemaEvolution()) {\n+      for (Schema.Field field : fields) {\n+        int fieldId = AvroSchemaUtil.getFieldId(field);\n+        names.add(field.name());\n+        results.add(visit(visitor.structFieldTypeById(struct, fieldId), field.schema(), visitor));\n+      }\n+    } else {\n+      String[] fieldNames = visitor.structFieldNames(struct);\n+      P[] fieldTypes = visitor.structFieldTypes(struct);\n+      Preconditions.checkArgument(fieldTypes.length == fields.size(),\n+          \"Structs do not match: %s != %s\", struct, record);\n+      for (int i = 0; i < fieldTypes.length; i += 1) {\n+        String fieldName = fieldNames[i];\n+        Schema.Field field = fields.get(i);\n+        Preconditions.checkArgument(AvroSchemaUtil.makeCompatibleName(fieldName).equals(field.name()),\n+            \"Structs do not match: field %s != %s\", fieldName, field.name());\n+        results.add(visit(fieldTypes[i], field.schema(), visitor));\n+      }\n+    }\n+\n+    visitor.recordLevels.pop();\n+\n+    return visitor.record(struct, record, names, results);\n+  }\n+\n+  private static <P, T> T visitUnion(P type, Schema union, AvroWithPartnerSchemaVisitor<P, T> visitor) {\n+    List<Schema> types = union.getTypes();\n+    Preconditions.checkArgument(AvroSchemaUtil.isOptionSchema(union),\n+        \"Cannot visit non-option union: %s\", union);\n+    List<T> options = Lists.newArrayListWithExpectedSize(types.size());\n+    for (Schema branch : types) {\n+      if (branch.getType() == Schema.Type.NULL) {\n+        options.add(visit(visitor.nullType(), branch, visitor));\n+      } else {\n+        options.add(visit(type, branch, visitor));\n+      }\n+    }\n+    return visitor.union(type, union, options);\n+  }\n+\n+  private static <P, T> T visitArray(P type, Schema array, AvroWithPartnerSchemaVisitor<P, T> visitor) {\n+    if (array.getLogicalType() instanceof LogicalMap || visitor.isMapType(type)) {\n+      Preconditions.checkState(\n+          AvroSchemaUtil.isKeyValueSchema(array.getElementType()),\n+          \"Cannot visit invalid logical map type: %s\", array);\n+      List<Schema.Field> keyValueFields = array.getElementType().getFields();\n+      return visitor.map(type, array,\n+          visit(visitor.mapKeyType(type), keyValueFields.get(0).schema(), visitor),\n+          visit(visitor.mapValueType(type), keyValueFields.get(1).schema(), visitor));\n+\n+    } else {\n+      return visitor.array(type, array, visit(visitor.arrayElementType(type), array.getElementType(), visitor));\n+    }\n+  }\n+\n+  /**\n+   * Just for checking state.\n+   */\n+  private Deque<String> recordLevels = Lists.newLinkedList();\n+\n+  // ---------------------------------- Partner type methods ---------------------------------------------\n+\n+  public boolean schemaEvolution() {\n+    return false;\n+  }\n+\n+  public abstract boolean isMapType(P type);\n+\n+  public abstract boolean isValidMapKey(P type);\n+\n+  public abstract P arrayElementType(P arrayType);\n+\n+  public abstract P mapKeyType(P mapType);\n+  public abstract P mapValueType(P mapType);\n+\n+  public String[] structFieldNames(P structType) {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  public P[] structFieldTypes(P structType) {", "originalCommit": "f1fd7d1b3407655009812382a5011b183b55d2a9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "449688f5c222e0ea4b5fe0995fdffe015f31794a", "url": "https://github.com/apache/iceberg/commit/449688f5c222e0ea4b5fe0995fdffe015f31794a", "message": "avro: Abstract AvroWithPartnerSchemaVisitor", "committedDate": "2020-07-28T05:56:56Z", "type": "commit"}, {"oid": "9795d36917009531420c4fc2772f694215b4563f", "url": "https://github.com/apache/iceberg/commit/9795d36917009531420c4fc2772f694215b4563f", "message": "Address Ryan's comments", "committedDate": "2020-07-28T07:09:37Z", "type": "forcePushed"}, {"oid": "24cf7cd1a630821506706e0d06de6acc48866db5", "url": "https://github.com/apache/iceberg/commit/24cf7cd1a630821506706e0d06de6acc48866db5", "message": "Address Ryan's comments", "committedDate": "2020-07-28T08:09:31Z", "type": "commit"}, {"oid": "24cf7cd1a630821506706e0d06de6acc48866db5", "url": "https://github.com/apache/iceberg/commit/24cf7cd1a630821506706e0d06de6acc48866db5", "message": "Address Ryan's comments", "committedDate": "2020-07-28T08:09:31Z", "type": "forcePushed"}]}