{"pr_number": 1173, "pr_title": "FlinkTypeVisitor: Use LogicalTypeVisitor and supports MultisetType", "pr_createdAt": "2020-07-07T03:41:37Z", "pr_url": "https://github.com/apache/iceberg/pull/1173", "timeline": [{"oid": "4af5bf4bcdfd43aa4dc42d7064702936918fd8db", "url": "https://github.com/apache/iceberg/commit/4af5bf4bcdfd43aa4dc42d7064702936918fd8db", "message": "FlinkTypeVisitor: Use LogicalTypeVisitor and supports MultisetType", "committedDate": "2020-07-07T03:36:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDcxNDYxMQ==", "url": "https://github.com/apache/iceberg/pull/1173#discussion_r450714611", "bodyText": "@JingsongLi I'm curious that what's the difference between the  flink style LogicalTypeVisitor  and iceberg style visitor... Currently, all of the visitor are iceberg style,  I'm not quite sure that what's the benifits to convert it to flink style visitor ...\nUpdate:  OK, I read the background in this issues here (#1173 (comment)), sounds reasonable.", "author": "openinx", "createdAt": "2020-07-07T09:00:00Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeVisitor.java", "diffHunk": "@@ -19,65 +19,63 @@\n \n package org.apache.iceberg.flink;\n \n-import java.util.List;\n-import java.util.Map;\n-import org.apache.flink.table.types.AtomicDataType;\n-import org.apache.flink.table.types.CollectionDataType;\n-import org.apache.flink.table.types.DataType;\n-import org.apache.flink.table.types.FieldsDataType;\n-import org.apache.flink.table.types.KeyValueDataType;\n-import org.apache.flink.table.types.logical.RowType;\n-import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n-import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.flink.table.types.logical.DayTimeIntervalType;\n+import org.apache.flink.table.types.logical.DistinctType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.LogicalTypeVisitor;\n+import org.apache.flink.table.types.logical.NullType;\n+import org.apache.flink.table.types.logical.RawType;\n+import org.apache.flink.table.types.logical.StructuredType;\n+import org.apache.flink.table.types.logical.SymbolType;\n+import org.apache.flink.table.types.logical.YearMonthIntervalType;\n+import org.apache.flink.table.types.logical.ZonedTimestampType;\n \n-public class FlinkTypeVisitor<T> {\n+public abstract class FlinkTypeVisitor<T> implements LogicalTypeVisitor<T> {", "originalCommit": "4af5bf4bcdfd43aa4dc42d7064702936918fd8db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDcxNTU5OA==", "url": "https://github.com/apache/iceberg/pull/1173#discussion_r450715598", "bodyText": "BTW, seems this FlinkTypeVisitor can be package access (I forget to check the access before).", "author": "openinx", "createdAt": "2020-07-07T09:01:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDcxNDYxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDcyMDc0NQ==", "url": "https://github.com/apache/iceberg/pull/1173#discussion_r450720745", "bodyText": "Sounds good that we've extended support the flink multiset data type .", "author": "openinx", "createdAt": "2020-07-07T09:10:25Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -64,86 +63,136 @@ private int getNextId() {\n   }\n \n   @Override\n-  public Type fields(FieldsDataType fields, List<Type> types) {\n-    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n-    boolean isRoot = root == fields;\n+  public Type visit(CharType charType) {\n+    return Types.StringType.get();\n+  }\n \n-    List<RowType.RowField> rowFields = ((RowType) fields.getLogicalType()).getFields();\n-    Preconditions.checkArgument(rowFields.size() == types.size(), \"fields list and types list should have same size.\");\n+  @Override\n+  public Type visit(VarCharType varCharType) {\n+    return Types.StringType.get();\n+  }\n \n-    for (int i = 0; i < rowFields.size(); i++) {\n-      int id = isRoot ? i : getNextId();\n+  @Override\n+  public Type visit(BooleanType booleanType) {\n+    return Types.BooleanType.get();\n+  }\n \n-      RowType.RowField field = rowFields.get(i);\n-      String name = field.getName();\n-      String comment = field.getDescription().orElse(null);\n+  @Override\n+  public Type visit(BinaryType binaryType) {\n+    return Types.FixedType.ofLength(binaryType.getLength());\n+  }\n \n-      if (field.getType().isNullable()) {\n-        newFields.add(Types.NestedField.optional(id, name, types.get(i), comment));\n-      } else {\n-        newFields.add(Types.NestedField.required(id, name, types.get(i), comment));\n-      }\n-    }\n+  @Override\n+  public Type visit(VarBinaryType varBinaryType) {\n+    return Types.BinaryType.get();\n+  }\n \n-    return Types.StructType.of(newFields);\n+  @Override\n+  public Type visit(DecimalType decimalType) {\n+    return Types.DecimalType.of(decimalType.getPrecision(), decimalType.getScale());\n+  }\n+\n+  @Override\n+  public Type visit(TinyIntType tinyIntType) {\n+    return Types.IntegerType.get();\n+  }\n+\n+  @Override\n+  public Type visit(SmallIntType smallIntType) {\n+    return Types.IntegerType.get();\n+  }\n+\n+  @Override\n+  public Type visit(IntType intType) {\n+    return Types.IntegerType.get();\n+  }\n+\n+  @Override\n+  public Type visit(BigIntType bigIntType) {\n+    return Types.LongType.get();\n+  }\n+\n+  @Override\n+  public Type visit(FloatType floatType) {\n+    return Types.FloatType.get();\n+  }\n+\n+  @Override\n+  public Type visit(DoubleType doubleType) {\n+    return Types.DoubleType.get();\n+  }\n+\n+  @Override\n+  public Type visit(DateType dateType) {\n+    return Types.DateType.get();\n+  }\n+\n+  @Override\n+  public Type visit(TimeType timeType) {\n+    return Types.TimeType.get();\n   }\n \n   @Override\n-  public Type collection(CollectionDataType collection, Type elementType) {\n-    if (collection.getElementDataType().getLogicalType().isNullable()) {\n+  public Type visit(TimestampType timestampType) {\n+    return Types.TimestampType.withoutZone();\n+  }\n+\n+  @Override\n+  public Type visit(LocalZonedTimestampType localZonedTimestampType) {\n+    return Types.TimestampType.withZone();\n+  }\n+\n+  @Override\n+  public Type visit(ArrayType arrayType) {\n+    Type elementType = arrayType.getElementType().accept(this);\n+    if (arrayType.getElementType().isNullable()) {\n       return Types.ListType.ofOptional(getNextId(), elementType);\n     } else {\n       return Types.ListType.ofRequired(getNextId(), elementType);\n     }\n   }\n \n   @Override\n-  public Type map(KeyValueDataType map, Type keyType, Type valueType) {\n+  public Type visit(MultisetType multisetType) {\n+    Type elementType = multisetType.getElementType().accept(this);\n+    return Types.MapType.ofRequired(getNextId(), getNextId(), elementType, Types.IntegerType.get());", "originalCommit": "4af5bf4bcdfd43aa4dc42d7064702936918fd8db", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "47beb33eda1b024280129f2422a9f32d6a0d79e9", "url": "https://github.com/apache/iceberg/commit/47beb33eda1b024280129f2422a9f32d6a0d79e9", "message": "Public to package", "committedDate": "2020-07-07T09:32:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjA4OTA1MA==", "url": "https://github.com/apache/iceberg/pull/1173#discussion_r452089050", "bodyText": "Seems here we don't need to loop twice ( the first loop to get List<Type> and the next loop to get List<Types.NestedField> ). Could be simplified like the following:\n  @Override\n  public Type visit(RowType rowType) {\n    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(rowType.getFieldCount());\n    boolean isRoot = root == rowType;\n\n    for (int i = 0; i < rowType.getFieldCount(); i++) {\n      int id = isRoot ? i : getNextId();\n\n      RowType.RowField field = rowType.getFields().get(i);\n      String name = field.getName();\n      String comment = field.getDescription().orElse(null);\n      Type type = field.getType().accept(this);\n\n      if (field.getType().isNullable()) {\n        newFields.add(Types.NestedField.optional(id, name, type, comment));\n      } else {\n        newFields.add(Types.NestedField.required(id, name, type, comment));\n      }\n    }\n\n    return Types.StructType.of(newFields);\n  }", "author": "openinx", "createdAt": "2020-07-09T09:32:13Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -64,86 +63,136 @@ private int getNextId() {\n   }\n \n   @Override\n-  public Type fields(FieldsDataType fields, List<Type> types) {\n-    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n-    boolean isRoot = root == fields;\n+  public Type visit(CharType charType) {\n+    return Types.StringType.get();\n+  }\n \n-    List<RowType.RowField> rowFields = ((RowType) fields.getLogicalType()).getFields();\n-    Preconditions.checkArgument(rowFields.size() == types.size(), \"fields list and types list should have same size.\");\n+  @Override\n+  public Type visit(VarCharType varCharType) {\n+    return Types.StringType.get();\n+  }\n \n-    for (int i = 0; i < rowFields.size(); i++) {\n-      int id = isRoot ? i : getNextId();\n+  @Override\n+  public Type visit(BooleanType booleanType) {\n+    return Types.BooleanType.get();\n+  }\n \n-      RowType.RowField field = rowFields.get(i);\n-      String name = field.getName();\n-      String comment = field.getDescription().orElse(null);\n+  @Override\n+  public Type visit(BinaryType binaryType) {\n+    return Types.FixedType.ofLength(binaryType.getLength());\n+  }\n \n-      if (field.getType().isNullable()) {\n-        newFields.add(Types.NestedField.optional(id, name, types.get(i), comment));\n-      } else {\n-        newFields.add(Types.NestedField.required(id, name, types.get(i), comment));\n-      }\n-    }\n+  @Override\n+  public Type visit(VarBinaryType varBinaryType) {\n+    return Types.BinaryType.get();\n+  }\n \n-    return Types.StructType.of(newFields);\n+  @Override\n+  public Type visit(DecimalType decimalType) {\n+    return Types.DecimalType.of(decimalType.getPrecision(), decimalType.getScale());\n+  }\n+\n+  @Override\n+  public Type visit(TinyIntType tinyIntType) {\n+    return Types.IntegerType.get();\n+  }\n+\n+  @Override\n+  public Type visit(SmallIntType smallIntType) {\n+    return Types.IntegerType.get();\n+  }\n+\n+  @Override\n+  public Type visit(IntType intType) {\n+    return Types.IntegerType.get();\n+  }\n+\n+  @Override\n+  public Type visit(BigIntType bigIntType) {\n+    return Types.LongType.get();\n+  }\n+\n+  @Override\n+  public Type visit(FloatType floatType) {\n+    return Types.FloatType.get();\n+  }\n+\n+  @Override\n+  public Type visit(DoubleType doubleType) {\n+    return Types.DoubleType.get();\n+  }\n+\n+  @Override\n+  public Type visit(DateType dateType) {\n+    return Types.DateType.get();\n+  }\n+\n+  @Override\n+  public Type visit(TimeType timeType) {\n+    return Types.TimeType.get();\n   }\n \n   @Override\n-  public Type collection(CollectionDataType collection, Type elementType) {\n-    if (collection.getElementDataType().getLogicalType().isNullable()) {\n+  public Type visit(TimestampType timestampType) {\n+    return Types.TimestampType.withoutZone();\n+  }\n+\n+  @Override\n+  public Type visit(LocalZonedTimestampType localZonedTimestampType) {\n+    return Types.TimestampType.withZone();\n+  }\n+\n+  @Override\n+  public Type visit(ArrayType arrayType) {\n+    Type elementType = arrayType.getElementType().accept(this);\n+    if (arrayType.getElementType().isNullable()) {\n       return Types.ListType.ofOptional(getNextId(), elementType);\n     } else {\n       return Types.ListType.ofRequired(getNextId(), elementType);\n     }\n   }\n \n   @Override\n-  public Type map(KeyValueDataType map, Type keyType, Type valueType) {\n+  public Type visit(MultisetType multisetType) {\n+    Type elementType = multisetType.getElementType().accept(this);\n+    return Types.MapType.ofRequired(getNextId(), getNextId(), elementType, Types.IntegerType.get());\n+  }\n+\n+  @Override\n+  public Type visit(MapType mapType) {\n     // keys in map are not allowed to be null.\n-    if (map.getValueDataType().getLogicalType().isNullable()) {\n+    Type keyType = mapType.getKeyType().accept(this);\n+    Type valueType = mapType.getValueType().accept(this);\n+    if (mapType.getValueType().isNullable()) {\n       return Types.MapType.ofOptional(getNextId(), getNextId(), keyType, valueType);\n     } else {\n       return Types.MapType.ofRequired(getNextId(), getNextId(), keyType, valueType);\n     }\n   }\n \n-  @SuppressWarnings(\"checkstyle:CyclomaticComplexity\")\n-  @Override\n-  public Type atomic(AtomicDataType type) {\n-    LogicalType inner = type.getLogicalType();\n-    if (inner instanceof VarCharType ||\n-        inner instanceof CharType) {\n-      return Types.StringType.get();\n-    } else if (inner instanceof BooleanType) {\n-      return Types.BooleanType.get();\n-    } else if (inner instanceof IntType ||\n-        inner instanceof SmallIntType ||\n-        inner instanceof TinyIntType) {\n-      return Types.IntegerType.get();\n-    } else if (inner instanceof BigIntType) {\n-      return Types.LongType.get();\n-    } else if (inner instanceof VarBinaryType) {\n-      return Types.BinaryType.get();\n-    } else if (inner instanceof BinaryType) {\n-      BinaryType binaryType = (BinaryType) inner;\n-      return Types.FixedType.ofLength(binaryType.getLength());\n-    } else if (inner instanceof FloatType) {\n-      return Types.FloatType.get();\n-    } else if (inner instanceof DoubleType) {\n-      return Types.DoubleType.get();\n-    } else if (inner instanceof DateType) {\n-      return Types.DateType.get();\n-    } else if (inner instanceof TimeType) {\n-      return Types.TimeType.get();\n-    } else if (inner instanceof TimestampType) {\n-      return Types.TimestampType.withoutZone();\n-    } else if (inner instanceof LocalZonedTimestampType) {\n-      return Types.TimestampType.withZone();\n-    } else if (inner instanceof DecimalType) {\n-      DecimalType decimalType = (DecimalType) inner;\n-      return Types.DecimalType.of(decimalType.getPrecision(), decimalType.getScale());\n-    } else {\n-      throw new UnsupportedOperationException(\"Not a supported type: \" + type.toString());\n+  @Override\n+  public Type visit(RowType rowType) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(rowType.getFieldCount());\n+    boolean isRoot = root == rowType;\n+\n+    List<Type> types = rowType.getFields().stream()", "originalCommit": "47beb33eda1b024280129f2422a9f32d6a0d79e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjA5NjUwMw==", "url": "https://github.com/apache/iceberg/pull/1173#discussion_r452096503", "bodyText": "One thing is :  we may adjust the place to generate field Id for nested types, then we may need to adjust the unit test ..", "author": "openinx", "createdAt": "2020-07-09T09:44:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjA4OTA1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzM5MzY4OA==", "url": "https://github.com/apache/iceberg/pull/1173#discussion_r453393688", "bodyText": "I'd prefer to keep the loop twice. If we need change the generation ID for nested types, I think it is better to change Spark too.", "author": "JingsongLi", "createdAt": "2020-07-13T01:39:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjA4OTA1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQwMTY1Mg==", "url": "https://github.com/apache/iceberg/pull/1173#discussion_r453401652", "bodyText": "I'm OK about the current twice loop here now, let's just keep the consistence id generation with spark here.", "author": "openinx", "createdAt": "2020-07-13T02:20:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjA4OTA1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDUwMzAwNg==", "url": "https://github.com/apache/iceberg/pull/1173#discussion_r454503006", "bodyText": "There is also a factory method that accepts a nullability boolean, NestedField.of.", "author": "rdblue", "createdAt": "2020-07-14T16:56:44Z", "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkTypeToType.java", "diffHunk": "@@ -64,86 +63,136 @@ private int getNextId() {\n   }\n \n   @Override\n-  public Type fields(FieldsDataType fields, List<Type> types) {\n-    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(types.size());\n-    boolean isRoot = root == fields;\n+  public Type visit(CharType charType) {\n+    return Types.StringType.get();\n+  }\n \n-    List<RowType.RowField> rowFields = ((RowType) fields.getLogicalType()).getFields();\n-    Preconditions.checkArgument(rowFields.size() == types.size(), \"fields list and types list should have same size.\");\n+  @Override\n+  public Type visit(VarCharType varCharType) {\n+    return Types.StringType.get();\n+  }\n \n-    for (int i = 0; i < rowFields.size(); i++) {\n-      int id = isRoot ? i : getNextId();\n+  @Override\n+  public Type visit(BooleanType booleanType) {\n+    return Types.BooleanType.get();\n+  }\n \n-      RowType.RowField field = rowFields.get(i);\n-      String name = field.getName();\n-      String comment = field.getDescription().orElse(null);\n+  @Override\n+  public Type visit(BinaryType binaryType) {\n+    return Types.FixedType.ofLength(binaryType.getLength());\n+  }\n \n-      if (field.getType().isNullable()) {\n-        newFields.add(Types.NestedField.optional(id, name, types.get(i), comment));\n-      } else {\n-        newFields.add(Types.NestedField.required(id, name, types.get(i), comment));\n-      }\n-    }\n+  @Override\n+  public Type visit(VarBinaryType varBinaryType) {\n+    return Types.BinaryType.get();\n+  }\n \n-    return Types.StructType.of(newFields);\n+  @Override\n+  public Type visit(DecimalType decimalType) {\n+    return Types.DecimalType.of(decimalType.getPrecision(), decimalType.getScale());\n+  }\n+\n+  @Override\n+  public Type visit(TinyIntType tinyIntType) {\n+    return Types.IntegerType.get();\n+  }\n+\n+  @Override\n+  public Type visit(SmallIntType smallIntType) {\n+    return Types.IntegerType.get();\n+  }\n+\n+  @Override\n+  public Type visit(IntType intType) {\n+    return Types.IntegerType.get();\n+  }\n+\n+  @Override\n+  public Type visit(BigIntType bigIntType) {\n+    return Types.LongType.get();\n+  }\n+\n+  @Override\n+  public Type visit(FloatType floatType) {\n+    return Types.FloatType.get();\n+  }\n+\n+  @Override\n+  public Type visit(DoubleType doubleType) {\n+    return Types.DoubleType.get();\n+  }\n+\n+  @Override\n+  public Type visit(DateType dateType) {\n+    return Types.DateType.get();\n+  }\n+\n+  @Override\n+  public Type visit(TimeType timeType) {\n+    return Types.TimeType.get();\n   }\n \n   @Override\n-  public Type collection(CollectionDataType collection, Type elementType) {\n-    if (collection.getElementDataType().getLogicalType().isNullable()) {\n+  public Type visit(TimestampType timestampType) {\n+    return Types.TimestampType.withoutZone();\n+  }\n+\n+  @Override\n+  public Type visit(LocalZonedTimestampType localZonedTimestampType) {\n+    return Types.TimestampType.withZone();\n+  }\n+\n+  @Override\n+  public Type visit(ArrayType arrayType) {\n+    Type elementType = arrayType.getElementType().accept(this);\n+    if (arrayType.getElementType().isNullable()) {\n       return Types.ListType.ofOptional(getNextId(), elementType);\n     } else {\n       return Types.ListType.ofRequired(getNextId(), elementType);\n     }\n   }\n \n   @Override\n-  public Type map(KeyValueDataType map, Type keyType, Type valueType) {\n+  public Type visit(MultisetType multisetType) {\n+    Type elementType = multisetType.getElementType().accept(this);\n+    return Types.MapType.ofRequired(getNextId(), getNextId(), elementType, Types.IntegerType.get());\n+  }\n+\n+  @Override\n+  public Type visit(MapType mapType) {\n     // keys in map are not allowed to be null.\n-    if (map.getValueDataType().getLogicalType().isNullable()) {\n+    Type keyType = mapType.getKeyType().accept(this);\n+    Type valueType = mapType.getValueType().accept(this);\n+    if (mapType.getValueType().isNullable()) {\n       return Types.MapType.ofOptional(getNextId(), getNextId(), keyType, valueType);\n     } else {\n       return Types.MapType.ofRequired(getNextId(), getNextId(), keyType, valueType);\n     }\n   }\n \n-  @SuppressWarnings(\"checkstyle:CyclomaticComplexity\")\n-  @Override\n-  public Type atomic(AtomicDataType type) {\n-    LogicalType inner = type.getLogicalType();\n-    if (inner instanceof VarCharType ||\n-        inner instanceof CharType) {\n-      return Types.StringType.get();\n-    } else if (inner instanceof BooleanType) {\n-      return Types.BooleanType.get();\n-    } else if (inner instanceof IntType ||\n-        inner instanceof SmallIntType ||\n-        inner instanceof TinyIntType) {\n-      return Types.IntegerType.get();\n-    } else if (inner instanceof BigIntType) {\n-      return Types.LongType.get();\n-    } else if (inner instanceof VarBinaryType) {\n-      return Types.BinaryType.get();\n-    } else if (inner instanceof BinaryType) {\n-      BinaryType binaryType = (BinaryType) inner;\n-      return Types.FixedType.ofLength(binaryType.getLength());\n-    } else if (inner instanceof FloatType) {\n-      return Types.FloatType.get();\n-    } else if (inner instanceof DoubleType) {\n-      return Types.DoubleType.get();\n-    } else if (inner instanceof DateType) {\n-      return Types.DateType.get();\n-    } else if (inner instanceof TimeType) {\n-      return Types.TimeType.get();\n-    } else if (inner instanceof TimestampType) {\n-      return Types.TimestampType.withoutZone();\n-    } else if (inner instanceof LocalZonedTimestampType) {\n-      return Types.TimestampType.withZone();\n-    } else if (inner instanceof DecimalType) {\n-      DecimalType decimalType = (DecimalType) inner;\n-      return Types.DecimalType.of(decimalType.getPrecision(), decimalType.getScale());\n-    } else {\n-      throw new UnsupportedOperationException(\"Not a supported type: \" + type.toString());\n+  @Override\n+  public Type visit(RowType rowType) {\n+    List<Types.NestedField> newFields = Lists.newArrayListWithExpectedSize(rowType.getFieldCount());\n+    boolean isRoot = root == rowType;\n+\n+    List<Type> types = rowType.getFields().stream()\n+        .map(f -> f.getType().accept(this))\n+        .collect(Collectors.toList());\n+\n+    for (int i = 0; i < rowType.getFieldCount(); i++) {\n+      int id = isRoot ? i : getNextId();\n+\n+      RowType.RowField field = rowType.getFields().get(i);\n+      String name = field.getName();\n+      String comment = field.getDescription().orElse(null);\n+\n+      if (field.getType().isNullable()) {\n+        newFields.add(Types.NestedField.optional(id, name, types.get(i), comment));", "originalCommit": "47beb33eda1b024280129f2422a9f32d6a0d79e9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDUwNDA0Ng==", "url": "https://github.com/apache/iceberg/pull/1173#discussion_r454504046", "bodyText": "What happens for a multiset of nullable items?", "author": "rdblue", "createdAt": "2020-07-14T16:58:27Z", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkSchemaUtil.java", "diffHunk": "@@ -54,21 +54,22 @@ public void testConvertFlinkSchemaToIcebergSchema() {\n         .field(\"decimal\", DataTypes.DECIMAL(2, 2))\n         .field(\"decimal2\", DataTypes.DECIMAL(38, 2))\n         .field(\"decimal3\", DataTypes.DECIMAL(10, 1))\n+        .field(\"multiset\", DataTypes.MULTISET(DataTypes.STRING().notNull()))", "originalCommit": "47beb33eda1b024280129f2422a9f32d6a0d79e9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDc0NDI5MA==", "url": "https://github.com/apache/iceberg/pull/1173#discussion_r454744290", "bodyText": "Just like a nullable key in Map, because the default behavior in Flink is nullable key, we support its conversion:\n\nin the conversion of Flink type to Iceberg type, just ignore the nullable of key.\nin the conversion of Iceberg type to Flink type, the nullable of key becomes false.", "author": "JingsongLi", "createdAt": "2020-07-15T01:57:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDUwNDA0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTMzMzI1OQ==", "url": "https://github.com/apache/iceberg/pull/1173#discussion_r455333259", "bodyText": "Okay, for rows that are passed to Iceberg that have null map keys or null values in a multiset, what should happen?", "author": "rdblue", "createdAt": "2020-07-15T20:49:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDUwNDA0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ2Nzk2NA==", "url": "https://github.com/apache/iceberg/pull/1173#discussion_r455467964", "bodyText": "Null values are OK, the problem is null keys.\nFor null keys support, looks like formats are OK, the only constraint of formats is that Avro only support string key of map type.\nBut the thing is that whether we have any special optimizations for not null. The answer is yes, see ParquetValueWriters.option. If a null key comes to parquet writer, I think there should be NullPointException. This looks not so elegant.\nAnother choice is what I said in https://github.com/apache/iceberg/pull/1096/files/8891cd5438306f0b4b226706058beff7c3cd4080#diff-12a375418217cdc6be26c73e02d56065R102\nWe can throw a UnsupportedException here to tell users, although Flink has default nullable map key.", "author": "JingsongLi", "createdAt": "2020-07-16T02:11:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDUwNDA0Ng=="}], "type": "inlineReview"}]}