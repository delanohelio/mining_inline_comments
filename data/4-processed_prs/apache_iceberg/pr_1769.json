{"pr_number": 1769, "pr_title": "Spark: Add RollbackToTimestampProcedure", "pr_createdAt": "2020-11-13T19:33:39Z", "pr_url": "https://github.com/apache/iceberg/pull/1769", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzE4MDk5Mg==", "url": "https://github.com/apache/iceberg/pull/1769#discussion_r523180992", "bodyText": "Here we have the same problem as in other cases. If there is a concurrent operation after commit, the output may not be precise. To make it reliable, we may attach a UUID to this operation and fetch the snapshot by it. Any other ideas are welcome.", "author": "aokolnychyi", "createdAt": "2020-11-13T19:35:54Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/procedures/RollbackToTimestampProcedure.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.procedures;\n+\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.spark.procedures.SparkProcedures.ProcedureBuilder;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils;\n+import org.apache.spark.sql.connector.catalog.TableCatalog;\n+import org.apache.spark.sql.connector.iceberg.catalog.ProcedureParameter;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.Metadata;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * A procedure that rollbacks a table to a given point in time.\n+ */\n+class RollbackToTimestampProcedure extends BaseProcedure {\n+\n+  private static final ProcedureParameter[] PARAMETERS = new ProcedureParameter[]{\n+      ProcedureParameter.required(\"namespace\", DataTypes.StringType),\n+      ProcedureParameter.required(\"table\", DataTypes.StringType),\n+      ProcedureParameter.required(\"timestamp\", DataTypes.TimestampType)\n+  };\n+\n+  private static final StructType OUTPUT_TYPE = new StructType(new StructField[]{\n+      new StructField(\"previous_snapshot_id\", DataTypes.LongType, false, Metadata.empty()),\n+      new StructField(\"current_snapshot_id\", DataTypes.LongType, false, Metadata.empty())\n+  });\n+\n+  public static ProcedureBuilder builder() {\n+    return new BaseProcedure.Builder<RollbackToTimestampProcedure>() {\n+      @Override\n+      protected RollbackToTimestampProcedure doBuild() {\n+        return new RollbackToTimestampProcedure(tableCatalog());\n+      }\n+    };\n+  }\n+\n+  private RollbackToTimestampProcedure(TableCatalog catalog) {\n+    super(catalog);\n+  }\n+\n+  @Override\n+  public ProcedureParameter[] parameters() {\n+    return PARAMETERS;\n+  }\n+\n+  @Override\n+  public StructType outputType() {\n+    return OUTPUT_TYPE;\n+  }\n+\n+  @Override\n+  public InternalRow[] call(InternalRow args) {\n+    String namespace = args.getString(0);\n+    String tableName = args.getString(1);\n+    // timestamps in Spark have nanosecond precision so this conversion is lossy\n+    long timestampMillis = DateTimeUtils.toMillis(args.getLong(2));\n+\n+    return modifyIcebergTable(namespace, tableName, table -> {\n+      Snapshot previousSnapshot = table.currentSnapshot();\n+\n+      table.manageSnapshots()\n+          .rollbackToTime(timestampMillis)\n+          .commit();\n+\n+      Snapshot currentSnapshot = table.currentSnapshot();", "originalCommit": "74700a0450627f9aac9bede1efa79f1062768da1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzIyOTU1NA==", "url": "https://github.com/apache/iceberg/pull/1769#discussion_r523229554", "bodyText": "If we are worried about concurrent operations, then we should set a validation to fail if the current snapshot ID changes. We support this in manageSnapshots for cherry picking, we just don't set it for rollbacks.", "author": "rdblue", "createdAt": "2020-11-13T20:59:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzE4MDk5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI3Mzk4Mw==", "url": "https://github.com/apache/iceberg/pull/1769#discussion_r523273983", "bodyText": "It is a bit different here. Apart from validating the concurrent operations while rolling back, I am talking about what happens after the rollback is successful.  It may be that table.currentSnapshot() returns a snapshot that is not the same snapshot we rollbacked to. It may belong to a concurrent operation.", "author": "aokolnychyi", "createdAt": "2020-11-13T22:53:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzE4MDk5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI4MDIxMw==", "url": "https://github.com/apache/iceberg/pull/1769#discussion_r523280213", "bodyText": "I see what you mean. I don't think it is a big deal if that happens, but we can always add a callback to pass the snapshot ID that will be used back to this function.", "author": "rdblue", "createdAt": "2020-11-13T23:15:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzE4MDk5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI4MzIxMw==", "url": "https://github.com/apache/iceberg/pull/1769#discussion_r523283213", "bodyText": "I have a separate issue to track this. Let's address it later.", "author": "aokolnychyi", "createdAt": "2020-11-13T23:26:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzE4MDk5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzE4MTIxNA==", "url": "https://github.com/apache/iceberg/pull/1769#discussion_r523181214", "bodyText": "I think this truncation should be fine.", "author": "aokolnychyi", "createdAt": "2020-11-13T19:36:21Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/procedures/RollbackToTimestampProcedure.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.procedures;\n+\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.spark.procedures.SparkProcedures.ProcedureBuilder;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils;\n+import org.apache.spark.sql.connector.catalog.TableCatalog;\n+import org.apache.spark.sql.connector.iceberg.catalog.ProcedureParameter;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.Metadata;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * A procedure that rollbacks a table to a given point in time.\n+ */\n+class RollbackToTimestampProcedure extends BaseProcedure {\n+\n+  private static final ProcedureParameter[] PARAMETERS = new ProcedureParameter[]{\n+      ProcedureParameter.required(\"namespace\", DataTypes.StringType),\n+      ProcedureParameter.required(\"table\", DataTypes.StringType),\n+      ProcedureParameter.required(\"timestamp\", DataTypes.TimestampType)\n+  };\n+\n+  private static final StructType OUTPUT_TYPE = new StructType(new StructField[]{\n+      new StructField(\"previous_snapshot_id\", DataTypes.LongType, false, Metadata.empty()),\n+      new StructField(\"current_snapshot_id\", DataTypes.LongType, false, Metadata.empty())\n+  });\n+\n+  public static ProcedureBuilder builder() {\n+    return new BaseProcedure.Builder<RollbackToTimestampProcedure>() {\n+      @Override\n+      protected RollbackToTimestampProcedure doBuild() {\n+        return new RollbackToTimestampProcedure(tableCatalog());\n+      }\n+    };\n+  }\n+\n+  private RollbackToTimestampProcedure(TableCatalog catalog) {\n+    super(catalog);\n+  }\n+\n+  @Override\n+  public ProcedureParameter[] parameters() {\n+    return PARAMETERS;\n+  }\n+\n+  @Override\n+  public StructType outputType() {\n+    return OUTPUT_TYPE;\n+  }\n+\n+  @Override\n+  public InternalRow[] call(InternalRow args) {\n+    String namespace = args.getString(0);\n+    String tableName = args.getString(1);\n+    // timestamps in Spark have nanosecond precision so this conversion is lossy\n+    long timestampMillis = DateTimeUtils.toMillis(args.getLong(2));", "originalCommit": "74700a0450627f9aac9bede1efa79f1062768da1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzIzMDI0MA==", "url": "https://github.com/apache/iceberg/pull/1769#discussion_r523230240", "bodyText": "Minor: Some of the setup could be put into a @Before method.", "author": "rdblue", "createdAt": "2020-11-13T21:01:41Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestRollbackToTimestampProcedure.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.time.LocalDateTime;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.spark.sql.AnalysisException;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchProcedureException;\n+import org.junit.After;\n+import org.junit.Assume;\n+import org.junit.Test;\n+\n+public class TestRollbackToTimestampProcedure extends SparkExtensionsTestBase {\n+\n+  public TestRollbackToTimestampProcedure(String catalogName, String implementation, Map<String, String> config) {\n+    super(catalogName, implementation, config);\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+  }\n+\n+  @Test\n+  public void testRollbackToTimestampUsingPositionalArgs() throws InterruptedException {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+    String firstSnapshotTimestamp = LocalDateTime.now().toString();\n+\n+    Thread.sleep(1000);\n+\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    assertEquals(\"Should have expected rows\",\n+        ImmutableList.of(row(1L, \"a\"), row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+\n+    table.refresh();\n+\n+    Snapshot secondSnapshot = table.currentSnapshot();\n+\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.rollback_to_timestamp('%s', '%s', TIMESTAMP '%s')\",\n+        catalogName, tableIdent.namespace(), tableIdent.name(), firstSnapshotTimestamp);\n+\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(secondSnapshot.snapshotId(), firstSnapshot.snapshotId())),\n+        output);\n+\n+    assertEquals(\"Rollback must be successful\",\n+        ImmutableList.of(row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+  }\n+\n+  @Test\n+  public void testRollbackToTimestampUsingNamedArgs() throws InterruptedException {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+    String firstSnapshotTimestamp = LocalDateTime.now().toString();\n+\n+    Thread.sleep(1000);\n+\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    assertEquals(\"Should have expected rows\",\n+        ImmutableList.of(row(1L, \"a\"), row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+\n+    table.refresh();\n+\n+    Snapshot secondSnapshot = table.currentSnapshot();\n+\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.rollback_to_timestamp(timestamp => TIMESTAMP '%s', namespace => '%s', table => '%s')\",\n+        catalogName, firstSnapshotTimestamp, tableIdent.namespace(), tableIdent.name());\n+\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(secondSnapshot.snapshotId(), firstSnapshot.snapshotId())),\n+        output);\n+\n+    assertEquals(\"Rollback must be successful\",\n+        ImmutableList.of(row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+  }\n+\n+  @Test\n+  public void testRollbackToTimestampRefreshesRelationCache() throws InterruptedException {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+    String firstSnapshotTimestamp = LocalDateTime.now().toString();\n+\n+    Thread.sleep(1000);\n+\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    table.refresh();\n+\n+    Snapshot secondSnapshot = table.currentSnapshot();\n+\n+    Dataset<Row> query = spark.sql(\"SELECT * FROM \" + tableName + \" WHERE id = 1\");\n+    query.createOrReplaceTempView(\"tmp\");\n+\n+    spark.sql(\"CACHE TABLE tmp\");\n+\n+    assertEquals(\"View should have expected rows\",\n+        ImmutableList.of(row(1L, \"a\"), row(1L, \"a\")),\n+        sql(\"SELECT * FROM tmp\"));\n+\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.rollback_to_timestamp(namespace => '%s', table => '%s', timestamp => TIMESTAMP '%s')\",\n+        catalogName, tableIdent.namespace(), tableIdent.name(), firstSnapshotTimestamp);\n+\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(secondSnapshot.snapshotId(), firstSnapshot.snapshotId())),\n+        output);\n+\n+    assertEquals(\"View cache must be invalidated\",\n+        ImmutableList.of(row(1L, \"a\")),\n+        sql(\"SELECT * FROM tmp\"));\n+\n+    sql(\"UNCACHE TABLE tmp\");\n+  }\n+\n+  @Test\n+  public void testRollbackToTimestampWithQuotedIdentifiers() throws InterruptedException {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+    String firstSnapshotTimestamp = LocalDateTime.now().toString();", "originalCommit": "74700a0450627f9aac9bede1efa79f1062768da1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzIzMDUyNg==", "url": "https://github.com/apache/iceberg/pull/1769#discussion_r523230526", "bodyText": "Can we use a waitUntilAfter(firstSnapshot.timestampMillis()) method instead? Sleep causes tests to take longer.", "author": "rdblue", "createdAt": "2020-11-13T21:02:21Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestRollbackToTimestampProcedure.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.time.LocalDateTime;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.spark.sql.AnalysisException;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchProcedureException;\n+import org.junit.After;\n+import org.junit.Assume;\n+import org.junit.Test;\n+\n+public class TestRollbackToTimestampProcedure extends SparkExtensionsTestBase {\n+\n+  public TestRollbackToTimestampProcedure(String catalogName, String implementation, Map<String, String> config) {\n+    super(catalogName, implementation, config);\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+  }\n+\n+  @Test\n+  public void testRollbackToTimestampUsingPositionalArgs() throws InterruptedException {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+    String firstSnapshotTimestamp = LocalDateTime.now().toString();\n+\n+    Thread.sleep(1000);\n+\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    assertEquals(\"Should have expected rows\",\n+        ImmutableList.of(row(1L, \"a\"), row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+\n+    table.refresh();\n+\n+    Snapshot secondSnapshot = table.currentSnapshot();\n+\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.rollback_to_timestamp('%s', '%s', TIMESTAMP '%s')\",\n+        catalogName, tableIdent.namespace(), tableIdent.name(), firstSnapshotTimestamp);\n+\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(secondSnapshot.snapshotId(), firstSnapshot.snapshotId())),\n+        output);\n+\n+    assertEquals(\"Rollback must be successful\",\n+        ImmutableList.of(row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+  }\n+\n+  @Test\n+  public void testRollbackToTimestampUsingNamedArgs() throws InterruptedException {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+    String firstSnapshotTimestamp = LocalDateTime.now().toString();\n+\n+    Thread.sleep(1000);\n+\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    assertEquals(\"Should have expected rows\",\n+        ImmutableList.of(row(1L, \"a\"), row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+\n+    table.refresh();\n+\n+    Snapshot secondSnapshot = table.currentSnapshot();\n+\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.rollback_to_timestamp(timestamp => TIMESTAMP '%s', namespace => '%s', table => '%s')\",\n+        catalogName, firstSnapshotTimestamp, tableIdent.namespace(), tableIdent.name());\n+\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(secondSnapshot.snapshotId(), firstSnapshot.snapshotId())),\n+        output);\n+\n+    assertEquals(\"Rollback must be successful\",\n+        ImmutableList.of(row(1L, \"a\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+  }\n+\n+  @Test\n+  public void testRollbackToTimestampRefreshesRelationCache() throws InterruptedException {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+    String firstSnapshotTimestamp = LocalDateTime.now().toString();\n+\n+    Thread.sleep(1000);", "originalCommit": "74700a0450627f9aac9bede1efa79f1062768da1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI3ODIyOA==", "url": "https://github.com/apache/iceberg/pull/1769#discussion_r523278228", "bodyText": "Done.", "author": "aokolnychyi", "createdAt": "2020-11-13T23:07:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzIzMDUyNg=="}], "type": "inlineReview"}, {"oid": "8d1d2fb2404d24d7a63ba20af0f79bb1db24af51", "url": "https://github.com/apache/iceberg/commit/8d1d2fb2404d24d7a63ba20af0f79bb1db24af51", "message": "Spark: Add RollbackToTimestampProcedure", "committedDate": "2020-11-14T00:59:17Z", "type": "commit"}, {"oid": "8d1d2fb2404d24d7a63ba20af0f79bb1db24af51", "url": "https://github.com/apache/iceberg/commit/8d1d2fb2404d24d7a63ba20af0f79bb1db24af51", "message": "Spark: Add RollbackToTimestampProcedure", "committedDate": "2020-11-14T00:59:17Z", "type": "forcePushed"}, {"oid": "4611900294604bfee243f408bce0ab15861e4050", "url": "https://github.com/apache/iceberg/commit/4611900294604bfee243f408bce0ab15861e4050", "message": "Merge branch 'master' into rollback-to-timestamp", "committedDate": "2020-11-14T01:06:47Z", "type": "commit"}]}