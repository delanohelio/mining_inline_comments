{"pr_number": 1874, "pr_title": "Spark: Add ExpireSnapshotsProcedure", "pr_createdAt": "2020-12-04T11:52:33Z", "pr_url": "https://github.com/apache/iceberg/pull/1874", "timeline": [{"oid": "e389de505c22cf998c09b5f72f601ed94b11c57b", "url": "https://github.com/apache/iceberg/commit/e389de505c22cf998c09b5f72f601ed94b11c57b", "message": "expire snapshot: add sql extension", "committedDate": "2020-12-04T10:36:01Z", "type": "commit"}, {"oid": "040b1f554b5413d64b4951bc45e1495e447856e3", "url": "https://github.com/apache/iceberg/commit/040b1f554b5413d64b4951bc45e1495e447856e3", "message": "add test for expire snapshot", "committedDate": "2020-12-04T10:40:32Z", "type": "commit"}, {"oid": "5b68c526e75ed82b07e146fefdec1c0e7cd593eb", "url": "https://github.com/apache/iceberg/commit/5b68c526e75ed82b07e146fefdec1c0e7cd593eb", "message": "More tests and some changes", "committedDate": "2020-12-04T11:49:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjExMzA4OA==", "url": "https://github.com/apache/iceberg/pull/1874#discussion_r536113088", "bodyText": "Not sure we need some of the more generic checks here, like testing if named and pos args cannot be mixed", "author": "RussellSpitzer", "createdAt": "2020-12-04T13:50:55Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestExpireSnapshotsProcedure.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.sql.Timestamp;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.exceptions.ValidationException;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.Iterables;\n+import org.apache.spark.sql.AnalysisException;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchProcedureException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableProperties.GC_ENABLED;\n+\n+public class TestExpireSnapshotsProcedure extends SparkExtensionsTestBase {\n+\n+  public TestExpireSnapshotsProcedure(String catalogName, String implementation, Map<String, String> config) {\n+    super(catalogName, implementation, config);\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+  }\n+\n+  @Test\n+  public void testExpireSnapshotsInEmptyTable() {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.expire_snapshots('%s', '%s')\",\n+        catalogName, tableIdent.namespace(), tableIdent.name());\n+    assertEquals(\"Should not delete any files\", ImmutableList.of(row(0L, 0L, 0L)), output);\n+  }\n+\n+  @Test\n+  public void testExpireSnapshotsUsingPositionalArgs() {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+\n+    waitUntilAfter(firstSnapshot.timestampMillis());\n+\n+    sql(\"INSERT INTO TABLE %s VALUES (2, 'b')\", tableName);\n+\n+    table.refresh();\n+\n+    Snapshot secondSnapshot = table.currentSnapshot();\n+    Timestamp secondSnapshotTimestamp = Timestamp.from(Instant.ofEpochMilli(secondSnapshot.timestampMillis()));\n+\n+    Assert.assertEquals(\"Should be 2 snapshots\", 2, Iterables.size(table.snapshots()));\n+\n+    // expire without retainLast param\n+    List<Object[]> output1 = sql(\n+        \"CALL %s.system.expire_snapshots('%s', '%s', TIMESTAMP '%s')\",\n+        catalogName, tableIdent.namespace(), tableIdent.name(), secondSnapshotTimestamp);\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(0L, 0L, 1L)),\n+        output1);\n+\n+    table.refresh();\n+\n+    Assert.assertEquals(\"Should expire one snapshot\", 1, Iterables.size(table.snapshots()));\n+\n+    sql(\"INSERT OVERWRITE %s VALUES (3, 'c')\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (4, 'd')\", tableName);\n+    assertEquals(\"Should have expected rows\",\n+        ImmutableList.of(row(3L, \"c\"), row(4L, \"d\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+\n+    table.refresh();\n+\n+    waitUntilAfter(table.currentSnapshot().timestampMillis());\n+\n+    Timestamp currentTimestamp = Timestamp.from(Instant.ofEpochMilli(System.currentTimeMillis()));\n+\n+    Assert.assertEquals(\"Should be 3 snapshots\", 3, Iterables.size(table.snapshots()));\n+\n+    // expire with retainLast param\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.expire_snapshots('%s', '%s', TIMESTAMP '%s', 2)\",\n+        catalogName, tableIdent.namespace(), tableIdent.name(), currentTimestamp);\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(2L, 2L, 1L)),\n+        output);\n+  }\n+\n+  @Test\n+  public void testExpireSnapshotUsingNamedArgs() {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (2, 'b')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+\n+    Assert.assertEquals(\"Should be 2 snapshots\", 2, Iterables.size(table.snapshots()));\n+\n+    waitUntilAfter(table.currentSnapshot().timestampMillis());\n+\n+    Timestamp currentTimestamp = Timestamp.from(Instant.ofEpochMilli(System.currentTimeMillis()));\n+\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.expire_snapshots('%s', '%s', TIMESTAMP '%s', 1)\",\n+        catalogName, tableIdent.namespace(), tableIdent.name(), currentTimestamp);\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(0L, 0L, 1L)),\n+        output);\n+  }\n+\n+  @Test\n+  public void testExpireSnapshotsGCDisabled() {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+\n+    sql(\"ALTER TABLE %s SET TBLPROPERTIES ('%s' 'false')\", tableName, GC_ENABLED);\n+\n+    AssertHelpers.assertThrows(\"Should reject call\",\n+        ValidationException.class, \"Cannot expire snapshots: GC is disabled\",\n+        () -> sql(\"CALL %s.system.expire_snapshots('%s', '%s')\", catalogName,\n+            tableIdent.namespace(), tableIdent.name()));\n+  }\n+\n+  @Test\n+  public void testInvalidExpireSnapshotsCases() {\n+    AssertHelpers.assertThrows(\"Should not allow mixed args\",", "originalCommit": "5b68c526e75ed82b07e146fefdec1c0e7cd593eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjEzOTg1Ng==", "url": "https://github.com/apache/iceberg/pull/1874#discussion_r536139856", "bodyText": "It is a bit weird but we have such checks in other procedures so I added for consistency.", "author": "aokolnychyi", "createdAt": "2020-12-04T14:30:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjExMzA4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjE1MDUxOQ==", "url": "https://github.com/apache/iceberg/pull/1874#discussion_r536150519", "bodyText": "Sounds fine, It doesn't really matter since they run so quickly.", "author": "RussellSpitzer", "createdAt": "2020-12-04T14:46:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjExMzA4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjExNTI0OA==", "url": "https://github.com/apache/iceberg/pull/1874#discussion_r536115248", "bodyText": "So we are going with the action default expire time? Just checking because I thougt some folks wanted that changed", "author": "RussellSpitzer", "createdAt": "2020-12-04T13:54:19Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/procedures/ExpireSnapshotsProcedure.java", "diffHunk": "@@ -96,6 +75,36 @@ public StructType outputType() {\n     return OUTPUT_TYPE;\n   }\n \n+  @Override\n+  public InternalRow[] call(InternalRow args) {\n+    String namespace = args.getString(0);\n+    String tableName = args.getString(1);\n+    Long olderThanMillis = args.isNullAt(2) ? null : DateTimeUtils.toMillis(args.getLong(2));\n+    Integer retainLastNum = args.isNullAt(3) ? null : args.getInt(3);\n+\n+    return modifyIcebergTable(namespace, tableName, table -> {\n+      Actions actions = Actions.forTable(table);\n+\n+      ExpireSnapshotsAction action = actions.expireSnapshots();\n+\n+      if (olderThanMillis != null) {\n+        action.expireOlderThan(olderThanMillis);", "originalCommit": "5b68c526e75ed82b07e146fefdec1c0e7cd593eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjEzOTM5Nw==", "url": "https://github.com/apache/iceberg/pull/1874#discussion_r536139397", "bodyText": "The action delegates to ExpireSnapshots table API that, in turn, respects the default table props we added recently.", "author": "aokolnychyi", "createdAt": "2020-12-04T14:30:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjExNTI0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjE1MDk2NA==", "url": "https://github.com/apache/iceberg/pull/1874#discussion_r536150964", "bodyText": "Ah! Excellent, I forgot about that", "author": "RussellSpitzer", "createdAt": "2020-12-04T14:46:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjExNTI0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjIzNjEyNg==", "url": "https://github.com/apache/iceberg/pull/1874#discussion_r536236126", "bodyText": "Named args?", "author": "rdblue", "createdAt": "2020-12-04T16:49:28Z", "path": "spark3-extensions/src/test/java/org/apache/iceberg/spark/extensions/TestExpireSnapshotsProcedure.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.extensions;\n+\n+import java.sql.Timestamp;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.exceptions.ValidationException;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.Iterables;\n+import org.apache.spark.sql.AnalysisException;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchProcedureException;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableProperties.GC_ENABLED;\n+\n+public class TestExpireSnapshotsProcedure extends SparkExtensionsTestBase {\n+\n+  public TestExpireSnapshotsProcedure(String catalogName, String implementation, Map<String, String> config) {\n+    super(catalogName, implementation, config);\n+  }\n+\n+  @After\n+  public void removeTables() {\n+    sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+  }\n+\n+  @Test\n+  public void testExpireSnapshotsInEmptyTable() {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.expire_snapshots('%s', '%s')\",\n+        catalogName, tableIdent.namespace(), tableIdent.name());\n+    assertEquals(\"Should not delete any files\", ImmutableList.of(row(0L, 0L, 0L)), output);\n+  }\n+\n+  @Test\n+  public void testExpireSnapshotsUsingPositionalArgs() {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+    Snapshot firstSnapshot = table.currentSnapshot();\n+\n+    waitUntilAfter(firstSnapshot.timestampMillis());\n+\n+    sql(\"INSERT INTO TABLE %s VALUES (2, 'b')\", tableName);\n+\n+    table.refresh();\n+\n+    Snapshot secondSnapshot = table.currentSnapshot();\n+    Timestamp secondSnapshotTimestamp = Timestamp.from(Instant.ofEpochMilli(secondSnapshot.timestampMillis()));\n+\n+    Assert.assertEquals(\"Should be 2 snapshots\", 2, Iterables.size(table.snapshots()));\n+\n+    // expire without retainLast param\n+    List<Object[]> output1 = sql(\n+        \"CALL %s.system.expire_snapshots('%s', '%s', TIMESTAMP '%s')\",\n+        catalogName, tableIdent.namespace(), tableIdent.name(), secondSnapshotTimestamp);\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(0L, 0L, 1L)),\n+        output1);\n+\n+    table.refresh();\n+\n+    Assert.assertEquals(\"Should expire one snapshot\", 1, Iterables.size(table.snapshots()));\n+\n+    sql(\"INSERT OVERWRITE %s VALUES (3, 'c')\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (4, 'd')\", tableName);\n+    assertEquals(\"Should have expected rows\",\n+        ImmutableList.of(row(3L, \"c\"), row(4L, \"d\")),\n+        sql(\"SELECT * FROM %s ORDER BY id\", tableName));\n+\n+    table.refresh();\n+\n+    waitUntilAfter(table.currentSnapshot().timestampMillis());\n+\n+    Timestamp currentTimestamp = Timestamp.from(Instant.ofEpochMilli(System.currentTimeMillis()));\n+\n+    Assert.assertEquals(\"Should be 3 snapshots\", 3, Iterables.size(table.snapshots()));\n+\n+    // expire with retainLast param\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.expire_snapshots('%s', '%s', TIMESTAMP '%s', 2)\",\n+        catalogName, tableIdent.namespace(), tableIdent.name(), currentTimestamp);\n+    assertEquals(\"Procedure output must match\",\n+        ImmutableList.of(row(2L, 2L, 1L)),\n+        output);\n+  }\n+\n+  @Test\n+  public void testExpireSnapshotUsingNamedArgs() {\n+    sql(\"CREATE TABLE %s (id bigint NOT NULL, data string) USING iceberg\", tableName);\n+\n+    sql(\"INSERT INTO TABLE %s VALUES (1, 'a')\", tableName);\n+    sql(\"INSERT INTO TABLE %s VALUES (2, 'b')\", tableName);\n+\n+    Table table = validationCatalog.loadTable(tableIdent);\n+\n+    Assert.assertEquals(\"Should be 2 snapshots\", 2, Iterables.size(table.snapshots()));\n+\n+    waitUntilAfter(table.currentSnapshot().timestampMillis());\n+\n+    Timestamp currentTimestamp = Timestamp.from(Instant.ofEpochMilli(System.currentTimeMillis()));\n+\n+    List<Object[]> output = sql(\n+        \"CALL %s.system.expire_snapshots('%s', '%s', TIMESTAMP '%s', 1)\",", "originalCommit": "5b68c526e75ed82b07e146fefdec1c0e7cd593eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI1ODEyMA==", "url": "https://github.com/apache/iceberg/pull/1874#discussion_r536258120", "bodyText": "Done.", "author": "aokolnychyi", "createdAt": "2020-12-04T17:27:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjIzNjEyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjIzNzk3Mw==", "url": "https://github.com/apache/iceberg/pull/1874#discussion_r536237973", "bodyText": "Don't we usually name columns like this with _count instead of num_? I would expect deleted_data_files_count, like we have added_data_files_count in manifests or record_count in data files.", "author": "rdblue", "createdAt": "2020-12-04T16:52:11Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/procedures/ExpireSnapshotsProcedure.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.procedures;\n+\n+import org.apache.iceberg.actions.Actions;\n+import org.apache.iceberg.actions.ExpireSnapshotsAction;\n+import org.apache.iceberg.actions.ExpireSnapshotsActionResult;\n+import org.apache.iceberg.spark.procedures.SparkProcedures.ProcedureBuilder;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils;\n+import org.apache.spark.sql.connector.catalog.TableCatalog;\n+import org.apache.spark.sql.connector.iceberg.catalog.ProcedureParameter;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.Metadata;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * A procedure that expires snapshots in a table.\n+ *\n+ * @see Actions#expireSnapshots()\n+ */\n+public class ExpireSnapshotsProcedure extends BaseProcedure {\n+\n+  private static final ProcedureParameter[] PARAMETERS = new ProcedureParameter[] {\n+      ProcedureParameter.required(\"namespace\", DataTypes.StringType),\n+      ProcedureParameter.required(\"table\", DataTypes.StringType),\n+      ProcedureParameter.optional(\"older_than\", DataTypes.TimestampType),\n+      ProcedureParameter.optional(\"retain_last\", DataTypes.IntegerType)\n+  };\n+\n+  private static final StructType OUTPUT_TYPE = new StructType(new StructField[]{\n+      new StructField(\"num_deleted_data_files\", DataTypes.LongType, true, Metadata.empty()),\n+      new StructField(\"num_deleted_manifest_files\", DataTypes.LongType, true, Metadata.empty()),\n+      new StructField(\"num_deleted_manifest_lists\", DataTypes.LongType, true, Metadata.empty())", "originalCommit": "5b68c526e75ed82b07e146fefdec1c0e7cd593eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI1NjExOA==", "url": "https://github.com/apache/iceberg/pull/1874#discussion_r536256118", "bodyText": "Done.", "author": "aokolnychyi", "createdAt": "2020-12-04T17:24:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjIzNzk3Mw=="}], "type": "inlineReview"}, {"oid": "440a9f9dbc0ed1792295ca158cd1efce2b978e2a", "url": "https://github.com/apache/iceberg/commit/440a9f9dbc0ed1792295ca158cd1efce2b978e2a", "message": "Minor updates", "committedDate": "2020-12-04T17:11:03Z", "type": "commit"}]}