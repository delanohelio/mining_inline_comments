{"pr_number": 1843, "pr_title": "Support for file paths in SparkCatalogs via HadoopTables", "pr_createdAt": "2020-11-27T13:00:27Z", "pr_url": "https://github.com/apache/iceberg/pull/1843", "timeline": [{"oid": "2acf7ffa7fb64dfcd7692f9fd24fa92c4d7ca6aa", "url": "https://github.com/apache/iceberg/commit/2acf7ffa7fb64dfcd7692f9fd24fa92c4d7ca6aa", "message": "fix visibility", "committedDate": "2020-11-30T17:28:41Z", "type": "forcePushed"}, {"oid": "d915653ebce5a6cb1c0fe1ff37d735c8dda6868b", "url": "https://github.com/apache/iceberg/commit/d915653ebce5a6cb1c0fe1ff37d735c8dda6868b", "message": "fix build", "committedDate": "2020-12-01T14:24:36Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY0NzI1MQ==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r533647251", "bodyText": "I think this is okay, but if staging isn't supported then a path identifier should fail instead of going ahead without using the path. Otherwise, this will attempt to create a table in the Iceberg catalog with a crazy name, which would probably fail.", "author": "rdblue", "createdAt": "2020-12-01T18:55:45Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -165,6 +179,7 @@ public StagedTable stageCreate(Identifier ident, StructType schema, Transform[]\n                                  Map<String, String> properties) throws TableAlreadyExistsException {\n     Schema icebergSchema = SparkSchemaUtil.convert(schema);\n     try {\n+      // can't stage a hadoop table", "originalCommit": "14fa86f36df62588c98a9fbc9a4a29f797d4f07b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY1MjY2NA==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r533652664", "bodyText": "After thinking about this a little more, I think we will need to support some form of staging for Hadoop tables. Because this catalog implements the atomic operation mix-in, the staging calls will be used for all CTAS plans. Using SupportsCatalogOptions would mean that save() gets turned into a CTAS. So if we don't want the existing creates to fail, we have to support a staged table.\nWe can do that in a couple of ways. First, we could create a table builder based on HadoopCatalogTableBuilder that supports a location. Second, we could reuse the fake staged table from the session catalog (for non-Iceberg tables). I'd prefer to create a builder that can construct the transactions for path tables. We could add it to HadoopTables.", "author": "rdblue", "createdAt": "2020-12-01T19:04:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY0NzI1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDE3MTU0MA==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r534171540", "bodyText": "I'd prefer to create a builder that can construct the transactions for path tables. We could add it to HadoopTables.\n\nAgreed. Added in most recent update", "author": "rymurr", "createdAt": "2020-12-02T13:37:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY0NzI1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjM3MzI3OQ==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536373279", "bodyText": "How about isValidLocation?", "author": "rdblue", "createdAt": "2020-12-04T20:53:27Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -209,4 +278,35 @@ public void setConf(Configuration conf) {\n   public Configuration getConf() {\n     return conf;\n   }\n+\n+\n+  /**\n+   * Check to see if the location is a potential Hadoop table by checking if its an absolute path on some filesystem.\n+   */\n+  public static boolean isHadoopTable(String location) {", "originalCommit": "57685ba7ace1053d6189fa032ee3c9b68984dd50", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjM3NDEzOQ==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536374139", "bodyText": "If this uses a session, then it should be identified when the catalog is created and stored as an instance field. Catalogs are specific to a SQL session, so they should not use the active session except for in initialization. After that, the same session should always be used.", "author": "rdblue", "createdAt": "2020-12-04T20:55:13Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -132,10 +134,17 @@ protected TableIdentifier buildIdentifier(Identifier identifier) {\n     return TableIdentifier.of(Namespace.of(identifier.namespace()), identifier.name());\n   }\n \n+  private String[] currentNamespace() {\n+    return SparkSession.active().sessionState().catalogManager().currentNamespace();", "originalCommit": "57685ba7ace1053d6189fa032ee3c9b68984dd50", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjYzMzgxNw==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536633817", "bodyText": "fixed. Just for my learning why is it ok to get hadoop config from active session but not the current namespace? I have been following the commonly used SparkSession.active().sessionState().newHadoopConf() pattern", "author": "rymurr", "createdAt": "2020-12-05T09:55:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjM3NDEzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkyOTUxMw==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536929513", "bodyText": "This should throw an exception if it can't rename, right?", "author": "rdblue", "createdAt": "2020-12-06T01:31:15Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -257,6 +317,7 @@ public boolean dropTable(Identifier ident) {\n   @Override\n   public void renameTable(Identifier from, Identifier to) throws NoSuchTableException, TableAlreadyExistsException {\n     try {\n+      // can't rename hadoop tables", "originalCommit": "bd39f71606de90a165aa4d1696017a5c77bfc628", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkzMTEzMA==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536931130", "bodyText": "I think this should have a method like checkNotPathIdentifier that throws an IllegalArgumentException if a PathIdentifier is passed, so that we can ensure that they aren't passed to methods that don't support paths.", "author": "rdblue", "createdAt": "2020-12-06T01:42:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkyOTUxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzM4NDI0Mg==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537384242", "bodyText": "done", "author": "rymurr", "createdAt": "2020-12-07T10:13:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkyOTUxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkyOTYzNA==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536929634", "bodyText": "There should also be no way to pass a path as a namespace.", "author": "rdblue", "createdAt": "2020-12-06T01:31:52Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -268,14 +329,19 @@ public void renameTable(Identifier from, Identifier to) throws NoSuchTableExcept\n   @Override\n   public void invalidateTable(Identifier ident) {\n     try {\n-      icebergCatalog.loadTable(buildIdentifier(ident)).refresh();\n+      TableIdentifier tableIdentifier = buildIdentifier(ident);\n+      Table table = isPathIdentifier(ident) ?\n+          tables.load(tableIdentifier.name()) :\n+          icebergCatalog.loadTable(tableIdentifier);\n+      table.refresh();\n     } catch (org.apache.iceberg.exceptions.NoSuchTableException ignored) {\n       // ignore if the table doesn't exist, it is not cached\n     }\n   }\n \n   @Override\n   public Identifier[] listTables(String[] namespace) {\n+    // no way to identify if this is a path and we should use tables instead of catalog.", "originalCommit": "bd39f71606de90a165aa4d1696017a5c77bfc628", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzM4NTEyOQ==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537385129", "bodyText": "not sure how to identify a path here? Single element w/ '/' in it? Seems arbitrary. The HadoopCatalog treats directory names as namespaces so there would be no way to identify that here.", "author": "rymurr", "createdAt": "2020-12-07T10:14:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkyOTYzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc2MTk0Ng==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537761946", "bodyText": "Sorry, I wasn't very clear. If anything calls this, then it went through a path for normal identifiers. So I don't think that there is a need to worry about paths here because there isn't a way to pass a path in here.", "author": "rdblue", "createdAt": "2020-12-07T19:15:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkyOTYzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc2NTM2Ng==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537765366", "bodyText": "Ah I see, have removed the comment.", "author": "rymurr", "createdAt": "2020-12-07T19:20:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkyOTYzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkyOTY2OQ==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536929669", "bodyText": "Nit: unnecessary newline.", "author": "rdblue", "createdAt": "2020-12-06T01:32:03Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -453,4 +520,5 @@ private static void commitChanges(Table table, SetProperty setLocation, SetPrope\n \n     transaction.commitTransaction();\n   }\n+", "originalCommit": "bd39f71606de90a165aa4d1696017a5c77bfc628", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzM4NTE4NA==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537385184", "bodyText": "removed", "author": "rymurr", "createdAt": "2020-12-07T10:14:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkyOTY2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkzMDg0MA==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536930840", "bodyText": "Can this use TableBuilder instead? That would make the SparkCatalog implementation a lot cleaner because the code to configure the builder could be shared.\nI opened #1879 because tests would fail unless the builder is also supported in CachingCatalog.", "author": "rdblue", "createdAt": "2020-12-06T01:40:30Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -200,6 +197,76 @@ TableOperations newTableOps(String location) {\n     }\n   }\n \n+  private TableMetadata tableMetadata(Schema schema, PartitionSpec spec, SortOrder order,\n+                                      Map<String, String> properties, String location) {\n+    Preconditions.checkNotNull(schema, \"A table schema is required\");\n+\n+    Map<String, String> tableProps = properties == null ? ImmutableMap.of() : properties;\n+    PartitionSpec partitionSpec = spec == null ? PartitionSpec.unpartitioned() : spec;\n+    SortOrder sortOrder = order == null ? SortOrder.unsorted() : order;\n+    return TableMetadata.newTableMetadata(schema, partitionSpec, sortOrder, location, tableProps);\n+  }\n+\n+  /**\n+   * Start a transaction to create a table.\n+   *\n+   * @param identifier a location for the table\n+   * @param schema a schema\n+   * @param spec a partition spec\n+   * @param properties a string map of table properties\n+   * @return a {@link Transaction} to create the table\n+   * @throws AlreadyExistsException if the table already exists\n+   */\n+  public Transaction newCreateTableTransaction(", "originalCommit": "bd39f71606de90a165aa4d1696017a5c77bfc628", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzM4NjIzMA==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537386230", "bodyText": "fixed. Will rebase once #1879 is merged. I also prefer the TableBuilder pattern, much cleaner.", "author": "rymurr", "createdAt": "2020-12-07T10:16:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkzMDg0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkzMTUxNg==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536931516", "bodyText": "I think that the namespace should be the location, not an array of path parts. This would create really weird namespaces, like [\"s3:\", \"\", \"bucket\", \"path\", \"to\"].", "author": "rdblue", "createdAt": "2020-12-06T01:45:13Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/PathIdentifier.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import java.util.List;\n+import org.apache.iceberg.relocated.com.google.common.base.Splitter;\n+import org.apache.iceberg.relocated.com.google.common.collect.Iterables;\n+import org.apache.spark.sql.connector.catalog.Identifier;\n+\n+public class PathIdentifier implements Identifier {\n+  private final String[] namespace;\n+  private final String location;\n+  private final String name;\n+\n+  public PathIdentifier(String location) {\n+    this.location = location;\n+    List<String> pathParts = Splitter.on(\"/\").splitToList(location);\n+    name = Iterables.getLast(pathParts);\n+    namespace = pathParts.size() > 1 ? pathParts.subList(0, pathParts.size() - 1).toArray(new String[0]) :\n+        new String[0];", "originalCommit": "bd39f71606de90a165aa4d1696017a5c77bfc628", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzM4ODczMw==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537388733", "bodyText": "agreed that it shouldn't be [\"s3:\", \"\", \"bucket\", \"path\", \"to\"] but I am not sure why it would be the full location. Then we have namespace returning {location} the new public method location returning location and the name method returning just the filename. To me namespace + name should equal location. I have updated this patch w/ my suggestion but happy to revert.", "author": "rymurr", "createdAt": "2020-12-07T10:19:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkzMTUxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzQwNjEzMw==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537406133", "bodyText": "Shouldn't namespace be just iceberg and name location to match built-in sources?", "author": "aokolnychyi", "createdAt": "2020-12-07T10:45:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkzMTUxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzQwODI3Mg==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537408272", "bodyText": "I prefer @aokolnychyi's suggestion over splitting filename from directories. Then we dont have the extra location method on PathIdentifier too.", "author": "rymurr", "createdAt": "2020-12-07T10:49:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkzMTUxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc1ODA0OQ==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537758049", "bodyText": "Shouldn't namespace be just iceberg and name location to match built-in sources?\n\nI don't think so. Those identifiers would not be passed to Iceberg as PathIdentifier so there isn't a strong reason to make Iceberg's PathIdentifier use the same convention. They are all \"iceberg\" identifiers.\n\nTo me namespace + name should equal location.\n\nI'm fine either way. I do think that it makes sense to omit it from the namespace ([\"s3://bucket/path/to\"] and \"table\"). The main requirement is that the location should be available unmodified when this is used.\nSounds like we agree that the table name should be the last directory name to make the subquery alias work.", "author": "rdblue", "createdAt": "2020-12-07T19:09:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkzMTUxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc2MzQwMQ==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537763401", "bodyText": "cool, have left it as is. Thanks for the pointer to subquery alias!", "author": "rymurr", "createdAt": "2020-12-07T19:17:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkzMTUxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkzMTcwMQ==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r536931701", "bodyText": "This should be tableIdentifier.location() right?", "author": "rdblue", "createdAt": "2020-12-06T01:46:38Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -164,13 +183,24 @@ public SparkTable createTable(Identifier ident, StructType schema,\n   public StagedTable stageCreate(Identifier ident, StructType schema, Transform[] transforms,\n                                  Map<String, String> properties) throws TableAlreadyExistsException {\n     Schema icebergSchema = SparkSchemaUtil.convert(schema);\n+    TableIdentifier tableIdentifier = buildIdentifier(ident);\n     try {\n-      return new StagedSparkTable(icebergCatalog.newCreateTableTransaction(\n-          buildIdentifier(ident),\n-          icebergSchema,\n-          Spark3Util.toPartitionSpec(icebergSchema, transforms),\n-          properties.get(\"location\"),\n-          Spark3Util.rebuildCreateProperties(properties)));\n+      Transaction transaction;\n+      if (isPathIdentifier(ident)) {\n+        transaction = tables.newCreateTableTransaction(\n+            tableIdentifier.name(),", "originalCommit": "bd39f71606de90a165aa4d1696017a5c77bfc628", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzM4ODg4Mw==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537388883", "bodyText": "yes, fixed.", "author": "rymurr", "createdAt": "2020-12-07T10:20:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkzMTcwMQ=="}], "type": "inlineReview"}, {"oid": "c9589f8645950dc8d9723f8ca251f6d887fd5bf7", "url": "https://github.com/apache/iceberg/commit/c9589f8645950dc8d9723f8ca251f6d887fd5bf7", "message": "wip: create and drop support for file paths\n\ncloses #1306", "committedDate": "2020-12-07T18:36:43Z", "type": "commit"}, {"oid": "36b31ef063675c2848fddfe27ec039613f2ef67c", "url": "https://github.com/apache/iceberg/commit/36b31ef063675c2848fddfe27ec039613f2ef67c", "message": "fix visibility", "committedDate": "2020-12-07T18:36:44Z", "type": "commit"}, {"oid": "78bfda94b0d6b5aba71798f101e3354cefd91298", "url": "https://github.com/apache/iceberg/commit/78bfda94b0d6b5aba71798f101e3354cefd91298", "message": "fix checkstyle", "committedDate": "2020-12-07T18:36:45Z", "type": "commit"}, {"oid": "71c69de631a89752e76091cd5f6e5f4c82f8880e", "url": "https://github.com/apache/iceberg/commit/71c69de631a89752e76091cd5f6e5f4c82f8880e", "message": "skip `DROP` if session catalog and add ALTER", "committedDate": "2020-12-07T18:36:46Z", "type": "commit"}, {"oid": "2a1d19aa07a890767925198b3c4e20cdf8027c3a", "url": "https://github.com/apache/iceberg/commit/2a1d19aa07a890767925198b3c4e20cdf8027c3a", "message": "remove HadoopDelegatedCatalog.java", "committedDate": "2020-12-07T18:36:47Z", "type": "commit"}, {"oid": "d725841b68e31b7ba57293aa2ae1120b086c6133", "url": "https://github.com/apache/iceberg/commit/d725841b68e31b7ba57293aa2ae1120b086c6133", "message": "revert change in visibility", "committedDate": "2020-12-07T18:36:48Z", "type": "commit"}, {"oid": "a5530cead241efae4d8a6f0652d84b3ef15b574e", "url": "https://github.com/apache/iceberg/commit/a5530cead241efae4d8a6f0652d84b3ef15b574e", "message": "fix build", "committedDate": "2020-12-07T18:36:49Z", "type": "commit"}, {"oid": "a5c6f95fb4a0a4d9a390ea0c8ba148b475728810", "url": "https://github.com/apache/iceberg/commit/a5c6f95fb4a0a4d9a390ea0c8ba148b475728810", "message": "fix checkstyle", "committedDate": "2020-12-07T18:36:50Z", "type": "commit"}, {"oid": "94e6b63b1aeaf8abe0bb31b5057f70ee6e133e54", "url": "https://github.com/apache/iceberg/commit/94e6b63b1aeaf8abe0bb31b5057f70ee6e133e54", "message": "use hadoop tables to validate", "committedDate": "2020-12-07T18:36:51Z", "type": "commit"}, {"oid": "8b392767e5540920914894995819839e954f7925", "url": "https://github.com/apache/iceberg/commit/8b392767e5540920914894995819839e954f7925", "message": "add transactions to hadoop tables", "committedDate": "2020-12-07T18:36:52Z", "type": "commit"}, {"oid": "068a4f9587ad0991f9e368a4f96633c83767cd96", "url": "https://github.com/apache/iceberg/commit/068a4f9587ad0991f9e368a4f96633c83767cd96", "message": "move check to hadoop tables and ensure path is absolute", "committedDate": "2020-12-07T18:36:53Z", "type": "commit"}, {"oid": "8710c1508f4344b84a427701176d82e89fd668e5", "url": "https://github.com/apache/iceberg/commit/8710c1508f4344b84a427701176d82e89fd668e5", "message": "clean up", "committedDate": "2020-12-07T18:36:53Z", "type": "commit"}, {"oid": "dfb9e2c35ab31d40b5b425a8a15cd8ae9c246581", "url": "https://github.com/apache/iceberg/commit/dfb9e2c35ab31d40b5b425a8a15cd8ae9c246581", "message": "respect default catalog if added", "committedDate": "2020-12-07T18:36:54Z", "type": "commit"}, {"oid": "fbba2c15fe186cbf7f7694af52f2883361161d09", "url": "https://github.com/apache/iceberg/commit/fbba2c15fe186cbf7f7694af52f2883361161d09", "message": "address code review commends and reduce scope of change", "committedDate": "2020-12-07T18:36:55Z", "type": "commit"}, {"oid": "46d5fb7360c32ff7d1b25555786440f7f3d61885", "url": "https://github.com/apache/iceberg/commit/46d5fb7360c32ff7d1b25555786440f7f3d61885", "message": "address code review and simplify", "committedDate": "2020-12-07T18:36:56Z", "type": "commit"}, {"oid": "46d5fb7360c32ff7d1b25555786440f7f3d61885", "url": "https://github.com/apache/iceberg/commit/46d5fb7360c32ff7d1b25555786440f7f3d61885", "message": "address code review and simplify", "committedDate": "2020-12-07T18:36:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzczODU0Mg==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537738542", "bodyText": "I think this should validate that the location matches the one passed to create the builder. If this is a different location, it can't just be ignored.", "author": "rdblue", "createdAt": "2020-12-07T18:40:20Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -200,6 +193,162 @@ TableOperations newTableOps(String location) {\n     }\n   }\n \n+  private TableMetadata tableMetadata(Schema schema, PartitionSpec spec, SortOrder order,\n+                                      Map<String, String> properties, String location) {\n+    Preconditions.checkNotNull(schema, \"A table schema is required\");\n+\n+    Map<String, String> tableProps = properties == null ? ImmutableMap.of() : properties;\n+    PartitionSpec partitionSpec = spec == null ? PartitionSpec.unpartitioned() : spec;\n+    SortOrder sortOrder = order == null ? SortOrder.unsorted() : order;\n+    return TableMetadata.newTableMetadata(schema, partitionSpec, sortOrder, location, tableProps);\n+  }\n+\n+  /**\n+   * Start a transaction to create a table.\n+   *\n+   * @param location a location for the table\n+   * @param schema a schema\n+   * @param spec a partition spec\n+   * @param properties a string map of table properties\n+   * @return a {@link Transaction} to create the table\n+   * @throws AlreadyExistsException if the table already exists\n+   */\n+  public Transaction newCreateTableTransaction(\n+      String location,\n+      Schema schema,\n+      PartitionSpec spec,\n+      Map<String, String> properties) {\n+    return buildTable(location, schema).withPartitionSpec(spec).withProperties(properties).createTransaction();\n+  }\n+\n+  /**\n+   * Start a transaction to replace a table.\n+   *\n+   * @param location a location for the table\n+   * @param schema a schema\n+   * @param spec a partition spec\n+   * @param properties a string map of table properties\n+   * @param orCreate whether to create the table if not exists\n+   * @return a {@link Transaction} to replace the table\n+   * @throws NoSuchTableException if the table doesn't exist and orCreate is false\n+   */\n+  public Transaction newReplaceTableTransaction(\n+      String location,\n+      Schema schema,\n+      PartitionSpec spec,\n+      Map<String, String> properties,\n+      boolean orCreate) {\n+\n+\n+    Catalog.TableBuilder builder = buildTable(location, schema).withPartitionSpec(spec).withProperties(properties);\n+    return orCreate ? builder.createOrReplaceTransaction() : builder.replaceTransaction();\n+  }\n+\n+  public Catalog.TableBuilder buildTable(String location, Schema schema) {\n+    return new HadoopTableBuilder(location, schema);\n+  }\n+\n+  private class HadoopTableBuilder implements Catalog.TableBuilder {\n+    private final String location;\n+    private final Schema schema;\n+    private final ImmutableMap.Builder<String, String> propertiesBuilder = ImmutableMap.builder();\n+    private PartitionSpec spec = PartitionSpec.unpartitioned();\n+    private SortOrder sortOrder = SortOrder.unsorted();\n+\n+\n+    HadoopTableBuilder(String location, Schema schema) {\n+      this.location = location;\n+      this.schema = schema;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withPartitionSpec(PartitionSpec newSpec) {\n+      this.spec = newSpec != null ? newSpec : PartitionSpec.unpartitioned();\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withSortOrder(SortOrder newSortOrder) {\n+      this.sortOrder = newSortOrder != null ? newSortOrder : SortOrder.unsorted();\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withLocation(String newLocation) {\n+      return this;", "originalCommit": "46d5fb7360c32ff7d1b25555786440f7f3d61885", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc0Njg0OQ==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537746849", "bodyText": "Agreed. Have added a precondition check.", "author": "rymurr", "createdAt": "2020-12-07T18:53:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzczODU0Mg=="}], "type": "inlineReview"}, {"oid": "e5be0da20ff2b87a9be8b6a2689e360136a9e5af", "url": "https://github.com/apache/iceberg/commit/e5be0da20ff2b87a9be8b6a2689e360136a9e5af", "message": "add table location check", "committedDate": "2020-12-07T18:53:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc1OTk4NQ==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537759985", "bodyText": "There should be no need to call toArray here because the joiner accepts Iterable<?>.", "author": "rdblue", "createdAt": "2020-12-07T19:12:25Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/PathIdentifier.java", "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import java.util.List;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Splitter;\n+import org.apache.iceberg.relocated.com.google.common.collect.Iterables;\n+import org.apache.spark.sql.connector.catalog.Identifier;\n+\n+public class PathIdentifier implements Identifier {\n+  private final String[] namespace;\n+  private final String location;\n+  private final String name;\n+\n+  public PathIdentifier(String location) {\n+    this.location = location;\n+    List<String> pathParts = Splitter.on(\"/\").splitToList(location);\n+    name = Iterables.getLast(pathParts);\n+    namespace = pathParts.size() > 1 ?\n+        new String[]{Joiner.on(\"/\").join(pathParts.subList(0, pathParts.size() - 1).toArray(new String[0]))} :", "originalCommit": "46d5fb7360c32ff7d1b25555786440f7f3d61885", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc2MTk4NA==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537761984", "bodyText": "yup, hangover from previous change. Fixed now.", "author": "rymurr", "createdAt": "2020-12-07T19:15:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc1OTk4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc2MDQ4OQ==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537760489", "bodyText": "We usually make Splitter and Joiner instances static fields.", "author": "rdblue", "createdAt": "2020-12-07T19:13:13Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/PathIdentifier.java", "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import java.util.List;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.base.Splitter;\n+import org.apache.iceberg.relocated.com.google.common.collect.Iterables;\n+import org.apache.spark.sql.connector.catalog.Identifier;\n+\n+public class PathIdentifier implements Identifier {\n+  private final String[] namespace;\n+  private final String location;\n+  private final String name;\n+\n+  public PathIdentifier(String location) {\n+    this.location = location;\n+    List<String> pathParts = Splitter.on(\"/\").splitToList(location);", "originalCommit": "46d5fb7360c32ff7d1b25555786440f7f3d61885", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc2MTgzOQ==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537761839", "bodyText": "agreed. Lazy mistake.  Fixed", "author": "rymurr", "createdAt": "2020-12-07T19:15:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc2MDQ4OQ=="}], "type": "inlineReview"}, {"oid": "f7eb6b951b1e38f3aa7e7e07371e3ad9e7bf5c2a", "url": "https://github.com/apache/iceberg/commit/f7eb6b951b1e38f3aa7e7e07371e3ad9e7bf5c2a", "message": "clean up PathIdentifier", "committedDate": "2020-12-07T19:18:10Z", "type": "commit"}, {"oid": "78071f355a639cafdc8a0ee3487303081999907e", "url": "https://github.com/apache/iceberg/commit/78071f355a639cafdc8a0ee3487303081999907e", "message": "remove pointless comment", "committedDate": "2020-12-07T19:20:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc2NjY5MQ==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r537766691", "bodyText": "Looks like there are 3 ways this is called:\n\nTo load a table\nTo create a builder\nTo drop a table\n\nI think it would be a bit cleaner to make the first 2 into private methods (load and newBuilder) rather than using pathOrTable with the same functions in lots of places.", "author": "rdblue", "createdAt": "2020-12-07T19:22:55Z", "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -453,4 +467,21 @@ private static void commitChanges(Table table, SetProperty setLocation, SetPrope\n \n     transaction.commitTransaction();\n   }\n+\n+  private static boolean isPathIdentifier(Identifier ident) {\n+    return ident instanceof PathIdentifier;\n+  }\n+\n+  private static void checkNotPathIdentifier(Identifier identifier, String method) {\n+    if (identifier instanceof PathIdentifier) {\n+      throw new IllegalArgumentException(String.format(\"Cannot pass path based identifier to %s method. %s is a path.\",\n+          method, identifier));\n+    }\n+  }\n+\n+  private <T> T pathOrTable(Identifier ident, Function<String, T> path, Function<TableIdentifier, T> table) {", "originalCommit": "46d5fb7360c32ff7d1b25555786440f7f3d61885", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "211b070f40eb1c0444e60d9fc2fe2b89196df176", "url": "https://github.com/apache/iceberg/commit/211b070f40eb1c0444e60d9fc2fe2b89196df176", "message": "clearer path vs catalog checks", "committedDate": "2020-12-07T20:07:28Z", "type": "commit"}, {"oid": "793a117e05794833ec9e083cc12c020ac3207d14", "url": "https://github.com/apache/iceberg/commit/793a117e05794833ec9e083cc12c020ac3207d14", "message": "add unit test for PathIdentifier", "committedDate": "2020-12-08T14:45:13Z", "type": "commit"}, {"oid": "793a117e05794833ec9e083cc12c020ac3207d14", "url": "https://github.com/apache/iceberg/commit/793a117e05794833ec9e083cc12c020ac3207d14", "message": "add unit test for PathIdentifier", "committedDate": "2020-12-08T14:45:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg0ODQzNg==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r538848436", "bodyText": "Nit: preconditions already support argument formatting, so String.format is redundant.", "author": "rdblue", "createdAt": "2020-12-08T22:16:02Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -200,6 +193,165 @@ TableOperations newTableOps(String location) {\n     }\n   }\n \n+  private TableMetadata tableMetadata(Schema schema, PartitionSpec spec, SortOrder order,\n+                                      Map<String, String> properties, String location) {\n+    Preconditions.checkNotNull(schema, \"A table schema is required\");\n+\n+    Map<String, String> tableProps = properties == null ? ImmutableMap.of() : properties;\n+    PartitionSpec partitionSpec = spec == null ? PartitionSpec.unpartitioned() : spec;\n+    SortOrder sortOrder = order == null ? SortOrder.unsorted() : order;\n+    return TableMetadata.newTableMetadata(schema, partitionSpec, sortOrder, location, tableProps);\n+  }\n+\n+  /**\n+   * Start a transaction to create a table.\n+   *\n+   * @param location a location for the table\n+   * @param schema a schema\n+   * @param spec a partition spec\n+   * @param properties a string map of table properties\n+   * @return a {@link Transaction} to create the table\n+   * @throws AlreadyExistsException if the table already exists\n+   */\n+  public Transaction newCreateTableTransaction(\n+      String location,\n+      Schema schema,\n+      PartitionSpec spec,\n+      Map<String, String> properties) {\n+    return buildTable(location, schema).withPartitionSpec(spec).withProperties(properties).createTransaction();\n+  }\n+\n+  /**\n+   * Start a transaction to replace a table.\n+   *\n+   * @param location a location for the table\n+   * @param schema a schema\n+   * @param spec a partition spec\n+   * @param properties a string map of table properties\n+   * @param orCreate whether to create the table if not exists\n+   * @return a {@link Transaction} to replace the table\n+   * @throws NoSuchTableException if the table doesn't exist and orCreate is false\n+   */\n+  public Transaction newReplaceTableTransaction(\n+      String location,\n+      Schema schema,\n+      PartitionSpec spec,\n+      Map<String, String> properties,\n+      boolean orCreate) {\n+\n+\n+    Catalog.TableBuilder builder = buildTable(location, schema).withPartitionSpec(spec).withProperties(properties);\n+    return orCreate ? builder.createOrReplaceTransaction() : builder.replaceTransaction();\n+  }\n+\n+  public Catalog.TableBuilder buildTable(String location, Schema schema) {\n+    return new HadoopTableBuilder(location, schema);\n+  }\n+\n+  private class HadoopTableBuilder implements Catalog.TableBuilder {\n+    private final String location;\n+    private final Schema schema;\n+    private final ImmutableMap.Builder<String, String> propertiesBuilder = ImmutableMap.builder();\n+    private PartitionSpec spec = PartitionSpec.unpartitioned();\n+    private SortOrder sortOrder = SortOrder.unsorted();\n+\n+\n+    HadoopTableBuilder(String location, Schema schema) {\n+      this.location = location;\n+      this.schema = schema;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withPartitionSpec(PartitionSpec newSpec) {\n+      this.spec = newSpec != null ? newSpec : PartitionSpec.unpartitioned();\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withSortOrder(SortOrder newSortOrder) {\n+      this.sortOrder = newSortOrder != null ? newSortOrder : SortOrder.unsorted();\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withLocation(String newLocation) {\n+      Preconditions.checkArgument(newLocation == null || location.equals(newLocation),\n+          String.format(\"Table location %s differs from the table location (%s) from the PathIdentifier\",\n+              newLocation, location));", "originalCommit": "793a117e05794833ec9e083cc12c020ac3207d14", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDEwMTY3Ng==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r550101676", "bodyText": "@rymurr  Here we use the SortOrder.unsorted or null to set the sort order rather than the sortOrder set from here ?  Is it correct ?  IMO,  we've ignored the user-provied sort order ?", "author": "openinx", "createdAt": "2020-12-30T10:00:25Z", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTables.java", "diffHunk": "@@ -200,6 +193,165 @@ TableOperations newTableOps(String location) {\n     }\n   }\n \n+  private TableMetadata tableMetadata(Schema schema, PartitionSpec spec, SortOrder order,\n+                                      Map<String, String> properties, String location) {\n+    Preconditions.checkNotNull(schema, \"A table schema is required\");\n+\n+    Map<String, String> tableProps = properties == null ? ImmutableMap.of() : properties;\n+    PartitionSpec partitionSpec = spec == null ? PartitionSpec.unpartitioned() : spec;\n+    SortOrder sortOrder = order == null ? SortOrder.unsorted() : order;\n+    return TableMetadata.newTableMetadata(schema, partitionSpec, sortOrder, location, tableProps);\n+  }\n+\n+  /**\n+   * Start a transaction to create a table.\n+   *\n+   * @param location a location for the table\n+   * @param schema a schema\n+   * @param spec a partition spec\n+   * @param properties a string map of table properties\n+   * @return a {@link Transaction} to create the table\n+   * @throws AlreadyExistsException if the table already exists\n+   */\n+  public Transaction newCreateTableTransaction(\n+      String location,\n+      Schema schema,\n+      PartitionSpec spec,\n+      Map<String, String> properties) {\n+    return buildTable(location, schema).withPartitionSpec(spec).withProperties(properties).createTransaction();\n+  }\n+\n+  /**\n+   * Start a transaction to replace a table.\n+   *\n+   * @param location a location for the table\n+   * @param schema a schema\n+   * @param spec a partition spec\n+   * @param properties a string map of table properties\n+   * @param orCreate whether to create the table if not exists\n+   * @return a {@link Transaction} to replace the table\n+   * @throws NoSuchTableException if the table doesn't exist and orCreate is false\n+   */\n+  public Transaction newReplaceTableTransaction(\n+      String location,\n+      Schema schema,\n+      PartitionSpec spec,\n+      Map<String, String> properties,\n+      boolean orCreate) {\n+\n+\n+    Catalog.TableBuilder builder = buildTable(location, schema).withPartitionSpec(spec).withProperties(properties);\n+    return orCreate ? builder.createOrReplaceTransaction() : builder.replaceTransaction();\n+  }\n+\n+  public Catalog.TableBuilder buildTable(String location, Schema schema) {\n+    return new HadoopTableBuilder(location, schema);\n+  }\n+\n+  private class HadoopTableBuilder implements Catalog.TableBuilder {\n+    private final String location;\n+    private final Schema schema;\n+    private final ImmutableMap.Builder<String, String> propertiesBuilder = ImmutableMap.builder();\n+    private PartitionSpec spec = PartitionSpec.unpartitioned();\n+    private SortOrder sortOrder = SortOrder.unsorted();\n+\n+\n+    HadoopTableBuilder(String location, Schema schema) {\n+      this.location = location;\n+      this.schema = schema;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withPartitionSpec(PartitionSpec newSpec) {\n+      this.spec = newSpec != null ? newSpec : PartitionSpec.unpartitioned();\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withSortOrder(SortOrder newSortOrder) {\n+      this.sortOrder = newSortOrder != null ? newSortOrder : SortOrder.unsorted();\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withLocation(String newLocation) {\n+      Preconditions.checkArgument(newLocation == null || location.equals(newLocation),\n+          String.format(\"Table location %s differs from the table location (%s) from the PathIdentifier\",\n+              newLocation, location));\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withProperties(Map<String, String> properties) {\n+      if (properties != null) {\n+        propertiesBuilder.putAll(properties);\n+      }\n+      return this;\n+    }\n+\n+    @Override\n+    public Catalog.TableBuilder withProperty(String key, String value) {\n+      propertiesBuilder.put(key, value);\n+      return this;\n+    }\n+\n+    @Override\n+    public Table create() {\n+      TableOperations ops = newTableOps(location);\n+      if (ops.current() != null) {\n+        throw new AlreadyExistsException(\"Table already exists at location: %s\", location);\n+      }\n+\n+      Map<String, String> properties = propertiesBuilder.build();\n+      TableMetadata metadata = tableMetadata(schema, spec, sortOrder, properties, location);\n+      ops.commit(null, metadata);\n+      return new BaseTable(ops, location);\n+    }\n+\n+    @Override\n+    public Transaction createTransaction() {\n+      TableOperations ops = newTableOps(location);\n+      if (ops.current() != null) {\n+        throw new AlreadyExistsException(\"Table already exists: %s\", location);\n+      }\n+\n+      Map<String, String> properties = propertiesBuilder.build();\n+      TableMetadata metadata = tableMetadata(schema, spec, null, properties, location);\n+      return Transactions.createTableTransaction(location, ops, metadata);\n+    }\n+\n+    @Override\n+    public Transaction replaceTransaction() {\n+      return newReplaceTableTransaction(false);\n+    }\n+\n+    @Override\n+    public Transaction createOrReplaceTransaction() {\n+      return newReplaceTableTransaction(true);\n+    }\n+\n+    private Transaction newReplaceTableTransaction(boolean orCreate) {\n+      TableOperations ops = newTableOps(location);\n+      if (!orCreate && ops.current() == null) {\n+        throw new NoSuchTableException(\"No such table: %s\", location);\n+      }\n+\n+      Map<String, String> properties = propertiesBuilder.build();\n+      TableMetadata metadata;\n+      if (ops.current() != null) {\n+        metadata = ops.current().buildReplacement(schema, spec, SortOrder.unsorted(), location, properties);\n+      } else {\n+        metadata = tableMetadata(schema, spec, null, properties, location);", "originalCommit": "793a117e05794833ec9e083cc12c020ac3207d14", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE2MTUwMA==", "url": "https://github.com/apache/iceberg/pull/1843#discussion_r550161500", "bodyText": "good spot @openinx not sure how that sneaked in! I have rasied #2009 to address", "author": "rymurr", "createdAt": "2020-12-30T11:27:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDEwMTY3Ng=="}], "type": "inlineReview"}]}