{"pr_number": 1122, "pr_title": "Move classes that depend on DSv2 in Spark 2.x to spark2", "pr_createdAt": "2020-06-17T21:32:40Z", "pr_url": "https://github.com/apache/iceberg/pull/1122", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTg0NzMyMQ==", "url": "https://github.com/apache/iceberg/pull/1122#discussion_r441847321", "bodyText": "This class is not used, so I removed it.", "author": "rdblue", "createdAt": "2020-06-17T21:34:26Z", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -480,41 +479,21 @@ private InternalRowReaderFactory() {\n     public InputPartitionReader<ColumnarBatch> create(CombinedScanTask task, Schema tableSchema, Schema expectedSchema,\n                                                       String nameMapping, FileIO io,\n                                                       EncryptionManager encryptionManager, boolean caseSensitive) {\n-      return new BatchDataReader(task, expectedSchema, nameMapping, io, encryptionManager, caseSensitive, batchSize);\n+      return new BatchReader(task, expectedSchema, nameMapping, io, encryptionManager, caseSensitive, batchSize);\n     }\n   }\n \n-  private static class StructLikeInternalRow implements StructLike {", "originalCommit": "167867cabd547951ee4e9e26c6ee15fb1904f5de", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTg0NzQ5MQ==", "url": "https://github.com/apache/iceberg/pull/1122#discussion_r441847491", "bodyText": "This wasn't used. The name mapping string is passed instead.", "author": "rdblue", "createdAt": "2020-06-17T21:34:50Z", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -396,8 +396,7 @@ public String toString() {\n \n     private transient Schema tableSchema = null;\n     private transient Schema expectedSchema = null;\n-    private transient NameMapping nameMapping = null;", "originalCommit": "167867cabd547951ee4e9e26c6ee15fb1904f5de", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ea0c9a124718a97895fcc1a2feebeea1377beec0", "url": "https://github.com/apache/iceberg/commit/ea0c9a124718a97895fcc1a2feebeea1377beec0", "message": "Move classes that depend on DSv2 in Spark 2.x to spark2.", "committedDate": "2020-06-17T23:47:18Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE2ODgyMQ==", "url": "https://github.com/apache/iceberg/pull/1122#discussion_r442168821", "bodyText": "IIUC, both spark2 and spark3 will rely on this code, and this code requires one specific Spark dependency about the InternalRow, will this potentially go into an issue that has two versions of spark dependencies in Spark3 module?\nAlso if the signature of InternalRow of Spark2 and Spark3 is different, will this lead to an issue?", "author": "jerryshao", "createdAt": "2020-06-18T11:52:13Z", "path": "spark/src/main/java/org/apache/iceberg/spark/source/BaseWriter.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.source;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.List;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.Metrics;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.encryption.EncryptedOutputFile;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.util.Tasks;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+\n+abstract class BaseWriter implements Closeable {\n+  protected static final int ROWS_DIVISOR = 1000;\n+\n+  private final List<DataFile> completedFiles = Lists.newArrayList();\n+  private final PartitionSpec spec;\n+  private final FileFormat format;\n+  private final SparkAppenderFactory appenderFactory;\n+  private final OutputFileFactory fileFactory;\n+  private final FileIO io;\n+  private final long targetFileSize;\n+  private PartitionKey currentKey = null;\n+  private FileAppender<InternalRow> currentAppender = null;\n+  private EncryptedOutputFile currentFile = null;\n+  private long currentRows = 0;\n+\n+  BaseWriter(PartitionSpec spec, FileFormat format, SparkAppenderFactory appenderFactory,\n+             OutputFileFactory fileFactory, FileIO io, long targetFileSize) {\n+    this.spec = spec;\n+    this.format = format;\n+    this.appenderFactory = appenderFactory;\n+    this.fileFactory = fileFactory;\n+    this.io = io;\n+    this.targetFileSize = targetFileSize;\n+  }\n+\n+  public abstract void write(InternalRow row) throws IOException;", "originalCommit": "ea0c9a124718a97895fcc1a2feebeea1377beec0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzAyMDY1MA==", "url": "https://github.com/apache/iceberg/pull/1122#discussion_r443020650", "bodyText": "Yes. The alternative is to have two copies of everything, which I think isn't worth it. This API is unlikely to change between Spark versions because it is relied upon so heavily in Spark. I think it should be fine as long as we have thorough testing to catch any issues.", "author": "rdblue", "createdAt": "2020-06-19T19:58:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjE2ODgyMQ=="}], "type": "inlineReview"}, {"oid": "963538f3a7b43e65e7804ea7208b44dda6744f64", "url": "https://github.com/apache/iceberg/commit/963538f3a7b43e65e7804ea7208b44dda6744f64", "message": "Move classes that depend on DSv2 in Spark 2.x to spark2.", "committedDate": "2020-06-19T22:52:18Z", "type": "commit"}, {"oid": "4b3d4b188e7dcf726d56b47b9a583f7373175880", "url": "https://github.com/apache/iceberg/commit/4b3d4b188e7dcf726d56b47b9a583f7373175880", "message": "Move tests that depend on the Iceberg source.", "committedDate": "2020-06-19T23:14:30Z", "type": "commit"}, {"oid": "4b3d4b188e7dcf726d56b47b9a583f7373175880", "url": "https://github.com/apache/iceberg/commit/4b3d4b188e7dcf726d56b47b9a583f7373175880", "message": "Move tests that depend on the Iceberg source.", "committedDate": "2020-06-19T23:14:30Z", "type": "forcePushed"}, {"oid": "1fd43cf8bc7a4fd5a8baac9edc2687edf0a4129f", "url": "https://github.com/apache/iceberg/commit/1fd43cf8bc7a4fd5a8baac9edc2687edf0a4129f", "message": "Fix checkstyle issues, undo accidental move.", "committedDate": "2020-06-19T23:36:34Z", "type": "commit"}, {"oid": "c677fee8cf8b5bc8e4f4937ede6d7bb24b3be85e", "url": "https://github.com/apache/iceberg/commit/c677fee8cf8b5bc8e4f4937ede6d7bb24b3be85e", "message": "Bump test memory for spark2.", "committedDate": "2020-06-20T00:36:09Z", "type": "commit"}]}