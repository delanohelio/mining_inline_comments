{"pr_number": 1207, "pr_title": "ORC: Support row position as a metadata column", "pr_createdAt": "2020-07-15T04:46:33Z", "pr_url": "https://github.com/apache/iceberg/pull/1207", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTMyNTA3Mw==", "url": "https://github.com/apache/iceberg/pull/1207#discussion_r455325073", "bodyText": "This seems to introduce a lot of code churn, when most implementations don't use batchOffsetInFile. What about a less intrusive way of passing this by using a context method that is called once for each batch?\nParquet has something similar, where each row group causes new context to be passed to the readers: https://github.com/apache/iceberg/blob/master/parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueReader.java#L32\nThis could expose a method like setBatchContext(long batchOffsetInFile) with a no-op default. Then only a few implementations would need to change.", "author": "rdblue", "createdAt": "2020-07-15T20:33:46Z", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcRowReader.java", "diffHunk": "@@ -29,6 +29,6 @@\n   /**\n    * Reads a row.\n    */\n-  T read(VectorizedRowBatch batch, int row);\n+  T read(VectorizedRowBatch batch, long batchOffsetInFile, int rowOffsetInBatch);", "originalCommit": "1bc55be9857af48730a6c740a9cbd27093b4b06d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQwMTQyMg==", "url": "https://github.com/apache/iceberg/pull/1207#discussion_r455401422", "bodyText": "Thanks for the suggestion! This reduces the code changes significantly.", "author": "shardulm94", "createdAt": "2020-07-15T22:28:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTMyNTA3Mw=="}], "type": "inlineReview"}, {"oid": "1c5de07152fc60658b6de1a0b926ce10acdf121d", "url": "https://github.com/apache/iceberg/commit/1c5de07152fc60658b6de1a0b926ce10acdf121d", "message": "ORC: Support row postition as a metadata column", "committedDate": "2020-07-15T22:22:34Z", "type": "commit"}, {"oid": "1c5de07152fc60658b6de1a0b926ce10acdf121d", "url": "https://github.com/apache/iceberg/commit/1c5de07152fc60658b6de1a0b926ce10acdf121d", "message": "ORC: Support row postition as a metadata column", "committedDate": "2020-07-15T22:22:34Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQwMjAwMg==", "url": "https://github.com/apache/iceberg/pull/1207#discussion_r455402002", "bodyText": "I am checking the current field with the ROW_POSITION field defined in MetadataColumns, we can probably check just the field ID though.", "author": "shardulm94", "createdAt": "2020-07-15T22:29:59Z", "path": "spark/src/main/java/org/apache/iceberg/spark/data/vectorized/VectorizedSparkOrcReaders.java", "diffHunk": "@@ -378,16 +395,20 @@ private StructConverter(Types.StructType structType, List<Converter> fieldConver\n     }\n \n     @Override\n-    public ColumnVector convert(org.apache.orc.storage.ql.exec.vector.ColumnVector vector, int batchSize) {\n+    public ColumnVector convert(org.apache.orc.storage.ql.exec.vector.ColumnVector vector, int batchSize,\n+                                long batchOffsetInFile) {\n       StructColumnVector structVector = (StructColumnVector) vector;\n       List<Types.NestedField> fields = structType.fields();\n       List<ColumnVector> fieldVectors = Lists.newArrayListWithExpectedSize(fields.size());\n       for (int pos = 0, vectorIndex = 0; pos < fields.size(); pos += 1) {\n         Types.NestedField field = fields.get(pos);\n         if (idToConstant.containsKey(field.fieldId())) {\n           fieldVectors.add(new ConstantColumnVector(field.type(), batchSize, idToConstant.get(field.fieldId())));\n+        } else if (field.equals(MetadataColumns.ROW_POSITION)) {", "originalCommit": "1c5de07152fc60658b6de1a0b926ce10acdf121d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}