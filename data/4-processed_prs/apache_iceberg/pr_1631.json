{"pr_number": 1631, "pr_title": "Use TestHiveShell to run StorageHandler tests. Use Parameterized runner.", "pr_createdAt": "2020-10-19T14:09:47Z", "pr_url": "https://github.com/apache/iceberg/pull/1631", "timeline": [{"oid": "1e14cb5e32e6a8778208eb9782a20045099212ac", "url": "https://github.com/apache/iceberg/commit/1e14cb5e32e6a8778208eb9782a20045099212ac", "message": "Use TestHiveShell to run StorageHandler tests. Use Parameterized runner.", "committedDate": "2020-10-19T13:59:28Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzg5NDg5Mw==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r507894893", "bodyText": "Is the tez dependency required? I don't see any imports explicitly referencing tez.", "author": "shardulm94", "createdAt": "2020-10-19T16:37:04Z", "path": "build.gradle", "diffHunk": "@@ -463,12 +463,10 @@ project(':iceberg-mr') {\n     testCompile(\"org.apache.calcite:calcite-core\")\n     testCompile(\"com.esotericsoftware:kryo-shaded:4.0.2\")\n     testCompile(\"com.fasterxml.jackson.core:jackson-annotations:2.6.5\")\n-    testCompile(\"com.klarna:hiverunner:5.2.1\") {\n-      exclude group: 'javax.jms', module: 'jms'\n+    testCompile(\"org.apache.hive:hive-service\") {\n       exclude group: 'org.apache.hive', module: 'hive-exec'\n-      exclude group: 'org.codehaus.jettison', module: 'jettison'\n-      exclude group: 'org.apache.calcite.avatica'\n     }\n+    testCompile(\"org.apache.tez:tez-dag:0.8.4\")", "originalCommit": "1e14cb5e32e6a8778208eb9782a20045099212ac", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzkxNDczMQ==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r507914731", "bodyText": "You're right, thanks. It's not required for Hive2, indeed. I've removed the dependency.\nOn the other hand, it is needed for Hive3, where HiveServer2.start() initializes a TezSessionPoolManager, which depends on some Tez code.", "author": "marton-bod", "createdAt": "2020-10-19T17:08:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzg5NDg5Mw=="}], "type": "inlineReview"}, {"oid": "513fbca4f5ebd69c2188c0e95a064807f921c554", "url": "https://github.com/apache/iceberg/commit/513fbca4f5ebd69c2188c0e95a064807f921c554", "message": "Remove tez dependency from iceberg-mr", "committedDate": "2020-10-19T17:04:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODAwNTc1NQ==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r508005755", "bodyText": "Isn't there an option to get an ephemeral port when creating the socket in the listener? Seems odd to find a free port and try to use it. There's a small chance of collision with new connections on the host.", "author": "rdblue", "createdAt": "2020-10-19T19:22:28Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestHiveShell.java", "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.service.cli.CLIService;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationHandle;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.SessionHandle;\n+import org.apache.hive.service.cli.session.HiveSession;\n+import org.apache.hive.service.server.HiveServer2;\n+import org.apache.iceberg.common.DynMethods;\n+\n+import static org.apache.commons.lang3.StringUtils.isNotBlank;\n+import static org.apache.iceberg.relocated.com.google.common.base.Preconditions.checkState;\n+\n+/**\n+ * Test class for running HiveQL queries, essentially acting like a Beeline shell in tests.\n+ *\n+ * It takes a metastore URL via conf, and spins up an HS2 instance which connects to it. The shell will only accept\n+ * queries if it has been previously initialized via {@link #start()}, and a session has been opened via\n+ * {@link #openSession()}. Prior to calling {@link #start()}, the shell should first be configured with props that apply\n+ * across all test cases by calling {@link #setHiveConfValue(String, String)} ()}. On the other hand, session-level conf\n+ * can be applied anytime via {@link #setHiveSessionValue(String, String)} ()}, once we've opened an active session.\n+ */\n+public class TestHiveShell {\n+\n+  private static final DynMethods.StaticMethod FIND_FREE_PORT = DynMethods.builder(\"findFreePort\")\n+          .impl(\"org.apache.hadoop.hive.metastore.utils.MetaStoreUtils\")\n+          .impl(\"org.apache.hadoop.hive.metastore.MetaStoreUtils\")\n+          .buildStatic();\n+\n+  private final HiveServer2 hs2;\n+  private final HiveConf conf;\n+  private CLIService client;\n+  private HiveSession session;\n+  private boolean started;\n+\n+  public TestHiveShell() {\n+    conf = initializeConf();\n+    hs2 = new HiveServer2();\n+  }\n+\n+  public void setHiveConfValue(String key, String value) {\n+    checkState(!started, \"TestHiveShell has already been started. Cannot set Hive conf anymore.\");\n+    conf.set(key, value);\n+  }\n+\n+  public void setHiveSessionValue(String key, String value) {\n+    checkState(session != null, \"There is no open session for setting variables.\");\n+    try {\n+      session.getSessionConf().set(key, value);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Unable to set Hive session variable: \", e);\n+    }\n+  }\n+\n+  public void start() {\n+    checkState(isNotBlank(conf.get(HiveConf.ConfVars.METASTOREURIS.varname)),\n+            \"hive.metastore.uris must be supplied in config. TestHiveShell needs an external metastore to connect to.\");\n+    hs2.init(conf);\n+    hs2.start();\n+    client = hs2.getServices().stream()\n+            .filter(CLIService.class::isInstance)\n+            .findFirst()\n+            .map(CLIService.class::cast)\n+            .get();\n+    started = true;\n+  }\n+\n+  public void stop() {\n+    if (client != null) {\n+      client.stop();\n+    }\n+    hs2.stop();\n+    started = false;\n+  }\n+\n+  public void openSession() {\n+    checkState(started, \"You have to start TestHiveShell first, before opening a session.\");\n+    try {\n+      SessionHandle sessionHandle = client.getSessionManager().openSession(\n+              CLIService.SERVER_VERSION, \"\", \"\", \"127.0.0.1\", Collections.emptyMap());\n+      session = client.getSessionManager().getSession(sessionHandle);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Unable to open new Hive session: \", e);\n+    }\n+  }\n+\n+  public void closeSession() {\n+    checkState(session != null, \"There is no open session to be closed.\");\n+    try {\n+      session.close();\n+      session = null;\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Unable to close Hive session: \", e);\n+    }\n+  }\n+\n+  public List<Object[]> executeStatement(String statement) {\n+    checkState(session != null,\n+            \"You have to start TestHiveShell and open a session first, before running a query.\");\n+    try {\n+      OperationHandle handle = client.executeStatement(session.getSessionHandle(), statement, Collections.emptyMap());\n+      List<Object[]> resultSet = new ArrayList<>();\n+      if (handle.hasResultSet()) {\n+        RowSet rowSet;\n+        // keep fetching results until we can\n+        while ((rowSet = client.fetchResults(handle)) != null && rowSet.numRows() > 0) {\n+          for (Object[] row : rowSet) {\n+            resultSet.add(row.clone());\n+          }\n+        }\n+      }\n+      return resultSet;\n+    } catch (HiveSQLException e) {\n+      throw new IllegalArgumentException(\"Failed to execute Hive query '\" + statement + \"': \" + e.getMessage(), e);\n+    }\n+  }\n+\n+  public Configuration getHiveConf() {\n+    if (session != null) {\n+      return session.getHiveConf();\n+    } else {\n+      return conf;\n+    }\n+  }\n+\n+  private HiveConf initializeConf() {\n+    HiveConf hiveConf = new HiveConf();\n+\n+    // Use random port to enable running tests in parallel\n+    hiveConf.setIntVar(HiveConf.ConfVars.HIVE_SERVER2_THRIFT_PORT, FIND_FREE_PORT.invoke());", "originalCommit": "513fbca4f5ebd69c2188c0e95a064807f921c554", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQzODUzNA==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r508438534", "bodyText": "You're right, there is a chance of collision. I've changed the port number to 0 in the config, which will make HS2 use an ephemeral port.", "author": "marton-bod", "createdAt": "2020-10-20T11:55:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODAwNTc1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODAwNzgwOA==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r508007808", "bodyText": "Nit: continuing indentation is off in this file", "author": "rdblue", "createdAt": "2020-10-19T19:26:07Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestHiveShell.java", "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.service.cli.CLIService;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationHandle;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.SessionHandle;\n+import org.apache.hive.service.cli.session.HiveSession;\n+import org.apache.hive.service.server.HiveServer2;\n+import org.apache.iceberg.common.DynMethods;\n+\n+import static org.apache.commons.lang3.StringUtils.isNotBlank;\n+import static org.apache.iceberg.relocated.com.google.common.base.Preconditions.checkState;\n+\n+/**\n+ * Test class for running HiveQL queries, essentially acting like a Beeline shell in tests.\n+ *\n+ * It takes a metastore URL via conf, and spins up an HS2 instance which connects to it. The shell will only accept\n+ * queries if it has been previously initialized via {@link #start()}, and a session has been opened via\n+ * {@link #openSession()}. Prior to calling {@link #start()}, the shell should first be configured with props that apply\n+ * across all test cases by calling {@link #setHiveConfValue(String, String)} ()}. On the other hand, session-level conf\n+ * can be applied anytime via {@link #setHiveSessionValue(String, String)} ()}, once we've opened an active session.\n+ */\n+public class TestHiveShell {\n+\n+  private static final DynMethods.StaticMethod FIND_FREE_PORT = DynMethods.builder(\"findFreePort\")\n+          .impl(\"org.apache.hadoop.hive.metastore.utils.MetaStoreUtils\")\n+          .impl(\"org.apache.hadoop.hive.metastore.MetaStoreUtils\")\n+          .buildStatic();\n+\n+  private final HiveServer2 hs2;\n+  private final HiveConf conf;\n+  private CLIService client;\n+  private HiveSession session;\n+  private boolean started;\n+\n+  public TestHiveShell() {\n+    conf = initializeConf();\n+    hs2 = new HiveServer2();\n+  }\n+\n+  public void setHiveConfValue(String key, String value) {\n+    checkState(!started, \"TestHiveShell has already been started. Cannot set Hive conf anymore.\");\n+    conf.set(key, value);\n+  }\n+\n+  public void setHiveSessionValue(String key, String value) {\n+    checkState(session != null, \"There is no open session for setting variables.\");\n+    try {\n+      session.getSessionConf().set(key, value);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Unable to set Hive session variable: \", e);\n+    }\n+  }\n+\n+  public void start() {\n+    checkState(isNotBlank(conf.get(HiveConf.ConfVars.METASTOREURIS.varname)),\n+            \"hive.metastore.uris must be supplied in config. TestHiveShell needs an external metastore to connect to.\");\n+    hs2.init(conf);\n+    hs2.start();\n+    client = hs2.getServices().stream()\n+            .filter(CLIService.class::isInstance)\n+            .findFirst()\n+            .map(CLIService.class::cast)\n+            .get();\n+    started = true;\n+  }\n+\n+  public void stop() {\n+    if (client != null) {\n+      client.stop();\n+    }\n+    hs2.stop();\n+    started = false;\n+  }\n+\n+  public void openSession() {\n+    checkState(started, \"You have to start TestHiveShell first, before opening a session.\");\n+    try {\n+      SessionHandle sessionHandle = client.getSessionManager().openSession(\n+              CLIService.SERVER_VERSION, \"\", \"\", \"127.0.0.1\", Collections.emptyMap());", "originalCommit": "513fbca4f5ebd69c2188c0e95a064807f921c554", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQzODcwMw==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r508438703", "bodyText": "fixed", "author": "marton-bod", "createdAt": "2020-10-20T11:56:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODAwNzgwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODAwODQyMg==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r508008422", "bodyText": "We try to avoid using statically imported methods. It's nice to see what class methods are in.\nAlso, we don't want to introduce a directly dependency on Apache commons. Could you use isEmpty instead?", "author": "rdblue", "createdAt": "2020-10-19T19:27:17Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestHiveShell.java", "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.service.cli.CLIService;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationHandle;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.SessionHandle;\n+import org.apache.hive.service.cli.session.HiveSession;\n+import org.apache.hive.service.server.HiveServer2;\n+import org.apache.iceberg.common.DynMethods;\n+\n+import static org.apache.commons.lang3.StringUtils.isNotBlank;\n+import static org.apache.iceberg.relocated.com.google.common.base.Preconditions.checkState;", "originalCommit": "513fbca4f5ebd69c2188c0e95a064807f921c554", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQzOTY0NA==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r508439644", "bodyText": "sure, removed the static imports\n(the isEmpty is not needed anymore due to \"inhousing\" the metastore)", "author": "marton-bod", "createdAt": "2020-10-20T11:57:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODAwODQyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODAwOTE1OQ==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r508009159", "bodyText": "Wouldn't it make sense to embed the TestHiveMetastore in TestHiveShell so that it is always available? Or is there a case where we use TestHiveShell without TestHiveMetastore?", "author": "rdblue", "createdAt": "2020-10-19T19:28:33Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergStorageHandlerBaseTest.java", "diffHunk": "@@ -112,113 +109,73 @@\n \n   // before variables\n   protected static TestHiveMetastore metastore;\n+  private static TestHiveShell shell;\n \n   private TestTables testTables;\n \n   public abstract TestTables testTables(Configuration conf, TemporaryFolder tmp) throws IOException;\n \n+  @Parameters(name = \"fileFormat={0}\")\n+  public static Iterable<FileFormat> fileFormats() {\n+    return ImmutableList.of(FileFormat.PARQUET, FileFormat.ORC, FileFormat.AVRO);\n+  }\n+\n+  @Parameter\n+  public FileFormat fileFormat;\n \n   @BeforeClass\n   public static void beforeClass() {\n     metastore = new TestHiveMetastore();\n     // We need to use increased pool size in these tests. See: #1620\n     metastore.start(METASTORE_POOL_SIZE);\n+    shell = new TestHiveShell();\n+\n+    String metastoreUris = metastore.hiveConf().getVar(HiveConf.ConfVars.METASTOREURIS);\n+    shell.setHiveConfValue(HiveConf.ConfVars.METASTOREURIS.varname, metastoreUris);\n+    String metastoreWarehouse = metastore.hiveConf().getVar(HiveConf.ConfVars.METASTOREWAREHOUSE);\n+    shell.setHiveConfValue(HiveConf.ConfVars.METASTOREWAREHOUSE.varname, metastoreWarehouse);\n+    shell.setHiveConfValue(\"hive.notification.event.poll.interval\", \"-1\");\n+\n+    shell.start();", "originalCommit": "513fbca4f5ebd69c2188c0e95a064807f921c554", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQ0MzM0Mw==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r508443343", "bodyText": "That's right, TestHiveShell always needs an external metastore instance, so yes I agree it makes sense to embed the TestHiveMetastore", "author": "marton-bod", "createdAt": "2020-10-20T12:04:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODAwOTE1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODAwOTg0NQ==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r508009845", "bodyText": "If TestMetaStore were integrated into this class, then I don't think we would need this check.", "author": "rdblue", "createdAt": "2020-10-19T19:29:49Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestHiveShell.java", "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.service.cli.CLIService;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationHandle;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.SessionHandle;\n+import org.apache.hive.service.cli.session.HiveSession;\n+import org.apache.hive.service.server.HiveServer2;\n+import org.apache.iceberg.common.DynMethods;\n+\n+import static org.apache.commons.lang3.StringUtils.isNotBlank;\n+import static org.apache.iceberg.relocated.com.google.common.base.Preconditions.checkState;\n+\n+/**\n+ * Test class for running HiveQL queries, essentially acting like a Beeline shell in tests.\n+ *\n+ * It takes a metastore URL via conf, and spins up an HS2 instance which connects to it. The shell will only accept\n+ * queries if it has been previously initialized via {@link #start()}, and a session has been opened via\n+ * {@link #openSession()}. Prior to calling {@link #start()}, the shell should first be configured with props that apply\n+ * across all test cases by calling {@link #setHiveConfValue(String, String)} ()}. On the other hand, session-level conf\n+ * can be applied anytime via {@link #setHiveSessionValue(String, String)} ()}, once we've opened an active session.\n+ */\n+public class TestHiveShell {\n+\n+  private static final DynMethods.StaticMethod FIND_FREE_PORT = DynMethods.builder(\"findFreePort\")\n+          .impl(\"org.apache.hadoop.hive.metastore.utils.MetaStoreUtils\")\n+          .impl(\"org.apache.hadoop.hive.metastore.MetaStoreUtils\")\n+          .buildStatic();\n+\n+  private final HiveServer2 hs2;\n+  private final HiveConf conf;\n+  private CLIService client;\n+  private HiveSession session;\n+  private boolean started;\n+\n+  public TestHiveShell() {\n+    conf = initializeConf();\n+    hs2 = new HiveServer2();\n+  }\n+\n+  public void setHiveConfValue(String key, String value) {\n+    checkState(!started, \"TestHiveShell has already been started. Cannot set Hive conf anymore.\");\n+    conf.set(key, value);\n+  }\n+\n+  public void setHiveSessionValue(String key, String value) {\n+    checkState(session != null, \"There is no open session for setting variables.\");\n+    try {\n+      session.getSessionConf().set(key, value);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Unable to set Hive session variable: \", e);\n+    }\n+  }\n+\n+  public void start() {\n+    checkState(isNotBlank(conf.get(HiveConf.ConfVars.METASTOREURIS.varname)),\n+            \"hive.metastore.uris must be supplied in config. TestHiveShell needs an external metastore to connect to.\");", "originalCommit": "513fbca4f5ebd69c2188c0e95a064807f921c554", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODAxMDgxMw==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r508010813", "bodyText": "Do you know how the metastore connections are handled in HS2? Does each HS2 service have a connection pool? Or are connections created per session?\nWhy did you choose to use a session per test case? Is that to avoid some sort of state leak? Are sessions not supposed to be used concurrently?", "author": "rdblue", "createdAt": "2020-10-19T19:31:33Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestHiveShell.java", "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.service.cli.CLIService;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationHandle;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.SessionHandle;\n+import org.apache.hive.service.cli.session.HiveSession;\n+import org.apache.hive.service.server.HiveServer2;\n+import org.apache.iceberg.common.DynMethods;\n+\n+import static org.apache.commons.lang3.StringUtils.isNotBlank;\n+import static org.apache.iceberg.relocated.com.google.common.base.Preconditions.checkState;\n+\n+/**\n+ * Test class for running HiveQL queries, essentially acting like a Beeline shell in tests.\n+ *\n+ * It takes a metastore URL via conf, and spins up an HS2 instance which connects to it. The shell will only accept\n+ * queries if it has been previously initialized via {@link #start()}, and a session has been opened via\n+ * {@link #openSession()}. Prior to calling {@link #start()}, the shell should first be configured with props that apply\n+ * across all test cases by calling {@link #setHiveConfValue(String, String)} ()}. On the other hand, session-level conf\n+ * can be applied anytime via {@link #setHiveSessionValue(String, String)} ()}, once we've opened an active session.\n+ */\n+public class TestHiveShell {", "originalCommit": "513fbca4f5ebd69c2188c0e95a064807f921c554", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODY0NjI1OA==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r508646258", "bodyText": "Do you know how the metastore connections are handled in HS2?\n\nDuring query compilation, HS2 calls the Metastore via thrift (using the ThriftHiveMetastore$Client), synchronously in the same thread where the Driver performs the other compilation tasks. The created metastore client is cached and reused throughout the life of the Driver execution.\n\nDoes each HS2 service have a connection pool?\n\nThe HS2 service we're using for submitting queries (CLIClient) does not use a thread pool (it only uses a thread pool when async compilation/execution is enabled, which isn't in our tests or by default).\n\nWhy did you choose to use a session per test case? Is that to avoid some sort of state leak?\n\nExactly, to avoid state/configuration leaks, in order to provide a 'clean slate' for each test method. Test methods could therefore go and set their session-level variables individually that they need for their test scenarios, without risks of test config spilling over (which could be hard to debug).", "author": "marton-bod", "createdAt": "2020-10-20T15:59:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODAxMDgxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTExOTU0Mw==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r511119543", "bodyText": "From your answers to the first two, it sounds like there will be one connection per driver that is reused, and planning/execution is single-threaded so we shouldn't have multiple connections from a single test case.\nAnd if the driver or its underlying connection to HMS is reused across sessions, then this should open a single connection to the Hive MetaStore per test suite. Is that correct?\nIf so, then I think we should be able to turn down the metastore pool size from 15 to 5 because this fixes the problem where a new connection is used for each command.", "author": "rdblue", "createdAt": "2020-10-23T19:45:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODAxMDgxMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg0ODAyNg==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r511848026", "bodyText": "The metastore client is cached in threadlocal, so each test method will create one and reuse it across its query executions (so not 1 connection per test suite but 1 per test method). However, since the connections are properly closed by calling session.close() at the end of each test method, I see no reason to keep the higher pool size. Changed it back to the default size.", "author": "marton-bod", "createdAt": "2020-10-26T10:11:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODAxMDgxMw=="}], "type": "inlineReview"}, {"oid": "68f3dd3280e406dabed54496da21ece705d18008", "url": "https://github.com/apache/iceberg/commit/68f3dd3280e406dabed54496da21ece705d18008", "message": "Integrate metastore into TestHiveShell", "committedDate": "2020-10-20T10:31:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTExNjU4Nw==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r511116587", "bodyText": "Nit: we avoid using get because it doesn't add much value. Getter methods are usually just named for the field that is returned.", "author": "rdblue", "createdAt": "2020-10-23T19:41:40Z", "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestHiveShell.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.hive.service.cli.CLIService;\n+import org.apache.hive.service.cli.HiveSQLException;\n+import org.apache.hive.service.cli.OperationHandle;\n+import org.apache.hive.service.cli.RowSet;\n+import org.apache.hive.service.cli.SessionHandle;\n+import org.apache.hive.service.cli.session.HiveSession;\n+import org.apache.hive.service.server.HiveServer2;\n+import org.apache.iceberg.hive.TestHiveMetastore;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+\n+/**\n+ * Test class for running HiveQL queries, essentially acting like a Beeline shell in tests.\n+ *\n+ * It spins up both an HS2 and a Metastore instance to work with. The shell will only accept\n+ * queries if it has been previously initialized via {@link #start()}, and a session has been opened via\n+ * {@link #openSession()}. Prior to calling {@link #start()}, the shell should first be configured with props that apply\n+ * across all test cases by calling {@link #setHiveConfValue(String, String)} ()}. On the other hand, session-level conf\n+ * can be applied anytime via {@link #setHiveSessionValue(String, String)} ()}, once we've opened an active session.\n+ */\n+public class TestHiveShell {\n+\n+  // We need to use increased pool size in these tests. See: #1620\n+  private static final int METASTORE_POOL_SIZE = 15;\n+\n+  private final TestHiveMetastore metastore;\n+  private final HiveServer2 hs2;\n+  private final HiveConf hs2Conf;\n+  private CLIService client;\n+  private HiveSession session;\n+  private boolean started;\n+\n+  public TestHiveShell() {\n+    metastore = new TestHiveMetastore();\n+    hs2Conf = initializeConf();\n+    hs2 = new HiveServer2();\n+  }\n+\n+  public void setHiveConfValue(String key, String value) {\n+    Preconditions.checkState(!started, \"TestHiveShell has already been started. Cannot set Hive conf anymore.\");\n+    hs2Conf.verifyAndSet(key, value);\n+  }\n+\n+  public void setHiveSessionValue(String key, String value) {\n+    Preconditions.checkState(session != null, \"There is no open session for setting variables.\");\n+    try {\n+      session.getSessionConf().set(key, value);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Unable to set Hive session variable: \", e);\n+    }\n+  }\n+\n+  public void start() {\n+    metastore.start(METASTORE_POOL_SIZE);\n+    hs2Conf.setVar(HiveConf.ConfVars.METASTOREURIS, metastore.hiveConf().getVar(HiveConf.ConfVars.METASTOREURIS));\n+    hs2Conf.setVar(HiveConf.ConfVars.METASTOREWAREHOUSE,\n+        metastore.hiveConf().getVar(HiveConf.ConfVars.METASTOREWAREHOUSE));\n+\n+    hs2.init(hs2Conf);\n+    hs2.start();\n+    client = hs2.getServices().stream()\n+            .filter(CLIService.class::isInstance)\n+            .findFirst()\n+            .map(CLIService.class::cast)\n+            .get();\n+    started = true;\n+  }\n+\n+  public void stop() {\n+    if (client != null) {\n+      client.stop();\n+    }\n+    hs2.stop();\n+    metastore.stop();\n+    started = false;\n+  }\n+\n+  public TestHiveMetastore getMetastore() {", "originalCommit": "68f3dd3280e406dabed54496da21ece705d18008", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTg0NTY5NQ==", "url": "https://github.com/apache/iceberg/pull/1631#discussion_r511845695", "bodyText": "sure, renamed it", "author": "marton-bod", "createdAt": "2020-10-26T10:07:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTExNjU4Nw=="}], "type": "inlineReview"}, {"oid": "49561297f2556521b109ac5488d2b1fe1fec7ce4", "url": "https://github.com/apache/iceberg/commit/49561297f2556521b109ac5488d2b1fe1fec7ce4", "message": "Rename accessor method; Use default pool size for metastore in TestHiveShell", "committedDate": "2020-10-26T10:07:20Z", "type": "commit"}]}