{"pr_number": 1030, "pr_title": "Add content types to DataFile and ManifestFile", "pr_createdAt": "2020-05-08T23:59:31Z", "pr_url": "https://github.com/apache/iceberg/pull/1030", "timeline": [{"oid": "05504792d831c162217244d30105e6f28d6558ab", "url": "https://github.com/apache/iceberg/commit/05504792d831c162217244d30105e6f28d6558ab", "message": "Add content types to DataFile and ManifestFile.", "committedDate": "2020-05-08T23:52:40Z", "type": "commit"}, {"oid": "6b69e63446db90ac579695ab80f54928162d846a", "url": "https://github.com/apache/iceberg/commit/6b69e63446db90ac579695ab80f54928162d846a", "message": "Fix Metadata table tests.\n\nThis also updates AllEntriesTable to return the correct sequence number.", "committedDate": "2020-05-11T23:55:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU2NzAxNg==", "url": "https://github.com/apache/iceberg/pull/1030#discussion_r429567016", "bodyText": "Will DeleteFile extend this or will it be totally separate?", "author": "aokolnychyi", "createdAt": "2020-05-23T18:17:34Z", "path": "api/src/main/java/org/apache/iceberg/DataFile.java", "diffHunk": "@@ -37,31 +38,58 @@\n  * Interface for files listed in a table manifest.\n  */\n public interface DataFile {\n+  // fields for adding delete data files\n+  Types.NestedField CONTENT = optional(134, \"content\", IntegerType.get(),\n+      \"Contents of the file: 0=data, 1=position deletes, 2=equality deletes\");\n+  Types.NestedField FILE_PATH = required(100, \"file_path\", StringType.get(), \"Location URI with FS scheme\");\n+  Types.NestedField FILE_FORMAT = required(101, \"file_format\", StringType.get(),\n+      \"File format name: avro, orc, or parquet\");\n+  Types.NestedField RECORD_COUNT = required(103, \"record_count\", LongType.get(), \"Number of records in the file\");\n+  Types.NestedField FILE_SIZE = required(104, \"file_size_in_bytes\", LongType.get(), \"Total file size in bytes\");\n+  Types.NestedField COLUMN_SIZES = optional(108, \"column_sizes\", MapType.ofRequired(117, 118,\n+      IntegerType.get(), LongType.get()), \"Map of column id to total size on disk\");\n+  Types.NestedField VALUE_COUNTS = optional(109, \"value_counts\", MapType.ofRequired(119, 120,\n+      IntegerType.get(), LongType.get()), \"Map of column id to total count, including null and NaN\");\n+  Types.NestedField NULL_VALUE_COUNTS = optional(110, \"null_value_counts\", MapType.ofRequired(121, 122,\n+      IntegerType.get(), LongType.get()), \"Map of column id to null value count\");\n+  Types.NestedField LOWER_BOUNDS = optional(125, \"lower_bounds\", MapType.ofRequired(126, 127,\n+      IntegerType.get(), BinaryType.get()), \"Map of column id to lower bound\");\n+  Types.NestedField UPPER_BOUNDS = optional(128, \"upper_bounds\", MapType.ofRequired(129, 130,\n+      IntegerType.get(), BinaryType.get()), \"Map of column id to upper bound\");\n+  Types.NestedField KEY_METADATA = optional(131, \"key_metadata\", BinaryType.get(), \"Encryption key metadata blob\");\n+  Types.NestedField SPLIT_OFFSETS = optional(132, \"split_offsets\", ListType.ofRequired(133, LongType.get()),\n+      \"Splittable offsets\");\n+  int PARTITION_ID = 102;\n+  String PARTITION_NAME = \"partition\";\n+  String PARTITION_DOC = \"Partition data tuple, schema based on the partition spec\";\n+  // NEXT ID TO ASSIGN: 135\n+\n   static StructType getType(StructType partitionType) {\n     // IDs start at 100 to leave room for changes to ManifestEntry\n     return StructType.of(\n-        required(100, \"file_path\", StringType.get()),\n-        required(101, \"file_format\", StringType.get()),\n-        required(102, \"partition\", partitionType),\n-        required(103, \"record_count\", LongType.get()),\n-        required(104, \"file_size_in_bytes\", LongType.get()),\n-        required(105, \"block_size_in_bytes\", LongType.get()),\n-        optional(108, \"column_sizes\", MapType.ofRequired(117, 118,\n-            IntegerType.get(), LongType.get())),\n-        optional(109, \"value_counts\", MapType.ofRequired(119, 120,\n-            IntegerType.get(), LongType.get())),\n-        optional(110, \"null_value_counts\", MapType.ofRequired(121, 122,\n-            IntegerType.get(), LongType.get())),\n-        optional(125, \"lower_bounds\", MapType.ofRequired(126, 127,\n-            IntegerType.get(), BinaryType.get())),\n-        optional(128, \"upper_bounds\", MapType.ofRequired(129, 130,\n-            IntegerType.get(), BinaryType.get())),\n-        optional(131, \"key_metadata\", BinaryType.get()),\n-        optional(132, \"split_offsets\", ListType.ofRequired(133, LongType.get()))\n-        // NEXT ID TO ASSIGN: 134\n+        CONTENT,\n+        FILE_PATH,\n+        FILE_FORMAT,\n+        required(PARTITION_ID, PARTITION_NAME, partitionType, PARTITION_DOC),\n+        RECORD_COUNT,\n+        FILE_SIZE,\n+        COLUMN_SIZES,\n+        VALUE_COUNTS,\n+        NULL_VALUE_COUNTS,\n+        LOWER_BOUNDS,\n+        UPPER_BOUNDS,\n+        KEY_METADATA,\n+        SPLIT_OFFSETS\n     );\n   }\n \n+  /**\n+   * @return the content stored in the file; one of DATA, POSITION_DELETES, or EQUALITY_DELETES\n+   */\n+  default FileContent content() {", "originalCommit": "6b69e63446db90ac579695ab80f54928162d846a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU2Nzc2Mg==", "url": "https://github.com/apache/iceberg/pull/1030#discussion_r429567762", "bodyText": "Ugh, this one wouldn't probably work correctly before if snapshot id inheritance was enabled.", "author": "aokolnychyi", "createdAt": "2020-05-23T18:26:57Z", "path": "core/src/main/java/org/apache/iceberg/AllEntriesTable.java", "diffHunk": "@@ -100,11 +100,13 @@ protected long targetSplitSize(TableOperations ops) {\n     protected CloseableIterable<FileScanTask> planFiles(\n         TableOperations ops, Snapshot snapshot, Expression rowFilter, boolean caseSensitive, boolean colStats) {\n       CloseableIterable<ManifestFile> manifests = AllDataFilesTable.allManifestFiles(ops.current().snapshots());\n+      Schema fileSchema = new Schema(schema().findType(\"data_file\").asStructType().fields());\n       String schemaString = SchemaParser.toJson(schema());\n       String specString = PartitionSpecParser.toJson(PartitionSpec.unpartitioned());\n+      ResidualEvaluator residuals = ResidualEvaluator.unpartitioned(rowFilter);\n \n-      return CloseableIterable.transform(manifests, manifest -> new BaseFileScanTask(\n-          DataFiles.fromManifest(manifest), schemaString, specString, ResidualEvaluator.unpartitioned(rowFilter)));\n+      return CloseableIterable.transform(manifests, manifest -> new ManifestEntriesTable.ManifestReadTask(", "originalCommit": "6b69e63446db90ac579695ab80f54928162d846a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU2ODgwNQ==", "url": "https://github.com/apache/iceberg/pull/1030#discussion_r429568805", "bodyText": "Is this change needed because we added FileContent in GenericDataFile?", "author": "aokolnychyi", "createdAt": "2020-05-23T18:41:08Z", "path": "core/src/main/java/org/apache/iceberg/V1Metadata.java", "diffHunk": "@@ -226,11 +254,10 @@ public Object get(int i) {\n           return wrapped.snapshotId();\n         case 2:\n           DataFile file = wrapped.file();\n-          if (file == null || file instanceof GenericDataFile) {", "originalCommit": "6b69e63446db90ac579695ab80f54928162d846a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}