{"pr_number": 1161, "pr_title": "Fix errors when use removeOrphanFiles By HadoopCatalog", "pr_createdAt": "2020-07-02T08:10:45Z", "pr_url": "https://github.com/apache/iceberg/pull/1161", "timeline": [{"oid": "6608675f429e50f78605c7b41e3e922ae2578c25", "url": "https://github.com/apache/iceberg/commit/6608675f429e50f78605c7b41e3e922ae2578c25", "message": "Fix errors when use removeOrphanFiles By HadoopCatalog", "committedDate": "2020-07-02T08:04:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODg1MDE3Mg==", "url": "https://github.com/apache/iceberg/pull/1161#discussion_r448850172", "bodyText": "Is possible to provide a unit test addressing your changes ?\nThanks.", "author": "openinx", "createdAt": "2020-07-02T08:52:04Z", "path": "spark/src/main/java/org/apache/iceberg/actions/BaseAction.java", "diffHunk": "@@ -30,8 +31,11 @@ protected String metadataTableName(MetadataTableType type) {\n     String tableName = table().toString();\n     if (tableName.contains(\"/\")) {\n       return tableName + \"#\" + type;\n-    } else if (tableName.startsWith(\"hadoop.\") || tableName.startsWith(\"hive.\")) {\n-      // HiveCatalog and HadoopCatalog prepend a logical name which we need to drop for Spark 2.4\n+    } else if (tableName.startsWith(\"hadoop.\")) {\n+      // HadoopCatalog tableName style is 'hadoop.ns.tb'\n+      return ((BaseTable) table()).operations().current().location() + \"#\" + type;", "originalCommit": "6608675f429e50f78605c7b41e3e922ae2578c25", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "f2f4223dea0312ca6945dc6166de9b6df33bbaec", "url": "https://github.com/apache/iceberg/commit/f2f4223dea0312ca6945dc6166de9b6df33bbaec", "message": "add a unit test", "committedDate": "2020-07-02T09:55:50Z", "type": "commit"}, {"oid": "21d859ba9752c96128a1543c2f14da626515733c", "url": "https://github.com/apache/iceberg/commit/21d859ba9752c96128a1543c2f14da626515733c", "message": "remove some char", "committedDate": "2020-07-02T10:06:45Z", "type": "commit"}, {"oid": "527bb60c067a12463688a99a2a05d67c86fb92ec", "url": "https://github.com/apache/iceberg/commit/527bb60c067a12463688a99a2a05d67c86fb92ec", "message": "repair code style", "committedDate": "2020-07-02T10:26:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NTI1NA==", "url": "https://github.com/apache/iceberg/pull/1161#discussion_r449655254", "bodyText": "I don't think this comment is correct because the solution is to convert to a path table reference.\nIf i understand correctly, the problem in Spark 2.4 is that IcebergSource uses the Hive catalog or it uses HadoopTables to load a path. The table you're passing in was loaded by HadoopCatalog, so it doesn't work because that catalog is not available. I agree that the solution is to convert a Hadoop table to a path reference, but then this comment should explain what's happening: a HadoopCatalog was used to load the table, so convert to the path.", "author": "rdblue", "createdAt": "2020-07-03T16:37:30Z", "path": "spark/src/main/java/org/apache/iceberg/actions/BaseAction.java", "diffHunk": "@@ -30,8 +31,11 @@ protected String metadataTableName(MetadataTableType type) {\n     String tableName = table().toString();\n     if (tableName.contains(\"/\")) {\n       return tableName + \"#\" + type;\n-    } else if (tableName.startsWith(\"hadoop.\") || tableName.startsWith(\"hive.\")) {\n-      // HiveCatalog and HadoopCatalog prepend a logical name which we need to drop for Spark 2.4\n+    } else if (tableName.startsWith(\"hadoop.\")) {\n+      // HadoopCatalog tableName style is 'hadoop.ns.tb'", "originalCommit": "527bb60c067a12463688a99a2a05d67c86fb92ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTc0Nzg2NA==", "url": "https://github.com/apache/iceberg/pull/1161#discussion_r449747864", "bodyText": "Yes, just as you described.I have modified the comment, I wonder if you have a better one.", "author": "zhangdove", "createdAt": "2020-07-04T07:11:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NTI1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTgwODg3NQ==", "url": "https://github.com/apache/iceberg/pull/1161#discussion_r449808875", "bodyText": "I made a suggestion. Thanks!", "author": "rdblue", "createdAt": "2020-07-04T22:03:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NTI1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NTQwNA==", "url": "https://github.com/apache/iceberg/pull/1161#discussion_r449655404", "bodyText": "Why not use table().location() instead? There's no need to cast to BaseTable and access TableOperations.", "author": "rdblue", "createdAt": "2020-07-03T16:38:05Z", "path": "spark/src/main/java/org/apache/iceberg/actions/BaseAction.java", "diffHunk": "@@ -30,8 +31,11 @@ protected String metadataTableName(MetadataTableType type) {\n     String tableName = table().toString();\n     if (tableName.contains(\"/\")) {\n       return tableName + \"#\" + type;\n-    } else if (tableName.startsWith(\"hadoop.\") || tableName.startsWith(\"hive.\")) {\n-      // HiveCatalog and HadoopCatalog prepend a logical name which we need to drop for Spark 2.4\n+    } else if (tableName.startsWith(\"hadoop.\")) {\n+      // HadoopCatalog tableName style is 'hadoop.ns.tb'\n+      return ((BaseTable) table()).operations().current().location() + \"#\" + type;", "originalCommit": "527bb60c067a12463688a99a2a05d67c86fb92ec", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTc0Mzc5OA==", "url": "https://github.com/apache/iceberg/pull/1161#discussion_r449743798", "bodyText": "That sounds like a good idea to me. I'll fix it.", "author": "zhangdove", "createdAt": "2020-07-04T06:06:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NTQwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NTc3MQ==", "url": "https://github.com/apache/iceberg/pull/1161#discussion_r449655771", "bodyText": "Nit: Indentation is off. It should be 2 indents (4 spaces) from the indent of the line that is being continued, df.select(...).", "author": "rdblue", "createdAt": "2020-07-03T16:39:34Z", "path": "spark2/src/test/java/org/apache/iceberg/actions/TestRemoveOrphanFilesAction.java", "diffHunk": "@@ -542,4 +545,41 @@ public void testRemoveOrphanFilesWithRelativeFilePath() throws IOException, Inte\n     Assert.assertEquals(\"Action should find 1 file\", invalidFiles, result);\n     Assert.assertTrue(\"Invalid file should be present\", fs.exists(new Path(invalidFiles.get(0))));\n   }\n+\n+  @Test\n+  public void testRemoveOrphanFilesWithHadoopCatalog() throws InterruptedException {\n+    HadoopCatalog catalog = new HadoopCatalog(new Configuration(), tableLocation);\n+    String namespaceName = \"testDb\";\n+    String tableName = \"testTb\";\n+\n+    Namespace namespace = Namespace.of(namespaceName);\n+    TableIdentifier tableIdentifier = TableIdentifier.of(namespace, tableName);\n+    Table table = catalog.createTable(tableIdentifier, SCHEMA, PartitionSpec.unpartitioned(), Maps.newHashMap());\n+\n+    List<ThreeColumnRecord> records = Lists.newArrayList(\n+            new ThreeColumnRecord(1, \"AAAAAAAAAA\", \"AAAA\")\n+    );\n+    Dataset<Row> df = spark.createDataFrame(records, ThreeColumnRecord.class).coalesce(1);\n+\n+    String tableFileSystemPath = tableLocation + \"/\" + namespaceName + \"/\" + tableName;\n+    df.select(\"c1\", \"c2\", \"c3\")\n+            .write()", "originalCommit": "527bb60c067a12463688a99a2a05d67c86fb92ec", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NjI5OA==", "url": "https://github.com/apache/iceberg/pull/1161#discussion_r449656298", "bodyText": "Can you add the comment that explains this line from the other test cases?", "author": "rdblue", "createdAt": "2020-07-03T16:41:41Z", "path": "spark2/src/test/java/org/apache/iceberg/actions/TestRemoveOrphanFilesAction.java", "diffHunk": "@@ -542,4 +545,41 @@ public void testRemoveOrphanFilesWithRelativeFilePath() throws IOException, Inte\n     Assert.assertEquals(\"Action should find 1 file\", invalidFiles, result);\n     Assert.assertTrue(\"Invalid file should be present\", fs.exists(new Path(invalidFiles.get(0))));\n   }\n+\n+  @Test\n+  public void testRemoveOrphanFilesWithHadoopCatalog() throws InterruptedException {\n+    HadoopCatalog catalog = new HadoopCatalog(new Configuration(), tableLocation);\n+    String namespaceName = \"testDb\";\n+    String tableName = \"testTb\";\n+\n+    Namespace namespace = Namespace.of(namespaceName);\n+    TableIdentifier tableIdentifier = TableIdentifier.of(namespace, tableName);\n+    Table table = catalog.createTable(tableIdentifier, SCHEMA, PartitionSpec.unpartitioned(), Maps.newHashMap());\n+\n+    List<ThreeColumnRecord> records = Lists.newArrayList(\n+            new ThreeColumnRecord(1, \"AAAAAAAAAA\", \"AAAA\")\n+    );\n+    Dataset<Row> df = spark.createDataFrame(records, ThreeColumnRecord.class).coalesce(1);\n+\n+    String tableFileSystemPath = tableLocation + \"/\" + namespaceName + \"/\" + tableName;\n+    df.select(\"c1\", \"c2\", \"c3\")\n+            .write()\n+            .format(\"iceberg\")\n+            .mode(\"append\")\n+            .save(tableFileSystemPath);\n+\n+    df.write().mode(\"append\").parquet(tableFileSystemPath + \"/data\");\n+\n+    Thread.sleep(1000);", "originalCommit": "527bb60c067a12463688a99a2a05d67c86fb92ec", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NjQxMA==", "url": "https://github.com/apache/iceberg/pull/1161#discussion_r449656410", "bodyText": "You can combine this with the previous line:\nList<String> deletedFiles = Actions.forTable(table)\n    .removeOrphanFiles()\n    .olderThan(timestamp)\n    .execute();", "author": "rdblue", "createdAt": "2020-07-03T16:42:08Z", "path": "spark2/src/test/java/org/apache/iceberg/actions/TestRemoveOrphanFilesAction.java", "diffHunk": "@@ -542,4 +545,41 @@ public void testRemoveOrphanFilesWithRelativeFilePath() throws IOException, Inte\n     Assert.assertEquals(\"Action should find 1 file\", invalidFiles, result);\n     Assert.assertTrue(\"Invalid file should be present\", fs.exists(new Path(invalidFiles.get(0))));\n   }\n+\n+  @Test\n+  public void testRemoveOrphanFilesWithHadoopCatalog() throws InterruptedException {\n+    HadoopCatalog catalog = new HadoopCatalog(new Configuration(), tableLocation);\n+    String namespaceName = \"testDb\";\n+    String tableName = \"testTb\";\n+\n+    Namespace namespace = Namespace.of(namespaceName);\n+    TableIdentifier tableIdentifier = TableIdentifier.of(namespace, tableName);\n+    Table table = catalog.createTable(tableIdentifier, SCHEMA, PartitionSpec.unpartitioned(), Maps.newHashMap());\n+\n+    List<ThreeColumnRecord> records = Lists.newArrayList(\n+            new ThreeColumnRecord(1, \"AAAAAAAAAA\", \"AAAA\")\n+    );\n+    Dataset<Row> df = spark.createDataFrame(records, ThreeColumnRecord.class).coalesce(1);\n+\n+    String tableFileSystemPath = tableLocation + \"/\" + namespaceName + \"/\" + tableName;\n+    df.select(\"c1\", \"c2\", \"c3\")\n+            .write()\n+            .format(\"iceberg\")\n+            .mode(\"append\")\n+            .save(tableFileSystemPath);\n+\n+    df.write().mode(\"append\").parquet(tableFileSystemPath + \"/data\");\n+\n+    Thread.sleep(1000);\n+\n+    long timestamp = System.currentTimeMillis();\n+\n+    Actions actions = Actions.forTable(table);\n+\n+    List<String> result = actions.removeOrphanFiles()", "originalCommit": "527bb60c067a12463688a99a2a05d67c86fb92ec", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NjYwMw==", "url": "https://github.com/apache/iceberg/pull/1161#discussion_r449656603", "bodyText": "Minor: The other tests don't use a separate variable for this. Could this be embedded in the olderThan call?", "author": "rdblue", "createdAt": "2020-07-03T16:42:48Z", "path": "spark2/src/test/java/org/apache/iceberg/actions/TestRemoveOrphanFilesAction.java", "diffHunk": "@@ -542,4 +545,41 @@ public void testRemoveOrphanFilesWithRelativeFilePath() throws IOException, Inte\n     Assert.assertEquals(\"Action should find 1 file\", invalidFiles, result);\n     Assert.assertTrue(\"Invalid file should be present\", fs.exists(new Path(invalidFiles.get(0))));\n   }\n+\n+  @Test\n+  public void testRemoveOrphanFilesWithHadoopCatalog() throws InterruptedException {\n+    HadoopCatalog catalog = new HadoopCatalog(new Configuration(), tableLocation);\n+    String namespaceName = \"testDb\";\n+    String tableName = \"testTb\";\n+\n+    Namespace namespace = Namespace.of(namespaceName);\n+    TableIdentifier tableIdentifier = TableIdentifier.of(namespace, tableName);\n+    Table table = catalog.createTable(tableIdentifier, SCHEMA, PartitionSpec.unpartitioned(), Maps.newHashMap());\n+\n+    List<ThreeColumnRecord> records = Lists.newArrayList(\n+            new ThreeColumnRecord(1, \"AAAAAAAAAA\", \"AAAA\")\n+    );\n+    Dataset<Row> df = spark.createDataFrame(records, ThreeColumnRecord.class).coalesce(1);\n+\n+    String tableFileSystemPath = tableLocation + \"/\" + namespaceName + \"/\" + tableName;\n+    df.select(\"c1\", \"c2\", \"c3\")\n+            .write()\n+            .format(\"iceberg\")\n+            .mode(\"append\")\n+            .save(tableFileSystemPath);\n+\n+    df.write().mode(\"append\").parquet(tableFileSystemPath + \"/data\");\n+\n+    Thread.sleep(1000);\n+\n+    long timestamp = System.currentTimeMillis();", "originalCommit": "527bb60c067a12463688a99a2a05d67c86fb92ec", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NjgxMA==", "url": "https://github.com/apache/iceberg/pull/1161#discussion_r449656810", "bodyText": "Does this work using table.location instead of building the path here?", "author": "rdblue", "createdAt": "2020-07-03T16:43:39Z", "path": "spark2/src/test/java/org/apache/iceberg/actions/TestRemoveOrphanFilesAction.java", "diffHunk": "@@ -542,4 +545,41 @@ public void testRemoveOrphanFilesWithRelativeFilePath() throws IOException, Inte\n     Assert.assertEquals(\"Action should find 1 file\", invalidFiles, result);\n     Assert.assertTrue(\"Invalid file should be present\", fs.exists(new Path(invalidFiles.get(0))));\n   }\n+\n+  @Test\n+  public void testRemoveOrphanFilesWithHadoopCatalog() throws InterruptedException {\n+    HadoopCatalog catalog = new HadoopCatalog(new Configuration(), tableLocation);\n+    String namespaceName = \"testDb\";\n+    String tableName = \"testTb\";\n+\n+    Namespace namespace = Namespace.of(namespaceName);\n+    TableIdentifier tableIdentifier = TableIdentifier.of(namespace, tableName);\n+    Table table = catalog.createTable(tableIdentifier, SCHEMA, PartitionSpec.unpartitioned(), Maps.newHashMap());\n+\n+    List<ThreeColumnRecord> records = Lists.newArrayList(\n+            new ThreeColumnRecord(1, \"AAAAAAAAAA\", \"AAAA\")\n+    );\n+    Dataset<Row> df = spark.createDataFrame(records, ThreeColumnRecord.class).coalesce(1);\n+\n+    String tableFileSystemPath = tableLocation + \"/\" + namespaceName + \"/\" + tableName;", "originalCommit": "527bb60c067a12463688a99a2a05d67c86fb92ec", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ccfbbf7527b7218fd8bb6a0c4d679248e751303d", "url": "https://github.com/apache/iceberg/commit/ccfbbf7527b7218fd8bb6a0c4d679248e751303d", "message": "A few small changes", "committedDate": "2020-07-04T07:09:46Z", "type": "commit"}, {"oid": "86569e3a95525e77ed681ffcf49107dcb0dbe3b9", "url": "https://github.com/apache/iceberg/commit/86569e3a95525e77ed681ffcf49107dcb0dbe3b9", "message": "remove no used import", "committedDate": "2020-07-04T07:18:52Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTgwODY2Mg==", "url": "https://github.com/apache/iceberg/pull/1161#discussion_r449808662", "bodyText": "Looks like this needs to be updated. There is no need to remove hadoop. if Hadoop tables don't use this code path.", "author": "rdblue", "createdAt": "2020-07-04T21:59:49Z", "path": "spark/src/main/java/org/apache/iceberg/actions/BaseAction.java", "diffHunk": "@@ -30,8 +30,11 @@ protected String metadataTableName(MetadataTableType type) {\n     String tableName = table().toString();\n     if (tableName.contains(\"/\")) {\n       return tableName + \"#\" + type;\n-    } else if (tableName.startsWith(\"hadoop.\") || tableName.startsWith(\"hive.\")) {\n-      // HiveCatalog and HadoopCatalog prepend a logical name which we need to drop for Spark 2.4\n+    } else if (tableName.startsWith(\"hadoop.\")) {\n+      // Load a path by HadoopCatalog or HadoopTables\n+      return table().location() + \"#\" + type;\n+    } else if (tableName.startsWith(\"hive.\")) {\n+      // HiveCatalog prepend a logical name which we need to drop for Spark 2.4\n       return tableName.replaceFirst(\"(hadoop\\\\.)|(hive\\\\.)\", \"\") + \".\" + type;", "originalCommit": "86569e3a95525e77ed681ffcf49107dcb0dbe3b9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTgwODg2NA==", "url": "https://github.com/apache/iceberg/pull/1161#discussion_r449808864", "bodyText": "How about \"for HadoopCatalog tables, use the table location to load the metadata table because IcebergCatalog uses HiveCatalog when the table is identified by name\".", "author": "rdblue", "createdAt": "2020-07-04T22:03:06Z", "path": "spark/src/main/java/org/apache/iceberg/actions/BaseAction.java", "diffHunk": "@@ -30,8 +30,11 @@ protected String metadataTableName(MetadataTableType type) {\n     String tableName = table().toString();\n     if (tableName.contains(\"/\")) {\n       return tableName + \"#\" + type;\n-    } else if (tableName.startsWith(\"hadoop.\") || tableName.startsWith(\"hive.\")) {\n-      // HiveCatalog and HadoopCatalog prepend a logical name which we need to drop for Spark 2.4\n+    } else if (tableName.startsWith(\"hadoop.\")) {\n+      // Load a path by HadoopCatalog or HadoopTables", "originalCommit": "86569e3a95525e77ed681ffcf49107dcb0dbe3b9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e676ca79d73cc396f370080295498984b1f247d3", "url": "https://github.com/apache/iceberg/commit/e676ca79d73cc396f370080295498984b1f247d3", "message": "update the comment and remove matching", "committedDate": "2020-07-05T02:25:06Z", "type": "commit"}]}