{"pr_number": 341, "pr_title": "Create external-table directory", "pr_createdAt": "2020-04-17T22:14:16Z", "pr_url": "https://github.com/greenplum-db/pxf/pull/341", "timeline": [{"oid": "0b2711221068d19681d6c61351922f80fbcb1600", "url": "https://github.com/greenplum-db/pxf/commit/0b2711221068d19681d6c61351922f80fbcb1600", "message": "Add pxf-automation-dependencies to test yml files\n\nAuthored-by: Oliver Albertini <oalbertini@vmware.com>", "committedDate": "2020-05-11T21:16:03Z", "type": "forcePushed"}, {"oid": "4c9c2307a01195f35ca3b1a4d142a8d9c406b0a7", "url": "https://github.com/greenplum-db/pxf/commit/4c9c2307a01195f35ca3b1a4d142a8d9c406b0a7", "message": "Add pxf-automation-dependencies to test yml files\n\nAuthored-by: Oliver Albertini <oalbertini@vmware.com>", "committedDate": "2020-05-11T21:50:38Z", "type": "forcePushed"}, {"oid": "276ebbbd03c611484639b953d71e91263ec47495", "url": "https://github.com/greenplum-db/pxf/commit/276ebbbd03c611484639b953d71e91263ec47495", "message": "Bump version to non-snapshot\n\n* loosen pxf tarball naming pattern\n\nAuthored-by: Oliver Albertini <oalbertini@vmware.com>", "committedDate": "2020-05-12T00:33:55Z", "type": "forcePushed"}, {"oid": "b0e65d494b7cdfdba19d2fb9740b09ef742292fc", "url": "https://github.com/greenplum-db/pxf/commit/b0e65d494b7cdfdba19d2fb9740b09ef742292fc", "message": "Add actual promotion script\n\nAuthored-by: Oliver Albertini <oalbertini@vmware.com>", "committedDate": "2020-05-13T01:19:45Z", "type": "forcePushed"}, {"oid": "2b7375eca27d7a40231a1fd9339130fef3d23ce7", "url": "https://github.com/greenplum-db/pxf/commit/2b7375eca27d7a40231a1fd9339130fef3d23ce7", "message": "Add actual promotion script\n\nAuthored-by: Oliver Albertini <oalbertini@vmware.com>", "committedDate": "2020-05-13T01:39:17Z", "type": "forcePushed"}, {"oid": "c6c24b239287642dd81adb645f53c56eee82ead8", "url": "https://github.com/greenplum-db/pxf/commit/c6c24b239287642dd81adb645f53c56eee82ead8", "message": "Add GitHub Action: Releases API\n\nand fix release tagging script\n\nAuthored-by: Oliver Albertini <oalbertini@vmware.com>", "committedDate": "2020-05-19T23:52:41Z", "type": "forcePushed"}, {"oid": "094585895edece081721334f481c30973a476b13", "url": "https://github.com/greenplum-db/pxf/commit/094585895edece081721334f481c30973a476b13", "message": "promote_pxf_artifacts: fix issues with script\n\nAuthored-by: Oliver Albertini <oalbertini@vmware.com>", "committedDate": "2020-05-20T01:51:52Z", "type": "forcePushed"}, {"oid": "15d5658ea047881ecc9c9338d152f7980afacf2b", "url": "https://github.com/greenplum-db/pxf/commit/15d5658ea047881ecc9c9338d152f7980afacf2b", "message": "Add GitHub Action: Releases API\n\npromote_pxf_artifacts: fix issues with script\n\nAuthored-by: Oliver Albertini <oalbertini@vmware.com>", "committedDate": "2020-05-20T03:07:06Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYxNjU2NQ==", "url": "https://github.com/greenplum-db/pxf/pull/341#discussion_r432616565", "bodyText": "will be useful for major upgrades as well, so maybe drop the word \"minor\" ?", "author": "denalex", "createdAt": "2020-05-29T16:58:38Z", "path": "server/pxf-service/src/scripts/pxf", "diffHunk": "@@ -318,6 +318,7 @@ doHelp() {\n \t  status              show the status of the local PXF server instance\n \t  version             show the version of PXF server\n \t  reset               undo the local PXF initialization\n+\t  register            install PXF extension under \\$GPHOME (useful after minor upgrades of Greenplum server)", "originalCommit": "bc8c12849e5829de06498749ede2750832733e36", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYyMDAwNg==", "url": "https://github.com/greenplum-db/pxf/pull/341#discussion_r432620006", "bodyText": "should we also add to init description \"... and install PXF extension under $GPHOME\"", "author": "denalex", "createdAt": "2020-05-29T17:05:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjYxNjU2NQ=="}], "type": "inlineReview"}, {"oid": "9554d00e4a5598d418e0b0a0557059c1bfb628fa", "url": "https://github.com/greenplum-db/pxf/commit/9554d00e4a5598d418e0b0a0557059c1bfb628fa", "message": "Continuous Integration: independent release process\n\nThis commit introduces several new pipelines to aid a PXF release\nprocess independent of any underlying SQL database. This commit thus\nincludes scripts for making and managing a PXF RPM, which includes the C\nextension, whose code now lives under external-table/. These are the new\npipelines:\n\n* pivnet_artifacts: a pipeline that fetches releases of GPDB from\n  PivNet, aka TanzuNet\n* pxf-build: pipeline that builds and releases new PXF artifacts\n* dev-pxf-build: dev version of pxf-build, much abbreviated\n* pxf-certification: pipeline that tests existing PXF artifacts against\n  new versions of Greenplum\n* pxf_pr_pipeline: new PR pipeline which uses the new build process\n\nVersion is now managed at the top level, in a file `version`. By\nchanging this file to a non-SNAPSHOT version, we can create a release\nusing the pxf-build pipeline. This causes a new tag/release to be\ntriggered on GitHub (Releases API), as well as a new SNAPSHOT version to\nbe committed.\n\nFurther, by uploading an OSL file to the appropriate cloud location,\nwe trigger publication of our release to the Release Engineering team.\n\nAlong with an independent release, we are now also installing PXF not\nunder GPHOME but separately in PXF_HOME. Thus this commit also has\nchanges to the PXF CLI to reflect the new install location. This\nincludes a new command called `pxf [cluster] register` to re-install the\nPXF C extension under GPHOME.\n\nOther noteworthy changes include:\n\n* The new pipelines make use of smaller images that don't include PXF\n  dependencies, but instead pull in those dependencies via tarballs that\n  are pre-built.\n* The new pattern for setting pipelines is to have targets in\n  concourse/Makefile.\n* Cloud tests have been hardened to reduce flakiness\n* In CI scripts we source ~gpadmin/.pxfrc which is cached on each image\n* Slack integrations have been added for pxf-certification, pxf-build,\n  and dev-pxf-build pipelines\n\nCo-authored-by: Oliver Albertini <oalbertini@vmware.com>\nCo-authored-by: Alexander Denissov <adenissov@pivotal.io>\nCo-authored-by: Francisco Guerrero <aguerrero@pivotal.io>", "committedDate": "2020-06-02T02:57:15Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzgxOTI0Mg==", "url": "https://github.com/greenplum-db/pxf/pull/341#discussion_r433819242", "bodyText": "maybe update the version to the correct version before merging?", "author": "frankgh", "createdAt": "2020-06-02T11:55:13Z", "path": "version", "diffHunk": "@@ -0,0 +1 @@\n+1.2.7-SNAPSHOT", "originalCommit": "9554d00e4a5598d418e0b0a0557059c1bfb628fa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzgxOTkwMQ==", "url": "https://github.com/greenplum-db/pxf/pull/341#discussion_r433819901", "bodyText": "Maybe update with the correct release body, to prepare for the release?", "author": "frankgh", "createdAt": "2020-06-02T11:56:31Z", "path": ".github/workflows/create-release-on-tag.yml", "diffHunk": "@@ -0,0 +1,44 @@\n+on:\n+  push:\n+    # Sequence of patterns matched against refs/tags\n+    tags:\n+      - '*' # match on any tag\n+\n+name: Create Release\n+\n+jobs:\n+  build:\n+    name: Create Release\n+    runs-on: ubuntu-latest\n+    steps:\n+      - name: Checkout code\n+        uses: actions/checkout@v2\n+      - name: Create Release\n+        id: create_release\n+        uses: actions/create-release@v1\n+        env:\n+          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # This token is provided by Actions, you do not need to create your own token\n+        with:\n+          tag_name: ${{ github.ref }}\n+          release_name: PXF Version ${{ github.ref }}\n+          body: |\n+            ## 5.12.0 (05/05/2020)", "originalCommit": "9554d00e4a5598d418e0b0a0557059c1bfb628fa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc0Mjg4NQ==", "url": "https://github.com/greenplum-db/pxf/pull/341#discussion_r434742885", "bodyText": "That should be done when updating the CHANGELOG.md. In the future we will hopefully automate that, but for now it remains manual.", "author": "oliverralbertini", "createdAt": "2020-06-03T17:40:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzgxOTkwMQ=="}], "type": "inlineReview"}, {"oid": "8822099d7c196566b3ad698292428e6a0c387575", "url": "https://github.com/greenplum-db/pxf/commit/8822099d7c196566b3ad698292428e6a0c387575", "message": "Move pxf extension into gpcontrib\n\nCo-authored-by: Jimmy Yih <jyih@pivotal.io>", "committedDate": "2020-06-03T17:41:41Z", "type": "commit"}, {"oid": "9d31a2b44f09ed8e1bba7f6f020ac4933dcfb2f8", "url": "https://github.com/greenplum-db/pxf/commit/9d31a2b44f09ed8e1bba7f6f020ac4933dcfb2f8", "message": "Unify the way to fetch/manage the number of segments (#6034)\n\n* Don't use GpIdentity.numsegments directly for the number of segments\r\n\r\nUse getgpsegmentCount() instead.\r\n\r\n* Unify the way to fetch/manage the number of segments\r\n\r\nCommit e0b06678aa lets us expanding a GPDB cluster without a restart,\r\nthe number of segments may changes during a transaction now, so we\r\nneed to take care of the numsegments.\r\n\r\nWe now have two way to get segments number, 1) from GpIdentity.numsegments\r\n2) from gp_segment_configuration (cdb_component_dbs) which dispatcher used\r\nto decide the segments range of dispatching. We did some hard work to\r\nupdate GpIdentity.numsegments correctly within e0b06678aa which made the\r\nmanagement of segments more complicated, now we want to use an easier way\r\nto do it:\r\n\r\n1. We only allow getting segments info (include number of segments) through\r\ngp_segment_configuration, gp_segment_configuration has newest segments info,\r\nthere is no need to update GpIdentity.numsegments, GpIdentity.numsegments is\r\nleft only for debugging and can be removed totally in the future.\r\n\r\n2. Each global transaction fetches/updates the newest snapshot of\r\ngp_segment_configuration and never change it until the end of transaction\r\nunless a writer gang is lost, so a global transaction can see consistent\r\nstate of segments. We used to use gxidDispatched to do the same thing, now\r\nit can be removed.\r\n\r\n* Remove GpIdentity.numsegments\r\n\r\nGpIdentity.numsegments take no effect now, remove it. This commit\r\ndoes not remove gp_num_contents_in_cluster because it needs to\r\nmodify utilities like gpstart, gpstop, gprecoverseg etc, let's\r\ndo such cleanup work in another PR.\r\n\r\n* Exchange the default UP/DOWN value in fts cache\r\n\r\nPreviously, Fts prober read gp_segment_configuration, checked the\r\nstatus of segments and then set the status of segments in the shared\r\nmemory struct named ftsProbeInfo->fts_status[], so other components\r\n(mainly used by dispatcher) can detect a segment was down.\r\n\r\nAll segments were initialized as down and then be updated to up in\r\nmost common cases, this brings two problems:\r\n\r\n1. The fts_status is invalid until FTS does the first loop, so QD\r\nneed to check ftsProbeInfo->fts_statusVersion > 0\r\n2. gpexpand add a new segment in gp_segment_configuration, the\r\nnew added segment may be marked as DOWN if FTS doesn't scan it\r\nyet.\r\n\r\nThis commit changes the default value from DOWN to UP which can\r\nresolve problems mentioned above.\r\n\r\n* Fts should not be used to notify backends that a gpexpand occurs\r\n\r\nAs Ashwin mentioned in PR#5679, \"I don't think giving FTS responsibility to\r\nprovide new segment count is right. FTS should only be responsible for HA\r\nof the segments. The dispatcher should independently figure out the count\r\nbased on catalog.gp_segment_configuration should be the only way to get\r\nthe segment count\", FTS should decouple from gpexpand.\r\n\r\n* Access gp_segment_configuration inside a transaction\r\n\r\n* upgrade log level from ERROR to FATAL if expand version changed\r\n\r\n* Modify gpexpand test cases according to new design", "committedDate": "2020-06-03T17:41:41Z", "type": "commit"}, {"oid": "171dcfaeefb0f1226cacc650d6de041045aaa1c1", "url": "https://github.com/greenplum-db/pxf/commit/171dcfaeefb0f1226cacc650d6de041045aaa1c1", "message": "Reporting cleanup for GPDB specific errors/messages\n\nThe Greenplum specific error handling via ereport()/elog() calls was\nin need of a unification effort as some parts of the code was using a\ndifferent messaging style to others (and to upstream). This aims at\nbringing many of the GPDB error calls in line with the upstream error\nmessage writing guidelines and thus make the user experience of\nGreenplum more consistent.\n\nThe main contributions of this patch are:\n\n* errmsg() messages shall start with a lowercase letter, and not end\n  with a period. errhint() and errdetail() shall be complete sentences\n  starting with capital letter and ending with a period. This attempts\n  to fix this on as many ereport() calls as possible, with too detailed\n  errmsg() content broken up into details and hints where possible.\n\n* Reindent ereport() calls to be more consistent with the common style\n  used in upstream and most parts of Greenplum:\n\n\tereport(ERROR,\n\t\t\t(errcode(<CODE>),\n\t\t\t errmsg(\"short message describing error\"),\n\t\t\t errhint(\"Longer message as a complete sentence.\")));\n\n* Avoid breaking messages due to long lines since it makes grepping\n  for error messages harder when debugging. This is also the de facto\n  standard in upstream code.\n\n* Convert a few internal error ereport() calls to elog(). There are\n  no doubt more that can be converted, but the low hanging fruit has\n  been dealt with. Also convert a few elog() calls which are user\n  facing to ereport().\n\n* Update the testfiles to match the new messages.\n\nSpelling and wording is mostly left for a follow-up commit, as this was\ngetting big enough as it was. The most obvious cases have been handled\nbut there is work left to be done here.\n\nDiscussion: https://github.com/greenplum-db/gpdb/pull/6378\nReviewed-by: Ashwin Agrawal <aagrawal@pivotal.io>\nReviewed-by: Heikki Linnakangas <hlinnakangas@pivotal.io>", "committedDate": "2020-06-03T17:41:41Z", "type": "commit"}, {"oid": "c63168e0fe8b44209b0075b3b9297b7a0d4eed8c", "url": "https://github.com/greenplum-db/pxf/commit/c63168e0fe8b44209b0075b3b9297b7a0d4eed8c", "message": "Fix various typos in gpcontrib", "committedDate": "2020-06-03T17:41:41Z", "type": "commit"}, {"oid": "c142c08aeccba0359088cbb690da550fcec9731b", "url": "https://github.com/greenplum-db/pxf/commit/c142c08aeccba0359088cbb690da550fcec9731b", "message": "Remove truncateStringInfo.\n\nA few places were using it in a somewhat strange way, to build comma\nseparated lists of strings. Change those to use a more idiomatic pattern.\nOther callers were calling it to truncate it to zero, replace those with\nthe upstream resetStringInfo() macro.", "committedDate": "2020-06-03T17:41:42Z", "type": "commit"}, {"oid": "7aee4a41aacbcad9a2e9d78512a82b1b0bf7d488", "url": "https://github.com/greenplum-db/pxf/commit/7aee4a41aacbcad9a2e9d78512a82b1b0bf7d488", "message": "Remove gphdfs from source code\n\ngphdfs is being deprecated for GPDB 6. This commit removes the\nfollowing:\n- Remove gphdfs from pipelines\n- Remove gphdfs from gpcontrib\n- Remove gphdfs from Makefile\n- Remove tests using gphdfs\n- Remove GUCs, code, and comments used for gphdfs\n- Remove gphdfs from GPDB docs\n- Remove avro and parquet formats", "committedDate": "2020-06-03T17:41:42Z", "type": "commit"}, {"oid": "a5b780701ccaf30ef244335424dbe0378553edc2", "url": "https://github.com/greenplum-db/pxf/commit/a5b780701ccaf30ef244335424dbe0378553edc2", "message": "Re-introduce headerguards in libchurl header\n\nCommit ad6b920fe648a5c1f71b1af33a891e6281b1e575 accidentally removed\nthe headerguards due to them being namedd GPHDFS, even though they\naren't GPHDFS related. This caused a lot of redefenition warnings at\nbuild time, which are fixed by this.", "committedDate": "2020-06-03T17:41:42Z", "type": "commit"}, {"oid": "f8582c4dfd0ca80c323da62be9246604237c90b8", "url": "https://github.com/greenplum-db/pxf/commit/f8582c4dfd0ca80c323da62be9246604237c90b8", "message": "Stop including \"executor/executor.h\" in builtins.h.\n\nIt was only needed for EState. builtins.h is included from many different\nplaces, so it seems good to not pull in executor.h. Add explicit #includes\ninto many places that were relying on the indirectly included executor.h.", "committedDate": "2020-06-03T17:41:42Z", "type": "commit"}, {"oid": "35b2eec6fe089b8692e5be0885ae8326bde42b36", "url": "https://github.com/greenplum-db/pxf/commit/35b2eec6fe089b8692e5be0885ae8326bde42b36", "message": "Propagate column projection information to external tables (#6941)\n\nWe introduce a new structure `ExternalSelectDesc` in ExtProtocolData\r\nthat encapsulates projection information (`ProjectionInfo`) as well\r\nas filter qualifiers. This allows for external protocols to do filter\r\npushdown and column projection (which is the contribution of this PR).\r\nWe have modified the PXF protocol to make use of both these attributes.<F24><F25>\r\n\r\nCo-authored-by: Francisco Guerrero <aguerrero@pivotal.io>\r\nCo-authored-by: Shivram Mani <smani@pivotal.io>", "committedDate": "2020-06-03T17:41:42Z", "type": "commit"}, {"oid": "a97ddf0e363ad6f5c812fcc3ae6efa7febd6c3ea", "url": "https://github.com/greenplum-db/pxf/commit/a97ddf0e363ad6f5c812fcc3ae6efa7febd6c3ea", "message": "Restore previous logic for PXF HAS-FILTER header\n\n- This will allow existing PXF Release (java) continue working with the\n  gpdb 6", "committedDate": "2020-06-03T17:41:42Z", "type": "commit"}, {"oid": "4d07f5da0c667431c9255eed33bd477a951f9391", "url": "https://github.com/greenplum-db/pxf/commit/4d07f5da0c667431c9255eed33bd477a951f9391", "message": "PXF Column Projection Support for non simple vars  (#7075)\n\n* Support non simple vars from ProjectionInfo\r\n* Add code to comments and add add_projection_index_header function", "committedDate": "2020-06-03T17:41:42Z", "type": "commit"}, {"oid": "1532d8dffbab1cc429ccd4701ba0ea8510494658", "url": "https://github.com/greenplum-db/pxf/commit/1532d8dffbab1cc429ccd4701ba0ea8510494658", "message": "Remove XID and segmentID from the write path sent to PXF (#7234)\n\n- The transaction ID and segment ID are only used by a subset of\r\n  profiles. PXF should be able to append the transaction and segment IDs\r\n  depending on the profile using the header information.\r\n- Remove write_file_name, do not send path", "committedDate": "2020-06-03T17:41:42Z", "type": "commit"}, {"oid": "4d42b6517fea9180ca5675e599b38ab6f9496eb5", "url": "https://github.com/greenplum-db/pxf/commit/4d42b6517fea9180ca5675e599b38ab6f9496eb5", "message": "Allow PXF to talk to custom host and port (#7292)\n\n- Read PXF host/port from environment variables\r\n- Add functions to get the PXF port and host\r\n- Add unit tests for get_pxf_port get_pxf_host\r\nWe store the current value of the environment variable, then we set a\r\ncustom host/port, run the tests, and finally restore the value of the\r\nenvironment variable.\r\n- Handle error when parsing PXF_PORT", "committedDate": "2020-06-03T17:41:43Z", "type": "commit"}, {"oid": "e4323b0584b718bfb1bd0d8a1e9bf52dcf125e0f", "url": "https://github.com/greenplum-db/pxf/commit/e4323b0584b718bfb1bd0d8a1e9bf52dcf125e0f", "message": "Mark internal functions as static\n\nThe libchurl abstraction layer has many internal helper functions\nwhich weren't marked static and thus exported. Fix by marking all\nas static.\n\nReviewed-by: Francisco Guerrero <aguerrero@pivotal.io>", "committedDate": "2020-06-03T17:41:43Z", "type": "commit"}, {"oid": "623e6cdb4eeaa041bfb3970d1fd4ce65be6402e7", "url": "https://github.com/greenplum-db/pxf/commit/623e6cdb4eeaa041bfb3970d1fd4ce65be6402e7", "message": "Fix potential pfree of NULL pointer\n\nIf strlen(addr) is zero then based on how get_dest_address() works\naddr will be NULL, and pfree() on NULL is not permitted.  Also, we\nknow that addr will either be a non-empty string or NULL, so we can\njust as well test for addr being NULL and avoid a strlen() call.\n\nFix by only pfreeing when addr is set. (this is in an elog(ERROR..)\ncontext so freeing isn't terribly interesting but it also doesn't\nhurt so I'm keeping the current codepath.)\n\nReviewed-by: Francisco Guerrero <aguerrero@pivotal.io>", "committedDate": "2020-06-03T17:41:43Z", "type": "commit"}, {"oid": "a110adab86cc7c645f2d6ff7a8a498f519f32ebd", "url": "https://github.com/greenplum-db/pxf/commit/a110adab86cc7c645f2d6ff7a8a498f519f32ebd", "message": "Avoid zeroing out memory when not required\n\nThe only time the internal buffer cleanup code was called was just\nbefore freeing the entire context, so individually zeroing out the\nmembers is pointless. Remove the function entirely and inline the\nbuffer freeing into the context cleanup codepath.\n\nFor zeroing the error buffer, it's only called right after allocating\nthe error buffer with palloc0() in the first place so the memory will\nalways be zeroed out when reaching here.\n\nReviewed-by: Francisco Guerrero <aguerrero@pivotal.io>", "committedDate": "2020-06-03T17:41:43Z", "type": "commit"}, {"oid": "f89ed28337364c45b021989745f1780298d088d4", "url": "https://github.com/greenplum-db/pxf/commit/f89ed28337364c45b021989745f1780298d088d4", "message": "Skip storing the last response as it's unused\n\nThe header callback was storing the response in the context, but as\nit was never used we might as well save the memory and just return\nthe required return of the number of bytes we would've saved should\nwe have allocated.\n\nReviewed-by: Francisco Guerrero <aguerrero@pivotal.io>", "committedDate": "2020-06-03T17:41:43Z", "type": "commit"}, {"oid": "afe4654b3da27936a0d8104b64fd5ad871288871", "url": "https://github.com/greenplum-db/pxf/commit/afe4654b3da27936a0d8104b64fd5ad871288871", "message": "Remove superfluous NULL check\n\nThe curl slist API properly handle NULLs so we can be less verbose\nand skip the check before passing to the slist cleanup function.\n\nReviewed-by: Francisco Guerrero <aguerrero@pivotal.io>", "committedDate": "2020-06-03T17:41:43Z", "type": "commit"}, {"oid": "38ee0f48011bb80f0257f28c4695900a605080df", "url": "https://github.com/greenplum-db/pxf/commit/38ee0f48011bb80f0257f28c4695900a605080df", "message": "PXF: Fix repository path\n\nFix remnant PXF paths that were pointing to the old repository path.\n\ngpAux/extensions/pxf -> gpcontrib/pxf\n\nBackport to 6X_STABLE", "committedDate": "2020-06-03T17:41:43Z", "type": "commit"}, {"oid": "4b575ebd052a686fae6f5b1f633de56f39abfbea", "url": "https://github.com/greenplum-db/pxf/commit/4b575ebd052a686fae6f5b1f633de56f39abfbea", "message": "6X Backport: Fix the path of PXF subdir (#7831)", "committedDate": "2020-06-03T17:41:43Z", "type": "commit"}, {"oid": "cd0d654f4bbd30fdd76aa0c725c44711f9e4d418", "url": "https://github.com/greenplum-db/pxf/commit/cd0d654f4bbd30fdd76aa0c725c44711f9e4d418", "message": "Propagate external table format options to PXF headers\n\nCurrently, PXF is not propagating the format options in the external\ntable framework. In Foreign Data Wrappers, these options are defined at\nthe foreign table-level and are being propagated to PXF.\n\nIn order for the PXF Server to better support both FDW and external\ntables we are consistently passing format information from both clients.", "committedDate": "2020-06-03T17:41:44Z", "type": "commit"}, {"oid": "92c372a2dc53f13263c4dac5f6c009dbed1fcdc2", "url": "https://github.com/greenplum-db/pxf/commit/92c372a2dc53f13263c4dac5f6c009dbed1fcdc2", "message": "Fix missing header file in pxfheaders_test.c\n\nAn elusive missing header file was detected when the Ubuntu job failed\nin CI. Centos and Mac did not show any indication of a missing header\nfile and no side effects were detected. However, Ubuntu was returning an\nint32 in makeDefElem instead of a 64-bit pointer.\n\nCo-authored-by: Ashwin Agrawal <aagrawal@pivotal.io>\nCo-authored-by: Jesse Zhang <jzhang@pivotal.io>\nCo-authored-by: Francisco Guerrero <aguerrero@pivotal.io>", "committedDate": "2020-06-03T17:41:44Z", "type": "commit"}, {"oid": "190e94726fd4bdeeb2ce8797296552211dbfef5f", "url": "https://github.com/greenplum-db/pxf/commit/190e94726fd4bdeeb2ce8797296552211dbfef5f", "message": "Fix warnings for unit tests.\n\nCo-authored-by: Melanie Plageman <mplageman@pivotal.io>", "committedDate": "2020-06-03T17:41:44Z", "type": "commit"}, {"oid": "264f98990d66902727611fdf481f7468ef96c8da", "url": "https://github.com/greenplum-db/pxf/commit/264f98990d66902727611fdf481f7468ef96c8da", "message": "Don't allocate storage according to a void type\n\nThe CURL and CURLM structs are opaque, so allocating a sizeof them\nwill incur a compiler warning in clang and gcc:\n\nwarning: invalid application of \u2018sizeof\u2019 to a void type [-Wpointer-arith]\n  context->curl_handle = palloc0(sizeof(CURL));\n\nAs the mocked object is only used for non-NULL verifications, make\nthem properly callocate a dummy allocation which will be enough for\nthe unit tests we have.\n\nReviewed-by: Ashwin Agrawal <aagrawal@pivotal.io>\nReviewed-by: Asim R P <apraveen@pivotal.io>", "committedDate": "2020-06-03T17:41:44Z", "type": "commit"}, {"oid": "067e9eff288b34af3c1a9f943a3f1ac7a4a75452", "url": "https://github.com/greenplum-db/pxf/commit/067e9eff288b34af3c1a9f943a3f1ac7a4a75452", "message": "Remove unused unittest functions\n\nThese functions are either dead supporting code or tests which aren't\nconnected (which also doesn't work at all). Fix the unused function\ncompiler warning by removing.\n\nReviewed-by: Ashwin Agrawal <aagrawal@pivotal.io>\nReviewed-by: Asim R P <apraveen@pivotal.io>", "committedDate": "2020-06-03T17:41:44Z", "type": "commit"}, {"oid": "c4486030fdfc18cd2c4bd74653d798b72dfa6143", "url": "https://github.com/greenplum-db/pxf/commit/c4486030fdfc18cd2c4bd74653d798b72dfa6143", "message": "Use the proper datatype in unittests\n\nFix various incorrecly initialized varibles. The fact that the tests\nstill worked fine with these doesn't instill too much confidence in\nthe mocks being representative, but let's fix the warnings anyways.\n\n* The fragments member in the GPHDUri struct defines a FragmentData\nList, so saving a straight FragmentData in the list is obviously\nincorrect and generates a compiler warning. Fix by making a proper\nlist of the FragmentData.\n\n* The pxf_serialize_filter_list test is testing the serialization of\na mock list of operators, it was however casting a NullTest into an\nOperatorExpression which is quite bogus. The actual test didn't care\nand still worked off the NullTest, so properly pass a NullTest into\nthe list to avoid a compiler warning.\n\n* PGPROC is an array, so initalizing with just {0} is incorrect, it\ndoes require {{0}}.\n\nReviewed-by: Ashwin Agrawal <aagrawal@pivotal.io>\nReviewed-by: Asim R P <apraveen@pivotal.io>", "committedDate": "2020-06-03T17:41:44Z", "type": "commit"}, {"oid": "42ec8870b158a1d0d0c0307cece047f1a189cc4a", "url": "https://github.com/greenplum-db/pxf/commit/42ec8870b158a1d0d0c0307cece047f1a189cc4a", "message": "Fix format string compiler warning in tests\n\nCalling snprintt and appendStringInfo without a proper format string\ngenerate a compiler warning. Fix by properly passing a dummy format\nfor snprintf and use appendStringInfoString which avoids the use of\na format completely.\n\nReviewed-by: Ashwin Agrawal <aagrawal@pivotal.io>\nReviewed-by: Asim R P <apraveen@pivotal.io>", "committedDate": "2020-06-03T17:41:44Z", "type": "commit"}, {"oid": "298c486d23cdf6e2c247146c0bbf532fbfd10f1a", "url": "https://github.com/greenplum-db/pxf/commit/298c486d23cdf6e2c247146c0bbf532fbfd10f1a", "message": "Remove bogus code\n\nSimply calling a variable is legal, but bogus C code. By the looks of\nthings this is a copy/pasteo or typo, but since the test works without\nit we can assume it useless so fix by removing.\n\nReviewed-by: Ashwin Agrawal <aagrawal@pivotal.io>\nReviewed-by: Asim R P <apraveen@pivotal.io>", "committedDate": "2020-06-03T17:41:44Z", "type": "commit"}, {"oid": "87216d558d312a1d853d8d02c56b5fb9113db909", "url": "https://github.com/greenplum-db/pxf/commit/87216d558d312a1d853d8d02c56b5fb9113db909", "message": "Fix various style nits in the unittests\n\nWhile hacking around in the tests, some things stood as warranting\nfixing as they were hard to unsee.\n\nReviewed-by: Ashwin Agrawal <aagrawal@pivotal.io>\nReviewed-by: Asim R P <apraveen@pivotal.io>", "committedDate": "2020-06-03T17:41:44Z", "type": "commit"}, {"oid": "c12a0a5af2eea383d2f2f700498b4c46fd62927b", "url": "https://github.com/greenplum-db/pxf/commit/c12a0a5af2eea383d2f2f700498b4c46fd62927b", "message": "PXF: Do not rely on getDistributedTransactionId()\n\nPXF relies on getDistributedTransactionId() to distribute load among\nsegments. This is important when the fragmentation call returns a small\nlist of fragments. Recently, the behavior of\ngetDistributedTransactionId() changed, and it no longer returns a value\nfor SELECT queries. As an alternative, we will use a combination of the\nsession id and the command count to balance the load on PXF.\n\nThis is a backport from master.", "committedDate": "2020-06-03T17:41:45Z", "type": "commit"}, {"oid": "2e95932cf9c19263c50bf8cc502f1dd28d17ecd8", "url": "https://github.com/greenplum-db/pxf/commit/2e95932cf9c19263c50bf8cc502f1dd28d17ecd8", "message": "PXF: Encode header values for custom headers\n\nStarting in Tomcat version 7.0.100, HTTP header validation was tightened\ndisallowing invalid header values. These changed in Tomcat were a side\neffect of fixes for CVE-2020-1935. This issue manifests when a table is\ncreated with non printable delimiters, for example:\n\n    CREATE EXTERNAL TABLE foo ()\n    LOCATION ('pxf://some/path?PROFILE=demo&SERVER=demo')\n    FORMAT 'CSV' ( DELIMITER E'\\x01' );\n\nThe delimiter value is passed to PXF Server in an HTTP header, however\nunencoded. This is causing Tomcat drop headers with invalid header\nvalues, and causing PXF to behave incorrectly.\n\nIn this commit, we encode custom (X-GP-*) header values, and add a new\nheader to indicate that custom header values are encoded, so they can be\nappropriately decoded on the PXF Server side.", "committedDate": "2020-06-03T17:41:45Z", "type": "commit"}, {"oid": "1f2e59530f86943c8df130bb14b8227f966f86d1", "url": "https://github.com/greenplum-db/pxf/commit/1f2e59530f86943c8df130bb14b8227f966f86d1", "message": "added IntelliJ files to gitignore", "committedDate": "2020-06-03T17:41:45Z", "type": "commit"}, {"oid": "5938ad7d1a2ec56749b9cff8274a0cc4fdafb29e", "url": "https://github.com/greenplum-db/pxf/commit/5938ad7d1a2ec56749b9cff8274a0cc4fdafb29e", "message": "Fix glob matching in PXF paths for Hadoop-compatible filesystems\n\nWhen querying a PXF external table with some glob matching paths in the\nLOCATION URI, Tomcat is rejecting the paths. In this commit, we remove\nthe `path` query string parameter as it has been deprecated and is no\nlonger used in the server, and it's causing issues with Tomcat because\nthe query string parameter is not URL-encoded.", "committedDate": "2020-06-03T17:41:45Z", "type": "commit"}, {"oid": "2674c5a49da8b1f92847779175bf5691f3139042", "url": "https://github.com/greenplum-db/pxf/commit/2674c5a49da8b1f92847779175bf5691f3139042", "message": "Continuous Integration: independent release process\n\nThis commit introduces several new pipelines to aid a PXF release\nprocess independent of any underlying SQL database. This commit thus\nincludes scripts for making and managing a PXF RPM, which includes the C\nextension, whose code now lives under external-table/. These are the new\npipelines:\n\n* pivnet_artifacts: a pipeline that fetches releases of GPDB from\n  PivNet, aka TanzuNet\n* pxf-build: pipeline that builds and releases new PXF artifacts\n* dev-pxf-build: dev version of pxf-build, much abbreviated\n* pxf-certification: pipeline that tests existing PXF artifacts against\n  new versions of Greenplum\n* pxf_pr_pipeline: new PR pipeline which uses the new build process\n\nVersion is now managed at the top level, in a file `version`. By\nchanging this file to a non-SNAPSHOT version, we can create a release\nusing the pxf-build pipeline. This causes a new tag/release to be\ntriggered on GitHub (Releases API), as well as a new SNAPSHOT version to\nbe committed.\n\nFurther, by uploading an OSL file to the appropriate cloud location,\nwe trigger publication of our release to the Release Engineering team.\n\nAlong with an independent release, we are now also installing PXF not\nunder GPHOME but separately in PXF_HOME. Thus this commit also has\nchanges to the PXF CLI to reflect the new install location. This\nincludes a new command called `pxf [cluster] register` to re-install the\nPXF C extension under GPHOME.\n\nOther noteworthy changes include:\n\n* The new pipelines make use of smaller images that don't include PXF\n  dependencies, but instead pull in those dependencies via tarballs that\n  are pre-built.\n* The new pattern for setting pipelines is to have targets in\n  concourse/Makefile.\n* Cloud tests have been hardened to reduce flakiness\n* In CI scripts we source ~gpadmin/.pxfrc which is cached on each image\n* Slack integrations have been added for pxf-certification, pxf-build,\n  and dev-pxf-build pipelines\n\nCo-authored-by: Oliver Albertini <oalbertini@vmware.com>\nCo-authored-by: Alexander Denissov <adenissov@pivotal.io>\nCo-authored-by: Francisco Guerrero <aguerrero@pivotal.io>", "committedDate": "2020-06-03T18:16:02Z", "type": "commit"}, {"oid": "2674c5a49da8b1f92847779175bf5691f3139042", "url": "https://github.com/greenplum-db/pxf/commit/2674c5a49da8b1f92847779175bf5691f3139042", "message": "Continuous Integration: independent release process\n\nThis commit introduces several new pipelines to aid a PXF release\nprocess independent of any underlying SQL database. This commit thus\nincludes scripts for making and managing a PXF RPM, which includes the C\nextension, whose code now lives under external-table/. These are the new\npipelines:\n\n* pivnet_artifacts: a pipeline that fetches releases of GPDB from\n  PivNet, aka TanzuNet\n* pxf-build: pipeline that builds and releases new PXF artifacts\n* dev-pxf-build: dev version of pxf-build, much abbreviated\n* pxf-certification: pipeline that tests existing PXF artifacts against\n  new versions of Greenplum\n* pxf_pr_pipeline: new PR pipeline which uses the new build process\n\nVersion is now managed at the top level, in a file `version`. By\nchanging this file to a non-SNAPSHOT version, we can create a release\nusing the pxf-build pipeline. This causes a new tag/release to be\ntriggered on GitHub (Releases API), as well as a new SNAPSHOT version to\nbe committed.\n\nFurther, by uploading an OSL file to the appropriate cloud location,\nwe trigger publication of our release to the Release Engineering team.\n\nAlong with an independent release, we are now also installing PXF not\nunder GPHOME but separately in PXF_HOME. Thus this commit also has\nchanges to the PXF CLI to reflect the new install location. This\nincludes a new command called `pxf [cluster] register` to re-install the\nPXF C extension under GPHOME.\n\nOther noteworthy changes include:\n\n* The new pipelines make use of smaller images that don't include PXF\n  dependencies, but instead pull in those dependencies via tarballs that\n  are pre-built.\n* The new pattern for setting pipelines is to have targets in\n  concourse/Makefile.\n* Cloud tests have been hardened to reduce flakiness\n* In CI scripts we source ~gpadmin/.pxfrc which is cached on each image\n* Slack integrations have been added for pxf-certification, pxf-build,\n  and dev-pxf-build pipelines\n\nCo-authored-by: Oliver Albertini <oalbertini@vmware.com>\nCo-authored-by: Alexander Denissov <adenissov@pivotal.io>\nCo-authored-by: Francisco Guerrero <aguerrero@pivotal.io>", "committedDate": "2020-06-03T18:16:02Z", "type": "forcePushed"}]}