{"pr_number": 604, "pr_title": "DEVX-2184: \"Detecting Abnormal Transactions\" recipe migration", "pr_createdAt": "2020-10-23T23:48:02Z", "pr_url": "https://github.com/confluentinc/kafka-tutorials/pull/604", "timeline": [{"oid": "8b7f3ea2a544340bd658db86bd0178639a43624a", "url": "https://github.com/confluentinc/kafka-tutorials/commit/8b7f3ea2a544340bd658db86bd0178639a43624a", "message": "DEVX-2184; start migration", "committedDate": "2020-10-15T22:44:34Z", "type": "commit"}, {"oid": "027c95a3e31b2f2d79d53b3156c6dfb1ab5125cd", "url": "https://github.com/confluentinc/kafka-tutorials/commit/027c95a3e31b2f2d79d53b3156c6dfb1ab5125cd", "message": "DEVX-2184; first pass at outline", "committedDate": "2020-10-21T16:37:22Z", "type": "commit"}, {"oid": "9b9c153c31008f5e7e62957a46246db31f898f1e", "url": "https://github.com/confluentinc/kafka-tutorials/commit/9b9c153c31008f5e7e62957a46246db31f898f1e", "message": "DEVX-2184; provide clearer explainations and fix steps", "committedDate": "2020-10-22T20:08:24Z", "type": "commit"}, {"oid": "3c49c1f567182f5184bf1074321536c007b7ed59", "url": "https://github.com/confluentinc/kafka-tutorials/commit/3c49c1f567182f5184bf1074321536c007b7ed59", "message": "DEVX-2184; working on testing", "committedDate": "2020-10-22T23:02:38Z", "type": "commit"}, {"oid": "b80999f1185c696f7810b218da6cf69fe3c4cdac", "url": "https://github.com/confluentinc/kafka-tutorials/commit/b80999f1185c696f7810b218da6cf69fe3c4cdac", "message": "DEVX-2184; fix test", "committedDate": "2020-10-23T20:26:40Z", "type": "commit"}, {"oid": "0791bc08e20c8939f919d1d59738d42a77d940ce", "url": "https://github.com/confluentinc/kafka-tutorials/commit/0791bc08e20c8939f919d1d59738d42a77d940ce", "message": "DEVX-2184; change title/heading", "committedDate": "2020-10-23T23:32:12Z", "type": "commit"}, {"oid": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "url": "https://github.com/confluentinc/kafka-tutorials/commit/e73b70cc2a2957e4e004f6e786eb79a9fe411727", "message": "Merge branch 'master' into DEVX-2184", "committedDate": "2020-10-23T23:49:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5Njk3NA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511596974", "bodyText": "@awalther28 is it possible that \"abnormal events\" might be too domain specific?  If so, maybe add a clause here with a few more words that generalizes this, because \"abnormal events\" might not be well understood or descriptive enough?", "author": "ybyzek", "createdAt": "2020-10-25T13:24:58Z", "path": "_data/tutorials.yaml", "diffHunk": "@@ -484,3 +483,24 @@ masking-data:\n     ruby: disabled\n     scala: disabled\n     swift: disabled\n+\n+anomaly-detection:\n+  title: \"Detecting abnormal events\"\n+  meta-description: \"Detecting abnormal events\"\n+  slug: \"/anomaly-detection\"\n+  question: \"How do I find abnormal events?\"", "originalCommit": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5NzI2OA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511597268", "bodyText": "Feel free to wordsmith...\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              introduction: \"Consider a topic with events containing information about financial transactions and a table with known suspicious names. A common pattern for fraudsters is to disguise transactions under the name of a popular company, the idea being that the chances of them being recognized is very low. For example, transactions labeled Verizon, Citibank, USPS, etc., are likely to look similar and blend in.\n          \n          \n            \n              introduction: \"A common pattern for fraudsters is to disguise transactions under the name of a popular company, the idea being that the chances of them being recognized is very low. For example, transactions labeled Verizon, Citibank, USPS, etc., are likely to look similar and blend in.  This tutorial shows you how to identify this pattern of behavior by detecting 'abnormal' transactions that occur within a window of time", "author": "ybyzek", "createdAt": "2020-10-25T13:27:44Z", "path": "_data/tutorials.yaml", "diffHunk": "@@ -484,3 +483,24 @@ masking-data:\n     ruby: disabled\n     scala: disabled\n     swift: disabled\n+\n+anomaly-detection:\n+  title: \"Detecting abnormal events\"\n+  meta-description: \"Detecting abnormal events\"\n+  slug: \"/anomaly-detection\"\n+  question: \"How do I find abnormal events?\"\n+  introduction: \"Consider a topic with events containing information about financial transactions and a table with known suspicious names. A common pattern for fraudsters is to disguise transactions under the name of a popular company, the idea being that the chances of them being recognized is very low. For example, transactions labeled Verizon, Citibank, USPS, etc., are likely to look similar and blend in.", "originalCommit": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5NzUwNg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511597506", "bodyText": "Would it be appropriate to leverage the new \"Short Answer\" capabilities, a la https://github.com/confluentinc/kafka-tutorials/blob/master/_data/harnesses/aggregating-count/ksql.yml#L1-L7", "author": "ybyzek", "createdAt": "2020-10-25T13:29:44Z", "path": "_data/harnesses/anomaly-detection/ksql.yml", "diffHunk": "@@ -0,0 +1,125 @@\n+dev:", "originalCommit": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjIxNjAyMg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512216022", "bodyText": "\ud83e\udd26 I can't believe I forgot this after talking about it last week. I added an answer section.", "author": "awalther28", "createdAt": "2020-10-26T19:30:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5NzUwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5ODAzOQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511598039", "bodyText": "Other workflows sometimes presume pre-existence of the Kafka topic before creating the ksqlDB stream or table.  Would it help to add a note about what happens in this case where the Kafka topic doesn't already exist?", "author": "ybyzek", "createdAt": "2020-10-25T13:34:27Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/create-suspicious-names-table.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+First, you will need to create a ksqlDB table and Kafka topic to represent the suspicious names data. A table is more fitting for this suspicious names data because it is a mutable collection that changes over time. We may want to add company names to this table or remove them in the future.\n+", "originalCommit": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjIxODAyNQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512218025", "bodyText": "I added a little blurb about kafka topics that should address your comment (below)\n\nFirst, you will need to create a ksqlDB table and Kafka topic to represent the suspicious names data. You can create a table from a Kafka topic or derive one from an existing stream or table. In both cases, a table's underlying data is durably stored in a topic on the Kafka brokers. In this tutorial we are creating a new Kafka topic for our table. If kafka_topic was not specified in the query, a new Kafka topic would be created for us.", "author": "awalther28", "createdAt": "2020-10-26T19:34:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5ODAzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5ODY3Mg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511598672", "bodyText": "Given that there is no data in the topic yet, is this required?", "author": "ybyzek", "createdAt": "2020-10-25T13:40:00Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/set-properties.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+Set ksqlDB to process data from the beginning of each Kafka topic:", "originalCommit": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjIzMTM1NQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512231355", "bodyText": "Yes it is required. I ran through the tutorial without it, the select statements consume from latest. With no data coming in, the derived streams wont' have any data in them.", "author": "awalther28", "createdAt": "2020-10-26T19:58:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5ODY3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5ODgyNQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511598825", "bodyText": "Consistency check: what should be in single quotes, backticks, double quotes?  Not sure we have an established style guide, WDYT?  cc: @bbejeck", "author": "ybyzek", "createdAt": "2020-10-25T13:41:28Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/create-suspicious-transactions-stream.adoc", "diffHunk": "@@ -0,0 +1,14 @@\n+Using the table of suspicious names and stream of transactions, create a new stream of events containing transactions that were sent to an account name contained in the 'suspicious_names' table. We can do this by performing an `INNER JOIN`. In this case the `INNER JOIN` will couple events in the transaction stream where the \"recipient\" is the same as \"company_name\" in the suspicious_names table. The stream created below will continuously be populated by the coupled events created by the query.", "originalCommit": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5ODk0Mg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511598942", "bodyText": "\"we flagged\" -- did we flag them or is it just that their names were in the table?", "author": "ybyzek", "createdAt": "2020-10-25T13:42:29Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/find-suspicious-transactions.adoc", "diffHunk": "@@ -0,0 +1,11 @@\n+Inspect the new stream.\n+\n++++++\n+<pre class=\"snippet\"><code class=\"sql\">{% include_raw tutorials/anomaly-detection/ksql/code/tutorial-steps/dev/find-suspicious-transactions.sql %}</code></pre>\n++++++\n+\n+Note that some of the transactions we inserted earlier were to companies that we flagged as possibly suspicious.", "originalCommit": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjIyMDM1Ng==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512220356", "bodyText": "I altered this sentence to be more direct\n\nNote that some of the transactions we inserted earlier were to companies that are in the suspicious names table.", "author": "awalther28", "createdAt": "2020-10-26T19:38:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5ODk0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5OTA3Mw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511599073", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            A single transaction to one of the companies in the suspicious_names table is probably okay, but multiple transactions to one or more of those companies in a 24-hour period is alarming. ksqlDB gives us the ability to see if alarming activity is/was present for a particular user with the following query.\n          \n          \n            \n            For this use case, let's say that a single transaction to one of the companies in the suspicious_names table is probably okay, but multiple transactions to one or more of those companies in a 24-hour period is an anomaly. ksqlDB gives us the ability to see if any anomalies are present for a particular user with the following query.", "author": "ybyzek", "createdAt": "2020-10-25T13:43:54Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/create-accounts-to-monitor-table.adoc", "diffHunk": "@@ -0,0 +1,17 @@\n+A single transaction to one of the companies in the suspicious_names table is probably okay, but multiple transactions to one or more of those companies in a 24-hour period is alarming. ksqlDB gives us the ability to see if alarming activity is/was present for a particular user with the following query.", "originalCommit": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5OTE3MA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511599170", "bodyText": "Not sure if there's a convention or not, but most of the meat in this tutorial is in this section.  Is there value in breaking this up?", "author": "ybyzek", "createdAt": "2020-10-25T13:44:40Z", "path": "_data/harnesses/anomaly-detection/ksql.yml", "diffHunk": "@@ -0,0 +1,125 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/anomaly-detection/ksql/markup/dev/init.adoc\n+\n+        - change_directory: anomaly-detection\n+          action: execute\n+          file: tutorial-steps/dev/make-dirs.sh\n+          render:\n+            file: tutorials/anomaly-detection/ksql/markup/dev/make-dirs.adoc\n+\n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/anomaly-detection/ksql/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/anomaly-detection/ksql/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+    - title: Write the program interactively using the CLI", "originalCommit": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjIzMDE5MQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512230191", "bodyText": "I did move forward with having this broken down into new sections. There is value but also some obstacles of keeping ksqldb cli configurations persistent through the newly created ksqldb cli sessions that are started with each new section. Talked about in slack on this thread. This is generally not done for ksqlDB tutorials, I would guess due to the hurdles of starting new cli sessions.", "author": "awalther28", "createdAt": "2020-10-26T19:56:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5OTE3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5OTYzOQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511599639", "bodyText": "This is a lot of information that is essentially buried in a \"footnote\".  Readers often skip this as a result.  Can you move most of this out of the footnote and into the text area?", "author": "ybyzek", "createdAt": "2020-10-25T13:49:06Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/create-accounts-to-monitor-table.adoc", "diffHunk": "@@ -0,0 +1,17 @@\n+A single transaction to one of the companies in the suspicious_names table is probably okay, but multiple transactions to one or more of those companies in a 24-hour period is alarming. ksqlDB gives us the ability to see if alarming activity is/was present for a particular user with the following query.\n+\n+[source,sql]\n+----\n+CREATE TABLE accounts_to_monitor\n+    WITH (kafka_topic='accounts_to_monitor', partitions=1, value_format='JSON') AS\n+    SELECT TIMESTAMPTOSTRING(WINDOWSTART, 'yyyy-MM-dd HH:mm:ss Z') AS WINDOW_START, // <1>\n+           TIMESTAMPTOSTRING(WINDOWEND, 'yyyy-MM-dd HH:mm:ss Z') AS WINDOW_END,\n+           USERNAME\n+    FROM suspicious_transactions\n+    WINDOW TUMBLING (SIZE 24 HOURS) // <2>\n+    GROUP BY USERNAME\n+    HAVING COUNT(*) > 3; // <3>\n+----\n+<1> The timestamps here are important, they tell us what interval of time suspicious activity occurred.\n+<2> The `WINDOW TUMBLING` part of the query allows us to do an aggregation with distinct time boundaries. In this case our window is fixed at a length of 24 hours, does not allow gaps, and does not allow overlapping. Other types of windows are explained in the \"Collect data over time\" section of Kafka-Tutorials. If further explanation is need, checkout the link:https://docs.ksqldb.io/en/latest/concepts/time-and-windows-in-ksqldb-queries/#windows-in-sql-queries[*ksqlDB documentation about windows*]. It contains in depth descriptions and visualizations.", "originalCommit": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjIzMjc1NA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512232754", "bodyText": "This was a tricky request... The numbers in the code + \"footnote\" are called callouts in asciidoc and are meant for annotations. I did find a way to embed the callout icons in paragraphs... hopefully that is more apparent?", "author": "awalther28", "createdAt": "2020-10-26T20:01:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5OTYzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5OTg5Mg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511599892", "bodyText": "\"This Kafka topic\" -- which Kafka topic?\nDoes the topic drive, or maybe the events drive?  (a la \"event-driven\" language)", "author": "ybyzek", "createdAt": "2020-10-25T13:50:49Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/print-accounts-to-monitor.adoc", "diffHunk": "@@ -0,0 +1,17 @@\n+The ksqlDB table and thus Kafka topic contain a list of accounts against which more than three suspicious transactions have taken place in a 24-hour window.\n+\n++++++\n+<pre class=\"snippet\"><code class=\"sql\">{% include_raw tutorials/anomaly-detection/ksql/code/tutorial-steps/dev/print-accounts-to-monitor.sql %}</code></pre>\n++++++\n+\n+The output should look like the following:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"sql\">{% include_raw tutorials/anomaly-detection/ksql/code/tutorial-steps/dev/print-accounts-to-monitor.log %}</code></pre>\n++++++\n+\n+Note that if you were to alter the `LIMIT` of results to something greater than 1, you would not see any other accounts flagged even though Victor von Frankenstein had a transaction that was flagged as suspicious. If you decided to rerun the query with a new limit, use `CTRL+D` to terminate the query. +\n+\n+\n+This Kafka topic can be used to drive monitoring and alerting applications that could take action such as placing a hold on the account, notifying the card holder, etc. +", "originalCommit": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjIzMjk4Nw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512232987", "bodyText": "I altered this statement to use more event driven language per your suggestion.", "author": "awalther28", "createdAt": "2020-10-26T20:01:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTU5OTg5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTYwMDAzMw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511600033", "bodyText": "Depending on what you are trying to achieve, maybe the INSERT statements don't below here.  Just the queries.  Like, if a user were to take this to production, they just want the table/stream/queries, but not the fake data gen pieces?", "author": "ybyzek", "createdAt": "2020-10-25T13:52:01Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/make-src-file.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+Now that you have a series of statements that's doing the right thing, the last step is to put them into a file so that they can be used outside the CLI session. Create a file at `src/statements.sql` with the following content:", "originalCommit": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTk4OTA2Mw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511989063", "bodyText": "100% agree. I had mentioned this in the last paragraph of my initial PR description.\n\nI'd prefer to have my test data split out of src/statements.sql. ... Left as is, I think I need to alter the \"Take it to Production\" section due to the test data in the src/statements.sql.\nI spent a decent amount of time trying to get input.json to work (without INSERT statements), but didn't have any luck. Could very well be a newbie problem. I can dig deeper into trying to split out the sample data and reach out to SMEs, or use a statements.sql that doesn't have any sample data in the \"Take it to Production\" setting. Any advice here would be greatly appreciated \ud83d\ude42", "author": "awalther28", "createdAt": "2020-10-26T14:10:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTYwMDAzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjAxMzAyNQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512013025", "bodyText": "@awalther28 sorry I missed the note in the description.  Just for clarification, is the concern about taking out the INSERT statements that the test will then fail for the production?  If so, IIUCvyou could either (a) execute but hide the INSERT or (b) skip the test for production.  Or if I misunderstood the concern, please let me know.", "author": "ybyzek", "createdAt": "2020-10-26T14:41:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTYwMDAzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjIxNDI2Mw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512214263", "bodyText": "The production test is okay either way.\nThe concern is that the ksqlDB test runner fails when using the same data in input.json instead, hence why there are INSERT statements.\nMy input.json was failing with the following error, I had tried numerous iterations of the file:\nlocalhost:anomaly-detection awalther$ docker exec ksqldb-cli ksql-test-runner -i /opt/app/test/input.json -s /opt/app/src/statements.sql -o /opt/app/test/output.json OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release. >>>>> Test failed: Topic suspicious_transactions. Expected <6> records but it was <0> Actual records:\nFor some reason I can't share my input.json via github.", "author": "awalther28", "createdAt": "2020-10-26T19:27:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTYwMDAzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTYwMDA1NQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511600055", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Similarly, create a file at `test/output.json` with the expected outputs. ksqlDB joins its grouping key with the window boundaries, we need to use a bit of extra expression to describe what to expect. We leverage the window key to describe the start and end boundaries that the key represents. Checkout our tutorial on link:https://kafka-tutorials.confluent.io/create-tumbling-windows/ksql.html[*tumbling windows*] for a more comprehensive explanation.\n          \n          \n            \n            Create a file at `test/output.json` with the expected outputs. ksqlDB joins its grouping key with the window boundaries, we need to use a bit of extra expression to describe what to expect. We leverage the window key to describe the start and end boundaries that the key represents. Checkout our tutorial on link:https://kafka-tutorials.confluent.io/create-tumbling-windows/ksql.html[*tumbling windows*] for a more comprehensive explanation.", "author": "ybyzek", "createdAt": "2020-10-25T13:52:22Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/test/make-test-output.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+Similarly, create a file at `test/output.json` with the expected outputs. ksqlDB joins its grouping key with the window boundaries, we need to use a bit of extra expression to describe what to expect. We leverage the window key to describe the start and end boundaries that the key represents. Checkout our tutorial on link:https://kafka-tutorials.confluent.io/create-tumbling-windows/ksql.html[*tumbling windows*] for a more comprehensive explanation.", "originalCommit": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTYwMDE3OA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511600178", "bodyText": "Output from what?", "author": "ybyzek", "createdAt": "2020-10-25T13:53:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTYwMDA1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTYwMDIxMA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r511600210", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Lastly, invoke the tests using the test runner and the statements file that you created earlier:\n          \n          \n            \n            Invoke the tests using the ksqlDB test runner and the statements file that you created earlier:", "author": "ybyzek", "createdAt": "2020-10-25T13:54:08Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/test/run-tests.adoc", "diffHunk": "@@ -0,0 +1,11 @@\n+Lastly, invoke the tests using the test runner and the statements file that you created earlier:", "originalCommit": "e73b70cc2a2957e4e004f6e786eb79a9fe411727", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "dddb2bad54e99e6b38211b83cd67d417d6627e18", "url": "https://github.com/confluentinc/kafka-tutorials/commit/dddb2bad54e99e6b38211b83cd67d417d6627e18", "message": "Apply suggestions from code review\n\nCo-authored-by: Yeva Byzek <ybyzek@users.noreply.github.com>", "committedDate": "2020-10-26T14:05:42Z", "type": "commit"}, {"oid": "543045219444f279f58f5d762d4369e63c9e0a20", "url": "https://github.com/confluentinc/kafka-tutorials/commit/543045219444f279f58f5d762d4369e63c9e0a20", "message": "DEVX-2184; address comments", "committedDate": "2020-10-26T16:56:52Z", "type": "commit"}, {"oid": "7b54a9c5e23a58b9006da3d9e56013270cff9b40", "url": "https://github.com/confluentinc/kafka-tutorials/commit/7b54a9c5e23a58b9006da3d9e56013270cff9b40", "message": "DEVX-2184; fix broken tests", "committedDate": "2020-10-26T18:24:36Z", "type": "commit"}, {"oid": "9f7b9f3a8127feef28a95b9b857629d807ac615f", "url": "https://github.com/confluentinc/kafka-tutorials/commit/9f7b9f3a8127feef28a95b9b857629d807ac615f", "message": "DEVX-2184; remove 'flagging'", "committedDate": "2020-10-26T19:37:58Z", "type": "commit"}, {"oid": "b83ebc354682f61a0a3edb6a83c19705a951c8e1", "url": "https://github.com/confluentinc/kafka-tutorials/commit/b83ebc354682f61a0a3edb6a83c19705a951c8e1", "message": "DEVX-2184; add offset policy back", "committedDate": "2020-10-26T19:54:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjIzMzUwMQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512233501", "bodyText": "@awalther28 is the INNER JOIN critical to the short answer for detecting anomalies?  Is it possible that only the WINDOWING is the key piece of the solution?  (In that, INNER JOIN is only required if the data isn't already joined...).\nTwo benefits to consider if INNER JOIN were removed are (a) keeping the short answer short and (b) freeing up real estate on the site.\nI'm on the fence, just wanted to share this food for thought", "author": "ybyzek", "createdAt": "2020-10-26T20:02:25Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/answer/join-and-windowing.adoc", "diffHunk": "@@ -0,0 +1,11 @@\n+Create new stream with INNER JOIN between the table and stream.", "originalCommit": "b83ebc354682f61a0a3edb6a83c19705a951c8e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjIzOTg0Nw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512239847", "bodyText": "I think the join is pretty critical, but imo a mention of it would suffice. @ybyzek what are your thoughts on something like\n\nGiven that transaction events are joined with table reference data, use WINDOWING to group anomalous transactions. //insert windowing render here//", "author": "awalther28", "createdAt": "2020-10-26T20:14:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjIzMzUwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI0MDI3MA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512240270", "bodyText": "SGTM!", "author": "ybyzek", "createdAt": "2020-10-26T20:15:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjIzMzUwMQ=="}], "type": "inlineReview"}, {"oid": "b2fb30b0ecb9639fd67a69e6414fad1571a41fe2", "url": "https://github.com/confluentinc/kafka-tutorials/commit/b2fb30b0ecb9639fd67a69e6414fad1571a41fe2", "message": "DEVX-2184; change short answer", "committedDate": "2020-10-26T20:19:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI4NTU2Mg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512285562", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Given that transaction events are joined with table reference data, use `WINDOWING` to group anomalous transactions.\n          \n          \n            \n            Assuming transaction events are joined with table reference data, use `WINDOWING` to group anomalous transactions.", "author": "ybyzek", "createdAt": "2020-10-26T21:39:46Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/answer/join-and-windowing.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+Given that transaction events are joined with table reference data, use `WINDOWING` to group anomalous transactions.", "originalCommit": "b2fb30b0ecb9639fd67a69e6414fad1571a41fe2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI4Njc2MQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512286761", "bodyText": "Note: the order of fields in the description does not match the order of fields in the ksqlDB statement. For a user following along, can we update the fields or the query so they are in sync?", "author": "ybyzek", "createdAt": "2020-10-26T21:42:08Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/create-transactions-stream.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+Likewise, you'll need a ksqlDB stream and Kafka topic to represent transaction events. The transaction information includes the identifier, the user sending the money, the time of the transaction, and the name of the recipient. Since this data represents a historical sequence of events, a stream is most appropriate.", "originalCommit": "b2fb30b0ecb9639fd67a69e6414fad1571a41fe2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjMxMTkxOA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512311918", "bodyText": "100% agree, this has been changed to match the order of the fields in the ksqlDB statement.", "author": "awalther28", "createdAt": "2020-10-26T22:41:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI4Njc2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI4NzA3MA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512287070", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Set KSQL to process data from the beginning of each Kafka topic:\n          \n          \n            \n            Set ksqlDB to process data from the beginning of each Kafka topic:", "author": "ybyzek", "createdAt": "2020-10-26T21:42:50Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/set-properties.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+Set KSQL to process data from the beginning of each Kafka topic:", "originalCommit": "b2fb30b0ecb9639fd67a69e6414fad1571a41fe2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI4Nzk5Ng==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512287996", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Using the table of suspicious names and stream of transactions, create a new stream of events containing transactions that were sent to an account name contained in the 'suspicious_names' table. We can do this by performing an `INNER JOIN`. In this case the `INNER JOIN` will couple events in the transaction stream where the \"recipient\" is the same as \"company_name\" in the suspicious_names table. The stream created below will continuously be populated by the coupled events created by the query.\n          \n          \n            \n            Using the table of suspicious names and stream of transactions, create a new stream of events containing only those transactions that were sent to an account name contained in the 'suspicious_names' table. We can do this by performing an `INNER JOIN`. In this case the `INNER JOIN` will couple events in the transaction stream where the \"recipient\" is the same as \"company_name\" in the suspicious_names table. The stream created below will continuously be populated by the coupled events created by the query.", "author": "ybyzek", "createdAt": "2020-10-26T21:44:47Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/create-suspicious-transactions-stream.adoc", "diffHunk": "@@ -0,0 +1,14 @@\n+Using the table of suspicious names and stream of transactions, create a new stream of events containing transactions that were sent to an account name contained in the 'suspicious_names' table. We can do this by performing an `INNER JOIN`. In this case the `INNER JOIN` will couple events in the transaction stream where the \"recipient\" is the same as \"company_name\" in the suspicious_names table. The stream created below will continuously be populated by the coupled events created by the query.", "originalCommit": "b2fb30b0ecb9639fd67a69e6414fad1571a41fe2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI4ODQ5MA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512288490", "bodyText": "Awesome presentation @awalther28", "author": "ybyzek", "createdAt": "2020-10-26T21:45:46Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/create-accounts-to-monitor-table.adoc", "diffHunk": "@@ -0,0 +1,21 @@\n+For this use case, let's say that a single transaction to one of the companies in the suspicious_names table is probably okay, but multiple transactions to one or more of those companies in a 24-hour period is an anomaly. ksqlDB gives us the ability to see if any anomalies are present for a particular user with the following query.\n+\n+[source,sql]\n+----\n+CREATE TABLE accounts_to_monitor\n+    WITH (kafka_topic='accounts_to_monitor', partitions=1, value_format='JSON') AS\n+    SELECT TIMESTAMPTOSTRING(WINDOWSTART, 'yyyy-MM-dd HH:mm:ss Z') AS WINDOW_START, // <1>\n+           TIMESTAMPTOSTRING(WINDOWEND, 'yyyy-MM-dd HH:mm:ss Z') AS WINDOW_END,\n+           USERNAME\n+    FROM suspicious_transactions\n+    WINDOW TUMBLING (SIZE 24 HOURS) // <2>\n+    GROUP BY USERNAME\n+    HAVING COUNT(*) > 3; // <3>\n+----\n++++++\n+<div class=\"colist arabic\">\n+<p><i class=\"conum\" data-value=\"1\"></i><b>1</b> The timestamps here are important, they tell us what interval of time suspicious activity occurred.</p>", "originalCommit": "b2fb30b0ecb9639fd67a69e6414fad1571a41fe2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI4ODk4Nw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512288987", "bodyText": "they tell us what interval of time suspicious activity occurred -- the timestamps themselves don't tell the interval.  Would it be more accurate to phrase, something along the lines of, they are used to calculate the interval of time between transactions (or however you see fit)", "author": "ybyzek", "createdAt": "2020-10-26T21:47:00Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/create-accounts-to-monitor-table.adoc", "diffHunk": "@@ -0,0 +1,21 @@\n+For this use case, let's say that a single transaction to one of the companies in the suspicious_names table is probably okay, but multiple transactions to one or more of those companies in a 24-hour period is an anomaly. ksqlDB gives us the ability to see if any anomalies are present for a particular user with the following query.\n+\n+[source,sql]\n+----\n+CREATE TABLE accounts_to_monitor\n+    WITH (kafka_topic='accounts_to_monitor', partitions=1, value_format='JSON') AS\n+    SELECT TIMESTAMPTOSTRING(WINDOWSTART, 'yyyy-MM-dd HH:mm:ss Z') AS WINDOW_START, // <1>\n+           TIMESTAMPTOSTRING(WINDOWEND, 'yyyy-MM-dd HH:mm:ss Z') AS WINDOW_END,\n+           USERNAME\n+    FROM suspicious_transactions\n+    WINDOW TUMBLING (SIZE 24 HOURS) // <2>\n+    GROUP BY USERNAME\n+    HAVING COUNT(*) > 3; // <3>\n+----\n++++++\n+<div class=\"colist arabic\">\n+<p><i class=\"conum\" data-value=\"1\"></i><b>1</b> The timestamps here are important, they tell us what interval of time suspicious activity occurred.</p>", "originalCommit": "b2fb30b0ecb9639fd67a69e6414fad1571a41fe2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI5NzMyNQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512297325", "bodyText": "hm rereading this, I think I should have said \"The fields WINDOW_START and WINDOW_END\" rather than \"timestamps\". The number maps to the field creation of the windows. @ybyzek what are your thoughts on:\n\nThe fields WINDOW_START and WINDOW_END tell us what interval of time suspicious activity occurred.", "author": "awalther28", "createdAt": "2020-10-26T22:05:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI4ODk4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjMwMTc4MA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512301780", "bodyText": "Actually, I misread as well! (I mistakenly was thinking of the timestamps of the transaction itself). Yes, your proposed text disambiguates.", "author": "ybyzek", "createdAt": "2020-10-26T22:16:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI4ODk4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjMxMjAzMA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512312030", "bodyText": "Change applied.", "author": "awalther28", "createdAt": "2020-10-26T22:41:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI4ODk4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI4OTM3Ng==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512289376", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <p><i class=\"conum\" data-value=\"2\"></i><b>2</b> The <code>WINDOW TUMBLING</code> part of the query allows us to do an aggregation with distinct time boundaries. In this case our window is fixed at a length of 24 hours, does not allow gaps, and does not allow overlapping. Other types of windows are explained in the \"Collect data over time\" section of Kafka-Tutorials. If further explanation is need, checkout the <a href=\"https://docs.ksqldb.io/en/latest/concepts/time-and-windows-in-ksqldb-queries/#windows-in-sql-queries\"><strong>ksqlDB documentation about windows</strong></a>. It contains in depth descriptions and visualizations.</p>\n          \n          \n            \n            <p><i class=\"conum\" data-value=\"2\"></i><b>2</b> The <code>WINDOW TUMBLING</code> part of the query allows us to do an aggregation with distinct time boundaries. In this case our window is fixed at a length of 24 hours, does not allow gaps, and does not allow overlapping. Other types of windows are explained in the \"Collect data over time\" section of Kafka-Tutorials. For more in-depth descriptions and visualizations, checkout the <a href=\"https://docs.ksqldb.io/en/latest/concepts/time-and-windows-in-ksqldb-queries/#windows-in-sql-queries\"><strong>ksqlDB documentation about windows</strong></a>. </p>", "author": "ybyzek", "createdAt": "2020-10-26T21:47:52Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/create-accounts-to-monitor-table.adoc", "diffHunk": "@@ -0,0 +1,21 @@\n+For this use case, let's say that a single transaction to one of the companies in the suspicious_names table is probably okay, but multiple transactions to one or more of those companies in a 24-hour period is an anomaly. ksqlDB gives us the ability to see if any anomalies are present for a particular user with the following query.\n+\n+[source,sql]\n+----\n+CREATE TABLE accounts_to_monitor\n+    WITH (kafka_topic='accounts_to_monitor', partitions=1, value_format='JSON') AS\n+    SELECT TIMESTAMPTOSTRING(WINDOWSTART, 'yyyy-MM-dd HH:mm:ss Z') AS WINDOW_START, // <1>\n+           TIMESTAMPTOSTRING(WINDOWEND, 'yyyy-MM-dd HH:mm:ss Z') AS WINDOW_END,\n+           USERNAME\n+    FROM suspicious_transactions\n+    WINDOW TUMBLING (SIZE 24 HOURS) // <2>\n+    GROUP BY USERNAME\n+    HAVING COUNT(*) > 3; // <3>\n+----\n++++++\n+<div class=\"colist arabic\">\n+<p><i class=\"conum\" data-value=\"1\"></i><b>1</b> The timestamps here are important, they tell us what interval of time suspicious activity occurred.</p>\n+<p><i class=\"conum\" data-value=\"2\"></i><b>2</b> The <code>WINDOW TUMBLING</code> part of the query allows us to do an aggregation with distinct time boundaries. In this case our window is fixed at a length of 24 hours, does not allow gaps, and does not allow overlapping. Other types of windows are explained in the \"Collect data over time\" section of Kafka-Tutorials. If further explanation is need, checkout the <a href=\"https://docs.ksqldb.io/en/latest/concepts/time-and-windows-in-ksqldb-queries/#windows-in-sql-queries\"><strong>ksqlDB documentation about windows</strong></a>. It contains in depth descriptions and visualizations.</p>", "originalCommit": "b2fb30b0ecb9639fd67a69e6414fad1571a41fe2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI4OTg4OQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512289889", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The ksqlDB table and thus Kafka topic contain a list of accounts against which more than three suspicious transactions have taken place in a 24-hour window.\n          \n          \n            \n            The ksqlDB table, and the underlying Kafka topic backing this table, contain a list of accounts against which more than three suspicious transactions have taken place in a 24-hour window.", "author": "ybyzek", "createdAt": "2020-10-26T21:49:07Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/print-accounts-to-monitor.adoc", "diffHunk": "@@ -0,0 +1,17 @@\n+The ksqlDB table and thus Kafka topic contain a list of accounts against which more than three suspicious transactions have taken place in a 24-hour window.", "originalCommit": "b2fb30b0ecb9639fd67a69e6414fad1571a41fe2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI5MDE1Nw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512290157", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Type 'exit' and hit enter to shutdown the ksqlDB cli.\n          \n          \n            \n            \n          \n          \n            \n            Type 'exit' and hit enter to shutdown the ksqlDB cli.", "author": "ybyzek", "createdAt": "2020-10-26T21:49:39Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/print-accounts-to-monitor.adoc", "diffHunk": "@@ -0,0 +1,17 @@\n+The ksqlDB table and thus Kafka topic contain a list of accounts against which more than three suspicious transactions have taken place in a 24-hour window.\n+\n++++++\n+<pre class=\"snippet\"><code class=\"sql\">{% include_raw tutorials/anomaly-detection/ksql/code/tutorial-steps/dev/print-accounts-to-monitor.sql %}</code></pre>\n++++++\n+\n+The output should look like the following:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"sql\">{% include_raw tutorials/anomaly-detection/ksql/code/tutorial-steps/dev/print-accounts-to-monitor.log %}</code></pre>\n++++++\n+\n+Note that if you were to alter the `LIMIT` of results to something greater than 1, you would not see any other accounts flagged even though Victor von Frankenstein had a transaction that was flagged as suspicious. If you decided to rerun the query with a new limit, use `CTRL+D` to terminate the query. +\n+\n+\n+Events within the Kafka topic accounts_to_monitor can be used to drive monitoring and alerting applications that could take action such as placing a hold on the account, notifying the card holder, etc. +\n+Type 'exit' and hit enter to shutdown the ksqlDB cli.", "originalCommit": "b2fb30b0ecb9639fd67a69e6414fad1571a41fe2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjI5MDY4Mw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512290683", "bodyText": "Would it make sense to modify as:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now that you have a series of statements that's doing the right thing, the last step is to put them into a file so that they can be used outside the CLI session. Create a file at `src/statements.sql` with the following content:\n          \n          \n            \n            Now that you have a series of statements that's doing the right thing, the last step is to put them into a file so that they can be used outside the CLI session. Create a file at `src/statements.sql` with the following content that represents the suspicious names (In production, you would likely use Kafka Connect to read the suspicious names from a database into a Kafka topic, and then create a ksqlDB stream for it).", "author": "ybyzek", "createdAt": "2020-10-26T21:50:43Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/make-src-file.adoc", "diffHunk": "@@ -0,0 +1,5 @@\n+Now that you have a series of statements that's doing the right thing, the last step is to put them into a file so that they can be used outside the CLI session. Create a file at `src/statements.sql` with the following content:", "originalCommit": "b2fb30b0ecb9639fd67a69e6414fad1571a41fe2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "299cc28fbe067bf88901779e4db77d23eccc9c5e", "url": "https://github.com/confluentinc/kafka-tutorials/commit/299cc28fbe067bf88901779e4db77d23eccc9c5e", "message": "Apply suggestions from code review\n\nCo-authored-by: Yeva Byzek <ybyzek@users.noreply.github.com>", "committedDate": "2020-10-26T21:55:09Z", "type": "commit"}, {"oid": "74d5eec36e6d3ff61bc89bb879c99930d6557c5a", "url": "https://github.com/confluentinc/kafka-tutorials/commit/74d5eec36e6d3ff61bc89bb879c99930d6557c5a", "message": "DEVX-2184; alter window annot and list of fields", "committedDate": "2020-10-26T22:40:02Z", "type": "commit"}, {"oid": "2f244aead130964f725b6cc34cbefedee56543c4", "url": "https://github.com/confluentinc/kafka-tutorials/commit/2f244aead130964f725b6cc34cbefedee56543c4", "message": "DEVX-2184; create new statement file for Prod", "committedDate": "2020-10-26T23:37:12Z", "type": "commit"}, {"oid": "d0eeede4a127ca8b3daca1c494a91707d4eeb0dc", "url": "https://github.com/confluentinc/kafka-tutorials/commit/d0eeede4a127ca8b3daca1c494a91707d4eeb0dc", "message": "DEVX-2184; change test sttmt file name", "committedDate": "2020-10-27T13:47:52Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjgyNDgzOA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r512824838", "bodyText": "Super minor nit: It wasn't obvious to me at first to create this table. Maybe add a sentence at the end, telling the user explicitly to create the table.  But only if you want to. Again this is a minor subjective comment.\nEDIT: All the tests passed, so forget my previous comment!", "author": "bbejeck", "createdAt": "2020-10-27T16:06:16Z", "path": "_includes/tutorials/anomaly-detection/ksql/markup/dev/create-accounts-to-monitor-table.adoc", "diffHunk": "@@ -0,0 +1,21 @@\n+For this use case, let's say that a single transaction to one of the companies in the suspicious_names table is probably okay, but multiple transactions to one or more of those companies in a 24-hour period is an anomaly. ksqlDB gives us the ability to see if any anomalies are present for a particular user with the following query.\n+\n+[source,sql]\n+----\n+CREATE TABLE accounts_to_monitor\n+    WITH (kafka_topic='accounts_to_monitor', partitions=1, value_format='JSON') AS\n+    SELECT TIMESTAMPTOSTRING(WINDOWSTART, 'yyyy-MM-dd HH:mm:ss Z') AS WINDOW_START, // <1>\n+           TIMESTAMPTOSTRING(WINDOWEND, 'yyyy-MM-dd HH:mm:ss Z') AS WINDOW_END,\n+           USERNAME\n+    FROM suspicious_transactions\n+    WINDOW TUMBLING (SIZE 24 HOURS) // <2>\n+    GROUP BY USERNAME\n+    HAVING COUNT(*) > 3; // <3>\n+----\n++++++\n+<div class=\"colist arabic\">\n+<p><i class=\"conum\" data-value=\"1\"></i><b>1</b> The fields `WINDOW_START` and `WINDOW_END` tell us what interval of time suspicious activity occurred.</p>\n+<p><i class=\"conum\" data-value=\"2\"></i><b>2</b> The <code>WINDOW TUMBLING</code> part of the query allows us to do an aggregation with distinct time boundaries. In this case our window is fixed at a length of 24 hours, does not allow gaps, and does not allow overlapping. Other types of windows are explained in the \"Collect data over time\" section of Kafka-Tutorials. For more in-depth descriptions and visualizations, checkout the <a href=\"https://docs.ksqldb.io/en/latest/concepts/time-and-windows-in-ksqldb-queries/#windows-in-sql-queries\"><strong>ksqlDB documentation about windows</strong></a>. </p>\n+<p><i class=\"conum\" data-value=\"3\"></i><b>3</b> The last two lines of the query address how you would determine if a user had multiple suspicious transactions. This aspect of the query says, in essence, if any user has greater than 3 suspicious transactions during the window, emit an event to the accounts_to_monitor table. </p>\n+</div>", "originalCommit": "d0eeede4a127ca8b3daca1c494a91707d4eeb0dc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzc2NDUyMA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/604#discussion_r513764520", "bodyText": "That's a great point, I did add a clause there.", "author": "awalther28", "createdAt": "2020-10-28T21:13:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjgyNDgzOA=="}], "type": "inlineReview"}, {"oid": "fd6d979136e1cdfc3a203b148134e4a53516f251", "url": "https://github.com/confluentinc/kafka-tutorials/commit/fd6d979136e1cdfc3a203b148134e4a53516f251", "message": "DEVX-2184; direct table creation + other use cases", "committedDate": "2020-10-28T21:09:27Z", "type": "commit"}, {"oid": "993713b15fc1c9a97fdeb522c4982fb64c976211", "url": "https://github.com/confluentinc/kafka-tutorials/commit/993713b15fc1c9a97fdeb522c4982fb64c976211", "message": "Merge branch 'master' into DEVX-2184", "committedDate": "2020-10-28T21:11:04Z", "type": "commit"}, {"oid": "a40aa8dc31e31a4aad84118ff5d10253bc4b6ee1", "url": "https://github.com/confluentinc/kafka-tutorials/commit/a40aa8dc31e31a4aad84118ff5d10253bc4b6ee1", "message": "DEVX-2184; fix typo", "committedDate": "2020-10-28T21:17:16Z", "type": "commit"}, {"oid": "64c8532a92a566b8732630b84ea6c7567ff823f7", "url": "https://github.com/confluentinc/kafka-tutorials/commit/64c8532a92a566b8732630b84ea6c7567ff823f7", "message": "Merge branch 'DEVX-2184' of github.com:confluentinc/kafka-tutorials into DEVX-2184", "committedDate": "2020-10-28T21:26:14Z", "type": "commit"}]}