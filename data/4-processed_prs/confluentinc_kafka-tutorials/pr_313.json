{"pr_number": 313, "pr_title": "New tutorials: generated test streams of data with ksqlDB and Kafka Connect", "pr_createdAt": "2020-04-02T21:11:31Z", "pr_url": "https://github.com/confluentinc/kafka-tutorials/pull/313", "timeline": [{"oid": "ac3d8942756844e2d8ae25ed92aaa28573a0f902", "url": "https://github.com/confluentinc/kafka-tutorials/commit/ac3d8942756844e2d8ae25ed92aaa28573a0f902", "message": "new tutorial", "committedDate": "2020-03-31T14:12:16Z", "type": "commit"}, {"oid": "6e0da3fb7068f5d715cc495801b8b183d3f12ff9", "url": "https://github.com/confluentinc/kafka-tutorials/commit/6e0da3fb7068f5d715cc495801b8b183d3f12ff9", "message": "Merge branch 'master' into 290-voluble", "committedDate": "2020-03-31T14:13:28Z", "type": "commit"}, {"oid": "a5cea09c5fe59ad47fa26ffe9ce39a358902f75f", "url": "https://github.com/confluentinc/kafka-tutorials/commit/a5cea09c5fe59ad47fa26ffe9ce39a358902f75f", "message": "ksqlDB tutorial WIP", "committedDate": "2020-04-02T09:31:57Z", "type": "commit"}, {"oid": "1b207ac86183dee5f465c130a0011048920ec79f", "url": "https://github.com/confluentinc/kafka-tutorials/commit/1b207ac86183dee5f465c130a0011048920ec79f", "message": "New tutorial: ksqlDB : generate streams of test data", "committedDate": "2020-04-02T14:23:01Z", "type": "commit"}, {"oid": "49caa9837b0ccfdc862f8424bfd9cf44974fedcd", "url": "https://github.com/confluentinc/kafka-tutorials/commit/49caa9837b0ccfdc862f8424bfd9cf44974fedcd", "message": "Merge branch 'master' into 290-voluble", "committedDate": "2020-04-02T14:23:26Z", "type": "commit"}, {"oid": "656d1b095990d79853dc9393bbd5704b70208c8c", "url": "https://github.com/confluentinc/kafka-tutorials/commit/656d1b095990d79853dc9393bbd5704b70208c8c", "message": "ksqlDB tutorial tweaks", "committedDate": "2020-04-02T20:25:05Z", "type": "commit"}, {"oid": "149bd6f5183c0198fb62335922441c288a38b64f", "url": "https://github.com/confluentinc/kafka-tutorials/commit/149bd6f5183c0198fb62335922441c288a38b64f", "message": "New tutorial: Kafka Connect generate test streams", "committedDate": "2020-04-02T20:25:34Z", "type": "commit"}, {"oid": "47c380a1e31e6246e75b4a7022fd0b3da47c0c13", "url": "https://github.com/confluentinc/kafka-tutorials/commit/47c380a1e31e6246e75b4a7022fd0b3da47c0c13", "message": "Tweaks", "committedDate": "2020-04-02T21:08:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4ODI5Mw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r403188293", "bodyText": "This file has duplicate content to consume-topic-02a.adoc.", "author": "bbejeck", "createdAt": "2020-04-03T17:46:38Z", "path": "_includes/tutorials/generate-test-data-streams/kafka/markup/dev/consume-topic-02b.adoc", "diffHunk": "@@ -0,0 +1,10 @@\n+We now have two Kafka topics being written to. The first (`devices`) is keyed on the MAC address, as can be seen from the data: ", "originalCommit": "47c380a1e31e6246e75b4a7022fd0b3da47c0c13", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzk1NzkxMA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r403957910", "bodyText": "Good catch, thanks @bbejeck. Fixed.", "author": "rmoff", "createdAt": "2020-04-06T09:39:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzE4ODI5Mw=="}], "type": "inlineReview"}, {"oid": "2f73ce3f7762ae3598ff4837863264643c031124", "url": "https://github.com/confluentinc/kafka-tutorials/commit/2f73ce3f7762ae3598ff4837863264643c031124", "message": "Fix duplicate content", "committedDate": "2020-04-06T09:39:05Z", "type": "commit"}, {"oid": "dab8d58a03dcbc5f363e62795baac539f57fcc2b", "url": "https://github.com/confluentinc/kafka-tutorials/commit/dab8d58a03dcbc5f363e62795baac539f57fcc2b", "message": "Merge branch 'master' into 290-voluble", "committedDate": "2020-09-21T14:34:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjIzOA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r493752238", "bodyText": "Can you add the CCloud section like the other tutorials?", "author": "ybyzek", "createdAt": "2020-09-23T17:06:00Z", "path": "_data/harnesses/generate-test-data-streams/ksql.yml", "diffHunk": "@@ -0,0 +1,198 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/init.adoc\n+        - action: execute\n+          file: tutorial-steps/dev/make-dirs.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-dirs.adoc\n+          stdout: tutorial-steps/dev/outputs/make-dirs.out\n+            \n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/wait-for-containers.adoc\n+          stdout: tutorial-steps/dev/outputs/wait-for-containers.out\n+\n+        - action: execute\n+          file: tutorial-steps/dev/check-plugin.sh\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/check-plugin.adoc\n+          stdout: tutorial-steps/dev/outputs/check-plugin.out\n+            \n+    - title: Create a standalone stream of test data\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-connector-01.adoc\n+\n+        - action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/check-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/check-connector-01.adoc\n+            - file: tutorial-steps/dev/describe-connector-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/describe-connector-01.adoc\n+            \n+    - title: Consume events from the test topic\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/consume-topic.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/consume-topic.adoc\n+\n+    - title: Declare the topic as a ksqlDB stream\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 255\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-stream-01.adoc\n+            - file: tutorial-steps/dev/describe-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/describe-stream-01.adoc\n+            - file: tutorial-steps/dev/query-stream-01.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/query-stream-01.adoc\n+\n+    - title: Create two related streams of test data\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 20\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/create-connector-02.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/create-connector-02.adoc\n+\n+        - action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+            \n+    - title: Join the test data streams in ksqlDB\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+          column_width: 255\n+          render:\n+            skip: true\n+          stdin:\n+            - file: tutorial-steps/dev/check-connector-02.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/check-connector-02.adoc\n+            - file: tutorial-steps/dev/join-streams-declare.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/join-streams-declare.adoc\n+            - file: tutorial-steps/dev/join-streams-do.sql\n+              render:\n+                file: tutorials/generate-test-data-streams/ksql/markup/dev/join-streams-do.adoc\n+\n+    - title: Clean up\n+      content:\n+      - action: execute\n+        file: tutorial-steps/dev/clean-up.sh\n+        render:\n+          file: tutorials/generate-test-data-streams/ksql/markup/dev/clean-up.adoc\n+\n+\n+prod:\n+  steps:\n+    - title: Write your statements to a file\n+      content:\n+        - action: make_file\n+          file: src/statements.sql\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/dev/make-src-file.adoc\n+\n+    - title: Send the statements to the REST endpoint\n+      content:\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/prod/send-to-api.sh\n+          stdout: tutorial-steps/prod/outputs/send-to-api.out\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/prod/submit-to-api.adoc\n+\n+    - title: Validate the deployment\n+      content:\n+        - action: execute\n+          file: tutorial-steps/prod/check-deploy.sh\n+          stdout: tutorial-steps/prod/outputs/check-deploy.out\n+          render:\n+            file: tutorials/generate-test-data-streams/ksql/markup/prod/check-deploy.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/clean-up.sh\n+          render:\n+            skip: true", "originalCommit": "dab8d58a03dcbc5f363e62795baac539f57fcc2b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDE0OTQwNg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r494149406", "bodyText": "Voluble isn't available on CCloud", "author": "rmoff", "createdAt": "2020-09-24T08:53:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjIzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDI0MTM4OQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r494241389", "bodyText": "It doesn't mean we can't run connector locally connected to cloud.", "author": "gAmUssA", "createdAt": "2020-09-24T11:34:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjIzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDI3MDM0Mw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r494270343", "bodyText": "@rmoff Voluble is a connector, so it can be run in a self-managed connect cluster to CCloud.", "author": "ybyzek", "createdAt": "2020-09-24T12:23:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjIzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDI4NDM3Mg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r494284372", "bodyText": "\u00af_(\u30c4)_/\u00af I don't think it makes sense to crowbar in Cloud to every single Connector tutorial. It's a tutorial on how to use a connector, not run it end-to-end. Consider, we also don't include how to run it outside of Docker, because that's left to the user to figure out.", "author": "rmoff", "createdAt": "2020-09-24T12:41:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjIzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjU4Ng==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r493752586", "bodyText": "problem no longer exists", "author": "ybyzek", "createdAt": "2020-09-23T17:06:38Z", "path": "_data/tutorials.yaml", "diffHunk": "@@ -226,6 +226,17 @@ flatten-nested-data:\n     kstreams: disabled\n     kafka: disabled\n \n+generate-test-data-streams:\n+  title: \"Generate streams of test data\"\n+  meta-description: \"Generate streams of test data\"\n+  slug: \"/generate-streams-of-test-data\"\n+  problem: \"you are working in the Kafka ecosystem and as part of learning and developing applications and pipelines need a stream of test data\"", "originalCommit": "dab8d58a03dcbc5f363e62795baac539f57fcc2b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDE1MjI4OQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/313#discussion_r494152289", "bodyText": "fixed", "author": "rmoff", "createdAt": "2020-09-24T08:58:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzc1MjU4Ng=="}], "type": "inlineReview"}, {"oid": "bbeacdce9cdb5bc39340e30d2ef6fc8e775f5262", "url": "https://github.com/confluentinc/kafka-tutorials/commit/bbeacdce9cdb5bc39340e30d2ef6fc8e775f5262", "message": "Remove `problem:`", "committedDate": "2020-09-24T08:57:58Z", "type": "commit"}, {"oid": "5aa3e979edb6793de35aadfec97d01e4ac874d85", "url": "https://github.com/confluentinc/kafka-tutorials/commit/5aa3e979edb6793de35aadfec97d01e4ac874d85", "message": "Merge in master, rename tutorial", "committedDate": "2020-09-24T11:12:26Z", "type": "commit"}, {"oid": "54dd43fbf0110298207ee6b7e83876add59f02f5", "url": "https://github.com/confluentinc/kafka-tutorials/commit/54dd43fbf0110298207ee6b7e83876add59f02f5", "message": "Merge branch '290-voluble' of github.com:confluentinc/kafka-tutorials into 290-voluble", "committedDate": "2020-09-24T11:13:16Z", "type": "commit"}]}