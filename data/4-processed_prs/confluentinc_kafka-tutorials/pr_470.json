{"pr_number": 470, "pr_title": "GH-446: Changing the number of partitions and replicas of a Kafka topic #446", "pr_createdAt": "2020-07-20T16:28:08Z", "pr_url": "https://github.com/confluentinc/kafka-tutorials/pull/470", "timeline": [{"oid": "fc062429c0ec01ef2be1856aa0c1e1745ddaf975", "url": "https://github.com/confluentinc/kafka-tutorials/commit/fc062429c0ec01ef2be1856aa0c1e1745ddaf975", "message": "GH-446: #446 framework", "committedDate": "2020-07-17T18:04:11Z", "type": "commit"}, {"oid": "9a5e4cb88f155c15a283d8be0854c86a53c2add1", "url": "https://github.com/confluentinc/kafka-tutorials/commit/9a5e4cb88f155c15a283d8be0854c86a53c2add1", "message": "Checkpoint 2", "committedDate": "2020-07-17T18:24:38Z", "type": "commit"}, {"oid": "f99dda78f24f7c4c5ff22d7b4b513e4852a5cb54", "url": "https://github.com/confluentinc/kafka-tutorials/commit/f99dda78f24f7c4c5ff22d7b4b513e4852a5cb54", "message": "Next checkpoint", "committedDate": "2020-07-17T19:50:35Z", "type": "commit"}, {"oid": "5d6fccceb1e27087e92e0473ef00d56c81206ca2", "url": "https://github.com/confluentinc/kafka-tutorials/commit/5d6fccceb1e27087e92e0473ef00d56c81206ca2", "message": "Fix some things", "committedDate": "2020-07-17T22:18:44Z", "type": "commit"}, {"oid": "c08fc2c8b5622f4a4f2c9adfc6b94e8139fa8539", "url": "https://github.com/confluentinc/kafka-tutorials/commit/c08fc2c8b5622f4a4f2c9adfc6b94e8139fa8539", "message": "Create proper streams", "committedDate": "2020-07-17T23:13:28Z", "type": "commit"}, {"oid": "2b95196b7e540027661e9a109881639073cea16e", "url": "https://github.com/confluentinc/kafka-tutorials/commit/2b95196b7e540027661e9a109881639073cea16e", "message": "Add per partition consumers", "committedDate": "2020-07-17T23:40:37Z", "type": "commit"}, {"oid": "8d30d752279f8a259e5e684a4ba43dee6cfaefa6", "url": "https://github.com/confluentinc/kafka-tutorials/commit/8d30d752279f8a259e5e684a4ba43dee6cfaefa6", "message": "Split test", "committedDate": "2020-07-17T23:57:34Z", "type": "commit"}, {"oid": "5b28c8fbac92fd7e26875450dc0538faa029ada0", "url": "https://github.com/confluentinc/kafka-tutorials/commit/5b28c8fbac92fd7e26875450dc0538faa029ada0", "message": "Get produce to work for make", "committedDate": "2020-07-18T00:16:05Z", "type": "commit"}, {"oid": "7a97a10f61e47b82e4129f2bced3daf7e324d5e4", "url": "https://github.com/confluentinc/kafka-tutorials/commit/7a97a10f61e47b82e4129f2bced3daf7e324d5e4", "message": "Add files for harness-console-consumer", "committedDate": "2020-07-18T00:26:09Z", "type": "commit"}, {"oid": "5ceffbac47755768ef503fb8ce26b6f0326eeb21", "url": "https://github.com/confluentinc/kafka-tutorials/commit/5ceffbac47755768ef503fb8ce26b6f0326eeb21", "message": "Fixup some tests", "committedDate": "2020-07-18T01:16:40Z", "type": "commit"}, {"oid": "c8c5fa8c7034c97db7560e6f91cdab6bd55967da", "url": "https://github.com/confluentinc/kafka-tutorials/commit/c8c5fa8c7034c97db7560e6f91cdab6bd55967da", "message": "make passes", "committedDate": "2020-07-18T01:25:32Z", "type": "commit"}, {"oid": "e0aedfac5b79d9a090506ef919eeee4e0ac6dde6", "url": "https://github.com/confluentinc/kafka-tutorials/commit/e0aedfac5b79d9a090506ef919eeee4e0ac6dde6", "message": "Modify introduction", "committedDate": "2020-07-18T01:32:07Z", "type": "commit"}, {"oid": "c99f37398606c87a1a32179f46083b7a7ae945f1", "url": "https://github.com/confluentinc/kafka-tutorials/commit/c99f37398606c87a1a32179f46083b7a7ae945f1", "message": "tweaks", "committedDate": "2020-07-18T01:51:45Z", "type": "commit"}, {"oid": "aadb05ea23964cee227495d903dbd5da2599862d", "url": "https://github.com/confluentinc/kafka-tutorials/commit/aadb05ea23964cee227495d903dbd5da2599862d", "message": "Add changing replicas; reformat some commands", "committedDate": "2020-07-18T02:27:12Z", "type": "commit"}, {"oid": "beef11dc519e9e9b8c7334b9e5e029e579ef9125", "url": "https://github.com/confluentinc/kafka-tutorials/commit/beef11dc519e9e9b8c7334b9e5e029e579ef9125", "message": "Tweak", "committedDate": "2020-07-18T02:39:24Z", "type": "commit"}, {"oid": "f844d695a0bb90ad09c93bdde749892ed98200bc", "url": "https://github.com/confluentinc/kafka-tutorials/commit/f844d695a0bb90ad09c93bdde749892ed98200bc", "message": "Rename KT folder; tweaks to tutorial", "committedDate": "2020-07-20T16:27:06Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIxMTgzMQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/470#discussion_r458211831", "bodyText": "skip needs to be replaced with file:<path to adoc file> to show the clean-up command to users.", "author": "bbejeck", "createdAt": "2020-07-21T16:01:47Z", "path": "_data/harnesses/change-topic-partitions-replicas/ksql.yml", "diffHunk": "@@ -0,0 +1,139 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/init.adoc\n+\n+        - change_directory: change-topic-partitions-replicas\n+          action: execute\n+          file: tutorial-steps/dev/make-dirs.sh\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/make-dirs.adoc\n+\n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+    - title: Create the original topic\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/create-topic.sh\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/create-topic.adoc\n+\n+    - title: Describe the original topic\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/describe-original-topic.sh\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/describe-original-topic.adoc\n+\n+    - title: Write the program interactively using the CLI\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          column_width: 24\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/start-cli.adoc\n+          stdin:\n+            - file: tutorial-steps/dev/create-original-stream.sql\n+              render:\n+                file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/create-inputs.adoc\n+\n+            - file: tutorial-steps/dev/create-new-stream.sql\n+              render:\n+                file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/create-new-stream.adoc\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+\n+    - title: Describe the new topic\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/describe-new-topic.sh\n+          stdout: tutorial-steps/dev/outputs/actual-describe-from-topic2.txt\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/describe-new-topic.adoc\n+\n+    - title: Write your statements to a file\n+      content:\n+        - action: make_file\n+          file: src/statements.sql\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/make-src-file.adoc\n+\n+test:\n+  steps:\n+    - title: Create the test data\n+      content:\n+        - action: make_file\n+          file: test/input.txt\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/test/make-test-input.adoc\n+\n+    - title: Produce the test data to the original topic\n+      content:\n+        - action: execute\n+          file: tutorial-steps/test/harness-console-producer.sh\n+          stdin: test/input.txt\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/test/produce-data-input.adoc\n+\n+        - name: wait for producer to write records\n+          action: sleep\n+          ms: 2000\n+          render:\n+            skip: true\n+\n+    - title: View the data in the original topic (partition 0)\n+      content:\n+        - action: execute\n+          file: tutorial-steps/test/harness-console-consumer-topic1-partition-0.sh\n+          stdout: tutorial-steps/test/outputs/actual-output-topic1-partition-0.txt\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/test/consume-data-topic1-partition-0.adoc\n+\n+    - title: View the data in the new topic (partition 0)\n+      content:\n+        - action: execute\n+          file: tutorial-steps/test/harness-console-consumer-topic2-partition-0.sh\n+          stdout: tutorial-steps/test/outputs/actual-output-topic2-partition-0.txt\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/test/consume-data-topic2-partition-0.adoc\n+\n+    - title: View the data in the new topic (partition 1)\n+      content:\n+        - action: execute\n+          file: tutorial-steps/test/harness-console-consumer-topic2-partition-1.sh\n+          stdout: tutorial-steps/test/outputs/actual-output-topic2-partition-1.txt\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/test/consume-data-topic2-partition-1.adoc\n+\n+prod:\n+  steps:\n+    - title: Send the statements to the REST API\n+      content:\n+        - action: skip\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/prod/submit-to-api.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/clean-up.sh\n+          render:\n+            skip: true", "originalCommit": "f844d695a0bb90ad09c93bdde749892ed98200bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkzMzI2MQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/470#discussion_r458933261", "bodyText": "Ack, replacing now", "author": "ybyzek", "createdAt": "2020-07-22T16:41:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIxMTgzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIyMDk4Mg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/470#discussion_r458220982", "bodyText": "Maybe we should add a step here instructing the user to shut down the ksqlDB cli since it's not needed beyond this step.", "author": "bbejeck", "createdAt": "2020-07-21T16:14:52Z", "path": "_includes/tutorials/change-topic-partitions-replicas/ksql/markup/dev/create-new-stream.adoc", "diffHunk": "@@ -0,0 +1,7 @@\n+Next, create a new ksqlDB stream\u2014let's call it `s2`\u2014that will be backed by a new target Kafka topic `topic2` with the desired number of partitions and replicas. Using the `WITH` clause, you can specify the partitions and replicas of the underlying Kafka topic.\n+\n+The result of `SELECT * FROM S1` causes every record from Kafka topic `topic1` (with 1 partition and 1 replica) to be produced to Kafka topic `topic2` (with 2 partitions and 2 replicas).\n+", "originalCommit": "f844d695a0bb90ad09c93bdde749892ed98200bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyNjAzOA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/470#discussion_r458926038", "bodyText": "@bbejeck good suggestion, adding now.", "author": "ybyzek", "createdAt": "2020-07-22T16:31:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIyMDk4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0MjExMw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/470#discussion_r458242113", "bodyText": "FYC: Swap the order of creating the test data and starting the producer.  It will be simpler for users to simply copy/paste from the tutorial.", "author": "bbejeck", "createdAt": "2020-07-21T16:47:12Z", "path": "_data/harnesses/change-topic-partitions-replicas/ksql.yml", "diffHunk": "@@ -0,0 +1,139 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/init.adoc\n+\n+        - change_directory: change-topic-partitions-replicas\n+          action: execute\n+          file: tutorial-steps/dev/make-dirs.sh\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/make-dirs.adoc\n+\n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+    - title: Create the original topic\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/create-topic.sh\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/create-topic.adoc\n+\n+    - title: Describe the original topic\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/describe-original-topic.sh\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/describe-original-topic.adoc\n+\n+    - title: Write the program interactively using the CLI\n+      content:\n+        - action: docker_ksql_cli_session\n+          container: ksqldb-cli\n+          docker_bootup_file: tutorial-steps/dev/start-cli.sh\n+          column_width: 24\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/start-cli.adoc\n+          stdin:\n+            - file: tutorial-steps/dev/create-original-stream.sql\n+              render:\n+                file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/create-inputs.adoc\n+\n+            - file: tutorial-steps/dev/create-new-stream.sql\n+              render:\n+                file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/create-new-stream.adoc\n+          stdout:\n+            directory: tutorial-steps/dev/outputs\n+\n+    - title: Describe the new topic\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/describe-new-topic.sh\n+          stdout: tutorial-steps/dev/outputs/actual-describe-from-topic2.txt\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/describe-new-topic.adoc\n+\n+    - title: Write your statements to a file\n+      content:\n+        - action: make_file\n+          file: src/statements.sql\n+          render:\n+            file: tutorials/change-topic-partitions-replicas/ksql/markup/dev/make-src-file.adoc\n+\n+test:\n+  steps:\n+    - title: Create the test data", "originalCommit": "f844d695a0bb90ad09c93bdde749892ed98200bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkzMDQzMg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/470#discussion_r458930432", "bodyText": "Ack, swapping now.", "author": "ybyzek", "createdAt": "2020-07-22T16:37:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0MjExMw=="}], "type": "inlineReview"}, {"oid": "8f59218b3a6bd366fa3c71ccceb5747f4b852240", "url": "https://github.com/confluentinc/kafka-tutorials/commit/8f59218b3a6bd366fa3c71ccceb5747f4b852240", "message": "Address feedback from Bill", "committedDate": "2020-07-22T16:41:47Z", "type": "commit"}, {"oid": "e92007bfe68b01fa40a7307a3442831b0b684144", "url": "https://github.com/confluentinc/kafka-tutorials/commit/e92007bfe68b01fa40a7307a3442831b0b684144", "message": "Merge branch 'master' into GH-446", "committedDate": "2020-07-22T16:44:25Z", "type": "commit"}, {"oid": "97ff23780632cf8d031412a449c88663d256db6d", "url": "https://github.com/confluentinc/kafka-tutorials/commit/97ff23780632cf8d031412a449c88663d256db6d", "message": "Tweak line", "committedDate": "2020-07-22T16:47:14Z", "type": "commit"}, {"oid": "71fd519bb95c1a4655cf8b391ae4ba4a04f33419", "url": "https://github.com/confluentinc/kafka-tutorials/commit/71fd519bb95c1a4655cf8b391ae4ba4a04f33419", "message": "Add missing file", "committedDate": "2020-07-22T16:53:16Z", "type": "commit"}, {"oid": "47c4900fdc8c344c8bfd1249e12cdf1af73c5ad1", "url": "https://github.com/confluentinc/kafka-tutorials/commit/47c4900fdc8c344c8bfd1249e12cdf1af73c5ad1", "message": "Tweak language", "committedDate": "2020-07-22T16:54:18Z", "type": "commit"}]}