{"pr_number": 465, "pr_title": "Add new KT for kafka-connect-datagen (local)", "pr_createdAt": "2020-07-06T18:35:13Z", "pr_url": "https://github.com/confluentinc/kafka-tutorials/pull/465", "timeline": [{"oid": "16946429ea52c4e1880bcf1dfefe42a3afae96fc", "url": "https://github.com/confluentinc/kafka-tutorials/commit/16946429ea52c4e1880bcf1dfefe42a3afae96fc", "message": "GH-464: groundwork for #464 kafka-connect-datagen for local Kafka topics", "committedDate": "2020-07-06T16:24:13Z", "type": "commit"}, {"oid": "a3aa94404cbddfd97641a2522fee0601790821a9", "url": "https://github.com/confluentinc/kafka-tutorials/commit/a3aa94404cbddfd97641a2522fee0601790821a9", "message": "Clean up consumer", "committedDate": "2020-07-06T17:26:09Z", "type": "commit"}, {"oid": "dcb4558dc6bb525e876e4f866db93385cd247048", "url": "https://github.com/confluentinc/kafka-tutorials/commit/dcb4558dc6bb525e876e4f866db93385cd247048", "message": "Pass local build", "committedDate": "2020-07-06T18:19:36Z", "type": "commit"}, {"oid": "c8823713ac0fd002c100b12cb76f28c41ac2ecd2", "url": "https://github.com/confluentinc/kafka-tutorials/commit/c8823713ac0fd002c100b12cb76f28c41ac2ecd2", "message": "Rename self-managed to local", "committedDate": "2020-07-06T18:24:49Z", "type": "commit"}, {"oid": "09d222ec1324837a821bafa82de40fd1537159cc", "url": "https://github.com/confluentinc/kafka-tutorials/commit/09d222ec1324837a821bafa82de40fd1537159cc", "message": "Add cleanup to prod", "committedDate": "2020-07-06T18:33:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg4ODEzNw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r450888137", "bodyText": "Would a link to the datagen repository work here?", "author": "rspurgeon", "createdAt": "2020-07-07T14:02:11Z", "path": "_data/tutorials.yaml", "diffHunk": "@@ -302,3 +302,14 @@ console-consumer-read-specific-offsets-partition:\n     ksql: disabled\n     kstreams: disabled\n     kafka: enabled\n+\n+kafka-connect-datagen-local:\n+  title: \"How to generate mock data to a local Kafka topic using the Kafka Connect Datagen\"\n+  meta-description: \"How to generate mock data to a local Kafka topic using the Kafka Connect Datagen\"\n+  slug: \"/kafka-connect-datagen-local\"\n+  problem: \"you want to test your Kafka applications but need mock data produced to Kafka topics.\"\n+  introduction: \"You will run a local instance of the kafka-connect-datagen connector to produce mock data to a local Kafka cluster\"", "originalCommit": "09d222ec1324837a821bafa82de40fd1537159cc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDkwOTgxOA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r450909818", "bodyText": "Yes, added", "author": "ybyzek", "createdAt": "2020-07-07T14:30:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg4ODEzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg5NTc0Mg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r450895742", "bodyText": "FYC Use an explicit version to prevent any unexpected compatibility issues down the line for users", "author": "rspurgeon", "createdAt": "2020-07-07T14:12:36Z", "path": "_includes/tutorials/kafka-connect-datagen-local/kafka/code/Dockerfile", "diffHunk": "@@ -0,0 +1,5 @@\n+FROM confluentinc/cp-kafka-connect-base:5.5.1\n+\n+ENV CONNECT_PLUGIN_PATH=\"/usr/share/java,/usr/share/confluent-hub-components\"\n+\n+RUN confluent-hub install --no-prompt confluentinc/kafka-connect-datagen:latest", "originalCommit": "09d222ec1324837a821bafa82de40fd1537159cc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDkwMTQ1MQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r450901451", "bodyText": "I'll pin this to 0.3.2", "author": "ybyzek", "createdAt": "2020-07-07T14:20:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg5NTc0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg5Njc2Mw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r450896763", "bodyText": "We're using cp-kafka-connect-base:5.5.1 for the connector but 5.5.0 for the services.  Is that intentional?", "author": "rspurgeon", "createdAt": "2020-07-07T14:14:04Z", "path": "_includes/tutorials/kafka-connect-datagen-local/kafka/code/docker-compose.yml", "diffHunk": "@@ -0,0 +1,71 @@\n+---\n+version: '2'\n+\n+services:\n+  zookeeper:\n+    image: confluentinc/cp-zookeeper:5.5.0", "originalCommit": "09d222ec1324837a821bafa82de40fd1537159cc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDkwMDc0Ng==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r450900746", "bodyText": "I'll change this to 5.5.0 for consistency.", "author": "ybyzek", "createdAt": "2020-07-07T14:19:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg5Njc2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDkwMDY1NQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r450900655", "bodyText": "Is it possible to leave the prod steps out entirely as they aren't relevant for this tutorial?   The Cleanup Docker step seems like a \"Dev\" step IMO", "author": "rspurgeon", "createdAt": "2020-07-07T14:19:04Z", "path": "_data/harnesses/kafka-connect-datagen-local/kafka.yml", "diffHunk": "@@ -0,0 +1,79 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/init.adoc\n+\n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: Dockerfile\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/make-dockerfile.adoc\n+\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+            \n+    - title: Create the connector\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/create-connector.sh\n+          stdout: tutorial-steps/dev/outputs/create-connector.log\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/create-connector.adoc\n+\n+        - name: give Kafka Connect chance to create the connector\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/dev/check-connector.sh\n+          stdout: tutorial-steps/dev/outputs/check-connector.log\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/check-connector.adoc\n+\n+        - name: give Kafka Connect further chance to get the data to the topic\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+    - title: Consume events from the Kafka topic\n+      content:\n+      - action: execute_async\n+        file: tutorial-steps/dev/harness-console-consumer-keys.sh\n+        stdout: tutorial-steps/dev/outputs/consume-topic.log\n+        render:\n+          file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/consume-topic-key-value.adoc\n+\n+      - name: wait for consumer to read records\n+        action: sleep\n+        ms: 10000\n+        render:\n+          skip: true\n+\n+prod:", "originalCommit": "09d222ec1324837a821bafa82de40fd1537159cc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDkxMTcxOQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r450911719", "bodyText": "It's setup this way to allow users to do this: https://github.com/confluentinc/kafka-tutorials#run-a-tutorial\nmake SEQUENCE=\"dev, test\"", "author": "ybyzek", "createdAt": "2020-07-07T14:33:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDkwMDY1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcwOTc4Nw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r457709787", "bodyText": "FYC add a quick note to clean-up.adoc that the prod step is only for clean-up.  Or maybe we can find a way to have some sort of flag to set that is skipped when running make SEQUENCE=\"dev, test\"", "author": "bbejeck", "createdAt": "2020-07-20T21:45:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDkwMDY1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyMDczNA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r457720734", "bodyText": "In lieu of changing the framework to support a flag to skip cleanup, I went the \"easy\" route of adding the note to clean-up.adoc", "author": "ybyzek", "createdAt": "2020-07-20T22:11:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDkwMDY1NQ=="}], "type": "inlineReview"}, {"oid": "0e5485221c5687ca64ae1b5a1f1ea827ef607e21", "url": "https://github.com/confluentinc/kafka-tutorials/commit/0e5485221c5687ca64ae1b5a1f1ea827ef607e21", "message": "Feedback from Rick", "committedDate": "2020-07-07T14:31:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcwNzA2NQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r457707065", "bodyText": "The clean-up step isn't displayed when running through the tutorial.  The skip: true part needs to be replaced with file: <path>\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        skip: true\n          \n          \n            \n                        tutorials/kafka-connect-datagen-local/kafka/markup/dev/clean-up.adoc", "author": "bbejeck", "createdAt": "2020-07-20T21:39:42Z", "path": "_data/harnesses/kafka-connect-datagen-local/kafka.yml", "diffHunk": "@@ -0,0 +1,79 @@\n+dev:\n+  steps:\n+    - title: Initialize the project\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/init.adoc\n+\n+    - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: Dockerfile\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/make-dockerfile.adoc\n+\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+            \n+    - title: Create the connector\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/create-connector.sh\n+          stdout: tutorial-steps/dev/outputs/create-connector.log\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/create-connector.adoc\n+\n+        - name: give Kafka Connect chance to create the connector\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+        - action: execute\n+          file: tutorial-steps/dev/check-connector.sh\n+          stdout: tutorial-steps/dev/outputs/check-connector.log\n+          render:\n+            file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/check-connector.adoc\n+\n+        - name: give Kafka Connect further chance to get the data to the topic\n+          action: sleep\n+          ms: 5000\n+          render:\n+            skip: true\n+\n+    - title: Consume events from the Kafka topic\n+      content:\n+      - action: execute_async\n+        file: tutorial-steps/dev/harness-console-consumer-keys.sh\n+        stdout: tutorial-steps/dev/outputs/consume-topic.log\n+        render:\n+          file: tutorials/kafka-connect-datagen-local/kafka/markup/dev/consume-topic-key-value.adoc\n+\n+      - name: wait for consumer to read records\n+        action: sleep\n+        ms: 10000\n+        render:\n+          skip: true\n+\n+prod:\n+  steps:\n+    - title: Cleanup Docker containers\n+      content:\n+        - action: execute\n+          file: tutorial-steps/dev/clean-up.sh\n+          render:\n+            skip: true", "originalCommit": "0e5485221c5687ca64ae1b5a1f1ea827ef607e21", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcxOTM3MA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/465#discussion_r457719370", "bodyText": "@bbejeck ack, thank you.  I've implemented this in the latest commit (it needed file: addition.)", "author": "ybyzek", "createdAt": "2020-07-20T22:08:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcwNzA2NQ=="}], "type": "inlineReview"}, {"oid": "93676502b18619d12a9867cb8e8717ad30834a40", "url": "https://github.com/confluentinc/kafka-tutorials/commit/93676502b18619d12a9867cb8e8717ad30834a40", "message": "Render cleanup step in prod", "committedDate": "2020-07-20T22:08:16Z", "type": "commit"}, {"oid": "c17258a0d044e9a60a7d577b561fb8ca253c62e8", "url": "https://github.com/confluentinc/kafka-tutorials/commit/c17258a0d044e9a60a7d577b561fb8ca253c62e8", "message": "Add note to clean-up.adoc", "committedDate": "2020-07-20T22:10:57Z", "type": "commit"}, {"oid": "04dd82d2a215813dc648d97ffc3fa815997413e3", "url": "https://github.com/confluentinc/kafka-tutorials/commit/04dd82d2a215813dc648d97ffc3fa815997413e3", "message": "Add Kafka Test Connect Datagen Local to semaphore.yml", "committedDate": "2020-07-21T00:23:08Z", "type": "commit"}]}