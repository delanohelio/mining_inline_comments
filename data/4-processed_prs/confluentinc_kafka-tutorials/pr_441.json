{"pr_number": 441, "pr_title": "MINOR: Add documentation about harness runner", "pr_createdAt": "2020-06-18T22:41:53Z", "pr_url": "https://github.com/confluentinc/kafka-tutorials/pull/441", "timeline": [{"oid": "7db63b22e671f8ed6787bc7696c78d746d1d891c", "url": "https://github.com/confluentinc/kafka-tutorials/commit/7db63b22e671f8ed6787bc7696c78d746d1d891c", "message": "intial commit for documenting harness runner", "committedDate": "2020-06-16T19:32:15Z", "type": "commit"}, {"oid": "329e16de87d5697391dee8827d1da1fcaf5aeeeb", "url": "https://github.com/confluentinc/kafka-tutorials/commit/329e16de87d5697391dee8827d1da1fcaf5aeeeb", "message": "add description of harness file to README", "committedDate": "2020-06-18T22:40:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk0MzMyOA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r442943328", "bodyText": "I noticed this section does not discuss action: docker_ksql_cli_session. This type probably deserves its own description below.", "author": "colinhicks", "createdAt": "2020-06-19T16:42:10Z", "path": "README.md", "diffHunk": "@@ -237,6 +237,180 @@ You can do the same for Kafka Streams and Kafka, by using the `kstreams` and `ka\n \n Lastly, create a Makefile in the `code` directory to invoke the harness runner and check any outputs that it produces. Then modify the `.semaphore/semaphore.yml` file to invoke that Makefile. This will make sure your tutorial gets checked by the CI system.\n \n+## Working with the harness file\n+\n+Given the test harness is the `heart` of a tutorial, it will be helpful to describe in detail how to work with a `kafka|ksql|kstreams.yml` file.  It should be noted the harness file is in the [YAML file formt](https://en.wikipedia.org/wiki/YAML), so formatting properly is essential.  The harness files generates the structure of the rendered tutorial and also validates any output of tutorial steps against expected values.\n+\n+This section is not meant to be an exhaustive decription of the harness file.  New tutorial authors should not need to create a harness file from scratch, using either the `tools/gen_project.sh` or  `tools/clone.sh` script will provide a usable harness file.  This section should provide enough guidance to add, update, or remove sections as needed.\n+\n+#### TLDR;\n+\n+To run a tutorial programatically do the following stepes. Note these instructions assume you've already checked out the kafka-tutorials repo).\n+\n+1. cd into `_includes/tutorials/<tutorial name>/<type>/code` directory where type is one of `ksql | kstreams | kafka`.\n+2. run the `make` command.\n+\n+The `Makefile` will delete and re-create the `outputs` directory used contain files with output from various steps used to verify the tutorial steps.\n+\n+Here's an example of the contents of a `Makefile`:\n+\n+```yml\n+STEPS_DIR := tutorial-steps\n+DEV_OUTPUTS_DIR := $(STEPS_DIR)/dev/outputs\n+TEMP_DIR := $(shell mktemp -d)\n+\n+tutorial:\n+  rm -r $(DEV_OUTPUTS_DIR) || true\n+  mkdir $(DEV_OUTPUTS_DIR)\n+  harness-runner ../../../../../_data/harnesses/fk-joins/kstreams.yml $(TEMP_DIR)\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-output-events.json $(DEV_OUTPUTS_DIR)/music-interest.json\n+```\n+\n+The last line uses the `diff` command to validate expected output against the actual output of tutorial steps.  The `Makefile` may have more than one valdiation step so it will have separate `diff` commmands for each verification.  For example:\n+\n+```yml\n+STEPS_DIR := tutorial-steps\n+DEV_OUTPUTS_DIR := $(STEPS_DIR)/dev/outputs\n+TEMP_DIR := $(shell mktemp -d)\n+\n+tutorial:\n+  rm -r $(DEV_OUTPUTS_DIR) || true\n+  mkdir $(DEV_OUTPUTS_DIR)\n+  harness-runner ../../../../../_data/harnesses/dynamic-output-topic/kstreams.yml $(TEMP_DIR)\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-output.json $(DEV_OUTPUTS_DIR)/actual-output.json\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-special-output.json $(DEV_OUTPUTS_DIR)/actual-special-order-output.json\n+```\n+\n+\n+\n+\n+#### 1. Structure\n+\n+Three top-level sections make up the harness file:\n+\n+* dev - the setup and teaching portion of the tutorial (required)\n+* test - test setup and execution of tests, if any (optional)\n+* prod - steps to build and deploy a docker image of the tutorial code (optional)\n+\n+In some cases, having a test and or prod section doesn't make sense, so those sections can be left out of the harness file.  The Apache Kafka console producer and consumer tutorials are a good example of tutorials that don't need a test or prod section.\n+\n+The `dev`, `test`, and `prod` sections contain a top-level element `steps`.  The `steps` contains any number of well, steps for the user to walk through.  Addtionally the `harness_runner` script follows the same steps for executing the tutorial automatically during builds.  The steps in any section are structured in the same way, so we'll only discuss the make-up of a single section.\n+\n+For reference here is an example section\n+\n+```yml\n+ - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/console-consumer-primitive-keys-values/kafka/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/console-consumer-primitive-keys-values/kafka/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+        - name: wait for ksqldb-server and connectors\n+          action: sleep\n+          ms: 30000\n+          render:\n+            skip: true\n+```\n+\n+\n+* Title - each section starts with a `title` element and as the label suggests, the text provided here is the text used the label the step for the tutorial user and the output to the console by the harness runner.  The `title` section contains one element - `content`\n+\n+* content - the `content` section (a YAML `dictionary`) contains an arbitrary sized list of YAML dictionaries named `action`. An `action` key creates an anonymous step i.e. not specified in the output of the test runner.  For output in the test runner, you can provide a `-name` key followed by some text for console output.\n+* action - `action` keys drive the behavior of the harness. An action key can be one of these values", "originalCommit": "329e16de87d5697391dee8827d1da1fcaf5aeeeb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk0NDkwNw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r442944907", "bodyText": "ack, will do!", "author": "bbejeck", "createdAt": "2020-06-19T16:45:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk0MzMyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NDU1OQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443064559", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            ## Working with the harness file\n          \n          \n            \n            ## Testing Locally", "author": "ybyzek", "createdAt": "2020-06-19T22:23:38Z", "path": "README.md", "diffHunk": "@@ -237,6 +237,180 @@ You can do the same for Kafka Streams and Kafka, by using the `kstreams` and `ka\n \n Lastly, create a Makefile in the `code` directory to invoke the harness runner and check any outputs that it produces. Then modify the `.semaphore/semaphore.yml` file to invoke that Makefile. This will make sure your tutorial gets checked by the CI system.\n \n+## Working with the harness file", "originalCommit": "329e16de87d5697391dee8827d1da1fcaf5aeeeb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NDc4Mw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443064783", "bodyText": "@bbejeck can we had a Table of Contents at the top of the README?", "author": "ybyzek", "createdAt": "2020-06-19T22:24:40Z", "path": "README.md", "diffHunk": "@@ -237,6 +237,180 @@ You can do the same for Kafka Streams and Kafka, by using the `kstreams` and `ka\n \n Lastly, create a Makefile in the `code` directory to invoke the harness runner and check any outputs that it produces. Then modify the `.semaphore/semaphore.yml` file to invoke that Makefile. This will make sure your tutorial gets checked by the CI system.\n \n+## Working with the harness file\n+\n+Given the test harness is the `heart` of a tutorial, it will be helpful to describe in detail how to work with a `kafka|ksql|kstreams.yml` file.  It should be noted the harness file is in the [YAML file formt](https://en.wikipedia.org/wiki/YAML), so formatting properly is essential.  The harness files generates the structure of the rendered tutorial and also validates any output of tutorial steps against expected values.", "originalCommit": "329e16de87d5697391dee8827d1da1fcaf5aeeeb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY0ODkyMA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443648920", "bodyText": "@ybyzek I took a stab at this, check it out and let me know WYT.", "author": "bbejeck", "createdAt": "2020-06-22T15:36:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NDc4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDI4MDgyNg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r444280826", "bodyText": "@bbejeck Awesome!  For your consideration: decrease it 2 levels instead of 3 levels -- makes it easier for future maintenance so you're not chasing down changes at the 3rd level back to the TOC.  But if you prefer 3, keep it ;). Looks great!", "author": "ybyzek", "createdAt": "2020-06-23T14:44:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NDc4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE5ODcyMw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r445198723", "bodyText": "@ybyzek great idea, will do", "author": "bbejeck", "createdAt": "2020-06-24T22:07:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NDc4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NDk5Mw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443064993", "bodyText": "Why assume?  Can we add a step:\ngit clone https://github.com/confluentinc/kafka-tutorials.git\ncd kafka-tutorials", "author": "ybyzek", "createdAt": "2020-06-19T22:25:30Z", "path": "README.md", "diffHunk": "@@ -237,6 +237,180 @@ You can do the same for Kafka Streams and Kafka, by using the `kstreams` and `ka\n \n Lastly, create a Makefile in the `code` directory to invoke the harness runner and check any outputs that it produces. Then modify the `.semaphore/semaphore.yml` file to invoke that Makefile. This will make sure your tutorial gets checked by the CI system.\n \n+## Working with the harness file\n+\n+Given the test harness is the `heart` of a tutorial, it will be helpful to describe in detail how to work with a `kafka|ksql|kstreams.yml` file.  It should be noted the harness file is in the [YAML file formt](https://en.wikipedia.org/wiki/YAML), so formatting properly is essential.  The harness files generates the structure of the rendered tutorial and also validates any output of tutorial steps against expected values.\n+\n+This section is not meant to be an exhaustive decription of the harness file.  New tutorial authors should not need to create a harness file from scratch, using either the `tools/gen_project.sh` or  `tools/clone.sh` script will provide a usable harness file.  This section should provide enough guidance to add, update, or remove sections as needed.\n+\n+#### TLDR;\n+\n+To run a tutorial programatically do the following stepes. Note these instructions assume you've already checked out the kafka-tutorials repo).", "originalCommit": "329e16de87d5697391dee8827d1da1fcaf5aeeeb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY3MzkwMA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443673900", "bodyText": "ack", "author": "bbejeck", "createdAt": "2020-06-22T16:13:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NDk5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NTE2Ng==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443065166", "bodyText": "FYC: hyperlink to an existing Makefile", "author": "ybyzek", "createdAt": "2020-06-19T22:26:18Z", "path": "README.md", "diffHunk": "@@ -237,6 +237,180 @@ You can do the same for Kafka Streams and Kafka, by using the `kstreams` and `ka\n \n Lastly, create a Makefile in the `code` directory to invoke the harness runner and check any outputs that it produces. Then modify the `.semaphore/semaphore.yml` file to invoke that Makefile. This will make sure your tutorial gets checked by the CI system.\n \n+## Working with the harness file\n+\n+Given the test harness is the `heart` of a tutorial, it will be helpful to describe in detail how to work with a `kafka|ksql|kstreams.yml` file.  It should be noted the harness file is in the [YAML file formt](https://en.wikipedia.org/wiki/YAML), so formatting properly is essential.  The harness files generates the structure of the rendered tutorial and also validates any output of tutorial steps against expected values.\n+\n+This section is not meant to be an exhaustive decription of the harness file.  New tutorial authors should not need to create a harness file from scratch, using either the `tools/gen_project.sh` or  `tools/clone.sh` script will provide a usable harness file.  This section should provide enough guidance to add, update, or remove sections as needed.\n+\n+#### TLDR;\n+\n+To run a tutorial programatically do the following stepes. Note these instructions assume you've already checked out the kafka-tutorials repo).\n+\n+1. cd into `_includes/tutorials/<tutorial name>/<type>/code` directory where type is one of `ksql | kstreams | kafka`.\n+2. run the `make` command.\n+\n+The `Makefile` will delete and re-create the `outputs` directory used contain files with output from various steps used to verify the tutorial steps.\n+\n+Here's an example of the contents of a `Makefile`:", "originalCommit": "329e16de87d5697391dee8827d1da1fcaf5aeeeb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY5NzA2Mw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443697063", "bodyText": "ack", "author": "bbejeck", "createdAt": "2020-06-22T16:52:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NTE2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NTcxOA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443065718", "bodyText": "Add example.\n\ncd _includes/tutorials/aggregating-count/kstreams/code", "author": "ybyzek", "createdAt": "2020-06-19T22:28:58Z", "path": "README.md", "diffHunk": "@@ -237,6 +237,180 @@ You can do the same for Kafka Streams and Kafka, by using the `kstreams` and `ka\n \n Lastly, create a Makefile in the `code` directory to invoke the harness runner and check any outputs that it produces. Then modify the `.semaphore/semaphore.yml` file to invoke that Makefile. This will make sure your tutorial gets checked by the CI system.\n \n+## Working with the harness file\n+\n+Given the test harness is the `heart` of a tutorial, it will be helpful to describe in detail how to work with a `kafka|ksql|kstreams.yml` file.  It should be noted the harness file is in the [YAML file formt](https://en.wikipedia.org/wiki/YAML), so formatting properly is essential.  The harness files generates the structure of the rendered tutorial and also validates any output of tutorial steps against expected values.\n+\n+This section is not meant to be an exhaustive decription of the harness file.  New tutorial authors should not need to create a harness file from scratch, using either the `tools/gen_project.sh` or  `tools/clone.sh` script will provide a usable harness file.  This section should provide enough guidance to add, update, or remove sections as needed.\n+\n+#### TLDR;\n+\n+To run a tutorial programatically do the following stepes. Note these instructions assume you've already checked out the kafka-tutorials repo).\n+\n+1. cd into `_includes/tutorials/<tutorial name>/<type>/code` directory where type is one of `ksql | kstreams | kafka`.", "originalCommit": "329e16de87d5697391dee8827d1da1fcaf5aeeeb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY3NDAzNA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443674034", "bodyText": "ack", "author": "bbejeck", "createdAt": "2020-06-22T16:14:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NTcxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NjE2Mg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443066162", "bodyText": "I tried to run this myself and got:\n\u201cThe \u2018harness-runner==0.0.1\u2019 distribution was not found and is required by the application\u201d\n\n\nHow can I resolve this?\nConsider whether this PR should add the explanation to resolve this error message", "author": "ybyzek", "createdAt": "2020-06-19T22:31:05Z", "path": "README.md", "diffHunk": "@@ -237,6 +237,180 @@ You can do the same for Kafka Streams and Kafka, by using the `kstreams` and `ka\n \n Lastly, create a Makefile in the `code` directory to invoke the harness runner and check any outputs that it produces. Then modify the `.semaphore/semaphore.yml` file to invoke that Makefile. This will make sure your tutorial gets checked by the CI system.\n \n+## Working with the harness file\n+\n+Given the test harness is the `heart` of a tutorial, it will be helpful to describe in detail how to work with a `kafka|ksql|kstreams.yml` file.  It should be noted the harness file is in the [YAML file formt](https://en.wikipedia.org/wiki/YAML), so formatting properly is essential.  The harness files generates the structure of the rendered tutorial and also validates any output of tutorial steps against expected values.\n+\n+This section is not meant to be an exhaustive decription of the harness file.  New tutorial authors should not need to create a harness file from scratch, using either the `tools/gen_project.sh` or  `tools/clone.sh` script will provide a usable harness file.  This section should provide enough guidance to add, update, or remove sections as needed.\n+\n+#### TLDR;\n+\n+To run a tutorial programatically do the following stepes. Note these instructions assume you've already checked out the kafka-tutorials repo).\n+\n+1. cd into `_includes/tutorials/<tutorial name>/<type>/code` directory where type is one of `ksql | kstreams | kafka`.\n+2. run the `make` command.", "originalCommit": "329e16de87d5697391dee8827d1da1fcaf5aeeeb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzQxNzg1Nw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443417857", "bodyText": "It would be good to have a dedicated prerequisites section just for being able to test locally. Right now there is ruby, bundle, etc.. required, but I'm not sure this is needed just to run the harness-runner ?\nIdeally a docker version of the harness-runner would be great so that users don't have to install python3 and pip3", "author": "vdesabou", "createdAt": "2020-06-22T09:05:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NjE2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzU3MDI4NA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443570284", "bodyText": "@bbejeck as a reference example:\nhttps://github.com/confluentinc/examples/blob/5.5.0-post/clients/cloud/python/README.md#example-3-run-all-the-above-in-docker\nhttps://github.com/confluentinc/examples/blob/5.5.0-post/clients/cloud/python/requirements.txt\nhttps://github.com/confluentinc/examples/blob/5.5.0-post/clients/cloud/python/Dockerfile\nI think you were thinking of addressing this in a separate PR.  But if you help me debug the harness runner error, I'm happy to build the Docker stuff.", "author": "ybyzek", "createdAt": "2020-06-22T13:47:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NjE2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ2NTMzMQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r444465331", "bodyText": "Dockerfile:\nFROM python:3.7-slim\nRUN pip3 install pyyaml\n\nBuild and execute:\ndocker build -t runner . ; docker run -v ${PWD}/harness_runner:/harness_runner/ -it --rm runner bash -c 'cd /harness_runner/ && pip3 install -e .'\n\nAnd now make works:\n(cd _includes/tutorials/transforming/kstreams/code/ && make)", "author": "ybyzek", "createdAt": "2020-06-23T19:45:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NjE2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NjI4Mw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443066283", "bodyText": "Hyperlink to example file?", "author": "ybyzek", "createdAt": "2020-06-19T22:31:45Z", "path": "README.md", "diffHunk": "@@ -237,6 +237,180 @@ You can do the same for Kafka Streams and Kafka, by using the `kstreams` and `ka\n \n Lastly, create a Makefile in the `code` directory to invoke the harness runner and check any outputs that it produces. Then modify the `.semaphore/semaphore.yml` file to invoke that Makefile. This will make sure your tutorial gets checked by the CI system.\n \n+## Working with the harness file\n+\n+Given the test harness is the `heart` of a tutorial, it will be helpful to describe in detail how to work with a `kafka|ksql|kstreams.yml` file.  It should be noted the harness file is in the [YAML file formt](https://en.wikipedia.org/wiki/YAML), so formatting properly is essential.  The harness files generates the structure of the rendered tutorial and also validates any output of tutorial steps against expected values.\n+\n+This section is not meant to be an exhaustive decription of the harness file.  New tutorial authors should not need to create a harness file from scratch, using either the `tools/gen_project.sh` or  `tools/clone.sh` script will provide a usable harness file.  This section should provide enough guidance to add, update, or remove sections as needed.\n+\n+#### TLDR;\n+\n+To run a tutorial programatically do the following stepes. Note these instructions assume you've already checked out the kafka-tutorials repo).\n+\n+1. cd into `_includes/tutorials/<tutorial name>/<type>/code` directory where type is one of `ksql | kstreams | kafka`.\n+2. run the `make` command.\n+\n+The `Makefile` will delete and re-create the `outputs` directory used contain files with output from various steps used to verify the tutorial steps.\n+\n+Here's an example of the contents of a `Makefile`:\n+\n+```yml\n+STEPS_DIR := tutorial-steps\n+DEV_OUTPUTS_DIR := $(STEPS_DIR)/dev/outputs\n+TEMP_DIR := $(shell mktemp -d)\n+\n+tutorial:\n+  rm -r $(DEV_OUTPUTS_DIR) || true\n+  mkdir $(DEV_OUTPUTS_DIR)\n+  harness-runner ../../../../../_data/harnesses/fk-joins/kstreams.yml $(TEMP_DIR)\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-output-events.json $(DEV_OUTPUTS_DIR)/music-interest.json\n+```\n+\n+The last line uses the `diff` command to validate expected output against the actual output of tutorial steps.  The `Makefile` may have more than one valdiation step so it will have separate `diff` commmands for each verification.  For example:\n+\n+```yml\n+STEPS_DIR := tutorial-steps\n+DEV_OUTPUTS_DIR := $(STEPS_DIR)/dev/outputs\n+TEMP_DIR := $(shell mktemp -d)\n+\n+tutorial:\n+  rm -r $(DEV_OUTPUTS_DIR) || true\n+  mkdir $(DEV_OUTPUTS_DIR)\n+  harness-runner ../../../../../_data/harnesses/dynamic-output-topic/kstreams.yml $(TEMP_DIR)\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-output.json $(DEV_OUTPUTS_DIR)/actual-output.json\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-special-output.json $(DEV_OUTPUTS_DIR)/actual-special-order-output.json\n+```\n+\n+\n+\n+\n+#### 1. Structure\n+\n+Three top-level sections make up the harness file:\n+\n+* dev - the setup and teaching portion of the tutorial (required)\n+* test - test setup and execution of tests, if any (optional)\n+* prod - steps to build and deploy a docker image of the tutorial code (optional)\n+\n+In some cases, having a test and or prod section doesn't make sense, so those sections can be left out of the harness file.  The Apache Kafka console producer and consumer tutorials are a good example of tutorials that don't need a test or prod section.\n+\n+The `dev`, `test`, and `prod` sections contain a top-level element `steps`.  The `steps` contains any number of well, steps for the user to walk through.  Addtionally the `harness_runner` script follows the same steps for executing the tutorial automatically during builds.  The steps in any section are structured in the same way, so we'll only discuss the make-up of a single section.\n+\n+For reference here is an example section", "originalCommit": "329e16de87d5697391dee8827d1da1fcaf5aeeeb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzY5NzIzMw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443697233", "bodyText": "ack", "author": "bbejeck", "createdAt": "2020-06-22T16:52:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NjI4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NjQ3Mg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443066472", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #### TLDR;\n          \n          \n            \n            #### TL;DR", "author": "ybyzek", "createdAt": "2020-06-19T22:32:38Z", "path": "README.md", "diffHunk": "@@ -237,6 +237,180 @@ You can do the same for Kafka Streams and Kafka, by using the `kstreams` and `ka\n \n Lastly, create a Makefile in the `code` directory to invoke the harness runner and check any outputs that it produces. Then modify the `.semaphore/semaphore.yml` file to invoke that Makefile. This will make sure your tutorial gets checked by the CI system.\n \n+## Working with the harness file\n+\n+Given the test harness is the `heart` of a tutorial, it will be helpful to describe in detail how to work with a `kafka|ksql|kstreams.yml` file.  It should be noted the harness file is in the [YAML file formt](https://en.wikipedia.org/wiki/YAML), so formatting properly is essential.  The harness files generates the structure of the rendered tutorial and also validates any output of tutorial steps against expected values.\n+\n+This section is not meant to be an exhaustive decription of the harness file.  New tutorial authors should not need to create a harness file from scratch, using either the `tools/gen_project.sh` or  `tools/clone.sh` script will provide a usable harness file.  This section should provide enough guidance to add, update, or remove sections as needed.\n+\n+#### TLDR;", "originalCommit": "329e16de87d5697391dee8827d1da1fcaf5aeeeb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2Njc3OQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443066779", "bodyText": "Can you add a hyperlink to those tutorials?", "author": "ybyzek", "createdAt": "2020-06-19T22:34:08Z", "path": "README.md", "diffHunk": "@@ -237,6 +237,180 @@ You can do the same for Kafka Streams and Kafka, by using the `kstreams` and `ka\n \n Lastly, create a Makefile in the `code` directory to invoke the harness runner and check any outputs that it produces. Then modify the `.semaphore/semaphore.yml` file to invoke that Makefile. This will make sure your tutorial gets checked by the CI system.\n \n+## Working with the harness file\n+\n+Given the test harness is the `heart` of a tutorial, it will be helpful to describe in detail how to work with a `kafka|ksql|kstreams.yml` file.  It should be noted the harness file is in the [YAML file formt](https://en.wikipedia.org/wiki/YAML), so formatting properly is essential.  The harness files generates the structure of the rendered tutorial and also validates any output of tutorial steps against expected values.\n+\n+This section is not meant to be an exhaustive decription of the harness file.  New tutorial authors should not need to create a harness file from scratch, using either the `tools/gen_project.sh` or  `tools/clone.sh` script will provide a usable harness file.  This section should provide enough guidance to add, update, or remove sections as needed.\n+\n+#### TLDR;\n+\n+To run a tutorial programatically do the following stepes. Note these instructions assume you've already checked out the kafka-tutorials repo).\n+\n+1. cd into `_includes/tutorials/<tutorial name>/<type>/code` directory where type is one of `ksql | kstreams | kafka`.\n+2. run the `make` command.\n+\n+The `Makefile` will delete and re-create the `outputs` directory used contain files with output from various steps used to verify the tutorial steps.\n+\n+Here's an example of the contents of a `Makefile`:\n+\n+```yml\n+STEPS_DIR := tutorial-steps\n+DEV_OUTPUTS_DIR := $(STEPS_DIR)/dev/outputs\n+TEMP_DIR := $(shell mktemp -d)\n+\n+tutorial:\n+  rm -r $(DEV_OUTPUTS_DIR) || true\n+  mkdir $(DEV_OUTPUTS_DIR)\n+  harness-runner ../../../../../_data/harnesses/fk-joins/kstreams.yml $(TEMP_DIR)\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-output-events.json $(DEV_OUTPUTS_DIR)/music-interest.json\n+```\n+\n+The last line uses the `diff` command to validate expected output against the actual output of tutorial steps.  The `Makefile` may have more than one valdiation step so it will have separate `diff` commmands for each verification.  For example:\n+\n+```yml\n+STEPS_DIR := tutorial-steps\n+DEV_OUTPUTS_DIR := $(STEPS_DIR)/dev/outputs\n+TEMP_DIR := $(shell mktemp -d)\n+\n+tutorial:\n+  rm -r $(DEV_OUTPUTS_DIR) || true\n+  mkdir $(DEV_OUTPUTS_DIR)\n+  harness-runner ../../../../../_data/harnesses/dynamic-output-topic/kstreams.yml $(TEMP_DIR)\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-output.json $(DEV_OUTPUTS_DIR)/actual-output.json\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-special-output.json $(DEV_OUTPUTS_DIR)/actual-special-order-output.json\n+```\n+\n+\n+\n+\n+#### 1. Structure\n+\n+Three top-level sections make up the harness file:\n+\n+* dev - the setup and teaching portion of the tutorial (required)\n+* test - test setup and execution of tests, if any (optional)\n+* prod - steps to build and deploy a docker image of the tutorial code (optional)\n+\n+In some cases, having a test and or prod section doesn't make sense, so those sections can be left out of the harness file.  The Apache Kafka console producer and consumer tutorials are a good example of tutorials that don't need a test or prod section.", "originalCommit": "329e16de87d5697391dee8827d1da1fcaf5aeeeb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzcwODE0Mg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443708142", "bodyText": "ack", "author": "bbejeck", "createdAt": "2020-06-22T17:12:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2Njc3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzA2NjgyMw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443066823", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                Somtimes the `execute` step is an _internal_ step only for the harness runner. Internal steps ignore the `render:` using a `skip: true` entry\n          \n          \n            \n                Sometimes the `execute` step is an _internal_ step only for the harness runner. Internal steps ignore the `render:` using a `skip: true` entry", "author": "ybyzek", "createdAt": "2020-06-19T22:34:24Z", "path": "README.md", "diffHunk": "@@ -237,6 +237,180 @@ You can do the same for Kafka Streams and Kafka, by using the `kstreams` and `ka\n \n Lastly, create a Makefile in the `code` directory to invoke the harness runner and check any outputs that it produces. Then modify the `.semaphore/semaphore.yml` file to invoke that Makefile. This will make sure your tutorial gets checked by the CI system.\n \n+## Working with the harness file\n+\n+Given the test harness is the `heart` of a tutorial, it will be helpful to describe in detail how to work with a `kafka|ksql|kstreams.yml` file.  It should be noted the harness file is in the [YAML file formt](https://en.wikipedia.org/wiki/YAML), so formatting properly is essential.  The harness files generates the structure of the rendered tutorial and also validates any output of tutorial steps against expected values.\n+\n+This section is not meant to be an exhaustive decription of the harness file.  New tutorial authors should not need to create a harness file from scratch, using either the `tools/gen_project.sh` or  `tools/clone.sh` script will provide a usable harness file.  This section should provide enough guidance to add, update, or remove sections as needed.\n+\n+#### TLDR;\n+\n+To run a tutorial programatically do the following stepes. Note these instructions assume you've already checked out the kafka-tutorials repo).\n+\n+1. cd into `_includes/tutorials/<tutorial name>/<type>/code` directory where type is one of `ksql | kstreams | kafka`.\n+2. run the `make` command.\n+\n+The `Makefile` will delete and re-create the `outputs` directory used contain files with output from various steps used to verify the tutorial steps.\n+\n+Here's an example of the contents of a `Makefile`:\n+\n+```yml\n+STEPS_DIR := tutorial-steps\n+DEV_OUTPUTS_DIR := $(STEPS_DIR)/dev/outputs\n+TEMP_DIR := $(shell mktemp -d)\n+\n+tutorial:\n+  rm -r $(DEV_OUTPUTS_DIR) || true\n+  mkdir $(DEV_OUTPUTS_DIR)\n+  harness-runner ../../../../../_data/harnesses/fk-joins/kstreams.yml $(TEMP_DIR)\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-output-events.json $(DEV_OUTPUTS_DIR)/music-interest.json\n+```\n+\n+The last line uses the `diff` command to validate expected output against the actual output of tutorial steps.  The `Makefile` may have more than one valdiation step so it will have separate `diff` commmands for each verification.  For example:\n+\n+```yml\n+STEPS_DIR := tutorial-steps\n+DEV_OUTPUTS_DIR := $(STEPS_DIR)/dev/outputs\n+TEMP_DIR := $(shell mktemp -d)\n+\n+tutorial:\n+  rm -r $(DEV_OUTPUTS_DIR) || true\n+  mkdir $(DEV_OUTPUTS_DIR)\n+  harness-runner ../../../../../_data/harnesses/dynamic-output-topic/kstreams.yml $(TEMP_DIR)\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-output.json $(DEV_OUTPUTS_DIR)/actual-output.json\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-special-output.json $(DEV_OUTPUTS_DIR)/actual-special-order-output.json\n+```\n+\n+\n+\n+\n+#### 1. Structure\n+\n+Three top-level sections make up the harness file:\n+\n+* dev - the setup and teaching portion of the tutorial (required)\n+* test - test setup and execution of tests, if any (optional)\n+* prod - steps to build and deploy a docker image of the tutorial code (optional)\n+\n+In some cases, having a test and or prod section doesn't make sense, so those sections can be left out of the harness file.  The Apache Kafka console producer and consumer tutorials are a good example of tutorials that don't need a test or prod section.\n+\n+The `dev`, `test`, and `prod` sections contain a top-level element `steps`.  The `steps` contains any number of well, steps for the user to walk through.  Addtionally the `harness_runner` script follows the same steps for executing the tutorial automatically during builds.  The steps in any section are structured in the same way, so we'll only discuss the make-up of a single section.\n+\n+For reference here is an example section\n+\n+```yml\n+ - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/console-consumer-primitive-keys-values/kafka/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/console-consumer-primitive-keys-values/kafka/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+        - name: wait for ksqldb-server and connectors\n+          action: sleep\n+          ms: 30000\n+          render:\n+            skip: true\n+```\n+\n+\n+* Title - each section starts with a `title` element and as the label suggests, the text provided here is the text used the label the step for the tutorial user and the output to the console by the harness runner.  The `title` section contains one element - `content`\n+\n+* content - the `content` section (a YAML `dictionary`) contains an arbitrary sized list of YAML dictionaries named `action`. An `action` key creates an anonymous step i.e. not specified in the output of the test runner.  For output in the test runner, you can provide a `-name` key followed by some text for console output.\n+* action - `action` keys drive the behavior of the harness. An action key can be one of these values\n+    * `action: make_file` - an action prompting the user to create a file for the tutorial.\n+    * `action: execute` - a synchronous action step\n+    * `action: execute_async` - an asynchronous step, this indicates a step the user will keep running for some portion of the tutorial.\n+    * `action: sleep` - pause the test runner for an amount of time specified by the `ms` key. You use `sleep` key to allow some asnyc action to complete\n+        * `ms: NNN` - the time in milliseconds you want the test harness to pause execution.  You only use `ms` after an `action: sleep` entry.\n+\n+In the next sections you'll see how to use `action` keys to organize your harness files\n+\n+\n+\n+#### 2. Action type descriptions and examples\n+\n+* `make_file`\n+    The `make_file` instructs the user to create a file an existing file required to run the tutorial.  Some examples are the `docker-compose.yml` file , a `statements.sql` (ksqlDB) , and Java files.\n+\n+    A `make_file` with a file to render look like this:\n+    ```yml\n+    - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/console-consumer-primitive-keys-values/kafka/markup/dev/make-docker-compose.adoc\n+    ```\n+\n+    * `file:` the path and name to the file.  The path is relative to `<tutorial-name>/<type>/code>` .The harness runner will use the file during the automated tutorial execution.\n+    * `render:` the file to render.  The `render` key is followed by one of two possible keys:\n+        * `file:` the path and name of the file to render to the user. \n+\n+* `execute` The `execute` step is a synchronous execution step during the tutorial for the user as well as the harness runner\n+\n+    ```yml\n+     - action: execute\n+          file: tutorial-steps/dev/init.sh\n+          render:\n+            file: tutorials/console-consumer-primitive-keys-values/kafka/markup/dev/init.adoc\n+    ```\n+\n+    Somtimes the `execute` step is an _internal_ step only for the harness runner. Internal steps ignore the `render:` using a `skip: true` entry", "originalCommit": "329e16de87d5697391dee8827d1da1fcaf5aeeeb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ce91dc13038c91cad2fd68a8fe63fd8398fcd92c", "url": "https://github.com/confluentinc/kafka-tutorials/commit/ce91dc13038c91cad2fd68a8fe63fd8398fcd92c", "message": "Apply suggestions from code review\n\nCo-authored-by: Yeva Byzek <ybyzek@users.noreply.github.com>", "committedDate": "2020-06-22T14:53:32Z", "type": "commit"}, {"oid": "db157806eeb0284be19a5ed370ad1a1f513c3c0a", "url": "https://github.com/confluentinc/kafka-tutorials/commit/db157806eeb0284be19a5ed370ad1a1f513c3c0a", "message": "First attempt at a TOC", "committedDate": "2020-06-22T15:26:26Z", "type": "commit"}, {"oid": "8e4271d97207f39c52ac093f34b6cc0c9723194f", "url": "https://github.com/confluentinc/kafka-tutorials/commit/8e4271d97207f39c52ac093f34b6cc0c9723194f", "message": "Updates per comments", "committedDate": "2020-06-22T17:12:55Z", "type": "commit"}, {"oid": "6a3552a4850c31fcc0acfaf25862f3aeda1ef28f", "url": "https://github.com/confluentinc/kafka-tutorials/commit/6a3552a4850c31fcc0acfaf25862f3aeda1ef28f", "message": "Add description of ocker_ksql_cli_session action", "committedDate": "2020-06-22T19:52:00Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mzc5MDM4OQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r443790389", "bodyText": "@colinhicks I've added a section for docker_ksql_cli_session", "author": "bbejeck", "createdAt": "2020-06-22T19:54:58Z", "path": "README.md", "diffHunk": "@@ -237,6 +268,210 @@ You can do the same for Kafka Streams and Kafka, by using the `kstreams` and `ka\n \n Lastly, create a Makefile in the `code` directory to invoke the harness runner and check any outputs that it produces. Then modify the `.semaphore/semaphore.yml` file to invoke that Makefile. This will make sure your tutorial gets checked by the CI system.\n \n+## Testing Locally\n+\n+Given the test harness is the `heart` of a tutorial, it will be helpful to describe in detail how to work with a `kafka|ksql|kstreams.yml` file.  It should be noted the harness file is in the [YAML file formt](https://en.wikipedia.org/wiki/YAML), so formatting properly is essential.  The harness files generates the structure of the rendered tutorial and also validates any output of tutorial steps against expected values.\n+\n+This section is not meant to be an exhaustive decription of the harness file.  New tutorial authors should not need to create a harness file from scratch, using either the `tools/gen_project.sh` or  `tools/clone.sh` script will provide a usable harness file.  This section should provide enough guidance to add, update, or remove sections as needed.\n+\n+#### TL;DR\n+\n+To run a tutorial programatically do the following stepes. Note to follow these instructions you'll need to checkout the kafka-tutorials repo:\n+\n+1. git clone https://github.com/confluentinc/kafka-tutorials.git\n+2. cd kafka-tutorials\n+\n+Once you have the kafka-tutorials repo checked out do the following:\n+\n+1. cd into `_includes/tutorials/<tutorial name>/<type>/code` directory where type is one of `ksql | kstreams | kafka`.\n+    * For exmaple `cd _includes/tutorials/fk-joins/kstreams/code`\n+2. run the `make` command.\n+\n+The `Makefile` will delete and re-create the `outputs` directory used contain files with output from various steps used to verify the tutorial steps.\n+\n+Here's of [the contents of an actual `Makefile`](https://github.com/confluentinc/kafka-tutorials/blob/master/_includes/tutorials/fk-joins/kstreams/code/Makefile) :\n+\n+```yml\n+STEPS_DIR := tutorial-steps\n+DEV_OUTPUTS_DIR := $(STEPS_DIR)/dev/outputs\n+TEMP_DIR := $(shell mktemp -d)\n+\n+tutorial:\n+  rm -r $(DEV_OUTPUTS_DIR) || true\n+  mkdir $(DEV_OUTPUTS_DIR)\n+  harness-runner ../../../../../_data/harnesses/fk-joins/kstreams.yml $(TEMP_DIR)\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-output-events.json $(DEV_OUTPUTS_DIR)/music-interest.json\n+```\n+\n+The last line uses the `diff` command to validate expected output against the actual output of tutorial steps.  The `Makefile` may have more than one valdiation step so it will have separate `diff` commmands for each verification.  \n+\n+For example here's the `Makefile` from the [dynamic output topics tutorial](https://github.com/confluentinc/kafka-tutorials/blob/master/_includes/tutorials/dynamic-output-topic/kstreams/code/Makefile)\n+\n+```yml\n+STEPS_DIR := tutorial-steps\n+DEV_OUTPUTS_DIR := $(STEPS_DIR)/dev/outputs\n+TEMP_DIR := $(shell mktemp -d)\n+\n+tutorial:\n+  rm -r $(DEV_OUTPUTS_DIR) || true\n+  mkdir $(DEV_OUTPUTS_DIR)\n+  harness-runner ../../../../../_data/harnesses/dynamic-output-topic/kstreams.yml $(TEMP_DIR)\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-output.json $(DEV_OUTPUTS_DIR)/actual-output.json\n+  diff --strip-trailing-cr $(STEPS_DIR)/dev/expected-special-output.json $(DEV_OUTPUTS_DIR)/actual-special-order-output.json\n+```\n+\n+#### 1. Structure\n+\n+Three top-level sections make up the harness file:\n+\n+* dev - the setup and teaching portion of the tutorial (required)\n+* test - test setup and execution of tests, if any (optional)\n+* prod - steps to build and deploy a docker image of the tutorial code (optional)\n+\n+In some cases, having a test and or prod section doesn't make sense, so those sections can be left out of the harness file.  The Apache Kafka [console producer and consumer basic operations](https://github.com/confluentinc/kafka-tutorials/blob/master/_data/harnesses/console-consumer-produer-basic/kafka.yml) and the Apache Kafka [console consumer with primitive keys and values](https://github.com/confluentinc/kafka-tutorials/blob/master/_data/harnesses/console-consumer-primitive-keys-values/kafka.yml) tutorials are a good example of tutorials that don't need a test or prod section.\n+\n+The `dev`, `test`, and `prod` sections contain a top-level element `steps`.  The `steps` contains any number of well, steps for the user to walk through.  Addtionally the `harness_runner` script follows the same steps for executing the tutorial automatically during builds.  The steps in any section are structured in the same way, so we'll only discuss the make-up of a single section.\n+\n+For reference here is an example section of the harness file from the [console consumer primitive keys and values tutorial](https://github.com/confluentinc/kafka-tutorials/blob/master/_data/harnesses/console-consumer-primitive-keys-values/kafka.yml)\n+\n+```yml\n+ - title: Get Confluent Platform\n+      content:\n+        - action: make_file\n+          file: docker-compose.yml\n+          render:\n+            file: tutorials/console-consumer-primitive-keys-values/kafka/markup/dev/make-docker-compose.adoc\n+\n+        - action: execute_async\n+          file: tutorial-steps/dev/docker-compose-up.sh\n+          render:\n+            file: tutorials/console-consumer-primitive-keys-values/kafka/markup/dev/start-compose.adoc\n+\n+        - action: execute\n+          file: tutorial-steps/dev/wait-for-containers.sh\n+          render:\n+            skip: true\n+\n+        - name: wait for ksqldb-server and connectors\n+          action: sleep\n+          ms: 30000\n+          render:\n+            skip: true\n+```\n+\n+\n+* Title - each section starts with a `title` element and as the label suggests, the text provided here is the text used the label the step for the tutorial user and the output to the console by the harness runner.  The `title` section contains one element - `content`\n+\n+* content - the `content` section (a YAML `dictionary`) contains an arbitrary sized list of YAML dictionaries named `action`. An `action` key creates an anonymous step i.e. not specified in the output of the test runner.  For output in the test runner, you can provide a `-name` key followed by some text for console output.\n+* action - `action` keys drive the behavior of the harness. An action key can be one of these values\n+    * `action: make_file` - an action prompting the user to create a file for the tutorial.\n+    * `action: execute` - a synchronous action step\n+    * `action: execute_async` - an asynchronous step, this indicates a step the user will keep running for some portion of the tutorial.\n+    * `action: sleep` - pause the test runner for an amount of time specified by the `ms` key. You use `sleep` key to allow some asnyc action to complete\n+        * `ms: NNN` - the time in milliseconds you want the test harness to pause execution.  You only use `ms` after an `action: sleep` entry.\n+    * `docker_ksql_cli_session` - an action starting a ksqlDB CLI session for working through a tutorial", "originalCommit": "6a3552a4850c31fcc0acfaf25862f3aeda1ef28f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ2ODQ1Nw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r444468457", "bodyText": "Should we add a 3rd step to setup environment per the instructions at https://github.com/confluentinc/kafka-tutorials#setup ?  If so, that might be where we provide the optional Dockerfile addition?", "author": "ybyzek", "createdAt": "2020-06-23T19:51:06Z", "path": "README.md", "diffHunk": "@@ -237,6 +268,210 @@ You can do the same for Kafka Streams and Kafka, by using the `kstreams` and `ka\n \n Lastly, create a Makefile in the `code` directory to invoke the harness runner and check any outputs that it produces. Then modify the `.semaphore/semaphore.yml` file to invoke that Makefile. This will make sure your tutorial gets checked by the CI system.\n \n+## Testing Locally\n+\n+Given the test harness is the `heart` of a tutorial, it will be helpful to describe in detail how to work with a `kafka|ksql|kstreams.yml` file.  It should be noted the harness file is in the [YAML file formt](https://en.wikipedia.org/wiki/YAML), so formatting properly is essential.  The harness files generates the structure of the rendered tutorial and also validates any output of tutorial steps against expected values.\n+\n+This section is not meant to be an exhaustive decription of the harness file.  New tutorial authors should not need to create a harness file from scratch, using either the `tools/gen_project.sh` or  `tools/clone.sh` script will provide a usable harness file.  This section should provide enough guidance to add, update, or remove sections as needed.\n+\n+#### TL;DR\n+\n+To run a tutorial programatically do the following stepes. Note to follow these instructions you'll need to checkout the kafka-tutorials repo:\n+\n+1. git clone https://github.com/confluentinc/kafka-tutorials.git\n+2. cd kafka-tutorials", "originalCommit": "6a3552a4850c31fcc0acfaf25862f3aeda1ef28f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ3MjY1Ng==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r444472656", "bodyText": "Or is it the case that running the harness_runner does NOT require all those other dependencies?", "author": "ybyzek", "createdAt": "2020-06-23T19:59:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ2ODQ1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTEwNzUzOQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r445107539", "bodyText": "Just wanted to document a suggestion from @vdesabou here -- this differentiation would address the confusion I had and help other users as well.\n\nIt would be great to have a clarification in prerequisite section to specify that dependencies are only to build the site and not required to test locally.", "author": "ybyzek", "createdAt": "2020-06-24T19:01:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ2ODQ1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDkyNjk0Ng==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r444926946", "bodyText": "Typo: YAML file formt", "author": "vdesabou", "createdAt": "2020-06-24T14:17:02Z", "path": "README.md", "diffHunk": "@@ -237,6 +268,210 @@ You can do the same for Kafka Streams and Kafka, by using the `kstreams` and `ka\n \n Lastly, create a Makefile in the `code` directory to invoke the harness runner and check any outputs that it produces. Then modify the `.semaphore/semaphore.yml` file to invoke that Makefile. This will make sure your tutorial gets checked by the CI system.\n \n+## Testing Locally\n+\n+Given the test harness is the `heart` of a tutorial, it will be helpful to describe in detail how to work with a `kafka|ksql|kstreams.yml` file.  It should be noted the harness file is in the [YAML file formt](https://en.wikipedia.org/wiki/YAML), so formatting properly is essential.  The harness files generates the structure of the rendered tutorial and also validates any output of tutorial steps against expected values.", "originalCommit": "6a3552a4850c31fcc0acfaf25862f3aeda1ef28f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTIwMTcyNQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/441#discussion_r445201725", "bodyText": "Good catch!", "author": "bbejeck", "createdAt": "2020-06-24T22:15:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDkyNjk0Ng=="}], "type": "inlineReview"}, {"oid": "d86c33e3d687bea521f85e7a333c16af9e07b9c1", "url": "https://github.com/confluentinc/kafka-tutorials/commit/d86c33e3d687bea521f85e7a333c16af9e07b9c1", "message": "Update TOC to only go to 2nd level", "committedDate": "2020-06-24T22:07:50Z", "type": "commit"}, {"oid": "5c6fd3b7b0d4892e61f1c0cffcefd46a89db161f", "url": "https://github.com/confluentinc/kafka-tutorials/commit/5c6fd3b7b0d4892e61f1c0cffcefd46a89db161f", "message": "add instructions for using docker to install python3", "committedDate": "2020-06-24T22:33:03Z", "type": "commit"}, {"oid": "aefeff9bf763a622a205677afe86e087fa1d97d2", "url": "https://github.com/confluentinc/kafka-tutorials/commit/aefeff9bf763a622a205677afe86e087fa1d97d2", "message": "Cleaned up grammar", "committedDate": "2020-06-24T22:52:29Z", "type": "commit"}]}