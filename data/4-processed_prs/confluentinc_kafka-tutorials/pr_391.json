{"pr_number": 391, "pr_title": "DEVX-1823: console consumer specific offsets partitions", "pr_createdAt": "2020-05-22T20:57:42Z", "pr_url": "https://github.com/confluentinc/kafka-tutorials/pull/391", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzMTAzOA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r431831038", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            docker exec -i broker /usr/bin/kafka-topics --create --topic example-topic --zookeeper zookeeper:2181 --replication-factor 1 --partitions 2\n          \n          \n            \n            docker-compose exec broker kafka-topics --create --topic example-topic --bootstrap-server broker:9092 --replication-factor 1 --partitions 2\n          \n      \n    \n    \n  \n\n/usr/bin is in the system path, so I'm not sure we need to clutter the command w/ the full path.  Also modified to use bootstrap-server and docker-compose exec instead of docker exec", "author": "rspurgeon", "createdAt": "2020-05-28T13:23:58Z", "path": "_includes/tutorials/console-consumer-read-specific-offsets-partition/kafka/code/tutorial-steps/dev/create-topic.sh", "diffHunk": "@@ -0,0 +1 @@\n+docker exec -i broker /usr/bin/kafka-topics --create --topic example-topic --zookeeper zookeeper:2181 --replication-factor 1 --partitions 2", "originalCommit": "61d0ca0002c7ee9b6c11fa158b37b6310f4fd114", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTk4MjcwMg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r431982702", "bodyText": "I'm in the process of converting the 101 PRs to use docker-compose I've already updated #380 I'm doing so for this one now.", "author": "bbejeck", "createdAt": "2020-05-28T16:53:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzMTAzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA5OTc0OA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r432099748", "bodyText": "actually just tried this and the /usr/bin is required. But I'm thinking of following the pattern of opening a shell on the container first", "author": "bbejeck", "createdAt": "2020-05-28T20:18:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzMTAzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEwNzcwNg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r432107706", "bodyText": "That's interesting. What could be preventing /usr/bin from being on the PATH for you?\nSeems to work with bare commands:\n$ docker run confluentinc/cp-kafka:5.5.0 sh -c 'echo $PATH'\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n\n--\n$ docker run confluentinc/cp-kafka:5.5.0 sh -c 'which kafka-topics'\n/usr/bin/kafka-topics", "author": "colinhicks", "createdAt": "2020-05-28T20:34:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzMTAzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjExODQ4Mw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r432118483", "bodyText": "It works for me without the full path:\n15:55:54 in dev/tmp/console-consumer-read-specific-offsets-partition took 2s\n[I] \u279c docker-compose exec broker kafka-topics --create --topic example-topic --bootstrap-server broker:9092 --replication-factor 1 --partitions 2\nCreated topic example-topic.", "author": "rspurgeon", "createdAt": "2020-05-28T20:56:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzMTAzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyMTc3NA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r432121774", "bodyText": "not sure, but I'm not too concerned as I've followed the pattern of having users open shell on the broker container and then use kafka-topics... . This follows the same path we have for users to run the console consumer and producer in these tutorials.", "author": "bbejeck", "createdAt": "2020-05-28T21:02:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzMTAzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyOTc1Mg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r432129752", "bodyText": "Just to close the loop, I must have fat-fingered something before as it works now, but I'm going with the container shell option.  I'll need to update the other PR and the one I just merged earlier for consistency", "author": "bbejeck", "createdAt": "2020-05-28T21:19:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzMTAzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzMjQxNg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r431832416", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            docker exec -i broker /usr/bin/kafka-console-producer --topic example-topic --broker-list broker:9092\\\n          \n          \n            \n              --property parse.key=true\\\n          \n          \n            \n              --property key.separator=\":\"\n          \n          \n            \n            docker-compose exec broker kafka-console-producer --topic example-topic --broker-list broker:9092 \\\n          \n          \n            \n              --property parse.key=true \\\n          \n          \n            \n              --property key.separator=\":\"", "author": "rspurgeon", "createdAt": "2020-05-28T13:25:58Z", "path": "_includes/tutorials/console-consumer-read-specific-offsets-partition/kafka/code/tutorial-steps/dev/console-producer-keys.sh", "diffHunk": "@@ -0,0 +1,3 @@\n+docker exec -i broker /usr/bin/kafka-console-producer --topic example-topic --broker-list broker:9092\\\n+  --property parse.key=true\\\n+  --property key.separator=\":\"", "originalCommit": "61d0ca0002c7ee9b6c11fa158b37b6310f4fd114", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzMjg1OA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r431832858", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            docker exec -it broker /usr/bin/kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\\n          \n          \n            \n            docker-compose exec broker kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\", "author": "rspurgeon", "createdAt": "2020-05-28T13:26:39Z", "path": "_includes/tutorials/console-consumer-read-specific-offsets-partition/kafka/code/tutorial-steps/dev/harness-console-consumer-keys-partition-one-offset-six.sh", "diffHunk": "@@ -0,0 +1,6 @@\n+docker exec -it broker /usr/bin/kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\", "originalCommit": "61d0ca0002c7ee9b6c11fa158b37b6310f4fd114", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzNTI0Mg==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r431835242", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            docker exec -it broker /usr/bin/kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\\n          \n          \n            \n            docker-compose exec broker kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\", "author": "rspurgeon", "createdAt": "2020-05-28T13:30:10Z", "path": "_includes/tutorials/console-consumer-read-specific-offsets-partition/kafka/code/tutorial-steps/dev/harness-console-consumer-keys-partition-one.sh", "diffHunk": "@@ -0,0 +1,6 @@\n+docker exec -it broker /usr/bin/kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\", "originalCommit": "61d0ca0002c7ee9b6c11fa158b37b6310f4fd114", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzNTQ1OQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r431835459", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            docker exec -it broker /usr/bin/kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\\n          \n          \n            \n            docker-compose exec broker kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\", "author": "rspurgeon", "createdAt": "2020-05-28T13:30:30Z", "path": "_includes/tutorials/console-consumer-read-specific-offsets-partition/kafka/code/tutorial-steps/dev/harness-console-consumer-keys-partition-zero.sh", "diffHunk": "@@ -0,0 +1,6 @@\n+docker exec -it broker /usr/bin/kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\", "originalCommit": "61d0ca0002c7ee9b6c11fa158b37b6310f4fd114", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzNTg0Ng==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r431835846", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            docker exec -it broker /usr/bin/kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\\n          \n          \n            \n            docker-compose exec broker kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\", "author": "rspurgeon", "createdAt": "2020-05-28T13:31:02Z", "path": "_includes/tutorials/console-consumer-read-specific-offsets-partition/kafka/code/tutorial-steps/dev/console-consumer-keys-partition-offset.sh", "diffHunk": "@@ -0,0 +1,5 @@\n+docker exec -it broker /usr/bin/kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\", "originalCommit": "61d0ca0002c7ee9b6c11fa158b37b6310f4fd114", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzNjIwMA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r431836200", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            docker exec -it broker /usr/bin/kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\\n          \n          \n            \n            docker-compose exec broker kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\", "author": "rspurgeon", "createdAt": "2020-05-28T13:31:31Z", "path": "_includes/tutorials/console-consumer-read-specific-offsets-partition/kafka/code/tutorial-steps/dev/console-consumer-keys-partition-one.sh", "diffHunk": "@@ -0,0 +1,5 @@\n+docker exec -it broker /usr/bin/kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\", "originalCommit": "61d0ca0002c7ee9b6c11fa158b37b6310f4fd114", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzNjM3NA==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r431836374", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            docker exec -it broker /usr/bin/kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\\n          \n          \n            \n            docker-compose exec broker kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\", "author": "rspurgeon", "createdAt": "2020-05-28T13:31:49Z", "path": "_includes/tutorials/console-consumer-read-specific-offsets-partition/kafka/code/tutorial-steps/dev/console-consumer-keys-partition-zero.sh", "diffHunk": "@@ -0,0 +1,5 @@\n+docker exec -it broker /usr/bin/kafka-console-consumer --topic example-topic --bootstrap-server broker:9092 \\", "originalCommit": "61d0ca0002c7ee9b6c11fa158b37b6310f4fd114", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTgzOTI3Mw==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r431839273", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            You'll notice you sent 12 records, but only 3 went to the first partition.  The reason for this is the way Kafka calculates the partition for any key.  Kafka calculates the partition by taking the hash of the key modulo the number of partitions.  So, even though you have 2 partitions, depending on what the key hash value is, you aren't guaranteed an even distribution of records across partitions.\n          \n          \n            \n            You'll notice you sent 12 records, but only 3 went to the first partition.  The reason for this is the way Kafka calculates the partition assigment for a given record.  Kafka calculates the partition by taking the hash of the key modulo the number of partitions.  So, even though you have 2 partitions, depending on what the key hash value is, you aren't guaranteed an even distribution of records across partitions.", "author": "rspurgeon", "createdAt": "2020-05-28T13:36:07Z", "path": "_includes/tutorials/console-consumer-read-specific-offsets-partition/kafka/markup/dev/consume-topic-partition-zero.adoc", "diffHunk": "@@ -0,0 +1,18 @@\n+Next let's open up a console consumer to read records sent to the topic in the previous step, but you'll only read from the first partition. Kafka partitions\n+are zero based so your two partitions are numbered `0`, and `1` respectively.\n+\n+Lets start a console consumer to read only records from the first partition, `0`\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/console-consumer-read-specific-offsets-partition/kafka/code/tutorial-steps/dev/console-consumer-keys-partition-zero.sh %}</code></pre>\n++++++\n+\n+After a few seconds you should see something like this\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/console-consumer-read-specific-offsets-partition/kafka/code/tutorial-steps/dev/expected-output-step-one.txt %}</code></pre>\n++++++\n+\n+You'll notice you sent 12 records, but only 3 went to the first partition.  The reason for this is the way Kafka calculates the partition for any key.  Kafka calculates the partition by taking the hash of the key modulo the number of partitions.  So, even though you have 2 partitions, depending on what the key hash value is, you aren't guaranteed an even distribution of records across partitions.", "originalCommit": "61d0ca0002c7ee9b6c11fa158b37b6310f4fd114", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTg0MjQyOQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r431842429", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            So far you've learned how to consume records from a specific partition. But when you specify the partition, you can optionally specify the offest to start conuming from.  Specifying a specific offset can be helpful when debugging an issue, in that you can skip consuming records that you konw aren't a potential problem.\n          \n          \n            \n            So far you've learned how to consume records from a specific partition. When you specify the partition, you can optionally specify the offest to start conuming from.  Specifying a specific offset can be helpful when debugging an issue, in that you can skip consuming records that you know aren't a potential problem.", "author": "rspurgeon", "createdAt": "2020-05-28T13:40:36Z", "path": "_includes/tutorials/console-consumer-read-specific-offsets-partition/kafka/markup/dev/consume-topic-partition-offsets.adoc", "diffHunk": "@@ -0,0 +1,23 @@\n+So far you've learned how to consume records from a specific partition. But when you specify the partition, you can optionally specify the offest to start conuming from.  Specifying a specific offset can be helpful when debugging an issue, in that you can skip consuming records that you konw aren't a potential problem.", "originalCommit": "61d0ca0002c7ee9b6c11fa158b37b6310f4fd114", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTg1MTI4MQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r431851281", "bodyText": "Pretty sure this should read 6, 7, 8\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            So you can see here, you've consumed records starting from offset 6 to the end, which includes record with offsets of `7, 8, and 9` the last three records.\n          \n          \n            \n            So you can see you've consumed records starting from offset 6 to the end, which includes record with offsets of `6, 7, and 8`, the last three records.\n          \n      \n    \n    \n  \n\nHere is an equivilant kafkacat command which prints the offsets:\nkafkacat -b :29092 -t example-topic -C -p 1 -o 6 -f 'Topic %t [%p] at offset %o: key %k: %s\\n'\nTopic example-topic [1] at offset 6: key key2: Go to\nTopic example-topic [1] at offset 7: key key3: Kafka\nTopic example-topic [1] at offset 8: key key4: summit\n% Reached end of topic example-topic [1] at offset 9", "author": "rspurgeon", "createdAt": "2020-05-28T13:52:03Z", "path": "_includes/tutorials/console-consumer-read-specific-offsets-partition/kafka/markup/dev/consume-topic-partition-offsets.adoc", "diffHunk": "@@ -0,0 +1,23 @@\n+So far you've learned how to consume records from a specific partition. But when you specify the partition, you can optionally specify the offest to start conuming from.  Specifying a specific offset can be helpful when debugging an issue, in that you can skip consuming records that you konw aren't a potential problem.\n+\n+If you haven't done so already, close the previous console consumer with a `CTRL+C`.\n+\n+From the previous step you know there are 9 records in the second partition.  In this step you'll only consume records starting from offset 5. The changes in this command include removing the `--from-begining` propery and adding an `--offset` flag\n+\n+It's import to note, when you specify the offset to start consuming from, it's _**exclusive**_ of the number given.  By giving a specific offset, you are saying \"I'm only interested in records _**after**_ this specific offset\".  That's exactly how commiting works in Kafka, consumer commits the offset of the last record read, so it will start consuming from the _*next*_ available offset.\n+\n+Here's the command to read records from the second partition starting at offset 6:\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/console-consumer-read-specific-offsets-partition/kafka/code/tutorial-steps/dev/console-consumer-keys-partition-offset.sh %}</code></pre>\n++++++\n+\n+After a few seconds you should see something like this\n+\n++++++\n+<pre class=\"snippet\"><code class=\"shell\">{% include_raw tutorials/console-consumer-read-specific-offsets-partition/kafka/code/tutorial-steps/dev/expected-output-step-three.txt %}</code></pre>\n++++++\n+\n+So you can see here, you've consumed records starting from offset 6 to the end, which includes record with offsets of `7, 8, and 9` the last three records.", "originalCommit": "61d0ca0002c7ee9b6c11fa158b37b6310f4fd114", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEyMDYwMQ==", "url": "https://github.com/confluentinc/kafka-tutorials/pull/391#discussion_r432120601", "bodyText": "oof, I confused myself at some point, good catch, I've updated this", "author": "bbejeck", "createdAt": "2020-05-28T21:00:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTg1MTI4MQ=="}], "type": "inlineReview"}, {"oid": "e36a26773653e29449d33e048eff0a18631e97c8", "url": "https://github.com/confluentinc/kafka-tutorials/commit/e36a26773653e29449d33e048eff0a18631e97c8", "message": "Changes to use broker container shell and updates for comments", "committedDate": "2020-05-28T20:58:34Z", "type": "forcePushed"}, {"oid": "b6966f5f7b3044458d26ab4134ec79ff3196fc7b", "url": "https://github.com/confluentinc/kafka-tutorials/commit/b6966f5f7b3044458d26ab4134ec79ff3196fc7b", "message": "initial commit of console consumer offset reading", "committedDate": "2020-05-29T21:40:02Z", "type": "commit"}, {"oid": "1acf3700d289703407e7e2430b7dc645d8a6cb8d", "url": "https://github.com/confluentinc/kafka-tutorials/commit/1acf3700d289703407e7e2430b7dc645d8a6cb8d", "message": "draft of complete tutorial", "committedDate": "2020-05-29T21:41:56Z", "type": "commit"}, {"oid": "95d7c2962f19068b82e98bdc837feb73211f458b", "url": "https://github.com/confluentinc/kafka-tutorials/commit/95d7c2962f19068b82e98bdc837feb73211f458b", "message": "Changes to use broker container shell and updates for comments", "committedDate": "2020-05-29T21:41:56Z", "type": "commit"}, {"oid": "169ffe6750b8eee9d43d8c83a81b92ea4c00afad", "url": "https://github.com/confluentinc/kafka-tutorials/commit/169ffe6750b8eee9d43d8c83a81b92ea4c00afad", "message": "Apply suggestions from code review\n\nCo-authored-by: Rick Spurgeon <rspurgeon@users.noreply.github.com>", "committedDate": "2020-05-29T21:41:56Z", "type": "commit"}, {"oid": "29cf27b894a48bebc2b8ed41d0485e6d19bf54f5", "url": "https://github.com/confluentinc/kafka-tutorials/commit/29cf27b894a48bebc2b8ed41d0485e6d19bf54f5", "message": "update to use docker-compose exec and remove '/usr/bin' paths", "committedDate": "2020-05-29T21:41:56Z", "type": "commit"}, {"oid": "29cf27b894a48bebc2b8ed41d0485e6d19bf54f5", "url": "https://github.com/confluentinc/kafka-tutorials/commit/29cf27b894a48bebc2b8ed41d0485e6d19bf54f5", "message": "update to use docker-compose exec and remove '/usr/bin' paths", "committedDate": "2020-05-29T21:41:56Z", "type": "forcePushed"}]}