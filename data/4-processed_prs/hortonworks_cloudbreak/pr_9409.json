{"pr_number": 9409, "pr_title": "CB-9657 DataLake runtime version is null", "pr_createdAt": "2020-11-11T12:46:33Z", "pr_url": "https://github.com/hortonworks/cloudbreak/pull/9409", "timeline": [{"oid": "58f5a947caaa4a2b0e358b98ca3edb04898ef6f1", "url": "https://github.com/hortonworks/cloudbreak/commit/58f5a947caaa4a2b0e358b98ca3edb04898ef6f1", "message": "CB-9657 DataLake runtime version is null", "committedDate": "2020-11-11T13:04:13Z", "type": "forcePushed"}, {"oid": "c65f8475b859b984af2038b92c04c096c0ef6e18", "url": "https://github.com/hortonworks/cloudbreak/commit/c65f8475b859b984af2038b92c04c096c0ef6e18", "message": "CB-9657 DataLake runtime version is null", "committedDate": "2020-11-11T13:16:08Z", "type": "forcePushed"}, {"oid": "693042e3ce9baba3d8e1e34354562baf8bb9344f", "url": "https://github.com/hortonworks/cloudbreak/commit/693042e3ce9baba3d8e1e34354562baf8bb9344f", "message": "CB-9657 DataLake runtime version is null", "committedDate": "2020-11-11T14:51:29Z", "type": "forcePushed"}, {"oid": "ca9c0099cfb773f14b0775530522c3375a10de12", "url": "https://github.com/hortonworks/cloudbreak/commit/ca9c0099cfb773f14b0775530522c3375a10de12", "message": "CB-9657 DataLake runtime version is null", "committedDate": "2020-11-11T15:26:26Z", "type": "forcePushed"}, {"oid": "28cb5147df6916f4f935f03080d6bc5b169cf718", "url": "https://github.com/hortonworks/cloudbreak/commit/28cb5147df6916f4f935f03080d6bc5b169cf718", "message": "CB-9657 DataLake runtime version is null", "committedDate": "2020-11-11T15:46:29Z", "type": "forcePushed"}, {"oid": "966b30adc14b6e113db79ab9f69b0f2659ab89ea", "url": "https://github.com/hortonworks/cloudbreak/commit/966b30adc14b6e113db79ab9f69b0f2659ab89ea", "message": "CB-9657 DataLake runtime version is null", "committedDate": "2020-11-11T19:28:10Z", "type": "forcePushed"}, {"oid": "959ff3d90a73acbdc519db0969131e104a19f44d", "url": "https://github.com/hortonworks/cloudbreak/commit/959ff3d90a73acbdc519db0969131e104a19f44d", "message": "CB-9657 DataLake runtime version is null", "committedDate": "2020-11-12T07:01:55Z", "type": "forcePushed"}, {"oid": "52e79a612549822df61cae91507591fbb73d2aee", "url": "https://github.com/hortonworks/cloudbreak/commit/52e79a612549822df61cae91507591fbb73d2aee", "message": "CB-9657 DataLake runtime version is null", "committedDate": "2020-11-12T08:03:56Z", "type": "forcePushed"}, {"oid": "2354fc14767aab05fb4f06a3a907c2f02e29103e", "url": "https://github.com/hortonworks/cloudbreak/commit/2354fc14767aab05fb4f06a3a907c2f02e29103e", "message": "CB-9657 DataLake runtime version is null", "committedDate": "2020-11-12T08:09:06Z", "type": "forcePushed"}, {"oid": "55e367ed3f835e04391c931827f762338a221103", "url": "https://github.com/hortonworks/cloudbreak/commit/55e367ed3f835e04391c931827f762338a221103", "message": "CB-9657 DataLake runtime version is null", "committedDate": "2020-11-12T08:25:44Z", "type": "forcePushed"}, {"oid": "1c8005e4e8f736ba928e419d52c29a43bfc68ef1", "url": "https://github.com/hortonworks/cloudbreak/commit/1c8005e4e8f736ba928e419d52c29a43bfc68ef1", "message": "CB-9657 DataLake runtime version is null", "committedDate": "2020-11-12T08:50:28Z", "type": "forcePushed"}, {"oid": "73fad4d80d65ff183fc1f12cc6ed77070612b0ae", "url": "https://github.com/hortonworks/cloudbreak/commit/73fad4d80d65ff183fc1f12cc6ed77070612b0ae", "message": "CB-9657 DataLake runtime version is null", "committedDate": "2020-11-12T09:17:57Z", "type": "forcePushed"}, {"oid": "ee2c652d9ee454997e59bed201181738b37cca21", "url": "https://github.com/hortonworks/cloudbreak/commit/ee2c652d9ee454997e59bed201181738b37cca21", "message": "CB-9657 DataLake runtime version is null", "committedDate": "2020-11-12T11:28:32Z", "type": "forcePushed"}, {"oid": "c4229eed20499f4da2cdc345c8b5d11338fc1b8d", "url": "https://github.com/hortonworks/cloudbreak/commit/c4229eed20499f4da2cdc345c8b5d11338fc1b8d", "message": "CB-9657 DataLake runtime version is null", "committedDate": "2020-11-12T12:37:15Z", "type": "forcePushed"}, {"oid": "43e734ba0c3e69934d6464179c4ce28ae7b8c753", "url": "https://github.com/hortonworks/cloudbreak/commit/43e734ba0c3e69934d6464179c4ce28ae7b8c753", "message": "CB-9657 DataLake runtime version is null\nin various scenarios runtime version of datalake can be null, this commit will prevent these scenarios\n- validation for existing available datalake should happen at the beginning of datahub creation, not in the middle of stack conversion, with this we can prevent errors during datalake runtime version check during datahub creation, because in case of custom SDX runtime in SDX service filled in only when datalake is available\n- dh runtime version validator should rely on data available in CB by default, and it can still fall back to SDX service\n- distrox related mock tests should create datalake before creating datahub", "committedDate": "2020-11-12T12:50:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA5MDIxMg==", "url": "https://github.com/hortonworks/cloudbreak/pull/9409#discussion_r522090212", "bodyText": "two things here. you're catching exceptions that have been thrown earlier by yourself which can be replaced with another flow control approach. maybe it's just me but I usually hate these exception driven development kind of approach \ud83d\ude42 because it is not just unnecessary to invoke any kind of exception but it can be unnecessarily resource-intensive to do so.\non the other hand, you're about to catch an Exception which is \"too wide\" to catch. it catches everything but the catch block doesn't ensure that the original problem/exception won't happen again. surely there are many cases when multiple kinds of exception should be handle in the same way but IMO one should be aware of the original exception not just to be able to handle it properly but to make a more meaningful log entry for that scenario", "author": "gregito", "createdAt": "2020-11-12T13:04:32Z", "path": "core/src/main/java/com/sequenceiq/cloudbreak/controller/validation/stack/StackRuntimeVersionValidator.java", "diffHunk": "@@ -32,23 +39,64 @@\n     @Inject\n     private SdxClientService sdxClientService;\n \n+    @Inject\n+    private StackViewService stackViewService;\n+\n+    @Inject\n+    private ClusterComponentConfigProvider clusterComponentConfigProvider;\n+\n     @Inject\n     private EntitlementService entitlementService;\n \n-    public void validate(StackV4Request stackRequest, Image image) {\n-        if (isDifferentDataHubAndDataLakeVersionAllowed()) {\n-            LOGGER.debug(\"The Data Hub version validation has been turned off with entitlement.\");\n-        } else if (StackType.WORKLOAD.equals(stackRequest.getType())) {\n-            LOGGER.debug(\"Validating Data Hub version.\");\n-            findStackVersion(stackRequest, image).ifPresent(stackRuntimeVersion -> {\n-                List<SdxClusterResponse> sdxClusters = sdxClientService.getByEnvironmentCrn(stackRequest.getEnvironmentCrn());\n-                sdxClusters.forEach(sdx -> validateStackVersion(stackRuntimeVersion, sdx.getRuntime()));\n-            });\n+    public void validate(StackV4Request stackRequest, Image image, StackType stackType) {\n+        if (StackType.WORKLOAD.equals(stackType)) {\n+            if (isDifferentDataHubAndDataLakeVersionAllowed()) {\n+                LOGGER.debug(\"The Data Hub version validation has been turned off with entitlement.\");\n+            } else {\n+                LOGGER.debug(\"Validating Data Hub version.\");\n+                findRequestedStackVersion(stackRequest, image).ifPresent(requestedRuntimeVersion -> {\n+                    checkRuntimeVersion(stackRequest.getEnvironmentCrn(), requestedRuntimeVersion);\n+                });\n+            }\n         }\n+    }\n+\n+    private void checkRuntimeVersion(String environmentCrn, String requestedStackVersion) {\n+        try {\n+            Optional<StackView> relatedDatalakeStack = stackViewService.findDatalakeViewByEnvironmentCrn(environmentCrn);\n+            if (relatedDatalakeStack.isPresent() && relatedDatalakeStack.get().isAvailable()) {\n+                List<ClouderaManagerProduct> clouderaManagerProductDetails =\n+                        clusterComponentConfigProvider.getClouderaManagerProductDetails(relatedDatalakeStack.get().getClusterView().getId());\n+                Optional<ClouderaManagerProduct> cdh = clouderaManagerProductDetails.stream()\n+                        .filter(clouderaManagerProduct -> StringUtils.equals(\"CDH\", clouderaManagerProduct.getName())).findFirst();\n+                if (cdh.isPresent() && cdh.get().getVersion() != null) {\n+                    compareRuntimeVersions(requestedStackVersion, StringUtils.substringBefore(cdh.get().getVersion(), \"-\"));\n+                } else {\n+                    throw new NotFoundException(String.format(\"Cannot found CDH details about related datalake stack in CB, name: %s\",\n+                            relatedDatalakeStack.get().getName()));\n+                }\n+            } else {\n+                throw new NotFoundException(String.format(\"Cannot found related dalatake stack in CB for environment CRN %s \" +\n+                        \"or the datalake isn't available yet.\", environmentCrn));\n+            }\n+        } catch (Exception e) {", "originalCommit": "43e734ba0c3e69934d6464179c4ce28ae7b8c753", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA5MTQ1Nw==", "url": "https://github.com/hortonworks/cloudbreak/pull/9409#discussion_r522091457", "bodyText": "as I can remember we had such a checkstyle entry to prevent one to catch Exception. certainly, there are cases where catching Exception is inevitable, but in this case probably not. correct me if I'm wrong \ud83d\ude42", "author": "gregito", "createdAt": "2020-11-12T13:06:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA5MDIxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA5NjQ0OA==", "url": "https://github.com/hortonworks/cloudbreak/pull/9409#discussion_r522096448", "bodyText": "ok, i can change the try block logic do not throw those exceptions, thats fine.\nregarding too wide catch, the original issue is not happening because of the code in the try block, its completely new logic to spare the unnecessary call in sdx service. i do not want different error handling here, only one thing: checking dl in cb, if any error, then fall back to existing logic (calling sdx service). i see no point for various complex error handling for a singe version validator", "author": "horadla23", "createdAt": "2020-11-12T13:15:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA5MDIxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjEwNDg0MQ==", "url": "https://github.com/hortonworks/cloudbreak/pull/9409#discussion_r522104841", "bodyText": "doesn't ensure that the original problem/exception won't happen again\n\nmost of the cases how can we ensure if:\n\ndatalake is not available, then it will next time\ndatalake is no present, then it will next time\nCDH version is not present, then it will next time\n\nI think there is no way to do it, these are user errors, we can handle these with one way: log it and fall back to sdx call\nor what would you do in these cases?\nwhat different error handling should be here also?\nin general speaking I agree with you, but I cannot see what more we can do here, please give me specific advises, if you have it regarding this case", "author": "horadla23", "createdAt": "2020-11-12T13:28:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA5MDIxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjEwNzc1MA==", "url": "https://github.com/hortonworks/cloudbreak/pull/9409#discussion_r522107750", "bodyText": "thanks!\nyeah, I'm thinking the same way. a single version validator shouldn't contain such complex error handling as that one. just the necessary but without sacrificing the foreseeing of the chances of malfunctions.", "author": "gregito", "createdAt": "2020-11-12T13:33:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA5MDIxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjEyMjk0NA==", "url": "https://github.com/hortonworks/cloudbreak/pull/9409#discussion_r522122944", "bodyText": "i would keep that exception catch, there is no checkstyle rule against it. here i do no trust logic of clusterComponentConfigProvider  enough to leave that catch :)", "author": "horadla23", "createdAt": "2020-11-12T13:56:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA5MDIxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjEyMzE0Mw==", "url": "https://github.com/hortonworks/cloudbreak/pull/9409#discussion_r522123143", "bodyText": "i also removed unnecessary throws", "author": "horadla23", "createdAt": "2020-11-12T13:56:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjA5MDIxMg=="}], "type": "inlineReview"}, {"oid": "c38082f73dcf71691c02c37d3bd5ed1e93b53489", "url": "https://github.com/hortonworks/cloudbreak/commit/c38082f73dcf71691c02c37d3bd5ed1e93b53489", "message": "CB-9657 DataLake runtime version is null\nin various scenarios runtime version of datalake can be null, this commit will prevent these scenarios\n- validation for existing available datalake should happen at the beginning of datahub creation, not in the middle of stack conversion, with this we can prevent errors during datalake runtime version check during datahub creation, because in case of custom SDX runtime in SDX service filled in only when datalake is available\n- dh runtime version validator should rely on data available in CB by default, and it can still fall back to SDX service\n- distrox related mock tests should create datalake before creating datahub", "committedDate": "2020-11-12T13:54:23Z", "type": "forcePushed"}, {"oid": "9828fc02cad4933cd2e98e4d01e987025fdd923e", "url": "https://github.com/hortonworks/cloudbreak/commit/9828fc02cad4933cd2e98e4d01e987025fdd923e", "message": "CB-9657 DataLake runtime version is null\nin various scenarios runtime version of datalake can be null, this commit will prevent these scenarios\n- validation for existing available datalake should happen at the beginning of datahub creation, not in the middle of stack conversion, with this we can prevent errors during datalake runtime version check during datahub creation, because in case of custom SDX runtime in SDX service filled in only when datalake is available\n- dh runtime version validator should rely on data available in CB by default, and it can still fall back to SDX service\n- distrox related mock tests should create datalake before creating datahub", "committedDate": "2020-11-12T15:37:23Z", "type": "forcePushed"}, {"oid": "d5f530825226e6736dbd4d8cce29a84b0e344b64", "url": "https://github.com/hortonworks/cloudbreak/commit/d5f530825226e6736dbd4d8cce29a84b0e344b64", "message": "CB-9657 DataLake runtime version is null\nin various scenarios runtime version of datalake can be null, this commit will prevent these scenarios\n- validation for existing available datalake should happen at the beginning of datahub creation, not in the middle of stack conversion, with this we can prevent errors during datalake runtime version check during datahub creation, because in case of custom SDX runtime in SDX service filled in only when datalake is available\n- dh runtime version validator should rely on data available in CB by default, and it can still fall back to SDX service\n- distrox related mock tests should create datalake before creating datahub", "committedDate": "2020-11-12T16:07:04Z", "type": "forcePushed"}, {"oid": "8e7b8260e4e5c338533db18f74e1e9a373792796", "url": "https://github.com/hortonworks/cloudbreak/commit/8e7b8260e4e5c338533db18f74e1e9a373792796", "message": "CB-9657 DataLake runtime version is null\nin various scenarios runtime version of datalake can be null, this commit will prevent these scenarios\n- validation for existing available datalake should happen at the beginning of datahub creation, not in the middle of stack conversion, with this we can prevent errors during datalake runtime version check during datahub creation, because in case of custom SDX runtime in SDX service filled in only when datalake is available\n- dh runtime version validator should rely on data available in CB by default, and it can still fall back to SDX service\n- distrox related mock tests should create datalake before creating datahub", "committedDate": "2020-11-12T17:30:19Z", "type": "forcePushed"}, {"oid": "21c34af3f4fd50e19e55ff74876827c11569443f", "url": "https://github.com/hortonworks/cloudbreak/commit/21c34af3f4fd50e19e55ff74876827c11569443f", "message": "CB-9657 DataLake runtime version is null\nin various scenarios runtime version of datalake can be null, this commit will prevent these scenarios\n- validation for existing available datalake should happen at the beginning of datahub creation, not in the middle of stack conversion, with this we can prevent errors during datalake runtime version check during datahub creation, because in case of custom SDX runtime in SDX service filled in only when datalake is available\n- dh runtime version validator should rely on data available in CB by default, and it can still fall back to SDX service\n- distrox related mock tests should create datalake before creating datahub", "committedDate": "2020-11-12T18:29:23Z", "type": "commit"}, {"oid": "21c34af3f4fd50e19e55ff74876827c11569443f", "url": "https://github.com/hortonworks/cloudbreak/commit/21c34af3f4fd50e19e55ff74876827c11569443f", "message": "CB-9657 DataLake runtime version is null\nin various scenarios runtime version of datalake can be null, this commit will prevent these scenarios\n- validation for existing available datalake should happen at the beginning of datahub creation, not in the middle of stack conversion, with this we can prevent errors during datalake runtime version check during datahub creation, because in case of custom SDX runtime in SDX service filled in only when datalake is available\n- dh runtime version validator should rely on data available in CB by default, and it can still fall back to SDX service\n- distrox related mock tests should create datalake before creating datahub", "committedDate": "2020-11-12T18:29:23Z", "type": "forcePushed"}]}