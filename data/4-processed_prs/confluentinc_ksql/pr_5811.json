{"pr_number": 5811, "pr_title": "test:  Adds another test case for pull queries for active restoring state", "pr_createdAt": "2020-07-10T17:11:15Z", "pr_url": "https://github.com/confluentinc/ksql/pull/5811", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk4NTM1Ng==", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r452985356", "bodyText": "This method checks that the clusterStatus response contains lag reporting? Not that there is actual lag, right?", "author": "vpapavas", "createdAt": "2020-07-10T17:46:09Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/HighAvailabilityTestUtil.java", "diffHunk": "@@ -264,5 +270,121 @@ public static void sendLagReportingRequest(\n           .get();\n     }\n   }\n+\n+  static String extractQueryId(final String outputString) {\n+    final java.util.regex.Matcher matcher = QUERY_ID_PATTERN.matcher(outputString);\n+    if (!matcher.find()) {\n+      throw new AssertionError(\"Could not find query id in: \" + outputString);\n+    }\n+    return matcher.group(1);\n+  }\n+\n+  // Ensures that lags exist for the cluster.  Makes the simplified assumption that there's just one\n+  // state store.\n+  static BiFunction<KsqlHostInfoEntity, Map<KsqlHostInfoEntity, HostStatusEntity>, Boolean>", "originalCommit": "67b17d59d38de14886f913fe9988b0733356d7cd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzAxMjM1Ng==", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453012356", "bodyText": "Correct.  The name and comments weren't great.  Changed to lagsReported. The latter version checks the actual values.", "author": "AlanConfluent", "createdAt": "2020-07-10T18:41:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk4NTM1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk4NjM0OQ==", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r452986349", "bodyText": "This method checks for a specific server if there is actual lag reported? I don't understand the if condition: currentOffset < 0  what does this mean?", "author": "vpapavas", "createdAt": "2020-07-10T17:48:13Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/HighAvailabilityTestUtil.java", "diffHunk": "@@ -264,5 +270,121 @@ public static void sendLagReportingRequest(\n           .get();\n     }\n   }\n+\n+  static String extractQueryId(final String outputString) {\n+    final java.util.regex.Matcher matcher = QUERY_ID_PATTERN.matcher(outputString);\n+    if (!matcher.find()) {\n+      throw new AssertionError(\"Could not find query id in: \" + outputString);\n+    }\n+    return matcher.group(1);\n+  }\n+\n+  // Ensures that lags exist for the cluster.  Makes the simplified assumption that there's just one\n+  // state store.\n+  static BiFunction<KsqlHostInfoEntity, Map<KsqlHostInfoEntity, HostStatusEntity>, Boolean>\n+  lagsExist(\n+      final int expectedClusterSize\n+  ) {\n+    return (remoteServer, clusterStatus) -> {\n+      if (clusterStatus.size() == expectedClusterSize) {\n+        int numWithLag = 0;\n+        for (Entry<KsqlHostInfoEntity, HostStatusEntity> e : clusterStatus.entrySet()) {\n+          if (e.getValue().getHostStoreLags().getStateStoreLags().size() > 0) {\n+            numWithLag++;\n+          }\n+        }\n+        if (numWithLag >= Math.min(expectedClusterSize, 2)) {\n+          LOG.info(\"Found expected lags: {}\", clusterStatus.toString());\n+          return true;\n+        }\n+      }\n+      LOG.info(\"Didn't yet find expected lags: {}\", clusterStatus.toString());\n+      return false;\n+    };\n+  }\n+\n+  // Ensures that lags exist for the given host.  Makes the simplified assumption that there's just\n+  // one state store.\n+  static BiFunction<KsqlHostInfoEntity, Map<KsqlHostInfoEntity, HostStatusEntity>, Boolean>\n+  lagsExist(\n+      final int clusterSize,\n+      final KsqlHostInfoEntity server,\n+      final long currentOffset,\n+      final long endOffset\n+  ) {\n+    return (remote, clusterStatus) -> {\n+      if (clusterStatus.size() == clusterSize) {\n+        HostStatusEntity hostStatusEntity = clusterStatus.get(server);\n+        if (hostStatusEntity == null) {\n+          LOG.info(\"Didn't find {}\", server.toString());\n+          return false;\n+        }\n+        Pair<Long, Long> pair = getOffsets(server,clusterStatus);\n+        long current = pair.left;\n+        long end = pair.right;\n+        if ((currentOffset < 0 || current >= currentOffset) && end >= endOffset) {", "originalCommit": "67b17d59d38de14886f913fe9988b0733356d7cd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzAwMjM2NA==", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453002364", "bodyText": "If offset currentOffset < 0, we don't check it.  It's just mean as a special value since some tests don't care about this.  I'll make this optional instead to make it more obvious.", "author": "AlanConfluent", "createdAt": "2020-07-10T18:22:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk4NjM0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk4NjcxOA==", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r452986718", "bodyText": "Why do we need the lagsExists check here?", "author": "vpapavas", "createdAt": "2020-07-10T17:48:58Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/PullQueryRoutingFunctionalTest.java", "diffHunk": "@@ -258,19 +249,13 @@ public void cleanUp() {\n     APP_SHUTOFFS_2.reset();\n   }\n \n-  @AfterClass\n-  public static void classTearDown() {\n-    TMP.delete();\n-  }\n-\n   @Test\n   public void shouldQueryActiveWhenActiveAliveQueryIssuedToStandby() throws Exception {\n     // Given:\n-    ClusterFormation clusterFormation = findClusterFormation(REST_APP_0, REST_APP_1, REST_APP_2);\n+    ClusterFormation clusterFormation = findClusterFormation(TEST_APP_0, TEST_APP_1, TEST_APP_2);\n     waitForClusterToBeDiscovered(clusterFormation.standBy.getApp(), 3);\n     waitForRemoteServerToChangeStatus(clusterFormation.router.getApp(),\n-        clusterFormation.router.getHost(),\n-        PullQueryRoutingFunctionalTest::lagsExist);\n+        clusterFormation.router.getHost(), HighAvailabilityTestUtil.lagsExist(3));", "originalCommit": "67b17d59d38de14886f913fe9988b0733356d7cd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzAwMTkwMg==", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453001902", "bodyText": "The intention is to ensure that all lags have been reported since we won't forward requests if we have no lag info by default.  If we sneak in a pull query before this happens, it will fail, so we just wait for all lags to be reported.", "author": "AlanConfluent", "createdAt": "2020-07-10T18:21:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk4NjcxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzAyNjI0OA==", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453026248", "bodyText": "This checks that the currentOffset is 3 and endOffset is 5, right?", "author": "vpapavas", "createdAt": "2020-07-10T19:00:24Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/PullQueryRoutingFunctionalTest.java", "diffHunk": "@@ -376,10 +358,11 @@ public void shouldFilterLaggyServers() throws Exception {\n \n     waitForRemoteServerToChangeStatus(clusterFormation.router.getApp(),\n         clusterFormation.router.getHost(),\n-        PullQueryRoutingFunctionalTest.lagsExist(clusterFormation.standBy.getHost(), 5));\n+        HighAvailabilityTestUtil.lagsReported(3, clusterFormation.standBy.getHost(),", "originalCommit": "34b1b9f322d27f108070f642924ea3b059880456", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzAyOTE3Mw==", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453029173", "bodyText": "This checks that there are three lag reports.  It was hardcoded before.  currentOffset is Optional.empty() in this case.  Maybe I should change this method to ignore the number of reports since HighAvailabilityTestUtil.lagsReported(3) does that above.", "author": "AlanConfluent", "createdAt": "2020-07-10T19:06:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzAyNjI0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzAzMDY2Ng==", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453030666", "bodyText": "I am confused by the title and description of the PR. You say you add a new test case for restoring the active after it restarts but that's not what's happening here: the active gets killed and we query the standby that has lag. Am I missing something?", "author": "vpapavas", "createdAt": "2020-07-10T19:10:28Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/PullQueryRoutingFunctionalTest.java", "diffHunk": "@@ -360,11 +343,10 @@ public void shouldQueryStandbyWhenActiveDeadStandbyAliveQueryIssuedToRouter() th\n   @Test", "originalCommit": "34b1b9f322d27f108070f642924ea3b059880456", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzAzMTk5OQ==", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453031999", "bodyText": "Yes.  There is no standby here.  There's just one server.  It gets up to date with its state store, it gets killed, has it's state store wiped out, and then restarts.  Then that same server is queried.", "author": "AlanConfluent", "createdAt": "2020-07-10T19:13:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzAzMDY2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzAzNTY1Mg==", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453035652", "bodyText": "Sorry, this file hasn't been changed materially.  The new file has a new test that does what I described.", "author": "AlanConfluent", "createdAt": "2020-07-10T19:21:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzAzMDY2Ng=="}], "type": "inlineReview"}, {"oid": "5fdf11eecf09d378a536df49c0ad4c82d4c1b515", "url": "https://github.com/confluentinc/ksql/commit/5fdf11eecf09d378a536df49c0ad4c82d4c1b515", "message": "test: Adds another test case for single active to pull query correctness tests", "committedDate": "2020-07-10T19:46:51Z", "type": "commit"}, {"oid": "e2c57b36a201f751fec0fc03891bcf5c52a1c6b2", "url": "https://github.com/confluentinc/ksql/commit/e2c57b36a201f751fec0fc03891bcf5c52a1c6b2", "message": "Working state", "committedDate": "2020-07-10T19:46:51Z", "type": "commit"}, {"oid": "092b78dea6c12e898ef93569a9d1daa29ad4a574", "url": "https://github.com/confluentinc/ksql/commit/092b78dea6c12e898ef93569a9d1daa29ad4a574", "message": "Splits test into another file", "committedDate": "2020-07-10T19:46:51Z", "type": "commit"}, {"oid": "413c9293e03d0a509ccf2b6927766800bbd32109", "url": "https://github.com/confluentinc/ksql/commit/413c9293e03d0a509ccf2b6927766800bbd32109", "message": "Feedback", "committedDate": "2020-07-10T19:46:51Z", "type": "commit"}, {"oid": "1af6cf792f4feb94d00330a3f3f4ae4eed4fb9a8", "url": "https://github.com/confluentinc/ksql/commit/1af6cf792f4feb94d00330a3f3f4ae4eed4fb9a8", "message": "Feedback", "committedDate": "2020-07-10T19:46:51Z", "type": "commit"}, {"oid": "1af6cf792f4feb94d00330a3f3f4ae4eed4fb9a8", "url": "https://github.com/confluentinc/ksql/commit/1af6cf792f4feb94d00330a3f3f4ae4eed4fb9a8", "message": "Feedback", "committedDate": "2020-07-10T19:46:51Z", "type": "forcePushed"}, {"oid": "746400f3e755d05770d849c3eea1a1019d7d7d0c", "url": "https://github.com/confluentinc/ksql/commit/746400f3e755d05770d849c3eea1a1019d7d7d0c", "message": "Adds annotation", "committedDate": "2020-07-10T21:03:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA4OTczMw==", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453089733", "bodyText": "Now the title makes sense :)", "author": "vpapavas", "createdAt": "2020-07-10T21:41:39Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/PullQuerySingleNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,346 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.getOffsets;\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForRemoteServerToChangeStatus;\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForStreamsMetadataToInitialize;\n+import static io.confluent.ksql.util.KsqlConfig.KSQL_STREAMS_PREFIX;\n+import static org.apache.kafka.streams.StreamsConfig.CONSUMER_PREFIX;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.not;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.name.ColumnName;\n+import io.confluent.ksql.rest.entity.ClusterStatusResponse;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.rest.integration.FaultyKafkaConsumer.FaultyKafkaConsumer0;\n+import io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.Shutoffs;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.rest.server.utils.TestUtils;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.serde.SerdeOption;\n+import io.confluent.ksql.test.util.KsqlIdentifierTestUtil;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.Pair;\n+import io.confluent.ksql.util.UserDataProvider;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@Category({IntegrationTest.class})\n+public class PullQuerySingleNodeFunctionalTest {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(PullQuerySingleNodeFunctionalTest.class);\n+\n+  private static final Pattern QUERY_ID_PATTERN = Pattern.compile(\"query with ID (\\\\S+)\");\n+  private static final String USER_TOPIC = \"user_topic_\";\n+  private static final String USERS_STREAM = \"users\";\n+  private static final UserDataProvider USER_PROVIDER = new UserDataProvider();\n+  private static final int HEADER = 1;\n+  private static final int BASE_TIME = 1_000_000;\n+  private final static String KEY = Iterables.get(USER_PROVIDER.data().keySet(), 0);\n+  private final static String KEY_3 = Iterables.get(USER_PROVIDER.data().keySet(), 3);\n+  private static final Map<String, ?> LAG_FILTER_3 =\n+      ImmutableMap.of(KsqlConfig.KSQL_QUERY_PULL_MAX_ALLOWED_OFFSET_LAG_CONFIG, \"3\");\n+\n+  private static final PhysicalSchema AGGREGATE_SCHEMA = PhysicalSchema.from(\n+      LogicalSchema.builder()\n+          .keyColumn(ColumnName.of(\"USERID\"), SqlTypes.STRING)\n+          .valueColumn(ColumnName.of(\"COUNT\"), SqlTypes.BIGINT)\n+          .build(),\n+      SerdeOption.none()\n+  );\n+\n+  private static final Map<String, Object> COMMON_CONFIG = ImmutableMap.<String, Object>builder()\n+      .put(KSQL_STREAMS_PREFIX + StreamsConfig.NUM_STREAM_THREADS_CONFIG, 1)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_SEND_INTERVAL_MS_CONFIG, 500)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_CHECK_INTERVAL_MS_CONFIG, 1000)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_DISCOVER_CLUSTER_MS_CONFIG, 2000)\n+      .put(KsqlRestConfig.KSQL_LAG_REPORTING_ENABLE_CONFIG, true)\n+      .put(KsqlRestConfig.KSQL_LAG_REPORTING_SEND_INTERVAL_MS_CONFIG, 3000)\n+      .put(KsqlConfig.KSQL_QUERY_PULL_ENABLE_STANDBY_READS, true)\n+      .put(KsqlConfig.KSQL_STREAMS_PREFIX + \"num.standby.replicas\", 1)\n+      .put(KsqlConfig.KSQL_SHUTDOWN_TIMEOUT_MS_CONFIG, 1000)\n+      .build();\n+\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+  private static final TemporaryFolder TMP = new TemporaryFolder();\n+  private static final int INT_PORT_0 = TestUtils.findFreeLocalPort();\n+  private static final KsqlHostInfoEntity host0 = new KsqlHostInfoEntity(\"localhost\", INT_PORT_0);\n+  private static final Shutoffs APP_SHUTOFFS_0 = new Shutoffs();\n+\n+  @Rule\n+  public final TestKsqlRestApp REST_APP_0 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KSQL_STREAMS_PREFIX + StreamsConfig.STATE_DIR_CONFIG, getNewStateDir(TMP))\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:0\")\n+      .withProperty(KsqlRestConfig.INTERNAL_LISTENER_CONFIG, \"http://localhost:\" + INT_PORT_0)\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:\" + INT_PORT_0)\n+      .withFaultyKsqlClient(APP_SHUTOFFS_0::getKsqlOutgoing)\n+      .withProperty(KSQL_STREAMS_PREFIX + CONSUMER_PREFIX\n+          + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, FaultyKafkaConsumer0.class.getName())\n+      .withProperty(KSQL_STREAMS_PREFIX + CONSUMER_PREFIX + \"max.poll.records\", 1)\n+      .withProperties(COMMON_CONFIG)\n+      .build();\n+\n+  private final AtomicLong timestampSupplier = new AtomicLong(BASE_TIME);\n+  private String output;\n+  private String queryId;\n+  private String sql;\n+  private String sqlKey3;\n+  private String topic;\n+\n+  @ClassRule\n+  public static final RuleChain CHAIN = RuleChain\n+      .outerRule(Retry.of(3, ZooKeeperClientException.class, 3, TimeUnit.SECONDS))\n+      .around(TEST_HARNESS).around(TMP);\n+\n+  @Rule\n+  public final Timeout timeout = Timeout.builder()\n+      .withTimeout(1, TimeUnit.MINUTES)\n+      .withLookingForStuckThread(true)\n+      .build();\n+\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    FaultyKafkaConsumer0.setPauseOffset(APP_SHUTOFFS_0::getKafkaPauseOffset);\n+  }\n+\n+  @After\n+  public void cleanUp() {\n+    REST_APP_0.closePersistentQueries();\n+    REST_APP_0.dropSourcesExcept();\n+    APP_SHUTOFFS_0.reset();\n+  }\n+\n+  @Before\n+  public void setUp() {\n+    //Create topic with 1 partition to control who is active and standby\n+    topic = USER_TOPIC + KsqlIdentifierTestUtil.uniqueIdentifierName();\n+    TEST_HARNESS.ensureTopics(1, topic);\n+\n+    TEST_HARNESS.produceRows(\n+        topic,\n+        USER_PROVIDER,\n+        FormatFactory.JSON,\n+        timestampSupplier::getAndIncrement\n+    );\n+\n+    //Create stream\n+    makeAdminRequest(\n+        REST_APP_0,\n+        \"CREATE STREAM \" + USERS_STREAM\n+            + \" (\" + USER_PROVIDER.ksqlSchemaString(false) + \")\"\n+            + \" WITH (\"\n+            + \"   kafka_topic='\" + topic + \"', \"\n+            + \"   value_format='JSON');\"\n+    );\n+    //Create table\n+    output = KsqlIdentifierTestUtil.uniqueIdentifierName();\n+    sql = \"SELECT * FROM \" + output + \" WHERE USERID = '\" + KEY + \"';\";\n+    List<KsqlEntity> res = makeAdminRequestWithResponse(\n+        REST_APP_0,\n+        \"CREATE TABLE \" + output + \" AS\"\n+            + \" SELECT \" + USER_PROVIDER.key() + \", COUNT(1) AS COUNT FROM \" + USERS_STREAM\n+            + \" GROUP BY \" + USER_PROVIDER.key() + \";\"\n+    );\n+    queryId = extractQueryId(res.get(0).toString());\n+    queryId = queryId.substring(0, queryId.length() - 1);\n+    waitForTableRows(TEST_HARNESS);\n+\n+    sqlKey3 = \"SELECT * FROM \" + output + \" WHERE USERID = '\" + KEY_3\n+        + \"';\";\n+    waitForStreamsMetadataToInitialize(\n+        REST_APP_0, ImmutableList.of(host0), queryId);\n+  }\n+\n+  @Test", "originalCommit": "746400f3e755d05770d849c3eea1a1019d7d7d0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA4OTk3OQ==", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453089979", "bodyText": "These are common methods with the PullQueryRoutingFunctionalTest. Maybe move them to the HATestUtil class so that they are in one place?", "author": "vpapavas", "createdAt": "2020-07-10T21:42:29Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/PullQuerySingleNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,346 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.getOffsets;\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForRemoteServerToChangeStatus;\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForStreamsMetadataToInitialize;\n+import static io.confluent.ksql.util.KsqlConfig.KSQL_STREAMS_PREFIX;\n+import static org.apache.kafka.streams.StreamsConfig.CONSUMER_PREFIX;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.not;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.name.ColumnName;\n+import io.confluent.ksql.rest.entity.ClusterStatusResponse;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.rest.integration.FaultyKafkaConsumer.FaultyKafkaConsumer0;\n+import io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.Shutoffs;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.rest.server.utils.TestUtils;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.serde.SerdeOption;\n+import io.confluent.ksql.test.util.KsqlIdentifierTestUtil;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.Pair;\n+import io.confluent.ksql.util.UserDataProvider;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@Category({IntegrationTest.class})\n+public class PullQuerySingleNodeFunctionalTest {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(PullQuerySingleNodeFunctionalTest.class);\n+\n+  private static final Pattern QUERY_ID_PATTERN = Pattern.compile(\"query with ID (\\\\S+)\");\n+  private static final String USER_TOPIC = \"user_topic_\";\n+  private static final String USERS_STREAM = \"users\";\n+  private static final UserDataProvider USER_PROVIDER = new UserDataProvider();\n+  private static final int HEADER = 1;\n+  private static final int BASE_TIME = 1_000_000;\n+  private final static String KEY = Iterables.get(USER_PROVIDER.data().keySet(), 0);\n+  private final static String KEY_3 = Iterables.get(USER_PROVIDER.data().keySet(), 3);\n+  private static final Map<String, ?> LAG_FILTER_3 =\n+      ImmutableMap.of(KsqlConfig.KSQL_QUERY_PULL_MAX_ALLOWED_OFFSET_LAG_CONFIG, \"3\");\n+\n+  private static final PhysicalSchema AGGREGATE_SCHEMA = PhysicalSchema.from(\n+      LogicalSchema.builder()\n+          .keyColumn(ColumnName.of(\"USERID\"), SqlTypes.STRING)\n+          .valueColumn(ColumnName.of(\"COUNT\"), SqlTypes.BIGINT)\n+          .build(),\n+      SerdeOption.none()\n+  );\n+\n+  private static final Map<String, Object> COMMON_CONFIG = ImmutableMap.<String, Object>builder()\n+      .put(KSQL_STREAMS_PREFIX + StreamsConfig.NUM_STREAM_THREADS_CONFIG, 1)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_SEND_INTERVAL_MS_CONFIG, 500)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_CHECK_INTERVAL_MS_CONFIG, 1000)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_DISCOVER_CLUSTER_MS_CONFIG, 2000)\n+      .put(KsqlRestConfig.KSQL_LAG_REPORTING_ENABLE_CONFIG, true)\n+      .put(KsqlRestConfig.KSQL_LAG_REPORTING_SEND_INTERVAL_MS_CONFIG, 3000)\n+      .put(KsqlConfig.KSQL_QUERY_PULL_ENABLE_STANDBY_READS, true)\n+      .put(KsqlConfig.KSQL_STREAMS_PREFIX + \"num.standby.replicas\", 1)\n+      .put(KsqlConfig.KSQL_SHUTDOWN_TIMEOUT_MS_CONFIG, 1000)\n+      .build();\n+\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+  private static final TemporaryFolder TMP = new TemporaryFolder();\n+  private static final int INT_PORT_0 = TestUtils.findFreeLocalPort();\n+  private static final KsqlHostInfoEntity host0 = new KsqlHostInfoEntity(\"localhost\", INT_PORT_0);\n+  private static final Shutoffs APP_SHUTOFFS_0 = new Shutoffs();\n+\n+  @Rule\n+  public final TestKsqlRestApp REST_APP_0 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KSQL_STREAMS_PREFIX + StreamsConfig.STATE_DIR_CONFIG, getNewStateDir(TMP))\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:0\")\n+      .withProperty(KsqlRestConfig.INTERNAL_LISTENER_CONFIG, \"http://localhost:\" + INT_PORT_0)\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:\" + INT_PORT_0)\n+      .withFaultyKsqlClient(APP_SHUTOFFS_0::getKsqlOutgoing)\n+      .withProperty(KSQL_STREAMS_PREFIX + CONSUMER_PREFIX\n+          + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, FaultyKafkaConsumer0.class.getName())\n+      .withProperty(KSQL_STREAMS_PREFIX + CONSUMER_PREFIX + \"max.poll.records\", 1)\n+      .withProperties(COMMON_CONFIG)\n+      .build();\n+\n+  private final AtomicLong timestampSupplier = new AtomicLong(BASE_TIME);\n+  private String output;\n+  private String queryId;\n+  private String sql;\n+  private String sqlKey3;\n+  private String topic;\n+\n+  @ClassRule\n+  public static final RuleChain CHAIN = RuleChain\n+      .outerRule(Retry.of(3, ZooKeeperClientException.class, 3, TimeUnit.SECONDS))\n+      .around(TEST_HARNESS).around(TMP);\n+\n+  @Rule\n+  public final Timeout timeout = Timeout.builder()\n+      .withTimeout(1, TimeUnit.MINUTES)\n+      .withLookingForStuckThread(true)\n+      .build();\n+\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    FaultyKafkaConsumer0.setPauseOffset(APP_SHUTOFFS_0::getKafkaPauseOffset);\n+  }\n+\n+  @After\n+  public void cleanUp() {\n+    REST_APP_0.closePersistentQueries();\n+    REST_APP_0.dropSourcesExcept();\n+    APP_SHUTOFFS_0.reset();\n+  }\n+\n+  @Before\n+  public void setUp() {\n+    //Create topic with 1 partition to control who is active and standby\n+    topic = USER_TOPIC + KsqlIdentifierTestUtil.uniqueIdentifierName();\n+    TEST_HARNESS.ensureTopics(1, topic);\n+\n+    TEST_HARNESS.produceRows(\n+        topic,\n+        USER_PROVIDER,\n+        FormatFactory.JSON,\n+        timestampSupplier::getAndIncrement\n+    );\n+\n+    //Create stream\n+    makeAdminRequest(\n+        REST_APP_0,\n+        \"CREATE STREAM \" + USERS_STREAM\n+            + \" (\" + USER_PROVIDER.ksqlSchemaString(false) + \")\"\n+            + \" WITH (\"\n+            + \"   kafka_topic='\" + topic + \"', \"\n+            + \"   value_format='JSON');\"\n+    );\n+    //Create table\n+    output = KsqlIdentifierTestUtil.uniqueIdentifierName();\n+    sql = \"SELECT * FROM \" + output + \" WHERE USERID = '\" + KEY + \"';\";\n+    List<KsqlEntity> res = makeAdminRequestWithResponse(\n+        REST_APP_0,\n+        \"CREATE TABLE \" + output + \" AS\"\n+            + \" SELECT \" + USER_PROVIDER.key() + \", COUNT(1) AS COUNT FROM \" + USERS_STREAM\n+            + \" GROUP BY \" + USER_PROVIDER.key() + \";\"\n+    );\n+    queryId = extractQueryId(res.get(0).toString());\n+    queryId = queryId.substring(0, queryId.length() - 1);\n+    waitForTableRows(TEST_HARNESS);\n+\n+    sqlKey3 = \"SELECT * FROM \" + output + \" WHERE USERID = '\" + KEY_3\n+        + \"';\";\n+    waitForStreamsMetadataToInitialize(\n+        REST_APP_0, ImmutableList.of(host0), queryId);\n+  }\n+\n+  @Test\n+  public void restoreAfterClearState() throws Exception {\n+    waitForStreamsMetadataToInitialize(REST_APP_0, ImmutableList.of(host0), queryId);\n+    waitForRemoteServerToChangeStatus(REST_APP_0, host0, HighAvailabilityTestUtil\n+        .lagsReported(host0, Optional.empty(), 5));\n+\n+    // When:\n+    final List<StreamedRow> rows_0 = makePullQueryRequest(\n+        REST_APP_0, sql, LAG_FILTER_3);\n+\n+    // Then:\n+    assertThat(rows_0, hasSize(HEADER + 1));\n+    KsqlHostInfoEntity host = rows_0.get(1).getSourceHost().get();\n+    assertThat(host.getHost(), is(host0.getHost()));\n+    assertThat(host.getPort(), is(host0.getPort()));\n+    assertThat(rows_0.get(1).getRow(), is(not(Optional.empty())));\n+    assertThat(rows_0.get(1).getRow().get().values(), is(ImmutableList.of(KEY, 1)));\n+\n+    // Stop the server and blow away the state\n+    LOG.info(\"Shutting down the server \" + host0.toString());\n+    REST_APP_0.stop();\n+    String stateDir = (String)REST_APP_0.getBaseConfig()\n+        .get(KSQL_STREAMS_PREFIX + StreamsConfig.STATE_DIR_CONFIG);\n+    clearDir(stateDir);\n+\n+    // Pause incoming kafka consumption\n+    APP_SHUTOFFS_0.setKafkaPauseOffset(2);\n+\n+    LOG.info(\"Restarting the server \" + host0.toString());\n+    REST_APP_0.start();\n+\n+    waitForStreamsMetadataToInitialize(REST_APP_0, ImmutableList.of(host0), queryId);\n+    waitForRemoteServerToChangeStatus(REST_APP_0, host0, HighAvailabilityTestUtil\n+        .lagsReported(host0, Optional.of(2L), 5));\n+\n+    ClusterStatusResponse clusterStatusResponse = HighAvailabilityTestUtil\n+        .sendClusterStatusRequest(REST_APP_0);\n+    Pair<Long, Long> pair = getOffsets(host0, clusterStatusResponse.getClusterStatus());\n+    assertThat(pair.left, is(2L));\n+    assertThat(pair.right, is(5L));\n+\n+    final List<StreamedRow> sameRows = makePullQueryRequest(\n+        REST_APP_0, sql, LAG_FILTER_3);\n+\n+    host = sameRows.get(1).getSourceHost().get();\n+    assertThat(host.getHost(), is(host0.getHost()));\n+    assertThat(host.getPort(), is(host0.getPort()));\n+    assertThat(sameRows.get(1).getRow(), is(not(Optional.empty())));\n+    // Still haven't gotten the update yet\n+    assertThat(sameRows.get(1).getRow().get().values(), is(ImmutableList.of(KEY, 1)));\n+\n+    // Row not found!\n+    final List<StreamedRow> headerOnly = makePullQueryRequest(\n+        REST_APP_0, sqlKey3, LAG_FILTER_3);\n+    assertThat(headerOnly.size(), is(1));\n+\n+    // Unpause incoming kafka consumption. We then expect active to catch back up.\n+    APP_SHUTOFFS_0.setKafkaPauseOffset(-1);\n+\n+    waitForRemoteServerToChangeStatus(REST_APP_0, host0, HighAvailabilityTestUtil\n+        .lagsReported(host0, Optional.of(5L), 5));\n+\n+    clusterStatusResponse = HighAvailabilityTestUtil\n+        .sendClusterStatusRequest(REST_APP_0);\n+    pair = getOffsets(host0, clusterStatusResponse.getClusterStatus());\n+    assertThat(pair.left, is(5L));\n+    assertThat(pair.right, is(5L));\n+\n+    final List<StreamedRow> updatedRows = makePullQueryRequest(\n+        REST_APP_0, sqlKey3, LAG_FILTER_3);\n+\n+    // Now it is found!\n+    host = updatedRows.get(1).getSourceHost().get();\n+    assertThat(host.getHost(), is(host0.getHost()));\n+    assertThat(host.getPort(), is(host0.getPort()));\n+    assertThat(updatedRows.get(1).getRow(), is(not(Optional.empty())));\n+    assertThat(updatedRows.get(1).getRow().get().values(), is(ImmutableList.of(KEY_3, 1)));\n+  }\n+\n+  private static String extractQueryId(final String outputString) {\n+    final java.util.regex.Matcher matcher = QUERY_ID_PATTERN.matcher(outputString);\n+    assertThat(\"Could not find query id in: \" + outputString, matcher.find());\n+    return matcher.group(1);\n+  }\n+\n+  private static void makeAdminRequest(TestKsqlRestApp restApp, final String sql) {\n+    RestIntegrationTestUtil.makeKsqlRequest(restApp, sql, Optional.empty());\n+  }\n+\n+  private static List<KsqlEntity> makeAdminRequestWithResponse(", "originalCommit": "746400f3e755d05770d849c3eea1a1019d7d7d0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEyODY3Mg==", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453128672", "bodyText": "Sure, sounds good.", "author": "AlanConfluent", "createdAt": "2020-07-11T00:14:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA4OTk3OQ=="}], "type": "inlineReview"}, {"oid": "aa22d115045f641459a371059219899f4c7be346", "url": "https://github.com/confluentinc/ksql/commit/aa22d115045f641459a371059219899f4c7be346", "message": "Fixes warning", "committedDate": "2020-07-10T21:42:49Z", "type": "commit"}, {"oid": "e25df51f64d3558b9f02ca0e7e9c54eae2ea463d", "url": "https://github.com/confluentinc/ksql/commit/e25df51f64d3558b9f02ca0e7e9c54eae2ea463d", "message": "More feedback", "committedDate": "2020-07-11T00:27:03Z", "type": "commit"}]}