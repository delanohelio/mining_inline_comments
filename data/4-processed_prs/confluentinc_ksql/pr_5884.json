{"pr_number": 5884, "pr_title": "feat: add suppress functionality", "pr_createdAt": "2020-07-27T20:03:09Z", "pr_url": "https://github.com/confluentinc/ksql/pull/5884", "timeline": [{"oid": "782694fe30551bee70042b26e37b58253eea54a4", "url": "https://github.com/confluentinc/ksql/commit/782694fe30551bee70042b26e37b58253eea54a4", "message": "add more qtt suppress tests\n\nchore: cherry-pick bd8c7fadf", "committedDate": "2020-07-27T19:13:26Z", "type": "commit"}, {"oid": "68f03ddd443ab07bc53c415ed5430b92f18957ed", "url": "https://github.com/confluentinc/ksql/commit/68f03ddd443ab07bc53c415ed5430b92f18957ed", "message": "fix: add name for suppression\n\nchore: cherry-pick 37c", "committedDate": "2020-07-27T19:26:45Z", "type": "commit"}, {"oid": "d4b31536e51de00a795b77d5818fd9cca595ecf1", "url": "https://github.com/confluentinc/ksql/commit/d4b31536e51de00a795b77d5818fd9cca595ecf1", "message": "feat: implement suppress on ktable\n\nchore: cherrypick 30cc", "committedDate": "2020-07-27T19:34:16Z", "type": "commit"}, {"oid": "08c01e86a4500d6c0668032770c615b99f15aefa", "url": "https://github.com/confluentinc/ksql/commit/08c01e86a4500d6c0668032770c615b99f15aefa", "message": "test: add default grace period tests\n\nchore: cherrypick cfd", "committedDate": "2020-07-27T19:46:15Z", "type": "commit"}, {"oid": "3f12926b76184c46127063d0a6906b0c6ef5a529", "url": "https://github.com/confluentinc/ksql/commit/3f12926b76184c46127063d0a6906b0c6ef5a529", "message": "chore: remove unused imports", "committedDate": "2020-07-27T19:56:57Z", "type": "commit"}, {"oid": "934e79aba168460590f384ae21332f8b6529730f", "url": "https://github.com/confluentinc/ksql/commit/934e79aba168460590f384ae21332f8b6529730f", "message": "fix: regenerate correct schema", "committedDate": "2020-07-27T21:07:44Z", "type": "commit"}, {"oid": "eb818b50cea0c436f927f91d83448562f1b8fc00", "url": "https://github.com/confluentinc/ksql/commit/eb818b50cea0c436f927f91d83448562f1b8fc00", "message": "chore: generate historical qtt plans", "committedDate": "2020-07-27T22:26:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIxODY3MQ==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461218671", "bodyText": "I think this could benefit from a comment explaining why we're adding the transformValues here", "author": "agavra", "createdAt": "2020-07-27T23:01:39Z", "path": "ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/TableSuppressBuilder.java", "diffHunk": "@@ -15,17 +15,98 @@\n \n package io.confluent.ksql.execution.streams;\n \n+import com.google.common.annotations.VisibleForTesting;\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.execution.builder.KsqlQueryBuilder;\n+import io.confluent.ksql.execution.context.QueryContext;\n import io.confluent.ksql.execution.plan.KTableHolder;\n-import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.execution.plan.KeySerdeFactory;\n+import io.confluent.ksql.execution.plan.TableSuppress;\n+import io.confluent.ksql.execution.streams.transform.KsTransformer;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.serde.SerdeOption;\n+import java.util.Set;\n+import java.util.function.BiFunction;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Suppressed;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+\n \n public final class TableSuppressBuilder {\n \n-  private TableSuppressBuilder() {\n+  private static final String SUPPRESS_OP_NAME = \"Suppress\";\n+\n+  public TableSuppressBuilder() {\n   }\n \n-  public static <K> KTableHolder<K> build(\n-      final KTableHolder<K> table\n+  public <K> KTableHolder<K> build(\n+      final KTableHolder<K> table,\n+      final TableSuppress<K> step,\n+      final KsqlQueryBuilder queryBuilder,\n+      final KeySerdeFactory keySerdeFactory,\n+      final MaterializedFactory materializedFactory\n   ) {\n-    throw new KsqlException(\"EMIT FINAL is not yet supported\");\n+    return build(\n+        table,\n+        step,\n+        queryBuilder,\n+        keySerdeFactory,\n+        materializedFactory,\n+        PhysicalSchema::from\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  @SuppressWarnings(\"unchecked\")\n+  <K> KTableHolder<K> build(\n+      final KTableHolder<K> table,\n+      final TableSuppress<K> step,\n+      final KsqlQueryBuilder queryBuilder,\n+      final KeySerdeFactory keySerdeFactory,\n+      final MaterializedFactory materializedFactory,\n+      final BiFunction<LogicalSchema, Set<SerdeOption>, PhysicalSchema> physicalSchemaFactory\n+  ) {\n+    final PhysicalSchema physicalSchema = physicalSchemaFactory.apply(\n+        table.getSchema(),\n+        step.getInternalFormats().getOptions()\n+    );\n+    final QueryContext queryContext = QueryContext.Stacker.of(\n+        step.getProperties().getQueryContext())\n+        .push(SUPPRESS_OP_NAME).getQueryContext();\n+    final Serde<GenericRow> valueSerde = queryBuilder.buildValueSerde(\n+        step.getInternalFormats().getValueFormat(),\n+        physicalSchema,\n+        queryContext\n+    );\n+    final Serde<K> keySerde = keySerdeFactory.buildKeySerde(\n+        step.getInternalFormats().getKeyFormat(),\n+        physicalSchema,\n+        queryContext\n+    );\n+    final Materialized<K, GenericRow, KeyValueStore<Bytes, byte[]>> materialized =\n+        materializedFactory.create(\n+            keySerde,\n+            valueSerde,\n+            SUPPRESS_OP_NAME\n+        );\n+\n+    final KTable<K, GenericRow> suppressed = table.getTable().transformValues(", "originalCommit": "934e79aba168460590f384ae21332f8b6529730f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIxOTIyMw==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461219223", "bodyText": "is this used anywhere?", "author": "agavra", "createdAt": "2020-07-27T23:03:10Z", "path": "ksqldb-execution/src/main/java/io/confluent/ksql/execution/plan/TableSuppress.java", "diffHunk": "@@ -57,6 +63,14 @@ public RefinementInfo getRefinementInfo() {\n     return refinementInfo;\n   }\n \n+  public Formats getInternalFormats() {\n+    return internalFormats;\n+  }\n+\n+  public KsqlWindowExpression getWindowExpression() {\n+    return windowExpression;\n+  }", "originalCommit": "934e79aba168460590f384ae21332f8b6529730f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTI0MTMzNg==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461241336", "bodyText": "I don't see it being called anywhere explicitly but when I remove it, I fail all my suppress qtts with the same error,\njava.lang.RuntimeException: com.fasterxml.jackson.databind.exc.MismatchedInputException: Missing required creator property 'windowExpression' (index 4)", "author": "nae701", "createdAt": "2020-07-28T00:10:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIxOTIyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTI0MjE1MA==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461242150", "bodyText": "you need to also remove it from the constructor and the @JsonProperty annotation", "author": "agavra", "createdAt": "2020-07-28T00:13:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIxOTIyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyMDI4Nw==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461220287", "bodyText": "just wondering, where did you pick this up? it's really cool - I think it's better than our standard @RunWith(MockitoJUnitRunner.class)", "author": "agavra", "createdAt": "2020-07-27T23:06:08Z", "path": "ksqldb-streams/src/test/java/io/confluent/ksql/execution/streams/TableSuppressBuilderTest.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.execution.streams;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.execution.builder.KsqlQueryBuilder;\n+import io.confluent.ksql.execution.context.QueryContext;\n+import io.confluent.ksql.execution.plan.ExecutionStep;\n+import io.confluent.ksql.execution.plan.ExecutionStepPropertiesV1;\n+import io.confluent.ksql.execution.plan.Formats;\n+import io.confluent.ksql.execution.plan.KTableHolder;\n+import io.confluent.ksql.execution.plan.KeySerdeFactory;\n+import io.confluent.ksql.execution.plan.TableSuppress;\n+import io.confluent.ksql.execution.windows.KsqlWindowExpression;\n+import io.confluent.ksql.function.FunctionRegistry;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.serde.RefinementInfo;\n+import io.confluent.ksql.serde.SerdeOption;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.Set;\n+import java.util.function.BiFunction;\n+\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.connect.data.Struct;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+public class TableSuppressBuilderTest {\n+\n+  @Mock\n+  private KsqlQueryBuilder queryBuilder;\n+  @Mock\n+  private ExecutionStep<KTableHolder<Struct>> sourceStep;\n+  @Mock\n+  private KTable<Struct, GenericRow> sourceKTable;\n+  @Mock\n+  private KTable<Struct, GenericRow> preKTable;\n+  @Mock\n+  private KTable<Struct, GenericRow> suppressedKTable;\n+  @Mock\n+  private RefinementInfo refinementInfo;\n+  @Mock\n+  private Formats internalFormats;\n+  @Mock\n+  private KsqlWindowExpression windowExpression;\n+  @Mock\n+  private KeySerdeFactory<Struct> keySerdeFactory;\n+  @Mock\n+  private MaterializedFactory materializedFactory;\n+  @Mock\n+  private  PhysicalSchema physicalSchema;\n+  @Mock\n+  private  Serde<GenericRow> valueSerde;\n+  @Mock\n+  private  Serde<Struct> keySerde;\n+  @Mock\n+  private  Materialized<Object, GenericRow, StateStore> materialized;\n+  @Mock\n+  private KTableHolder<Struct> tableHolder;\n+  @Mock\n+  private KTableHolder<Struct> suppressedtable;\n+\n+  private final QueryContext queryContext = new QueryContext.Stacker()\n+      .push(\"bar\")\n+      .getQueryContext();\n+  private TableSuppress<Struct> tableSuppress;\n+  private BiFunction<LogicalSchema, Set<SerdeOption>, PhysicalSchema> physicalSchemaFactory;\n+  private TableSuppressBuilder builder;\n+\n+  @Rule\n+  public final MockitoRule mockitoRule = MockitoJUnit.rule();", "originalCommit": "934e79aba168460590f384ae21332f8b6529730f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIzNTk0OA==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461235948", "bodyText": "This is what TableGroupByBuilderTest uses so I just followed that, why do you think it is better than our standard @RunWith(MockitoJUnitRunner.class)?", "author": "nae701", "createdAt": "2020-07-27T23:54:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyMDI4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIzODQzMg==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461238432", "bodyText": "With @RunWith you can only have one runner, which means if you want to run it with another runner (Enclosed.class or Parameterized.class for example) you can't use mocks with the @Mock annotation. That, and it doesn't use reflection to find the class which is just always been a pet peeve of mine.", "author": "agavra", "createdAt": "2020-07-28T00:02:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyMDI4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNDI1OA==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461224258", "bodyText": "it might be valuable to ensure that we're calling suppress with a FinalResultsSuppressionBuilder passed in. You can see usages of @Captor to see examples of how to use mockito to intercept the arguments being passed in and very that they're of the type you expect.\nThis is in contrast to other supressed instances we might be passing in in the future if we support things other than window close.", "author": "agavra", "createdAt": "2020-07-27T23:18:15Z", "path": "ksqldb-streams/src/test/java/io/confluent/ksql/execution/streams/TableSuppressBuilderTest.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.execution.streams;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.execution.builder.KsqlQueryBuilder;\n+import io.confluent.ksql.execution.context.QueryContext;\n+import io.confluent.ksql.execution.plan.ExecutionStep;\n+import io.confluent.ksql.execution.plan.ExecutionStepPropertiesV1;\n+import io.confluent.ksql.execution.plan.Formats;\n+import io.confluent.ksql.execution.plan.KTableHolder;\n+import io.confluent.ksql.execution.plan.KeySerdeFactory;\n+import io.confluent.ksql.execution.plan.TableSuppress;\n+import io.confluent.ksql.execution.windows.KsqlWindowExpression;\n+import io.confluent.ksql.function.FunctionRegistry;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.serde.RefinementInfo;\n+import io.confluent.ksql.serde.SerdeOption;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.Set;\n+import java.util.function.BiFunction;\n+\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.connect.data.Struct;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+public class TableSuppressBuilderTest {\n+\n+  @Mock\n+  private KsqlQueryBuilder queryBuilder;\n+  @Mock\n+  private ExecutionStep<KTableHolder<Struct>> sourceStep;\n+  @Mock\n+  private KTable<Struct, GenericRow> sourceKTable;\n+  @Mock\n+  private KTable<Struct, GenericRow> preKTable;\n+  @Mock\n+  private KTable<Struct, GenericRow> suppressedKTable;\n+  @Mock\n+  private RefinementInfo refinementInfo;\n+  @Mock\n+  private Formats internalFormats;\n+  @Mock\n+  private KsqlWindowExpression windowExpression;\n+  @Mock\n+  private KeySerdeFactory<Struct> keySerdeFactory;\n+  @Mock\n+  private MaterializedFactory materializedFactory;\n+  @Mock\n+  private  PhysicalSchema physicalSchema;\n+  @Mock\n+  private  Serde<GenericRow> valueSerde;\n+  @Mock\n+  private  Serde<Struct> keySerde;\n+  @Mock\n+  private  Materialized<Object, GenericRow, StateStore> materialized;\n+  @Mock\n+  private KTableHolder<Struct> tableHolder;\n+  @Mock\n+  private KTableHolder<Struct> suppressedtable;\n+\n+  private final QueryContext queryContext = new QueryContext.Stacker()\n+      .push(\"bar\")\n+      .getQueryContext();\n+  private TableSuppress<Struct> tableSuppress;\n+  private BiFunction<LogicalSchema, Set<SerdeOption>, PhysicalSchema> physicalSchemaFactory;\n+  private TableSuppressBuilder builder;\n+\n+  @Rule\n+  public final MockitoRule mockitoRule = MockitoJUnit.rule();\n+\n+  @Before\n+  @SuppressWarnings(\"unchecked\")\n+  public void init() {\n+    final ExecutionStepPropertiesV1 properties = new ExecutionStepPropertiesV1(queryContext);\n+\n+    physicalSchemaFactory = (a,b) -> physicalSchema;\n+    when(queryBuilder.buildValueSerde(any(), any(), any())).thenReturn(valueSerde);\n+    when(keySerdeFactory.buildKeySerde(any(), any(), any())).thenReturn(keySerde);\n+    when(materializedFactory.create(any(), any(), any())).thenReturn(materialized);\n+\n+    when(tableHolder.getTable()).thenReturn(sourceKTable);\n+    when(sourceKTable.transformValues(any(), any(Materialized.class))).thenReturn(preKTable);\n+    when(preKTable.suppress(any())).thenReturn(suppressedKTable);\n+    when(tableHolder.withTable(any(),any())).thenReturn(suppressedtable);\n+\n+    tableSuppress = new TableSuppress<>(properties, sourceStep, refinementInfo, internalFormats, windowExpression);\n+    builder = new TableSuppressBuilder();\n+  }\n+\n+  @Test\n+  @SuppressWarnings(\"unchecked\")\n+  public void shouldSuppressSourceTable() {\n+    // When:\n+    final KTableHolder<Struct> result = builder.build(tableHolder, tableSuppress, queryBuilder, keySerdeFactory, materializedFactory, physicalSchemaFactory);\n+\n+    // Then:\n+    assertThat(result, is(suppressedtable));\n+    verify(sourceKTable).transformValues(any(),any(Materialized.class));\n+    verify(preKTable).suppress(any());", "originalCommit": "934e79aba168460590f384ae21332f8b6529730f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNTUzMg==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461225532", "bodyText": "noting here in case the test doesn't come up later - what happens if we suppress with a tombstone? (e.g. the value coming in is entirely null, not a null column within the value)", "author": "agavra", "createdAt": "2020-07-27T23:21:55Z", "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +92,222 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",", "originalCommit": "934e79aba168460590f384ae21332f8b6529730f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc4NDYzNw==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461784637", "bodyText": "The FinalResultsSuppressionBuilder defaults to dropping tombstones, I will add a test to double check this", "author": "nae701", "createdAt": "2020-07-28T18:25:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNTUzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTc5OTc5Mg==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461799792", "bodyText": "@vvcephei Almog said that tombstones happen only on source tables, and since we are only suppressing on windowed streams, we don't have to worry about handling tombstones? What do you think", "author": "nae701", "createdAt": "2020-07-28T18:52:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNTUzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4MTQyNg==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461881426", "bodyText": "Hey @nae701 and @agavra , a \"tombstone\" in this case means that the result of the windowed aggregation is null, not that the input record's value is null. I'm not sure if any of the available aggregations in KSQL can do this. If so, you can test it; if not, you don't have to worry about it.\nFor example (taken from the docs):\nSELECT orderzip_code, TOPK(order_total, 5) FROM orders\n  WINDOW TUMBLING (SIZE 1 HOUR) GROUP BY order_zipcode\n  EMIT CHANGES;\n\nIn this case, the suppression would get a tombstone iff TOPK(order_total, 5) returns null (which I don't think it does, nor does COUNT, etc...).\nCan you plug in a UDF for the aggregation function? If so, you can make it return nulls as desired and test the tombstone case.", "author": "vvcephei", "createdAt": "2020-07-28T21:10:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNTUzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4MjI3Mw==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461882273", "bodyText": "I thought about this some more, I don't think it's possible for ksql to produce a tombstone in this case. Even if TOPK would return null, we still don't get a tombstone - we just get a null value for the column (probably KSQL_COL_2 or whatever the generated name would be in this case", "author": "agavra", "createdAt": "2020-07-28T21:11:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNTUzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM2NjQzNA==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r462366434", "bodyText": "Oh, I see, you mean we should see an output like this?\n{\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": null},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1}\n\nIf that is defined behavior we should probably have a test for it.", "author": "vvcephei", "createdAt": "2020-07-29T14:58:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNTUzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNjQ2Mg==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461226462", "bodyText": "how do we get a count of 2 here? I might be missing something, but I only see one value that should match (or is null timestamp treated as 0?):\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},", "author": "agavra", "createdAt": "2020-07-27T23:24:29Z", "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +92,222 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": null},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},", "originalCommit": "934e79aba168460590f384ae21332f8b6529730f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTI0Mjk3MA==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461242970", "bodyText": "Yeah the null timestamp is treated as 0 for some reason", "author": "nae701", "createdAt": "2020-07-28T00:16:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNjQ2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTY5Nzk2OQ==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461697969", "bodyText": "cc @vvcephei - can you confirm? though I suppose in reality you'd never have a 0 timestamp so this window would always be past the grace period and it's only a testing \"bug\"", "author": "agavra", "createdAt": "2020-07-28T16:04:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNjQ2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4MjcwOA==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461882708", "bodyText": "You probably need to just take a look at the behavior of the thing that reads these test specs. Timestamp is a primitive long in Streams (and Kafka in general), so there's nothing that would automatically convert a null to 0. If anything, you might get a NullPointerException trying to cast null to long (I.e., unboxing Long) at some point.", "author": "vvcephei", "createdAt": "2020-07-28T21:12:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNjQ2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNzA3MA==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461227070", "bodyText": "what if we made the third window start at a value in the middle instead of consecutive 0 -> 2 -> 4, like 10?", "author": "agavra", "createdAt": "2020-07-27T23:26:24Z", "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +92,222 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": null},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should drop events with no key\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\",\"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\",\"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\",\"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 0}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows with large jump\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 2 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 3},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 4},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 30}\n+\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 3},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 4, \"end\": 6, \"type\": \"time\"},\"timestamp\": 4}", "originalCommit": "934e79aba168460590f384ae21332f8b6529730f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyODEyNQ==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461228125", "bodyText": "we should test a session window that lasts longer than the session window size (e.g. 0,4,8 should all be in the same session window because the session gets extended). I'm also not sure it makes sense to have a session window with a grace period that's less than the session size so we should test a case where it's >= to the session size and in a future PR we might want to even fail if the grace period is less than the session size", "author": "agavra", "createdAt": "2020-07-27T23:29:52Z", "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +92,222 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": null},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should drop events with no key\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\",\"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\",\"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\",\"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 0}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows with large jump\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 2 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 3},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 4},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 30}\n+\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 3},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 4, \"end\": 6, \"type\": \"time\"},\"timestamp\": 4}\n+\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for session windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW SESSION (5 MILLISECONDS, GRACE PERIOD 0 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},", "originalCommit": "934e79aba168460590f384ae21332f8b6529730f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyOTQxMQ==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461229411", "bodyText": "let's also test a suppress with a filter (WHERE clause)", "author": "agavra", "createdAt": "2020-07-27T23:33:57Z", "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +92,222 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": null},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should drop events with no key\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\",\"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\",\"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\",\"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 0}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows with large jump\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 2 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 3},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 4},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 30}\n+\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 3},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 4, \"end\": 6, \"type\": \"time\"},\"timestamp\": 4}\n+\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for session windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW SESSION (5 MILLISECONDS, GRACE PERIOD 0 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k2\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 6},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 30}\n+\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 3},\"window\": {\"start\": 0, \"end\": 5, \"type\": \"session\"},\"timestamp\": 5},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k2\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 6, \"end\": 6, \"type\": \"session\"},\"timestamp\": 6}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for hopping windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW HOPPING (SIZE 5 MILLISECONDS,ADVANCE BY 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 6},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 10}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 5, \"type\": \"time\"}, \"timestamp\": 2},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 3},\"window\": {\"start\": 2, \"end\": 7, \"type\": \"time\"},\"timestamp\": 6},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 4, \"end\": 9, \"type\": \"time\"},\"timestamp\": 6}\n+      ]\n+    },\n+    {\n+      \"name\": \"should suppress multiple keys\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k2\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k2\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k2\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2}\n+\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k2\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should suppress after join\",", "originalCommit": "934e79aba168460590f384ae21332f8b6529730f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "29f7ce1eefbfa18084b3a50875b91e561eb0e3ee", "url": "https://github.com/confluentinc/ksql/commit/29f7ce1eefbfa18084b3a50875b91e561eb0e3ee", "message": "chore: add comments for clarity", "committedDate": "2020-07-28T16:52:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkyMjE1NQ==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461922155", "bodyText": "It looks like this is going to pass the name to Materialized and then pass the Materialized to transformValues, right? That's probably not what you want to do, since it will cause Streams to store a full extra copy of the table right before Suppress.\nI'm guessing you just wanted to pass the key and value serdes into Suppress, in which case, you can replace this with:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                final Materialized<K, GenericRow, KeyValueStore<Bytes, byte[]>> materialized =\n          \n          \n            \n                    materializedFactory.create(\n          \n          \n            \n                        keySerde,\n          \n          \n            \n                        valueSerde,\n          \n          \n            \n                        SUPPRESS_OP_NAME\n          \n          \n            \n                    );\n          \n          \n            \n                final Materialized<K, GenericRow, KeyValueStore<Bytes, byte[]>> materialized =\n          \n          \n            \n                    Materialized.with(\n          \n          \n            \n                        keySerde,\n          \n          \n            \n                        valueSerde\n          \n          \n            \n                    );\n          \n      \n    \n    \n  \n\nIt's a subtle and dangerous API, I know.", "author": "vvcephei", "createdAt": "2020-07-28T22:13:52Z", "path": "ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/TableSuppressBuilder.java", "diffHunk": "@@ -15,17 +15,98 @@\n \n package io.confluent.ksql.execution.streams;\n \n+import com.google.common.annotations.VisibleForTesting;\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.execution.builder.KsqlQueryBuilder;\n+import io.confluent.ksql.execution.context.QueryContext;\n import io.confluent.ksql.execution.plan.KTableHolder;\n-import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.execution.plan.KeySerdeFactory;\n+import io.confluent.ksql.execution.plan.TableSuppress;\n+import io.confluent.ksql.execution.streams.transform.KsTransformer;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.serde.SerdeOption;\n+import java.util.Set;\n+import java.util.function.BiFunction;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Suppressed;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+\n \n public final class TableSuppressBuilder {\n \n-  private TableSuppressBuilder() {\n+  private static final String SUPPRESS_OP_NAME = \"Suppress\";\n+\n+  public TableSuppressBuilder() {\n   }\n \n-  public static <K> KTableHolder<K> build(\n-      final KTableHolder<K> table\n+  public <K> KTableHolder<K> build(\n+      final KTableHolder<K> table,\n+      final TableSuppress<K> step,\n+      final KsqlQueryBuilder queryBuilder,\n+      final KeySerdeFactory keySerdeFactory,\n+      final MaterializedFactory materializedFactory\n   ) {\n-    throw new KsqlException(\"EMIT FINAL is not yet supported\");\n+    return build(\n+        table,\n+        step,\n+        queryBuilder,\n+        keySerdeFactory,\n+        materializedFactory,\n+        PhysicalSchema::from\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  @SuppressWarnings(\"unchecked\")\n+  <K> KTableHolder<K> build(\n+      final KTableHolder<K> table,\n+      final TableSuppress<K> step,\n+      final KsqlQueryBuilder queryBuilder,\n+      final KeySerdeFactory keySerdeFactory,\n+      final MaterializedFactory materializedFactory,\n+      final BiFunction<LogicalSchema, Set<SerdeOption>, PhysicalSchema> physicalSchemaFactory\n+  ) {\n+    final PhysicalSchema physicalSchema = physicalSchemaFactory.apply(\n+        table.getSchema(),\n+        step.getInternalFormats().getOptions()\n+    );\n+    final QueryContext queryContext = QueryContext.Stacker.of(\n+        step.getProperties().getQueryContext())\n+        .push(SUPPRESS_OP_NAME).getQueryContext();\n+    final Serde<GenericRow> valueSerde = queryBuilder.buildValueSerde(\n+        step.getInternalFormats().getValueFormat(),\n+        physicalSchema,\n+        queryContext\n+    );\n+    final Serde<K> keySerde = keySerdeFactory.buildKeySerde(\n+        step.getInternalFormats().getKeyFormat(),\n+        physicalSchema,\n+        queryContext\n+    );\n+    final Materialized<K, GenericRow, KeyValueStore<Bytes, byte[]>> materialized =\n+        materializedFactory.create(\n+            keySerde,\n+            valueSerde,\n+            SUPPRESS_OP_NAME\n+        );", "originalCommit": "eb818b50cea0c436f927f91d83448562f1b8fc00", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkzNzExNg==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461937116", "bodyText": "Ah great catch, thanks John!", "author": "nae701", "createdAt": "2020-07-28T22:49:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkyMjE1NQ=="}], "type": "inlineReview"}, {"oid": "872f11ca17c3999c5d6016d2fbd5e403b5fc8682", "url": "https://github.com/confluentinc/ksql/commit/872f11ca17c3999c5d6016d2fbd5e403b5fc8682", "message": "fix: remove window expression and fix feedback", "committedDate": "2020-07-29T00:43:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5NzIwMw==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461997203", "bodyText": "Feel free to disregard this comment, but it seems like it would be easier to read these specs if there were one record per line.", "author": "vvcephei", "createdAt": "2020-07-29T02:14:51Z", "path": "ksqldb-functional-tests/src/test/resources/historical_plans/suppress_-_should_drop_events_with_no_key/6.1.0_1595888718687/spec.json", "diffHunk": "@@ -0,0 +1,154 @@\n+{\n+  \"version\" : \"6.1.0\",\n+  \"timestamp\" : 1595888718687,\n+  \"path\" : \"query-validation-tests/suppress.json\",\n+  \"schemas\" : {\n+    \"CTAS_OUTPUT_0.KsqlTopic.Source\" : \"STRUCT<COL1 VARCHAR> NOT NULL\",\n+    \"CTAS_OUTPUT_0.Aggregate.GroupBy\" : \"STRUCT<ID VARCHAR, ROWTIME BIGINT> NOT NULL\",\n+    \"CTAS_OUTPUT_0.Aggregate.Aggregate.Materialize\" : \"STRUCT<ID VARCHAR, ROWTIME BIGINT, KSQL_AGG_VARIABLE_0 BIGINT> NOT NULL\",\n+    \"CTAS_OUTPUT_0.Suppress.Suppress\" : \"STRUCT<COUNT BIGINT> NOT NULL\",\n+    \"CTAS_OUTPUT_0.OUTPUT\" : \"STRUCT<COUNT BIGINT> NOT NULL\"\n+  },\n+  \"testCase\" : {\n+    \"name\" : \"should drop events with no key\",\n+    \"inputs\" : [ {\n+      \"topic\" : \"input_topic\",\n+      \"key\" : \"k1\",\n+      \"value\" : {\n+        \"COL1\" : \"v1\"\n+      },\n+      \"timestamp\" : 0\n+    }, {", "originalCommit": "872f11ca17c3999c5d6016d2fbd5e403b5fc8682", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxNDQ2Ng==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r462014466", "bodyText": "I am not quite sure why these records are not all on one line, this may just be the way that the historical plans are generated ? cc @agavra . But if you want to look at better formatted tests, they should be properly formatted in ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "author": "nae701", "createdAt": "2020-07-29T03:21:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5NzIwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAxNTc4OA==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r462015788", "bodyText": "okay yeah I checked other existing historical tests and they all seemed to be formatted like this, but you can still just look at the suppress.json specified above for a more user-friendly reading experience :)", "author": "nae701", "createdAt": "2020-07-29T03:26:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5NzIwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM1NjU0OA==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r462356548", "bodyText": "Ah, I didn't realize the tests were also specified in that file. So much easier to read!", "author": "vvcephei", "createdAt": "2020-07-29T14:45:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5NzIwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM1NzU0NA==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r462357544", "bodyText": "I guess in retrospect, we should check in the generated files in exactly the format they're generated so that we get a clean diff in the future. Sorry for my confusion.", "author": "vvcephei", "createdAt": "2020-07-29T14:47:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5NzIwMw=="}], "type": "inlineReview"}, {"oid": "7706f8e572bdddd04e68ff8c54fe43583949979d", "url": "https://github.com/confluentinc/ksql/commit/7706f8e572bdddd04e68ff8c54fe43583949979d", "message": "chore: remove unused window exp imports", "committedDate": "2020-07-29T03:30:45Z", "type": "commit"}, {"oid": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104", "url": "https://github.com/confluentinc/ksql/commit/b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104", "message": "chore: fix historical qtts suppress", "committedDate": "2020-07-29T04:51:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4NjMxNQ==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r462586315", "bodyText": "testing GitHub IntelliJ integration", "author": "agavra", "createdAt": "2020-07-29T21:01:33Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/planner/plan/SuppressNode.java", "diffHunk": "@@ -20,6 +20,7 @@\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.schema.ksql.LogicalSchema;\n import io.confluent.ksql.serde.RefinementInfo;\n+import io.confluent.ksql.serde.ValueFormat;", "originalCommit": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4NjQ0NQ==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r462586445", "bodyText": "woah - sorry forthe spam", "author": "agavra", "createdAt": "2020-07-29T21:01:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4NjMxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM2MjIxMA==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r462362210", "bodyText": "I'm sorry, but I'm not seeing how this example differs from the prior one. It seems like a 2ms tumbling window with no grace period should be emitted when that last record arrives at time 2. What have I missed?", "author": "vvcephei", "createdAt": "2020-07-29T14:53:13Z", "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -1,7 +1,83 @@\n {\n   \"tests\": [\n     {\n-      \"name\": \"Should Throw on Emit Final\",\n+      \"name\": \"should emit final result immediately at window end if grace is specified as zero\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 0 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1}\n+      ]\n+    },\n+    {\n+      \"name\": \"should not emit final result before window end if grace is specified as zero\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 0 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2}\n+      ],\n+      \"outputs\": [\n+      ]", "originalCommit": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzczNjU0NA==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r463736544", "bodyText": "This is a typo, the third input should not be there, and that's why there is no expected output. The test is passing however which confuses me, I'm taking a closer look", "author": "nae701", "createdAt": "2020-07-31T17:25:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM2MjIxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzcxNDkxOQ==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r463714919", "bodyText": "We should probably also add an event with an explicitly null key here.", "author": "vvcephei", "createdAt": "2020-07-31T16:39:24Z", "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +91,239 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should drop events with no key\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\",\"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\",\"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\",\"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 0}\n+      ]", "originalCommit": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzcxNTAzNA==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r463715034", "bodyText": "This looks out of place, given the name of this spec.", "author": "vvcephei", "createdAt": "2020-07-31T16:39:39Z", "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +91,239 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},", "originalCommit": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzcxNjQ3OQ==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r463716479", "bodyText": "What do you think about also adding a test for join after suppression? I don't know if you're allowed to join windowed streams, which may disqualify this idea.", "author": "vvcephei", "createdAt": "2020-07-31T16:42:43Z", "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +91,239 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should drop events with no key\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\",\"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\",\"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\",\"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 0}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows with large jump\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 2 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 3},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 10},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 30}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 3},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 10, \"end\": 12, \"type\": \"time\"},\"timestamp\": 10}\n+\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for session windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW SESSION (5 MILLISECONDS, GRACE PERIOD 6 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 4},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 8},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 16},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 15},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 30}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 3},\"window\": {\"start\": 0, \"end\": 8, \"type\": \"session\"},\"timestamp\": 8},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 15, \"end\": 16, \"type\": \"session\"},\"timestamp\": 16}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for hopping windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW HOPPING (SIZE 5 MILLISECONDS,ADVANCE BY 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 6},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 10}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 5, \"type\": \"time\"}, \"timestamp\": 2},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 3},\"window\": {\"start\": 2, \"end\": 7, \"type\": \"time\"},\"timestamp\": 6},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 4, \"end\": 9, \"type\": \"time\"},\"timestamp\": 6}\n+      ]\n+    },\n+    {\n+      \"name\": \"should suppress multiple keys\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k2\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k2\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k2\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2}\n+\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k2\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should suppress after join\",", "originalCommit": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg4MTYzMw==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r463881633", "bodyText": "I am not sure either but maybe @agavra knows? Though my understanding was that suppression here will return a table with windowed keys, and the only windowed joins that ksqlDB supports is that between two streams? I may be misunderstanding the joins possible here though", "author": "nae701", "createdAt": "2020-07-31T23:09:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzcxNjQ3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU2ODI4MA==", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r464568280", "bodyText": "I don't think we allow windowed sources to any operation at the moment, so probably no need to test that here", "author": "agavra", "createdAt": "2020-08-03T17:47:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzcxNjQ3OQ=="}], "type": "inlineReview"}]}