{"pr_number": 4875, "pr_title": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "pr_createdAt": "2020-03-23T22:01:33Z", "pr_url": "https://github.com/confluentinc/ksql/pull/4875", "timeline": [{"oid": "5a871718d2401b79c45548a52994b37e3106d778", "url": "https://github.com/confluentinc/ksql/commit/5a871718d2401b79c45548a52994b37e3106d778", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-24T00:12:34Z", "type": "forcePushed"}, {"oid": "8ab02f964c73fb48d54f0deeffbb5884cbf93c62", "url": "https://github.com/confluentinc/ksql/commit/8ab02f964c73fb48d54f0deeffbb5884cbf93c62", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-24T18:58:12Z", "type": "forcePushed"}, {"oid": "865e158a791082b48f6c11e75bcf26befd28b1d0", "url": "https://github.com/confluentinc/ksql/commit/865e158a791082b48f6c11e75bcf26befd28b1d0", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-25T18:46:27Z", "type": "forcePushed"}, {"oid": "115659497df719d8e1913ed113d2d61a4056a302", "url": "https://github.com/confluentinc/ksql/commit/115659497df719d8e1913ed113d2d61a4056a302", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-25T22:36:51Z", "type": "forcePushed"}, {"oid": "fcd157bf075d61c840bab2bab86b1013f28a3204", "url": "https://github.com/confluentinc/ksql/commit/fcd157bf075d61c840bab2bab86b1013f28a3204", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-26T00:04:19Z", "type": "forcePushed"}, {"oid": "80f552536a53dcf361f7de8165e21fd20e47808a", "url": "https://github.com/confluentinc/ksql/commit/80f552536a53dcf361f7de8165e21fd20e47808a", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-26T00:05:54Z", "type": "forcePushed"}, {"oid": "4cc10dbfcf6030635899df8a758da0c3ba7ff519", "url": "https://github.com/confluentinc/ksql/commit/4cc10dbfcf6030635899df8a758da0c3ba7ff519", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-26T03:00:11Z", "type": "forcePushed"}, {"oid": "413146c650913a86bce395aff75949e0104e5e7a", "url": "https://github.com/confluentinc/ksql/commit/413146c650913a86bce395aff75949e0104e5e7a", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-26T03:35:16Z", "type": "forcePushed"}, {"oid": "157df014f2f5adb180949d2b07a132b957a4d0f2", "url": "https://github.com/confluentinc/ksql/commit/157df014f2f5adb180949d2b07a132b957a4d0f2", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-26T06:45:19Z", "type": "forcePushed"}, {"oid": "470d006b25626e2d60ef3fb8f6ef0ebc52b11b62", "url": "https://github.com/confluentinc/ksql/commit/470d006b25626e2d60ef3fb8f6ef0ebc52b11b62", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-26T07:18:50Z", "type": "forcePushed"}, {"oid": "d0dc3c9e88cd0e986f3058c761ac1929836b07ce", "url": "https://github.com/confluentinc/ksql/commit/d0dc3c9e88cd0e986f3058c761ac1929836b07ce", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-26T23:14:33Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk2OTQyOA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r398969428", "bodyText": "Changing this to reduce the amount of logging from creating the KsqlRequestConfig", "author": "stevenpyzhang", "createdAt": "2020-03-27T00:26:43Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java", "diffHunk": "@@ -247,8 +247,9 @@ public Response handleKsqlStatements(\n           request,\n           distributedCmdResponseTimeout);\n \n-      final KsqlRequestConfig requestConfig =\n-          new KsqlRequestConfig(request.getRequestProperties());\n+      final boolean internalRequest =", "originalCommit": "d0dc3c9e88cd0e986f3058c761ac1929836b07ce", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3MTIwMg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400871202", "bodyText": "Rather than change this, just make KsqlRequstConfig not log on construction.  You can do this by changing its constructor to pass false for the doLog param of AbstractConfig's constructor:\npublic KsqlRequestConfig(final Map<?, ?> props) {\n    super(CURRENT_DEF, props, false);\n  }", "author": "big-andy-coates", "createdAt": "2020-03-31T12:26:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk2OTQyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg5MTk5MA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401891990", "bodyText": "Thanks! I didn't realize this was an option", "author": "stevenpyzhang", "createdAt": "2020-04-01T20:33:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk2OTQyOA=="}], "type": "inlineReview"}, {"oid": "5784bc7d76ce514960fe7116a3aeb898bed15188", "url": "https://github.com/confluentinc/ksql/commit/5784bc7d76ce514960fe7116a3aeb898bed15188", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-27T00:54:45Z", "type": "forcePushed"}, {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693", "url": "https://github.com/confluentinc/ksql/commit/5271edf3d2fbf858bde71926fedd246edd9fa693", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-27T00:55:25Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk3NzM1MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r398977351", "bodyText": "This has to be set in order for waitForClusterToBeDiscovered(REST_APP_0, 2); to work properly. The wait is necessary in order to make sure the queries are in a RUNNING state before proceeding with the test", "author": "stevenpyzhang", "createdAt": "2020-03-27T00:56:47Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForClusterToBeDiscovered;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.Queries;\n+import io.confluent.ksql.rest.entity.QueryDescription;\n+import io.confluent.ksql.rest.entity.QueryDescriptionList;\n+import io.confluent.ksql.rest.entity.RunningQuery;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.test.util.secure.ClientTrustStore;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+\n+@Category({IntegrationTest.class})\n+public class ShowQueriesMultiNodeFunctionalTest {\n+\n+  private static final PageViewDataProvider PAGE_VIEWS_PROVIDER = new PageViewDataProvider();\n+  private static final String PAGE_VIEW_TOPIC = PAGE_VIEWS_PROVIDER.topicName();\n+  private static final String PAGE_VIEW_STREAM = PAGE_VIEWS_PROVIDER.kstreamName();\n+  private static final KsqlHostInfoEntity host0 = new KsqlHostInfoEntity(\"localhost\", 8088);\n+  private static final KsqlHostInfoEntity host1 = new KsqlHostInfoEntity(\"localhost\", 8089);\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+  private static final TestKsqlRestApp REST_APP_0 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg1NzIzNQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400857235", "bodyText": "When I run this test I see this reported in the output:\njava.lang.UnsupportedOperationException: KSQL client is disabled\n\tat io.confluent.ksql.services.DisabledKsqlClient.makeAsyncHeartbeatRequest(DisabledKsqlClient.java:70)\n\tat io.confluent.ksql.rest.server.HeartbeatAgent$SendHeartbeatService.runOneIteration(HeartbeatAgent.java:322)\n\tat com.google.common.util.concurrent.AbstractScheduledService$ServiceDelegate$Task.run(AbstractScheduledService.java:193)\n\tat com.google.common.util.concurrent.Callables$4.run(Callables.java:119)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nWhich seems to suggest that maybe this isn't doing what you think it is.\nRather than relying on another feature to ensure the queries are running before proceeding, might it not be better to code the tests to await the expected final state?  This way, we can be sure that your change works even if heartbeats are disabled.\nTo achieve this, you can change your tests to use assertThatEventually, as I've shown below. assertThatEventually takes a Supplier which it polls to get a result.", "author": "big-andy-coates", "createdAt": "2020-03-31T12:03:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk3NzM1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTkyMDI2MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401920261", "bodyText": "Resolving as this dependency is now removed.", "author": "stevenpyzhang", "createdAt": "2020-04-01T21:27:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk3NzM1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA0NTMzOA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399045338", "bodyText": "Adding in once we're satisfied with the final new output", "author": "stevenpyzhang", "createdAt": "2020-03-27T05:38:39Z", "path": "docs-md/developer-guide/ksqldb-reference/show-queries.md", "diffHunk": "@@ -13,13 +13,15 @@ Synopsis\n --------\r\n \r\n ```sql\r\n-SHOW QUERIES;\r\n+SHOW | LIST QUERIES [EXTENDED];\r\n ```\r\n \r\n Description\r\n -----------\r\n \r\n-List the running persistent queries.\r\n+`SHOW QUERIES` lists queries running in the cluster.\r\n+\r\n+`SHOW QUERIES EXTENDED` lists queries running in the cluster in more detail.\r\n \r\n Example\r\n -------\r", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5MzM2MA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400793360", "bodyText": "What's the proposed new output?", "author": "big-andy-coates", "createdAt": "2020-03-31T10:06:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA0NTMzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTkyMTAwNg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401921006", "bodyText": "adding a sample cli output", "author": "stevenpyzhang", "createdAt": "2020-04-01T21:29:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA0NTMzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIzMjY1MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402232651", "bodyText": "The example output in the description looks more like the JSON response from the server.  This looks good to me, except maybe I'd make the state field in the extended version match the output in the non-extended, i.e.\n\"state\": \"RUNNING\",\n\nbecomes:\n\"state\": \"RUNNING:2\",\n\n???\nWhat I'm more interested in seeing though is the output from the CLI... The PR doesn't seem to have any new code to display this new info.  Does it need some, or will these new fields be output automagically?", "author": "big-andy-coates", "createdAt": "2020-04-02T11:10:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA0NTMzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjcyMjU1OA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402722558", "bodyText": "I actually changed it so that the state for a RunningQuery is set to the string representation of a QueryStateCount.\nSimilar thing for the extended output.\nCurrently this change is backwards compatible with the CLI since I'm keeping the state field and setting them to the string representation of the new query state objects", "author": "stevenpyzhang", "createdAt": "2020-04-03T03:52:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA0NTMzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM2NjgwOQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399366809", "bodyText": "nit: I believe the toString is superfluous here", "author": "agavra", "createdAt": "2020-03-27T15:55:03Z", "path": "ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java", "diffHunk": "@@ -659,6 +659,11 @@ private void printQueryDescription(final QueryDescription query) {\n     if (query.getState().isPresent()) {\n       writer().println(String.format(\"%-20s : %s\", \"Status\", query.getState().get()));\n     }\n+    if (query.getKsqlHostQueryState().size() > 0) {\n+      writer().println(String.format(\n+          \"%-20s : %s\", \"Host Query Status\",\n+          query.getKsqlHostQueryState().toString()));", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM2OTQ3NA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399369474", "bodyText": "can we just use KafkaStreams.State#valueOf instead of this map?", "author": "agavra", "createdAt": "2020-03-27T15:58:52Z", "path": "ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java", "diffHunk": "@@ -46,6 +51,17 @@ private KsqlConstants() {\n   public static final String DEFAULT_AVRO_SCHEMA_FULL_NAME =\n           AVRO_SCHEMA_NAMESPACE + \".\" + AVRO_SCHEMA_NAME;\n \n+  public static final ImmutableMap<String, KafkaStreams.State>\n+      STRING_TO_KAFKA_STREAMS_STATE_MAPPING;\n+\n+  static {\n+    final  Map<String, KafkaStreams.State> stringToStateMapping = new HashMap<>();\n+    for (KafkaStreams.State state: KafkaStreams.State.values()) {\n+      stringToStateMapping.put(state.toString(), state);\n+    }\n+    STRING_TO_KAFKA_STREAMS_STATE_MAPPING = ImmutableMap.copyOf(stringToStateMapping);", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM2OTczMg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399369732", "bodyText": "nit: javadoc ;)", "author": "agavra", "createdAt": "2020-03-27T15:59:15Z", "path": "ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java", "diffHunk": "@@ -34,6 +34,12 @@\n       String sql\n   );\n \n+  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM3MzI4Ng==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399373286", "bodyText": "nit: up to you, but I would recommend replacing all of these .forEach calls with vanilla for-each loops. It will make the stack traces way more readable, error handling easier and debugging anything with remote calls a little simpler. the way it stands, I think we have four nested lambdas, which were really designed for stateless transforms", "author": "agavra", "createdAt": "2020-03-27T16:04:24Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +57,143 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          listQueries,\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> hosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      hosts.forEach(hostInfo -> {\n+        final KsqlEntityList response = serviceContext.getKsqlClient()\n+            .makeKsqlRequestWithRequestProperties(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    hostInfo.host(),\n+                    hostInfo.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+            .getResponse();\n+\n+        response.forEach(remoteQueries -> {\n+          final List<RunningQuery> queries = ((Queries) remoteQueries).getQueries();\n+          queries.forEach(q -> {\n+            final String queryId = q.getId().toString();\n+            \n+            // If the query has already been discovered, update the KafkaStreamsStateCount object\n+            if (queryToRunningQuery.containsKey(queryId)) {\n+              q.getState().getState()\n+                  .forEach((state, count) ->", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ3MjIxOA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400472218", "bodyText": "done", "author": "stevenpyzhang", "createdAt": "2020-03-30T20:26:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM3MzI4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM4MjQ0MA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399382440", "bodyText": "for SerDe of the maps, I would recommend using:\n    Map<String, String> pairs = Splitter.on(\",\").withKeyValueSeparator(\":\").split(serialized);\n    state =  pairs.entrySet().stream()\n        .collect(Collectors.toMap(\n            e -> KafkaStreams.State.valueOf(e.getKey()),\n            e -> Integer.parseInt(e.getValue()),\n            (v1, v2) -> {throw new IllegalStateException(\"duplicate keys\")},\n            TreeMap::new\n        ));\nAnd you can use the correspond method to serialize: Joiner.on(\",\").withKeyValueSeparator(\":\").join(values);", "author": "agavra", "createdAt": "2020-03-27T16:18:20Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import io.confluent.ksql.util.KsqlConstants;\n+import io.confluent.ksql.util.KsqlException;\n+\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.TreeMap;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class KafkaStreamsStateCount {\n+  \n+  // Use a TreeMap so toString() will always return the same string\n+  private final TreeMap<KafkaStreams.State, Integer> state;\n+\n+  public KafkaStreamsStateCount() {\n+    this.state = returnTreeMap();\n+  }\n+\n+  @JsonCreator\n+  public KafkaStreamsStateCount(final String serializedPair) {\n+    final String [] parts = serializedPair.split(\",\");", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTM2MTQ0Mw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401361443", "bodyText": "done", "author": "stevenpyzhang", "createdAt": "2020-04-01T05:19:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM4MjQ0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM4NzMyNQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399387325", "bodyText": "a lot of this seems duplicated from above, can we simplify it?", "author": "agavra", "createdAt": "2020-03-27T16:25:28Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +57,143 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          listQueries,\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> hosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      hosts.forEach(hostInfo -> {\n+        final KsqlEntityList response = serviceContext.getKsqlClient()\n+            .makeKsqlRequestWithRequestProperties(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    hostInfo.host(),\n+                    hostInfo.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+            .getResponse();\n+\n+        response.forEach(remoteQueries -> {\n+          final List<RunningQuery> queries = ((Queries) remoteQueries).getQueries();\n+          queries.forEach(q -> {\n+            final String queryId = q.getId().toString();\n+            \n+            // If the query has already been discovered, update the KafkaStreamsStateCount object\n+            if (queryToRunningQuery.containsKey(queryId)) {\n+              q.getState().getState()\n+                  .forEach((state, count) ->\n+                      queryToRunningQuery\n+                          .get(queryId)\n+                          .getState()\n+                          .updateStateCount(state, count));\n+            } else {\n+              queryToRunningQuery.put(queryId, q);\n+            }\n+          });\n+        });\n+      });\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n-                q.getStatementString(),\n-                ImmutableSet.of(q.getSinkName().text()),\n-                ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n-                q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+        new ArrayList<>(queryToRunningQuery.values())));\n   }\n \n-}\n+  private static Optional<KsqlEntity> executeExtended(\n+      final ListQueries listQueries,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    final List<QueryDescription> queryDescriptions = \n+        executionContext.getPersistentQueries().stream()\n+            .map(query -> {\n+              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+              ksqlHostQueryState.put(\n+                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                  query.getState());\n+              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }).collect(Collectors.toList());\n+\n+    final Map<String, QueryDescription> queryToQueryDescription =\n+        queryDescriptions.stream().collect(\n+            Collectors.toMap(\n+                query -> query.getId().toString(),\n+                query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> hosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      hosts.forEach(hostInfo -> {\n+        final KsqlEntityList response = \n+            serviceContext.getKsqlClient().makeKsqlRequestWithRequestProperties(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    hostInfo.host(),\n+                    hostInfo.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true)\n+        ).getResponse();\n+\n+        response.forEach(remoteQueries -> {\n+          final List<QueryDescription> queries =\n+              ((QueryDescriptionList) remoteQueries).getQueryDescriptions();\n+\n+          queries.forEach(q -> {\n+            final String queryId = q.getId().toString();\n+\n+            // If the query has already been discovered, add to the ksqlQueryHostState mapping", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM4NzY3Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399387677", "bodyText": "what happens if there's an error with this? also I believe we have an async execute call on ksql client. Can we use that instead so that we don't handle them one at a time? (as your comment in the description mentions)", "author": "agavra", "createdAt": "2020-03-27T16:26:03Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +57,143 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          listQueries,\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> hosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      hosts.forEach(hostInfo -> {\n+        final KsqlEntityList response = serviceContext.getKsqlClient()", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM5MDQ1NA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399390454", "bodyText": "instead of actually spinning up a rest app, which takes forever and probably tests more than we want to test - can we make this test mock out any network communication? I think adding an integration for this is overkill as it's a relatively minor feature and we'd be testing way more than we need to", "author": "agavra", "createdAt": "2020-03-27T16:30:12Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForClusterToBeDiscovered;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.Queries;\n+import io.confluent.ksql.rest.entity.QueryDescription;\n+import io.confluent.ksql.rest.entity.QueryDescriptionList;\n+import io.confluent.ksql.rest.entity.RunningQuery;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.test.util.secure.ClientTrustStore;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+\n+@Category({IntegrationTest.class})\n+public class ShowQueriesMultiNodeFunctionalTest {", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMjUxOA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400822518", "bodyText": "I actually think this is a worthwhile test, (replying to @agavra's comment). We need to test somewhere that two nodes can actually talk to each other to resolve the full list of states.  The more we mock out the less sure we are that this all functionally hangs together.\nAt the moment we don't have some centralised was of communicating between nodes with its own set of tests.  If we did, then I'd agree with this test testing too much.", "author": "big-andy-coates", "createdAt": "2020-03-31T10:58:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM5MDQ1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM5MTU1Mw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399391553", "bodyText": "can we test the exceptional cases here as well? and follow Given/When/Then for all tests?", "author": "agavra", "createdAt": "2020-03-27T16:32:02Z", "path": "ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.ksql.util.KsqlException;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+@SuppressWarnings(\"SameParameterValue\")\n+public class KafkaStreamsStateCountTest {\n+\n+  KafkaStreamsStateCount kafkaStreamsStateCount;\n+  \n+  @Before\n+  public void setup() {\n+    kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+  }\n+\n+  @Test\n+  public void shouldUpdateExistingStateCount() {\n+    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 2);\n+    assertThat(\n+        kafkaStreamsStateCount.getState().get(KafkaStreams.State.RUNNING),\n+        is(2));\n+    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 4);\n+    assertThat(\n+        kafkaStreamsStateCount.getState().get(KafkaStreams.State.RUNNING),\n+        is(6));\n+  }\n+\n+  @Test\n+  public void shouldToString() {\n+    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 2);\n+    assertThat(\n+        kafkaStreamsStateCount.toString(),\n+        is(\"RUNNING:2\"));\n+    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.NOT_RUNNING, 1);\n+    assertThat(\n+        kafkaStreamsStateCount.toString(),\n+        is(\"NOT_RUNNING:1, RUNNING:2\"));\n+  }\n+\n+  @Test\n+  public void shouldConvertStringToKafkaStreamsStateCount() {", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM5MjIxMg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399392212", "bodyText": "I believe you can use EnumMap here - as the order is deterministic based on the ordering of the State enum ordinal", "author": "agavra", "createdAt": "2020-03-27T16:33:03Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import io.confluent.ksql.util.KsqlConstants;\n+import io.confluent.ksql.util.KsqlException;\n+\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.TreeMap;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class KafkaStreamsStateCount {\n+  \n+  // Use a TreeMap so toString() will always return the same string\n+  private final TreeMap<KafkaStreams.State, Integer> state;", "originalCommit": "5271edf3d2fbf858bde71926fedd246edd9fa693", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "35a707ccf27366ed8f44f71aa302c7159d3826ad", "url": "https://github.com/confluentinc/ksql/commit/35a707ccf27366ed8f44f71aa302c7159d3826ad", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-03-27T18:41:31Z", "type": "forcePushed"}, {"oid": "15fc917b558b649851a97563869bc2b80ec8d0a0", "url": "https://github.com/confluentinc/ksql/commit/15fc917b558b649851a97563869bc2b80ec8d0a0", "message": "address comments", "committedDate": "2020-03-29T16:31:38Z", "type": "forcePushed"}, {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "url": "https://github.com/confluentinc/ksql/commit/e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "message": "address comments", "committedDate": "2020-03-30T17:33:52Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NDQwNA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400794404", "bodyText": "nit: toString is superfluous here.", "author": "big-andy-coates", "createdAt": "2020-03-31T10:08:36Z", "path": "ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java", "diffHunk": "@@ -530,7 +530,7 @@ private void printQueries(\n       ));\n       for (final RunningQuery writeQuery : queries) {\n         writer().println(writeQuery.getId().getId()\n-            + \" (\" + writeQuery.getState().orElse(\"N/A\")\n+            + \" (\" + writeQuery.getState().toString()", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NDkwMg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400794902", "bodyText": "The test would be less coupled to KafkaStreamsStateCount if you use a mock.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private KafkaStreamsStateCount kafkaStreamsStateCount;\n          \n          \n            \n              @Mock(name = \"RUNNING:1, ERROR:2\")\n          \n          \n            \n              private KafkaStreamsStateCount kafkaStreamsStateCount;\n          \n      \n    \n    \n  \n\nThen kafkaStreamsStateCount.toString() will return RUNNING:1, ERROR:2, which you can check for in your test.\nNow if the output of toString changes you don't need to update this test.", "author": "big-andy-coates", "createdAt": "2020-03-31T10:09:32Z", "path": "ksqldb-cli/src/test/java/io/confluent/ksql/cli/console/ConsoleTest.java", "diffHunk": "@@ -129,6 +131,7 @@\n       1,\n       \"statement\"\n   );\n+  private KafkaStreamsStateCount kafkaStreamsStateCount;", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTAwNDc0Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401004747", "bodyText": "woah I had no idea this was a thing, that's so cool!", "author": "agavra", "createdAt": "2020-03-31T15:27:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NDkwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgwODI0Mw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401808243", "bodyText": "Hmm, this isn't working for me. The tests have RUNNING:1,ERROR:2 in the cases, but they're still passing after setting @Mock(name = \"RUNNING:1, ERROR:2\") (no space in between the state counts)", "author": "stevenpyzhang", "createdAt": "2020-04-01T18:04:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NDkwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjIyOTEwOQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402229109", "bodyText": "Just a thought, but you have removed the code that assigns a new instance to this field, right?  If not, have you tried debugging? Cos this does work...", "author": "big-andy-coates", "createdAt": "2020-04-02T11:03:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NDkwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY1NDAxNQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402654015", "bodyText": "I ended up just mocking this regularly since I also needed to mock the getStates method", "author": "stevenpyzhang", "createdAt": "2020-04-02T23:29:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NDkwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwMzA1Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400803057", "bodyText": "This looks a lot like interface bloat to me.  It looks like what you needed to do was add an additional map parameter to the existing makeKsqlRequest method.  Instead you've added a whole new method.\nThis has two disadvantages:\n\nimplementations of the interface now need to implement an additional method\nusers to the interface may need to check the implementation to work out what the two methods do so they can work out which to call.\n\nThink what would happen in a year of twos time if this pattern was followed when people added a few more variants to add additional parameters?  The result is a bloated interface which is hard to use and to implement.\nA better way....\nQ: Is there any difference between calling:\nmakeKsqlRequest(uri, sql);\n// or\nmakeKsqlRequestWithRequestProperties(uri, sql, emptyMap);\nI'm guessing / hoping not.\nIf this is the case, I'd suggest one of two approaches:\n\nAdd the new param to the existing makeKsqlRequest method and default all existing calls to passing an ImmutableMap.of() for the new param, i.e. passing an empty map.\nHave two separate methods, but provide a default implementation for one that calls the other:\n\npublic interface SimpleKsqlClient {\n  \n default RestResponse<KsqlEntityList> makeKsqlRequest(\n      URI serverEndPoint,\n      String sql\n  ) {\n    return makeKsqlRequest(serverEndPoint, sql, ImmutableMap.of());\n  }\n\n   RestResponse<KsqlEntityList> makeKsqlRequest(\n      URI serverEndPoint,\n      String sql,\n      Map<String, ?> props\n  );\n}\nOf these, my preference would be for the first option as this solves both issues, where as the second option only removes the need for implementations to implement a second method, while still leaving users of the interface to work out which method they need to call.", "author": "big-andy-coates", "createdAt": "2020-03-31T10:23:06Z", "path": "ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java", "diffHunk": "@@ -34,6 +34,19 @@\n       String sql\n   );\n \n+  /**\n+   * Send a request to remote Ksql server.\n+   * @param serverEndPoint the remote destination\n+   * @param sql the sql statement\n+   * @param requestProperties the request metadata provided by the server\n+   * @return the result of sql statement execution\n+   */\n+  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n+      URI serverEndPoint,\n+      String sql,\n+      Map<String, ?> requestProperties\n+  );\n+", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk2MzU3Mg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401963572", "bodyText": "Went with your first suggestion.", "author": "stevenpyzhang", "createdAt": "2020-04-01T23:14:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwMzA1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwNTY1NQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400805655", "bodyText": "nit: duplicate code. Why not create the map in the calling function and pass it down, rather than passing sessionProperites?", "author": "big-andy-coates", "createdAt": "2020-03-31T10:27:34Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ExplainExecutor.java", "diffHunk": "@@ -118,20 +125,29 @@ private static QueryDescription explainStatement(\n               new IllegalStateException(\"The provided statement did not run a ksql query\"));\n     }\n \n-    return QueryDescriptionFactory.forQueryMetadata(metadata);\n+    return QueryDescriptionFactory.forQueryMetadata(\n+        metadata,\n+        Collections.singletonMap(\n+            new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+            metadata.getState()));\n   }\n \n   private static QueryDescription explainQuery(\n       final String queryId,\n-      final KsqlExecutionContext executionContext\n+      final KsqlExecutionContext executionContext,\n+      final SessionProperties sessionProperties\n   ) {\n     final PersistentQueryMetadata metadata = executionContext\n         .getPersistentQuery(new QueryId(queryId))\n         .orElseThrow(() -> new KsqlException(\n             \"Query with id:\" + queryId + \" does not exist, \"\n                 + \"use SHOW QUERIES to view the full set of queries.\"));\n \n-    return QueryDescriptionFactory.forQueryMetadata(metadata);\n+    return QueryDescriptionFactory.forQueryMetadata(\n+        metadata,\n+        Collections.singletonMap(\n+            new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+            metadata.getState()));", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg3OTIwNQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401879205", "bodyText": "I changed it to pass down the KsqlHostInfoEntity object, but the map would still need to be made separately in each function since the QueryMetadata isn't available for the Explain statement case.", "author": "stevenpyzhang", "createdAt": "2020-04-01T20:09:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwNTY1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk1NzE5MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401957191", "bodyText": "Actually, I realized, for explainStatement, the ksqlQueryHostState should actually be an emptyMap since we're not actually running the statement yet.", "author": "stevenpyzhang", "createdAt": "2020-04-01T22:55:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwNTY1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxMDE5Mw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400810193", "bodyText": "This is called sessionProperties on the receiving end... consider calling it sessionProperties here?", "author": "big-andy-coates", "createdAt": "2020-03-31T10:35:22Z", "path": "ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java", "diffHunk": "@@ -34,6 +34,19 @@\n       String sql\n   );\n \n+  /**\n+   * Send a request to remote Ksql server.\n+   * @param serverEndPoint the remote destination\n+   * @param sql the sql statement\n+   * @param requestProperties the request metadata provided by the server\n+   * @return the result of sql statement execution\n+   */\n+  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n+      URI serverEndPoint,\n+      String sql,\n+      Map<String, ?> requestProperties", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk2NDI1OA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401964258", "bodyText": "It should still be requestProperties, SessionProperties is created in the REST resource by looking at the incoming requests's requestProperties so they're not exactly the same object", "author": "stevenpyzhang", "createdAt": "2020-04-01T23:16:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxMDE5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxNDk3OQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400814979", "bodyText": "Humm... silently excluding results on failure is probably not ideal.  Better to capture this information and return it as part of the result, e.g. have a list of unresponsive hosts.", "author": "big-andy-coates", "createdAt": "2020-03-31T10:44:25Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjcxODczMQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402718731", "bodyText": "I'm not sure how that would exactly fit in with the current outputs that's proposed. Would it be fine to just log the failure for now and I'll file a issue for improving the response to indicate unresponsive hosts?", "author": "stevenpyzhang", "createdAt": "2020-04-03T03:34:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxNDk3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMDg1MA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404730850", "bodyText": "If you're planning on do that as the next task, then sure, by all means get this one merged and then enhance to include unresponsive hosts.\nIf you mean just raise it as a task and then it gets lost in the backlog... never to see the light of day again... ;).   Then I'd say no.\nThis piece of work you're doing, (which is awesome!), would be incomplete IMHO if the user wasn't informed that the results were incomplete.  One of the main reasons they may be looking into the query status on the different hosts is because something is wrong and they're investigating.  Hence we should be providing them with the info they need, not hiding errors from them.\nThe current output has two modes, right?\nNormal outputs something like status: RUNNING:1, CREATED: 2.  So why not include a UNRESPONSIVE: 2 in that list?\nExtended output goes a step further and outputs the state on each host, e.g. Host Query Status    : {Host1=RUNNING, Host2=RUNNING}. This too could easily be extended to include Host3=UNRESPONSIVE.", "author": "big-andy-coates", "createdAt": "2020-04-07T11:18:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxNDk3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxODQyNg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400818426", "bodyText": "Rather than wrap values in new ArrayList, why not change Queries constructor to take a Collection and internally take a defensive immutable copy using ImmutableList.copyOf(queries)?", "author": "big-andy-coates", "createdAt": "2020-03-31T10:51:14Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n+        }\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n-                q.getStatementString(),\n-                ImmutableSet.of(q.getSinkName().text()),\n-                ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n-                q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+        new ArrayList<>(queryToRunningQuery.values())));", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMDI5Ng==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400820296", "bodyText": "nit: private", "author": "big-andy-coates", "createdAt": "2020-03-31T10:54:33Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java", "diffHunk": "@@ -37,21 +38,35 @@\n import io.confluent.ksql.serde.KeyFormat;\n import io.confluent.ksql.statement.ConfiguredStatement;\n import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlHostInfo;\n import io.confluent.ksql.util.PersistentQueryMetadata;\n+\n+import java.util.Collections;\n import java.util.Optional;\n+\n+import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.rules.ExpectedException;\n import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n import org.mockito.junit.MockitoJUnitRunner;\n \n @RunWith(MockitoJUnitRunner.class)\n public class ExplainExecutorTest {\n \n+  private static final KsqlHostInfo LOCAL_HOST = new KsqlHostInfo(\"host\", 8080);\n   @Rule\n   public final TemporaryEngine engine = new TemporaryEngine();\n   @Rule\n   public ExpectedException expectedException = ExpectedException.none();\n+  @Mock\n+  SessionProperties sessionProperties;", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMDQ2OQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400820469", "bodyText": "nit: private", "author": "big-andy-coates", "createdAt": "2020-03-31T10:54:53Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java", "diffHunk": "@@ -39,17 +41,39 @@\n import io.confluent.ksql.serde.KeyFormat;\n import io.confluent.ksql.statement.ConfiguredStatement;\n import io.confluent.ksql.util.PersistentQueryMetadata;\n+\n+import java.util.Collections;\n+import java.util.Map;\n import java.util.Optional;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n import org.mockito.junit.MockitoJUnitRunner;\n \n @RunWith(MockitoJUnitRunner.class)\n public class ListQueriesExecutorTest {\n \n+  private static final KsqlHostInfoEntity LOCAL_HOST = new KsqlHostInfoEntity(\"some host\", 555);\n+  private static final KafkaStreams.State QUERY_STATE = KafkaStreams.State.RUNNING;\n+  private static final Map<KsqlHostInfoEntity, String> KSQL_HOST_INFO_MAP = Collections.singletonMap(LOCAL_HOST, QUERY_STATE.toString());\n   @Rule public final TemporaryEngine engine = new TemporaryEngine();\n \n+  @Mock\n+  SessionProperties sessionProperties;", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMDczMA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400820730", "bodyText": "nit: private, and prefer mock to actual instance, as this decouples this test from KafkaStreamsStateCount implementation.", "author": "big-andy-coates", "createdAt": "2020-03-31T10:55:22Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java", "diffHunk": "@@ -39,17 +41,39 @@\n import io.confluent.ksql.serde.KeyFormat;\n import io.confluent.ksql.statement.ConfiguredStatement;\n import io.confluent.ksql.util.PersistentQueryMetadata;\n+\n+import java.util.Collections;\n+import java.util.Map;\n import java.util.Optional;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n import org.mockito.junit.MockitoJUnitRunner;\n \n @RunWith(MockitoJUnitRunner.class)\n public class ListQueriesExecutorTest {\n \n+  private static final KsqlHostInfoEntity LOCAL_HOST = new KsqlHostInfoEntity(\"some host\", 555);\n+  private static final KafkaStreams.State QUERY_STATE = KafkaStreams.State.RUNNING;\n+  private static final Map<KsqlHostInfoEntity, String> KSQL_HOST_INFO_MAP = Collections.singletonMap(LOCAL_HOST, QUERY_STATE.toString());\n   @Rule public final TemporaryEngine engine = new TemporaryEngine();\n \n+  @Mock\n+  SessionProperties sessionProperties;\n+\n+  KafkaStreamsStateCount kafkaStreamsStateCount;", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTkwMjI5MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401902291", "bodyText": "made it private, but I don't think this can be mocked. shouldListQueriesBasic test compares the state count object created in the output of ListQueriesExecutor with this variable and if it's a mock, it wouldn't be a match.", "author": "stevenpyzhang", "createdAt": "2020-04-01T20:53:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMDczMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMzI1Ng==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400823256", "bodyText": "fyi: !remoteHosts.isEmpty() is often more efficient than remoteHosts.size() != 0.  The former only needs to check the first entry in the list. The latter may, depending on the collection implementation, need to iterate all entries to find the size.", "author": "big-andy-coates", "createdAt": "2020-03-31T10:59:47Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n+        }\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n-                q.getStatementString(),\n-                ImmutableSet.of(q.getSinkName().text()),\n-                ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n-                q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+        new ArrayList<>(queryToRunningQuery.values())));\n   }\n \n-}\n+  private static Optional<KsqlEntity> executeExtended(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    final List<QueryDescription> queryDescriptions = \n+        executionContext.getPersistentQueries().stream()\n+            .map(query -> {\n+              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+              ksqlHostQueryState.put(\n+                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                  query.getState());\n+              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }).collect(Collectors.toList());\n+\n+    final Map<String, QueryDescription> queryToQueryDescription =\n+        queryDescriptions.stream().collect(\n+            Collectors.toMap(\n+                query -> query.getId().toString(),\n+                query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      if (remoteHosts.size() != 0) {", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyNDE4Ng==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400824186", "bodyText": "Why create it as a List<QueryDescription> only to convert to a Map<String, QueryDescription>? Why not just create as a map initially?\nAlso, why not make the map stronger typed, e.g. Map<QueryId, QueryDescription>?", "author": "big-andy-coates", "createdAt": "2020-03-31T11:01:36Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n+        }\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n-                q.getStatementString(),\n-                ImmutableSet.of(q.getSinkName().text()),\n-                ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n-                q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+        new ArrayList<>(queryToRunningQuery.values())));\n   }\n \n-}\n+  private static Optional<KsqlEntity> executeExtended(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    final List<QueryDescription> queryDescriptions = \n+        executionContext.getPersistentQueries().stream()\n+            .map(query -> {\n+              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+              ksqlHostQueryState.put(\n+                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                  query.getState());\n+              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }).collect(Collectors.toList());\n+\n+    final Map<String, QueryDescription> queryToQueryDescription =", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY1NjE4Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402656187", "bodyText": "done", "author": "stevenpyzhang", "createdAt": "2020-04-02T23:36:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyNDE4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzMjkyNw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400832927", "bodyText": "These executor services are not being shutdown, so they're a resource leak!", "author": "big-andy-coates", "createdAt": "2020-03-31T11:18:20Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY1NjIzMg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402656232", "bodyText": "shut down!", "author": "stevenpyzhang", "createdAt": "2020-04-02T23:37:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzMjkyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzNTQ5OQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400835499", "bodyText": "It may be sensible to add a timeout on this get() call, or at least ensure the ksqlClient is configured with sensible connect and read timeouts. We don't want this blocking indefinitely.", "author": "big-andy-coates", "createdAt": "2020-03-31T11:23:19Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzOTE4OA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400839188", "bodyText": ".getResponse throws unsupported operation on an error response!\nThis shouts \"Missing unit tests\" to me.  Can you add unit tests that:\na) return a failed RestResponse\nb) throw an exception from the Future.get.", "author": "big-andy-coates", "createdAt": "2020-03-31T11:30:13Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzI1NzI1MA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r403257250", "bodyText": "added a lot more tests to ListQueriesExecutorTest", "author": "stevenpyzhang", "createdAt": "2020-04-03T19:16:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzOTE4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg1NTkxNQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400855915", "bodyText": "nit: does not throw InterruptedException", "author": "big-andy-coates", "createdAt": "2020-03-31T12:01:02Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForClusterToBeDiscovered;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.Queries;\n+import io.confluent.ksql.rest.entity.QueryDescription;\n+import io.confluent.ksql.rest.entity.QueryDescriptionList;\n+import io.confluent.ksql.rest.entity.RunningQuery;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.test.util.secure.ClientTrustStore;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+\n+@Category({IntegrationTest.class})\n+public class ShowQueriesMultiNodeFunctionalTest {\n+\n+  private static final PageViewDataProvider PAGE_VIEWS_PROVIDER = new PageViewDataProvider();\n+  private static final String PAGE_VIEW_TOPIC = PAGE_VIEWS_PROVIDER.topicName();\n+  private static final String PAGE_VIEW_STREAM = PAGE_VIEWS_PROVIDER.kstreamName();\n+  private static final KsqlHostInfoEntity host0 = new KsqlHostInfoEntity(\"localhost\", 8088);\n+  private static final KsqlHostInfoEntity host1 = new KsqlHostInfoEntity(\"localhost\", 8089);\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+  private static final TestKsqlRestApp REST_APP_0 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .withProperties(ClientTrustStore.trustStoreProps())\n+      .build();\n+  private static final TestKsqlRestApp REST_APP_1 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8089\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8089\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .withProperties(ClientTrustStore.trustStoreProps())\n+      .build();\n+\n+  @ClassRule\n+  public static final RuleChain CHAIN = RuleChain\n+      .outerRule(Retry.of(3, ZooKeeperClientException.class, 3, TimeUnit.SECONDS))\n+      .around(TEST_HARNESS)\n+      .around(REST_APP_0)\n+      .around(REST_APP_1);\n+\n+  @BeforeClass\n+  public static void setUpClass() throws InterruptedException {", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2NTY2MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400865661", "bodyText": "I can replace this with a test that uses assertThatEventually which passes without any reliance on heartbeating:\n@Test\n  public void shouldShowAllQueries() {\n    // When:\n    final Supplier<String> app0Response = () -> getShowQueriesResult(REST_APP_0);\n    final Supplier<String> app1Response = () -> getShowQueriesResult(REST_APP_1);\n\n    // Then:\n    assertThatEventually(\"App0\", app0Response, is(\"RUNNING:2\"));\n    assertThatEventually(\"App1\", app1Response, is(\"RUNNING:2\"));\n  }\n\n  private static String getShowQueriesResult(final TestKsqlRestApp restApp) {\n    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n        restApp,\n        \"Show Queries;\"\n    );\n\n    if (results.size() != 1) {\n      return \"Expected 1 response, got \" + results.size();\n    }\n\n    final KsqlEntity result = results.get(0);\n\n    if (!(result instanceof Queries)) {\n      return \"Expected Queries, got \" + result;\n    }\n\n    final List<RunningQuery> runningQueries = ((Queries) result)\n        .getQueries();\n\n    if (runningQueries.size() != 1) {\n      return \"Expected 1 running query, got \" + runningQueries.size();\n    }\n\n    return runningQueries.get(0).getState().toString();\n  }\nSee if you can do the same for shouldShowAllQueriesExtended.", "author": "big-andy-coates", "createdAt": "2020-03-31T12:18:06Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForClusterToBeDiscovered;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.Queries;\n+import io.confluent.ksql.rest.entity.QueryDescription;\n+import io.confluent.ksql.rest.entity.QueryDescriptionList;\n+import io.confluent.ksql.rest.entity.RunningQuery;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.test.util.secure.ClientTrustStore;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+\n+@Category({IntegrationTest.class})\n+public class ShowQueriesMultiNodeFunctionalTest {\n+\n+  private static final PageViewDataProvider PAGE_VIEWS_PROVIDER = new PageViewDataProvider();\n+  private static final String PAGE_VIEW_TOPIC = PAGE_VIEWS_PROVIDER.topicName();\n+  private static final String PAGE_VIEW_STREAM = PAGE_VIEWS_PROVIDER.kstreamName();\n+  private static final KsqlHostInfoEntity host0 = new KsqlHostInfoEntity(\"localhost\", 8088);\n+  private static final KsqlHostInfoEntity host1 = new KsqlHostInfoEntity(\"localhost\", 8089);\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+  private static final TestKsqlRestApp REST_APP_0 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .withProperties(ClientTrustStore.trustStoreProps())\n+      .build();\n+  private static final TestKsqlRestApp REST_APP_1 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8089\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8089\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .withProperties(ClientTrustStore.trustStoreProps())\n+      .build();\n+\n+  @ClassRule\n+  public static final RuleChain CHAIN = RuleChain\n+      .outerRule(Retry.of(3, ZooKeeperClientException.class, 3, TimeUnit.SECONDS))\n+      .around(TEST_HARNESS)\n+      .around(REST_APP_0)\n+      .around(REST_APP_1);\n+\n+  @BeforeClass\n+  public static void setUpClass() throws InterruptedException {\n+    TEST_HARNESS.ensureTopics(2, PAGE_VIEW_TOPIC);\n+    TEST_HARNESS.produceRows(PAGE_VIEW_TOPIC, PAGE_VIEWS_PROVIDER, FormatFactory.JSON);\n+    RestIntegrationTestUtil.createStream(REST_APP_0, PAGE_VIEWS_PROVIDER);\n+    RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_0,\n+        \"CREATE STREAM S AS SELECT * FROM \" + PAGE_VIEW_STREAM + \";\"\n+    );\n+    waitForClusterToBeDiscovered(REST_APP_0, 2);\n+  }\n+\n+  @Test\n+  public void shouldShowAllQueries() {\n+    final List<KsqlEntity> allEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_0,\n+        \"Show Queries;\"\n+    );\n+\n+    final List<RunningQuery> allRunningQueries0 = ((Queries) allEntities0.get(0)).getQueries();\n+    assertThat(allRunningQueries0.size(), equalTo(1));\n+    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n+\n+    final List<KsqlEntity> allEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_1,\n+        \"Show Queries;\"\n+    );\n+\n+    final List<RunningQuery> allRunningQueries1 = ((Queries) allEntities1.get(0)).getQueries();\n+    assertThat(allRunningQueries1.size(), equalTo(1));\n+    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n+  }", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk2OTYzNQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401969635", "bodyText": "changed shouldShowAllQueriesExtended to use asserThatEventually", "author": "stevenpyzhang", "createdAt": "2020-04-01T23:33:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2NTY2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2NjcxMg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400866712", "bodyText": "There is a lot of code duplication in this class.  Let's break it down and see how we can remove this duplication!\nIt seems to me that this class needs to be able to:\n- get the local node's running queries\n- get the local node's extended query info\n- scatter-gather either of the above requests to all nodes.\nAt the moment the scatter-gather code is duplicated: once for each of the type of info we need to get back. But the logic is the same!  Hence we should try to have only one copy of that logic.\nMy approach to this would to refactor the code so that there is a pair pf method to get the two different types of local info, a pair of methods to do the merging of the two different types and a single method for doing the scatter gather.\nIf we do all that, then we end up with something like:\npublic final class ListQueriesExecutor {\n\n  private static final Logger LOG = LoggerFactory.getLogger(ListQueriesExecutor.class);\n\n  private ListQueriesExecutor() {\n  }\n\n  public static Optional<KsqlEntity> execute(\n      final ConfiguredStatement<ListQueries> statement,\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext,\n      final ServiceContext serviceContext\n  ) {\n    final List<KsqlEntity> remoteResults =\n        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n\n    return statement.getStatement().getShowExtended()\n        ? executeExtended(remoteResults, statement, sessionProperties, executionContext)\n        : executeSimple(remoteResults, statement, executionContext);\n  }\n\n  private static Optional<KsqlEntity> executeSimple(\n      final List<KsqlEntity> remoteResults,\n      final ConfiguredStatement<ListQueries> statement,\n      final KsqlExecutionContext executionContext\n  ) {\n    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n\n    mergeSimple(remoteResults, runningQueries);\n\n    return Optional.of(new Queries(\n        statement.getStatementText(),\n        new ArrayList<>(runningQueries.values())));\n  }\n\n  private static Map<QueryId, RunningQuery> getLocalSimple(\n      final KsqlExecutionContext executionContext\n  ) {\n    return executionContext.getPersistentQueries()\n        .stream()\n        .map(q -> {\n          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n          return new RunningQuery(\n              q.getStatementString(),\n              ImmutableSet.of(q.getSinkName().text()),\n              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n              q.getQueryId(),\n              kafkaStreamsStateCount\n          );\n        }).collect(Collectors.toMap(RunningQuery::getId, Function.identity()));\n  }\n\n  private static void mergeSimple(\n      final List<KsqlEntity> remoteResults,\n      final Map<QueryId, RunningQuery> allResults\n  ) {\n    remoteResults.stream()\n        .map(Queries.class::cast)\n        .map(Queries::getQueries)\n        .flatMap(List::stream)\n        .forEach(rq ->\n            allResults.compute(rq.getId(), (id, existing) -> {\n              if (existing == null) {\n                return rq;\n              }\n\n              for (Entry<KafkaStreams.State, Integer> entry : rq.getState().getState().entrySet()) {\n                existing\n                    .getState()\n                    .updateStateCount(entry.getKey(), entry.getValue());\n              }\n\n              return existing;\n            })\n        );\n  }\n\n  private static Optional<KsqlEntity> executeExtended(\n      final List<KsqlEntity> remoteResults,\n      final ConfiguredStatement<ListQueries> statement,\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext\n  ) {\n    final Map<QueryId, QueryDescription> queryDescriptions =\n        getLocalExtended(sessionProperties, executionContext);\n\n    mergeExtended(remoteResults, queryDescriptions);\n\n    return Optional.of(new QueryDescriptionList(\n        statement.getStatementText(),\n        new ArrayList<>(queryDescriptions.values())));\n  }\n\n  private static Map<QueryId, QueryDescription> getLocalExtended(\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext\n  ) {\n    return executionContext.getPersistentQueries().stream()\n        .map(query -> {\n          final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n          ksqlHostQueryState.put(\n              new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n              query.getState());\n          return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n        }).collect(Collectors.toMap(QueryDescription::getId, Function.identity()));\n  }\n\n  private static void mergeExtended(\n      final List<KsqlEntity> remoteResults,\n      final Map<QueryId, QueryDescription> allResults\n  ) {\n    remoteResults.stream()\n        .map(QueryDescriptionList.class::cast)\n        .map(QueryDescriptionList::getQueryDescriptions)\n        .flatMap(List::stream)\n        .forEach(qd ->\n            allResults.compute(qd.getId(), (id, existing) -> {\n              if (existing == null) {\n                return qd;\n              }\n\n              existing.getKsqlHostQueryState().putAll(qd.getKsqlHostQueryState());\n              return existing;\n            })\n        );\n  }\n\n  private static List<KsqlEntity> scatterGather(\n      final ConfiguredStatement<ListQueries> statement,\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext,\n      final ServiceContext serviceContext\n  ) {\n    if (sessionProperties.getInternalRequest()) {\n      return ImmutableList.of();\n    }\n\n    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n        executionContext.getPersistentQueries(),\n        sessionProperties.getKsqlHostInfo()\n    );\n\n    if (remoteHosts.isEmpty()) {\n      return ImmutableList.of();\n    }\n\n    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n\n    try {\n      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n\n      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futures = new HashMap<>();\n      for (HostInfo host : remoteHosts) {\n        final Future<RestResponse<KsqlEntityList>> f = executorService.submit(() -> ksqlClient\n            .makeKsqlRequestWithRequestProperties(\n                ServerUtil.buildRemoteUri(\n                    sessionProperties.getLocalUrl(),\n                    host.host(),\n                    host.port()\n                ),\n                statement.getStatementText(),\n                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n        );\n\n        futures.put(host, f);\n      }\n\n      // Todo: we should NOT ignore these failed hosts:  we should include this in the response.\n      final List<HostInfo> failedHosts = new ArrayList<>();\n      final List<KsqlEntity> results = new ArrayList<>();\n      for (final Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e : futures.entrySet()) {\n        try {\n          final RestResponse<KsqlEntityList> response = e.getValue().get();\n          if (response.isErroneous()) {\n            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n                e.getKey(), response.getErrorMessage().getMessage());\n            failedHosts.add(e.getKey());\n          } else {\n            results.add(response.getResponse().get(0));\n          }\n        } catch (final Exception cause) {\n          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n          failedHosts.add(e.getKey());\n        }\n      }\n\n      return results;\n    } finally {\n      executorService.shutdown();\n    }\n  }\n}", "author": "big-andy-coates", "createdAt": "2020-03-31T12:19:35Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjc3NDYzMg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402774632", "bodyText": "Thanks for the suggestion! I followed the outline and refactored the code.", "author": "stevenpyzhang", "createdAt": "2020-04-03T07:02:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2NjcxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2ODY0Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400868647", "bodyText": "Rather than create the KafkaStreamsStateCount here, why not just pass q.getState() to the RunningQuery constructor and internally create the KafkaStreamsStateCount instance?  Thereby removing code duplication...", "author": "big-andy-coates", "createdAt": "2020-03-31T12:22:29Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2OTEzNg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400869136", "bodyText": "No need for a concurrent collection type here. It's only being accessed by one thread...", "author": "big-andy-coates", "createdAt": "2020-03-31T12:23:08Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3MTYwNg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400871606", "bodyText": "Would be good to see tests added to cover when the passed map is NOT empty.", "author": "big-andy-coates", "createdAt": "2020-03-31T12:26:59Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/entity/QueryDescriptionFactoryTest.java", "diffHunk": "@@ -117,7 +117,7 @@ public void setUp() {\n         queryCloseCallback,\n         closeTimeout);\n \n-    transientQueryDescription = QueryDescriptionFactory.forQueryMetadata(transientQuery);\n+    transientQueryDescription = QueryDescriptionFactory.forQueryMetadata(transientQuery, Collections.emptyMap());", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk1NTM2OQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401955369", "bodyText": "The passed map should always be empty for now since the only way forQueryMetadata() would be called on a transient query would be in ExplainExecutor.explainStatement() and the query isn't actually running at that point", "author": "stevenpyzhang", "createdAt": "2020-04-01T22:50:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3MTYwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk1NzYzMQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r401957631", "bodyText": "after #4308 is completed, there should be tests with non-empty maps for transient queries", "author": "stevenpyzhang", "createdAt": "2020-04-01T22:56:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3MTYwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3NjI4MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400876281", "bodyText": "There's no need to parse APPLICATION_SERVER: you can just build it with known host & port.\nplease try and avoid subclassing HashMap just to add an entry.  Just using ImmutableMap.\n\nprivate static final String APPLICATION_HOST = \"localhost\";\n  private static final int APPLICATION_PORT = 9099;\n  private static final String APPLICATION_SERVER = \"http://\" + APPLICATION_HOST + \":\" + APPLICATION_PORT;\n\n...\n\n@Test\n  public void shouldShowQueriesExtended() {\n    // Given:\n    final Map<String, Object> overriddenProperties =\n        Collections.singletonMap(\"ksql.streams.auto.offset.reset\", \"earliest\");\n\n    final List<PersistentQueryMetadata> queryMetadata = createQueries(\n        \"CREATE STREAM test_describe_1 AS SELECT * FROM test_stream;\" +\n            \"CREATE STREAM test_describe_2 AS SELECT * FROM test_stream;\", overriddenProperties);\n\n    // When:\n    final QueryDescriptionList descriptionList = makeSingleRequest(\n        \"SHOW QUERIES EXTENDED;\", QueryDescriptionList.class);\n\n    // Then:\n    final Map<KsqlHostInfoEntity, String> queryHostState = ImmutableMap.of(\n        new KsqlHostInfoEntity(APPLICATION_HOST, APPLICATION_PORT),\n        \"CREATED\"\n    );\n\n    assertThat(descriptionList.getQueryDescriptions(), containsInAnyOrder(\n        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(0), queryHostState),\n        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(1), queryHostState)));\n  }", "author": "big-andy-coates", "createdAt": "2020-03-31T12:34:14Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java", "diffHunk": "@@ -539,10 +544,18 @@ public void shouldShowQueriesExtended() {\n     final QueryDescriptionList descriptionList = makeSingleRequest(\n         \"SHOW QUERIES EXTENDED;\", QueryDescriptionList.class);\n \n+    final HostInfo hostInfo = ServerUtil.parseHostInfo(APPLICATION_SERVER);\n+    final HashMap<KsqlHostInfoEntity, String> queryHostState = \n+        new HashMap<KsqlHostInfoEntity, String>(){{ \n+          put(\n+              new KsqlHostInfoEntity(hostInfo.host(), hostInfo.port()),\n+              \"CREATED\"\n+          );\n+    }};\n     // Then:\n     assertThat(descriptionList.getQueryDescriptions(), containsInAnyOrder(\n-        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(0)),\n-        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(1))));\n+        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(0), queryHostState),\n+        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(1), queryHostState)));", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3NzExMw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400877113", "bodyText": "The code would be a little cleaner If the KafkaStreamsStateCount constructor too the initial state, and used that to set that states count to 1.  You could then inline the construction.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                      final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n          \n          \n            \n                      kafkaStreamsStateCount.updateStateCount(md.getState(), 1);\n          \n          \n            \n                      final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount(md.getState());", "author": "big-andy-coates", "createdAt": "2020-03-31T12:35:40Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java", "diffHunk": "@@ -1981,14 +1994,17 @@ private PersistentQueryMetadata createQuery(\n \n     return createQueries(sql, overriddenProperties)\n         .stream()\n-        .map(md -> new RunningQuery(\n+        .map(md -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(md.getState(), 1);", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY0MDI4NQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402640285", "bodyText": "I think the introduction of this constructor public QueryStateCount(final Map<KafkaStreams.State, Integer> states) is sufficient for an initial state count", "author": "stevenpyzhang", "createdAt": "2020-04-02T22:49:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3NzExMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3ODU4OQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400878589", "bodyText": "Why not just inline this? i.e. make all the code that calls this just call the new version with the extra map param?\n(In case you're unaware IntelliJ can do this for you: with cursor on the function name, right click -> refactor -> inline method)", "author": "big-andy-coates", "createdAt": "2020-03-31T12:37:53Z", "path": "ksqldb-rest-client/src/main/java/io/confluent/ksql/rest/client/KsqlTarget.java", "diffHunk": "@@ -138,23 +138,31 @@ public KsqlTarget properties(final Map<String, ?> properties) {\n \n   public RestResponse<KsqlEntityList> postKsqlRequest(\n       final String ksql,\n+      final Map<String, ?> requestProperties,\n       final Optional<Long> previousCommandSeqNum\n   ) {\n     return post(\n         KSQL_PATH,\n-        createKsqlRequest(ksql, Collections.emptyMap(), previousCommandSeqNum),\n+        createKsqlRequest(ksql, requestProperties, previousCommandSeqNum),\n         r -> deserialize(r.getBody(), KsqlEntityList.class)\n     );\n   }\n+  \n+  public RestResponse<KsqlEntityList> postKsqlRequest(", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY1NjQ1Mw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402656453", "bodyText": "done", "author": "stevenpyzhang", "createdAt": "2020-04-02T23:37:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3ODU4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg4NTQ2Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400885467", "bodyText": "Would be nice to decouple this class from KafkaStream.State.  This enum is encapsulated by QueryMetadata deliberately.  If you would rather an enum that a String, (and I can understand you would), then add a new KSQL QueryState enum.   (This will probably be needed by @rodesai's work on query state anyway).\nAlso consider renaming this class to QueryStateCounts, which is less coupled to KS.", "author": "big-andy-coates", "createdAt": "2020-03-31T12:48:57Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import io.confluent.ksql.util.KsqlException;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class KafkaStreamsStateCount {\n+  \n+  // Use a EnumMap so toString() will always return the same string\n+  private final EnumMap<KafkaStreams.State, Integer> state;\n+\n+  public KafkaStreamsStateCount() {", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjcxOTkxMQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402719911", "bodyText": "Renamed the file, haven't gotten to the creating KSQL query state enums yet", "author": "stevenpyzhang", "createdAt": "2020-04-03T03:40:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg4NTQ2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5MzgyOQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400893829", "bodyText": "I'm a little confused by this class.  Why does it have all this code to convert to and from a string representation in the form <state>: <count>, <state>: <count>?  Why not just return this as a JSON Object?  The Jackson does all the heavy lifting for you!\n {\n     \"CREATED\": 1,\n     \"RUNNING\": 2\n}\nThis can be achieved with:\n@JsonIgnoreProperties(ignoreUnknown = true)\npublic class KafkaStreamsStateCount {\n\n  private final Map<State, Integer> states;\n\n  public KafkaStreamsStateCount() {\n    this.states = new HashMap<>();\n  }\n\n  @SuppressWarnings(\"unused\") // Invoked by reflection\n  @JsonCreator\n  public KafkaStreamsStateCount(final Map<State, Integer> states) {\n    this.states = new HashMap<>(states);\n  }\n\n  public void updateStateCount(final String state, final int change) {\n    updateStateCount(KafkaStreams.State.valueOf(state), change);\n  }\n\n  public void updateStateCount(final KafkaStreams.State state, final int change) {\n    states.compute(state, (key, existing) ->\n        existing == null\n            ? change\n            : existing + change\n    );\n  }\n\n  @JsonValue\n  public Map<KafkaStreams.State, Integer> getState() {\n    return states;\n  }\n\n  @Override\n  public boolean equals(final Object o) {\n    if (this == o) {\n      return true;\n    }\n\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n\n    final KafkaStreamsStateCount that = (KafkaStreamsStateCount) o;\n    return Objects.equals(states, that.states);\n  }\n\n  @Override\n  public int hashCode() {\n    return Objects.hash(states);\n  }\n}", "author": "big-andy-coates", "createdAt": "2020-03-31T13:01:29Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import io.confluent.ksql.util.KsqlException;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class KafkaStreamsStateCount {", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY0MDg4NQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402640885", "bodyText": "it's returned as a json object now, and the toString() representation is being used to populate the state field in the show queries output", "author": "stevenpyzhang", "createdAt": "2020-04-02T22:50:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5MzgyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5NjQ3NA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400896474", "bodyText": "Might be worth keeping the old state for a while as this will allow backwards compatibility for older CLI versions... i.e.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  @JsonProperty(\"state\") final KafkaStreamsStateCount state\n          \n          \n            \n                  @JsonProperty(\"state\") final Optional<String> state, // Kept for backwards compatibility.\n          \n          \n            \n                  @JsonProperty(\"stateCounts\") final KafkaStreamsStateCount stateCounts\n          \n      \n    \n    \n  \n\nand just populate the state string somehow, e.g. using the stateCounts string representation?  I think this would work as I think the old CLI just outputs this string as-is. Need to check though.", "author": "big-andy-coates", "createdAt": "2020-03-31T13:05:15Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java", "diffHunk": "@@ -31,15 +30,15 @@\n   private final Set<String> sinks;\n   private final Set<String> sinkKafkaTopics;\n   private final QueryId id;\n-  private final Optional<String> state;\n+  private final KafkaStreamsStateCount state;\n \n   @JsonCreator\n   public RunningQuery(\n       @JsonProperty(\"queryString\") final String queryString,\n       @JsonProperty(\"sinks\") final Set<String> sinks,\n       @JsonProperty(\"sinkKafkaTopics\") final Set<String> sinkKafkaTopics,\n       @JsonProperty(\"id\") final QueryId id,\n-      @JsonProperty(\"state\") final Optional<String> state\n+      @JsonProperty(\"state\") final KafkaStreamsStateCount state", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY0MDc5NQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402640795", "bodyText": "yea, I'm refactoring the output so that it'll be more backwards compatible here.", "author": "stevenpyzhang", "createdAt": "2020-04-02T22:50:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5NjQ3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5NzIwOA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400897208", "bodyText": "With the changes I suggested to make this object serialize as a JSON object you can add tests such as:\n@Test\n  public void shouldRoundTripWhenEmpty() {\n    // When:\n    final String json = assertDeserializedToSame(kafkaStreamsStateCount);\n\n    // Then:\n    assertThat(json, is(\"{}\"));\n  }\n\n  @Test\n  public void shouldRoundTripWhenNotEmpty() {\n    // Given:\n    kafkaStreamsStateCount.updateStateCount(State.RUNNING, 2);\n    kafkaStreamsStateCount.updateStateCount(State.CREATED, 10);\n\n    // When:\n    final String json = assertDeserializedToSame(kafkaStreamsStateCount);\n\n    // Then:\n    assertThat(json, is(\"{\"\n        + \"\\\"CREATED\\\":10,\"\n        + \"\\\"RUNNING\\\":2\"\n        + \"}\"));\n  }\n\n  private static String assertDeserializedToSame(final KafkaStreamsStateCount original) {\n    try {\n      final String json = MAPPER.writeValueAsString(original);\n\n      final KafkaStreamsStateCount deserialized = MAPPER\n          .readValue(json, KafkaStreamsStateCount.class);\n\n      assertThat(deserialized, is(original));\n\n      return json;\n    } catch (Exception e) {\n      throw new AssertionError(\"Failed to round trip\", e);\n    }\n  }", "author": "big-andy-coates", "createdAt": "2020-03-31T13:06:22Z", "path": "ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.ksql.util.KsqlException;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.Map;\n+\n+@SuppressWarnings(\"SameParameterValue\")\n+public class KafkaStreamsStateCountTest {", "originalCommit": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjY0MDU0MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r402640541", "bodyText": "added the tests", "author": "stevenpyzhang", "createdAt": "2020-04-02T22:49:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5NzIwOA=="}], "type": "inlineReview"}, {"oid": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "url": "https://github.com/confluentinc/ksql/commit/9abab589a7bfda4cc6a15271d0ea4807b974597f", "message": "addressing more comments", "committedDate": "2020-04-01T22:17:53Z", "type": "forcePushed"}, {"oid": "d4b8243ca0ae9157476193db226d7c0021976fb9", "url": "https://github.com/confluentinc/ksql/commit/d4b8243ca0ae9157476193db226d7c0021976fb9", "message": "addressing more comments", "committedDate": "2020-04-01T22:44:36Z", "type": "forcePushed"}, {"oid": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "url": "https://github.com/confluentinc/ksql/commit/a904008a542ae27a43a2fb5bd255a54ae00fcd55", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "committedDate": "2020-04-02T17:35:34Z", "type": "commit"}, {"oid": "4957a5c4a3edab330671adb712176c6e37cbd7da", "url": "https://github.com/confluentinc/ksql/commit/4957a5c4a3edab330671adb712176c6e37cbd7da", "message": "address comments", "committedDate": "2020-04-02T17:35:34Z", "type": "commit"}, {"oid": "653bc6806701e95d4493ff6bd261c220a095420c", "url": "https://github.com/confluentinc/ksql/commit/653bc6806701e95d4493ff6bd261c220a095420c", "message": "addressing more comments", "committedDate": "2020-04-02T17:35:34Z", "type": "commit"}, {"oid": "41f17ebde495835e6e126d4203cc324e61ca58e3", "url": "https://github.com/confluentinc/ksql/commit/41f17ebde495835e6e126d4203cc324e61ca58e3", "message": "refactor for backwards-compatability", "committedDate": "2020-04-02T22:21:49Z", "type": "forcePushed"}, {"oid": "293e001f7a95180faa8acee22006e4dd023c41de", "url": "https://github.com/confluentinc/ksql/commit/293e001f7a95180faa8acee22006e4dd023c41de", "message": "refactor for backwards-compatability", "committedDate": "2020-04-02T22:28:05Z", "type": "forcePushed"}, {"oid": "f8004d34f95b5a57a89361eac2935c8eff9a12c4", "url": "https://github.com/confluentinc/ksql/commit/f8004d34f95b5a57a89361eac2935c8eff9a12c4", "message": "refactor for backwards-compatability", "committedDate": "2020-04-02T23:10:36Z", "type": "forcePushed"}, {"oid": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "url": "https://github.com/confluentinc/ksql/commit/2b52197e3af9f3516cbd30435da8dd389a85c7a3", "message": "refactor for backwards-compatability", "committedDate": "2020-04-03T00:45:24Z", "type": "commit"}, {"oid": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "url": "https://github.com/confluentinc/ksql/commit/2b52197e3af9f3516cbd30435da8dd389a85c7a3", "message": "refactor for backwards-compatability", "committedDate": "2020-04-03T00:45:24Z", "type": "forcePushed"}, {"oid": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "url": "https://github.com/confluentinc/ksql/commit/9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "message": "refactor ListQueriesExecutor", "committedDate": "2020-04-03T07:01:39Z", "type": "commit"}, {"oid": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "url": "https://github.com/confluentinc/ksql/commit/9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "message": "refactor ListQueriesExecutor", "committedDate": "2020-04-03T07:01:39Z", "type": "forcePushed"}, {"oid": "2094b3f1ad442ed2642e50820ce0ab00bb969683", "url": "https://github.com/confluentinc/ksql/commit/2094b3f1ad442ed2642e50820ce0ab00bb969683", "message": "more unit tests", "committedDate": "2020-04-03T22:24:09Z", "type": "forcePushed"}, {"oid": "8c62c220495be00a406c5f0936fda64c140109a4", "url": "https://github.com/confluentinc/ksql/commit/8c62c220495be00a406c5f0936fda64c140109a4", "message": "more unit tests", "committedDate": "2020-04-03T22:44:50Z", "type": "forcePushed"}, {"oid": "27c42723a0ad44d98003cfdcc1f65bd15d7293d3", "url": "https://github.com/confluentinc/ksql/commit/27c42723a0ad44d98003cfdcc1f65bd15d7293d3", "message": "more unit tests", "committedDate": "2020-04-03T22:45:28Z", "type": "forcePushed"}, {"oid": "0d58bdfac00e58458eb64afbca33d5e729b3a5ca", "url": "https://github.com/confluentinc/ksql/commit/0d58bdfac00e58458eb64afbca33d5e729b3a5ca", "message": "more unit tests", "committedDate": "2020-04-06T16:45:24Z", "type": "forcePushed"}, {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3", "url": "https://github.com/confluentinc/ksql/commit/1825fd40b7926520ef42fd9c83174d83fec182f3", "message": "more unit tests", "committedDate": "2020-04-06T17:32:26Z", "type": "commit"}, {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3", "url": "https://github.com/confluentinc/ksql/commit/1825fd40b7926520ef42fd9c83174d83fec182f3", "message": "more unit tests", "committedDate": "2020-04-06T17:32:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMzQwNQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404733405", "bodyText": "As per #4875 (comment), and note in summary, I don't think this should be swallowed.", "author": "big-andy-coates", "createdAt": "2020-04-07T11:22:55Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, RunningQuery> getLocalSimple(\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            q -> new RunningQuery(\n                 q.getStatementString(),\n                 ImmutableSet.of(q.getSinkName().text()),\n                 ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n                 q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+                Optional.empty(),\n+                new QueryStateCount(\n+                    Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ));\n   }\n \n-}\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n+\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n+        statement.getStatementText(),\n+        queryDescriptions.values().stream().map(queryDescription -> \n+            new QueryDescription(\n+                queryDescription.getId(),\n+                queryDescription.getStatementText(),\n+                queryDescription.getWindowType(),\n+                queryDescription.getFields(),\n+                queryDescription.getSources(),\n+                queryDescription.getSinks(),\n+                queryDescription.getTopology(),\n+                queryDescription.getExecutionPlan(),\n+                queryDescription.getOverriddenProperties(),\n+                Optional.of(queryDescription.getKsqlHostQueryState().toString()),\n+                queryDescription.getKsqlHostQueryState()\n+            )\n+        ).collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Error response from host. host: {}, cause: {}\",", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMzQzNA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404733434", "bodyText": "As per #4875 (comment), and note in summary, I don't think this should be swallowed.", "author": "big-andy-coates", "createdAt": "2020-04-07T11:22:59Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, RunningQuery> getLocalSimple(\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            q -> new RunningQuery(\n                 q.getStatementString(),\n                 ImmutableSet.of(q.getSinkName().text()),\n                 ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n                 q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+                Optional.empty(),\n+                new QueryStateCount(\n+                    Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ));\n   }\n \n-}\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n+\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n+        statement.getStatementText(),\n+        queryDescriptions.values().stream().map(queryDescription -> \n+            new QueryDescription(\n+                queryDescription.getId(),\n+                queryDescription.getStatementText(),\n+                queryDescription.getWindowType(),\n+                queryDescription.getFields(),\n+                queryDescription.getSources(),\n+                queryDescription.getSinks(),\n+                queryDescription.getTopology(),\n+                queryDescription.getExecutionPlan(),\n+                queryDescription.getOverriddenProperties(),\n+                Optional.of(queryDescription.getKsqlHostQueryState().toString()),\n+                queryDescription.getKsqlHostQueryState()\n+            )\n+        ).collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Error response from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n+          } else {\n+            results.add(response.getResponse().get(0));\n+          }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMzk1Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404733957", "bodyText": "As per #4875 (comment):\n\nIt may be sensible to add a timeout on this get() call, or at least ensure the ksqlClient is configured with sensible connect and read timeouts. We don't want this blocking indefinitely.", "author": "big-andy-coates", "createdAt": "2020-04-07T11:23:58Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, RunningQuery> getLocalSimple(\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            q -> new RunningQuery(\n                 q.getStatementString(),\n                 ImmutableSet.of(q.getSinkName().text()),\n                 ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n                 q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+                Optional.empty(),\n+                new QueryStateCount(\n+                    Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ));\n   }\n \n-}\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n+\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n+        statement.getStatementText(),\n+        queryDescriptions.values().stream().map(queryDescription -> \n+            new QueryDescription(\n+                queryDescription.getId(),\n+                queryDescription.getStatementText(),\n+                queryDescription.getWindowType(),\n+                queryDescription.getFields(),\n+                queryDescription.getSources(),\n+                queryDescription.getSinks(),\n+                queryDescription.getTopology(),\n+                queryDescription.getExecutionPlan(),\n+                queryDescription.getOverriddenProperties(),\n+                Optional.of(queryDescription.getKsqlHostQueryState().toString()),\n+                queryDescription.getKsqlHostQueryState()\n+            )\n+        ).collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAzODEwNg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r405038106", "bodyText": "added a timeout", "author": "stevenpyzhang", "createdAt": "2020-04-07T18:52:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMzk1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczNzQ2Mg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404737462", "bodyText": "This creation of a new copy of each RunningQuery confused me at first. Then I realised you are probably doing this to set the legacy state field, right?   I've commented in RunningQuery explaining how you don't need to set state via the constructor - so this code to create new RunningQuerys can be removed.", "author": "big-andy-coates", "createdAt": "2020-04-07T11:30:24Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwMzI4NQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r405003285", "bodyText": "got rid of it now", "author": "stevenpyzhang", "createdAt": "2020-04-07T17:55:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczNzQ2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0MTYwNg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404741606", "bodyText": "A cleaner way (my bad) would be to remove this param from the constructor but to still have the getter. For example:\n  public Optional<String> getState() {\n    return stateCount.getStates().isEmpty()\n        ? Optional.empty()\n        : Optional.of(stateCount.toString());\n  }\n(You may even just be able to always return Optional.of(stateCount.toString())).\nI believe Jackson will then include state as a field in the json.  Though add a unit test for this.\nIf you're wondering how this can work, then remember we're keeping this field around for backwards compatibility and the old version of the CLI will have the old version of this class, which will still take state as a constructor param. Hence, all we need is the state in the Json. We don't need to be able to accept it as a constructor param any more.", "author": "big-andy-coates", "createdAt": "2020-04-07T11:38:22Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java", "diffHunk": "@@ -32,20 +32,23 @@\n   private final Set<String> sinkKafkaTopics;\n   private final QueryId id;\n   private final Optional<String> state;\n+  private final QueryStateCount stateCount;\n \n   @JsonCreator\n   public RunningQuery(\n       @JsonProperty(\"queryString\") final String queryString,\n       @JsonProperty(\"sinks\") final Set<String> sinks,\n       @JsonProperty(\"sinkKafkaTopics\") final Set<String> sinkKafkaTopics,\n       @JsonProperty(\"id\") final QueryId id,\n-      @JsonProperty(\"state\") final Optional<String> state\n+      @JsonProperty(\"state\") final Optional<String> state, // Kept for backwards compatibility.", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwNDE4Ng==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r405004186", "bodyText": "That makes sense.\nI had to fiddle around with it a bit, but it does work now.\n  @JsonProperty(\"state\")\n  public Optional<String> getState() {\n    return Optional.of(stateCount.toString());\n  }\n\nJust need to specify the @JsonProperty annotation on the getter to keep the field in the json output\nThe consoleTest basically tests the JSON output for RunningQuery so I didn't add any additional tests.", "author": "stevenpyzhang", "createdAt": "2020-04-07T17:57:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0MTYwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0MzcxNg==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404743716", "bodyText": "You can remove this code by following the same trick I've suggested for RunningQuery in QueryDescription.", "author": "big-andy-coates", "createdAt": "2020-04-07T11:42:30Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, RunningQuery> getLocalSimple(\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            q -> new RunningQuery(\n                 q.getStatementString(),\n                 ImmutableSet.of(q.getSinkName().text()),\n                 ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n                 q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+                Optional.empty(),\n+                new QueryStateCount(\n+                    Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ));\n   }\n \n-}\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n+\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n+        statement.getStatementText(),\n+        queryDescriptions.values().stream().map(queryDescription -> \n+            new QueryDescription(\n+                queryDescription.getId(),\n+                queryDescription.getStatementText(),\n+                queryDescription.getWindowType(),\n+                queryDescription.getFields(),\n+                queryDescription.getSources(),\n+                queryDescription.getSinks(),\n+                queryDescription.getTopology(),\n+                queryDescription.getExecutionPlan(),\n+                queryDescription.getOverriddenProperties(),\n+                Optional.of(queryDescription.getKsqlHostQueryState().toString()),\n+                queryDescription.getKsqlHostQueryState()", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxNDg0MQ==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r405014841", "bodyText": "done", "author": "stevenpyzhang", "createdAt": "2020-04-07T18:14:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0MzcxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0NzIxNA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404747214", "bodyText": "Consider adding an explanation of what the different statuses mean?  (Including UNRESPONSIVE when you do that).\nMind you, @rodesai is planning on simplifying the list... so maybe talk to him first.  I guess you can always add it and he can update it.", "author": "big-andy-coates", "createdAt": "2020-04-07T11:49:15Z", "path": "docs-md/developer-guide/ksqldb-reference/show-queries.md", "diffHunk": "@@ -13,16 +13,80 @@ Synopsis\n --------\r\n \r\n ```sql\r\n-SHOW QUERIES;\r\n+SHOW | LIST QUERIES [EXTENDED];\r\n ```\r\n \r\n Description\r\n -----------\r\n \r\n-List the running persistent queries.\r\n+`SHOW QUERIES` lists queries running in the cluster.\r\n+\r\n+`SHOW QUERIES EXTENDED` lists queries running in the cluster in more detail.\r\n \r\n Example\r\n -------\r\n \r\n-TODO: example\r\n+```sql\r\n+ksql> show queries;\r\n+\r\n+ Query ID    | Status    | Sink Name | Sink Kafka Topic | Query String                                                                                                                                \r\n+------------------------------------------------------------------------------------------------------------\r\n+ CSAS_TEST_0 | RUNNING:2 | TEST      | TEST             | CREATE STREAM TEST WITH (KAFKA_TOPIC='TEST', PARTITIONS=1, REPLICAS=1) AS SELECT *FROM KSQL_PROCESSING_LOG KSQL_PROCESSING_LOG EMIT CHANGES; \r", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAzNzk0Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r405037947", "bodyText": "I'll update the docs with explanation of the statuses when we move to our own query states.", "author": "stevenpyzhang", "createdAt": "2020-04-07T18:52:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0NzIxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0OTM4MA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404749380", "bodyText": "Just a suggestion, but...\nLet's say I'm running a 50 node cluster (!!!) and I know from running the none extended version of this command that 1 node is not happy. I'm running this command to find the one node's server name.... Searching through 50 of these host-status pairs will be a PITA.\nCan I suggest grouping the hosts by status?  (either server or client side, though server side is probably better). So that the output is more:\nHost Query Status.                 :  Running (49) : [host1, host2, host3, ... host 50]\n                                      Failed (1):  [host23]\n\nI think that would make your hard work much more useful to users.", "author": "big-andy-coates", "createdAt": "2020-04-07T11:53:28Z", "path": "docs-md/developer-guide/ksqldb-reference/show-queries.md", "diffHunk": "@@ -13,16 +13,80 @@ Synopsis\n --------\r\n \r\n ```sql\r\n-SHOW QUERIES;\r\n+SHOW | LIST QUERIES [EXTENDED];\r\n ```\r\n \r\n Description\r\n -----------\r\n \r\n-List the running persistent queries.\r\n+`SHOW QUERIES` lists queries running in the cluster.\r\n+\r\n+`SHOW QUERIES EXTENDED` lists queries running in the cluster in more detail.\r\n \r\n Example\r\n -------\r\n \r\n-TODO: example\r\n+```sql\r\n+ksql> show queries;\r\n+\r\n+ Query ID    | Status    | Sink Name | Sink Kafka Topic | Query String                                                                                                                                \r\n+------------------------------------------------------------------------------------------------------------\r\n+ CSAS_TEST_0 | RUNNING:2 | TEST      | TEST             | CREATE STREAM TEST WITH (KAFKA_TOPIC='TEST', PARTITIONS=1, REPLICAS=1) AS SELECT *FROM KSQL_PROCESSING_LOG KSQL_PROCESSING_LOG EMIT CHANGES; \r\n+------------------------------------------------------------------------------------------------------------\r\n+For detailed information on a Query run: EXPLAIN <Query ID>;\r\n+```\r\n+\r\n+\r\n+```sql\r\n+ksql> show queries extended;\r\n+\r\n+ID                   : CSAS_TEST_0\r\n+SQL                  : CREATE STREAM TEST WITH (KAFKA_TOPIC='TEST', PARTITIONS=1, REPLICAS=1) AS SELECT *\r\n+FROM KSQL_PROCESSING_LOG KSQL_PROCESSING_LOG\r\n+EMIT CHANGES;\r\n+Host Query Status    : {192.168.1.6:8088=RUNNING, 192.168.1.6:8089=RUNNING}\r", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAwNzgyMA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r405007820", "bodyText": "Wait, can't they just do a ctrl+f to search for it? I'm not sure the gain for reworking the output is really that much", "author": "stevenpyzhang", "createdAt": "2020-04-07T18:02:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0OTM4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTY5NzExMw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r405697113", "bodyText": "If you've worked in a role where you're responsible for large numbers of clusters of things you suddenly get a different view on how UIs / CLis should work ;)\nPersonally, I think its a worthwhile change.  At the moment the normal output gives you the counts and the extended gives you the hosts, but you lose the counts. Would be good if you kept the counts in extended...", "author": "big-andy-coates", "createdAt": "2020-04-08T17:35:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0OTM4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1Mjk3Mw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404752973", "bodyText": "Exposes mutable state of object, i.e. breaks encapsulation. I think this should still ensure consistent ordering:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                return ksqlHostQueryState;\n          \n          \n            \n                return Collections.unmodifyableMap(ksqlHostQueryState);\n          \n      \n    \n    \n  \n\nIf not, then you can always just store a normal map in the field and return:\n  final Map<x, y> orderedMap = new TreeMap<>(Comparator.comparing(KsqlHostInfoEntity::toString))\n   orderedMap.putAll(ksqlHostQueryState);\nreturn orderedMap;", "author": "big-andy-coates", "createdAt": "2020-04-07T12:00:15Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java", "diffHunk": "@@ -110,6 +121,10 @@ public String getExecutionPlan() {\n     return state;\n   }\n \n+  public Map<KsqlHostInfoEntity, String> getKsqlHostQueryState() {\n+    return ksqlHostQueryState;", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1MzE3NA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404753174", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private final TreeMap<KsqlHostInfoEntity, String> ksqlHostQueryState;\n          \n          \n            \n              private final Map<KsqlHostInfoEntity, String> ksqlHostQueryState;\n          \n      \n    \n    \n  \n\nIs sufficient, no?", "author": "big-andy-coates", "createdAt": "2020-04-07T12:00:40Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java", "diffHunk": "@@ -42,7 +45,9 @@\n   private final String executionPlan;\n   private final Map<String, Object> overriddenProperties;\n   private final Optional<String> state;\n+  private final TreeMap<KsqlHostInfoEntity, String> ksqlHostQueryState;", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1MzgxMw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404753813", "bodyText": "Would be good to add a unit test to test this is returning an ordered collection. (Or just JSON with ordered fields).", "author": "big-andy-coates", "createdAt": "2020-04-07T12:01:56Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java", "diffHunk": "@@ -68,6 +74,11 @@ public QueryDescription(\n     this.overriddenProperties = ImmutableMap.copyOf(Objects\n         .requireNonNull(overriddenProperties, \"overriddenProperties\"));\n     this.state = Objects.requireNonNull(state, \"state\");\n+    \n+    this.ksqlHostQueryState =\n+        new TreeMap<>(Comparator.comparing(KsqlHostInfoEntity::toString));\n+    this.ksqlHostQueryState\n+        .putAll(Objects.requireNonNull(ksqlHostQueryState, \"ksqlHostQueryState\"));", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAzOTI3Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r405039277", "bodyText": "I actually only wanted an ordered set because some of the new tests I added weren't working because the toString() of this map would return different results, but those tests don't rely on the string representation anymore since the state field was removed from the constructor so order doesn't matter for now.", "author": "stevenpyzhang", "createdAt": "2020-04-07T18:54:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1MzgxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1Mzk5OA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404753998", "bodyText": "Consider adding a unit test using EqualsTester if the class does not already have one.", "author": "big-andy-coates", "createdAt": "2020-04-07T12:02:17Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java", "diffHunk": "@@ -130,7 +145,8 @@ public boolean equals(final Object o) {\n         && Objects.equals(sources, that.sources)\n         && Objects.equals(sinks, that.sinks)\n         && Objects.equals(overriddenProperties, that.overriddenProperties)\n-        && Objects.equals(state, that.state);\n+        && Objects.equals(state, that.state)\n+        && Objects.equals(ksqlHostQueryState, that.ksqlHostQueryState);", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1NDQ5OA==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404754498", "bodyText": "Breaks encapsulation by returning mutable object state.  As above, wrap in unmodifyableMap.", "author": "big-andy-coates", "createdAt": "2020-04-07T12:03:17Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import com.google.common.base.Joiner;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class QueryStateCount {\n+  \n+  // Use a EnumMap so toString() will always return the same string\n+  private final EnumMap<KafkaStreams.State, Integer> states;\n+\n+  public QueryStateCount() {\n+    this.states = returnEnumMap();\n+  }\n+\n+  @SuppressWarnings(\"unused\") // Invoked by reflection\n+  @JsonCreator\n+  public QueryStateCount(final Map<KafkaStreams.State, Integer> states) {\n+    this.states = states.isEmpty() ? returnEnumMap() : new EnumMap<>(states);\n+  }\n+\n+  \n+  public void updateStateCount(final String state, final int change) {\n+    updateStateCount(KafkaStreams.State.valueOf(state), change);\n+  }\n+\n+  public void updateStateCount(final KafkaStreams.State state, final int change) {\n+    this.states.compute(state, (key, existing) ->\n+        existing == null\n+            ? change\n+            : existing + change);\n+    \n+  }\n+\n+  @JsonValue\n+  public Map<KafkaStreams.State, Integer> getStates() {\n+    return states;", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1NDc4Nw==", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404754787", "bodyText": "Add test using EqualsTester.", "author": "big-andy-coates", "createdAt": "2020-04-07T12:03:52Z", "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import com.google.common.base.Joiner;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class QueryStateCount {\n+  \n+  // Use a EnumMap so toString() will always return the same string\n+  private final EnumMap<KafkaStreams.State, Integer> states;\n+\n+  public QueryStateCount() {\n+    this.states = returnEnumMap();\n+  }\n+\n+  @SuppressWarnings(\"unused\") // Invoked by reflection\n+  @JsonCreator\n+  public QueryStateCount(final Map<KafkaStreams.State, Integer> states) {\n+    this.states = states.isEmpty() ? returnEnumMap() : new EnumMap<>(states);\n+  }\n+\n+  \n+  public void updateStateCount(final String state, final int change) {\n+    updateStateCount(KafkaStreams.State.valueOf(state), change);\n+  }\n+\n+  public void updateStateCount(final KafkaStreams.State state, final int change) {\n+    this.states.compute(state, (key, existing) ->\n+        existing == null\n+            ? change\n+            : existing + change);\n+    \n+  }\n+\n+  @JsonValue\n+  public Map<KafkaStreams.State, Integer> getStates() {\n+    return states;\n+  }\n+\n+  @Override\n+  public boolean equals(final Object o) {\n+    if (this == o) {\n+      return true;\n+    }\n+\n+    if (o == null || getClass() != o.getClass()) {\n+      return false;\n+    }\n+\n+    final QueryStateCount that = (QueryStateCount) o;\n+    return Objects.equals(states, that.states);\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return Objects.hash(states);\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return Joiner.on(\",\").withKeyValueSeparator(\":\").join(this.states);\n+  }", "originalCommit": "1825fd40b7926520ef42fd9c83174d83fec182f3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "url": "https://github.com/confluentinc/ksql/commit/9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "message": "last refactor", "committedDate": "2020-04-07T18:45:15Z", "type": "commit"}, {"oid": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "url": "https://github.com/confluentinc/ksql/commit/9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "message": "last refactor", "committedDate": "2020-04-07T18:45:15Z", "type": "forcePushed"}]}