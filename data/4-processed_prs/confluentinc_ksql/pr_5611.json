{"pr_number": 5611, "pr_title": "docs: KLIP-28 introduce CREATE OR REPLACE", "pr_createdAt": "2020-06-11T22:50:34Z", "pr_url": "https://github.com/confluentinc/ksql/pull/5611", "timeline": [{"oid": "aed31a2478e49956e469d11e11bccf74ef5c472c", "url": "https://github.com/confluentinc/ksql/commit/aed31a2478e49956e469d11e11bccf74ef5c472c", "message": "docs: KLIP-28 introduce CREATE OR REPLACE", "committedDate": "2020-06-11T22:40:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDgxODk0Mg==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440818942", "bodyText": "Does this include removing columns from the output schema, as well as adding columns?\nWhat about changing the type of a column?\nRemoving and changing the type of existing columns has implications for downstream queries. The simplest solution would be to not allow either of these in this first pass, but not sure of the intent of the KLIP from this statement.  Can we make sure the doc is clearer on this please?\nIMHO it's crucial that we ensure dumping the full database schema and running it on a fresh instance would succeed and result in all the same output schemas and data.", "author": "big-andy-coates", "createdAt": "2020-06-16T12:42:51Z", "path": "design-proposals/klip-28-create-or-replace", "diffHunk": "@@ -0,0 +1,156 @@\n+# KLIP 28 - Introduce CREATE OR REPLACE\n+\n+**Author**: agavra | \n+**Release Target**: 0.11 | \n+**Status**: _In Discussion_ | \n+**Discussion**: _link to the design discussion PR_\n+\n+**tl;dr:** _CREATE OR REPLACE is a mechanism geared toward enabling in-place ksqlDB query evolution._\n+           \n+## Motivation and background\n+\n+Production deployments of databases are never static; they evolve as application and business \n+requirements change. To that end, all popular data stores have ways of managing and manipulating \n+existing data. For stream processing applications, a user may want to modify their application as \n+a result of:\n+\n+- Business Requirements: requirements simply change over time\n+- Schema Evolution: the incoming data or required output has been modified\n+- Optimizations: the same application can be executed more efficiently (either by user or engine)\n+\n+At time of writing, ksqlDB provides a crude mechanism for altering its application behavior: dropping \n+a query and restarting it at the earliest or latest offset. While this often works well in development \n+environments, there are limitations to its applicability in production:\n+\n+- Data Retention: the earliest available offset may not correspond with the beginning of time\n+- Downtime: the delta between terminating and catch-up may be out of the application\u2019s SLO\n+- Output Routing: populating to the old output topic will produce duplicates while using a new output topic will require cascading migrations\n+- Compute: recomputing the complete history for a query may not be feasible\n+\n+Kafka Streams provides more granular mechanisms (e.g. restarting queries with different behaviors \n+but identical consumer groups), but these methods burden users with extra complexity and lack guardrails.\n+\n+## Scope\n+\n+To better understand the scope of this KLIP and any future improvements, we define a taxonomy on \n+query upgrades as any combination of three types of characteristics: **source query, upgrade** and\n+**environment**:\n+\n+| **Category** | **Characteristic** | **Description** |\n+|----------|----------------|-------------|\n+| Query | Stateful | Stateful queries maintain local storage |\n+| | Windowed | Windowed queries maintain a limited amount of state specified by a window in time\n+| | Joined | Joined queries read from multiple sources\n+| | Multistage | Multistage queries contain intermediate, non-user visible topics in Kafka\n+| | Nondeterministic | Nondeterministic queries may produce different results when executing identical input\n+| | Simple | Queries with none of the above characteristics\n+| Upgrade | Transparent | Transparent upgrades change the way something is computer (e.g. improving a UDF performance)\n+| | Data Selection | Data selecting query upgrades change which/how many events are emitted\n+| | Schema Evolution | Schema evolving query upgrades change the output type of the data |\n+| | Source Modifying | These upgrades change the source data, whether by means of modifying a JOIN or swapping out a source |\n+| | Topology | These upgrades are invisible to the user, but change the topology, such as the number of sub-topologies or the ordering of operations (e.g. filter push down) |\n+| | Scaling | Scaling upgrades change the physical properties of the query in order to enable better performance characteristics. |\n+| | Unsupported | Unsupported upgrades are ones that will semantically change the query in an unsupported way. There are no plans to implement these migrations. |\n+| Environment | Backfill | Backfill requires the output data to be accurate not just from a point in time, but from the earliest point of retained history |\n+| | Cascading | Cascading environments contain queries that are not terminal, but rather feed into downstream stream processing tasks |\n+| | Exactly Once | Exactly Once environments do not allow for data duplication or missed events |\n+| | Ordered | Ordered environments require that a single offset delineates pre- and post-migration (no events are interleaved) |\n+| | Live | Live environments describe queries that cannot afford downtime, either by means of acting as live storage (e.g. responding to pull queries) or feeding into high availability systems (powering important functionality) |\n+\n+### What is in scope\n+\n+- Specify a syntax that can support arbitrary upgrades\n+- Design a validator to fail unsupported upgrades\n+- Design a mechanism for upgrading queries under limited scope\n+\n+### What is not in scope\n+\n+The Design section below enumerates which upgrades are out of scope\n+\n+## Value/Return\n+\n+This KLIP will represent a significant step forward in the operability of ksqlDB in production, as\n+noted in the background and motivation section.\n+\n+## Public APIS\n+\n+The syntax `CREATE OR REPLACE (STREAM | TABLE) source_name WITH (key=value, ...) AS query;` will be\n+introduced to allow users to specify an existing stream or table to replace with a new query that\n+will resume from the same processing point as any previously existing query.\n+\n+## Design\n+\n+If the `source_name` does not yet exist, a `CREATE OR REPLACE` statement functions identically to\n+a normal `CREATE` statement. Otherwise, ksqlDB executes the following:\n+\n+1. Identify the original `queryID` that populates the source (`INSERT INTO` discussed later)\n+2. Ensure the upgrade is valid\n+3. Terminate `queryID`\n+4. Start the new query under the same `queryID`\n+\n+A few changes need to happen in order to make this work. For 1, we need to maintain a mapping from\n+source to queryID(s). If the source has multiple associated ids (in the case of `INSERT INTO`) then\n+the upgrade will fail and not terminate any queries.\n+\n+For step 2, there will be a component to determine whether two topologies are \"upgrade\n+compatible\"; the first iterations, which will be delivered as part of this KLIP, will only allow\n+for the most basic upgrades: \n+\n+- Any _transparent_ upgrade will be supported\n+- Any _data selection_ upgrade will be supported\n+- _Schema evolution_ upgrades will be supported on simple and stateful queries, but it will be", "originalCommit": "aed31a2478e49956e469d11e11bccf74ef5c472c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk1MDUzMQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440950531", "bodyText": "For example,\nLet's say we have:\nCREATE STREAM S1 AS \n   SELECT ID, NAME, COST FROM BLAH;\n\nCREATE STREAM S2 AS\n   SELECT ID, NAME FROM S1;\nBut then we run:\n-- drops the `NAME` column from the projection:\nCREATE OR REPLACE S1 AS\n   SELECT ID, COST FROM BLAH;\nNow S2 references a column in S1 that doesn't exist in the DB schema!  While this would work with formats that can support evolution and optional fields etc... it leaves the DB schema inconsistent, i.e. we lose referential integrity of the db schema.", "author": "big-andy-coates", "createdAt": "2020-06-16T15:39:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDgxODk0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk1MzAwMA==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440953000", "bodyText": "Personally, I'd go with not allowing rename / removing initially.\nLater we can build up system tables that track what columns are actually used in downstream queries and only allows you to remove / rename columns that aren't in use.", "author": "big-andy-coates", "createdAt": "2020-06-16T15:42:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDgxODk0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk1MzY3NQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440953675", "bodyText": "Would be interesting to see what a trad db does if you try and rename/remove a column in DB if its used in a materialized view?", "author": "big-andy-coates", "createdAt": "2020-06-16T15:43:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDgxODk0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk2MTgxMQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440961811", "bodyText": "@big-andy-coates I feel like this should follow the schema compatibility rules defined in schema registry, shouldn't it?\nIf schema registry isn't configured, maybe fall back to FORWARD, then one can only remove nullable fields, but I don't have a strong opinion on that", "author": "PeterLindner", "createdAt": "2020-06-16T15:54:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDgxODk0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk4NDMyMA==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440984320", "bodyText": "@PeterLinder originally I was thinking along the same lines as you, but I think Andy has me convinced. While removing fields would be acceptable from a data schema evolution perspective, the table schema evolution would be broken by removing fields that are used in downstream queries.", "author": "agavra", "createdAt": "2020-06-16T16:28:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDgxODk0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk5NDQyMg==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440994422", "bodyText": "Added:\nNote that _Schema Evolution_ compatibility is defined by the limitations of the serialization\nformat that is used with the added restrictions against removing fields and changing types to ensure\nreferential integrity of ksqlDB tables. This way, downstream query output schemas willn not be affected\nby upstream schema evolution.", "author": "agavra", "createdAt": "2020-06-16T16:43:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDgxODk0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjI0NTc4Ng==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r442245786", "bodyText": "Great! Though note its not just removing columns, but also renaming columns!", "author": "big-andy-coates", "createdAt": "2020-06-18T13:56:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDgxODk0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Mjk0MTcxNQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r442941715", "bodyText": "From my perspective, there isn't be a difference between removing and renaming (renaming=removing and adding). If I'm checking that all columns from the previous schema exist in the new one, if one was renamed that check would fail!", "author": "agavra", "createdAt": "2020-06-19T16:38:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDgxODk0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDgyMDIwOA==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440820208", "bodyText": "Missing details...", "author": "big-andy-coates", "createdAt": "2020-06-16T12:44:50Z", "path": "design-proposals/klip-28-create-or-replace", "diffHunk": "@@ -0,0 +1,156 @@\n+# KLIP 28 - Introduce CREATE OR REPLACE\n+\n+**Author**: agavra | \n+**Release Target**: 0.11 | \n+**Status**: _In Discussion_ | \n+**Discussion**: _link to the design discussion PR_\n+\n+**tl;dr:** _CREATE OR REPLACE is a mechanism geared toward enabling in-place ksqlDB query evolution._\n+           \n+## Motivation and background\n+\n+Production deployments of databases are never static; they evolve as application and business \n+requirements change. To that end, all popular data stores have ways of managing and manipulating \n+existing data. For stream processing applications, a user may want to modify their application as \n+a result of:\n+\n+- Business Requirements: requirements simply change over time\n+- Schema Evolution: the incoming data or required output has been modified\n+- Optimizations: the same application can be executed more efficiently (either by user or engine)\n+\n+At time of writing, ksqlDB provides a crude mechanism for altering its application behavior: dropping \n+a query and restarting it at the earliest or latest offset. While this often works well in development \n+environments, there are limitations to its applicability in production:\n+\n+- Data Retention: the earliest available offset may not correspond with the beginning of time\n+- Downtime: the delta between terminating and catch-up may be out of the application\u2019s SLO\n+- Output Routing: populating to the old output topic will produce duplicates while using a new output topic will require cascading migrations\n+- Compute: recomputing the complete history for a query may not be feasible\n+\n+Kafka Streams provides more granular mechanisms (e.g. restarting queries with different behaviors \n+but identical consumer groups), but these methods burden users with extra complexity and lack guardrails.\n+\n+## Scope\n+\n+To better understand the scope of this KLIP and any future improvements, we define a taxonomy on \n+query upgrades as any combination of three types of characteristics: **source query, upgrade** and\n+**environment**:\n+\n+| **Category** | **Characteristic** | **Description** |\n+|----------|----------------|-------------|\n+| Query | Stateful | Stateful queries maintain local storage |\n+| | Windowed | Windowed queries maintain a limited amount of state specified by a window in time\n+| | Joined | Joined queries read from multiple sources\n+| | Multistage | Multistage queries contain intermediate, non-user visible topics in Kafka\n+| | Nondeterministic | Nondeterministic queries may produce different results when executing identical input\n+| | Simple | Queries with none of the above characteristics\n+| Upgrade | Transparent | Transparent upgrades change the way something is computer (e.g. improving a UDF performance)\n+| | Data Selection | Data selecting query upgrades change which/how many events are emitted\n+| | Schema Evolution | Schema evolving query upgrades change the output type of the data |\n+| | Source Modifying | These upgrades change the source data, whether by means of modifying a JOIN or swapping out a source |\n+| | Topology | These upgrades are invisible to the user, but change the topology, such as the number of sub-topologies or the ordering of operations (e.g. filter push down) |\n+| | Scaling | Scaling upgrades change the physical properties of the query in order to enable better performance characteristics. |\n+| | Unsupported | Unsupported upgrades are ones that will semantically change the query in an unsupported way. There are no plans to implement these migrations. |\n+| Environment | Backfill | Backfill requires the output data to be accurate not just from a point in time, but from the earliest point of retained history |\n+| | Cascading | Cascading environments contain queries that are not terminal, but rather feed into downstream stream processing tasks |\n+| | Exactly Once | Exactly Once environments do not allow for data duplication or missed events |\n+| | Ordered | Ordered environments require that a single offset delineates pre- and post-migration (no events are interleaved) |\n+| | Live | Live environments describe queries that cannot afford downtime, either by means of acting as live storage (e.g. responding to pull queries) or feeding into high availability systems (powering important functionality) |\n+\n+### What is in scope\n+\n+- Specify a syntax that can support arbitrary upgrades\n+- Design a validator to fail unsupported upgrades\n+- Design a mechanism for upgrading queries under limited scope\n+\n+### What is not in scope\n+\n+The Design section below enumerates which upgrades are out of scope\n+\n+## Value/Return\n+\n+This KLIP will represent a significant step forward in the operability of ksqlDB in production, as\n+noted in the background and motivation section.\n+\n+## Public APIS\n+\n+The syntax `CREATE OR REPLACE (STREAM | TABLE) source_name WITH (key=value, ...) AS query;` will be\n+introduced to allow users to specify an existing stream or table to replace with a new query that\n+will resume from the same processing point as any previously existing query.\n+\n+## Design\n+\n+If the `source_name` does not yet exist, a `CREATE OR REPLACE` statement functions identically to\n+a normal `CREATE` statement. Otherwise, ksqlDB executes the following:\n+\n+1. Identify the original `queryID` that populates the source (`INSERT INTO` discussed later)\n+2. Ensure the upgrade is valid\n+3. Terminate `queryID`\n+4. Start the new query under the same `queryID`\n+\n+A few changes need to happen in order to make this work. For 1, we need to maintain a mapping from\n+source to queryID(s). If the source has multiple associated ids (in the case of `INSERT INTO`) then\n+the upgrade will fail and not terminate any queries.\n+\n+For step 2, there will be a component to determine whether two topologies are \"upgrade\n+compatible\"; the first iterations, which will be delivered as part of this KLIP, will only allow\n+for the most basic upgrades: \n+\n+- Any _transparent_ upgrade will be supported\n+- Any _data selection_ upgrade will be supported\n+- _Schema evolution_ upgrades will be supported on simple and stateful queries, but it will be\n+    communicated that the users will not get `backfill` or `ordered` properties for stateful.\n+- _Source modifying_ upgrades will not be supported\n+- _Topology changes_ will not be supported\n+\n+There are currently discussions that discuss how to expand the support of some of these upgrades,\n+but we believe there is value in supporting the limitted set described above.\n+\n+For step 4, we need to be able to generate queryIDs differently for `CREATE OR REPLACE` statements\n+than for others (i.e. it shouldn't just be the offset of the command, but rather the same queryID \n+as the original query.) One simple way to implement this is to allow the queryID to be specified\n+in the command topic. Since the engine receiving the request has a complete view of the engine\n+metadata, it can determine the queryID to enqueue onto the command topic.\n+\n+### On \"INSERT INTO\"\n+\n+Insert into can eventually be replaced with `UNION` as proposed in [KLIP-17](https://github.com/confluentinc/ksql/pull/4125),\n+but that must happen in lock-step with this proposal. At first, we will support `CREATE OR REPLACE`\n+and `INSERT INTO`. Then, we will add support for `UNION`, allowing us to model consecutive `INSERT INTO`\n+statements as replacing unions with larger unions (essentially adding an extra source to the union).\n+The approach for that will require a slight modification to the four steps outlined in the design\n+section above.\n+\n+## Test plan\n+\n+_What are the failure scenarios you are going to cover in your testing? What scale testing do you plan to run? What about peformance and load testing? It goes ", "originalCommit": "aed31a2478e49956e469d11e11bccf74ef5c472c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTAyMTUyNw==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r441021527", "bodyText": "added a section", "author": "agavra", "createdAt": "2020-06-16T17:28:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDgyMDIwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDgyMTEzMw==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440821133", "bodyText": "Rather than add a new file, can we not just add the OR REPLACE bit to the current CREATE TABLE AS and CREATE STREAM AS documentation?", "author": "big-andy-coates", "createdAt": "2020-06-16T12:46:21Z", "path": "design-proposals/klip-28-create-or-replace", "diffHunk": "@@ -0,0 +1,156 @@\n+# KLIP 28 - Introduce CREATE OR REPLACE\n+\n+**Author**: agavra | \n+**Release Target**: 0.11 | \n+**Status**: _In Discussion_ | \n+**Discussion**: _link to the design discussion PR_\n+\n+**tl;dr:** _CREATE OR REPLACE is a mechanism geared toward enabling in-place ksqlDB query evolution._\n+           \n+## Motivation and background\n+\n+Production deployments of databases are never static; they evolve as application and business \n+requirements change. To that end, all popular data stores have ways of managing and manipulating \n+existing data. For stream processing applications, a user may want to modify their application as \n+a result of:\n+\n+- Business Requirements: requirements simply change over time\n+- Schema Evolution: the incoming data or required output has been modified\n+- Optimizations: the same application can be executed more efficiently (either by user or engine)\n+\n+At time of writing, ksqlDB provides a crude mechanism for altering its application behavior: dropping \n+a query and restarting it at the earliest or latest offset. While this often works well in development \n+environments, there are limitations to its applicability in production:\n+\n+- Data Retention: the earliest available offset may not correspond with the beginning of time\n+- Downtime: the delta between terminating and catch-up may be out of the application\u2019s SLO\n+- Output Routing: populating to the old output topic will produce duplicates while using a new output topic will require cascading migrations\n+- Compute: recomputing the complete history for a query may not be feasible\n+\n+Kafka Streams provides more granular mechanisms (e.g. restarting queries with different behaviors \n+but identical consumer groups), but these methods burden users with extra complexity and lack guardrails.\n+\n+## Scope\n+\n+To better understand the scope of this KLIP and any future improvements, we define a taxonomy on \n+query upgrades as any combination of three types of characteristics: **source query, upgrade** and\n+**environment**:\n+\n+| **Category** | **Characteristic** | **Description** |\n+|----------|----------------|-------------|\n+| Query | Stateful | Stateful queries maintain local storage |\n+| | Windowed | Windowed queries maintain a limited amount of state specified by a window in time\n+| | Joined | Joined queries read from multiple sources\n+| | Multistage | Multistage queries contain intermediate, non-user visible topics in Kafka\n+| | Nondeterministic | Nondeterministic queries may produce different results when executing identical input\n+| | Simple | Queries with none of the above characteristics\n+| Upgrade | Transparent | Transparent upgrades change the way something is computer (e.g. improving a UDF performance)\n+| | Data Selection | Data selecting query upgrades change which/how many events are emitted\n+| | Schema Evolution | Schema evolving query upgrades change the output type of the data |\n+| | Source Modifying | These upgrades change the source data, whether by means of modifying a JOIN or swapping out a source |\n+| | Topology | These upgrades are invisible to the user, but change the topology, such as the number of sub-topologies or the ordering of operations (e.g. filter push down) |\n+| | Scaling | Scaling upgrades change the physical properties of the query in order to enable better performance characteristics. |\n+| | Unsupported | Unsupported upgrades are ones that will semantically change the query in an unsupported way. There are no plans to implement these migrations. |\n+| Environment | Backfill | Backfill requires the output data to be accurate not just from a point in time, but from the earliest point of retained history |\n+| | Cascading | Cascading environments contain queries that are not terminal, but rather feed into downstream stream processing tasks |\n+| | Exactly Once | Exactly Once environments do not allow for data duplication or missed events |\n+| | Ordered | Ordered environments require that a single offset delineates pre- and post-migration (no events are interleaved) |\n+| | Live | Live environments describe queries that cannot afford downtime, either by means of acting as live storage (e.g. responding to pull queries) or feeding into high availability systems (powering important functionality) |\n+\n+### What is in scope\n+\n+- Specify a syntax that can support arbitrary upgrades\n+- Design a validator to fail unsupported upgrades\n+- Design a mechanism for upgrading queries under limited scope\n+\n+### What is not in scope\n+\n+The Design section below enumerates which upgrades are out of scope\n+\n+## Value/Return\n+\n+This KLIP will represent a significant step forward in the operability of ksqlDB in production, as\n+noted in the background and motivation section.\n+\n+## Public APIS\n+\n+The syntax `CREATE OR REPLACE (STREAM | TABLE) source_name WITH (key=value, ...) AS query;` will be\n+introduced to allow users to specify an existing stream or table to replace with a new query that\n+will resume from the same processing point as any previously existing query.\n+\n+## Design\n+\n+If the `source_name` does not yet exist, a `CREATE OR REPLACE` statement functions identically to\n+a normal `CREATE` statement. Otherwise, ksqlDB executes the following:\n+\n+1. Identify the original `queryID` that populates the source (`INSERT INTO` discussed later)\n+2. Ensure the upgrade is valid\n+3. Terminate `queryID`\n+4. Start the new query under the same `queryID`\n+\n+A few changes need to happen in order to make this work. For 1, we need to maintain a mapping from\n+source to queryID(s). If the source has multiple associated ids (in the case of `INSERT INTO`) then\n+the upgrade will fail and not terminate any queries.\n+\n+For step 2, there will be a component to determine whether two topologies are \"upgrade\n+compatible\"; the first iterations, which will be delivered as part of this KLIP, will only allow\n+for the most basic upgrades: \n+\n+- Any _transparent_ upgrade will be supported\n+- Any _data selection_ upgrade will be supported\n+- _Schema evolution_ upgrades will be supported on simple and stateful queries, but it will be\n+    communicated that the users will not get `backfill` or `ordered` properties for stateful.\n+- _Source modifying_ upgrades will not be supported\n+- _Topology changes_ will not be supported\n+\n+There are currently discussions that discuss how to expand the support of some of these upgrades,\n+but we believe there is value in supporting the limitted set described above.\n+\n+For step 4, we need to be able to generate queryIDs differently for `CREATE OR REPLACE` statements\n+than for others (i.e. it shouldn't just be the offset of the command, but rather the same queryID \n+as the original query.) One simple way to implement this is to allow the queryID to be specified\n+in the command topic. Since the engine receiving the request has a complete view of the engine\n+metadata, it can determine the queryID to enqueue onto the command topic.\n+\n+### On \"INSERT INTO\"\n+\n+Insert into can eventually be replaced with `UNION` as proposed in [KLIP-17](https://github.com/confluentinc/ksql/pull/4125),\n+but that must happen in lock-step with this proposal. At first, we will support `CREATE OR REPLACE`\n+and `INSERT INTO`. Then, we will add support for `UNION`, allowing us to model consecutive `INSERT INTO`\n+statements as replacing unions with larger unions (essentially adding an extra source to the union).\n+The approach for that will require a slight modification to the four steps outlined in the design\n+section above.\n+\n+## Test plan\n+\n+_What are the failure scenarios you are going to cover in your testing? What scale testing do you plan to run? What about peformance and load testing? It goes \n+without saying that most classes should have unit tests._\n+\n+## Documentation Updates\n+\n+We will add the following `md` file:\n+\n+### Synopsis:\n+\n+```sql\n+CREATE OR REPLACE (STREAM | TABLE) source_name \n+    [WITH ( property_name = expression [, ...] )]\n+    AS query;\n+```", "originalCommit": "aed31a2478e49956e469d11e11bccf74ef5c472c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDkzNjQ2Mw==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440936463", "bodyText": "+1", "author": "rmoff", "createdAt": "2020-06-16T15:20:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDgyMTEzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDgyNjIzOA==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440826238", "bodyText": "One simple way to implement this is to allow the queryID to be specified in the command topic.\n\nFYI, the query plan already includes the query id.", "author": "big-andy-coates", "createdAt": "2020-06-16T12:54:33Z", "path": "design-proposals/klip-28-create-or-replace", "diffHunk": "@@ -0,0 +1,156 @@\n+# KLIP 28 - Introduce CREATE OR REPLACE\n+\n+**Author**: agavra | \n+**Release Target**: 0.11 | \n+**Status**: _In Discussion_ | \n+**Discussion**: _link to the design discussion PR_\n+\n+**tl;dr:** _CREATE OR REPLACE is a mechanism geared toward enabling in-place ksqlDB query evolution._\n+           \n+## Motivation and background\n+\n+Production deployments of databases are never static; they evolve as application and business \n+requirements change. To that end, all popular data stores have ways of managing and manipulating \n+existing data. For stream processing applications, a user may want to modify their application as \n+a result of:\n+\n+- Business Requirements: requirements simply change over time\n+- Schema Evolution: the incoming data or required output has been modified\n+- Optimizations: the same application can be executed more efficiently (either by user or engine)\n+\n+At time of writing, ksqlDB provides a crude mechanism for altering its application behavior: dropping \n+a query and restarting it at the earliest or latest offset. While this often works well in development \n+environments, there are limitations to its applicability in production:\n+\n+- Data Retention: the earliest available offset may not correspond with the beginning of time\n+- Downtime: the delta between terminating and catch-up may be out of the application\u2019s SLO\n+- Output Routing: populating to the old output topic will produce duplicates while using a new output topic will require cascading migrations\n+- Compute: recomputing the complete history for a query may not be feasible\n+\n+Kafka Streams provides more granular mechanisms (e.g. restarting queries with different behaviors \n+but identical consumer groups), but these methods burden users with extra complexity and lack guardrails.\n+\n+## Scope\n+\n+To better understand the scope of this KLIP and any future improvements, we define a taxonomy on \n+query upgrades as any combination of three types of characteristics: **source query, upgrade** and\n+**environment**:\n+\n+| **Category** | **Characteristic** | **Description** |\n+|----------|----------------|-------------|\n+| Query | Stateful | Stateful queries maintain local storage |\n+| | Windowed | Windowed queries maintain a limited amount of state specified by a window in time\n+| | Joined | Joined queries read from multiple sources\n+| | Multistage | Multistage queries contain intermediate, non-user visible topics in Kafka\n+| | Nondeterministic | Nondeterministic queries may produce different results when executing identical input\n+| | Simple | Queries with none of the above characteristics\n+| Upgrade | Transparent | Transparent upgrades change the way something is computer (e.g. improving a UDF performance)\n+| | Data Selection | Data selecting query upgrades change which/how many events are emitted\n+| | Schema Evolution | Schema evolving query upgrades change the output type of the data |\n+| | Source Modifying | These upgrades change the source data, whether by means of modifying a JOIN or swapping out a source |\n+| | Topology | These upgrades are invisible to the user, but change the topology, such as the number of sub-topologies or the ordering of operations (e.g. filter push down) |\n+| | Scaling | Scaling upgrades change the physical properties of the query in order to enable better performance characteristics. |\n+| | Unsupported | Unsupported upgrades are ones that will semantically change the query in an unsupported way. There are no plans to implement these migrations. |\n+| Environment | Backfill | Backfill requires the output data to be accurate not just from a point in time, but from the earliest point of retained history |\n+| | Cascading | Cascading environments contain queries that are not terminal, but rather feed into downstream stream processing tasks |\n+| | Exactly Once | Exactly Once environments do not allow for data duplication or missed events |\n+| | Ordered | Ordered environments require that a single offset delineates pre- and post-migration (no events are interleaved) |\n+| | Live | Live environments describe queries that cannot afford downtime, either by means of acting as live storage (e.g. responding to pull queries) or feeding into high availability systems (powering important functionality) |\n+\n+### What is in scope\n+\n+- Specify a syntax that can support arbitrary upgrades\n+- Design a validator to fail unsupported upgrades\n+- Design a mechanism for upgrading queries under limited scope\n+\n+### What is not in scope\n+\n+The Design section below enumerates which upgrades are out of scope\n+\n+## Value/Return\n+\n+This KLIP will represent a significant step forward in the operability of ksqlDB in production, as\n+noted in the background and motivation section.\n+\n+## Public APIS\n+\n+The syntax `CREATE OR REPLACE (STREAM | TABLE) source_name WITH (key=value, ...) AS query;` will be\n+introduced to allow users to specify an existing stream or table to replace with a new query that\n+will resume from the same processing point as any previously existing query.\n+\n+## Design\n+\n+If the `source_name` does not yet exist, a `CREATE OR REPLACE` statement functions identically to\n+a normal `CREATE` statement. Otherwise, ksqlDB executes the following:\n+\n+1. Identify the original `queryID` that populates the source (`INSERT INTO` discussed later)\n+2. Ensure the upgrade is valid\n+3. Terminate `queryID`\n+4. Start the new query under the same `queryID`\n+\n+A few changes need to happen in order to make this work. For 1, we need to maintain a mapping from\n+source to queryID(s). If the source has multiple associated ids (in the case of `INSERT INTO`) then\n+the upgrade will fail and not terminate any queries.\n+\n+For step 2, there will be a component to determine whether two topologies are \"upgrade\n+compatible\"; the first iterations, which will be delivered as part of this KLIP, will only allow\n+for the most basic upgrades: \n+\n+- Any _transparent_ upgrade will be supported\n+- Any _data selection_ upgrade will be supported\n+- _Schema evolution_ upgrades will be supported on simple and stateful queries, but it will be\n+    communicated that the users will not get `backfill` or `ordered` properties for stateful.\n+- _Source modifying_ upgrades will not be supported\n+- _Topology changes_ will not be supported\n+\n+There are currently discussions that discuss how to expand the support of some of these upgrades,\n+but we believe there is value in supporting the limitted set described above.\n+\n+For step 4, we need to be able to generate queryIDs differently for `CREATE OR REPLACE` statements\n+than for others (i.e. it shouldn't just be the offset of the command, but rather the same queryID \n+as the original query.) One simple way to implement this is to allow the queryID to be specified", "originalCommit": "aed31a2478e49956e469d11e11bccf74ef5c472c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDkyODYzOA==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440928638", "bodyText": "Instead of\n\nbut these methods burden users with extra complexity and lack guardrails\n\nhow about\n\nbut to directly expose these methods to users through ksqlDB would burden them with extra complexity and lack guardrails\n\nOr, perhaps I'm misunderstanding the intention here?", "author": "rmoff", "createdAt": "2020-06-16T15:11:48Z", "path": "design-proposals/klip-28-create-or-replace", "diffHunk": "@@ -0,0 +1,156 @@\n+# KLIP 28 - Introduce CREATE OR REPLACE\n+\n+**Author**: agavra | \n+**Release Target**: 0.11 | \n+**Status**: _In Discussion_ | \n+**Discussion**: _link to the design discussion PR_\n+\n+**tl;dr:** _CREATE OR REPLACE is a mechanism geared toward enabling in-place ksqlDB query evolution._\n+           \n+## Motivation and background\n+\n+Production deployments of databases are never static; they evolve as application and business \n+requirements change. To that end, all popular data stores have ways of managing and manipulating \n+existing data. For stream processing applications, a user may want to modify their application as \n+a result of:\n+\n+- Business Requirements: requirements simply change over time\n+- Schema Evolution: the incoming data or required output has been modified\n+- Optimizations: the same application can be executed more efficiently (either by user or engine)\n+\n+At time of writing, ksqlDB provides a crude mechanism for altering its application behavior: dropping \n+a query and restarting it at the earliest or latest offset. While this often works well in development \n+environments, there are limitations to its applicability in production:\n+\n+- Data Retention: the earliest available offset may not correspond with the beginning of time\n+- Downtime: the delta between terminating and catch-up may be out of the application\u2019s SLO\n+- Output Routing: populating to the old output topic will produce duplicates while using a new output topic will require cascading migrations\n+- Compute: recomputing the complete history for a query may not be feasible\n+\n+Kafka Streams provides more granular mechanisms (e.g. restarting queries with different behaviors \n+but identical consumer groups), but these methods burden users with extra complexity and lack guardrails.", "originalCommit": "aed31a2478e49956e469d11e11bccf74ef5c472c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk4NTI1OQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440985259", "bodyText": "I think both statements are true - the intention in this KLIP is also to call out that there are improvements that need to be made in Kafka Streams to ensure that an upgrade is valid. Some of that burden will be on KSQL in the short term, but the intention is to address some of these concerns inside Kafka Streams as well", "author": "agavra", "createdAt": "2020-06-16T16:30:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDkyODYzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDkzMzc4OA==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440933788", "bodyText": "Which Environment would be for a Simple query that didn't require backfill? For example, a query with a predicate that needed to be changed but only future-processed records needed to reflect it (an example would be changing the alert threshold for a monitor)", "author": "rmoff", "createdAt": "2020-06-16T15:18:18Z", "path": "design-proposals/klip-28-create-or-replace", "diffHunk": "@@ -0,0 +1,156 @@\n+# KLIP 28 - Introduce CREATE OR REPLACE\n+\n+**Author**: agavra | \n+**Release Target**: 0.11 | \n+**Status**: _In Discussion_ | \n+**Discussion**: _link to the design discussion PR_\n+\n+**tl;dr:** _CREATE OR REPLACE is a mechanism geared toward enabling in-place ksqlDB query evolution._\n+           \n+## Motivation and background\n+\n+Production deployments of databases are never static; they evolve as application and business \n+requirements change. To that end, all popular data stores have ways of managing and manipulating \n+existing data. For stream processing applications, a user may want to modify their application as \n+a result of:\n+\n+- Business Requirements: requirements simply change over time\n+- Schema Evolution: the incoming data or required output has been modified\n+- Optimizations: the same application can be executed more efficiently (either by user or engine)\n+\n+At time of writing, ksqlDB provides a crude mechanism for altering its application behavior: dropping \n+a query and restarting it at the earliest or latest offset. While this often works well in development \n+environments, there are limitations to its applicability in production:\n+\n+- Data Retention: the earliest available offset may not correspond with the beginning of time\n+- Downtime: the delta between terminating and catch-up may be out of the application\u2019s SLO\n+- Output Routing: populating to the old output topic will produce duplicates while using a new output topic will require cascading migrations\n+- Compute: recomputing the complete history for a query may not be feasible\n+\n+Kafka Streams provides more granular mechanisms (e.g. restarting queries with different behaviors \n+but identical consumer groups), but these methods burden users with extra complexity and lack guardrails.\n+\n+## Scope\n+\n+To better understand the scope of this KLIP and any future improvements, we define a taxonomy on \n+query upgrades as any combination of three types of characteristics: **source query, upgrade** and\n+**environment**:\n+\n+| **Category** | **Characteristic** | **Description** |\n+|----------|----------------|-------------|\n+| Query | Stateful | Stateful queries maintain local storage |\n+| | Windowed | Windowed queries maintain a limited amount of state specified by a window in time\n+| | Joined | Joined queries read from multiple sources\n+| | Multistage | Multistage queries contain intermediate, non-user visible topics in Kafka\n+| | Nondeterministic | Nondeterministic queries may produce different results when executing identical input\n+| | Simple | Queries with none of the above characteristics\n+| Upgrade | Transparent | Transparent upgrades change the way something is computer (e.g. improving a UDF performance)\n+| | Data Selection | Data selecting query upgrades change which/how many events are emitted\n+| | Schema Evolution | Schema evolving query upgrades change the output type of the data |\n+| | Source Modifying | These upgrades change the source data, whether by means of modifying a JOIN or swapping out a source |\n+| | Topology | These upgrades are invisible to the user, but change the topology, such as the number of sub-topologies or the ordering of operations (e.g. filter push down) |\n+| | Scaling | Scaling upgrades change the physical properties of the query in order to enable better performance characteristics. |\n+| | Unsupported | Unsupported upgrades are ones that will semantically change the query in an unsupported way. There are no plans to implement these migrations. |\n+| Environment | Backfill | Backfill requires the output data to be accurate not just from a point in time, but from the earliest point of retained history |", "originalCommit": "aed31a2478e49956e469d11e11bccf74ef5c472c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk0OTcxOQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r440949719", "bodyText": "I haven't specified this, but the intention is that none of the environments need to apply (so in your example it would be simply a \"Simple\" query). I will clarify the KLIP", "author": "agavra", "createdAt": "2020-06-16T15:38:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDkzMzc4OA=="}], "type": "inlineReview"}, {"oid": "7291b890e53e2bbd7c90cf79f0a18b6a54a5e13b", "url": "https://github.com/confluentinc/ksql/commit/7291b890e53e2bbd7c90cf79f0a18b6a54a5e13b", "message": "docs: KLIP-28 introduce CREATE OR REPLACE", "committedDate": "2020-06-16T17:29:22Z", "type": "forcePushed"}, {"oid": "99494da8845c64262edd974d1032f86dc7bb7e6e", "url": "https://github.com/confluentinc/ksql/commit/99494da8845c64262edd974d1032f86dc7bb7e6e", "message": "docs: address comments", "committedDate": "2020-06-16T17:30:31Z", "type": "commit"}, {"oid": "99494da8845c64262edd974d1032f86dc7bb7e6e", "url": "https://github.com/confluentinc/ksql/commit/99494da8845c64262edd974d1032f86dc7bb7e6e", "message": "docs: address comments", "committedDate": "2020-06-16T17:30:31Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3OTMyOQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444379329", "bodyText": "What's an example of this? Changing the number of streams threads, and other streams properties?\nWhat about changing parameters such as the number of output partitions -- and other properties from the \"WITH\" clause, such as output format? Will that be supported?", "author": "vcrfxia", "createdAt": "2020-06-23T17:10:56Z", "path": "design-proposals/klip-28-create-or-replace.md", "diffHunk": "@@ -0,0 +1,200 @@\n+# KLIP 28 - Introduce CREATE OR REPLACE\n+\n+**Author**: agavra | \n+**Release Target**: 0.11 | \n+**Status**: _In Discussion_ | \n+**Discussion**: _link to the design discussion PR_\n+\n+**tl;dr:** _CREATE OR REPLACE is a mechanism geared toward enabling in-place ksqlDB query evolution._\n+           \n+## Motivation and background\n+\n+Production deployments of databases are never static; they evolve as application and business \n+requirements change. To that end, all popular data stores have ways of managing and manipulating \n+existing data. For stream processing applications, a user may want to modify their application as \n+a result of:\n+\n+- Business Requirements: requirements simply change over time\n+- Schema Evolution: the incoming data or required output has been modified\n+- Optimizations: the same application can be executed more efficiently (either by user or engine)\n+\n+At time of writing, ksqlDB provides a crude mechanism for altering its application behavior: dropping \n+a query and restarting it at the earliest or latest offset. While this often works well in development \n+environments, there are limitations to its applicability in production:\n+\n+- Data Retention: the earliest available offset may not correspond with the beginning of time\n+- Downtime: the delta between terminating and catch-up may be out of the application\u2019s SLO\n+- Output Routing: populating to the old output topic will produce duplicates while using a new output topic will require cascading migrations\n+- Compute: recomputing the complete history for a query may not be feasible\n+\n+Kafka Streams provides more granular mechanisms (e.g. restarting queries with different behaviors \n+but identical consumer groups), but these methods burden users with extra complexity and lack guardrails.\n+\n+## Scope\n+\n+To better understand the scope of this KLIP and any future improvements, we define a taxonomy on \n+query upgrades as any combination of three types of characteristics: **source query, upgrade** and\n+(optionally) **environment**:\n+\n+| **Category** | **Characteristic** | **Description** |\n+|----------|----------------|-------------|\n+| Query | Stateful | Stateful queries maintain local storage |\n+| | Windowed | Windowed queries maintain a limited amount of state specified by a window in time\n+| | Joined | Joined queries read from multiple sources\n+| | Multistage | Multistage queries contain intermediate, non-user visible topics in Kafka\n+| | Nondeterministic | Nondeterministic queries may produce different results when executing identical input\n+| | Simple | Queries with none of the above characteristics\n+| Upgrade | Transparent | Transparent upgrades change the way something is computer (e.g. improving a UDF performance)\n+| | Data Selection | Data selecting query upgrades change which/how many events are emitted\n+| | Schema Evolution | Schema evolving query upgrades change the output type of the data |\n+| | Source Modifying | These upgrades change the source data, whether by means of modifying a JOIN or swapping out a source |\n+| | Topology | These upgrades are invisible to the user, but change the topology, such as the number of sub-topologies or the ordering of operations (e.g. filter push down) |\n+| | Scaling | Scaling upgrades change the physical properties of the query in order to enable better performance characteristics. |", "originalCommit": "99494da8845c64262edd974d1032f86dc7bb7e6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM5NTc5OQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444395799", "bodyText": "What's an example of this?\n\nI don't have a good example as available in the language today, but things like scaling out partitions or streams threads would such \"scaling\" operations. We could imagine changing number of stream threads might be one such thing (e.g. CREATE OR REPLACE ... WITH(num_threads=1000))\nThe scope of what this KLIP will implement doesn't really address any scaling changes (such as changing number of output partitions) but that could be some advanced upgrades that we want to support in the future. I felt it was important to include this in the table though for completeness", "author": "agavra", "createdAt": "2020-06-23T17:39:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3OTMyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ3NzAxOQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444477019", "bodyText": "When a CREATE OR REPLACE statement is issued, does the new query use the query properties (e.g., number of streams threads) set at the time of the CREATE OR REPLACE statement or does it maintain properties from the original query (if present)? I assume the latter but think this is worth calling out explicitly. If this is the case, then changing the number of streams threads is already supported under this proposal.", "author": "vcrfxia", "createdAt": "2020-06-23T20:07:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3OTMyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ4MDYyMg==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444480622", "bodyText": "It would indeed use the most recent one - so I suppose it is already supported \ud83d\ude02 I can update the KLIP if you'd like, though perhaps just seeing this discussion is sufficient documentation", "author": "agavra", "createdAt": "2020-06-23T20:14:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3OTMyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ4NTk2Ng==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444485966", "bodyText": "Are we planning to do any validation on the new query properties, in terms of checking for compatibility? For example, I'm not entirely clear on what happens if a Streams app is restarted with a different value for replication.factor (assuming the internal topics are already created with the old value) but I suspect there are combinations of values where this might fail?", "author": "vcrfxia", "createdAt": "2020-06-23T20:25:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3OTMyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ5MTU1NQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444491555", "bodyText": "Are we planning to do any validation on the new query properties, in terms of checking for compatibility?\n\nThe intention for compatibility was to setup a whitelist of items that can change, and if anything else changes we consider the upgrade incompatible. Honestly, I hadn't considered the query properties until now, but they definitely seem something important to put into the compatibility calculus.\nAs for your specific question, I think upping the replication factor is supported but reducing it is not (though I might be wrong on that one).", "author": "agavra", "createdAt": "2020-06-23T20:36:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3OTMyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ5MjM5Mw==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444492393", "bodyText": "Sounds good. Just wanted to check we had a plan :)", "author": "vcrfxia", "createdAt": "2020-06-23T20:38:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3OTMyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ5NDUxMw==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444494513", "bodyText": "I appreciate the thorough review \ud83d\ude04", "author": "agavra", "createdAt": "2020-06-23T20:42:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3OTMyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3OTUxOQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444379519", "bodyText": "\"No plans to implement these migrations\" at this time, or ever?", "author": "vcrfxia", "createdAt": "2020-06-23T17:11:16Z", "path": "design-proposals/klip-28-create-or-replace.md", "diffHunk": "@@ -0,0 +1,200 @@\n+# KLIP 28 - Introduce CREATE OR REPLACE\n+\n+**Author**: agavra | \n+**Release Target**: 0.11 | \n+**Status**: _In Discussion_ | \n+**Discussion**: _link to the design discussion PR_\n+\n+**tl;dr:** _CREATE OR REPLACE is a mechanism geared toward enabling in-place ksqlDB query evolution._\n+           \n+## Motivation and background\n+\n+Production deployments of databases are never static; they evolve as application and business \n+requirements change. To that end, all popular data stores have ways of managing and manipulating \n+existing data. For stream processing applications, a user may want to modify their application as \n+a result of:\n+\n+- Business Requirements: requirements simply change over time\n+- Schema Evolution: the incoming data or required output has been modified\n+- Optimizations: the same application can be executed more efficiently (either by user or engine)\n+\n+At time of writing, ksqlDB provides a crude mechanism for altering its application behavior: dropping \n+a query and restarting it at the earliest or latest offset. While this often works well in development \n+environments, there are limitations to its applicability in production:\n+\n+- Data Retention: the earliest available offset may not correspond with the beginning of time\n+- Downtime: the delta between terminating and catch-up may be out of the application\u2019s SLO\n+- Output Routing: populating to the old output topic will produce duplicates while using a new output topic will require cascading migrations\n+- Compute: recomputing the complete history for a query may not be feasible\n+\n+Kafka Streams provides more granular mechanisms (e.g. restarting queries with different behaviors \n+but identical consumer groups), but these methods burden users with extra complexity and lack guardrails.\n+\n+## Scope\n+\n+To better understand the scope of this KLIP and any future improvements, we define a taxonomy on \n+query upgrades as any combination of three types of characteristics: **source query, upgrade** and\n+(optionally) **environment**:\n+\n+| **Category** | **Characteristic** | **Description** |\n+|----------|----------------|-------------|\n+| Query | Stateful | Stateful queries maintain local storage |\n+| | Windowed | Windowed queries maintain a limited amount of state specified by a window in time\n+| | Joined | Joined queries read from multiple sources\n+| | Multistage | Multistage queries contain intermediate, non-user visible topics in Kafka\n+| | Nondeterministic | Nondeterministic queries may produce different results when executing identical input\n+| | Simple | Queries with none of the above characteristics\n+| Upgrade | Transparent | Transparent upgrades change the way something is computer (e.g. improving a UDF performance)\n+| | Data Selection | Data selecting query upgrades change which/how many events are emitted\n+| | Schema Evolution | Schema evolving query upgrades change the output type of the data |\n+| | Source Modifying | These upgrades change the source data, whether by means of modifying a JOIN or swapping out a source |\n+| | Topology | These upgrades are invisible to the user, but change the topology, such as the number of sub-topologies or the ordering of operations (e.g. filter push down) |\n+| | Scaling | Scaling upgrades change the physical properties of the query in order to enable better performance characteristics. |\n+| | Unsupported | Unsupported upgrades are ones that will semantically change the query in an unsupported way. There are no plans to implement these migrations. |", "originalCommit": "99494da8845c64262edd974d1032f86dc7bb7e6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM4ODM1OQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444388359", "bodyText": "Ever - these are things like changing a stream to table, or a table to a stream. Things that just don't make sense in our mental model.", "author": "agavra", "createdAt": "2020-06-23T17:26:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3OTUxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3OTgyOA==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444379828", "bodyText": "Does this mean the only thing that's supported is adding fields? What about reordering fields? Reordering fields would be breaking in the case of DELIMITED.", "author": "vcrfxia", "createdAt": "2020-06-23T17:11:49Z", "path": "design-proposals/klip-28-create-or-replace.md", "diffHunk": "@@ -0,0 +1,200 @@\n+# KLIP 28 - Introduce CREATE OR REPLACE\n+\n+**Author**: agavra | \n+**Release Target**: 0.11 | \n+**Status**: _In Discussion_ | \n+**Discussion**: _link to the design discussion PR_\n+\n+**tl;dr:** _CREATE OR REPLACE is a mechanism geared toward enabling in-place ksqlDB query evolution._\n+           \n+## Motivation and background\n+\n+Production deployments of databases are never static; they evolve as application and business \n+requirements change. To that end, all popular data stores have ways of managing and manipulating \n+existing data. For stream processing applications, a user may want to modify their application as \n+a result of:\n+\n+- Business Requirements: requirements simply change over time\n+- Schema Evolution: the incoming data or required output has been modified\n+- Optimizations: the same application can be executed more efficiently (either by user or engine)\n+\n+At time of writing, ksqlDB provides a crude mechanism for altering its application behavior: dropping \n+a query and restarting it at the earliest or latest offset. While this often works well in development \n+environments, there are limitations to its applicability in production:\n+\n+- Data Retention: the earliest available offset may not correspond with the beginning of time\n+- Downtime: the delta between terminating and catch-up may be out of the application\u2019s SLO\n+- Output Routing: populating to the old output topic will produce duplicates while using a new output topic will require cascading migrations\n+- Compute: recomputing the complete history for a query may not be feasible\n+\n+Kafka Streams provides more granular mechanisms (e.g. restarting queries with different behaviors \n+but identical consumer groups), but these methods burden users with extra complexity and lack guardrails.\n+\n+## Scope\n+\n+To better understand the scope of this KLIP and any future improvements, we define a taxonomy on \n+query upgrades as any combination of three types of characteristics: **source query, upgrade** and\n+(optionally) **environment**:\n+\n+| **Category** | **Characteristic** | **Description** |\n+|----------|----------------|-------------|\n+| Query | Stateful | Stateful queries maintain local storage |\n+| | Windowed | Windowed queries maintain a limited amount of state specified by a window in time\n+| | Joined | Joined queries read from multiple sources\n+| | Multistage | Multistage queries contain intermediate, non-user visible topics in Kafka\n+| | Nondeterministic | Nondeterministic queries may produce different results when executing identical input\n+| | Simple | Queries with none of the above characteristics\n+| Upgrade | Transparent | Transparent upgrades change the way something is computer (e.g. improving a UDF performance)\n+| | Data Selection | Data selecting query upgrades change which/how many events are emitted\n+| | Schema Evolution | Schema evolving query upgrades change the output type of the data |\n+| | Source Modifying | These upgrades change the source data, whether by means of modifying a JOIN or swapping out a source |\n+| | Topology | These upgrades are invisible to the user, but change the topology, such as the number of sub-topologies or the ordering of operations (e.g. filter push down) |\n+| | Scaling | Scaling upgrades change the physical properties of the query in order to enable better performance characteristics. |\n+| | Unsupported | Unsupported upgrades are ones that will semantically change the query in an unsupported way. There are no plans to implement these migrations. |\n+| Environment | Backfill | Backfill requires the output data to be accurate not just from a point in time, but from the earliest point of retained history |\n+| | Cascading | Cascading environments contain queries that are not terminal, but rather feed into downstream stream processing tasks |\n+| | Exactly Once | Exactly Once environments do not allow for data duplication or missed events |\n+| | Ordered | Ordered environments require that a single offset delineates pre- and post-migration (no events are interleaved) |\n+| | Live | Live environments describe queries that cannot afford downtime, either by means of acting as live storage (e.g. responding to pull queries) or feeding into high availability systems (powering important functionality) |\n+\n+### What is in scope\n+\n+- Specify a syntax that can support arbitrary upgrades\n+- Design a validator to fail unsupported upgrades\n+- Design a mechanism for upgrading queries under limited scope\n+\n+### What is not in scope\n+\n+The Design section below enumerates which upgrades are out of scope\n+\n+## Value/Return\n+\n+This KLIP will represent a significant step forward in the operability of ksqlDB in production, as\n+noted in the background and motivation section.\n+\n+## Public APIS\n+\n+The syntax `CREATE OR REPLACE (STREAM | TABLE) source_name WITH (key=value, ...) AS query;` will be\n+introduced to allow users to specify an existing stream or table to replace with a new query that\n+will resume from the same processing point as any previously existing query.\n+\n+## Design\n+\n+If the `source_name` does not yet exist, a `CREATE OR REPLACE` statement functions identically to\n+a normal `CREATE` statement. Otherwise, ksqlDB executes the following:\n+\n+1. Identify the original `queryID` that populates the source (`INSERT INTO` discussed later)\n+2. Ensure the upgrade is valid\n+3. Terminate `queryID`\n+4. Start the new query under the same `queryID`\n+\n+A few changes need to happen in order to make this work. For 1, we need to maintain a mapping from\n+source to queryID(s). If the source has multiple associated ids (in the case of `INSERT INTO`) then\n+the upgrade will fail and not terminate any queries.\n+\n+For step 2, there will be a component to determine whether two topologies are \"upgrade\n+compatible\"; the first iterations, which will be delivered as part of this KLIP, will only allow\n+for the most basic upgrades: \n+\n+- Any _transparent_ upgrade will be supported\n+- Any _data selection_ upgrade will be supported\n+- _Schema evolution_ upgrades will be supported on simple and stateful queries, but it will be\n+    communicated that the users will not get `backfill` or `ordered` properties for stateful.\n+- _Source modifying_ upgrades will not be supported\n+- _Topology changes_ will not be supported\n+\n+Note that _Schema Evolution_ compatibility is defined by the limitations of the serialization\n+format that is used with the added restrictions against removing fields and changing types to ensure", "originalCommit": "99494da8845c64262edd974d1032f86dc7bb7e6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM4ODAzOA==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444388038", "bodyText": "see my note below - that would be a limitation of the serialization format. Reordering would be OK in JSON for example, but not in delimited (and I don't think in AVRO or PROTOBUF either). But essentially the only \"useful\" query upgrade for schema evolution is adding fields - which I suspect is a vast majority of the use cases for schema evolution.", "author": "agavra", "createdAt": "2020-06-23T17:25:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3OTgyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDk3MDcwNQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444970705", "bodyText": "We've even got to be careful when reordering JSON columns.  Once we support multiple key columns, changing the order of key columns would break the binary compatibility of keys.\nIMHO, best just to no allow column re-ordering. I can't see it being a much asked for thing anyway.", "author": "big-andy-coates", "createdAt": "2020-06-24T15:14:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3OTgyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDk5OTI2OA==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444999268", "bodyText": "Fair, the ethos of this project is to be extra restrictive and lift restrictions later so we may as well be extra cautious up front.", "author": "agavra", "createdAt": "2020-06-24T15:54:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM3OTgyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM4MDExNA==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444380114", "bodyText": "Is this true? Wouldn't adding a field would break downstream queries in the case of DELIMITED?", "author": "vcrfxia", "createdAt": "2020-06-23T17:12:21Z", "path": "design-proposals/klip-28-create-or-replace.md", "diffHunk": "@@ -0,0 +1,200 @@\n+# KLIP 28 - Introduce CREATE OR REPLACE\n+\n+**Author**: agavra | \n+**Release Target**: 0.11 | \n+**Status**: _In Discussion_ | \n+**Discussion**: _link to the design discussion PR_\n+\n+**tl;dr:** _CREATE OR REPLACE is a mechanism geared toward enabling in-place ksqlDB query evolution._\n+           \n+## Motivation and background\n+\n+Production deployments of databases are never static; they evolve as application and business \n+requirements change. To that end, all popular data stores have ways of managing and manipulating \n+existing data. For stream processing applications, a user may want to modify their application as \n+a result of:\n+\n+- Business Requirements: requirements simply change over time\n+- Schema Evolution: the incoming data or required output has been modified\n+- Optimizations: the same application can be executed more efficiently (either by user or engine)\n+\n+At time of writing, ksqlDB provides a crude mechanism for altering its application behavior: dropping \n+a query and restarting it at the earliest or latest offset. While this often works well in development \n+environments, there are limitations to its applicability in production:\n+\n+- Data Retention: the earliest available offset may not correspond with the beginning of time\n+- Downtime: the delta between terminating and catch-up may be out of the application\u2019s SLO\n+- Output Routing: populating to the old output topic will produce duplicates while using a new output topic will require cascading migrations\n+- Compute: recomputing the complete history for a query may not be feasible\n+\n+Kafka Streams provides more granular mechanisms (e.g. restarting queries with different behaviors \n+but identical consumer groups), but these methods burden users with extra complexity and lack guardrails.\n+\n+## Scope\n+\n+To better understand the scope of this KLIP and any future improvements, we define a taxonomy on \n+query upgrades as any combination of three types of characteristics: **source query, upgrade** and\n+(optionally) **environment**:\n+\n+| **Category** | **Characteristic** | **Description** |\n+|----------|----------------|-------------|\n+| Query | Stateful | Stateful queries maintain local storage |\n+| | Windowed | Windowed queries maintain a limited amount of state specified by a window in time\n+| | Joined | Joined queries read from multiple sources\n+| | Multistage | Multistage queries contain intermediate, non-user visible topics in Kafka\n+| | Nondeterministic | Nondeterministic queries may produce different results when executing identical input\n+| | Simple | Queries with none of the above characteristics\n+| Upgrade | Transparent | Transparent upgrades change the way something is computer (e.g. improving a UDF performance)\n+| | Data Selection | Data selecting query upgrades change which/how many events are emitted\n+| | Schema Evolution | Schema evolving query upgrades change the output type of the data |\n+| | Source Modifying | These upgrades change the source data, whether by means of modifying a JOIN or swapping out a source |\n+| | Topology | These upgrades are invisible to the user, but change the topology, such as the number of sub-topologies or the ordering of operations (e.g. filter push down) |\n+| | Scaling | Scaling upgrades change the physical properties of the query in order to enable better performance characteristics. |\n+| | Unsupported | Unsupported upgrades are ones that will semantically change the query in an unsupported way. There are no plans to implement these migrations. |\n+| Environment | Backfill | Backfill requires the output data to be accurate not just from a point in time, but from the earliest point of retained history |\n+| | Cascading | Cascading environments contain queries that are not terminal, but rather feed into downstream stream processing tasks |\n+| | Exactly Once | Exactly Once environments do not allow for data duplication or missed events |\n+| | Ordered | Ordered environments require that a single offset delineates pre- and post-migration (no events are interleaved) |\n+| | Live | Live environments describe queries that cannot afford downtime, either by means of acting as live storage (e.g. responding to pull queries) or feeding into high availability systems (powering important functionality) |\n+\n+### What is in scope\n+\n+- Specify a syntax that can support arbitrary upgrades\n+- Design a validator to fail unsupported upgrades\n+- Design a mechanism for upgrading queries under limited scope\n+\n+### What is not in scope\n+\n+The Design section below enumerates which upgrades are out of scope\n+\n+## Value/Return\n+\n+This KLIP will represent a significant step forward in the operability of ksqlDB in production, as\n+noted in the background and motivation section.\n+\n+## Public APIS\n+\n+The syntax `CREATE OR REPLACE (STREAM | TABLE) source_name WITH (key=value, ...) AS query;` will be\n+introduced to allow users to specify an existing stream or table to replace with a new query that\n+will resume from the same processing point as any previously existing query.\n+\n+## Design\n+\n+If the `source_name` does not yet exist, a `CREATE OR REPLACE` statement functions identically to\n+a normal `CREATE` statement. Otherwise, ksqlDB executes the following:\n+\n+1. Identify the original `queryID` that populates the source (`INSERT INTO` discussed later)\n+2. Ensure the upgrade is valid\n+3. Terminate `queryID`\n+4. Start the new query under the same `queryID`\n+\n+A few changes need to happen in order to make this work. For 1, we need to maintain a mapping from\n+source to queryID(s). If the source has multiple associated ids (in the case of `INSERT INTO`) then\n+the upgrade will fail and not terminate any queries.\n+\n+For step 2, there will be a component to determine whether two topologies are \"upgrade\n+compatible\"; the first iterations, which will be delivered as part of this KLIP, will only allow\n+for the most basic upgrades: \n+\n+- Any _transparent_ upgrade will be supported\n+- Any _data selection_ upgrade will be supported\n+- _Schema evolution_ upgrades will be supported on simple and stateful queries, but it will be\n+    communicated that the users will not get `backfill` or `ordered` properties for stateful.\n+- _Source modifying_ upgrades will not be supported\n+- _Topology changes_ will not be supported\n+\n+Note that _Schema Evolution_ compatibility is defined by the limitations of the serialization\n+format that is used with the added restrictions against removing fields and changing types to ensure\n+referential integrity of ksqlDB tables. This way, downstream query output schemas willn not be affected", "originalCommit": "99494da8845c64262edd974d1032f86dc7bb7e6e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM4Njg3OQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444386879", "bodyText": "Yeah - that's why I mention \"defined by the limitations of the serialization format that is used\" and then there's added restrictions against removing fields and changing types, even if the format supports that. Changing a type, for example, would be supported by delimited and JSON - but I plan on explicitly restricting that.", "author": "agavra", "createdAt": "2020-06-23T17:23:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM4MDExNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM4MDE1Nw==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444380157", "bodyText": "Cool!", "author": "vcrfxia", "createdAt": "2020-06-23T17:12:25Z", "path": "design-proposals/klip-28-create-or-replace.md", "diffHunk": "@@ -0,0 +1,200 @@\n+# KLIP 28 - Introduce CREATE OR REPLACE\n+\n+**Author**: agavra | \n+**Release Target**: 0.11 | \n+**Status**: _In Discussion_ | \n+**Discussion**: _link to the design discussion PR_\n+\n+**tl;dr:** _CREATE OR REPLACE is a mechanism geared toward enabling in-place ksqlDB query evolution._\n+           \n+## Motivation and background\n+\n+Production deployments of databases are never static; they evolve as application and business \n+requirements change. To that end, all popular data stores have ways of managing and manipulating \n+existing data. For stream processing applications, a user may want to modify their application as \n+a result of:\n+\n+- Business Requirements: requirements simply change over time\n+- Schema Evolution: the incoming data or required output has been modified\n+- Optimizations: the same application can be executed more efficiently (either by user or engine)\n+\n+At time of writing, ksqlDB provides a crude mechanism for altering its application behavior: dropping \n+a query and restarting it at the earliest or latest offset. While this often works well in development \n+environments, there are limitations to its applicability in production:\n+\n+- Data Retention: the earliest available offset may not correspond with the beginning of time\n+- Downtime: the delta between terminating and catch-up may be out of the application\u2019s SLO\n+- Output Routing: populating to the old output topic will produce duplicates while using a new output topic will require cascading migrations\n+- Compute: recomputing the complete history for a query may not be feasible\n+\n+Kafka Streams provides more granular mechanisms (e.g. restarting queries with different behaviors \n+but identical consumer groups), but these methods burden users with extra complexity and lack guardrails.\n+\n+## Scope\n+\n+To better understand the scope of this KLIP and any future improvements, we define a taxonomy on \n+query upgrades as any combination of three types of characteristics: **source query, upgrade** and\n+(optionally) **environment**:\n+\n+| **Category** | **Characteristic** | **Description** |\n+|----------|----------------|-------------|\n+| Query | Stateful | Stateful queries maintain local storage |\n+| | Windowed | Windowed queries maintain a limited amount of state specified by a window in time\n+| | Joined | Joined queries read from multiple sources\n+| | Multistage | Multistage queries contain intermediate, non-user visible topics in Kafka\n+| | Nondeterministic | Nondeterministic queries may produce different results when executing identical input\n+| | Simple | Queries with none of the above characteristics\n+| Upgrade | Transparent | Transparent upgrades change the way something is computer (e.g. improving a UDF performance)\n+| | Data Selection | Data selecting query upgrades change which/how many events are emitted\n+| | Schema Evolution | Schema evolving query upgrades change the output type of the data |\n+| | Source Modifying | These upgrades change the source data, whether by means of modifying a JOIN or swapping out a source |\n+| | Topology | These upgrades are invisible to the user, but change the topology, such as the number of sub-topologies or the ordering of operations (e.g. filter push down) |\n+| | Scaling | Scaling upgrades change the physical properties of the query in order to enable better performance characteristics. |\n+| | Unsupported | Unsupported upgrades are ones that will semantically change the query in an unsupported way. There are no plans to implement these migrations. |\n+| Environment | Backfill | Backfill requires the output data to be accurate not just from a point in time, but from the earliest point of retained history |\n+| | Cascading | Cascading environments contain queries that are not terminal, but rather feed into downstream stream processing tasks |\n+| | Exactly Once | Exactly Once environments do not allow for data duplication or missed events |\n+| | Ordered | Ordered environments require that a single offset delineates pre- and post-migration (no events are interleaved) |\n+| | Live | Live environments describe queries that cannot afford downtime, either by means of acting as live storage (e.g. responding to pull queries) or feeding into high availability systems (powering important functionality) |\n+\n+### What is in scope\n+\n+- Specify a syntax that can support arbitrary upgrades\n+- Design a validator to fail unsupported upgrades\n+- Design a mechanism for upgrading queries under limited scope\n+\n+### What is not in scope\n+\n+The Design section below enumerates which upgrades are out of scope\n+\n+## Value/Return\n+\n+This KLIP will represent a significant step forward in the operability of ksqlDB in production, as\n+noted in the background and motivation section.\n+\n+## Public APIS\n+\n+The syntax `CREATE OR REPLACE (STREAM | TABLE) source_name WITH (key=value, ...) AS query;` will be\n+introduced to allow users to specify an existing stream or table to replace with a new query that\n+will resume from the same processing point as any previously existing query.\n+\n+## Design\n+\n+If the `source_name` does not yet exist, a `CREATE OR REPLACE` statement functions identically to\n+a normal `CREATE` statement. Otherwise, ksqlDB executes the following:\n+\n+1. Identify the original `queryID` that populates the source (`INSERT INTO` discussed later)\n+2. Ensure the upgrade is valid\n+3. Terminate `queryID`\n+4. Start the new query under the same `queryID`\n+\n+A few changes need to happen in order to make this work. For 1, we need to maintain a mapping from\n+source to queryID(s). If the source has multiple associated ids (in the case of `INSERT INTO`) then\n+the upgrade will fail and not terminate any queries.\n+\n+For step 2, there will be a component to determine whether two topologies are \"upgrade\n+compatible\"; the first iterations, which will be delivered as part of this KLIP, will only allow\n+for the most basic upgrades: \n+\n+- Any _transparent_ upgrade will be supported\n+- Any _data selection_ upgrade will be supported\n+- _Schema evolution_ upgrades will be supported on simple and stateful queries, but it will be\n+    communicated that the users will not get `backfill` or `ordered` properties for stateful.\n+- _Source modifying_ upgrades will not be supported\n+- _Topology changes_ will not be supported\n+\n+Note that _Schema Evolution_ compatibility is defined by the limitations of the serialization\n+format that is used with the added restrictions against removing fields and changing types to ensure\n+referential integrity of ksqlDB tables. This way, downstream query output schemas willn not be affected\n+by upstream schema evolution.\n+\n+There are currently discussions that discuss how to expand the support of some of these upgrades,\n+but we believe there is value in supporting the limitted set described above.\n+\n+For step 4, we need to be able to generate queryIDs differently for `CREATE OR REPLACE` statements\n+than for others (i.e. it shouldn't just be the offset of the command, but rather the same queryID \n+as the original query.) One simple way to implement this is to allow the queryID to be specified\n+in the command topic. Since the engine receiving the request has a complete view of the engine\n+metadata, it can determine the queryID to enqueue onto the command topic.\n+\n+### On \"INSERT INTO\"\n+\n+Insert into can eventually be replaced with `UNION` as proposed in [KLIP-17](https://github.com/confluentinc/ksql/pull/4125),\n+but that must happen in lock-step with this proposal. At first, we will support `CREATE OR REPLACE`\n+and `INSERT INTO`. Then, we will add support for `UNION`, allowing us to model consecutive `INSERT INTO`\n+statements as replacing unions with larger unions (essentially adding an extra source to the union).", "originalCommit": "99494da8845c64262edd974d1032f86dc7bb7e6e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDM4MDMzNg==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444380336", "bodyText": "super nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            | Upgrade | Transparent | Transparent upgrades change the way something is computer (e.g. improving a UDF performance)\n          \n          \n            \n            | Upgrade | Transparent | Transparent upgrades change the way something is computed (e.g. improving a UDF performance)", "author": "vcrfxia", "createdAt": "2020-06-23T17:12:42Z", "path": "design-proposals/klip-28-create-or-replace.md", "diffHunk": "@@ -0,0 +1,200 @@\n+# KLIP 28 - Introduce CREATE OR REPLACE\n+\n+**Author**: agavra | \n+**Release Target**: 0.11 | \n+**Status**: _In Discussion_ | \n+**Discussion**: _link to the design discussion PR_\n+\n+**tl;dr:** _CREATE OR REPLACE is a mechanism geared toward enabling in-place ksqlDB query evolution._\n+           \n+## Motivation and background\n+\n+Production deployments of databases are never static; they evolve as application and business \n+requirements change. To that end, all popular data stores have ways of managing and manipulating \n+existing data. For stream processing applications, a user may want to modify their application as \n+a result of:\n+\n+- Business Requirements: requirements simply change over time\n+- Schema Evolution: the incoming data or required output has been modified\n+- Optimizations: the same application can be executed more efficiently (either by user or engine)\n+\n+At time of writing, ksqlDB provides a crude mechanism for altering its application behavior: dropping \n+a query and restarting it at the earliest or latest offset. While this often works well in development \n+environments, there are limitations to its applicability in production:\n+\n+- Data Retention: the earliest available offset may not correspond with the beginning of time\n+- Downtime: the delta between terminating and catch-up may be out of the application\u2019s SLO\n+- Output Routing: populating to the old output topic will produce duplicates while using a new output topic will require cascading migrations\n+- Compute: recomputing the complete history for a query may not be feasible\n+\n+Kafka Streams provides more granular mechanisms (e.g. restarting queries with different behaviors \n+but identical consumer groups), but these methods burden users with extra complexity and lack guardrails.\n+\n+## Scope\n+\n+To better understand the scope of this KLIP and any future improvements, we define a taxonomy on \n+query upgrades as any combination of three types of characteristics: **source query, upgrade** and\n+(optionally) **environment**:\n+\n+| **Category** | **Characteristic** | **Description** |\n+|----------|----------------|-------------|\n+| Query | Stateful | Stateful queries maintain local storage |\n+| | Windowed | Windowed queries maintain a limited amount of state specified by a window in time\n+| | Joined | Joined queries read from multiple sources\n+| | Multistage | Multistage queries contain intermediate, non-user visible topics in Kafka\n+| | Nondeterministic | Nondeterministic queries may produce different results when executing identical input\n+| | Simple | Queries with none of the above characteristics\n+| Upgrade | Transparent | Transparent upgrades change the way something is computer (e.g. improving a UDF performance)", "originalCommit": "99494da8845c64262edd974d1032f86dc7bb7e6e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "fb67282746a8dacfc0128bc4b838eb427fa307aa", "url": "https://github.com/confluentinc/ksql/commit/fb67282746a8dacfc0128bc4b838eb427fa307aa", "message": "Update design-proposals/klip-28-create-or-replace.md\n\nCo-authored-by: Victoria Xia <victoria.f.xia281@gmail.com>", "committedDate": "2020-06-23T17:39:51Z", "type": "commit"}, {"oid": "e1816f3333083c41e8c7146118a4ae26e06bd4ac", "url": "https://github.com/confluentinc/ksql/commit/e1816f3333083c41e8c7146118a4ae26e06bd4ac", "message": "Update klip-28-create-or-replace.md", "committedDate": "2020-06-23T17:42:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDk3MTk0NQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444971945", "bodyText": "Not just removing fields, but also renaming fields.", "author": "big-andy-coates", "createdAt": "2020-06-24T15:15:55Z", "path": "design-proposals/klip-28-create-or-replace.md", "diffHunk": "@@ -0,0 +1,200 @@\n+# KLIP 28 - Introduce CREATE OR REPLACE\n+\n+**Author**: agavra | \n+**Release Target**: 0.11 | \n+**Status**: _Approved_ | \n+**Discussion**: _https://github.com/confluentinc/ksql/pull/5611_\n+\n+**tl;dr:** _CREATE OR REPLACE is a mechanism geared toward enabling in-place ksqlDB query evolution._\n+           \n+## Motivation and background\n+\n+Production deployments of databases are never static; they evolve as application and business \n+requirements change. To that end, all popular data stores have ways of managing and manipulating \n+existing data. For stream processing applications, a user may want to modify their application as \n+a result of:\n+\n+- Business Requirements: requirements simply change over time\n+- Schema Evolution: the incoming data or required output has been modified\n+- Optimizations: the same application can be executed more efficiently (either by user or engine)\n+\n+At time of writing, ksqlDB provides a crude mechanism for altering its application behavior: dropping \n+a query and restarting it at the earliest or latest offset. While this often works well in development \n+environments, there are limitations to its applicability in production:\n+\n+- Data Retention: the earliest available offset may not correspond with the beginning of time\n+- Downtime: the delta between terminating and catch-up may be out of the application\u2019s SLO\n+- Output Routing: populating to the old output topic will produce duplicates while using a new output topic will require cascading migrations\n+- Compute: recomputing the complete history for a query may not be feasible\n+\n+Kafka Streams provides more granular mechanisms (e.g. restarting queries with different behaviors \n+but identical consumer groups), but these methods burden users with extra complexity and lack guardrails.\n+\n+## Scope\n+\n+To better understand the scope of this KLIP and any future improvements, we define a taxonomy on \n+query upgrades as any combination of three types of characteristics: **source query, upgrade** and\n+(optionally) **environment**:\n+\n+| **Category** | **Characteristic** | **Description** |\n+|----------|----------------|-------------|\n+| Query | Stateful | Stateful queries maintain local storage |\n+| | Windowed | Windowed queries maintain a limited amount of state specified by a window in time\n+| | Joined | Joined queries read from multiple sources\n+| | Multistage | Multistage queries contain intermediate, non-user visible topics in Kafka\n+| | Nondeterministic | Nondeterministic queries may produce different results when executing identical input\n+| | Simple | Queries with none of the above characteristics\n+| Upgrade | Transparent | Transparent upgrades change the way something is computed (e.g. improving a UDF performance)\n+| | Data Selection | Data selecting query upgrades change which/how many events are emitted\n+| | Schema Evolution | Schema evolving query upgrades change the output type of the data |\n+| | Source Modifying | These upgrades change the source data, whether by means of modifying a JOIN or swapping out a source |\n+| | Topology | These upgrades are invisible to the user, but change the topology, such as the number of sub-topologies or the ordering of operations (e.g. filter push down) |\n+| | Scaling | Scaling upgrades change the physical properties of the query in order to enable better performance characteristics. |\n+| | Unsupported | Unsupported upgrades are ones that will semantically change the query in an unsupported way. There are no plans to implement these migrations. |\n+| Environment | Backfill | Backfill requires the output data to be accurate not just from a point in time, but from the earliest point of retained history |\n+| | Cascading | Cascading environments contain queries that are not terminal, but rather feed into downstream stream processing tasks |\n+| | Exactly Once | Exactly Once environments do not allow for data duplication or missed events |\n+| | Ordered | Ordered environments require that a single offset delineates pre- and post-migration (no events are interleaved) |\n+| | Live | Live environments describe queries that cannot afford downtime, either by means of acting as live storage (e.g. responding to pull queries) or feeding into high availability systems (powering important functionality) |\n+\n+### What is in scope\n+\n+- Specify a syntax that can support arbitrary upgrades\n+- Design a validator to fail unsupported upgrades\n+- Design a mechanism for upgrading queries under limited scope\n+\n+### What is not in scope\n+\n+The Design section below enumerates which upgrades are out of scope\n+\n+## Value/Return\n+\n+This KLIP will represent a significant step forward in the operability of ksqlDB in production, as\n+noted in the background and motivation section.\n+\n+## Public APIS\n+\n+The syntax `CREATE OR REPLACE (STREAM | TABLE) source_name WITH (key=value, ...) AS query;` will be\n+introduced to allow users to specify an existing stream or table to replace with a new query that\n+will resume from the same processing point as any previously existing query.\n+\n+## Design\n+\n+If the `source_name` does not yet exist, a `CREATE OR REPLACE` statement functions identically to\n+a normal `CREATE` statement. Otherwise, ksqlDB executes the following:\n+\n+1. Identify the original `queryID` that populates the source (`INSERT INTO` discussed later)\n+2. Ensure the upgrade is valid\n+3. Terminate `queryID`\n+4. Start the new query under the same `queryID`\n+\n+A few changes need to happen in order to make this work. For 1, we need to maintain a mapping from\n+source to queryID(s). If the source has multiple associated ids (in the case of `INSERT INTO`) then\n+the upgrade will fail and not terminate any queries.\n+\n+For step 2, there will be a component to determine whether two topologies are \"upgrade\n+compatible\"; the first iterations, which will be delivered as part of this KLIP, will only allow\n+for the most basic upgrades: \n+\n+- Any _transparent_ upgrade will be supported\n+- Any _data selection_ upgrade will be supported\n+- _Schema evolution_ upgrades will be supported on simple and stateful queries, but it will be\n+    communicated that the users will not get `backfill` or `ordered` properties for stateful.\n+- _Source modifying_ upgrades will not be supported\n+- _Topology changes_ will not be supported\n+\n+Note that _Schema Evolution_ compatibility is defined by the limitations of the serialization\n+format that is used with the added restrictions against removing fields and changing types to ensure", "originalCommit": "e1816f3333083c41e8c7146118a4ae26e06bd4ac", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDk5ODc2NQ==", "url": "https://github.com/confluentinc/ksql/pull/5611#discussion_r444998765", "bodyText": "Copying from above:\n\nFrom my perspective, there isn't be a difference between removing and renaming (renaming=removing and adding). If I'm checking that all columns from the previous schema exist in the new one, if one was renamed that check would fail!\n\nThe reason I'm pedantic about this is that figuring out whether a field is \"renamed\" is actually pretty darn tough!", "author": "agavra", "createdAt": "2020-06-24T15:54:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDk3MTk0NQ=="}], "type": "inlineReview"}]}