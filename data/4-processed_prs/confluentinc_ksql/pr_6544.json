{"pr_number": 6544, "pr_title": "feat: support multi-column key declarations", "pr_createdAt": "2020-10-29T18:42:11Z", "pr_url": "https://github.com/confluentinc/ksql/pull/6544", "timeline": [{"oid": "627deaf91e153e65514d6c82fae3b89730473512", "url": "https://github.com/confluentinc/ksql/commit/627deaf91e153e65514d6c82fae3b89730473512", "message": "feat: support multi-column key declarations", "committedDate": "2020-10-29T20:47:27Z", "type": "forcePushed"}, {"oid": "7b75de383a9b35503f3897c8e2eead67142cfec5", "url": "https://github.com/confluentinc/ksql/commit/7b75de383a9b35503f3897c8e2eead67142cfec5", "message": "feat: support multi-column key declarations", "committedDate": "2020-10-29T21:39:03Z", "type": "forcePushed"}, {"oid": "20d2c78ec74a88360fddb695fb087236c9ec4ab6", "url": "https://github.com/confluentinc/ksql/commit/20d2c78ec74a88360fddb695fb087236c9ec4ab6", "message": "feat: support multi-column key declarations", "committedDate": "2020-10-29T21:44:48Z", "type": "forcePushed"}, {"oid": "36ded16889a98cc1fef3382eec929c84372472ab", "url": "https://github.com/confluentinc/ksql/commit/36ded16889a98cc1fef3382eec929c84372472ab", "message": "feat: support multi-column key declarations", "committedDate": "2020-10-29T22:04:12Z", "type": "forcePushed"}, {"oid": "348b36b17be6acdb18218ffb353af1fadaa25ba7", "url": "https://github.com/confluentinc/ksql/commit/348b36b17be6acdb18218ffb353af1fadaa25ba7", "message": "feat: support multi-column key declarations", "committedDate": "2020-10-30T00:20:32Z", "type": "forcePushed"}, {"oid": "20d2c78ec74a88360fddb695fb087236c9ec4ab6", "url": "https://github.com/confluentinc/ksql/commit/20d2c78ec74a88360fddb695fb087236c9ec4ab6", "message": "feat: support multi-column key declarations", "committedDate": "2020-10-29T21:44:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzQ0OA==", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707448", "bodyText": "nit (not your code):\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  // Persistent queries have key columns as key columns - so final projection can exclude them:\n          \n          \n            \n                  // Persistent queries have key columns as value columns - so final projection can exclude them:", "author": "vcrfxia", "createdAt": "2020-11-05T00:17:02Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/planner/plan/FinalProjectNode.java", "diffHunk": "@@ -104,6 +108,7 @@ public void validateKeyPresent(final SourceName sinkName) {\n \n     if (into.isPresent()) {\n       // Persistent queries have key columns as key columns - so final projection can exclude them:", "originalCommit": "20d2c78ec74a88360fddb695fb087236c9ec4ab6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzQ3Mw==", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707473", "bodyText": "Not directly related to your PR, but can you help me understand why the validation that key columns are not selected more than once is performed in FinalProjectNode while the validation that key columns are selected is performed in DataSourceNode, rather than performing both checks in the same place?", "author": "vcrfxia", "createdAt": "2020-11-05T00:17:07Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/planner/plan/FinalProjectNode.java", "diffHunk": "@@ -114,10 +119,28 @@ public void validateKeyPresent(final SourceName sinkName) {\n             return true;\n           }\n \n-          return parentSchema.isKeyColumn(columnName);\n+          if (parentSchema.isKeyColumn(columnName)) {\n+            seenKeyColumns.computeIfAbsent(columnName, k -> new HashSet<>()).add(se.getAlias());\n+            return true;\n+          }\n         }\n         return false;\n       });\n+\n+      for (final Entry<ColumnName, Set<ColumnName>> seenKey : seenKeyColumns.entrySet()) {\n+        if (seenKey.getValue().size() > 1) {\n+          final String keys = GrammaticalJoiner.and().join(\n+              seenKey.getValue().stream().map(Name::text).sorted());\n+          throw new KsqlException(\"The projection contains a key column (\" + seenKey.getKey()", "originalCommit": "20d2c78ec74a88360fddb695fb087236c9ec4ab6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODM1Mzc3Nw==", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r518353777", "bodyText": "Every node \"validates\" that the key is selected, they just all delegate to the child node that has that information:\n// PlanNode.java:L145\n  void validateKeyPresent(final SourceName sinkName, final Projection projection) {\n    getSources().forEach(s -> s.validateKeyPresent(sinkName, projection));\n  }\nDataSourceNode, JoinNode and UserRepartitionNode all override this method because those are the nodes that truly \"know\" whether the key was selected. Imagine we projected the key column with a different name, the schema in the FinalProjectNode would consider that the key - but of course we didn't select that! We selected the original key.\nTo illustrate, in the example below the project node has a schema [col1 INT PRIMARY KEY] but we didn't select col1 - so it would fail! Of course we could do some magic and \"remember\" that b.col1 is actually a.id, but why not just delegate that to the node that already tracks that?\nCREATE TABLE a (id INT PRIMARY KEY, col1 INT);\nCREATE TABLE b AS SELECT id AS col1; \n(Note that it's a little confusing, because there is also VerifiableNode, which AggregateNode, FinalProjectNode and SuppressNode all override - and it is VerifiableNode#validateKeyPresent is what is called at the top level, but these just delegate down to the three source nodes eventually).\n\nwhy the validation that key columns are not selected more than once is performed in FinalProjectNode\n\nI think this one is clearer why it can't be in DataSourceNode, it's the other way around that might need some justification.\n\nAll that being said, I think this can definitely be made clearer going forward. The logical nodes don't follow a very strict abstraction model unfortunately.", "author": "agavra", "createdAt": "2020-11-05T20:45:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzQ3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODM2NzI4Mg==", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r518367282", "bodyText": "Thanks for the explanation -- super helpful!", "author": "vcrfxia", "createdAt": "2020-11-05T21:12:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzQ3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzUwNw==", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707507", "bodyText": "nit: it's a bit odd that this method is called validate now that there's validation being performed in build() as well. Can we either move the validation back into this method, or rename this method to something more specific (throwOnZeroValueColumns() or similar)?", "author": "vcrfxia", "createdAt": "2020-11-05T00:17:11Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/planner/plan/FinalProjectNode.java", "diffHunk": "@@ -142,16 +165,6 @@ public void validateKeyPresent(final SourceName sinkName) {\n   private void validate() {", "originalCommit": "20d2c78ec74a88360fddb695fb087236c9ec4ab6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzY5Ng==", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707696", "bodyText": "To check my understanding: this works today because we only ever end up with a single key after partition by or group by, but this method signature will have to change to support building structs with multiple key columns in a future PR, yes?", "author": "vcrfxia", "createdAt": "2020-11-05T00:17:55Z", "path": "ksqldb-execution/src/main/java/io/confluent/ksql/execution/util/StructKeyUtil.java", "diffHunk": "@@ -58,16 +57,14 @@ public static KeyBuilder keyBuilder(final ColumnName name, final SqlType type) {\n   public static final class KeyBuilder {\n \n     private final Schema keySchema;\n-    private final org.apache.kafka.connect.data.Field keyField;\n \n-    private KeyBuilder(final Schema keySchema) {\n+    public KeyBuilder(final Schema keySchema) {\n       this.keySchema = Objects.requireNonNull(keySchema, \"keySchema\");\n-      this.keyField = Iterables.getOnlyElement(keySchema.fields());\n     }\n \n-    public Struct build(final Object keyValue) {\n+    public Struct build(final Object keyValue, final int fieldIndex) {", "originalCommit": "20d2c78ec74a88360fddb695fb087236c9ec4ab6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODI5NDI1NQ==", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r518294255", "bodyText": "yes - I tried to change this to make it more generic but it causes a shocking amount of code jitter, so I'll do that in a future PR", "author": "agavra", "createdAt": "2020-11-05T19:07:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzY5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzgyMg==", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707822", "bodyText": "How is this is a nested struct key?", "author": "vcrfxia", "createdAt": "2020-11-05T00:18:23Z", "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/multi-col-keys.json", "diffHunk": "@@ -0,0 +1,371 @@\n+{\n+  \"tests\": [\n+    {\n+      \"name\": \"select * from stream\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": null, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": null, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"OUTPUT\", \"key\": null, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, K2 INT KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * from table\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE TABLE INPUT (K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT * FROM INPUT;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * with WHERE on single key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT WHERE K = 1;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 2, \"K2\": 1}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, K2 INT KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * with WHERE on both key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT WHERE K = 1 AND K2 = 2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 1}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, K2 INT KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * from stream partition by single key col\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT PARTITION BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"K2\": 2, \"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, V INT, K2 INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * from stream partition by struct representing the key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT PARTITION BY STRUCT(K:=K, K2:=K2);\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0, \"K\": 1, \"K2\": 2}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"KSQL_COL_0 STRUCT<K INT, K2 INT> KEY, V INT, K INT, K2 INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"group by one col\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, COUNT(*) as COUNT FROM INPUT GROUP BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"K INTEGER KEY, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"group by two cols\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, K2, COUNT(*) as COUNT FROM INPUT GROUP BY K, K2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"COUNT\": 1}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"KSQL_COL_0 STRING KEY, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"group by one col table with tombstones\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE TABLE INPUT (K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, COUNT(*) as COUNT FROM INPUT GROUP BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": null}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}},\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 0}}\n+      ]\n+    },\n+    {\n+      \"name\": \"group by two cols table with tombstones\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE TABLE INPUT (K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, K2, COUNT(*) as COUNT FROM INPUT GROUP BY K, K2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": null}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"COUNT\": 1}},\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"COUNT\": 0}}\n+      ]\n+    },\n+    {\n+      \"name\": \"group by two cols with AS_VALUE copies\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, K2, AS_VALUE(K) as kv, AS_VALUE(K2) as kv2, COUNT(*) as COUNT FROM INPUT GROUP BY K, K2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"KV\": 1, \"KV2\": 2, \"COUNT\": 1}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"KSQL_COL_0 STRING KEY, KV INT, KV2 INT, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"windowed group by one col\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 1 SECOND) GROUP BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}, \"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}, \"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}, \"timestamp\": 1001}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}, \"window\": {\"start\": 0, \"end\": 1000, \"type\": \"time\"}},\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 2}, \"window\": {\"start\": 0, \"end\": 1000, \"type\": \"time\"}},\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}, \"window\": {\"start\": 1000, \"end\": 2000, \"type\": \"time\"}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"K INTEGER KEY, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"join with repartition on single key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM S1 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s1', format='JSON');\",\n+        \"CREATE STREAM S2 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s2', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM S1 JOIN S2 WITHIN 1 DAY on S1.K = S2.K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"s1\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"s2\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"S1_K2\": 2, \"S1_V\": 0, \"S2_K\": 1, \"S2_K2\": 2, \"S2_V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"S1_K INTEGER KEY, S1_K2 INTEGER, S1_V INTEGER, S2_K INTEGER, S2_K2 INTEGER, S2_V INTEGER\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"join with repartition on single value\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM S1 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s1', format='JSON');\",\n+        \"CREATE STREAM S2 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s2', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM S1 JOIN S2 WITHIN 1 DAY on S1.v = S2.V;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"s1\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"s2\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 0, \"value\": {\"S1_K\": 1, \"S1_K2\": 2, \"S2_K\": 1, \"S2_K2\": 2, \"S2_V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"S1_V INTEGER KEY, S1_K INTEGER, S1_K2 INTEGER, S2_K INTEGER, S2_K2 INTEGER, S2_V INTEGER\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"nested struct key\",", "originalCommit": "20d2c78ec74a88360fddb695fb087236c9ec4ab6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODM1NTU1Mg==", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r518355552", "bodyText": "physically, it's a struct within a struct. I'll rename this \"struct as column in multi-column key\"", "author": "agavra", "createdAt": "2020-11-05T20:49:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzgyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzg0Mw==", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707843", "bodyText": "Can we also add a negative test for partition by on multiple columns?", "author": "vcrfxia", "createdAt": "2020-11-05T00:18:26Z", "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/multi-col-keys.json", "diffHunk": "@@ -0,0 +1,371 @@\n+{\n+  \"tests\": [\n+    {\n+      \"name\": \"select * from stream\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": null, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": null, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"OUTPUT\", \"key\": null, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, K2 INT KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * from table\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE TABLE INPUT (K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT * FROM INPUT;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * with WHERE on single key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT WHERE K = 1;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 2, \"K2\": 1}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, K2 INT KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * with WHERE on both key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT WHERE K = 1 AND K2 = 2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 1}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, K2 INT KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * from stream partition by single key col\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT PARTITION BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"K2\": 2, \"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, V INT, K2 INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * from stream partition by struct representing the key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT PARTITION BY STRUCT(K:=K, K2:=K2);\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0, \"K\": 1, \"K2\": 2}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"KSQL_COL_0 STRUCT<K INT, K2 INT> KEY, V INT, K INT, K2 INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"group by one col\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, COUNT(*) as COUNT FROM INPUT GROUP BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"K INTEGER KEY, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"group by two cols\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, K2, COUNT(*) as COUNT FROM INPUT GROUP BY K, K2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"COUNT\": 1}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"KSQL_COL_0 STRING KEY, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"group by one col table with tombstones\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE TABLE INPUT (K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, COUNT(*) as COUNT FROM INPUT GROUP BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": null}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}},\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 0}}\n+      ]\n+    },\n+    {\n+      \"name\": \"group by two cols table with tombstones\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE TABLE INPUT (K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, K2, COUNT(*) as COUNT FROM INPUT GROUP BY K, K2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": null}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"COUNT\": 1}},\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"COUNT\": 0}}\n+      ]\n+    },\n+    {\n+      \"name\": \"group by two cols with AS_VALUE copies\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, K2, AS_VALUE(K) as kv, AS_VALUE(K2) as kv2, COUNT(*) as COUNT FROM INPUT GROUP BY K, K2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"KV\": 1, \"KV2\": 2, \"COUNT\": 1}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"KSQL_COL_0 STRING KEY, KV INT, KV2 INT, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"windowed group by one col\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 1 SECOND) GROUP BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}, \"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}, \"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}, \"timestamp\": 1001}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}, \"window\": {\"start\": 0, \"end\": 1000, \"type\": \"time\"}},\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 2}, \"window\": {\"start\": 0, \"end\": 1000, \"type\": \"time\"}},\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}, \"window\": {\"start\": 1000, \"end\": 2000, \"type\": \"time\"}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"K INTEGER KEY, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"join with repartition on single key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM S1 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s1', format='JSON');\",\n+        \"CREATE STREAM S2 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s2', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM S1 JOIN S2 WITHIN 1 DAY on S1.K = S2.K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"s1\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"s2\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"S1_K2\": 2, \"S1_V\": 0, \"S2_K\": 1, \"S2_K2\": 2, \"S2_V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"S1_K INTEGER KEY, S1_K2 INTEGER, S1_V INTEGER, S2_K INTEGER, S2_K2 INTEGER, S2_V INTEGER\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"join with repartition on single value\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM S1 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s1', format='JSON');\",\n+        \"CREATE STREAM S2 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s2', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM S1 JOIN S2 WITHIN 1 DAY on S1.v = S2.V;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"s1\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"s2\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 0, \"value\": {\"S1_K\": 1, \"S1_K2\": 2, \"S2_K\": 1, \"S2_K2\": 2, \"S2_V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"S1_V INTEGER KEY, S1_K INTEGER, S1_K2 INTEGER, S2_K INTEGER, S2_K2 INTEGER, S2_V INTEGER\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"nested struct key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 STRUCT<F1 INT> KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": {\"F1\": 2}}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": {\"F1\": 2}}, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, K2 STRUCT<F1 INT> KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select only single key col\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT K, V FROM INPUT;\"\n+      ],\n+      \"expectedException\": {\n+        \"type\": \"io.confluent.ksql.util.KsqlStatementException\",\n+        \"message\": \"The query used to build `OUTPUT` must include the key columns K and K2 in its projection.\"\n+      }\n+    },\n+    {\n+      \"name\": \"join on multi-column key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM S1 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s1', format='JSON');\",\n+        \"CREATE STREAM S2 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s2', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM S1 JOIN S2 WITHIN 1 DAY on S1.K = S2.K AND S1.K2 = S2.K2;\"\n+      ],\n+      \"expectedException\": {\n+        \"type\": \"io.confluent.ksql.util.KsqlStatementException\",\n+        \"message\": \"JOINs on multiple conditions are not yet supported: ((S1.K = S2.K) AND (S1.K2 = S2.K2))\"\n+      }\n+    },\n+    {\n+      \"name\": \"join to multi-column table\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM S (K STRING KEY, ID VARCHAR) WITH (kafka_topic='S', format='JSON');\",\n+        \"CREATE TABLE NO_KEY (K STRING PRIMARY KEY, K2 STRING PRIMARY KEY, NAME string) WITH (kafka_topic='NO_KEY', format='JSON');\",\n+        \"CREATE STREAM OUTPUT as SELECT s.k, name FROM S JOIN NO_KEY t ON s.k = t.k;\"\n+      ],\n+      \"expectedException\": {\n+        \"type\": \"io.confluent.ksql.util.KsqlStatementException\",\n+        \"message\": \"Cannot repartition a TABLE source. If this is a join, joins on tables with multiple columns is not yet supported.\"\n+      }\n+    }\n+  ]\n+}", "originalCommit": "20d2c78ec74a88360fddb695fb087236c9ec4ab6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODM1ODQ3NA==", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r518358474", "bodyText": "I originally did not add this because our parser doesn't even except PARTITION BY x,y but i'll add one in and make sure it doesn't parse", "author": "agavra", "createdAt": "2020-11-05T20:54:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzg0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzg2Mw==", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707863", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              public void shouldHandleMultiField() {\n          \n          \n            \n              public void shouldHandleMultiKeyField() {\n          \n      \n    \n    \n  \n\nand similarly for the other new tests below.", "author": "vcrfxia", "createdAt": "2020-11-05T00:18:30Z", "path": "ksqldb-streams/src/test/java/io/confluent/ksql/execution/streams/SourceBuilderTest.java", "diffHunk": "@@ -555,6 +560,70 @@ public void shouldHandleNullKey() {\n   }\n \n   @Test\n+  public void shouldHandleMultiField() {", "originalCommit": "20d2c78ec74a88360fddb695fb087236c9ec4ab6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzg4Mg==", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707882", "bodyText": "It's not possible for a user to have a windowed, multi-key table today, right? Since group by on multiple columns still creates a single key, and we don't allow importing windowed tables?\nAlso, this method looks unused.", "author": "vcrfxia", "createdAt": "2020-11-05T00:18:34Z", "path": "ksqldb-streams/src/test/java/io/confluent/ksql/execution/streams/SourceBuilderTest.java", "diffHunk": "@@ -768,6 +849,20 @@ private void givenWindowedSourceTable() {\n     );\n   }\n \n+  private void givenWindowedMultiKeySourceTable() {", "originalCommit": "20d2c78ec74a88360fddb695fb087236c9ec4ab6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODM1OTI5Ng==", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r518359296", "bodyText": "yes you are right, that was from a change i had backed out and forgot to udpate! thanks for catching this", "author": "agavra", "createdAt": "2020-11-05T20:56:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzg4Mg=="}], "type": "inlineReview"}, {"oid": "b80179045c88861c45fc05c61ad484c4559ab4ee", "url": "https://github.com/confluentinc/ksql/commit/b80179045c88861c45fc05c61ad484c4559ab4ee", "message": "feat: support multi-column key declarations", "committedDate": "2020-11-05T23:39:45Z", "type": "commit"}, {"oid": "3b251ddc8c37bfbb01811961d14b45e2920c62ea", "url": "https://github.com/confluentinc/ksql/commit/3b251ddc8c37bfbb01811961d14b45e2920c62ea", "message": "chore: victorias comments", "committedDate": "2020-11-05T23:39:46Z", "type": "commit"}, {"oid": "f058668991caf6bba494db6416936ee3efa35b8c", "url": "https://github.com/confluentinc/ksql/commit/f058668991caf6bba494db6416936ee3efa35b8c", "message": "chore: rebase", "committedDate": "2020-11-05T23:43:11Z", "type": "commit"}, {"oid": "f058668991caf6bba494db6416936ee3efa35b8c", "url": "https://github.com/confluentinc/ksql/commit/f058668991caf6bba494db6416936ee3efa35b8c", "message": "chore: rebase", "committedDate": "2020-11-05T23:43:11Z", "type": "forcePushed"}]}