{"pr_number": 6721, "pr_title": "docs: klip-42 - Schema Migrations Tool", "pr_createdAt": "2020-12-04T19:41:51Z", "pr_url": "https://github.com/confluentinc/ksql/pull/6721", "timeline": [{"oid": "e6ab1ff376fb389f04d73c07f5abaf6a8cab0022", "url": "https://github.com/confluentinc/ksql/commit/e6ab1ff376fb389f04d73c07f5abaf6a8cab0022", "message": "docs: klip-42 - Schema Migrations Tool", "committedDate": "2020-12-04T19:40:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NzY1OA==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r536447658", "bodyText": "Is squashing (periodically combining all previous migrations into one) out of scope? I don't think it needs to be a v1 thing, but this is historically important because over time, the value of having all migrations around diminishes.", "author": "MichaelDrogalis", "createdAt": "2020-12-04T23:43:26Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: TBD |\n+**Status**: _In Discussion_ |\n+**Discussion**: TBD\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## What is in scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Rollback migrated schemas to previous versions\n+    - Version control ksqlDB schema\n+\n+* Provide a test plan that validates the new tool will meet the product requirements\n+\n+\n+## What is not in scope", "originalCommit": "e6ab1ff376fb389f04d73c07f5abaf6a8cab0022", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzcwNTYzOQ==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537705639", "bodyText": "It is out of scope for this tool. The proposal for squashing is to use a different tool that will export the ksqlDB metastore to a SQL file. Squashing will be a combination of exporting the metastore and replace the migrations files with this new file.\nIf we want to integrate squashing into the migrations tool, then we'll have to support the testing framework (YATT) in order to run every migration in a testing environment, then export the current env as SQL file. We still need the metastore export tool.", "author": "spena", "createdAt": "2020-12-07T17:50:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NzY1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzcwNzc3OA==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537707778", "bodyText": "Makes sense, SGTM.", "author": "MichaelDrogalis", "createdAt": "2020-12-07T17:53:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NzY1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0ODQ2Ng==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r536448466", "bodyText": "One other thing that I think would be really useful would be producing a consolidated view of all the statements in one file. Rails, and I think Django, do this so you can see what is going on in one place. This consolidated view is typically checked into version control, and is always treated as read-only. @derekjn had some ideas about how this relates to or could be subsumed by supporting schema dumping.", "author": "MichaelDrogalis", "createdAt": "2020-12-04T23:46:16Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: TBD |\n+**Status**: _In Discussion_ |\n+**Discussion**: TBD\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## What is in scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Rollback migrated schemas to previous versions\n+    - Version control ksqlDB schema", "originalCommit": "e6ab1ff376fb389f04d73c07f5abaf6a8cab0022", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc2OTI4Nw==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537769287", "bodyText": "Is this similar to Flyway's dry-runs feature? https://flywaydb.org/documentation/concepts/dryruns", "author": "spena", "createdAt": "2020-12-07T19:27:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0ODQ2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjUwNzQ5MA==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r542507490", "bodyText": "I talked with @derekjn about this. This is the functionality we expect to have when working on the dump/export command for ksqlDB, which will export all metadata as a SQL file.", "author": "spena", "createdAt": "2020-12-14T16:09:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0ODQ2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0ODc3Mg==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r536448772", "bodyText": "Is there any ceremony around the description, or can it be whatever? It looks like that is how you make those nice printouts when you migrate?", "author": "MichaelDrogalis", "createdAt": "2020-12-04T23:47:21Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: TBD |\n+**Status**: _In Discussion_ |\n+**Discussion**: TBD\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## What is in scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Rollback migrated schemas to previous versions\n+    - Version control ksqlDB schema\n+\n+* Provide a test plan that validates the new tool will meet the product requirements\n+\n+\n+## What is not in scope\n+\n+* Some features found in existing migrations tools won't be supported\n+\n+  - `Execute entire migrations in a single transaction`\n+\n+    ksqlDB has support for a transactional metastore. However, this is limited to DDL statements that are persisted in the\n+    Command topic. But DML statements, such as INSERT, write directly to the topic and do not work with transactions. This disallows\n+    our tool to provide of a transaction support for the whole migration process. Also, DDL statements may create or delete topics,\n+    which falls in the non-transactional process.\n+\n+  - `Support for simulated or dry-runs executions`\n+\n+    A dry-run requires the tool to know the current state of the ksqlDB schema before attempting to verify the new migrations scripts. This\n+    requires a ksqlDB metastore exporting tool to work. Also, to make this simulation 100% safe, the tool requires a dummy Kafka and SR\n+    environment that can validate issues with topics and SR subjects names, as well as security restrictions.\n+\n+  - `Other features, such as repeatable migrations and callbacks`\n+\n+    Not required for a basic migration.\n+\n+* Do performance analysis on migrations\n+\n+  In other DBs, there are operations that take too much time to complete. Such is the case of ALTER statements, which can add/remove columns\n+  that would take time to complete on large tables. ksqlDB operations are quick unless an issue with the ksqlDB environment affects\n+  these executions.\n+\n+## Value/Return\n+\n+Users will be able to integrate ksqlDB upgrades testing with any CI/CD environments of their choice. This is a huge benefit for users who want\n+to automate ksqlDB upgrades with their application lifecycle.\n+\n+Also, a new tool will let users to easily automate schema evolution and migrations changes. They will be able to deploy new schema changes in\n+all their environments (Prod, QA, Devel, etc).\n+\n+## Public APIS\n+\n+- No changes on current public APIs\n+- A new Java API for Java developers\n+\n+  This seems important. However, it is in consideration if supporting a Java API is necessary.\n+\n+## Design\n+\n+I'm going to adopt `Flyway` and `DBGeni` tool syntax and behavior to design the ksqlDB migrations tool. Users will define a new migration in an SQL\n+script. This new SQL script describes the changes to do to migrate the cluster from state A to state B. Then run the migration from the\n+command line to apply the new state in the ksqlDB cluster. Users can also run this migration automatically as part of the build process and/or\n+testing in a CI/CD environment.\n+\n+For instance, the following example creates a new file that setups the initial state of the cluster.\n+\n+`V1__Initial_setup.sql`\n+```sql\n+CREATE STREAM pageviews (\n+    user_id INTEGER KEY, \n+    url STRING, \n+    status INTEGER\n+) WITH (\n+    KAFKA_TOPIC='pageviews', \n+    VALUE_FORMAT='JSON'    \n+);\n+\n+CREATE TABLE pageviews_metrics AS\n+ SELECT url, COUNT(*) AS num_views\n+  FROM pageviews\n+  GROUP BY url\n+  EMIT CHANGES;\n+```\n+\n+The user runs the migration tool on a specific ksqlDB cluster. The tool updates the cluster by running the SQL statements from the above file.\n+Then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: << Empty Schema >>\n+Migrating schema to version 1 - Initial setup\n+```\n+\n+Later, the user needs new changes on the cluster. All previous migrations files are immutable. So, any changes on the cluster require a new migration\n+file (or SQL script). Let's create one to create the users table.\n+\n+`V2__Add_users.sql`\n+```sql\n+CREATE TABLE users (\n+   ID BIGINT PRIMARY KEY, \n+   STRING NAME, \n+   ADDRESS ADDRESS_TYPE\n+ ) WITH (\n+   KAFKA_TOPIC='users', \n+   VALUE_FORMAT='JSON' \n+ );\n+```\n+\n+The user runs the migration tool on the same ksqlDB cluster. The tool detects the cluster has already version 1, so it executes only the newer version 2 migration\n+file. It then sets the state of the cluster to version 2.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: 1\n+Migrating schema to version 2 - Add users\n+```\n+\n+The benefit of this tool is that it detects the required updates to execute in the ksqlDB cluster. So, users don't need to know which SQL statements need to perform\n+to update the cluster. It also makes it easy to work with multiple clusters. Say that you have devel, stag and prod clusters. The tool will manage and track the version\n+of these clusters and apply the right SQL operations.\n+\n+To be able to do that, the tool will use a metadata stream and table that contains the current schema version and all executed updates.\n+\n+### Schema metadata\n+\n+Each ksqlDB cluster requires metadata objects where to track the current schema state. This is not only useful for the tool to know the migrations files to apply, but also for\n+users who can quickly verify if the cluster requires changes to fix a schema bug or add a major/minor improvement for their applications.\n+\n+The tool creates two metadata objects, a stream and table. automatically during the first migration; or when the user runs the tool with a parameter to initialize it.\n+\n+i.e.\n+```\n+$ ksql-migrations initialize\n+Schema metadata initialized successfully\n+```\n+\n+Due to some query limitations (lack of ORDER BY clause and pull queries working only on materialized views) in ksqlDB, the metadata will be stored in two places;  \n+One stream (MIGRATION_EVENTS) and one table (SCHEMA_VERSION).\n+\n+The stream and table require topics unique for the cluster. In this case, these topics names will use the same convention as the processing log. It's not going\n+to be an internal topic because it will be a user topic. The topic name is: `{clusterID}ksql_{StreamOrTableName}`.\n+\n+The user can specify a different name for the SCHEMA_VERSION table. This can be done through the tool configuration file. See `Configurations` for more details.\n+\n+The `MIGRATION_EVENTS` stream will keep track of every migration change (including undo changes). This will contain the history of changes the user has done. Also, this stream\n+will contain a key to the current version of the schema (specified as `CURRENT` version). Every time a new migration or undo happens, the tool will insert a new event with the\n+`CURRENT` key pointing to the current version.\n+\n+This is the `CREATE` statement for the `MIGRATION_EVENTS` stream:\n+```sql\n+CREATE STREAM migration_events (\n+  version_key  STRING KEY,\n+  version      STRING,\n+  name         STRING,\n+  state        STRING,\n+  undoable     BOOLEAN,\n+  checksum     STRING,\n+  started_on   STRING,\n+  completed_on STRING,\n+  previous     STRING\n+) WITH (  \n+  KAFKA_TOPIC='default_ksql_migration_events',\n+  VALUE_FORMAT='JSON',\n+  PARTITIONS=1,\n+  REPLICAS=1\n+);\n+```\n+\n+The `version_key` column has the version of the migration applied or undone. Other keys `CURRENT` and `LATEST` will be reserved for internal purposes.\n+The `version` column has the version of the migration applied or undone.\n+The `name` column has the name of the migration.\n+The `state` column has the state of the migration process. It can be any of `Pending`, `Running`, `Migrated`, `Error`, `Undone`.\n+The `undoable` column specifies if the migration can be undone or not. This requires an undoable migration file (See `Undo migrations`).\n+The `checksum` column has the MD5 checksum of the migration file. It is used to validate the schema migrations with the local files.\n+The `started_on` column has the date and time when the migration started.\n+The `completed_on` column has the date and time when the migration finished.\n+The `previous` column has the previous version applied.\n+\n+The `SCHEMA_VERSION` table will also keep track of every migration change (including undo changes), but with the difference that being a table the tool will see quickly if a schema\n+version has been migrated or undone. It will also give us a quick view of the `CURRENT` state of the schema. The major advantage is that the tool will use pull queries in this materialized\n+view to get the `CURRENT` state of the cluster.\n+\n+There is another reserved key `LATEST` that will point to the latest change applied (migrated or undone). This will be used by the tool to stream all changes up to the row that `LATEST` points, and stop.\n+The `ksql-migrations info` command will use this to display information about the migrations that have been applied or undone. I cannot stream the `MIGRATION_EVENTS` or `SCHEMA_VERSION` directly because\n+the tool does not know when to stop.\n+\n+\n+This is the `CREATE` statement for the `SCHEMA_VERSION` table:\n+```sql\n+CREATE TABLE schema_version\n+  WITH (\n+    KAFKA_TOPIC='default_ksql_schema_version',\n+    VALUE_FORMAT='JSON',\n+    PARTITIONS=1\n+  )\n+  AS SELECT \n+    version_key, \n+    latest_by_offset(version) as version, \n+    latest_by_offset(name) AS name, \n+    latest_by_offset(state) AS state, \n+    latest_by_offset(undoable) AS undoable, \n+    latest_by_offset(checksum) AS checksum, \n+    latest_by_offset(started_on) AS started_on, \n+    latest_by_offset(completed_on) AS completed_on, \n+    latest_by_offset(previous) AS previous\n+  FROM migration_events \n+  GROUP BY version_key;\n+```\n+\n+The following are the outputs that we'll see on each stream and table, and how the tool will figure out the current schema version using pull queries.\n+\n+The `MIGRATION_EVENTS` stream output:\n+```shell script\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | undoable | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Migrated | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| 2           | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The `SCHEMA_VERSION` table output:\n+```shell script\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | undoable | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The tool will later use pull queries to identify the current state of the system:\n+```sql\n+SELECT version, state, previous FROM SCHEMA_VERSION WHERE version_key = 'CURRENT'; \n+```\n+\n+When undo changes happen, the query will first get the current schema version to undo. Apply the revert operations, then set `CURRENT` to\n+the previous migrated version. In this case, it will look at the `previous` column in `SCHEMA_VERSION`, then use a pull query to get information\n+about the previous migration.\n+```sql\n+SELECT * FROM SCHEMA_VERSION WHERE version_key = '<previous>';\n+```\n+\n+And set the new `CURRENT` in the `MIGRATION_EVENTS` to update the current schema version.\n+\n+### Undo migrations\n+\n+Undo a previous migration is necessary in the application lifecycle. A user sometimes want to revert the changes of an application because of a bug found in it.\n+This also requires the database schema to be reverted or rollback to the previous version.\n+\n+The migrations tool allows users to revert changes. Note that undo is considered a forward migration. A new migration file is required which contains\n+the SQL operations to revert the changes of a previous migration. The file in this case should contain the `U` prefix with the version number of the migration to rollback.\n+\n+For instance, let's undo the migration version 2 applied before. The migration file used before was named `V2__Add_users.sql`. For the undo file, we should add the `U` prefix.\n+\n+`U2_Add_users.sql`\n+```sql\n+DROP TABLE users;\n+```\n+\n+The user runs the migration tool on the ksqlDB cluster. The tool detects the cluster has version 2, so it executes only the undo file for version 2.  \n+It then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations undo\n+Current version of schema: 2\n+Undoing migration of schema to version 2 - Add users\n+```\n+\n+The `undo` action will only revert the previous change. It will not attempt to undo all applied migrations.\n+\n+\n+### Naming convention\n+\n+Hope you have noticed the naming rules I followed in the previous examples for naming the migration files. Having a naming convention for files is necessary\n+for the tool to detect what migration to apply or revert. Naming files are easier than creating configurations or command parameters to specify the same info.\n+\n+The migration files follow the same `Flyway` naming convention.\n+`(Prefix)(Version)__(Description).sql`\n+\n+The `Prefix` specifies whether the file is a new migration (`V`) or undo (`U`) file.\n+The `Version` is the version number used for the schema. For minor versions, such as `1.1`, an underscore is required (i.e. `1_1`)\n+The `Description` is just a name or description of the new migration.", "originalCommit": "e6ab1ff376fb389f04d73c07f5abaf6a8cab0022", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzcxNjU1Mw==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537716553", "bodyText": "Just using underscores or spaces to separate words. If underscores are used, then they will automatically converted to spaces at runtime. I'll add that comment.", "author": "spena", "createdAt": "2020-12-07T18:06:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0ODc3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0OTAyMg==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r536449022", "bodyText": "Is it worthwhile to support these as Docker environment variables, as we do with our general server configuration?", "author": "MichaelDrogalis", "createdAt": "2020-12-04T23:48:16Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: TBD |\n+**Status**: _In Discussion_ |\n+**Discussion**: TBD\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## What is in scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Rollback migrated schemas to previous versions\n+    - Version control ksqlDB schema\n+\n+* Provide a test plan that validates the new tool will meet the product requirements\n+\n+\n+## What is not in scope\n+\n+* Some features found in existing migrations tools won't be supported\n+\n+  - `Execute entire migrations in a single transaction`\n+\n+    ksqlDB has support for a transactional metastore. However, this is limited to DDL statements that are persisted in the\n+    Command topic. But DML statements, such as INSERT, write directly to the topic and do not work with transactions. This disallows\n+    our tool to provide of a transaction support for the whole migration process. Also, DDL statements may create or delete topics,\n+    which falls in the non-transactional process.\n+\n+  - `Support for simulated or dry-runs executions`\n+\n+    A dry-run requires the tool to know the current state of the ksqlDB schema before attempting to verify the new migrations scripts. This\n+    requires a ksqlDB metastore exporting tool to work. Also, to make this simulation 100% safe, the tool requires a dummy Kafka and SR\n+    environment that can validate issues with topics and SR subjects names, as well as security restrictions.\n+\n+  - `Other features, such as repeatable migrations and callbacks`\n+\n+    Not required for a basic migration.\n+\n+* Do performance analysis on migrations\n+\n+  In other DBs, there are operations that take too much time to complete. Such is the case of ALTER statements, which can add/remove columns\n+  that would take time to complete on large tables. ksqlDB operations are quick unless an issue with the ksqlDB environment affects\n+  these executions.\n+\n+## Value/Return\n+\n+Users will be able to integrate ksqlDB upgrades testing with any CI/CD environments of their choice. This is a huge benefit for users who want\n+to automate ksqlDB upgrades with their application lifecycle.\n+\n+Also, a new tool will let users to easily automate schema evolution and migrations changes. They will be able to deploy new schema changes in\n+all their environments (Prod, QA, Devel, etc).\n+\n+## Public APIS\n+\n+- No changes on current public APIs\n+- A new Java API for Java developers\n+\n+  This seems important. However, it is in consideration if supporting a Java API is necessary.\n+\n+## Design\n+\n+I'm going to adopt `Flyway` and `DBGeni` tool syntax and behavior to design the ksqlDB migrations tool. Users will define a new migration in an SQL\n+script. This new SQL script describes the changes to do to migrate the cluster from state A to state B. Then run the migration from the\n+command line to apply the new state in the ksqlDB cluster. Users can also run this migration automatically as part of the build process and/or\n+testing in a CI/CD environment.\n+\n+For instance, the following example creates a new file that setups the initial state of the cluster.\n+\n+`V1__Initial_setup.sql`\n+```sql\n+CREATE STREAM pageviews (\n+    user_id INTEGER KEY, \n+    url STRING, \n+    status INTEGER\n+) WITH (\n+    KAFKA_TOPIC='pageviews', \n+    VALUE_FORMAT='JSON'    \n+);\n+\n+CREATE TABLE pageviews_metrics AS\n+ SELECT url, COUNT(*) AS num_views\n+  FROM pageviews\n+  GROUP BY url\n+  EMIT CHANGES;\n+```\n+\n+The user runs the migration tool on a specific ksqlDB cluster. The tool updates the cluster by running the SQL statements from the above file.\n+Then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: << Empty Schema >>\n+Migrating schema to version 1 - Initial setup\n+```\n+\n+Later, the user needs new changes on the cluster. All previous migrations files are immutable. So, any changes on the cluster require a new migration\n+file (or SQL script). Let's create one to create the users table.\n+\n+`V2__Add_users.sql`\n+```sql\n+CREATE TABLE users (\n+   ID BIGINT PRIMARY KEY, \n+   STRING NAME, \n+   ADDRESS ADDRESS_TYPE\n+ ) WITH (\n+   KAFKA_TOPIC='users', \n+   VALUE_FORMAT='JSON' \n+ );\n+```\n+\n+The user runs the migration tool on the same ksqlDB cluster. The tool detects the cluster has already version 1, so it executes only the newer version 2 migration\n+file. It then sets the state of the cluster to version 2.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: 1\n+Migrating schema to version 2 - Add users\n+```\n+\n+The benefit of this tool is that it detects the required updates to execute in the ksqlDB cluster. So, users don't need to know which SQL statements need to perform\n+to update the cluster. It also makes it easy to work with multiple clusters. Say that you have devel, stag and prod clusters. The tool will manage and track the version\n+of these clusters and apply the right SQL operations.\n+\n+To be able to do that, the tool will use a metadata stream and table that contains the current schema version and all executed updates.\n+\n+### Schema metadata\n+\n+Each ksqlDB cluster requires metadata objects where to track the current schema state. This is not only useful for the tool to know the migrations files to apply, but also for\n+users who can quickly verify if the cluster requires changes to fix a schema bug or add a major/minor improvement for their applications.\n+\n+The tool creates two metadata objects, a stream and table. automatically during the first migration; or when the user runs the tool with a parameter to initialize it.\n+\n+i.e.\n+```\n+$ ksql-migrations initialize\n+Schema metadata initialized successfully\n+```\n+\n+Due to some query limitations (lack of ORDER BY clause and pull queries working only on materialized views) in ksqlDB, the metadata will be stored in two places;  \n+One stream (MIGRATION_EVENTS) and one table (SCHEMA_VERSION).\n+\n+The stream and table require topics unique for the cluster. In this case, these topics names will use the same convention as the processing log. It's not going\n+to be an internal topic because it will be a user topic. The topic name is: `{clusterID}ksql_{StreamOrTableName}`.\n+\n+The user can specify a different name for the SCHEMA_VERSION table. This can be done through the tool configuration file. See `Configurations` for more details.\n+\n+The `MIGRATION_EVENTS` stream will keep track of every migration change (including undo changes). This will contain the history of changes the user has done. Also, this stream\n+will contain a key to the current version of the schema (specified as `CURRENT` version). Every time a new migration or undo happens, the tool will insert a new event with the\n+`CURRENT` key pointing to the current version.\n+\n+This is the `CREATE` statement for the `MIGRATION_EVENTS` stream:\n+```sql\n+CREATE STREAM migration_events (\n+  version_key  STRING KEY,\n+  version      STRING,\n+  name         STRING,\n+  state        STRING,\n+  undoable     BOOLEAN,\n+  checksum     STRING,\n+  started_on   STRING,\n+  completed_on STRING,\n+  previous     STRING\n+) WITH (  \n+  KAFKA_TOPIC='default_ksql_migration_events',\n+  VALUE_FORMAT='JSON',\n+  PARTITIONS=1,\n+  REPLICAS=1\n+);\n+```\n+\n+The `version_key` column has the version of the migration applied or undone. Other keys `CURRENT` and `LATEST` will be reserved for internal purposes.\n+The `version` column has the version of the migration applied or undone.\n+The `name` column has the name of the migration.\n+The `state` column has the state of the migration process. It can be any of `Pending`, `Running`, `Migrated`, `Error`, `Undone`.\n+The `undoable` column specifies if the migration can be undone or not. This requires an undoable migration file (See `Undo migrations`).\n+The `checksum` column has the MD5 checksum of the migration file. It is used to validate the schema migrations with the local files.\n+The `started_on` column has the date and time when the migration started.\n+The `completed_on` column has the date and time when the migration finished.\n+The `previous` column has the previous version applied.\n+\n+The `SCHEMA_VERSION` table will also keep track of every migration change (including undo changes), but with the difference that being a table the tool will see quickly if a schema\n+version has been migrated or undone. It will also give us a quick view of the `CURRENT` state of the schema. The major advantage is that the tool will use pull queries in this materialized\n+view to get the `CURRENT` state of the cluster.\n+\n+There is another reserved key `LATEST` that will point to the latest change applied (migrated or undone). This will be used by the tool to stream all changes up to the row that `LATEST` points, and stop.\n+The `ksql-migrations info` command will use this to display information about the migrations that have been applied or undone. I cannot stream the `MIGRATION_EVENTS` or `SCHEMA_VERSION` directly because\n+the tool does not know when to stop.\n+\n+\n+This is the `CREATE` statement for the `SCHEMA_VERSION` table:\n+```sql\n+CREATE TABLE schema_version\n+  WITH (\n+    KAFKA_TOPIC='default_ksql_schema_version',\n+    VALUE_FORMAT='JSON',\n+    PARTITIONS=1\n+  )\n+  AS SELECT \n+    version_key, \n+    latest_by_offset(version) as version, \n+    latest_by_offset(name) AS name, \n+    latest_by_offset(state) AS state, \n+    latest_by_offset(undoable) AS undoable, \n+    latest_by_offset(checksum) AS checksum, \n+    latest_by_offset(started_on) AS started_on, \n+    latest_by_offset(completed_on) AS completed_on, \n+    latest_by_offset(previous) AS previous\n+  FROM migration_events \n+  GROUP BY version_key;\n+```\n+\n+The following are the outputs that we'll see on each stream and table, and how the tool will figure out the current schema version using pull queries.\n+\n+The `MIGRATION_EVENTS` stream output:\n+```shell script\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | undoable | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Migrated | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| 2           | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The `SCHEMA_VERSION` table output:\n+```shell script\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | undoable | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The tool will later use pull queries to identify the current state of the system:\n+```sql\n+SELECT version, state, previous FROM SCHEMA_VERSION WHERE version_key = 'CURRENT'; \n+```\n+\n+When undo changes happen, the query will first get the current schema version to undo. Apply the revert operations, then set `CURRENT` to\n+the previous migrated version. In this case, it will look at the `previous` column in `SCHEMA_VERSION`, then use a pull query to get information\n+about the previous migration.\n+```sql\n+SELECT * FROM SCHEMA_VERSION WHERE version_key = '<previous>';\n+```\n+\n+And set the new `CURRENT` in the `MIGRATION_EVENTS` to update the current schema version.\n+\n+### Undo migrations\n+\n+Undo a previous migration is necessary in the application lifecycle. A user sometimes want to revert the changes of an application because of a bug found in it.\n+This also requires the database schema to be reverted or rollback to the previous version.\n+\n+The migrations tool allows users to revert changes. Note that undo is considered a forward migration. A new migration file is required which contains\n+the SQL operations to revert the changes of a previous migration. The file in this case should contain the `U` prefix with the version number of the migration to rollback.\n+\n+For instance, let's undo the migration version 2 applied before. The migration file used before was named `V2__Add_users.sql`. For the undo file, we should add the `U` prefix.\n+\n+`U2_Add_users.sql`\n+```sql\n+DROP TABLE users;\n+```\n+\n+The user runs the migration tool on the ksqlDB cluster. The tool detects the cluster has version 2, so it executes only the undo file for version 2.  \n+It then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations undo\n+Current version of schema: 2\n+Undoing migration of schema to version 2 - Add users\n+```\n+\n+The `undo` action will only revert the previous change. It will not attempt to undo all applied migrations.\n+\n+\n+### Naming convention\n+\n+Hope you have noticed the naming rules I followed in the previous examples for naming the migration files. Having a naming convention for files is necessary\n+for the tool to detect what migration to apply or revert. Naming files are easier than creating configurations or command parameters to specify the same info.\n+\n+The migration files follow the same `Flyway` naming convention.\n+`(Prefix)(Version)__(Description).sql`\n+\n+The `Prefix` specifies whether the file is a new migration (`V`) or undo (`U`) file.\n+The `Version` is the version number used for the schema. For minor versions, such as `1.1`, an underscore is required (i.e. `1_1`)\n+The `Description` is just a name or description of the new migration.\n+\n+i.e.\n+```\n+- V1__Initial_setup.sql    # a new version to migrate (v1)\n+- U1__Initial_setup.sql    # rollback v1 schema\n+- V2__Add_users.sql        # a new version to migrate (v2)\n+- U2__Add_users.sql        # rollback v2 schema\n+- V2_1__Fix_topic_name.sql # A new version to migrate (v2.1)\n+- U2_1__Fix_topic_name.sql # rollback v2.1 schema\n+```\n+\n+It is recommended the user creates these two files on any new migration. The tool will not enforce that. We need specify this recomendation in the ksqlDB documents.\n+\n+### Command Syntax\n+\n+Finally, let's look at the rest of the command parameters that will exist to facilitate schema migrations.\n+\n+```shell script\n+Usage:\n+  ksql-migrations [options] commands\n+  \n+Commands\n+  initialize   Initializes the schema version table\n+\n+  apply ( all | next | until <target> )\n+  \n+              Migrates a schema to new available schema versions (default: next)\n+              \n+              If 'all' is specified, then it migrates all newer versions available\n+              If 'next' is specified, then it migrates only the next available version\n+              If 'until <target>' is specified, then it migrates all available versions before <target>\n+  \n+  undo ( all | last | until <target> )\n+  \n+              Rollbacks a schema to the previous schema version (default: last)\n+              \n+              If 'all' is specified, then it rollbacks all previous versions\n+              If 'last' is specified, then it rollbacks the previous version\n+              If 'until <target>' is specified, then it rollbacks all previous versions after <target>\n+  \n+  info        Displays information about the current and available migrations\n+  \n+  baseline    Sets the current schema to the specified version\n+  \n+              This is useful when production environments already have a schema unversioned. This sets\n+              the baseline from where to start applying migrations (i.e. kqsl-migrations baseline 1 'Current State')\n+  \n+  clean       Cleans the schema metadata objects                \n+  \n+  validate    Validate applied migrations against local files\n+  \n+              Compares local files checksum against the current metadata checksums to check for migrations files that have changed.\n+              This tells the user that their schema might be not valid against their local files.\n+  \n+Options\n+  -c, --config-file  Specifies a configuration file\n+ \n+  -h, --help         Shows this help  \n+    \n+```\n+\n+### Configurations\n+\n+The tool will support a configuration file where all details for the server and tool migrations will be set. The following\n+are the basic configurations that the tool should support.\n+\n+Example of `ksql-migrations.properties`\n+```\n+# Server URL and authentication", "originalCommit": "e6ab1ff376fb389f04d73c07f5abaf6a8cab0022", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY0NDMxNw==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537644317", "bodyText": "This will happen automatically, given the behavior of our docker utility belt.", "author": "colinhicks", "createdAt": "2020-12-07T16:28:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0OTAyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzc3MDI4Nw==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537770287", "bodyText": "Yes, those are automatically supported.", "author": "spena", "createdAt": "2020-12-07T19:28:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0OTAyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0OTMyNg==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r536449326", "bodyText": "What would happen if multiple CI servers tried to migrate against the same cluster at the same time? Put differently, what sort of race conditions can happen?", "author": "MichaelDrogalis", "createdAt": "2020-12-04T23:49:19Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: TBD |\n+**Status**: _In Discussion_ |\n+**Discussion**: TBD\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## What is in scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Rollback migrated schemas to previous versions\n+    - Version control ksqlDB schema\n+\n+* Provide a test plan that validates the new tool will meet the product requirements\n+\n+\n+## What is not in scope\n+\n+* Some features found in existing migrations tools won't be supported\n+\n+  - `Execute entire migrations in a single transaction`\n+\n+    ksqlDB has support for a transactional metastore. However, this is limited to DDL statements that are persisted in the\n+    Command topic. But DML statements, such as INSERT, write directly to the topic and do not work with transactions. This disallows\n+    our tool to provide of a transaction support for the whole migration process. Also, DDL statements may create or delete topics,\n+    which falls in the non-transactional process.\n+\n+  - `Support for simulated or dry-runs executions`\n+\n+    A dry-run requires the tool to know the current state of the ksqlDB schema before attempting to verify the new migrations scripts. This\n+    requires a ksqlDB metastore exporting tool to work. Also, to make this simulation 100% safe, the tool requires a dummy Kafka and SR\n+    environment that can validate issues with topics and SR subjects names, as well as security restrictions.\n+\n+  - `Other features, such as repeatable migrations and callbacks`\n+\n+    Not required for a basic migration.\n+\n+* Do performance analysis on migrations\n+\n+  In other DBs, there are operations that take too much time to complete. Such is the case of ALTER statements, which can add/remove columns\n+  that would take time to complete on large tables. ksqlDB operations are quick unless an issue with the ksqlDB environment affects\n+  these executions.\n+\n+## Value/Return\n+\n+Users will be able to integrate ksqlDB upgrades testing with any CI/CD environments of their choice. This is a huge benefit for users who want\n+to automate ksqlDB upgrades with their application lifecycle.\n+\n+Also, a new tool will let users to easily automate schema evolution and migrations changes. They will be able to deploy new schema changes in\n+all their environments (Prod, QA, Devel, etc).\n+\n+## Public APIS\n+\n+- No changes on current public APIs\n+- A new Java API for Java developers\n+\n+  This seems important. However, it is in consideration if supporting a Java API is necessary.\n+\n+## Design\n+\n+I'm going to adopt `Flyway` and `DBGeni` tool syntax and behavior to design the ksqlDB migrations tool. Users will define a new migration in an SQL\n+script. This new SQL script describes the changes to do to migrate the cluster from state A to state B. Then run the migration from the\n+command line to apply the new state in the ksqlDB cluster. Users can also run this migration automatically as part of the build process and/or\n+testing in a CI/CD environment.\n+\n+For instance, the following example creates a new file that setups the initial state of the cluster.\n+\n+`V1__Initial_setup.sql`\n+```sql\n+CREATE STREAM pageviews (\n+    user_id INTEGER KEY, \n+    url STRING, \n+    status INTEGER\n+) WITH (\n+    KAFKA_TOPIC='pageviews', \n+    VALUE_FORMAT='JSON'    \n+);\n+\n+CREATE TABLE pageviews_metrics AS\n+ SELECT url, COUNT(*) AS num_views\n+  FROM pageviews\n+  GROUP BY url\n+  EMIT CHANGES;\n+```\n+\n+The user runs the migration tool on a specific ksqlDB cluster. The tool updates the cluster by running the SQL statements from the above file.\n+Then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: << Empty Schema >>\n+Migrating schema to version 1 - Initial setup\n+```\n+\n+Later, the user needs new changes on the cluster. All previous migrations files are immutable. So, any changes on the cluster require a new migration\n+file (or SQL script). Let's create one to create the users table.\n+\n+`V2__Add_users.sql`\n+```sql\n+CREATE TABLE users (\n+   ID BIGINT PRIMARY KEY, \n+   STRING NAME, \n+   ADDRESS ADDRESS_TYPE\n+ ) WITH (\n+   KAFKA_TOPIC='users', \n+   VALUE_FORMAT='JSON' \n+ );\n+```\n+\n+The user runs the migration tool on the same ksqlDB cluster. The tool detects the cluster has already version 1, so it executes only the newer version 2 migration\n+file. It then sets the state of the cluster to version 2.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: 1\n+Migrating schema to version 2 - Add users\n+```\n+\n+The benefit of this tool is that it detects the required updates to execute in the ksqlDB cluster. So, users don't need to know which SQL statements need to perform\n+to update the cluster. It also makes it easy to work with multiple clusters. Say that you have devel, stag and prod clusters. The tool will manage and track the version\n+of these clusters and apply the right SQL operations.\n+\n+To be able to do that, the tool will use a metadata stream and table that contains the current schema version and all executed updates.\n+\n+### Schema metadata\n+\n+Each ksqlDB cluster requires metadata objects where to track the current schema state. This is not only useful for the tool to know the migrations files to apply, but also for\n+users who can quickly verify if the cluster requires changes to fix a schema bug or add a major/minor improvement for their applications.\n+\n+The tool creates two metadata objects, a stream and table. automatically during the first migration; or when the user runs the tool with a parameter to initialize it.\n+\n+i.e.\n+```\n+$ ksql-migrations initialize\n+Schema metadata initialized successfully\n+```\n+\n+Due to some query limitations (lack of ORDER BY clause and pull queries working only on materialized views) in ksqlDB, the metadata will be stored in two places;  \n+One stream (MIGRATION_EVENTS) and one table (SCHEMA_VERSION).\n+\n+The stream and table require topics unique for the cluster. In this case, these topics names will use the same convention as the processing log. It's not going\n+to be an internal topic because it will be a user topic. The topic name is: `{clusterID}ksql_{StreamOrTableName}`.\n+\n+The user can specify a different name for the SCHEMA_VERSION table. This can be done through the tool configuration file. See `Configurations` for more details.\n+\n+The `MIGRATION_EVENTS` stream will keep track of every migration change (including undo changes). This will contain the history of changes the user has done. Also, this stream\n+will contain a key to the current version of the schema (specified as `CURRENT` version). Every time a new migration or undo happens, the tool will insert a new event with the\n+`CURRENT` key pointing to the current version.\n+\n+This is the `CREATE` statement for the `MIGRATION_EVENTS` stream:\n+```sql\n+CREATE STREAM migration_events (\n+  version_key  STRING KEY,\n+  version      STRING,\n+  name         STRING,\n+  state        STRING,\n+  undoable     BOOLEAN,\n+  checksum     STRING,\n+  started_on   STRING,\n+  completed_on STRING,\n+  previous     STRING\n+) WITH (  \n+  KAFKA_TOPIC='default_ksql_migration_events',\n+  VALUE_FORMAT='JSON',\n+  PARTITIONS=1,\n+  REPLICAS=1\n+);\n+```\n+\n+The `version_key` column has the version of the migration applied or undone. Other keys `CURRENT` and `LATEST` will be reserved for internal purposes.\n+The `version` column has the version of the migration applied or undone.\n+The `name` column has the name of the migration.\n+The `state` column has the state of the migration process. It can be any of `Pending`, `Running`, `Migrated`, `Error`, `Undone`.\n+The `undoable` column specifies if the migration can be undone or not. This requires an undoable migration file (See `Undo migrations`).\n+The `checksum` column has the MD5 checksum of the migration file. It is used to validate the schema migrations with the local files.\n+The `started_on` column has the date and time when the migration started.\n+The `completed_on` column has the date and time when the migration finished.\n+The `previous` column has the previous version applied.\n+\n+The `SCHEMA_VERSION` table will also keep track of every migration change (including undo changes), but with the difference that being a table the tool will see quickly if a schema\n+version has been migrated or undone. It will also give us a quick view of the `CURRENT` state of the schema. The major advantage is that the tool will use pull queries in this materialized\n+view to get the `CURRENT` state of the cluster.\n+\n+There is another reserved key `LATEST` that will point to the latest change applied (migrated or undone). This will be used by the tool to stream all changes up to the row that `LATEST` points, and stop.\n+The `ksql-migrations info` command will use this to display information about the migrations that have been applied or undone. I cannot stream the `MIGRATION_EVENTS` or `SCHEMA_VERSION` directly because\n+the tool does not know when to stop.\n+\n+\n+This is the `CREATE` statement for the `SCHEMA_VERSION` table:\n+```sql\n+CREATE TABLE schema_version\n+  WITH (\n+    KAFKA_TOPIC='default_ksql_schema_version',\n+    VALUE_FORMAT='JSON',\n+    PARTITIONS=1\n+  )\n+  AS SELECT \n+    version_key, \n+    latest_by_offset(version) as version, \n+    latest_by_offset(name) AS name, \n+    latest_by_offset(state) AS state, \n+    latest_by_offset(undoable) AS undoable, \n+    latest_by_offset(checksum) AS checksum, \n+    latest_by_offset(started_on) AS started_on, \n+    latest_by_offset(completed_on) AS completed_on, \n+    latest_by_offset(previous) AS previous\n+  FROM migration_events \n+  GROUP BY version_key;\n+```\n+\n+The following are the outputs that we'll see on each stream and table, and how the tool will figure out the current schema version using pull queries.\n+\n+The `MIGRATION_EVENTS` stream output:\n+```shell script\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | undoable | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Migrated | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| 2           | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The `SCHEMA_VERSION` table output:\n+```shell script\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | undoable | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The tool will later use pull queries to identify the current state of the system:\n+```sql\n+SELECT version, state, previous FROM SCHEMA_VERSION WHERE version_key = 'CURRENT'; \n+```\n+\n+When undo changes happen, the query will first get the current schema version to undo. Apply the revert operations, then set `CURRENT` to\n+the previous migrated version. In this case, it will look at the `previous` column in `SCHEMA_VERSION`, then use a pull query to get information\n+about the previous migration.\n+```sql\n+SELECT * FROM SCHEMA_VERSION WHERE version_key = '<previous>';\n+```\n+\n+And set the new `CURRENT` in the `MIGRATION_EVENTS` to update the current schema version.\n+\n+### Undo migrations\n+\n+Undo a previous migration is necessary in the application lifecycle. A user sometimes want to revert the changes of an application because of a bug found in it.\n+This also requires the database schema to be reverted or rollback to the previous version.\n+\n+The migrations tool allows users to revert changes. Note that undo is considered a forward migration. A new migration file is required which contains\n+the SQL operations to revert the changes of a previous migration. The file in this case should contain the `U` prefix with the version number of the migration to rollback.\n+\n+For instance, let's undo the migration version 2 applied before. The migration file used before was named `V2__Add_users.sql`. For the undo file, we should add the `U` prefix.\n+\n+`U2_Add_users.sql`\n+```sql\n+DROP TABLE users;\n+```\n+\n+The user runs the migration tool on the ksqlDB cluster. The tool detects the cluster has version 2, so it executes only the undo file for version 2.  \n+It then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations undo\n+Current version of schema: 2\n+Undoing migration of schema to version 2 - Add users\n+```\n+\n+The `undo` action will only revert the previous change. It will not attempt to undo all applied migrations.\n+\n+\n+### Naming convention\n+\n+Hope you have noticed the naming rules I followed in the previous examples for naming the migration files. Having a naming convention for files is necessary\n+for the tool to detect what migration to apply or revert. Naming files are easier than creating configurations or command parameters to specify the same info.\n+\n+The migration files follow the same `Flyway` naming convention.\n+`(Prefix)(Version)__(Description).sql`\n+\n+The `Prefix` specifies whether the file is a new migration (`V`) or undo (`U`) file.\n+The `Version` is the version number used for the schema. For minor versions, such as `1.1`, an underscore is required (i.e. `1_1`)\n+The `Description` is just a name or description of the new migration.\n+\n+i.e.\n+```\n+- V1__Initial_setup.sql    # a new version to migrate (v1)\n+- U1__Initial_setup.sql    # rollback v1 schema\n+- V2__Add_users.sql        # a new version to migrate (v2)\n+- U2__Add_users.sql        # rollback v2 schema\n+- V2_1__Fix_topic_name.sql # A new version to migrate (v2.1)\n+- U2_1__Fix_topic_name.sql # rollback v2.1 schema\n+```\n+\n+It is recommended the user creates these two files on any new migration. The tool will not enforce that. We need specify this recomendation in the ksqlDB documents.\n+\n+### Command Syntax\n+\n+Finally, let's look at the rest of the command parameters that will exist to facilitate schema migrations.\n+\n+```shell script\n+Usage:\n+  ksql-migrations [options] commands\n+  \n+Commands\n+  initialize   Initializes the schema version table\n+\n+  apply ( all | next | until <target> )\n+  \n+              Migrates a schema to new available schema versions (default: next)\n+              \n+              If 'all' is specified, then it migrates all newer versions available\n+              If 'next' is specified, then it migrates only the next available version\n+              If 'until <target>' is specified, then it migrates all available versions before <target>\n+  \n+  undo ( all | last | until <target> )\n+  \n+              Rollbacks a schema to the previous schema version (default: last)\n+              \n+              If 'all' is specified, then it rollbacks all previous versions\n+              If 'last' is specified, then it rollbacks the previous version\n+              If 'until <target>' is specified, then it rollbacks all previous versions after <target>\n+  \n+  info        Displays information about the current and available migrations\n+  \n+  baseline    Sets the current schema to the specified version\n+  \n+              This is useful when production environments already have a schema unversioned. This sets\n+              the baseline from where to start applying migrations (i.e. kqsl-migrations baseline 1 'Current State')\n+  \n+  clean       Cleans the schema metadata objects                \n+  \n+  validate    Validate applied migrations against local files\n+  \n+              Compares local files checksum against the current metadata checksums to check for migrations files that have changed.\n+              This tells the user that their schema might be not valid against their local files.\n+  \n+Options\n+  -c, --config-file  Specifies a configuration file\n+ \n+  -h, --help         Shows this help  \n+    \n+```\n+\n+### Configurations\n+\n+The tool will support a configuration file where all details for the server and tool migrations will be set. The following\n+are the basic configurations that the tool should support.\n+\n+Example of `ksql-migrations.properties`\n+```\n+# Server URL and authentication\n+ksql.server.url='http://localhost:8080'\n+ksql.username='user1'\n+ksql.password='pass1'\n+\n+# Migrations details\n+ksql.migrations.stream.name='migration_events'\n+ksql.migrations.table.name='schema_version'\n+```\n+\n+Note: The command line options and other configurations will also be defined during the implementation.\n+\n+### Questions", "originalCommit": "e6ab1ff376fb389f04d73c07f5abaf6a8cab0022", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzcxODQ2Nw==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537718467", "bodyText": "Locking the migrations stream and tables may help to avoid these race conditions. I need to think how to do that to also avoid locking an object during a failure in the migrations. Say the network connection fails, thus cannot unlock the stream and table.\nI am thinking of adding another command to the tool to manually unlock or fix a failed migration. I'll add more info to the KLIP later.", "author": "spena", "createdAt": "2020-12-07T18:09:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0OTMyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzg0ODQ1Nw==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537848457", "bodyText": "I considered using a second stream and table to store lock information, but it is getting complicated. I tried different ideas (which we can discuss offline), but I can't make it work. For instance, say we have a stream with schema (id, locked, locked_by) and the following rows:\nid,  locked,  locked_by\n* 1, true       u1\n  1, true       u2\n  1, true       u3\n  1, false     u1\n\nHow can I create a table that shows me who has the lock? It should be u1. I was playing with earliest_by_offset, latest_by_offset. Also latest_by_offset(id, 2) to get the latest two to check in the application which one has the lock, but I forgot I could have more than 2 users trying to migrate. Without having transactions or a locking mechanism in ksqlDB, this is not reliable.\nI think the only solution would be to support LOCK in ksqlDB, which requires session connections with the clients. This would let clients lock a table for the client session, thus avoiding other sessions read or write into a stream or table. @colinhicks We talked about sessions before, and I think we need this time. What do you think?", "author": "spena", "createdAt": "2020-12-07T21:33:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0OTMyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzg1MzMyOQ==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537853329", "bodyText": "Locking might get really complicated to add. We don't have to solve this right out of the gate, but we should know how it'll behave in v1.", "author": "MichaelDrogalis", "createdAt": "2020-12-07T21:41:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0OTMyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzYyMjU1Ng==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537622556", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            `U2_Add_users.sql`\n          \n          \n            \n            `U2__Add_users.sql`", "author": "colinhicks", "createdAt": "2020-12-07T16:01:17Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: TBD |\n+**Status**: _In Discussion_ |\n+**Discussion**: TBD\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## What is in scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Rollback migrated schemas to previous versions\n+    - Version control ksqlDB schema\n+\n+* Provide a test plan that validates the new tool will meet the product requirements\n+\n+\n+## What is not in scope\n+\n+* Some features found in existing migrations tools won't be supported\n+\n+  - `Execute entire migrations in a single transaction`\n+\n+    ksqlDB has support for a transactional metastore. However, this is limited to DDL statements that are persisted in the\n+    Command topic. But DML statements, such as INSERT, write directly to the topic and do not work with transactions. This disallows\n+    our tool to provide of a transaction support for the whole migration process. Also, DDL statements may create or delete topics,\n+    which falls in the non-transactional process.\n+\n+  - `Support for simulated or dry-runs executions`\n+\n+    A dry-run requires the tool to know the current state of the ksqlDB schema before attempting to verify the new migrations scripts. This\n+    requires a ksqlDB metastore exporting tool to work. Also, to make this simulation 100% safe, the tool requires a dummy Kafka and SR\n+    environment that can validate issues with topics and SR subjects names, as well as security restrictions.\n+\n+  - `Other features, such as repeatable migrations and callbacks`\n+\n+    Not required for a basic migration.\n+\n+* Do performance analysis on migrations\n+\n+  In other DBs, there are operations that take too much time to complete. Such is the case of ALTER statements, which can add/remove columns\n+  that would take time to complete on large tables. ksqlDB operations are quick unless an issue with the ksqlDB environment affects\n+  these executions.\n+\n+## Value/Return\n+\n+Users will be able to integrate ksqlDB upgrades testing with any CI/CD environments of their choice. This is a huge benefit for users who want\n+to automate ksqlDB upgrades with their application lifecycle.\n+\n+Also, a new tool will let users to easily automate schema evolution and migrations changes. They will be able to deploy new schema changes in\n+all their environments (Prod, QA, Devel, etc).\n+\n+## Public APIS\n+\n+- No changes on current public APIs\n+- A new Java API for Java developers\n+\n+  This seems important. However, it is in consideration if supporting a Java API is necessary.\n+\n+## Design\n+\n+I'm going to adopt `Flyway` and `DBGeni` tool syntax and behavior to design the ksqlDB migrations tool. Users will define a new migration in an SQL\n+script. This new SQL script describes the changes to do to migrate the cluster from state A to state B. Then run the migration from the\n+command line to apply the new state in the ksqlDB cluster. Users can also run this migration automatically as part of the build process and/or\n+testing in a CI/CD environment.\n+\n+For instance, the following example creates a new file that setups the initial state of the cluster.\n+\n+`V1__Initial_setup.sql`\n+```sql\n+CREATE STREAM pageviews (\n+    user_id INTEGER KEY, \n+    url STRING, \n+    status INTEGER\n+) WITH (\n+    KAFKA_TOPIC='pageviews', \n+    VALUE_FORMAT='JSON'    \n+);\n+\n+CREATE TABLE pageviews_metrics AS\n+ SELECT url, COUNT(*) AS num_views\n+  FROM pageviews\n+  GROUP BY url\n+  EMIT CHANGES;\n+```\n+\n+The user runs the migration tool on a specific ksqlDB cluster. The tool updates the cluster by running the SQL statements from the above file.\n+Then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: << Empty Schema >>\n+Migrating schema to version 1 - Initial setup\n+```\n+\n+Later, the user needs new changes on the cluster. All previous migrations files are immutable. So, any changes on the cluster require a new migration\n+file (or SQL script). Let's create one to create the users table.\n+\n+`V2__Add_users.sql`\n+```sql\n+CREATE TABLE users (\n+   ID BIGINT PRIMARY KEY, \n+   STRING NAME, \n+   ADDRESS ADDRESS_TYPE\n+ ) WITH (\n+   KAFKA_TOPIC='users', \n+   VALUE_FORMAT='JSON' \n+ );\n+```\n+\n+The user runs the migration tool on the same ksqlDB cluster. The tool detects the cluster has already version 1, so it executes only the newer version 2 migration\n+file. It then sets the state of the cluster to version 2.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: 1\n+Migrating schema to version 2 - Add users\n+```\n+\n+The benefit of this tool is that it detects the required updates to execute in the ksqlDB cluster. So, users don't need to know which SQL statements need to perform\n+to update the cluster. It also makes it easy to work with multiple clusters. Say that you have devel, stag and prod clusters. The tool will manage and track the version\n+of these clusters and apply the right SQL operations.\n+\n+To be able to do that, the tool will use a metadata stream and table that contains the current schema version and all executed updates.\n+\n+### Schema metadata\n+\n+Each ksqlDB cluster requires metadata objects where to track the current schema state. This is not only useful for the tool to know the migrations files to apply, but also for\n+users who can quickly verify if the cluster requires changes to fix a schema bug or add a major/minor improvement for their applications.\n+\n+The tool creates two metadata objects, a stream and table. automatically during the first migration; or when the user runs the tool with a parameter to initialize it.\n+\n+i.e.\n+```\n+$ ksql-migrations initialize\n+Schema metadata initialized successfully\n+```\n+\n+Due to some query limitations (lack of ORDER BY clause and pull queries working only on materialized views) in ksqlDB, the metadata will be stored in two places;  \n+One stream (MIGRATION_EVENTS) and one table (SCHEMA_VERSION).\n+\n+The stream and table require topics unique for the cluster. In this case, these topics names will use the same convention as the processing log. It's not going\n+to be an internal topic because it will be a user topic. The topic name is: `{clusterID}ksql_{StreamOrTableName}`.\n+\n+The user can specify a different name for the SCHEMA_VERSION table. This can be done through the tool configuration file. See `Configurations` for more details.\n+\n+The `MIGRATION_EVENTS` stream will keep track of every migration change (including undo changes). This will contain the history of changes the user has done. Also, this stream\n+will contain a key to the current version of the schema (specified as `CURRENT` version). Every time a new migration or undo happens, the tool will insert a new event with the\n+`CURRENT` key pointing to the current version.\n+\n+This is the `CREATE` statement for the `MIGRATION_EVENTS` stream:\n+```sql\n+CREATE STREAM migration_events (\n+  version_key  STRING KEY,\n+  version      STRING,\n+  name         STRING,\n+  state        STRING,\n+  undoable     BOOLEAN,\n+  checksum     STRING,\n+  started_on   STRING,\n+  completed_on STRING,\n+  previous     STRING\n+) WITH (  \n+  KAFKA_TOPIC='default_ksql_migration_events',\n+  VALUE_FORMAT='JSON',\n+  PARTITIONS=1,\n+  REPLICAS=1\n+);\n+```\n+\n+The `version_key` column has the version of the migration applied or undone. Other keys `CURRENT` and `LATEST` will be reserved for internal purposes.\n+The `version` column has the version of the migration applied or undone.\n+The `name` column has the name of the migration.\n+The `state` column has the state of the migration process. It can be any of `Pending`, `Running`, `Migrated`, `Error`, `Undone`.\n+The `undoable` column specifies if the migration can be undone or not. This requires an undoable migration file (See `Undo migrations`).\n+The `checksum` column has the MD5 checksum of the migration file. It is used to validate the schema migrations with the local files.\n+The `started_on` column has the date and time when the migration started.\n+The `completed_on` column has the date and time when the migration finished.\n+The `previous` column has the previous version applied.\n+\n+The `SCHEMA_VERSION` table will also keep track of every migration change (including undo changes), but with the difference that being a table the tool will see quickly if a schema\n+version has been migrated or undone. It will also give us a quick view of the `CURRENT` state of the schema. The major advantage is that the tool will use pull queries in this materialized\n+view to get the `CURRENT` state of the cluster.\n+\n+There is another reserved key `LATEST` that will point to the latest change applied (migrated or undone). This will be used by the tool to stream all changes up to the row that `LATEST` points, and stop.\n+The `ksql-migrations info` command will use this to display information about the migrations that have been applied or undone. I cannot stream the `MIGRATION_EVENTS` or `SCHEMA_VERSION` directly because\n+the tool does not know when to stop.\n+\n+\n+This is the `CREATE` statement for the `SCHEMA_VERSION` table:\n+```sql\n+CREATE TABLE schema_version\n+  WITH (\n+    KAFKA_TOPIC='default_ksql_schema_version',\n+    VALUE_FORMAT='JSON',\n+    PARTITIONS=1\n+  )\n+  AS SELECT \n+    version_key, \n+    latest_by_offset(version) as version, \n+    latest_by_offset(name) AS name, \n+    latest_by_offset(state) AS state, \n+    latest_by_offset(undoable) AS undoable, \n+    latest_by_offset(checksum) AS checksum, \n+    latest_by_offset(started_on) AS started_on, \n+    latest_by_offset(completed_on) AS completed_on, \n+    latest_by_offset(previous) AS previous\n+  FROM migration_events \n+  GROUP BY version_key;\n+```\n+\n+The following are the outputs that we'll see on each stream and table, and how the tool will figure out the current schema version using pull queries.\n+\n+The `MIGRATION_EVENTS` stream output:\n+```shell script\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | undoable | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Migrated | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| 2           | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The `SCHEMA_VERSION` table output:\n+```shell script\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | undoable | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The tool will later use pull queries to identify the current state of the system:\n+```sql\n+SELECT version, state, previous FROM SCHEMA_VERSION WHERE version_key = 'CURRENT'; \n+```\n+\n+When undo changes happen, the query will first get the current schema version to undo. Apply the revert operations, then set `CURRENT` to\n+the previous migrated version. In this case, it will look at the `previous` column in `SCHEMA_VERSION`, then use a pull query to get information\n+about the previous migration.\n+```sql\n+SELECT * FROM SCHEMA_VERSION WHERE version_key = '<previous>';\n+```\n+\n+And set the new `CURRENT` in the `MIGRATION_EVENTS` to update the current schema version.\n+\n+### Undo migrations\n+\n+Undo a previous migration is necessary in the application lifecycle. A user sometimes want to revert the changes of an application because of a bug found in it.\n+This also requires the database schema to be reverted or rollback to the previous version.\n+\n+The migrations tool allows users to revert changes. Note that undo is considered a forward migration. A new migration file is required which contains\n+the SQL operations to revert the changes of a previous migration. The file in this case should contain the `U` prefix with the version number of the migration to rollback.\n+\n+For instance, let's undo the migration version 2 applied before. The migration file used before was named `V2__Add_users.sql`. For the undo file, we should add the `U` prefix.\n+\n+`U2_Add_users.sql`", "originalCommit": "e6ab1ff376fb389f04d73c07f5abaf6a8cab0022", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzcxODc3OA==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537718778", "bodyText": "Done", "author": "spena", "createdAt": "2020-12-07T18:09:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzYyMjU1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzYzMTE2Ng==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537631166", "bodyText": "I would expect that it would apply all migrations up to and including the target. I noticed this is also the behavior of dbgeni.", "author": "colinhicks", "createdAt": "2020-12-07T16:11:57Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: TBD |\n+**Status**: _In Discussion_ |\n+**Discussion**: TBD\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## What is in scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Rollback migrated schemas to previous versions\n+    - Version control ksqlDB schema\n+\n+* Provide a test plan that validates the new tool will meet the product requirements\n+\n+\n+## What is not in scope\n+\n+* Some features found in existing migrations tools won't be supported\n+\n+  - `Execute entire migrations in a single transaction`\n+\n+    ksqlDB has support for a transactional metastore. However, this is limited to DDL statements that are persisted in the\n+    Command topic. But DML statements, such as INSERT, write directly to the topic and do not work with transactions. This disallows\n+    our tool to provide of a transaction support for the whole migration process. Also, DDL statements may create or delete topics,\n+    which falls in the non-transactional process.\n+\n+  - `Support for simulated or dry-runs executions`\n+\n+    A dry-run requires the tool to know the current state of the ksqlDB schema before attempting to verify the new migrations scripts. This\n+    requires a ksqlDB metastore exporting tool to work. Also, to make this simulation 100% safe, the tool requires a dummy Kafka and SR\n+    environment that can validate issues with topics and SR subjects names, as well as security restrictions.\n+\n+  - `Other features, such as repeatable migrations and callbacks`\n+\n+    Not required for a basic migration.\n+\n+* Do performance analysis on migrations\n+\n+  In other DBs, there are operations that take too much time to complete. Such is the case of ALTER statements, which can add/remove columns\n+  that would take time to complete on large tables. ksqlDB operations are quick unless an issue with the ksqlDB environment affects\n+  these executions.\n+\n+## Value/Return\n+\n+Users will be able to integrate ksqlDB upgrades testing with any CI/CD environments of their choice. This is a huge benefit for users who want\n+to automate ksqlDB upgrades with their application lifecycle.\n+\n+Also, a new tool will let users to easily automate schema evolution and migrations changes. They will be able to deploy new schema changes in\n+all their environments (Prod, QA, Devel, etc).\n+\n+## Public APIS\n+\n+- No changes on current public APIs\n+- A new Java API for Java developers\n+\n+  This seems important. However, it is in consideration if supporting a Java API is necessary.\n+\n+## Design\n+\n+I'm going to adopt `Flyway` and `DBGeni` tool syntax and behavior to design the ksqlDB migrations tool. Users will define a new migration in an SQL\n+script. This new SQL script describes the changes to do to migrate the cluster from state A to state B. Then run the migration from the\n+command line to apply the new state in the ksqlDB cluster. Users can also run this migration automatically as part of the build process and/or\n+testing in a CI/CD environment.\n+\n+For instance, the following example creates a new file that setups the initial state of the cluster.\n+\n+`V1__Initial_setup.sql`\n+```sql\n+CREATE STREAM pageviews (\n+    user_id INTEGER KEY, \n+    url STRING, \n+    status INTEGER\n+) WITH (\n+    KAFKA_TOPIC='pageviews', \n+    VALUE_FORMAT='JSON'    \n+);\n+\n+CREATE TABLE pageviews_metrics AS\n+ SELECT url, COUNT(*) AS num_views\n+  FROM pageviews\n+  GROUP BY url\n+  EMIT CHANGES;\n+```\n+\n+The user runs the migration tool on a specific ksqlDB cluster. The tool updates the cluster by running the SQL statements from the above file.\n+Then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: << Empty Schema >>\n+Migrating schema to version 1 - Initial setup\n+```\n+\n+Later, the user needs new changes on the cluster. All previous migrations files are immutable. So, any changes on the cluster require a new migration\n+file (or SQL script). Let's create one to create the users table.\n+\n+`V2__Add_users.sql`\n+```sql\n+CREATE TABLE users (\n+   ID BIGINT PRIMARY KEY, \n+   STRING NAME, \n+   ADDRESS ADDRESS_TYPE\n+ ) WITH (\n+   KAFKA_TOPIC='users', \n+   VALUE_FORMAT='JSON' \n+ );\n+```\n+\n+The user runs the migration tool on the same ksqlDB cluster. The tool detects the cluster has already version 1, so it executes only the newer version 2 migration\n+file. It then sets the state of the cluster to version 2.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: 1\n+Migrating schema to version 2 - Add users\n+```\n+\n+The benefit of this tool is that it detects the required updates to execute in the ksqlDB cluster. So, users don't need to know which SQL statements need to perform\n+to update the cluster. It also makes it easy to work with multiple clusters. Say that you have devel, stag and prod clusters. The tool will manage and track the version\n+of these clusters and apply the right SQL operations.\n+\n+To be able to do that, the tool will use a metadata stream and table that contains the current schema version and all executed updates.\n+\n+### Schema metadata\n+\n+Each ksqlDB cluster requires metadata objects where to track the current schema state. This is not only useful for the tool to know the migrations files to apply, but also for\n+users who can quickly verify if the cluster requires changes to fix a schema bug or add a major/minor improvement for their applications.\n+\n+The tool creates two metadata objects, a stream and table. automatically during the first migration; or when the user runs the tool with a parameter to initialize it.\n+\n+i.e.\n+```\n+$ ksql-migrations initialize\n+Schema metadata initialized successfully\n+```\n+\n+Due to some query limitations (lack of ORDER BY clause and pull queries working only on materialized views) in ksqlDB, the metadata will be stored in two places;  \n+One stream (MIGRATION_EVENTS) and one table (SCHEMA_VERSION).\n+\n+The stream and table require topics unique for the cluster. In this case, these topics names will use the same convention as the processing log. It's not going\n+to be an internal topic because it will be a user topic. The topic name is: `{clusterID}ksql_{StreamOrTableName}`.\n+\n+The user can specify a different name for the SCHEMA_VERSION table. This can be done through the tool configuration file. See `Configurations` for more details.\n+\n+The `MIGRATION_EVENTS` stream will keep track of every migration change (including undo changes). This will contain the history of changes the user has done. Also, this stream\n+will contain a key to the current version of the schema (specified as `CURRENT` version). Every time a new migration or undo happens, the tool will insert a new event with the\n+`CURRENT` key pointing to the current version.\n+\n+This is the `CREATE` statement for the `MIGRATION_EVENTS` stream:\n+```sql\n+CREATE STREAM migration_events (\n+  version_key  STRING KEY,\n+  version      STRING,\n+  name         STRING,\n+  state        STRING,\n+  undoable     BOOLEAN,\n+  checksum     STRING,\n+  started_on   STRING,\n+  completed_on STRING,\n+  previous     STRING\n+) WITH (  \n+  KAFKA_TOPIC='default_ksql_migration_events',\n+  VALUE_FORMAT='JSON',\n+  PARTITIONS=1,\n+  REPLICAS=1\n+);\n+```\n+\n+The `version_key` column has the version of the migration applied or undone. Other keys `CURRENT` and `LATEST` will be reserved for internal purposes.\n+The `version` column has the version of the migration applied or undone.\n+The `name` column has the name of the migration.\n+The `state` column has the state of the migration process. It can be any of `Pending`, `Running`, `Migrated`, `Error`, `Undone`.\n+The `undoable` column specifies if the migration can be undone or not. This requires an undoable migration file (See `Undo migrations`).\n+The `checksum` column has the MD5 checksum of the migration file. It is used to validate the schema migrations with the local files.\n+The `started_on` column has the date and time when the migration started.\n+The `completed_on` column has the date and time when the migration finished.\n+The `previous` column has the previous version applied.\n+\n+The `SCHEMA_VERSION` table will also keep track of every migration change (including undo changes), but with the difference that being a table the tool will see quickly if a schema\n+version has been migrated or undone. It will also give us a quick view of the `CURRENT` state of the schema. The major advantage is that the tool will use pull queries in this materialized\n+view to get the `CURRENT` state of the cluster.\n+\n+There is another reserved key `LATEST` that will point to the latest change applied (migrated or undone). This will be used by the tool to stream all changes up to the row that `LATEST` points, and stop.\n+The `ksql-migrations info` command will use this to display information about the migrations that have been applied or undone. I cannot stream the `MIGRATION_EVENTS` or `SCHEMA_VERSION` directly because\n+the tool does not know when to stop.\n+\n+\n+This is the `CREATE` statement for the `SCHEMA_VERSION` table:\n+```sql\n+CREATE TABLE schema_version\n+  WITH (\n+    KAFKA_TOPIC='default_ksql_schema_version',\n+    VALUE_FORMAT='JSON',\n+    PARTITIONS=1\n+  )\n+  AS SELECT \n+    version_key, \n+    latest_by_offset(version) as version, \n+    latest_by_offset(name) AS name, \n+    latest_by_offset(state) AS state, \n+    latest_by_offset(undoable) AS undoable, \n+    latest_by_offset(checksum) AS checksum, \n+    latest_by_offset(started_on) AS started_on, \n+    latest_by_offset(completed_on) AS completed_on, \n+    latest_by_offset(previous) AS previous\n+  FROM migration_events \n+  GROUP BY version_key;\n+```\n+\n+The following are the outputs that we'll see on each stream and table, and how the tool will figure out the current schema version using pull queries.\n+\n+The `MIGRATION_EVENTS` stream output:\n+```shell script\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | undoable | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Migrated | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| 2           | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The `SCHEMA_VERSION` table output:\n+```shell script\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | undoable | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The tool will later use pull queries to identify the current state of the system:\n+```sql\n+SELECT version, state, previous FROM SCHEMA_VERSION WHERE version_key = 'CURRENT'; \n+```\n+\n+When undo changes happen, the query will first get the current schema version to undo. Apply the revert operations, then set `CURRENT` to\n+the previous migrated version. In this case, it will look at the `previous` column in `SCHEMA_VERSION`, then use a pull query to get information\n+about the previous migration.\n+```sql\n+SELECT * FROM SCHEMA_VERSION WHERE version_key = '<previous>';\n+```\n+\n+And set the new `CURRENT` in the `MIGRATION_EVENTS` to update the current schema version.\n+\n+### Undo migrations\n+\n+Undo a previous migration is necessary in the application lifecycle. A user sometimes want to revert the changes of an application because of a bug found in it.\n+This also requires the database schema to be reverted or rollback to the previous version.\n+\n+The migrations tool allows users to revert changes. Note that undo is considered a forward migration. A new migration file is required which contains\n+the SQL operations to revert the changes of a previous migration. The file in this case should contain the `U` prefix with the version number of the migration to rollback.\n+\n+For instance, let's undo the migration version 2 applied before. The migration file used before was named `V2__Add_users.sql`. For the undo file, we should add the `U` prefix.\n+\n+`U2_Add_users.sql`\n+```sql\n+DROP TABLE users;\n+```\n+\n+The user runs the migration tool on the ksqlDB cluster. The tool detects the cluster has version 2, so it executes only the undo file for version 2.  \n+It then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations undo\n+Current version of schema: 2\n+Undoing migration of schema to version 2 - Add users\n+```\n+\n+The `undo` action will only revert the previous change. It will not attempt to undo all applied migrations.\n+\n+\n+### Naming convention\n+\n+Hope you have noticed the naming rules I followed in the previous examples for naming the migration files. Having a naming convention for files is necessary\n+for the tool to detect what migration to apply or revert. Naming files are easier than creating configurations or command parameters to specify the same info.\n+\n+The migration files follow the same `Flyway` naming convention.\n+`(Prefix)(Version)__(Description).sql`\n+\n+The `Prefix` specifies whether the file is a new migration (`V`) or undo (`U`) file.\n+The `Version` is the version number used for the schema. For minor versions, such as `1.1`, an underscore is required (i.e. `1_1`)\n+The `Description` is just a name or description of the new migration.\n+\n+i.e.\n+```\n+- V1__Initial_setup.sql    # a new version to migrate (v1)\n+- U1__Initial_setup.sql    # rollback v1 schema\n+- V2__Add_users.sql        # a new version to migrate (v2)\n+- U2__Add_users.sql        # rollback v2 schema\n+- V2_1__Fix_topic_name.sql # A new version to migrate (v2.1)\n+- U2_1__Fix_topic_name.sql # rollback v2.1 schema\n+```\n+\n+It is recommended the user creates these two files on any new migration. The tool will not enforce that. We need specify this recomendation in the ksqlDB documents.\n+\n+### Command Syntax\n+\n+Finally, let's look at the rest of the command parameters that will exist to facilitate schema migrations.\n+\n+```shell script\n+Usage:\n+  ksql-migrations [options] commands\n+  \n+Commands\n+  initialize   Initializes the schema version table\n+\n+  apply ( all | next | until <target> )\n+  \n+              Migrates a schema to new available schema versions (default: next)\n+              \n+              If 'all' is specified, then it migrates all newer versions available\n+              If 'next' is specified, then it migrates only the next available version\n+              If 'until <target>' is specified, then it migrates all available versions before <target>", "originalCommit": "e6ab1ff376fb389f04d73c07f5abaf6a8cab0022", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzcxOTg5NA==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537719894", "bodyText": "Yeah, I did that too initially, but I thought of keeping the apply and undo in sync 'cause they have next and last. Anyway, your expectation would be the same for many other users. I'll make that change.", "author": "spena", "createdAt": "2020-12-07T18:11:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzYzMTE2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzYzMTk4Mw==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537631983", "bodyText": "Can we consider previous instead? I think this mirrors apply's next option better, personally.", "author": "colinhicks", "createdAt": "2020-12-07T16:13:03Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: TBD |\n+**Status**: _In Discussion_ |\n+**Discussion**: TBD\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## What is in scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Rollback migrated schemas to previous versions\n+    - Version control ksqlDB schema\n+\n+* Provide a test plan that validates the new tool will meet the product requirements\n+\n+\n+## What is not in scope\n+\n+* Some features found in existing migrations tools won't be supported\n+\n+  - `Execute entire migrations in a single transaction`\n+\n+    ksqlDB has support for a transactional metastore. However, this is limited to DDL statements that are persisted in the\n+    Command topic. But DML statements, such as INSERT, write directly to the topic and do not work with transactions. This disallows\n+    our tool to provide of a transaction support for the whole migration process. Also, DDL statements may create or delete topics,\n+    which falls in the non-transactional process.\n+\n+  - `Support for simulated or dry-runs executions`\n+\n+    A dry-run requires the tool to know the current state of the ksqlDB schema before attempting to verify the new migrations scripts. This\n+    requires a ksqlDB metastore exporting tool to work. Also, to make this simulation 100% safe, the tool requires a dummy Kafka and SR\n+    environment that can validate issues with topics and SR subjects names, as well as security restrictions.\n+\n+  - `Other features, such as repeatable migrations and callbacks`\n+\n+    Not required for a basic migration.\n+\n+* Do performance analysis on migrations\n+\n+  In other DBs, there are operations that take too much time to complete. Such is the case of ALTER statements, which can add/remove columns\n+  that would take time to complete on large tables. ksqlDB operations are quick unless an issue with the ksqlDB environment affects\n+  these executions.\n+\n+## Value/Return\n+\n+Users will be able to integrate ksqlDB upgrades testing with any CI/CD environments of their choice. This is a huge benefit for users who want\n+to automate ksqlDB upgrades with their application lifecycle.\n+\n+Also, a new tool will let users to easily automate schema evolution and migrations changes. They will be able to deploy new schema changes in\n+all their environments (Prod, QA, Devel, etc).\n+\n+## Public APIS\n+\n+- No changes on current public APIs\n+- A new Java API for Java developers\n+\n+  This seems important. However, it is in consideration if supporting a Java API is necessary.\n+\n+## Design\n+\n+I'm going to adopt `Flyway` and `DBGeni` tool syntax and behavior to design the ksqlDB migrations tool. Users will define a new migration in an SQL\n+script. This new SQL script describes the changes to do to migrate the cluster from state A to state B. Then run the migration from the\n+command line to apply the new state in the ksqlDB cluster. Users can also run this migration automatically as part of the build process and/or\n+testing in a CI/CD environment.\n+\n+For instance, the following example creates a new file that setups the initial state of the cluster.\n+\n+`V1__Initial_setup.sql`\n+```sql\n+CREATE STREAM pageviews (\n+    user_id INTEGER KEY, \n+    url STRING, \n+    status INTEGER\n+) WITH (\n+    KAFKA_TOPIC='pageviews', \n+    VALUE_FORMAT='JSON'    \n+);\n+\n+CREATE TABLE pageviews_metrics AS\n+ SELECT url, COUNT(*) AS num_views\n+  FROM pageviews\n+  GROUP BY url\n+  EMIT CHANGES;\n+```\n+\n+The user runs the migration tool on a specific ksqlDB cluster. The tool updates the cluster by running the SQL statements from the above file.\n+Then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: << Empty Schema >>\n+Migrating schema to version 1 - Initial setup\n+```\n+\n+Later, the user needs new changes on the cluster. All previous migrations files are immutable. So, any changes on the cluster require a new migration\n+file (or SQL script). Let's create one to create the users table.\n+\n+`V2__Add_users.sql`\n+```sql\n+CREATE TABLE users (\n+   ID BIGINT PRIMARY KEY, \n+   STRING NAME, \n+   ADDRESS ADDRESS_TYPE\n+ ) WITH (\n+   KAFKA_TOPIC='users', \n+   VALUE_FORMAT='JSON' \n+ );\n+```\n+\n+The user runs the migration tool on the same ksqlDB cluster. The tool detects the cluster has already version 1, so it executes only the newer version 2 migration\n+file. It then sets the state of the cluster to version 2.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: 1\n+Migrating schema to version 2 - Add users\n+```\n+\n+The benefit of this tool is that it detects the required updates to execute in the ksqlDB cluster. So, users don't need to know which SQL statements need to perform\n+to update the cluster. It also makes it easy to work with multiple clusters. Say that you have devel, stag and prod clusters. The tool will manage and track the version\n+of these clusters and apply the right SQL operations.\n+\n+To be able to do that, the tool will use a metadata stream and table that contains the current schema version and all executed updates.\n+\n+### Schema metadata\n+\n+Each ksqlDB cluster requires metadata objects where to track the current schema state. This is not only useful for the tool to know the migrations files to apply, but also for\n+users who can quickly verify if the cluster requires changes to fix a schema bug or add a major/minor improvement for their applications.\n+\n+The tool creates two metadata objects, a stream and table. automatically during the first migration; or when the user runs the tool with a parameter to initialize it.\n+\n+i.e.\n+```\n+$ ksql-migrations initialize\n+Schema metadata initialized successfully\n+```\n+\n+Due to some query limitations (lack of ORDER BY clause and pull queries working only on materialized views) in ksqlDB, the metadata will be stored in two places;  \n+One stream (MIGRATION_EVENTS) and one table (SCHEMA_VERSION).\n+\n+The stream and table require topics unique for the cluster. In this case, these topics names will use the same convention as the processing log. It's not going\n+to be an internal topic because it will be a user topic. The topic name is: `{clusterID}ksql_{StreamOrTableName}`.\n+\n+The user can specify a different name for the SCHEMA_VERSION table. This can be done through the tool configuration file. See `Configurations` for more details.\n+\n+The `MIGRATION_EVENTS` stream will keep track of every migration change (including undo changes). This will contain the history of changes the user has done. Also, this stream\n+will contain a key to the current version of the schema (specified as `CURRENT` version). Every time a new migration or undo happens, the tool will insert a new event with the\n+`CURRENT` key pointing to the current version.\n+\n+This is the `CREATE` statement for the `MIGRATION_EVENTS` stream:\n+```sql\n+CREATE STREAM migration_events (\n+  version_key  STRING KEY,\n+  version      STRING,\n+  name         STRING,\n+  state        STRING,\n+  undoable     BOOLEAN,\n+  checksum     STRING,\n+  started_on   STRING,\n+  completed_on STRING,\n+  previous     STRING\n+) WITH (  \n+  KAFKA_TOPIC='default_ksql_migration_events',\n+  VALUE_FORMAT='JSON',\n+  PARTITIONS=1,\n+  REPLICAS=1\n+);\n+```\n+\n+The `version_key` column has the version of the migration applied or undone. Other keys `CURRENT` and `LATEST` will be reserved for internal purposes.\n+The `version` column has the version of the migration applied or undone.\n+The `name` column has the name of the migration.\n+The `state` column has the state of the migration process. It can be any of `Pending`, `Running`, `Migrated`, `Error`, `Undone`.\n+The `undoable` column specifies if the migration can be undone or not. This requires an undoable migration file (See `Undo migrations`).\n+The `checksum` column has the MD5 checksum of the migration file. It is used to validate the schema migrations with the local files.\n+The `started_on` column has the date and time when the migration started.\n+The `completed_on` column has the date and time when the migration finished.\n+The `previous` column has the previous version applied.\n+\n+The `SCHEMA_VERSION` table will also keep track of every migration change (including undo changes), but with the difference that being a table the tool will see quickly if a schema\n+version has been migrated or undone. It will also give us a quick view of the `CURRENT` state of the schema. The major advantage is that the tool will use pull queries in this materialized\n+view to get the `CURRENT` state of the cluster.\n+\n+There is another reserved key `LATEST` that will point to the latest change applied (migrated or undone). This will be used by the tool to stream all changes up to the row that `LATEST` points, and stop.\n+The `ksql-migrations info` command will use this to display information about the migrations that have been applied or undone. I cannot stream the `MIGRATION_EVENTS` or `SCHEMA_VERSION` directly because\n+the tool does not know when to stop.\n+\n+\n+This is the `CREATE` statement for the `SCHEMA_VERSION` table:\n+```sql\n+CREATE TABLE schema_version\n+  WITH (\n+    KAFKA_TOPIC='default_ksql_schema_version',\n+    VALUE_FORMAT='JSON',\n+    PARTITIONS=1\n+  )\n+  AS SELECT \n+    version_key, \n+    latest_by_offset(version) as version, \n+    latest_by_offset(name) AS name, \n+    latest_by_offset(state) AS state, \n+    latest_by_offset(undoable) AS undoable, \n+    latest_by_offset(checksum) AS checksum, \n+    latest_by_offset(started_on) AS started_on, \n+    latest_by_offset(completed_on) AS completed_on, \n+    latest_by_offset(previous) AS previous\n+  FROM migration_events \n+  GROUP BY version_key;\n+```\n+\n+The following are the outputs that we'll see on each stream and table, and how the tool will figure out the current schema version using pull queries.\n+\n+The `MIGRATION_EVENTS` stream output:\n+```shell script\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | undoable | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Migrated | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| 2           | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The `SCHEMA_VERSION` table output:\n+```shell script\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | undoable | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The tool will later use pull queries to identify the current state of the system:\n+```sql\n+SELECT version, state, previous FROM SCHEMA_VERSION WHERE version_key = 'CURRENT'; \n+```\n+\n+When undo changes happen, the query will first get the current schema version to undo. Apply the revert operations, then set `CURRENT` to\n+the previous migrated version. In this case, it will look at the `previous` column in `SCHEMA_VERSION`, then use a pull query to get information\n+about the previous migration.\n+```sql\n+SELECT * FROM SCHEMA_VERSION WHERE version_key = '<previous>';\n+```\n+\n+And set the new `CURRENT` in the `MIGRATION_EVENTS` to update the current schema version.\n+\n+### Undo migrations\n+\n+Undo a previous migration is necessary in the application lifecycle. A user sometimes want to revert the changes of an application because of a bug found in it.\n+This also requires the database schema to be reverted or rollback to the previous version.\n+\n+The migrations tool allows users to revert changes. Note that undo is considered a forward migration. A new migration file is required which contains\n+the SQL operations to revert the changes of a previous migration. The file in this case should contain the `U` prefix with the version number of the migration to rollback.\n+\n+For instance, let's undo the migration version 2 applied before. The migration file used before was named `V2__Add_users.sql`. For the undo file, we should add the `U` prefix.\n+\n+`U2_Add_users.sql`\n+```sql\n+DROP TABLE users;\n+```\n+\n+The user runs the migration tool on the ksqlDB cluster. The tool detects the cluster has version 2, so it executes only the undo file for version 2.  \n+It then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations undo\n+Current version of schema: 2\n+Undoing migration of schema to version 2 - Add users\n+```\n+\n+The `undo` action will only revert the previous change. It will not attempt to undo all applied migrations.\n+\n+\n+### Naming convention\n+\n+Hope you have noticed the naming rules I followed in the previous examples for naming the migration files. Having a naming convention for files is necessary\n+for the tool to detect what migration to apply or revert. Naming files are easier than creating configurations or command parameters to specify the same info.\n+\n+The migration files follow the same `Flyway` naming convention.\n+`(Prefix)(Version)__(Description).sql`\n+\n+The `Prefix` specifies whether the file is a new migration (`V`) or undo (`U`) file.\n+The `Version` is the version number used for the schema. For minor versions, such as `1.1`, an underscore is required (i.e. `1_1`)\n+The `Description` is just a name or description of the new migration.\n+\n+i.e.\n+```\n+- V1__Initial_setup.sql    # a new version to migrate (v1)\n+- U1__Initial_setup.sql    # rollback v1 schema\n+- V2__Add_users.sql        # a new version to migrate (v2)\n+- U2__Add_users.sql        # rollback v2 schema\n+- V2_1__Fix_topic_name.sql # A new version to migrate (v2.1)\n+- U2_1__Fix_topic_name.sql # rollback v2.1 schema\n+```\n+\n+It is recommended the user creates these two files on any new migration. The tool will not enforce that. We need specify this recomendation in the ksqlDB documents.\n+\n+### Command Syntax\n+\n+Finally, let's look at the rest of the command parameters that will exist to facilitate schema migrations.\n+\n+```shell script\n+Usage:\n+  ksql-migrations [options] commands\n+  \n+Commands\n+  initialize   Initializes the schema version table\n+\n+  apply ( all | next | until <target> )\n+  \n+              Migrates a schema to new available schema versions (default: next)\n+              \n+              If 'all' is specified, then it migrates all newer versions available\n+              If 'next' is specified, then it migrates only the next available version\n+              If 'until <target>' is specified, then it migrates all available versions before <target>\n+  \n+  undo ( all | last | until <target> )\n+  \n+              Rollbacks a schema to the previous schema version (default: last)\n+              \n+              If 'all' is specified, then it rollbacks all previous versions\n+              If 'last' is specified, then it rollbacks the previous version", "originalCommit": "e6ab1ff376fb389f04d73c07f5abaf6a8cab0022", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzcyMDIyOQ==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537720229", "bodyText": "Done", "author": "spena", "createdAt": "2020-12-07T18:11:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzYzMTk4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY0MDcyMw==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537640723", "bodyText": "How feasible would it be to support variables / --define as a ksql-migrate CLI option?\nLet's say I want to apply the same migration in dev and prod, but the topic names I use are different between environments. If I could specify kafka_topic='${topicName}' in my migration, I could reuse the migration with ksql-migrate apply -d topicName=dev-mytopic.", "author": "colinhicks", "createdAt": "2020-12-07T16:24:18Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: TBD |\n+**Status**: _In Discussion_ |\n+**Discussion**: TBD\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## What is in scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Rollback migrated schemas to previous versions\n+    - Version control ksqlDB schema\n+\n+* Provide a test plan that validates the new tool will meet the product requirements\n+\n+\n+## What is not in scope\n+\n+* Some features found in existing migrations tools won't be supported\n+\n+  - `Execute entire migrations in a single transaction`\n+\n+    ksqlDB has support for a transactional metastore. However, this is limited to DDL statements that are persisted in the\n+    Command topic. But DML statements, such as INSERT, write directly to the topic and do not work with transactions. This disallows\n+    our tool to provide of a transaction support for the whole migration process. Also, DDL statements may create or delete topics,\n+    which falls in the non-transactional process.\n+\n+  - `Support for simulated or dry-runs executions`\n+\n+    A dry-run requires the tool to know the current state of the ksqlDB schema before attempting to verify the new migrations scripts. This\n+    requires a ksqlDB metastore exporting tool to work. Also, to make this simulation 100% safe, the tool requires a dummy Kafka and SR\n+    environment that can validate issues with topics and SR subjects names, as well as security restrictions.\n+\n+  - `Other features, such as repeatable migrations and callbacks`\n+\n+    Not required for a basic migration.\n+\n+* Do performance analysis on migrations\n+\n+  In other DBs, there are operations that take too much time to complete. Such is the case of ALTER statements, which can add/remove columns\n+  that would take time to complete on large tables. ksqlDB operations are quick unless an issue with the ksqlDB environment affects\n+  these executions.\n+\n+## Value/Return\n+\n+Users will be able to integrate ksqlDB upgrades testing with any CI/CD environments of their choice. This is a huge benefit for users who want\n+to automate ksqlDB upgrades with their application lifecycle.\n+\n+Also, a new tool will let users to easily automate schema evolution and migrations changes. They will be able to deploy new schema changes in\n+all their environments (Prod, QA, Devel, etc).\n+\n+## Public APIS\n+\n+- No changes on current public APIs\n+- A new Java API for Java developers\n+\n+  This seems important. However, it is in consideration if supporting a Java API is necessary.\n+\n+## Design\n+\n+I'm going to adopt `Flyway` and `DBGeni` tool syntax and behavior to design the ksqlDB migrations tool. Users will define a new migration in an SQL\n+script. This new SQL script describes the changes to do to migrate the cluster from state A to state B. Then run the migration from the\n+command line to apply the new state in the ksqlDB cluster. Users can also run this migration automatically as part of the build process and/or\n+testing in a CI/CD environment.\n+\n+For instance, the following example creates a new file that setups the initial state of the cluster.\n+\n+`V1__Initial_setup.sql`\n+```sql\n+CREATE STREAM pageviews (\n+    user_id INTEGER KEY, \n+    url STRING, \n+    status INTEGER\n+) WITH (\n+    KAFKA_TOPIC='pageviews', \n+    VALUE_FORMAT='JSON'    \n+);\n+\n+CREATE TABLE pageviews_metrics AS\n+ SELECT url, COUNT(*) AS num_views\n+  FROM pageviews\n+  GROUP BY url\n+  EMIT CHANGES;\n+```\n+\n+The user runs the migration tool on a specific ksqlDB cluster. The tool updates the cluster by running the SQL statements from the above file.\n+Then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: << Empty Schema >>\n+Migrating schema to version 1 - Initial setup\n+```\n+\n+Later, the user needs new changes on the cluster. All previous migrations files are immutable. So, any changes on the cluster require a new migration\n+file (or SQL script). Let's create one to create the users table.\n+\n+`V2__Add_users.sql`\n+```sql\n+CREATE TABLE users (\n+   ID BIGINT PRIMARY KEY, \n+   STRING NAME, \n+   ADDRESS ADDRESS_TYPE\n+ ) WITH (\n+   KAFKA_TOPIC='users', \n+   VALUE_FORMAT='JSON' \n+ );\n+```\n+\n+The user runs the migration tool on the same ksqlDB cluster. The tool detects the cluster has already version 1, so it executes only the newer version 2 migration\n+file. It then sets the state of the cluster to version 2.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: 1\n+Migrating schema to version 2 - Add users\n+```\n+\n+The benefit of this tool is that it detects the required updates to execute in the ksqlDB cluster. So, users don't need to know which SQL statements need to perform\n+to update the cluster. It also makes it easy to work with multiple clusters. Say that you have devel, stag and prod clusters. The tool will manage and track the version\n+of these clusters and apply the right SQL operations.\n+\n+To be able to do that, the tool will use a metadata stream and table that contains the current schema version and all executed updates.\n+\n+### Schema metadata\n+\n+Each ksqlDB cluster requires metadata objects where to track the current schema state. This is not only useful for the tool to know the migrations files to apply, but also for\n+users who can quickly verify if the cluster requires changes to fix a schema bug or add a major/minor improvement for their applications.\n+\n+The tool creates two metadata objects, a stream and table. automatically during the first migration; or when the user runs the tool with a parameter to initialize it.\n+\n+i.e.\n+```\n+$ ksql-migrations initialize\n+Schema metadata initialized successfully\n+```\n+\n+Due to some query limitations (lack of ORDER BY clause and pull queries working only on materialized views) in ksqlDB, the metadata will be stored in two places;  \n+One stream (MIGRATION_EVENTS) and one table (SCHEMA_VERSION).\n+\n+The stream and table require topics unique for the cluster. In this case, these topics names will use the same convention as the processing log. It's not going\n+to be an internal topic because it will be a user topic. The topic name is: `{clusterID}ksql_{StreamOrTableName}`.\n+\n+The user can specify a different name for the SCHEMA_VERSION table. This can be done through the tool configuration file. See `Configurations` for more details.\n+\n+The `MIGRATION_EVENTS` stream will keep track of every migration change (including undo changes). This will contain the history of changes the user has done. Also, this stream\n+will contain a key to the current version of the schema (specified as `CURRENT` version). Every time a new migration or undo happens, the tool will insert a new event with the\n+`CURRENT` key pointing to the current version.\n+\n+This is the `CREATE` statement for the `MIGRATION_EVENTS` stream:\n+```sql\n+CREATE STREAM migration_events (\n+  version_key  STRING KEY,\n+  version      STRING,\n+  name         STRING,\n+  state        STRING,\n+  undoable     BOOLEAN,\n+  checksum     STRING,\n+  started_on   STRING,\n+  completed_on STRING,\n+  previous     STRING\n+) WITH (  \n+  KAFKA_TOPIC='default_ksql_migration_events',\n+  VALUE_FORMAT='JSON',\n+  PARTITIONS=1,\n+  REPLICAS=1\n+);\n+```\n+\n+The `version_key` column has the version of the migration applied or undone. Other keys `CURRENT` and `LATEST` will be reserved for internal purposes.\n+The `version` column has the version of the migration applied or undone.\n+The `name` column has the name of the migration.\n+The `state` column has the state of the migration process. It can be any of `Pending`, `Running`, `Migrated`, `Error`, `Undone`.\n+The `undoable` column specifies if the migration can be undone or not. This requires an undoable migration file (See `Undo migrations`).\n+The `checksum` column has the MD5 checksum of the migration file. It is used to validate the schema migrations with the local files.\n+The `started_on` column has the date and time when the migration started.\n+The `completed_on` column has the date and time when the migration finished.\n+The `previous` column has the previous version applied.\n+\n+The `SCHEMA_VERSION` table will also keep track of every migration change (including undo changes), but with the difference that being a table the tool will see quickly if a schema\n+version has been migrated or undone. It will also give us a quick view of the `CURRENT` state of the schema. The major advantage is that the tool will use pull queries in this materialized\n+view to get the `CURRENT` state of the cluster.\n+\n+There is another reserved key `LATEST` that will point to the latest change applied (migrated or undone). This will be used by the tool to stream all changes up to the row that `LATEST` points, and stop.\n+The `ksql-migrations info` command will use this to display information about the migrations that have been applied or undone. I cannot stream the `MIGRATION_EVENTS` or `SCHEMA_VERSION` directly because\n+the tool does not know when to stop.\n+\n+\n+This is the `CREATE` statement for the `SCHEMA_VERSION` table:\n+```sql\n+CREATE TABLE schema_version\n+  WITH (\n+    KAFKA_TOPIC='default_ksql_schema_version',\n+    VALUE_FORMAT='JSON',\n+    PARTITIONS=1\n+  )\n+  AS SELECT \n+    version_key, \n+    latest_by_offset(version) as version, \n+    latest_by_offset(name) AS name, \n+    latest_by_offset(state) AS state, \n+    latest_by_offset(undoable) AS undoable, \n+    latest_by_offset(checksum) AS checksum, \n+    latest_by_offset(started_on) AS started_on, \n+    latest_by_offset(completed_on) AS completed_on, \n+    latest_by_offset(previous) AS previous\n+  FROM migration_events \n+  GROUP BY version_key;\n+```\n+\n+The following are the outputs that we'll see on each stream and table, and how the tool will figure out the current schema version using pull queries.\n+\n+The `MIGRATION_EVENTS` stream output:\n+```shell script\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | undoable | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Migrated | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| 2           | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The `SCHEMA_VERSION` table output:\n+```shell script\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | undoable | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | No       | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | No       | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The tool will later use pull queries to identify the current state of the system:\n+```sql\n+SELECT version, state, previous FROM SCHEMA_VERSION WHERE version_key = 'CURRENT'; \n+```\n+\n+When undo changes happen, the query will first get the current schema version to undo. Apply the revert operations, then set `CURRENT` to\n+the previous migrated version. In this case, it will look at the `previous` column in `SCHEMA_VERSION`, then use a pull query to get information\n+about the previous migration.\n+```sql\n+SELECT * FROM SCHEMA_VERSION WHERE version_key = '<previous>';\n+```\n+\n+And set the new `CURRENT` in the `MIGRATION_EVENTS` to update the current schema version.\n+\n+### Undo migrations\n+\n+Undo a previous migration is necessary in the application lifecycle. A user sometimes want to revert the changes of an application because of a bug found in it.\n+This also requires the database schema to be reverted or rollback to the previous version.\n+\n+The migrations tool allows users to revert changes. Note that undo is considered a forward migration. A new migration file is required which contains\n+the SQL operations to revert the changes of a previous migration. The file in this case should contain the `U` prefix with the version number of the migration to rollback.\n+\n+For instance, let's undo the migration version 2 applied before. The migration file used before was named `V2__Add_users.sql`. For the undo file, we should add the `U` prefix.\n+\n+`U2_Add_users.sql`\n+```sql\n+DROP TABLE users;\n+```\n+\n+The user runs the migration tool on the ksqlDB cluster. The tool detects the cluster has version 2, so it executes only the undo file for version 2.  \n+It then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations undo\n+Current version of schema: 2\n+Undoing migration of schema to version 2 - Add users\n+```\n+\n+The `undo` action will only revert the previous change. It will not attempt to undo all applied migrations.\n+\n+\n+### Naming convention\n+\n+Hope you have noticed the naming rules I followed in the previous examples for naming the migration files. Having a naming convention for files is necessary\n+for the tool to detect what migration to apply or revert. Naming files are easier than creating configurations or command parameters to specify the same info.\n+\n+The migration files follow the same `Flyway` naming convention.\n+`(Prefix)(Version)__(Description).sql`\n+\n+The `Prefix` specifies whether the file is a new migration (`V`) or undo (`U`) file.\n+The `Version` is the version number used for the schema. For minor versions, such as `1.1`, an underscore is required (i.e. `1_1`)\n+The `Description` is just a name or description of the new migration.\n+\n+i.e.\n+```\n+- V1__Initial_setup.sql    # a new version to migrate (v1)\n+- U1__Initial_setup.sql    # rollback v1 schema\n+- V2__Add_users.sql        # a new version to migrate (v2)\n+- U2__Add_users.sql        # rollback v2 schema\n+- V2_1__Fix_topic_name.sql # A new version to migrate (v2.1)\n+- U2_1__Fix_topic_name.sql # rollback v2.1 schema\n+```\n+\n+It is recommended the user creates these two files on any new migration. The tool will not enforce that. We need specify this recomendation in the ksqlDB documents.\n+\n+### Command Syntax\n+\n+Finally, let's look at the rest of the command parameters that will exist to facilitate schema migrations.\n+\n+```shell script\n+Usage:\n+  ksql-migrations [options] commands\n+  \n+Commands\n+  initialize   Initializes the schema version table\n+\n+  apply ( all | next | until <target> )\n+  \n+              Migrates a schema to new available schema versions (default: next)\n+              \n+              If 'all' is specified, then it migrates all newer versions available\n+              If 'next' is specified, then it migrates only the next available version\n+              If 'until <target>' is specified, then it migrates all available versions before <target>\n+  \n+  undo ( all | last | until <target> )\n+  \n+              Rollbacks a schema to the previous schema version (default: last)\n+              \n+              If 'all' is specified, then it rollbacks all previous versions\n+              If 'last' is specified, then it rollbacks the previous version\n+              If 'until <target>' is specified, then it rollbacks all previous versions after <target>\n+  \n+  info        Displays information about the current and available migrations\n+  \n+  baseline    Sets the current schema to the specified version\n+  \n+              This is useful when production environments already have a schema unversioned. This sets\n+              the baseline from where to start applying migrations (i.e. kqsl-migrations baseline 1 'Current State')\n+  \n+  clean       Cleans the schema metadata objects                \n+  \n+  validate    Validate applied migrations against local files\n+  \n+              Compares local files checksum against the current metadata checksums to check for migrations files that have changed.\n+              This tells the user that their schema might be not valid against their local files.\n+  \n+Options\n+  -c, --config-file  Specifies a configuration file\n+ \n+  -h, --help         Shows this help  \n+    ", "originalCommit": "e6ab1ff376fb389f04d73c07f5abaf6a8cab0022", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzg1MDc4NQ==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537850785", "bodyText": "That's something we could add too. Seems useful. I'll add it to the klip.", "author": "spena", "createdAt": "2020-12-07T21:36:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY0MDcyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzg1MjA3OA==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537852078", "bodyText": "Done. I added the parameter to the tool help.", "author": "spena", "createdAt": "2020-12-07T21:39:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY0MDcyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzkwNTgwNg==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537905806", "bodyText": "+1, I think this is a great idea @colinhicks.", "author": "derekjn", "createdAt": "2020-12-07T23:16:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY0MDcyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY0MjkyNA==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537642924", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The `version_key` column has the version of the migration applied or undone. Other keys `CURRENT` and `LATEST` will be reserved for internal purposes.\n          \n          \n            \n            The `version_key` column has the version of the migration applied or undone. Special values of the `version_key`, `CURRENT` and `LATEST`, will be reserved for internal purposes.", "author": "colinhicks", "createdAt": "2020-12-07T16:27:01Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: TBD |\n+**Status**: _In Discussion_ |\n+**Discussion**: TBD\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## What is in scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Rollback migrated schemas to previous versions\n+    - Version control ksqlDB schema\n+\n+* Provide a test plan that validates the new tool will meet the product requirements\n+\n+\n+## What is not in scope\n+\n+* Some features found in existing migrations tools won't be supported\n+\n+  - `Execute entire migrations in a single transaction`\n+\n+    ksqlDB has support for a transactional metastore. However, this is limited to DDL statements that are persisted in the\n+    Command topic. But DML statements, such as INSERT, write directly to the topic and do not work with transactions. This disallows\n+    our tool to provide of a transaction support for the whole migration process. Also, DDL statements may create or delete topics,\n+    which falls in the non-transactional process.\n+\n+  - `Support for simulated or dry-runs executions`\n+\n+    A dry-run requires the tool to know the current state of the ksqlDB schema before attempting to verify the new migrations scripts. This\n+    requires a ksqlDB metastore exporting tool to work. Also, to make this simulation 100% safe, the tool requires a dummy Kafka and SR\n+    environment that can validate issues with topics and SR subjects names, as well as security restrictions.\n+\n+  - `Other features, such as repeatable migrations and callbacks`\n+\n+    Not required for a basic migration.\n+\n+* Do performance analysis on migrations\n+\n+  In other DBs, there are operations that take too much time to complete. Such is the case of ALTER statements, which can add/remove columns\n+  that would take time to complete on large tables. ksqlDB operations are quick unless an issue with the ksqlDB environment affects\n+  these executions.\n+\n+## Value/Return\n+\n+Users will be able to integrate ksqlDB upgrades testing with any CI/CD environments of their choice. This is a huge benefit for users who want\n+to automate ksqlDB upgrades with their application lifecycle.\n+\n+Also, a new tool will let users to easily automate schema evolution and migrations changes. They will be able to deploy new schema changes in\n+all their environments (Prod, QA, Devel, etc).\n+\n+## Public APIS\n+\n+- No changes on current public APIs\n+- A new Java API for Java developers\n+\n+  This seems important. However, it is in consideration if supporting a Java API is necessary.\n+\n+## Design\n+\n+I'm going to adopt `Flyway` and `DBGeni` tool syntax and behavior to design the ksqlDB migrations tool. Users will define a new migration in an SQL\n+script. This new SQL script describes the changes to do to migrate the cluster from state A to state B. Then run the migration from the\n+command line to apply the new state in the ksqlDB cluster. Users can also run this migration automatically as part of the build process and/or\n+testing in a CI/CD environment.\n+\n+For instance, the following example creates a new file that setups the initial state of the cluster.\n+\n+`V1__Initial_setup.sql`\n+```sql\n+CREATE STREAM pageviews (\n+    user_id INTEGER KEY, \n+    url STRING, \n+    status INTEGER\n+) WITH (\n+    KAFKA_TOPIC='pageviews', \n+    VALUE_FORMAT='JSON'    \n+);\n+\n+CREATE TABLE pageviews_metrics AS\n+ SELECT url, COUNT(*) AS num_views\n+  FROM pageviews\n+  GROUP BY url\n+  EMIT CHANGES;\n+```\n+\n+The user runs the migration tool on a specific ksqlDB cluster. The tool updates the cluster by running the SQL statements from the above file.\n+Then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: << Empty Schema >>\n+Migrating schema to version 1 - Initial setup\n+```\n+\n+Later, the user needs new changes on the cluster. All previous migrations files are immutable. So, any changes on the cluster require a new migration\n+file (or SQL script). Let's create one to create the users table.\n+\n+`V2__Add_users.sql`\n+```sql\n+CREATE TABLE users (\n+   ID BIGINT PRIMARY KEY, \n+   STRING NAME, \n+   ADDRESS ADDRESS_TYPE\n+ ) WITH (\n+   KAFKA_TOPIC='users', \n+   VALUE_FORMAT='JSON' \n+ );\n+```\n+\n+The user runs the migration tool on the same ksqlDB cluster. The tool detects the cluster has already version 1, so it executes only the newer version 2 migration\n+file. It then sets the state of the cluster to version 2.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: 1\n+Migrating schema to version 2 - Add users\n+```\n+\n+The benefit of this tool is that it detects the required updates to execute in the ksqlDB cluster. So, users don't need to know which SQL statements need to perform\n+to update the cluster. It also makes it easy to work with multiple clusters. Say that you have devel, stag and prod clusters. The tool will manage and track the version\n+of these clusters and apply the right SQL operations.\n+\n+To be able to do that, the tool will use a metadata stream and table that contains the current schema version and all executed updates.\n+\n+### Schema metadata\n+\n+Each ksqlDB cluster requires metadata objects where to track the current schema state. This is not only useful for the tool to know the migrations files to apply, but also for\n+users who can quickly verify if the cluster requires changes to fix a schema bug or add a major/minor improvement for their applications.\n+\n+The tool creates two metadata objects, a stream and table. automatically during the first migration; or when the user runs the tool with a parameter to initialize it.\n+\n+i.e.\n+```\n+$ ksql-migrations initialize\n+Schema metadata initialized successfully\n+```\n+\n+Due to some query limitations (lack of ORDER BY clause and pull queries working only on materialized views) in ksqlDB, the metadata will be stored in two places;  \n+One stream (MIGRATION_EVENTS) and one table (SCHEMA_VERSION).\n+\n+The stream and table require topics unique for the cluster. In this case, these topics names will use the same convention as the processing log. It's not going\n+to be an internal topic because it will be a user topic. The topic name is: `{clusterID}ksql_{StreamOrTableName}`.\n+\n+The user can specify a different name for the SCHEMA_VERSION table. This can be done through the tool configuration file. See `Configurations` for more details.\n+\n+The `MIGRATION_EVENTS` stream will keep track of every migration change (including undo changes). This will contain the history of changes the user has done. Also, this stream\n+will contain a key to the current version of the schema (specified as `CURRENT` version). Every time a new migration or undo happens, the tool will insert a new event with the\n+`CURRENT` key pointing to the current version.\n+\n+This is the `CREATE` statement for the `MIGRATION_EVENTS` stream:\n+```sql\n+CREATE STREAM migration_events (\n+  version_key  STRING KEY,\n+  version      STRING,\n+  name         STRING,\n+  state        STRING,\n+  undoable     BOOLEAN,\n+  checksum     STRING,\n+  started_on   STRING,\n+  completed_on STRING,\n+  previous     STRING\n+) WITH (  \n+  KAFKA_TOPIC='default_ksql_migration_events',\n+  VALUE_FORMAT='JSON',\n+  PARTITIONS=1,\n+  REPLICAS=1\n+);\n+```\n+\n+The `version_key` column has the version of the migration applied or undone. Other keys `CURRENT` and `LATEST` will be reserved for internal purposes.", "originalCommit": "e6ab1ff376fb389f04d73c07f5abaf6a8cab0022", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzcyMDYzNg==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r537720636", "bodyText": "Done", "author": "spena", "createdAt": "2020-12-07T18:12:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY0MjkyNA=="}], "type": "inlineReview"}, {"oid": "3ea065a55fa3e58f996af20f9dc1aa3f6313753c", "url": "https://github.com/confluentinc/ksql/commit/3ea065a55fa3e58f996af20f9dc1aa3f6313753c", "message": "chore: address PR feedback", "committedDate": "2020-12-07T18:12:43Z", "type": "commit"}, {"oid": "e172944f818f53135de579144895372291a54a59", "url": "https://github.com/confluentinc/ksql/commit/e172944f818f53135de579144895372291a54a59", "message": "chore: add '--define' parameters to migrations tool", "committedDate": "2020-12-07T21:38:39Z", "type": "commit"}, {"oid": "ee3551315470b1c97ef82ba8737a8aa8fcbc26f5", "url": "https://github.com/confluentinc/ksql/commit/ee3551315470b1c97ef82ba8737a8aa8fcbc26f5", "message": "chore: remove 'undoable' field from schema metadata\n\nThe 'undoable' field will be derived from the migration files. This\nfield is not needed in the stream object.", "committedDate": "2020-12-11T20:51:10Z", "type": "commit"}, {"oid": "53bd8898107b89b3e4af8bebcc01a60ac9a27d9e", "url": "https://github.com/confluentinc/ksql/commit/53bd8898107b89b3e4af8bebcc01a60ac9a27d9e", "message": "chore: add Directory structure section", "committedDate": "2020-12-11T21:27:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjU4MzU5MA==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r542583590", "bodyText": "sumlation\n\nTypo", "author": "derekjn", "createdAt": "2020-12-14T17:49:54Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: 0.16 |\n+**Status**: _In Discussion_ |\n+**Discussion**: https://github.com/confluentinc/ksql/pull/6721\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## In scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Dry-run operations to verify what migrations will be applied without altering the cluster\n+    - Version control ksqlDB schema\n+\n+\n+## Out of scope\n+\n+* Some features found in existing migrations tools won't be supported\n+\n+  - `Execute entire migrations in a single transaction`\n+\n+    ksqlDB has support for a transactional metastore. However, this is limited to DDL statements that are persisted in the\n+    Command topic. But DML statements, such as INSERT, write directly to the topic and do not work with transactions. This disallows\n+    our tool to provide of a transaction support for the whole migration process. Also, DDL statements may create or delete topics,\n+    which falls in the non-transactional process.\n+\n+  - `Support for simulated executions`\n+\n+    A sumlation requires the tool to know the current state of the ksqlDB schema before attempting to verify the new migrations scripts. This", "originalCommit": "ed219807bfb6f4765b5efb553a019273f2eab71e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "f7572bc7bec4b0c1acd00955f35cb5eec5e5e87f", "url": "https://github.com/confluentinc/ksql/commit/f7572bc7bec4b0c1acd00955f35cb5eec5e5e87f", "message": "chore: Update KLIP with Derek's feedback\n\n- Use integer versions instead of decimal verions\n- Add undo as future work\n- Add dry-run support", "committedDate": "2020-12-14T20:03:39Z", "type": "forcePushed"}, {"oid": "7bc5875896c0206574e096c0ead808b5a87caa89", "url": "https://github.com/confluentinc/ksql/commit/7bc5875896c0206574e096c0ead808b5a87caa89", "message": "chore: Update KLIP with Derek's feedback\n\n- Use integer versions instead of decimal verions\n- Add undo as future work\n- Add dry-run support", "committedDate": "2020-12-14T20:04:20Z", "type": "commit"}, {"oid": "7bc5875896c0206574e096c0ead808b5a87caa89", "url": "https://github.com/confluentinc/ksql/commit/7bc5875896c0206574e096c0ead808b5a87caa89", "message": "chore: Update KLIP with Derek's feedback\n\n- Use integer versions instead of decimal verions\n- Add undo as future work\n- Add dry-run support", "committedDate": "2020-12-14T20:04:20Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0MzAxMQ==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r544543011", "bodyText": "at the moment, pull queries don't give us any consistency guarantees. if we query at different times and different replicas we may get not-up-to-date information. is that problematic for this design?", "author": "agavra", "createdAt": "2020-12-16T18:53:51Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: 0.16 |\n+**Status**: _Design Approved_ |\n+**Discussion**: https://github.com/confluentinc/ksql/pull/6721\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## In scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Dry-run operations to verify what migrations will be applied without altering the cluster\n+    - Version control ksqlDB schema\n+\n+\n+## Out of scope\n+\n+* Some features found in existing migrations tools won't be supported\n+\n+  - `Execute entire migrations in a single transaction`\n+\n+    ksqlDB has support for a transactional metastore. However, this is limited to DDL statements that are persisted in the\n+    Command topic. But DML statements, such as INSERT, write directly to the topic and do not work with transactions. This disallows\n+    our tool to provide of a transaction support for the whole migration process. Also, DDL statements may create or delete topics,\n+    which falls in the non-transactional process.\n+\n+  - `Support for simulated executions`\n+\n+    A simulation requires the tool to know the current state of the ksqlDB schema before attempting to verify the new migrations scripts. This\n+    requires a ksqlDB metastore exporting tool to work. Also, to make this simulation 100% safe, the tool requires a dummy Kafka and SR\n+    environment that can validate issues with topics and SR subjects names, as well as security restrictions.\n+\n+  - `Other features, such as repeatable migrations and callbacks`\n+\n+    Not required for a basic migration.\n+\n+* Do performance analysis on migrations\n+\n+  In other DBs, there are operations that take too much time to complete. Such is the case of ALTER statements, which can add/remove columns\n+  that would take time to complete on large tables. ksqlDB operations are quick unless an issue with the ksqlDB environment affects\n+  these executions.\n+\n+* Squash several migration files into one\n+\n+  This is a very important functionality users may want to use. Over time, users may have several small migration files that can be squashed\n+  into one single file. However, this functionality gets out of scope for the migrations tool. It is easier to write a ksqlDB metastore tool\n+  that exports the cluster metadata to a SQL file, then use this SQL file as a replacement for the user migrations scripts.\n+\n+## Future work\n+\n+* `Undo migrated schemas to previous versions`\n+\n+  ksqlDB has a few statements that support undo, and some of them are limited. The first version for migrations will not support this feature.\n+  Detailed information about undo is explained in the document for future reference. Also, the schema metadata (See Schema metadata) needs to\n+  be prepared with future undo operations.\n+\n+## Value/Return\n+\n+Users will be able to integrate ksqlDB upgrades testing with any CI/CD environments of their choice. This is a huge benefit for users who want\n+to automate ksqlDB upgrades with their application lifecycle.\n+\n+Also, a new tool will let users to easily automate schema evolution and migrations changes. They will be able to deploy new schema changes in\n+all their environments (Prod, QA, Devel, etc).\n+\n+## Public APIS\n+\n+- No changes on current public APIs\n+- A new Java API for Java developers\n+\n+  This seems important. However, it is in consideration if supporting a Java API is necessary.\n+\n+## Design\n+\n+I'm going to adopt `Flyway` and `DBGeni` tool syntax and behavior to design the ksqlDB migrations tool. Users will define a new migration in an SQL\n+script. This new SQL script describes the changes to do to migrate the cluster from state A to state B. Then run the migration from the\n+command line to apply the new state in the ksqlDB cluster. Users can also run this migration automatically as part of the build process and/or\n+testing in a CI/CD environment.\n+\n+For instance, the following example creates a new file that setups the initial state of the cluster.\n+\n+`V000001__Initial_setup.sql`\n+```sql\n+CREATE STREAM pageviews (\n+    user_id INTEGER KEY, \n+    url STRING, \n+    status INTEGER\n+) WITH (\n+    KAFKA_TOPIC='pageviews', \n+    VALUE_FORMAT='JSON'    \n+);\n+\n+CREATE TABLE pageviews_metrics AS\n+ SELECT url, COUNT(*) AS num_views\n+  FROM pageviews\n+  GROUP BY url\n+  EMIT CHANGES;\n+```\n+\n+The user runs the migration tool on a specific ksqlDB cluster. The tool updates the cluster by running the SQL statements from the above file.\n+Then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: << Empty Schema >>\n+Migrating schema to version 1 - Initial setup\n+```\n+\n+Later, the user needs new changes on the cluster. All previous migrations files are immutable. So, any changes on the cluster require a new migration\n+file (or SQL script). Let's create one to create the users table.\n+\n+`V000002__Add_users.sql`\n+```sql\n+CREATE TABLE users (\n+   ID BIGINT PRIMARY KEY, \n+   STRING NAME, \n+   ADDRESS ADDRESS_TYPE\n+ ) WITH (\n+   KAFKA_TOPIC='users', \n+   VALUE_FORMAT='JSON' \n+ );\n+```\n+\n+The user runs the migration tool on the same ksqlDB cluster. The tool detects the cluster has already version 1, so it executes only the newer version 2 migration\n+file. It then sets the state of the cluster to version 2.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: 1\n+Migrating schema to version 2 - Add users\n+```\n+\n+All migration files will support only integer versions (no decimal versions). Integer versions are easier to sort when are found in the file name. Also, there are\n+too few cases that require decimal versioning (i.e. `1.1`) in schema changes. We don't expect users to use decimal versions on ksqlDB migrations.\n+\n+The benefit of this tool is that it detects the required updates to execute in the ksqlDB cluster. So, users don't need to know which SQL statements need to perform\n+to update the cluster. It also makes it easy to work with multiple clusters. Say that you have devel, stag and prod clusters. The tool will manage and track the version\n+of these clusters and apply the right SQL operations.\n+\n+To be able to do that, the tool will use a metadata stream and table that contains the current schema version and all executed updates.\n+\n+### Schema metadata\n+\n+Each ksqlDB cluster requires metadata objects where to track the current schema state. This is not only useful for the tool to know the migrations files to apply, but also for\n+users who can quickly verify if the cluster requires changes to fix a schema bug or add a major/minor improvement for their applications.\n+\n+The tool creates two metadata objects, a stream and table. automatically during the first migration; or when the user runs the tool with a parameter to initialize it.\n+\n+i.e.\n+```\n+$ ksql-migrations initialize\n+Schema metadata initialized successfully\n+```\n+\n+Due to some query limitations (lack of ORDER BY clause and pull queries working only on materialized views) in ksqlDB, the metadata will be stored in two places;  \n+One stream (MIGRATION_EVENTS) and one table (SCHEMA_VERSION).\n+\n+The stream and table require topics unique for the cluster. In this case, these topics names will use the same convention as the processing log. It's not going\n+to be an internal topic because it will be a user topic. The topic name is: `{clusterID}ksql_{StreamOrTableName}`.\n+\n+The user can specify a different name for the SCHEMA_VERSION table. This can be done through the tool configuration file. See `Configurations` for more details.\n+\n+The `MIGRATION_EVENTS` stream will keep track of every migration change (including undo changes). This will contain the history of changes the user has done. Also, this stream\n+will contain a key to the current version of the schema (specified as `CURRENT` version). Every time a new migration or undo happens, the tool will insert a new event with the\n+`CURRENT` key pointing to the current version.\n+\n+This is the `CREATE` statement for the `MIGRATION_EVENTS` stream:\n+```sql\n+CREATE STREAM migration_events (\n+  version_key  STRING KEY,\n+  version      STRING,\n+  name         STRING,\n+  state        STRING,  \n+  checksum     STRING,\n+  started_on   STRING,\n+  completed_on STRING,\n+  previous     STRING\n+) WITH (  \n+  KAFKA_TOPIC='default_ksql_migration_events',\n+  VALUE_FORMAT='JSON',\n+  PARTITIONS=1,\n+  REPLICAS=1\n+);\n+```\n+\n+The `version_key` column has the version of the migration applied or undone. Special values of the `version_key`, `CURRENT` and `LATEST` will be reserved for internal purposes.\n+The `version` column has the version of the migration applied.\n+The `name` column has the name of the migration.\n+The `state` column has the state of the migration process. It can be any of `Pending`, `Running`, `Migrated`, `Error`, `Undone`.\n+The `checksum` column has the MD5 checksum of the migration file. It is used to validate the schema migrations with the local files.\n+The `started_on` column has the date and time when the migration started.\n+The `completed_on` column has the date and time when the migration finished.\n+The `previous` column has the previous version applied.\n+\n+The `SCHEMA_VERSION` table will also keep track of every migration change (including future work for undo changes), but with the difference that being a table the tool will see quickly if a schema\n+version has been migrated or undone. It will also give us a quick view of the `CURRENT` state of the schema. The major advantage is that the tool will use pull queries in this materialized", "originalCommit": "7bc5875896c0206574e096c0ead808b5a87caa89", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTE4ODUzNg==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r545188536", "bodyText": "I'm not sure about this.\nI understand that inserting a row in the stream may eventually be available in the MV for a pull query. So my idea was this:\n\nInsert a row in the stream for a Pending migration (i.e. v1)\nRun the pull query on the MV and wait until CURRENT is set to v1 and Pending (fail otherwise)\nExecute the v1 migration script\nInsert a row in the stream to change Pending -> Migrated\nRun the pull query on the MV and wait until CURRENT is set to v1 and Migrated (fail otherwise)\nContinue with the next migration script\n\nBut you mentioned queries at different times and different replicas. I think even a complete state store clean up would cause this consistency issues because when the ksql node is restarted, it will take time to sync the state store again. Do you have some ideas how to do it?", "author": "spena", "createdAt": "2020-12-17T15:41:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0MzAxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTIzOTM3Nw==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r545239377", "bodyText": "I don't really have a good idea about how to work around this until we have vector clock support (cc @vvcephei) so that we can ensure we're at least up to date as of a certain point", "author": "agavra", "createdAt": "2020-12-17T16:47:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0MzAxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0NTUwOQ==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r544545509", "bodyText": "these will be output every time, right? so the actual stream would also have this after the first event with both of them pointing to 1?", "author": "agavra", "createdAt": "2020-12-16T18:57:24Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: 0.16 |\n+**Status**: _Design Approved_ |\n+**Discussion**: https://github.com/confluentinc/ksql/pull/6721\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## In scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Dry-run operations to verify what migrations will be applied without altering the cluster\n+    - Version control ksqlDB schema\n+\n+\n+## Out of scope\n+\n+* Some features found in existing migrations tools won't be supported\n+\n+  - `Execute entire migrations in a single transaction`\n+\n+    ksqlDB has support for a transactional metastore. However, this is limited to DDL statements that are persisted in the\n+    Command topic. But DML statements, such as INSERT, write directly to the topic and do not work with transactions. This disallows\n+    our tool to provide of a transaction support for the whole migration process. Also, DDL statements may create or delete topics,\n+    which falls in the non-transactional process.\n+\n+  - `Support for simulated executions`\n+\n+    A simulation requires the tool to know the current state of the ksqlDB schema before attempting to verify the new migrations scripts. This\n+    requires a ksqlDB metastore exporting tool to work. Also, to make this simulation 100% safe, the tool requires a dummy Kafka and SR\n+    environment that can validate issues with topics and SR subjects names, as well as security restrictions.\n+\n+  - `Other features, such as repeatable migrations and callbacks`\n+\n+    Not required for a basic migration.\n+\n+* Do performance analysis on migrations\n+\n+  In other DBs, there are operations that take too much time to complete. Such is the case of ALTER statements, which can add/remove columns\n+  that would take time to complete on large tables. ksqlDB operations are quick unless an issue with the ksqlDB environment affects\n+  these executions.\n+\n+* Squash several migration files into one\n+\n+  This is a very important functionality users may want to use. Over time, users may have several small migration files that can be squashed\n+  into one single file. However, this functionality gets out of scope for the migrations tool. It is easier to write a ksqlDB metastore tool\n+  that exports the cluster metadata to a SQL file, then use this SQL file as a replacement for the user migrations scripts.\n+\n+## Future work\n+\n+* `Undo migrated schemas to previous versions`\n+\n+  ksqlDB has a few statements that support undo, and some of them are limited. The first version for migrations will not support this feature.\n+  Detailed information about undo is explained in the document for future reference. Also, the schema metadata (See Schema metadata) needs to\n+  be prepared with future undo operations.\n+\n+## Value/Return\n+\n+Users will be able to integrate ksqlDB upgrades testing with any CI/CD environments of their choice. This is a huge benefit for users who want\n+to automate ksqlDB upgrades with their application lifecycle.\n+\n+Also, a new tool will let users to easily automate schema evolution and migrations changes. They will be able to deploy new schema changes in\n+all their environments (Prod, QA, Devel, etc).\n+\n+## Public APIS\n+\n+- No changes on current public APIs\n+- A new Java API for Java developers\n+\n+  This seems important. However, it is in consideration if supporting a Java API is necessary.\n+\n+## Design\n+\n+I'm going to adopt `Flyway` and `DBGeni` tool syntax and behavior to design the ksqlDB migrations tool. Users will define a new migration in an SQL\n+script. This new SQL script describes the changes to do to migrate the cluster from state A to state B. Then run the migration from the\n+command line to apply the new state in the ksqlDB cluster. Users can also run this migration automatically as part of the build process and/or\n+testing in a CI/CD environment.\n+\n+For instance, the following example creates a new file that setups the initial state of the cluster.\n+\n+`V000001__Initial_setup.sql`\n+```sql\n+CREATE STREAM pageviews (\n+    user_id INTEGER KEY, \n+    url STRING, \n+    status INTEGER\n+) WITH (\n+    KAFKA_TOPIC='pageviews', \n+    VALUE_FORMAT='JSON'    \n+);\n+\n+CREATE TABLE pageviews_metrics AS\n+ SELECT url, COUNT(*) AS num_views\n+  FROM pageviews\n+  GROUP BY url\n+  EMIT CHANGES;\n+```\n+\n+The user runs the migration tool on a specific ksqlDB cluster. The tool updates the cluster by running the SQL statements from the above file.\n+Then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: << Empty Schema >>\n+Migrating schema to version 1 - Initial setup\n+```\n+\n+Later, the user needs new changes on the cluster. All previous migrations files are immutable. So, any changes on the cluster require a new migration\n+file (or SQL script). Let's create one to create the users table.\n+\n+`V000002__Add_users.sql`\n+```sql\n+CREATE TABLE users (\n+   ID BIGINT PRIMARY KEY, \n+   STRING NAME, \n+   ADDRESS ADDRESS_TYPE\n+ ) WITH (\n+   KAFKA_TOPIC='users', \n+   VALUE_FORMAT='JSON' \n+ );\n+```\n+\n+The user runs the migration tool on the same ksqlDB cluster. The tool detects the cluster has already version 1, so it executes only the newer version 2 migration\n+file. It then sets the state of the cluster to version 2.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: 1\n+Migrating schema to version 2 - Add users\n+```\n+\n+All migration files will support only integer versions (no decimal versions). Integer versions are easier to sort when are found in the file name. Also, there are\n+too few cases that require decimal versioning (i.e. `1.1`) in schema changes. We don't expect users to use decimal versions on ksqlDB migrations.\n+\n+The benefit of this tool is that it detects the required updates to execute in the ksqlDB cluster. So, users don't need to know which SQL statements need to perform\n+to update the cluster. It also makes it easy to work with multiple clusters. Say that you have devel, stag and prod clusters. The tool will manage and track the version\n+of these clusters and apply the right SQL operations.\n+\n+To be able to do that, the tool will use a metadata stream and table that contains the current schema version and all executed updates.\n+\n+### Schema metadata\n+\n+Each ksqlDB cluster requires metadata objects where to track the current schema state. This is not only useful for the tool to know the migrations files to apply, but also for\n+users who can quickly verify if the cluster requires changes to fix a schema bug or add a major/minor improvement for their applications.\n+\n+The tool creates two metadata objects, a stream and table. automatically during the first migration; or when the user runs the tool with a parameter to initialize it.\n+\n+i.e.\n+```\n+$ ksql-migrations initialize\n+Schema metadata initialized successfully\n+```\n+\n+Due to some query limitations (lack of ORDER BY clause and pull queries working only on materialized views) in ksqlDB, the metadata will be stored in two places;  \n+One stream (MIGRATION_EVENTS) and one table (SCHEMA_VERSION).\n+\n+The stream and table require topics unique for the cluster. In this case, these topics names will use the same convention as the processing log. It's not going\n+to be an internal topic because it will be a user topic. The topic name is: `{clusterID}ksql_{StreamOrTableName}`.\n+\n+The user can specify a different name for the SCHEMA_VERSION table. This can be done through the tool configuration file. See `Configurations` for more details.\n+\n+The `MIGRATION_EVENTS` stream will keep track of every migration change (including undo changes). This will contain the history of changes the user has done. Also, this stream\n+will contain a key to the current version of the schema (specified as `CURRENT` version). Every time a new migration or undo happens, the tool will insert a new event with the\n+`CURRENT` key pointing to the current version.\n+\n+This is the `CREATE` statement for the `MIGRATION_EVENTS` stream:\n+```sql\n+CREATE STREAM migration_events (\n+  version_key  STRING KEY,\n+  version      STRING,\n+  name         STRING,\n+  state        STRING,  \n+  checksum     STRING,\n+  started_on   STRING,\n+  completed_on STRING,\n+  previous     STRING\n+) WITH (  \n+  KAFKA_TOPIC='default_ksql_migration_events',\n+  VALUE_FORMAT='JSON',\n+  PARTITIONS=1,\n+  REPLICAS=1\n+);\n+```\n+\n+The `version_key` column has the version of the migration applied or undone. Special values of the `version_key`, `CURRENT` and `LATEST` will be reserved for internal purposes.\n+The `version` column has the version of the migration applied.\n+The `name` column has the name of the migration.\n+The `state` column has the state of the migration process. It can be any of `Pending`, `Running`, `Migrated`, `Error`, `Undone`.\n+The `checksum` column has the MD5 checksum of the migration file. It is used to validate the schema migrations with the local files.\n+The `started_on` column has the date and time when the migration started.\n+The `completed_on` column has the date and time when the migration finished.\n+The `previous` column has the previous version applied.\n+\n+The `SCHEMA_VERSION` table will also keep track of every migration change (including future work for undo changes), but with the difference that being a table the tool will see quickly if a schema\n+version has been migrated or undone. It will also give us a quick view of the `CURRENT` state of the schema. The major advantage is that the tool will use pull queries in this materialized\n+view to get the `CURRENT` state of the cluster.\n+\n+There is another reserved key `LATEST` that will point to the latest change applied. This will be used by the tool to stream all changes up to the row that `LATEST` points, and stop.\n+The `ksql-migrations info` command will use this to display information about the migrations that have been applied or undone. I cannot stream the `MIGRATION_EVENTS` or `SCHEMA_VERSION` directly because\n+the tool does not know when to stop.\n+\n+*Note:*\n+The below schema is designed so we support undo operations in the future. When an undo happens, the `CURRENT` key will point to the previous version found.\n+\n+This is the `CREATE` statement for the `SCHEMA_VERSION` table:\n+```sql\n+CREATE TABLE schema_version\n+  WITH (\n+    KAFKA_TOPIC='default_ksql_schema_version',\n+    VALUE_FORMAT='JSON',\n+    PARTITIONS=1\n+  )\n+  AS SELECT \n+    version_key, \n+    latest_by_offset(version) as version, \n+    latest_by_offset(name) AS name, \n+    latest_by_offset(state) AS state,     \n+    latest_by_offset(checksum) AS checksum, \n+    latest_by_offset(started_on) AS started_on, \n+    latest_by_offset(completed_on) AS completed_on, \n+    latest_by_offset(previous) AS previous\n+  FROM migration_events \n+  GROUP BY version_key;\n+```\n+\n+The following are the outputs that we'll see on each stream and table, and how the tool will figure out the current schema version using pull queries.\n+\n+The `MIGRATION_EVENTS` stream output:\n+```shell script\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Migrated | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| 2           | 2       | Add users     | Undone   | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |", "originalCommit": "7bc5875896c0206574e096c0ead808b5a87caa89", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTE3NDA5NQ==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r545174095", "bodyText": "Yes. CURRENT and LATEST will always point to the same row. The reason is the support of Undo operations, where CURRENT may point to a previous version. We're not going to support Undo for the moment. I left them just for future reference, but now I'm thinking about it, I think only one is necessary. We can add the LATEST pointer once Undo is supported.", "author": "spena", "createdAt": "2020-12-17T15:23:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0NTUwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0NjcyNQ==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r544546725", "bodyText": "which two files?", "author": "agavra", "createdAt": "2020-12-16T18:59:13Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: 0.16 |\n+**Status**: _Design Approved_ |\n+**Discussion**: https://github.com/confluentinc/ksql/pull/6721\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## In scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Dry-run operations to verify what migrations will be applied without altering the cluster\n+    - Version control ksqlDB schema\n+\n+\n+## Out of scope\n+\n+* Some features found in existing migrations tools won't be supported\n+\n+  - `Execute entire migrations in a single transaction`\n+\n+    ksqlDB has support for a transactional metastore. However, this is limited to DDL statements that are persisted in the\n+    Command topic. But DML statements, such as INSERT, write directly to the topic and do not work with transactions. This disallows\n+    our tool to provide of a transaction support for the whole migration process. Also, DDL statements may create or delete topics,\n+    which falls in the non-transactional process.\n+\n+  - `Support for simulated executions`\n+\n+    A simulation requires the tool to know the current state of the ksqlDB schema before attempting to verify the new migrations scripts. This\n+    requires a ksqlDB metastore exporting tool to work. Also, to make this simulation 100% safe, the tool requires a dummy Kafka and SR\n+    environment that can validate issues with topics and SR subjects names, as well as security restrictions.\n+\n+  - `Other features, such as repeatable migrations and callbacks`\n+\n+    Not required for a basic migration.\n+\n+* Do performance analysis on migrations\n+\n+  In other DBs, there are operations that take too much time to complete. Such is the case of ALTER statements, which can add/remove columns\n+  that would take time to complete on large tables. ksqlDB operations are quick unless an issue with the ksqlDB environment affects\n+  these executions.\n+\n+* Squash several migration files into one\n+\n+  This is a very important functionality users may want to use. Over time, users may have several small migration files that can be squashed\n+  into one single file. However, this functionality gets out of scope for the migrations tool. It is easier to write a ksqlDB metastore tool\n+  that exports the cluster metadata to a SQL file, then use this SQL file as a replacement for the user migrations scripts.\n+\n+## Future work\n+\n+* `Undo migrated schemas to previous versions`\n+\n+  ksqlDB has a few statements that support undo, and some of them are limited. The first version for migrations will not support this feature.\n+  Detailed information about undo is explained in the document for future reference. Also, the schema metadata (See Schema metadata) needs to\n+  be prepared with future undo operations.\n+\n+## Value/Return\n+\n+Users will be able to integrate ksqlDB upgrades testing with any CI/CD environments of their choice. This is a huge benefit for users who want\n+to automate ksqlDB upgrades with their application lifecycle.\n+\n+Also, a new tool will let users to easily automate schema evolution and migrations changes. They will be able to deploy new schema changes in\n+all their environments (Prod, QA, Devel, etc).\n+\n+## Public APIS\n+\n+- No changes on current public APIs\n+- A new Java API for Java developers\n+\n+  This seems important. However, it is in consideration if supporting a Java API is necessary.\n+\n+## Design\n+\n+I'm going to adopt `Flyway` and `DBGeni` tool syntax and behavior to design the ksqlDB migrations tool. Users will define a new migration in an SQL\n+script. This new SQL script describes the changes to do to migrate the cluster from state A to state B. Then run the migration from the\n+command line to apply the new state in the ksqlDB cluster. Users can also run this migration automatically as part of the build process and/or\n+testing in a CI/CD environment.\n+\n+For instance, the following example creates a new file that setups the initial state of the cluster.\n+\n+`V000001__Initial_setup.sql`\n+```sql\n+CREATE STREAM pageviews (\n+    user_id INTEGER KEY, \n+    url STRING, \n+    status INTEGER\n+) WITH (\n+    KAFKA_TOPIC='pageviews', \n+    VALUE_FORMAT='JSON'    \n+);\n+\n+CREATE TABLE pageviews_metrics AS\n+ SELECT url, COUNT(*) AS num_views\n+  FROM pageviews\n+  GROUP BY url\n+  EMIT CHANGES;\n+```\n+\n+The user runs the migration tool on a specific ksqlDB cluster. The tool updates the cluster by running the SQL statements from the above file.\n+Then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: << Empty Schema >>\n+Migrating schema to version 1 - Initial setup\n+```\n+\n+Later, the user needs new changes on the cluster. All previous migrations files are immutable. So, any changes on the cluster require a new migration\n+file (or SQL script). Let's create one to create the users table.\n+\n+`V000002__Add_users.sql`\n+```sql\n+CREATE TABLE users (\n+   ID BIGINT PRIMARY KEY, \n+   STRING NAME, \n+   ADDRESS ADDRESS_TYPE\n+ ) WITH (\n+   KAFKA_TOPIC='users', \n+   VALUE_FORMAT='JSON' \n+ );\n+```\n+\n+The user runs the migration tool on the same ksqlDB cluster. The tool detects the cluster has already version 1, so it executes only the newer version 2 migration\n+file. It then sets the state of the cluster to version 2.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: 1\n+Migrating schema to version 2 - Add users\n+```\n+\n+All migration files will support only integer versions (no decimal versions). Integer versions are easier to sort when are found in the file name. Also, there are\n+too few cases that require decimal versioning (i.e. `1.1`) in schema changes. We don't expect users to use decimal versions on ksqlDB migrations.\n+\n+The benefit of this tool is that it detects the required updates to execute in the ksqlDB cluster. So, users don't need to know which SQL statements need to perform\n+to update the cluster. It also makes it easy to work with multiple clusters. Say that you have devel, stag and prod clusters. The tool will manage and track the version\n+of these clusters and apply the right SQL operations.\n+\n+To be able to do that, the tool will use a metadata stream and table that contains the current schema version and all executed updates.\n+\n+### Schema metadata\n+\n+Each ksqlDB cluster requires metadata objects where to track the current schema state. This is not only useful for the tool to know the migrations files to apply, but also for\n+users who can quickly verify if the cluster requires changes to fix a schema bug or add a major/minor improvement for their applications.\n+\n+The tool creates two metadata objects, a stream and table. automatically during the first migration; or when the user runs the tool with a parameter to initialize it.\n+\n+i.e.\n+```\n+$ ksql-migrations initialize\n+Schema metadata initialized successfully\n+```\n+\n+Due to some query limitations (lack of ORDER BY clause and pull queries working only on materialized views) in ksqlDB, the metadata will be stored in two places;  \n+One stream (MIGRATION_EVENTS) and one table (SCHEMA_VERSION).\n+\n+The stream and table require topics unique for the cluster. In this case, these topics names will use the same convention as the processing log. It's not going\n+to be an internal topic because it will be a user topic. The topic name is: `{clusterID}ksql_{StreamOrTableName}`.\n+\n+The user can specify a different name for the SCHEMA_VERSION table. This can be done through the tool configuration file. See `Configurations` for more details.\n+\n+The `MIGRATION_EVENTS` stream will keep track of every migration change (including undo changes). This will contain the history of changes the user has done. Also, this stream\n+will contain a key to the current version of the schema (specified as `CURRENT` version). Every time a new migration or undo happens, the tool will insert a new event with the\n+`CURRENT` key pointing to the current version.\n+\n+This is the `CREATE` statement for the `MIGRATION_EVENTS` stream:\n+```sql\n+CREATE STREAM migration_events (\n+  version_key  STRING KEY,\n+  version      STRING,\n+  name         STRING,\n+  state        STRING,  \n+  checksum     STRING,\n+  started_on   STRING,\n+  completed_on STRING,\n+  previous     STRING\n+) WITH (  \n+  KAFKA_TOPIC='default_ksql_migration_events',\n+  VALUE_FORMAT='JSON',\n+  PARTITIONS=1,\n+  REPLICAS=1\n+);\n+```\n+\n+The `version_key` column has the version of the migration applied or undone. Special values of the `version_key`, `CURRENT` and `LATEST` will be reserved for internal purposes.\n+The `version` column has the version of the migration applied.\n+The `name` column has the name of the migration.\n+The `state` column has the state of the migration process. It can be any of `Pending`, `Running`, `Migrated`, `Error`, `Undone`.\n+The `checksum` column has the MD5 checksum of the migration file. It is used to validate the schema migrations with the local files.\n+The `started_on` column has the date and time when the migration started.\n+The `completed_on` column has the date and time when the migration finished.\n+The `previous` column has the previous version applied.\n+\n+The `SCHEMA_VERSION` table will also keep track of every migration change (including future work for undo changes), but with the difference that being a table the tool will see quickly if a schema\n+version has been migrated or undone. It will also give us a quick view of the `CURRENT` state of the schema. The major advantage is that the tool will use pull queries in this materialized\n+view to get the `CURRENT` state of the cluster.\n+\n+There is another reserved key `LATEST` that will point to the latest change applied. This will be used by the tool to stream all changes up to the row that `LATEST` points, and stop.\n+The `ksql-migrations info` command will use this to display information about the migrations that have been applied or undone. I cannot stream the `MIGRATION_EVENTS` or `SCHEMA_VERSION` directly because\n+the tool does not know when to stop.\n+\n+*Note:*\n+The below schema is designed so we support undo operations in the future. When an undo happens, the `CURRENT` key will point to the previous version found.\n+\n+This is the `CREATE` statement for the `SCHEMA_VERSION` table:\n+```sql\n+CREATE TABLE schema_version\n+  WITH (\n+    KAFKA_TOPIC='default_ksql_schema_version',\n+    VALUE_FORMAT='JSON',\n+    PARTITIONS=1\n+  )\n+  AS SELECT \n+    version_key, \n+    latest_by_offset(version) as version, \n+    latest_by_offset(name) AS name, \n+    latest_by_offset(state) AS state,     \n+    latest_by_offset(checksum) AS checksum, \n+    latest_by_offset(started_on) AS started_on, \n+    latest_by_offset(completed_on) AS completed_on, \n+    latest_by_offset(previous) AS previous\n+  FROM migration_events \n+  GROUP BY version_key;\n+```\n+\n+The following are the outputs that we'll see on each stream and table, and how the tool will figure out the current schema version using pull queries.\n+\n+The `MIGRATION_EVENTS` stream output:\n+```shell script\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Migrated | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| 2           | 2       | Add users     | Undone   | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The `SCHEMA_VERSION` table output:\n+```shell script\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Undone   | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The tool will later use pull queries to identify the current state of the system:\n+```sql\n+SELECT version, state, previous FROM SCHEMA_VERSION WHERE version_key = 'CURRENT'; \n+```\n+\n+\n+### Naming convention\n+\n+Hope you have noticed the naming rules I followed in the previous examples for naming the migration files. Having a naming convention for files is necessary\n+for the tool to detect what migration to apply or revert. Naming files are easier than creating configurations or command parameters to specify the same info.\n+\n+The migration files follow the same `Flyway` naming convention.\n+`(Prefix)(Version)__(Description).sql`\n+\n+The `Prefix` specifies whether the file is a new migration (`V`) file. The prefix is used so that we can add other operations in the future, such as undo operations.\n+The `Version` is the version number used for the schema. Versions will not support decimal versions. Integers with 6 digits are used.\n+The `Description` is a name or description of the new migration. Description uses underscores (automatically replaced by spaces at runtime) or spaces separated the words.\n+\n+i.e.\n+```\n+- V000001__Initial_setup.sql    # a new version to migrate (v1) with name 'Initial setup'\n+- V000002__Add_users.sql        # a new version to migrate (v2) with name 'Add users'\n+```\n+\n+It is recommended the user creates these two files on any new migration. The tool will not enforce that. We need specify this recommendation in the ksqlDB documents.", "originalCommit": "7bc5875896c0206574e096c0ead808b5a87caa89", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTE3NDc2Mw==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r545174763", "bodyText": "I need to remove that. We were going to support Undo operations, so these two files referenced to the V and U files. There is one file only now.", "author": "spena", "createdAt": "2020-12-17T15:23:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0NjcyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0ODUxOA==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r544548518", "bodyText": "what happens if the user tries to initialize twice? I assume we should detect and fail?", "author": "agavra", "createdAt": "2020-12-16T19:01:56Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: 0.16 |\n+**Status**: _Design Approved_ |\n+**Discussion**: https://github.com/confluentinc/ksql/pull/6721\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## In scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Dry-run operations to verify what migrations will be applied without altering the cluster\n+    - Version control ksqlDB schema\n+\n+\n+## Out of scope\n+\n+* Some features found in existing migrations tools won't be supported\n+\n+  - `Execute entire migrations in a single transaction`\n+\n+    ksqlDB has support for a transactional metastore. However, this is limited to DDL statements that are persisted in the\n+    Command topic. But DML statements, such as INSERT, write directly to the topic and do not work with transactions. This disallows\n+    our tool to provide of a transaction support for the whole migration process. Also, DDL statements may create or delete topics,\n+    which falls in the non-transactional process.\n+\n+  - `Support for simulated executions`\n+\n+    A simulation requires the tool to know the current state of the ksqlDB schema before attempting to verify the new migrations scripts. This\n+    requires a ksqlDB metastore exporting tool to work. Also, to make this simulation 100% safe, the tool requires a dummy Kafka and SR\n+    environment that can validate issues with topics and SR subjects names, as well as security restrictions.\n+\n+  - `Other features, such as repeatable migrations and callbacks`\n+\n+    Not required for a basic migration.\n+\n+* Do performance analysis on migrations\n+\n+  In other DBs, there are operations that take too much time to complete. Such is the case of ALTER statements, which can add/remove columns\n+  that would take time to complete on large tables. ksqlDB operations are quick unless an issue with the ksqlDB environment affects\n+  these executions.\n+\n+* Squash several migration files into one\n+\n+  This is a very important functionality users may want to use. Over time, users may have several small migration files that can be squashed\n+  into one single file. However, this functionality gets out of scope for the migrations tool. It is easier to write a ksqlDB metastore tool\n+  that exports the cluster metadata to a SQL file, then use this SQL file as a replacement for the user migrations scripts.\n+\n+## Future work\n+\n+* `Undo migrated schemas to previous versions`\n+\n+  ksqlDB has a few statements that support undo, and some of them are limited. The first version for migrations will not support this feature.\n+  Detailed information about undo is explained in the document for future reference. Also, the schema metadata (See Schema metadata) needs to\n+  be prepared with future undo operations.\n+\n+## Value/Return\n+\n+Users will be able to integrate ksqlDB upgrades testing with any CI/CD environments of their choice. This is a huge benefit for users who want\n+to automate ksqlDB upgrades with their application lifecycle.\n+\n+Also, a new tool will let users to easily automate schema evolution and migrations changes. They will be able to deploy new schema changes in\n+all their environments (Prod, QA, Devel, etc).\n+\n+## Public APIS\n+\n+- No changes on current public APIs\n+- A new Java API for Java developers\n+\n+  This seems important. However, it is in consideration if supporting a Java API is necessary.\n+\n+## Design\n+\n+I'm going to adopt `Flyway` and `DBGeni` tool syntax and behavior to design the ksqlDB migrations tool. Users will define a new migration in an SQL\n+script. This new SQL script describes the changes to do to migrate the cluster from state A to state B. Then run the migration from the\n+command line to apply the new state in the ksqlDB cluster. Users can also run this migration automatically as part of the build process and/or\n+testing in a CI/CD environment.\n+\n+For instance, the following example creates a new file that setups the initial state of the cluster.\n+\n+`V000001__Initial_setup.sql`\n+```sql\n+CREATE STREAM pageviews (\n+    user_id INTEGER KEY, \n+    url STRING, \n+    status INTEGER\n+) WITH (\n+    KAFKA_TOPIC='pageviews', \n+    VALUE_FORMAT='JSON'    \n+);\n+\n+CREATE TABLE pageviews_metrics AS\n+ SELECT url, COUNT(*) AS num_views\n+  FROM pageviews\n+  GROUP BY url\n+  EMIT CHANGES;\n+```\n+\n+The user runs the migration tool on a specific ksqlDB cluster. The tool updates the cluster by running the SQL statements from the above file.\n+Then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: << Empty Schema >>\n+Migrating schema to version 1 - Initial setup\n+```\n+\n+Later, the user needs new changes on the cluster. All previous migrations files are immutable. So, any changes on the cluster require a new migration\n+file (or SQL script). Let's create one to create the users table.\n+\n+`V000002__Add_users.sql`\n+```sql\n+CREATE TABLE users (\n+   ID BIGINT PRIMARY KEY, \n+   STRING NAME, \n+   ADDRESS ADDRESS_TYPE\n+ ) WITH (\n+   KAFKA_TOPIC='users', \n+   VALUE_FORMAT='JSON' \n+ );\n+```\n+\n+The user runs the migration tool on the same ksqlDB cluster. The tool detects the cluster has already version 1, so it executes only the newer version 2 migration\n+file. It then sets the state of the cluster to version 2.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: 1\n+Migrating schema to version 2 - Add users\n+```\n+\n+All migration files will support only integer versions (no decimal versions). Integer versions are easier to sort when are found in the file name. Also, there are\n+too few cases that require decimal versioning (i.e. `1.1`) in schema changes. We don't expect users to use decimal versions on ksqlDB migrations.\n+\n+The benefit of this tool is that it detects the required updates to execute in the ksqlDB cluster. So, users don't need to know which SQL statements need to perform\n+to update the cluster. It also makes it easy to work with multiple clusters. Say that you have devel, stag and prod clusters. The tool will manage and track the version\n+of these clusters and apply the right SQL operations.\n+\n+To be able to do that, the tool will use a metadata stream and table that contains the current schema version and all executed updates.\n+\n+### Schema metadata\n+\n+Each ksqlDB cluster requires metadata objects where to track the current schema state. This is not only useful for the tool to know the migrations files to apply, but also for\n+users who can quickly verify if the cluster requires changes to fix a schema bug or add a major/minor improvement for their applications.\n+\n+The tool creates two metadata objects, a stream and table. automatically during the first migration; or when the user runs the tool with a parameter to initialize it.\n+\n+i.e.\n+```\n+$ ksql-migrations initialize\n+Schema metadata initialized successfully\n+```\n+\n+Due to some query limitations (lack of ORDER BY clause and pull queries working only on materialized views) in ksqlDB, the metadata will be stored in two places;  \n+One stream (MIGRATION_EVENTS) and one table (SCHEMA_VERSION).\n+\n+The stream and table require topics unique for the cluster. In this case, these topics names will use the same convention as the processing log. It's not going\n+to be an internal topic because it will be a user topic. The topic name is: `{clusterID}ksql_{StreamOrTableName}`.\n+\n+The user can specify a different name for the SCHEMA_VERSION table. This can be done through the tool configuration file. See `Configurations` for more details.\n+\n+The `MIGRATION_EVENTS` stream will keep track of every migration change (including undo changes). This will contain the history of changes the user has done. Also, this stream\n+will contain a key to the current version of the schema (specified as `CURRENT` version). Every time a new migration or undo happens, the tool will insert a new event with the\n+`CURRENT` key pointing to the current version.\n+\n+This is the `CREATE` statement for the `MIGRATION_EVENTS` stream:\n+```sql\n+CREATE STREAM migration_events (\n+  version_key  STRING KEY,\n+  version      STRING,\n+  name         STRING,\n+  state        STRING,  \n+  checksum     STRING,\n+  started_on   STRING,\n+  completed_on STRING,\n+  previous     STRING\n+) WITH (  \n+  KAFKA_TOPIC='default_ksql_migration_events',\n+  VALUE_FORMAT='JSON',\n+  PARTITIONS=1,\n+  REPLICAS=1\n+);\n+```\n+\n+The `version_key` column has the version of the migration applied or undone. Special values of the `version_key`, `CURRENT` and `LATEST` will be reserved for internal purposes.\n+The `version` column has the version of the migration applied.\n+The `name` column has the name of the migration.\n+The `state` column has the state of the migration process. It can be any of `Pending`, `Running`, `Migrated`, `Error`, `Undone`.\n+The `checksum` column has the MD5 checksum of the migration file. It is used to validate the schema migrations with the local files.\n+The `started_on` column has the date and time when the migration started.\n+The `completed_on` column has the date and time when the migration finished.\n+The `previous` column has the previous version applied.\n+\n+The `SCHEMA_VERSION` table will also keep track of every migration change (including future work for undo changes), but with the difference that being a table the tool will see quickly if a schema\n+version has been migrated or undone. It will also give us a quick view of the `CURRENT` state of the schema. The major advantage is that the tool will use pull queries in this materialized\n+view to get the `CURRENT` state of the cluster.\n+\n+There is another reserved key `LATEST` that will point to the latest change applied. This will be used by the tool to stream all changes up to the row that `LATEST` points, and stop.\n+The `ksql-migrations info` command will use this to display information about the migrations that have been applied or undone. I cannot stream the `MIGRATION_EVENTS` or `SCHEMA_VERSION` directly because\n+the tool does not know when to stop.\n+\n+*Note:*\n+The below schema is designed so we support undo operations in the future. When an undo happens, the `CURRENT` key will point to the previous version found.\n+\n+This is the `CREATE` statement for the `SCHEMA_VERSION` table:\n+```sql\n+CREATE TABLE schema_version\n+  WITH (\n+    KAFKA_TOPIC='default_ksql_schema_version',\n+    VALUE_FORMAT='JSON',\n+    PARTITIONS=1\n+  )\n+  AS SELECT \n+    version_key, \n+    latest_by_offset(version) as version, \n+    latest_by_offset(name) AS name, \n+    latest_by_offset(state) AS state,     \n+    latest_by_offset(checksum) AS checksum, \n+    latest_by_offset(started_on) AS started_on, \n+    latest_by_offset(completed_on) AS completed_on, \n+    latest_by_offset(previous) AS previous\n+  FROM migration_events \n+  GROUP BY version_key;\n+```\n+\n+The following are the outputs that we'll see on each stream and table, and how the tool will figure out the current schema version using pull queries.\n+\n+The `MIGRATION_EVENTS` stream output:\n+```shell script\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Migrated | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| 2           | 2       | Add users     | Undone   | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The `SCHEMA_VERSION` table output:\n+```shell script\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Undone   | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The tool will later use pull queries to identify the current state of the system:\n+```sql\n+SELECT version, state, previous FROM SCHEMA_VERSION WHERE version_key = 'CURRENT'; \n+```\n+\n+\n+### Naming convention\n+\n+Hope you have noticed the naming rules I followed in the previous examples for naming the migration files. Having a naming convention for files is necessary\n+for the tool to detect what migration to apply or revert. Naming files are easier than creating configurations or command parameters to specify the same info.\n+\n+The migration files follow the same `Flyway` naming convention.\n+`(Prefix)(Version)__(Description).sql`\n+\n+The `Prefix` specifies whether the file is a new migration (`V`) file. The prefix is used so that we can add other operations in the future, such as undo operations.\n+The `Version` is the version number used for the schema. Versions will not support decimal versions. Integers with 6 digits are used.\n+The `Description` is a name or description of the new migration. Description uses underscores (automatically replaced by spaces at runtime) or spaces separated the words.\n+\n+i.e.\n+```\n+- V000001__Initial_setup.sql    # a new version to migrate (v1) with name 'Initial setup'\n+- V000002__Add_users.sql        # a new version to migrate (v2) with name 'Add users'\n+```\n+\n+It is recommended the user creates these two files on any new migration. The tool will not enforce that. We need specify this recommendation in the ksqlDB documents.\n+\n+### Dry-runs\n+\n+A dry-run for ksqlDB migrations will only verify what migrations will be applied in the cluster. It will not attempt to execute or simulate any migration statement found in the files. This\n+feature will allow users to test that migration files have the right version and description names as well as know what migrations will be applied in a determined cluster.\n+\n+### Directory structure\n+\n+The migrations tool will use following directory structure:\n+\n+<migrations-project-dir>\n+|\n+|- ksql-migrations.properties\n+|- migrations/\n+\n+When the migrations tool is executed, it will look at the `migrations` directory (by default) for SQL migration files to execute. This directory can be modified in the  \n+configuration file or command line parameters.\n+\n+If the `ksql-migrations.properties` exist in the root directory, then it will use the configuration provided by the file.\n+\n+### Command Syntax\n+\n+Finally, let's look at the rest of the command parameters that will exist to facilitate schema migrations.\n+\n+```shell script\n+Usage:\n+  ksql-migrations [options] commands\n+  \n+Commands\n+  new  <project-path>  Creates a new migrations project, directory structure and config file.\n+\n+  initialize   Initializes the schema version table", "originalCommit": "7bc5875896c0206574e096c0ead808b5a87caa89", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTE4MTI4MQ==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r545181281", "bodyText": "Yes. Although, you know. I think this is duplicated. The intention of initialize is to create an empty stream and table schema. And the intention of baseline is to create the stream and table schema too but with a version specified in the baseline parameter. Both are similar.\nI will remove the baseline and add the parameters to initialize to initialize to a specified version if desired.", "author": "spena", "createdAt": "2020-12-17T15:32:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU0ODUxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU1NzA1NQ==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r544557055", "bodyText": "do you have a description of how these integrations would look like? is that in-scope here or is that something that each developer would integrate on their own?", "author": "agavra", "createdAt": "2020-12-16T19:16:12Z", "path": "design-proposals/klip-42-schema-migrations-tool.md", "diffHunk": "@@ -0,0 +1,442 @@\n+# KLIP 42 - Schema Migrations Tool\n+\n+**Author**: Sergio Pe\u00f1a (@spena) |\n+**Release Target**: 0.16 |\n+**Status**: _Design Approved_ |\n+**Discussion**: https://github.com/confluentinc/ksql/pull/6721\n+\n+**tl;dr:** _New tool to provide ksqlDB users for easy and automated schema migrations for their\n+           ksqlDB environments. This allows users to version control their ksqlDB schema; recreate\n+           their schema from scratch; and migrate their current schema to newer versions._\n+\n+## Motivation and background\n+\n+Schema migrations (also database migrations) refers to the process of performing updates or rollbacks on a database schema to a\n+newer or older schema version. This practice is pretty common in any application lifecycle. Users use a version control for their\n+applications which allow them to know if an application requires an upgrade or rolling back a buggy change. The same is necessary\n+with a database schema. Users look for ways to version control schema changes along the application lifecycle.\n+\n+Existing tools exist to perform schema migrations on any database (MySQL, Postgres, Oracle, etc). These tools allow users to\n+version the database schema, then automate the process to easily upgrade the schema to a newer version. If a schema is buggy,\n+then users can rollback to the previous schema version. One more reason for using these tools is the integration with any\n+CI/CD system, which allows users to test and verify a schema upgrade will work as expected.\n+\n+You can learn more about these existing tools:\n+- [Flyway](https://flywaydb.org/)\n+- [Liquibase](https://www.liquibase.org/)\n+- [DBGeni](http://dbgeni.appsintheopen.com/index.html)\n+\n+ksqlDB requires the same kind of integration with CI/CD systems and automation to deploy ksqlDB schema changes in any environment.\n+Some tools, like `Flyway`, support plugins to integrate schema migrations with a different non-supported database. However, our\n+syntax is exclusively to ksqlDB; tools require JDBC support; and tools have several features that we cannot support\n+(i.e. transactions & databases); so this integration becomes complex or unsupported. For that reason, ksqlDB must have its own\n+schema migrations tool to provide the same migrations benefits to users who want to easily deploy and automate ksqlDB schema\n+changes in all their ksqlDB environments.\n+\n+These benefits include:\n+- Version the ksqlDB schema environments\n+- Integrate ksqlDB schema changes with CI/CD environments\n+- Simplify schema evolution changes across different environments\n+\n+This KLIP proposes a new tool for schema migrations. You will learn about the design aspects of the tool, and the features\n+to support for a basic schema migration process.\n+\n+## In scope\n+\n+* Discuss design details for a new tool that provides schema migrations support for ksqlDB\n+\n+    Basic features to support:\n+    - New CLI and API that can easily integrate with CI/CD environments\n+    - Apply migrations on any ksqlDB environments\n+    - Dry-run operations to verify what migrations will be applied without altering the cluster\n+    - Version control ksqlDB schema\n+\n+\n+## Out of scope\n+\n+* Some features found in existing migrations tools won't be supported\n+\n+  - `Execute entire migrations in a single transaction`\n+\n+    ksqlDB has support for a transactional metastore. However, this is limited to DDL statements that are persisted in the\n+    Command topic. But DML statements, such as INSERT, write directly to the topic and do not work with transactions. This disallows\n+    our tool to provide of a transaction support for the whole migration process. Also, DDL statements may create or delete topics,\n+    which falls in the non-transactional process.\n+\n+  - `Support for simulated executions`\n+\n+    A simulation requires the tool to know the current state of the ksqlDB schema before attempting to verify the new migrations scripts. This\n+    requires a ksqlDB metastore exporting tool to work. Also, to make this simulation 100% safe, the tool requires a dummy Kafka and SR\n+    environment that can validate issues with topics and SR subjects names, as well as security restrictions.\n+\n+  - `Other features, such as repeatable migrations and callbacks`\n+\n+    Not required for a basic migration.\n+\n+* Do performance analysis on migrations\n+\n+  In other DBs, there are operations that take too much time to complete. Such is the case of ALTER statements, which can add/remove columns\n+  that would take time to complete on large tables. ksqlDB operations are quick unless an issue with the ksqlDB environment affects\n+  these executions.\n+\n+* Squash several migration files into one\n+\n+  This is a very important functionality users may want to use. Over time, users may have several small migration files that can be squashed\n+  into one single file. However, this functionality gets out of scope for the migrations tool. It is easier to write a ksqlDB metastore tool\n+  that exports the cluster metadata to a SQL file, then use this SQL file as a replacement for the user migrations scripts.\n+\n+## Future work\n+\n+* `Undo migrated schemas to previous versions`\n+\n+  ksqlDB has a few statements that support undo, and some of them are limited. The first version for migrations will not support this feature.\n+  Detailed information about undo is explained in the document for future reference. Also, the schema metadata (See Schema metadata) needs to\n+  be prepared with future undo operations.\n+\n+## Value/Return\n+\n+Users will be able to integrate ksqlDB upgrades testing with any CI/CD environments of their choice. This is a huge benefit for users who want\n+to automate ksqlDB upgrades with their application lifecycle.\n+\n+Also, a new tool will let users to easily automate schema evolution and migrations changes. They will be able to deploy new schema changes in\n+all their environments (Prod, QA, Devel, etc).\n+\n+## Public APIS\n+\n+- No changes on current public APIs\n+- A new Java API for Java developers\n+\n+  This seems important. However, it is in consideration if supporting a Java API is necessary.\n+\n+## Design\n+\n+I'm going to adopt `Flyway` and `DBGeni` tool syntax and behavior to design the ksqlDB migrations tool. Users will define a new migration in an SQL\n+script. This new SQL script describes the changes to do to migrate the cluster from state A to state B. Then run the migration from the\n+command line to apply the new state in the ksqlDB cluster. Users can also run this migration automatically as part of the build process and/or\n+testing in a CI/CD environment.\n+\n+For instance, the following example creates a new file that setups the initial state of the cluster.\n+\n+`V000001__Initial_setup.sql`\n+```sql\n+CREATE STREAM pageviews (\n+    user_id INTEGER KEY, \n+    url STRING, \n+    status INTEGER\n+) WITH (\n+    KAFKA_TOPIC='pageviews', \n+    VALUE_FORMAT='JSON'    \n+);\n+\n+CREATE TABLE pageviews_metrics AS\n+ SELECT url, COUNT(*) AS num_views\n+  FROM pageviews\n+  GROUP BY url\n+  EMIT CHANGES;\n+```\n+\n+The user runs the migration tool on a specific ksqlDB cluster. The tool updates the cluster by running the SQL statements from the above file.\n+Then sets the state of the cluster to version 1.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: << Empty Schema >>\n+Migrating schema to version 1 - Initial setup\n+```\n+\n+Later, the user needs new changes on the cluster. All previous migrations files are immutable. So, any changes on the cluster require a new migration\n+file (or SQL script). Let's create one to create the users table.\n+\n+`V000002__Add_users.sql`\n+```sql\n+CREATE TABLE users (\n+   ID BIGINT PRIMARY KEY, \n+   STRING NAME, \n+   ADDRESS ADDRESS_TYPE\n+ ) WITH (\n+   KAFKA_TOPIC='users', \n+   VALUE_FORMAT='JSON' \n+ );\n+```\n+\n+The user runs the migration tool on the same ksqlDB cluster. The tool detects the cluster has already version 1, so it executes only the newer version 2 migration\n+file. It then sets the state of the cluster to version 2.\n+\n+```shell script\n+$ ksql-migrations apply\n+Current version of schema: 1\n+Migrating schema to version 2 - Add users\n+```\n+\n+All migration files will support only integer versions (no decimal versions). Integer versions are easier to sort when are found in the file name. Also, there are\n+too few cases that require decimal versioning (i.e. `1.1`) in schema changes. We don't expect users to use decimal versions on ksqlDB migrations.\n+\n+The benefit of this tool is that it detects the required updates to execute in the ksqlDB cluster. So, users don't need to know which SQL statements need to perform\n+to update the cluster. It also makes it easy to work with multiple clusters. Say that you have devel, stag and prod clusters. The tool will manage and track the version\n+of these clusters and apply the right SQL operations.\n+\n+To be able to do that, the tool will use a metadata stream and table that contains the current schema version and all executed updates.\n+\n+### Schema metadata\n+\n+Each ksqlDB cluster requires metadata objects where to track the current schema state. This is not only useful for the tool to know the migrations files to apply, but also for\n+users who can quickly verify if the cluster requires changes to fix a schema bug or add a major/minor improvement for their applications.\n+\n+The tool creates two metadata objects, a stream and table. automatically during the first migration; or when the user runs the tool with a parameter to initialize it.\n+\n+i.e.\n+```\n+$ ksql-migrations initialize\n+Schema metadata initialized successfully\n+```\n+\n+Due to some query limitations (lack of ORDER BY clause and pull queries working only on materialized views) in ksqlDB, the metadata will be stored in two places;  \n+One stream (MIGRATION_EVENTS) and one table (SCHEMA_VERSION).\n+\n+The stream and table require topics unique for the cluster. In this case, these topics names will use the same convention as the processing log. It's not going\n+to be an internal topic because it will be a user topic. The topic name is: `{clusterID}ksql_{StreamOrTableName}`.\n+\n+The user can specify a different name for the SCHEMA_VERSION table. This can be done through the tool configuration file. See `Configurations` for more details.\n+\n+The `MIGRATION_EVENTS` stream will keep track of every migration change (including undo changes). This will contain the history of changes the user has done. Also, this stream\n+will contain a key to the current version of the schema (specified as `CURRENT` version). Every time a new migration or undo happens, the tool will insert a new event with the\n+`CURRENT` key pointing to the current version.\n+\n+This is the `CREATE` statement for the `MIGRATION_EVENTS` stream:\n+```sql\n+CREATE STREAM migration_events (\n+  version_key  STRING KEY,\n+  version      STRING,\n+  name         STRING,\n+  state        STRING,  \n+  checksum     STRING,\n+  started_on   STRING,\n+  completed_on STRING,\n+  previous     STRING\n+) WITH (  \n+  KAFKA_TOPIC='default_ksql_migration_events',\n+  VALUE_FORMAT='JSON',\n+  PARTITIONS=1,\n+  REPLICAS=1\n+);\n+```\n+\n+The `version_key` column has the version of the migration applied or undone. Special values of the `version_key`, `CURRENT` and `LATEST` will be reserved for internal purposes.\n+The `version` column has the version of the migration applied.\n+The `name` column has the name of the migration.\n+The `state` column has the state of the migration process. It can be any of `Pending`, `Running`, `Migrated`, `Error`, `Undone`.\n+The `checksum` column has the MD5 checksum of the migration file. It is used to validate the schema migrations with the local files.\n+The `started_on` column has the date and time when the migration started.\n+The `completed_on` column has the date and time when the migration finished.\n+The `previous` column has the previous version applied.\n+\n+The `SCHEMA_VERSION` table will also keep track of every migration change (including future work for undo changes), but with the difference that being a table the tool will see quickly if a schema\n+version has been migrated or undone. It will also give us a quick view of the `CURRENT` state of the schema. The major advantage is that the tool will use pull queries in this materialized\n+view to get the `CURRENT` state of the cluster.\n+\n+There is another reserved key `LATEST` that will point to the latest change applied. This will be used by the tool to stream all changes up to the row that `LATEST` points, and stop.\n+The `ksql-migrations info` command will use this to display information about the migrations that have been applied or undone. I cannot stream the `MIGRATION_EVENTS` or `SCHEMA_VERSION` directly because\n+the tool does not know when to stop.\n+\n+*Note:*\n+The below schema is designed so we support undo operations in the future. When an undo happens, the `CURRENT` key will point to the previous version found.\n+\n+This is the `CREATE` statement for the `SCHEMA_VERSION` table:\n+```sql\n+CREATE TABLE schema_version\n+  WITH (\n+    KAFKA_TOPIC='default_ksql_schema_version',\n+    VALUE_FORMAT='JSON',\n+    PARTITIONS=1\n+  )\n+  AS SELECT \n+    version_key, \n+    latest_by_offset(version) as version, \n+    latest_by_offset(name) AS name, \n+    latest_by_offset(state) AS state,     \n+    latest_by_offset(checksum) AS checksum, \n+    latest_by_offset(started_on) AS started_on, \n+    latest_by_offset(completed_on) AS completed_on, \n+    latest_by_offset(previous) AS previous\n+  FROM migration_events \n+  GROUP BY version_key;\n+```\n+\n+The following are the outputs that we'll see on each stream and table, and how the tool will figure out the current schema version using pull queries.\n+\n+The `MIGRATION_EVENTS` stream output:\n+```shell script\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Migrated | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| 2           | 2       | Add users     | Undone   | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The `SCHEMA_VERSION` table output:\n+```shell script\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+| version_key | version | name          | state    | checksum   | started_on          | completed_on        | previous |\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+| 1           | 1       | Initial setup | Migrated | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| 2           | 2       | Add users     | Undone   | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n+| CURRENT     | 1       | Initial setup | Migrated | <MD5-sum>  | 12-01-2020 03:48:00 | 12-01-2020 03:48:05 | null     |\n+| LATEST      | 2       | Add users     | Undone   | <MD5-sum>  | 12-03-2020 10:34:30 | 12-03-2020 10:34:34 | 1        |\n++-------------+---------+---------------+----------+------------+---------------------+---------------------+----------+\n+```\n+\n+The tool will later use pull queries to identify the current state of the system:\n+```sql\n+SELECT version, state, previous FROM SCHEMA_VERSION WHERE version_key = 'CURRENT'; \n+```\n+\n+\n+### Naming convention\n+\n+Hope you have noticed the naming rules I followed in the previous examples for naming the migration files. Having a naming convention for files is necessary\n+for the tool to detect what migration to apply or revert. Naming files are easier than creating configurations or command parameters to specify the same info.\n+\n+The migration files follow the same `Flyway` naming convention.\n+`(Prefix)(Version)__(Description).sql`\n+\n+The `Prefix` specifies whether the file is a new migration (`V`) file. The prefix is used so that we can add other operations in the future, such as undo operations.\n+The `Version` is the version number used for the schema. Versions will not support decimal versions. Integers with 6 digits are used.\n+The `Description` is a name or description of the new migration. Description uses underscores (automatically replaced by spaces at runtime) or spaces separated the words.\n+\n+i.e.\n+```\n+- V000001__Initial_setup.sql    # a new version to migrate (v1) with name 'Initial setup'\n+- V000002__Add_users.sql        # a new version to migrate (v2) with name 'Add users'\n+```\n+\n+It is recommended the user creates these two files on any new migration. The tool will not enforce that. We need specify this recommendation in the ksqlDB documents.\n+\n+### Dry-runs\n+\n+A dry-run for ksqlDB migrations will only verify what migrations will be applied in the cluster. It will not attempt to execute or simulate any migration statement found in the files. This\n+feature will allow users to test that migration files have the right version and description names as well as know what migrations will be applied in a determined cluster.\n+\n+### Directory structure\n+\n+The migrations tool will use following directory structure:\n+\n+<migrations-project-dir>\n+|\n+|- ksql-migrations.properties\n+|- migrations/\n+\n+When the migrations tool is executed, it will look at the `migrations` directory (by default) for SQL migration files to execute. This directory can be modified in the  \n+configuration file or command line parameters.\n+\n+If the `ksql-migrations.properties` exist in the root directory, then it will use the configuration provided by the file.\n+\n+### Command Syntax\n+\n+Finally, let's look at the rest of the command parameters that will exist to facilitate schema migrations.\n+\n+```shell script\n+Usage:\n+  ksql-migrations [options] commands\n+  \n+Commands\n+  new  <project-path>  Creates a new migrations project, directory structure and config file.\n+\n+  initialize   Initializes the schema version table\n+  \n+  create [-v <version>] <desc> \n+  \n+                 Create a pair of migration files with <desc> as description.\n+                 Optional: Use the <version> to specify the version to use.\n+   \n+                 This will created a pair of empty migration files based\n+                 on the next schema version.\n+               \n+                 i.e.                  \n+                   $ ksql-migrations create add_users \n+                   Created V000002__Add_users.sql\n+\n+  apply ( all | next | until <target> )\n+  \n+              Migrates a schema to new available schema versions (default: all)\n+              \n+              If 'all' is specified, then it migrates all newer versions available\n+              If 'next' is specified, then it migrates only the next available version\n+              If 'until <target>' is specified, then it migrates all available versions before <target>\n+  \n+  info        Displays information about the current and available migrations\n+  \n+  baseline    Sets the current schema to the specified version\n+  \n+              This is useful when production environments already have a schema unversioned. This sets\n+              the baseline from where to start applying migrations (i.e. kqsl-migrations baseline 1 'Current State')\n+  \n+  clean       Cleans the schema metadata objects                \n+  \n+  validate    Validate applied migrations against local files\n+  \n+              Compares local files checksum against the current metadata checksums to check for migrations files that have changed.\n+              This tells the user that their schema might be not valid against their local files.\n+  \n+Options\n+  -c, --config-file  Specifies a configuration file\n+  \n+  -d, --define       Define variables for the client session (equivalent to the DEFINE statement).\n+  \n+  --dry-run          Simulates what migrations will be applied in the cluster. Dry-runs do not execute or simulate each migration\n+                     statement. Only displays the schema updates that may take place in the cluster without modifying the cluster.\n+ \n+  -h, --help         Shows this help  \n+    \n+```\n+\n+### Configurations\n+\n+The tool will support a configuration file where all details for the server and tool migrations will be set. The following\n+are the basic configurations that the tool should support.\n+\n+Example of `ksql-migrations.properties`\n+```\n+# Server URL and authentication\n+ksql.server.url='http://localhost:8080'\n+ksql.username='user1'\n+ksql.password='pass1'\n+\n+# Migrations details\n+ksql.migrations.streamName='migration_events'\n+ksql.migrations.tableName='schema_version'\n+ksql.migrations.createSchemas='true'\n+```\n+\n+Note: The command line options and other configurations will also be defined during the implementation.\n+\n+## Test plan\n+\n+- Verify positive and negative forward migrations\n+- Verify integration with Github and Jenkins", "originalCommit": "7bc5875896c0206574e096c0ead808b5a87caa89", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTE4Mzk4Ng==", "url": "https://github.com/confluentinc/ksql/pull/6721#discussion_r545183986", "bodyText": "Naa. I got excited in this plan. There is no integration. This plan is just run the main use case for having a migrations tool. So just a few tests that write a few migrations script, commit on github and automate Jenkins to pull and test. If everything works, then we're going to write a blog about it.", "author": "spena", "createdAt": "2020-12-17T15:35:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU1NzA1NQ=="}], "type": "inlineReview"}]}