{"pr_number": 5236, "pr_title": "docs: add KLIP-26: Java client interfaces", "pr_createdAt": "2020-04-30T08:52:09Z", "pr_url": "https://github.com/confluentinc/ksql/pull/5236", "timeline": [{"oid": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "url": "https://github.com/confluentinc/ksql/commit/aed38d5836550829f7fd459df31b47aaf7e5ad45", "message": "docs: klip-26: Java client interfaces", "committedDate": "2020-04-30T08:51:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzkzNDA5OA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r417934098", "bodyText": "I think this would need to be:\nCompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<Map<String, Object>> insertsPublisher);\n\nAs, for inserting, a row is represented as a map.", "author": "purplefox", "createdAt": "2020-04-30T11:12:55Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated\n+\n+We may want to introduce a limit to the number of rows that may be returned from these `executeQuery()` methods,\n+in order to decrease the likelihood of running out of memory.\n+\n+### Insert values\n+\n+A method to insert one row at a time:\n+```\n+  /**\n+   * Insert a single row into the relevant stream/table.\n+   *\n+   * @param streamName name of stream/table.\n+   * @param row the row to insert.\n+   * @return a future that completes once the request has been processed.\n+   */\n+  CompletableFuture<Void> insertInto(String streamName, Map<String, Object> row);\n+```\n+\n+A method to stream inserts (via the `/inserts-stream` endpoint):\n+```\n+  CompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<List<Object>> insertsPublisher);", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzkzNTIxOA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r417935218", "bodyText": "I wouldn't consider things like CTAS and CSAS as DML. DML in the relational DB world refers to operations which directly manipulate data, such as INSERT, DELETE and UPDATE. DDL refers to creating tables, indexes etc. I'd consider CTAS/CSAS as DDL.", "author": "purplefox", "createdAt": "2020-04-30T11:15:22Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated\n+\n+We may want to introduce a limit to the number of rows that may be returned from these `executeQuery()` methods,\n+in order to decrease the likelihood of running out of memory.\n+\n+### Insert values\n+\n+A method to insert one row at a time:\n+```\n+  /**\n+   * Insert a single row into the relevant stream/table.\n+   *\n+   * @param streamName name of stream/table.\n+   * @param row the row to insert.\n+   * @return a future that completes once the request has been processed.\n+   */\n+  CompletableFuture<Void> insertInto(String streamName, Map<String, Object> row);\n+```\n+\n+A method to stream inserts (via the `/inserts-stream` endpoint):\n+```\n+  CompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<List<Object>> insertsPublisher);\n+}\n+```\n+where `InsertResponse` is as follows:\n+```\n+public interface InsertResponse {\n+\n+  /**\n+   * Whether the row was successfully inserted or not.\n+   */\n+  boolean isSuccessful();\n+\n+  /**\n+   * Unique sequence number for the row in the stream of inserts.\n+   */\n+  int getSequenceNum();\n+\n+  /**\n+   * If unsuccessful, the error message.\n+   */\n+  String getErrorMessage();\n+\n+  /**\n+   * If unsuccessful, the error code.\n+   */\n+  int getErrorCode();\n+\n+}\n+```\n+\n+### DDL/DML operations\n+\n+#### `CREATE <STREAM/TABLE>`, `CREATE <STREAM/TABLE> ... AS SELECT`, `INSERT INTO`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Execute DDL statement: `CREATE STREAM`, `CREATE TABLE`\n+   */\n+  CompletableFuture<DdlResponse> executeDdl(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql, Map<String, Object> properties);", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgyODUyMQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r419828521", "bodyText": "Agree with @purplefox on this. DML is generally understood to mean INSERT, UPDATE, DELETE, TRUNCATE etc. DDL is basically everything else (CREATE, DROP, etc.). I think we should keep with convention on this.", "author": "derekjn", "createdAt": "2020-05-05T02:08:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzkzNTIxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYzNzE3Ng==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420637176", "bodyText": "As mentioned above, I've updated this to just have executeStatement() (as Almog suggested) rather than separate executeDdl() and executeDml() methods to avoid this confusion.", "author": "vcrfxia", "createdAt": "2020-05-06T08:51:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzkzNTIxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzkzNTgwMg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r417935802", "bodyText": "Why do we need command sequence number, command ID, etc? Are they used elsewhere in the API?", "author": "purplefox", "createdAt": "2020-04-30T11:16:36Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated\n+\n+We may want to introduce a limit to the number of rows that may be returned from these `executeQuery()` methods,\n+in order to decrease the likelihood of running out of memory.\n+\n+### Insert values\n+\n+A method to insert one row at a time:\n+```\n+  /**\n+   * Insert a single row into the relevant stream/table.\n+   *\n+   * @param streamName name of stream/table.\n+   * @param row the row to insert.\n+   * @return a future that completes once the request has been processed.\n+   */\n+  CompletableFuture<Void> insertInto(String streamName, Map<String, Object> row);\n+```\n+\n+A method to stream inserts (via the `/inserts-stream` endpoint):\n+```\n+  CompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<List<Object>> insertsPublisher);\n+}\n+```\n+where `InsertResponse` is as follows:\n+```\n+public interface InsertResponse {\n+\n+  /**\n+   * Whether the row was successfully inserted or not.\n+   */\n+  boolean isSuccessful();\n+\n+  /**\n+   * Unique sequence number for the row in the stream of inserts.\n+   */\n+  int getSequenceNum();\n+\n+  /**\n+   * If unsuccessful, the error message.\n+   */\n+  String getErrorMessage();\n+\n+  /**\n+   * If unsuccessful, the error code.\n+   */\n+  int getErrorCode();\n+\n+}\n+```\n+\n+### DDL/DML operations\n+\n+#### `CREATE <STREAM/TABLE>`, `CREATE <STREAM/TABLE> ... AS SELECT`, `INSERT INTO`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Execute DDL statement: `CREATE STREAM`, `CREATE TABLE`\n+   */\n+  CompletableFuture<DdlResponse> executeDdl(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql, Map<String, Object> properties);\n+\n+```\n+with\n+```\n+public interface DdlResponse {\n+\n+  enum Status { QUEUED, PARSING, EXECUTING, RUNNING, TERMINATED, SUCCESS, ERROR }\n+  \n+  Status getStatus();\n+  \n+  String getStatusMessage();\n+  \n+  long getCommandSequenceNumber();", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzk0MDI2NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r417940264", "bodyText": "{ QUEUED, PARSING, EXECUTING, RUNNING, TERMINATED, SUCCESS, ERROR }\n\nWhy does the user care about these states? I think I'd only be interested in whether the command succeeded or not, and that can be signalled with a CompletableFuture, with the exception containing the error if it didn't succeeed.", "author": "purplefox", "createdAt": "2020-04-30T11:25:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzkzNTgwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzk0MTQyNw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r417941427", "bodyText": "As an overall principle I like to think that \"less is more\" when it comes to API design. I.e. don't add stuff unless it's super important - as too much information can be overwhelming to users.", "author": "purplefox", "createdAt": "2020-04-30T11:28:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzkzNTgwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE3MTA5NQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418171095", "bodyText": "Good catch. I think it's worth exposing the command sequence number option for requests (in addition to sql which is required and properties which is optional), as that's the mechanism used by ksqlDB to ensure earlier requests have been executed before later requests.\nCommand ID is used by the /status endpoint, which isn't planned to be supported by the Java client as part of this KLIP. I think it's unlikely users will want to use the /status endpoint on their own (outside of the client) so I'll remove command ID.", "author": "vcrfxia", "createdAt": "2020-04-30T17:26:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzkzNTgwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE3MzQxNA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418173414", "bodyText": "Why does the user care about these states? I think I'd only be interested in whether the command succeeded or not, and that can be signalled with a CompletableFuture, with the exception containing the error if it didn't succeeed.\n\nA status of SUCCESS means the server has executed the statement while a status of QUEUED means the statement has been written to the command topic but the server has yet to execute it (and often means something is wrong). But you're right that these statuses aren't particularly actionable from the user's perspective, so we're probably better off nixing them from the client.", "author": "vcrfxia", "createdAt": "2020-04-30T17:30:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzkzNTgwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzkzNjc4MQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r417936781", "bodyText": "Imho, I'm not a fan of trying to design APIs \"up-front\" in design docs. I'd suggest trying a few things out in actual code and then you'll get a much better picture of what works, and what doesn't.", "author": "purplefox", "createdAt": "2020-04-30T11:18:38Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated\n+\n+We may want to introduce a limit to the number of rows that may be returned from these `executeQuery()` methods,\n+in order to decrease the likelihood of running out of memory.\n+\n+### Insert values\n+\n+A method to insert one row at a time:\n+```\n+  /**\n+   * Insert a single row into the relevant stream/table.\n+   *\n+   * @param streamName name of stream/table.\n+   * @param row the row to insert.\n+   * @return a future that completes once the request has been processed.\n+   */\n+  CompletableFuture<Void> insertInto(String streamName, Map<String, Object> row);\n+```\n+\n+A method to stream inserts (via the `/inserts-stream` endpoint):\n+```\n+  CompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<List<Object>> insertsPublisher);\n+}\n+```\n+where `InsertResponse` is as follows:\n+```\n+public interface InsertResponse {\n+\n+  /**\n+   * Whether the row was successfully inserted or not.\n+   */\n+  boolean isSuccessful();\n+\n+  /**\n+   * Unique sequence number for the row in the stream of inserts.\n+   */\n+  int getSequenceNum();\n+\n+  /**\n+   * If unsuccessful, the error message.\n+   */\n+  String getErrorMessage();\n+\n+  /**\n+   * If unsuccessful, the error code.\n+   */\n+  int getErrorCode();\n+\n+}\n+```\n+\n+### DDL/DML operations\n+\n+#### `CREATE <STREAM/TABLE>`, `CREATE <STREAM/TABLE> ... AS SELECT`, `INSERT INTO`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Execute DDL statement: `CREATE STREAM`, `CREATE TABLE`\n+   */\n+  CompletableFuture<DdlResponse> executeDdl(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql, Map<String, Object> properties);\n+\n+```\n+with\n+```\n+public interface DdlResponse {\n+\n+  enum Status { QUEUED, PARSING, EXECUTING, RUNNING, TERMINATED, SUCCESS, ERROR }\n+  \n+  Status getStatus();\n+  \n+  String getStatusMessage();\n+  \n+  long getCommandSequenceNumber();\n+\n+  String getCommandId();\n+}\n+```\n+and `DmlResponse` is identical.\n+\n+I don't love this proposal since `DDL` and `DML` aren't used throughout our docs but I'm not a huge fan of the alternatives I considered either, such as\n+```\n+  CompletableFuture<CreateSourceResponse> createStream(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createStream(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql, Map<String, Object> properties);\n+```\n+\n+In this version, the implementations of `createStream(...)` and `createTable(...)` would be identical and could be replaced with a single `createSource(...)`\n+but the name of this method feels confusing. As with the previous proposal, `CreateSourceResponse` and `InsertIntoResponse` are identical.\n+\n+Other alternatives include separating `CREATE <STREAM/TABLE>` and `CREATE <STREAM/TABLE> ... AS SELECT` into separate methods, but that feels unnecessarily complex.\n+\n+#### `DROP <STREAM/TABLE>`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Drop stream. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName);\n+\n+  /**\n+   * Drop stream. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName, boolean deleteTopic);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName, boolean deleteTopic);\n+```\n+where `DropSourceResponse` is actually the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse` above.\n+\n+Again, the implementations of `dropStream(...)` and `dropTable(...)` would be the same so we could instead have a single `dropSource(...)`, but the naming might be confusing.\n+\n+If we choose to keep them separate, there's an open question of whether the client should validate that `dropStream(...)` is not used to drop a table, and vice versa.\n+IMO such validation would be introducing complexity without much benefit, though this point of ambiguity makes me prefer a single `dropSource(...)` if we can agree on a method name that's not confusing.\n+\n+Note that users can also execute `DROP <STREAM/TABLE>` requests via `executeDdl(...)` or `executDml(...)` above.", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418115258", "bodyText": "to me, this sounds like it should be two different APIs and not the same class", "author": "agavra", "createdAt": "2020-04-30T15:55:24Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYyNzQ3Nw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420627477", "bodyText": "Can you (@agavra , @mjsax , or @derekjn ) elaborate on this? Is the proposal to switch from having two options:\nstreamQuery(); -- can either subscribe to result or poll\nexecuteQuery(); -- wait and receive results in a single batch\n\nto having three options\nstreamQuery(); -- subscribe to result\nsubmitQueryAndPoll(); -- poll from results, potentially as they arrive\nexecuteQueryAndWait(); -- wait and receive results in a single batch\n\n? (Having trouble with naming here -- am curious to know what others think is intuitive.)\nWhy is this preferable/more intuitive?", "author": "vcrfxia", "createdAt": "2020-05-06T08:34:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDY2NDAyNQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420664025", "bodyText": "Imho, the suggestion here seems more confusing and complex than the original API.\nThere is plenty of precedent for mixing sync and async in the same API - most messaging clients work this way. Also CompletableFuture itself works this way (it has a get method).\nI think if we split this out into different APIs it's going to leave the user scratching their head and lead to a poorer user experience.", "author": "purplefox", "createdAt": "2020-05-06T09:39:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk5NTg5MA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420995890", "bodyText": "I suppose that makes sense, I don't feel that strongly about it given the noted precedent", "author": "agavra", "createdAt": "2020-05-06T18:16:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTE5MTg3NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r421191874", "bodyText": "To me, the usage of the same return object but only allowing to either subscribe or poll from it is weird. It might be subjective, but in the end QueryResult becomes stateful: when returned, the state is \"empty\" (not determined), and when a user calls either subscribe or poll the state is set and cannot be changed any longer. Sound like bad UX to me. I am sure that most users know if they want to poll or subscribe when they submit the query and thus they should just use a corresponding method and get a corresponding result object back.\nThe current streamQuery() method can be used for push and pull queries anyway (making the prefix \"stream\" overloaded/ambiguous btw) and returns a QueryResult while executeQuery() returns List<Row> (also for push and pull queries). So both method do the same thing: they execute a pull or push query.\nThe difference is actually \"weird\" from a user point of view because the former \"streams\" (ie, incrementally transfers the result) to the client while the later first fetches the whole result and afterward returns (what does only work for finite query results anyway). However, this difference seems to be an implementation detail -- the client should make this decision internally. (Also, for infinite query result executeQuery() cannot be used.)\nThe user really only cares if she polls the result or if she subscribes to the result. Thus, the simplest thing seems to be keep executeQuery() and use it to let people poll() and keep streamQuery (or maybe rename to subscribeQuery() to avoid the naming ambiguity?) and let people subscribe. If either of both fetches the full result and afterward returns, or if it gets the result incrementally would become an implementation detail. Also, both method can be used for all query types what make it easier to users. For infinite result, they always need to \"stream\" the result, and for finite result, the client can pick if it's \"streams\" or \"fetches upfront\". This decision could maybe exposed on the result object to give people an idea about potential \"blocking\" behavior for \"fetching upfront\"\nJust my 2ct.", "author": "mjsax", "createdAt": "2020-05-07T01:48:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTMwNTUxNQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r421305515", "bodyText": "Thus, the simplest thing seems to be keep executeQuery() and use it to let people poll()\n\n\nNot sure I follow... ExecuteQuery() returns the results asynchronously as a List, there is no need to poll() anything here.", "author": "purplefox", "createdAt": "2020-05-07T07:47:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTMwNjE1Mw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r421306153", "bodyText": "keep streamQuery (or maybe rename to subscribeQuery() to avoid the naming ambiguity?) and let people subscribe\n\n\nI also don't follow this. Some folks prefer a synchronous access pattern (poll). How would they do this if we only provide an async API?", "author": "purplefox", "createdAt": "2020-05-07T07:48:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTMxMDQyNA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r421310424", "bodyText": "I think @mjsax is proposing we switch from\nstreamQuery(); -- can either (1) subscribe to result or (2) poll\nexecuteQuery(); -- wait and receive results in a single batch\n\n(as proposed in the KLIP) to\nsubscribeQuery(); -- subscribe to result stream\nexecuteQuery(); -- can either (1) poll (receive result messages one at a time) or (2) wait and receive all result messages in a single batch \n\nIn other words, the existing proposal splits the methods for receiving query results based on streaming vs. batch, whereas Matthias's proposal splits the methods based on async vs. sync.", "author": "vcrfxia", "createdAt": "2020-05-07T07:55:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk0Njg0OQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r421946849", "bodyText": "What @vcrfxia says.", "author": "mjsax", "createdAt": "2020-05-08T05:30:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAyMTM5OA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r422021398", "bodyText": "Maybe I've misunderstood the suggestion, but it makes no sense to me:\n\nIf subscribeQuery() doesn't allow you to poll the results, how will a user who doesn't like using the async API stream the results of a query from one place to another? They will be forced to get all the results in memory in a single List with executeQuery first.\nexecuteQuery() waits for all results to arrive and returns them in a List. There is no need to poll or subscribe anything, as you already have the results.", "author": "purplefox", "createdAt": "2020-05-08T08:39:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI0MTgyNw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r422241827", "bodyText": "When you say \"how will a user who doesn't like using the async API stream the results\" what do you exactly mean by \"stream the result\"? Are you talking about the internal transport mechanism how data is send from the server to the client? For this case, my answer is, the user does not make this decision but the client/server make the decision about how data is transferred. The use should not be concerned with an implementation detail like that.\n\nThey will be forced to get all the results in memory in a single List with executeQuery first.\n\nThe proposal is to change the return type of executeQuery to return a QueryResult2 (just a random placeholder to distinguish it from QueryResult streamQuery() or subscribeQuery() returns) on which the user can either call poll() or getAll() and getAll would return the List (if the result if finite and otherwise throw an exception).", "author": "mjsax", "createdAt": "2020-05-08T16:31:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzI4MTEzMA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r423281130", "bodyText": "I think it would help if you illustrated your suggestion with some method signatures as I don't understand the suggestion yet.", "author": "purplefox", "createdAt": "2020-05-11T19:53:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzM3NTc2OQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r423375769", "bodyText": "I did not sketch out the details... Something like this (just made up some \"random\" names):\nCompletableFuture<ResultMetadata> streamQuery(String query, Callback callback);\n\nResultMetadata // return error code and/or other metadata; not used to access the result Rows\n\n// triggered for each Row in the result\ninterface Callback {\n  // triggered async when a new row is available\n  void handle(Row row);\n}\n\nCompletableFuture<QueryResult> executeQuery(String query);\n\ninterface QueryResult extends ResultMetadata {\n  // fetch one Row from the result\n  Row poll(Duration timeout); // blocking\n\n  // fetch all remaining rows (ie, previously returned rows from `poll()` would not be contained\n  // -> if result is infinite, throw exception\n  // after `getAllRemaining()` was called, `poll()` would always return `null`\n  List<Row> getAllRemaining() throws IllegalStateException // blocking; no timeout?\n}\n\nSomething along those lines. The idea is really to separate async subscriptions (via streamQuery) from  sync data polling (via executeQuery). The API does no imply any restriction if a push/pull query is issued, ie, both can be issue via each methods. Especially for push queries either async callbacks or sync polling are expected patterns (getAllRemaining would only work for some corner cases). For pull queries, the async callback are less likely to be used (still allowed), while sync polling (either one by one via poll() or getting all rows via getAllRemaining()) should be the dominant usage pattern.", "author": "mjsax", "createdAt": "2020-05-11T23:25:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzUyMDA1NQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r423520055", "bodyText": "List getAllRemaining()\n\n\nBut, getAllRemaining() can't be blocking. (In the original API it returned CompletableFuture<List>)\nPeople who work in an async way also want to execute pull queries (the typical use case) asynchronously.\nWhether you want to stream query results/retrieve them all in one go and whether you prefer a synchronous/asynchronous API are orthogonal concerns.\nAlso, note that any CompletableFuture result can be returned synchronously (if you prefer a sync approach) by calling get() on it :)", "author": "purplefox", "createdAt": "2020-05-12T07:30:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzg0MjI2Nw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r423842267", "bodyText": "But, getAllRemaining() can't be blocking. (In the original API it returned CompletableFuture)\n\nMaybe we can just return plain QueryResult for executeQuery instead and return CompletableFuture<List> from getAllRemaining()?\n\nWhether you want to stream query results/retrieve them all in one go and whether you prefer a synchronous/asynchronous API are orthogonal concerns.\n\nI agree. And there are are multiple ways to design the API around it (it's basically 4 combinations but I don't think we would want to have 4 methods?) and I think that \"sync/async\" is the less important one while how one \"retrieves\" the result is more important and the API should put subscription vs pull int the focus.\nOr maybe we should have 3 methods (because in the end there are 3 ways how one retrieves the result: via a callback, via polling, via getAll). Using a callback is natively async, and polling is something in between (a single call to poll() is blocking but might timeout to unblock again). Last, getAll() can be async or sync, but is quite different to a callback or polling that are \"one by one\".\nSo maybe we could have:\n// as currently proposed; only usable for finite results\nCompletableFuture<List<Row>> executeQuery(String query);\n\n// split the current `streamQuery()` into two methods:\n\nCompletableFuture<QueryMetadata> subscribeQuery(String query, Consumer callback);\nCompletableFuture<QueryResult> query(String query); // for polling via `QueryResult`\n\n(The names are not great... -- just for illustrative purpose.)", "author": "mjsax", "createdAt": "2020-05-12T15:49:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExNTI1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExOTI5NQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418119295", "bodyText": "what happens if you call any of these methods on a column that isn't of the specified type?", "author": "agavra", "createdAt": "2020-04-30T16:01:27Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE3NDIwNA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418174204", "bodyText": "We should throw a client exception. I haven't thought too much about what that interface should look like. I assume a standard error message + cause should be enough?", "author": "vcrfxia", "createdAt": "2020-04-30T17:31:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExOTI5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE3NDY0NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418174644", "bodyText": "I don't have strong thoughts on what the cause in this case should be. Suggestions welcome.", "author": "vcrfxia", "createdAt": "2020-04-30T17:32:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExOTI5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5NDc3NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418194774", "bodyText": "yeah probably fine, I never like the getX pattern but I don't think there's a better one for this use case :(", "author": "agavra", "createdAt": "2020-04-30T18:06:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExOTI5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIzMzM4Mw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418233383", "bodyText": "Probably the \"right\" exception to be thrown here is a ClassCastException, but most likely they throw that anyway, but probably best to check that with a test.", "author": "purplefox", "createdAt": "2020-04-30T19:16:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExOTI5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NjM4OA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418246388", "bodyText": "I think, exceptions like this make sense (not sure if ClassCastException is the right one?) and should be documented in the KLIP (of course, also later in the JavaDocs).", "author": "mjsax", "createdAt": "2020-04-30T19:42:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODExOTI5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyMjk3Ng==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418122976", "bodyText": "I originally commented this above, but I see that you've thought this through. I tend to disagree here - having strings as column types seems somewhat annoying. Every time I want to programatically get a field I'll need to parse the type and that's not something that's easy (especially for Structs). It will also make it so that each location that is using types will need to re-parse it, instead of having the parsing done once when we construct the type and pass it around alongside the Row object. This will also make it harder for us to adjust our type system because we could accidentally break third-party parsers when maintaining backwards compatibility.\nIn general, exposing \"String\" for data types is always super error prone - I'd urge against it if possible. At a minimum, we should wrap the string in a ColumnType class so that later we can add methods that will do the parsing for the user.", "author": "agavra", "createdAt": "2020-04-30T16:06:59Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIzNTM2MA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418235360", "bodyText": "To be honest I suspect very few users will care about the types of the columns, at least they're not going to introspect them before looking up fields. When writing an app the app developer almost always knows the schema up front, i.e. they know that column 3 of their query result is a boolean. It's quite unusual for an app to have to work against a completely unknown schema.\nHaving said I do agree that string aren't great for column types (probably better to use an enum here), just that most people won't look at them anyway in normal use.", "author": "purplefox", "createdAt": "2020-04-30T19:20:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyMjk3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0ODE1OQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418248159", "bodyText": "I second what @agavra says.", "author": "mjsax", "createdAt": "2020-04-30T19:46:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyMjk3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgyNzI0NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r419827244", "bodyText": "I also agree with @agavra. I feel that one of the benefits of shipping our own client is that we can expose this kind of information in a strongly typed way, which is more conducive to helping users write robust, correct code.", "author": "derekjn", "createdAt": "2020-05-05T02:02:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyMjk3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDAyOTI3NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420029274", "bodyText": "Just to clarify the point I was trying to make:\nI agree that we shouldn't use strings for column types - an enum is better there.\nBut.... @agavra said:\n\nEvery time I want to programatically get a field I'll need to parse the type and that's not something that's easy (especially for Structs).\n\nThis is not true. In vast majority of cases the user won't ever look at the method that returns the type of the columns, as they will already know the schema. So whether they return strings or not is probably only of interest to a very small set of developers who are writing an app against a completely unknown schema.\nDoes that make sense?", "author": "purplefox", "createdAt": "2020-05-05T11:08:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyMjk3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDMwNTc2OA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420305768", "bodyText": "In vast majority of cases the user won't ever look at the method that returns the type of the columns, as they will already know the schema.\n\nThen why have this method at all? It seems that the people who want it won't be able to use it (the ones who want to programmatically access it) and the others won't need it. Without structured types, it seems useful only for debugging/logging.", "author": "agavra", "createdAt": "2020-05-05T18:05:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyMjk3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM2MjQ1Ng==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420362456", "bodyText": "I think the metadata is only useful for some niche reflection/introspection type use cases. An analogy is calling a Java method - you don't need to use the reflection API to call a method most of the time, because you know the method signature when you write the code.\nI'd recommend leaving the method there as it might benefit some cases, and it's easy to implement using enums. Structured types for structs, arrays, maps etc have little value imho, even for the reflection use cases. Saying a struct is a Json object or a field is just a decimal is good enough. Note that JDBC doesn't feel the need to make types more structured than simple ones, nor does Calcite and they do fine.", "author": "purplefox", "createdAt": "2020-05-05T19:44:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyMjk3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYzMjIyOQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420632229", "bodyText": "Introduced a ColumnType interface that currently wraps an enum type. We can add more methods to expose richer type information (e.g., inner types for nested/complex types) later on.", "author": "vcrfxia", "createdAt": "2020-05-06T08:42:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyMjk3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDY2NTk4MQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420665981", "bodyText": "Imho an enum is ok, and a new Interface is a bit overkill. But not a showstopper.", "author": "purplefox", "createdAt": "2020-05-06T09:42:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyMjk3Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTE5NDc1NQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r421194755", "bodyText": "Because changing return types of methods is not easily possible (ie, cannot deprecate the old method, as add a new one with the same name but only different return type), I would opt for the ColumnType interface as it's more future proof.", "author": "mjsax", "createdAt": "2020-05-07T01:58:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyMjk3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyNDk5NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418124994", "bodyText": "+1 to exposing Map not Json* I also prefer exposing interfaces, not classes, so that we have freedom about how we want to implement it underneath the hood. In other systems I've worked on we've done lots of optimizations around the clients in completely backwards compatible ways because we could play around with the return type (e.g. lazily parsing nested fields)", "author": "agavra", "createdAt": "2020-04-30T16:10:04Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI4OTgwMg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418289802", "bodyText": "Returning rich JsonObject and JsonArray has quite a few advantages - you have type safe getters, methods to serialize to string form and you can get still get it as a map if you want with getMap(). I find it a bit odd that you dislike the untyped string column types, but you prefer an unttyped jsonObject represented as a map ;)", "author": "purplefox", "createdAt": "2020-04-30T21:07:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyNDk5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMxODU5OA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418318598", "bodyText": "While I understand the advantages, I am with @agavra that it seems questionable to expose \"third party\" classes as public API.\nIf we (for whatever reason) in the future what to move off Vert.x, all applications using the client would break, if we need to keep some Vert.x dependency to just keep the return types. Overall, this coupling seems no desirable.", "author": "mjsax", "createdAt": "2020-04-30T22:12:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyNDk5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM0NTQ1MA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418345450", "bodyText": "I find it a bit odd that you dislike the untyped string column types, but you prefer an unttyped jsonObject represented as a map ;)\n\nMy top preference would be what you suggested on the PR (having our types that wrap JsonObject) but that seems a little overkill. I'm not totally sure why JsonObject gives me more type safety than just a Map does - but maybe I'm missing something (if I understand correctly, getMap does not return a JsonObject, it returns a map - the value type is consistent).\nAlso the concern both here and with String above was being able to play around with the implementation as well as type safety", "author": "agavra", "createdAt": "2020-04-30T23:29:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyNDk5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODQ2Nzg5Mg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418467892", "bodyText": "I'm not totally sure why JsonObject gives me more type safety than just a Map does\n\n\nBecause it has methods getString(), getInt(), getDecimal etc unlike a map where you have check type and cast.", "author": "purplefox", "createdAt": "2020-05-01T08:54:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyNDk5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODQ2ODM4Mg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418468382", "bodyText": "My top preference would be what you suggested on the PR (having our types that wrap JsonObject) but that seems a little overkill\n\n\nI'm good with that too, the issue isn't about want to expose vert.x specific classes, it's about providing something that has the most value to the user. Imho providing a rich class which supports nested Json types is a big win, and would be useful for struct values, for example.", "author": "purplefox", "createdAt": "2020-05-01T08:56:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyNDk5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgzNTAxNw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r419835017", "bodyText": "I would vote to replicate the classes but not expose vert.x specific ones.", "author": "mjsax", "createdAt": "2020-05-05T02:40:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyNDk5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYzMzcyMw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420633723", "bodyText": "Introduced KsqlObject and KsqlArray to wrap the Vert.x types JsonObject and JsonArray. (Not a fan of the new names but couldn't think of anything better.) Thanks for the input, all!", "author": "vcrfxia", "createdAt": "2020-05-06T08:45:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEyNDk5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMDQzNQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418130435", "bodyText": "maybe i'm missing something, but how do you terminate a push query using the client if you're waiting on it?", "author": "agavra", "createdAt": "2020-04-30T16:18:27Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE3NTI4NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418175284", "bodyText": "The client is async. Say you issue a push query via streamQuery(...). That method will return and you can stream results from the QueryResult at your leisure, then call terminatePushQuery(...) when you're done with it.", "author": "vcrfxia", "createdAt": "2020-04-30T17:33:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMDQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE4OTQ0NQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418189445", "bodyText": "Sorry, I specifically mean in the non-streaming case for push queries (that's the case I don't understand)\n   CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties); \n\nYou don't get back a QueryResult in that case", "author": "agavra", "createdAt": "2020-04-30T17:57:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMDQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIwMDMyMA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418200320", "bodyText": "Returning the CompletableFuture from executeQuery(...) happens before the query is terminated. Maybe you're thinking of when the CompletableFuture completes, which only happens when the query is finished?\nIf the user chooses to block on waiting for the CompletableFuture to complete, then you're right they won't be able to issue terminatePushQuery(...) during that time, but that's their decision then. Rather than blocking, they could check if the CompletableFuture has completed or not and choose to terminate the query after some time if they wish.", "author": "vcrfxia", "createdAt": "2020-04-30T18:16:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMDQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIwODM1Ng==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418208356", "bodyText": "I still don't understand, I'll walk you through how I would use this and then see if I'm missing something:\nCompletableFuture<List<Row>> result = executeQuery(\"SELECT * FROM foo EMIT CHANGES;\");\n\n// wait for 100ms, which is the refresh rate on my app\nThread.sleep(100);\n\nif (!result.isDone()) {\n  // I want to terminate the query before the next line, how do I do that?\n}\n\n// return whatever I was able to fetch in 100ms\nreturn result.get();\nAlso I know this example is stupid, you could wait directly on the future, but that's not the point \ud83d\ude1b", "author": "agavra", "createdAt": "2020-04-30T18:30:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMDQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxMjk1MQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418212951", "bodyText": "Oh, is your question just about how to get the query ID? I mistakenly thought it was about blocking/waiting on the CompletableFuture. We can update the return type from List<Row> to something that also includes the query ID, though that certainly makes the interface more complicated. Hmm...", "author": "vcrfxia", "createdAt": "2020-04-30T18:39:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMDQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxMzQ5MQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418213491", "bodyText": "If you had the query ID you'd just replace the line where the comment is with terminatePushQuery(queryId);", "author": "vcrfxia", "createdAt": "2020-04-30T18:40:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMDQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MjE4NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418252184", "bodyText": "It this really a \"valid\" usage pattern? I would strictly distinguish push and pull query result as both are semantically different and avoid the question all together... Even if a push query may return a finite result, I would never return it as a result set", "author": "mjsax", "createdAt": "2020-04-30T19:53:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMDQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5MDYxNg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418290616", "bodyText": "If you know a push query is going to be limited to 10 rows, then it's perfectly valid to return it as a List of Row. E.g. you might want the next 10 changes that happen to this table. Otherwise you'd have to subscribe to the publisher yourself, and manually collect the rows in a list. It's a time saver.", "author": "purplefox", "createdAt": "2020-04-30T21:09:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMDQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMyMDM0NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418320344", "bodyText": "Otherwise you'd have to subscribe to the publisher yourself, and manually collect the rows in a list. It's a time saver.\n\nWell, seem rather straightforward to do this if needed. I prefer to add syntactic sugar not in the first version of an API, but only after (frequent) user request, and stick to a \"clean\" separation of concern first. It's pretty hard to judge upfront if this pattern is common or not (my gut feeling is, it's not common -- of course, I don't have any data to backup this claim) so it might be better to be conservative.", "author": "mjsax", "createdAt": "2020-04-30T22:17:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMDQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODQ2ODkxNQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418468915", "bodyText": "Well, seem rather straightforward to do this if needed.\n\n\nFor some definition of \"straightforward\" I guess ;)\nYou'd have to create a class (the subscriber). Subscribe to it, manually collect the rows, deal with completable futures, etc. Not really that simple for a first time user.", "author": "purplefox", "createdAt": "2020-05-01T08:57:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMDQzNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgzNzc2NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r419837764", "bodyText": "Fair enough. I just see the \"danger\" that people use poll() on a query that return an infinite result. Or would we not allow this and throw an error upfront (might be easy to detect this case)?", "author": "mjsax", "createdAt": "2020-05-05T02:53:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMDQzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMTM1NQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418131355", "bodyText": "why do we need two different apis for DDL and DML? why not just executeStatement(String sql) - the response object can have different types if we need to disambiguate the responses", "author": "agavra", "createdAt": "2020-04-30T16:19:53Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated\n+\n+We may want to introduce a limit to the number of rows that may be returned from these `executeQuery()` methods,\n+in order to decrease the likelihood of running out of memory.\n+\n+### Insert values\n+\n+A method to insert one row at a time:\n+```\n+  /**\n+   * Insert a single row into the relevant stream/table.\n+   *\n+   * @param streamName name of stream/table.\n+   * @param row the row to insert.\n+   * @return a future that completes once the request has been processed.\n+   */\n+  CompletableFuture<Void> insertInto(String streamName, Map<String, Object> row);\n+```\n+\n+A method to stream inserts (via the `/inserts-stream` endpoint):\n+```\n+  CompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<List<Object>> insertsPublisher);\n+}\n+```\n+where `InsertResponse` is as follows:\n+```\n+public interface InsertResponse {\n+\n+  /**\n+   * Whether the row was successfully inserted or not.\n+   */\n+  boolean isSuccessful();\n+\n+  /**\n+   * Unique sequence number for the row in the stream of inserts.\n+   */\n+  int getSequenceNum();\n+\n+  /**\n+   * If unsuccessful, the error message.\n+   */\n+  String getErrorMessage();\n+\n+  /**\n+   * If unsuccessful, the error code.\n+   */\n+  int getErrorCode();\n+\n+}\n+```\n+\n+### DDL/DML operations\n+\n+#### `CREATE <STREAM/TABLE>`, `CREATE <STREAM/TABLE> ... AS SELECT`, `INSERT INTO`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Execute DDL statement: `CREATE STREAM`, `CREATE TABLE`\n+   */\n+  CompletableFuture<DdlResponse> executeDdl(String sql);", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE3NjQ3MQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418176471", "bodyText": "I'm fine with combining the DDL and DML statements but my concern with executeStatement() is that users might be tempted to issue other kinds of statements (create connector, admin operations, etc) with the method which wouldn't work since those need different return types. I couldn't think of a name to clarify that the method should be used for DDL and DML statements but nothing else.", "author": "vcrfxia", "createdAt": "2020-04-30T17:35:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMTM1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5MDYwOQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418190609", "bodyText": "I think it's fine to document the intended use case and then throw an exception if an unexpected statement comes in, but that's just an opinion", "author": "agavra", "createdAt": "2020-04-30T17:59:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMTM1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5NzQ5OA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418197498", "bodyText": "You think the client should be in the business of trying to parse statements before sending them to the server? Or are you suggesting the client throw an error if the entity it receives back from the server isn't what it was expecting.", "author": "vcrfxia", "createdAt": "2020-04-30T18:11:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMTM1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxNzYxMw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418217613", "bodyText": "I feel like we have the same problem either way, no? You can't stop them from submitting DDLs to the DML method. I'm unsure about whether the client should be in the business of parsing or not - I see arguments both ways.\nThis is the problem with accepting string SQL in the API :/ it would've been nice to have structured objects instead of strings, but I understand that this is something standard (e.g. in JDBC)", "author": "agavra", "createdAt": "2020-04-30T18:48:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMTM1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYzNjM3Mw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420636373", "bodyText": "Updated this to just have executeStatement() (as you suggested) rather than separate executeDdl() and executeDml() methods to avoid this confusion.\nMy instinct says the client shouldn't be in the business of parsing statements if we can avoid it as it seems cumbersome to have to worry about parsing logic in two places, though I'm curious what the arguments in favor of client parsing are.", "author": "vcrfxia", "createdAt": "2020-05-06T08:49:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzMTM1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzNDk1NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418134954", "bodyText": "again, not sure why we can't just group this into executeStatement instead of separating all these methods - seems straightforward to me and even more user friendly if I'm programatically constructing statements", "author": "agavra", "createdAt": "2020-04-30T16:25:39Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated\n+\n+We may want to introduce a limit to the number of rows that may be returned from these `executeQuery()` methods,\n+in order to decrease the likelihood of running out of memory.\n+\n+### Insert values\n+\n+A method to insert one row at a time:\n+```\n+  /**\n+   * Insert a single row into the relevant stream/table.\n+   *\n+   * @param streamName name of stream/table.\n+   * @param row the row to insert.\n+   * @return a future that completes once the request has been processed.\n+   */\n+  CompletableFuture<Void> insertInto(String streamName, Map<String, Object> row);\n+```\n+\n+A method to stream inserts (via the `/inserts-stream` endpoint):\n+```\n+  CompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<List<Object>> insertsPublisher);\n+}\n+```\n+where `InsertResponse` is as follows:\n+```\n+public interface InsertResponse {\n+\n+  /**\n+   * Whether the row was successfully inserted or not.\n+   */\n+  boolean isSuccessful();\n+\n+  /**\n+   * Unique sequence number for the row in the stream of inserts.\n+   */\n+  int getSequenceNum();\n+\n+  /**\n+   * If unsuccessful, the error message.\n+   */\n+  String getErrorMessage();\n+\n+  /**\n+   * If unsuccessful, the error code.\n+   */\n+  int getErrorCode();\n+\n+}\n+```\n+\n+### DDL/DML operations\n+\n+#### `CREATE <STREAM/TABLE>`, `CREATE <STREAM/TABLE> ... AS SELECT`, `INSERT INTO`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Execute DDL statement: `CREATE STREAM`, `CREATE TABLE`\n+   */\n+  CompletableFuture<DdlResponse> executeDdl(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql, Map<String, Object> properties);\n+\n+```\n+with\n+```\n+public interface DdlResponse {\n+\n+  enum Status { QUEUED, PARSING, EXECUTING, RUNNING, TERMINATED, SUCCESS, ERROR }\n+  \n+  Status getStatus();\n+  \n+  String getStatusMessage();\n+  \n+  long getCommandSequenceNumber();\n+\n+  String getCommandId();\n+}\n+```\n+and `DmlResponse` is identical.\n+\n+I don't love this proposal since `DDL` and `DML` aren't used throughout our docs but I'm not a huge fan of the alternatives I considered either, such as\n+```\n+  CompletableFuture<CreateSourceResponse> createStream(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createStream(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql, Map<String, Object> properties);\n+```\n+\n+In this version, the implementations of `createStream(...)` and `createTable(...)` would be identical and could be replaced with a single `createSource(...)`\n+but the name of this method feels confusing. As with the previous proposal, `CreateSourceResponse` and `InsertIntoResponse` are identical.\n+\n+Other alternatives include separating `CREATE <STREAM/TABLE>` and `CREATE <STREAM/TABLE> ... AS SELECT` into separate methods, but that feels unnecessarily complex.\n+\n+#### `DROP <STREAM/TABLE>`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Drop stream. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName);\n+\n+  /**\n+   * Drop stream. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName, boolean deleteTopic);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName, boolean deleteTopic);\n+```\n+where `DropSourceResponse` is actually the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse` above.\n+\n+Again, the implementations of `dropStream(...)` and `dropTable(...)` would be the same so we could instead have a single `dropSource(...)`, but the naming might be confusing.", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE3NjgxNQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418176815", "bodyText": "As above.", "author": "vcrfxia", "createdAt": "2020-04-30T17:35:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzNDk1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzNjM1MA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418136350", "bodyText": "+1 I don't think we need connector management as part of the ksqlDB client interface (at least for v1). This seems like something that the connect product should solve and then if the user wants connector management in java they can pull in a dedicated first-class connect client", "author": "agavra", "createdAt": "2020-04-30T16:27:47Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated\n+\n+We may want to introduce a limit to the number of rows that may be returned from these `executeQuery()` methods,\n+in order to decrease the likelihood of running out of memory.\n+\n+### Insert values\n+\n+A method to insert one row at a time:\n+```\n+  /**\n+   * Insert a single row into the relevant stream/table.\n+   *\n+   * @param streamName name of stream/table.\n+   * @param row the row to insert.\n+   * @return a future that completes once the request has been processed.\n+   */\n+  CompletableFuture<Void> insertInto(String streamName, Map<String, Object> row);\n+```\n+\n+A method to stream inserts (via the `/inserts-stream` endpoint):\n+```\n+  CompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<List<Object>> insertsPublisher);\n+}\n+```\n+where `InsertResponse` is as follows:\n+```\n+public interface InsertResponse {\n+\n+  /**\n+   * Whether the row was successfully inserted or not.\n+   */\n+  boolean isSuccessful();\n+\n+  /**\n+   * Unique sequence number for the row in the stream of inserts.\n+   */\n+  int getSequenceNum();\n+\n+  /**\n+   * If unsuccessful, the error message.\n+   */\n+  String getErrorMessage();\n+\n+  /**\n+   * If unsuccessful, the error code.\n+   */\n+  int getErrorCode();\n+\n+}\n+```\n+\n+### DDL/DML operations\n+\n+#### `CREATE <STREAM/TABLE>`, `CREATE <STREAM/TABLE> ... AS SELECT`, `INSERT INTO`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Execute DDL statement: `CREATE STREAM`, `CREATE TABLE`\n+   */\n+  CompletableFuture<DdlResponse> executeDdl(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql, Map<String, Object> properties);\n+\n+```\n+with\n+```\n+public interface DdlResponse {\n+\n+  enum Status { QUEUED, PARSING, EXECUTING, RUNNING, TERMINATED, SUCCESS, ERROR }\n+  \n+  Status getStatus();\n+  \n+  String getStatusMessage();\n+  \n+  long getCommandSequenceNumber();\n+\n+  String getCommandId();\n+}\n+```\n+and `DmlResponse` is identical.\n+\n+I don't love this proposal since `DDL` and `DML` aren't used throughout our docs but I'm not a huge fan of the alternatives I considered either, such as\n+```\n+  CompletableFuture<CreateSourceResponse> createStream(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createStream(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql, Map<String, Object> properties);\n+```\n+\n+In this version, the implementations of `createStream(...)` and `createTable(...)` would be identical and could be replaced with a single `createSource(...)`\n+but the name of this method feels confusing. As with the previous proposal, `CreateSourceResponse` and `InsertIntoResponse` are identical.\n+\n+Other alternatives include separating `CREATE <STREAM/TABLE>` and `CREATE <STREAM/TABLE> ... AS SELECT` into separate methods, but that feels unnecessarily complex.\n+\n+#### `DROP <STREAM/TABLE>`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Drop stream. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName);\n+\n+  /**\n+   * Drop stream. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName, boolean deleteTopic);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName, boolean deleteTopic);\n+```\n+where `DropSourceResponse` is actually the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse` above.\n+\n+Again, the implementations of `dropStream(...)` and `dropTable(...)` would be the same so we could instead have a single `dropSource(...)`, but the naming might be confusing.\n+\n+If we choose to keep them separate, there's an open question of whether the client should validate that `dropStream(...)` is not used to drop a table, and vice versa.\n+IMO such validation would be introducing complexity without much benefit, though this point of ambiguity makes me prefer a single `dropSource(...)` if we can agree on a method name that's not confusing.\n+\n+Note that users can also execute `DROP <STREAM/TABLE>` requests via `executeDdl(...)` or `executDml(...)` above.\n+\n+#### `TERMINATE <queryId>`\n+\n+```\n+  CompletableFuture<TerminateQueryResponse> terminatePersistentQuery(String queryId);\n+```\n+where `TerminateQueryResponse` is again the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse`/`DropSourceResponse` above.\n+\n+The method name `terminatePersistenQuery(...)` is to distinguish from `terminatePushQuery(...)` below.\n+\n+#### Connectors\n+\n+```\n+  CompletableFuture<ConnectorInfo> createSourceConnector(String name, Map<String, String> properties);\n+\n+  CompletableFuture<ConnectorInfo> createSinkConnector(String name, Map<String, String> properties);\n+\n+  CompletableFuture<Void> dropConnector(String name);\n+```\n+where `ConnectorInfo` is from an Apache Kafka module ([link](https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/entities/ConnectorInfo.java)).\n+\n+Or would we rather not have a dependency on Apache Kafka in the ksqlDB client interfaces?", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE3Nzc0Mg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418177742", "bodyText": "I'll leave this up to @derekjn . My thinking was that if ksqlDB is defined by pull queries + Connect integration, it'd be important for the client to offer both pieces of functionality, though I agree that end state you've described is the more preferable one.", "author": "vcrfxia", "createdAt": "2020-04-30T17:37:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzNjM1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDY2NTMwMw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420665303", "bodyText": "Imho, it would be good to have this functionality at some point. The more that the user can do with the ksqlDB client without having to use other clients, the better.\nHowever, I'm not convinced we need this yet. I'd recommend probably leaving it for now, we can always support it at a later date if we choose to.", "author": "purplefox", "createdAt": "2020-05-06T09:41:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzNjM1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTA4OTg1Mw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r421089853", "bodyText": "I agree that this probably isn't something we need right now. Users can always use the REST API directly here as a workaround. Also agree with @purplefox about keeping this on our radar for the future though.", "author": "derekjn", "createdAt": "2020-05-06T21:02:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzNjM1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTMxNTkxNA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r421315914", "bodyText": "Makes sense. Removed connector management from the scope of this KLIP (but left the proposed interfaces at the bottom in case we want to revisit them later).", "author": "vcrfxia", "createdAt": "2020-05-07T08:05:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzNjM1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzNzA4OQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418137089", "bodyText": "For this case, I think a String makes sense - especially if we ever want to support pluggable schemas (which is what schema registry has moved toward and they standardized on strings as the names for formats)", "author": "agavra", "createdAt": "2020-04-30T16:28:59Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated\n+\n+We may want to introduce a limit to the number of rows that may be returned from these `executeQuery()` methods,\n+in order to decrease the likelihood of running out of memory.\n+\n+### Insert values\n+\n+A method to insert one row at a time:\n+```\n+  /**\n+   * Insert a single row into the relevant stream/table.\n+   *\n+   * @param streamName name of stream/table.\n+   * @param row the row to insert.\n+   * @return a future that completes once the request has been processed.\n+   */\n+  CompletableFuture<Void> insertInto(String streamName, Map<String, Object> row);\n+```\n+\n+A method to stream inserts (via the `/inserts-stream` endpoint):\n+```\n+  CompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<List<Object>> insertsPublisher);\n+}\n+```\n+where `InsertResponse` is as follows:\n+```\n+public interface InsertResponse {\n+\n+  /**\n+   * Whether the row was successfully inserted or not.\n+   */\n+  boolean isSuccessful();\n+\n+  /**\n+   * Unique sequence number for the row in the stream of inserts.\n+   */\n+  int getSequenceNum();\n+\n+  /**\n+   * If unsuccessful, the error message.\n+   */\n+  String getErrorMessage();\n+\n+  /**\n+   * If unsuccessful, the error code.\n+   */\n+  int getErrorCode();\n+\n+}\n+```\n+\n+### DDL/DML operations\n+\n+#### `CREATE <STREAM/TABLE>`, `CREATE <STREAM/TABLE> ... AS SELECT`, `INSERT INTO`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Execute DDL statement: `CREATE STREAM`, `CREATE TABLE`\n+   */\n+  CompletableFuture<DdlResponse> executeDdl(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql, Map<String, Object> properties);\n+\n+```\n+with\n+```\n+public interface DdlResponse {\n+\n+  enum Status { QUEUED, PARSING, EXECUTING, RUNNING, TERMINATED, SUCCESS, ERROR }\n+  \n+  Status getStatus();\n+  \n+  String getStatusMessage();\n+  \n+  long getCommandSequenceNumber();\n+\n+  String getCommandId();\n+}\n+```\n+and `DmlResponse` is identical.\n+\n+I don't love this proposal since `DDL` and `DML` aren't used throughout our docs but I'm not a huge fan of the alternatives I considered either, such as\n+```\n+  CompletableFuture<CreateSourceResponse> createStream(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createStream(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql, Map<String, Object> properties);\n+```\n+\n+In this version, the implementations of `createStream(...)` and `createTable(...)` would be identical and could be replaced with a single `createSource(...)`\n+but the name of this method feels confusing. As with the previous proposal, `CreateSourceResponse` and `InsertIntoResponse` are identical.\n+\n+Other alternatives include separating `CREATE <STREAM/TABLE>` and `CREATE <STREAM/TABLE> ... AS SELECT` into separate methods, but that feels unnecessarily complex.\n+\n+#### `DROP <STREAM/TABLE>`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Drop stream. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName);\n+\n+  /**\n+   * Drop stream. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName, boolean deleteTopic);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName, boolean deleteTopic);\n+```\n+where `DropSourceResponse` is actually the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse` above.\n+\n+Again, the implementations of `dropStream(...)` and `dropTable(...)` would be the same so we could instead have a single `dropSource(...)`, but the naming might be confusing.\n+\n+If we choose to keep them separate, there's an open question of whether the client should validate that `dropStream(...)` is not used to drop a table, and vice versa.\n+IMO such validation would be introducing complexity without much benefit, though this point of ambiguity makes me prefer a single `dropSource(...)` if we can agree on a method name that's not confusing.\n+\n+Note that users can also execute `DROP <STREAM/TABLE>` requests via `executeDdl(...)` or `executDml(...)` above.\n+\n+#### `TERMINATE <queryId>`\n+\n+```\n+  CompletableFuture<TerminateQueryResponse> terminatePersistentQuery(String queryId);\n+```\n+where `TerminateQueryResponse` is again the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse`/`DropSourceResponse` above.\n+\n+The method name `terminatePersistenQuery(...)` is to distinguish from `terminatePushQuery(...)` below.\n+\n+#### Connectors\n+\n+```\n+  CompletableFuture<ConnectorInfo> createSourceConnector(String name, Map<String, String> properties);\n+\n+  CompletableFuture<ConnectorInfo> createSinkConnector(String name, Map<String, String> properties);\n+\n+  CompletableFuture<Void> dropConnector(String name);\n+```\n+where `ConnectorInfo` is from an Apache Kafka module ([link](https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/entities/ConnectorInfo.java)).\n+\n+Or would we rather not have a dependency on Apache Kafka in the ksqlDB client interfaces?\n+\n+### Admin operations\n+\n+#### `SHOW TOPICS`\n+\n+```\n+  CompletableFuture<List<TopicInfo>> listTopics();\n+```\n+with\n+```\n+public interface TopicInfo {\n+\n+  String getName();\n+\n+  int getPartitions();\n+  \n+  List<Integer> getReplicasPerPartition();\n+\n+}\n+```\n+\n+#### `SHOW <STREAMS/TABLES>`\n+\n+```\n+  CompletableFuture<List<StreamInfo>> listStreams();\n+\n+  CompletableFuture<List<TableInfo>> listTables();\n+```\n+with\n+```\n+public interface StreamInfo {\n+\n+  String getName();\n+\n+  String getTopic();\n+\n+  String getFormat();\n+  \n+}\n+```\n+and\n+```\n+public interface TableInfo {\n+\n+  String getName();\n+\n+  String getTopic();\n+\n+  String getFormat();\n+\n+  boolean isWindowed();\n+  \n+}\n+```\n+\n+I'm not sure whether it makes more sense for `StreamInfo#getFormat()` and `TableInfo#getFormat()` to return a string or an enum value.", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzODI1MA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418138250", "bodyText": "optional? seems like the exact intended use case \ud83d\ude02", "author": "agavra", "createdAt": "2020-04-30T16:30:48Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated\n+\n+We may want to introduce a limit to the number of rows that may be returned from these `executeQuery()` methods,\n+in order to decrease the likelihood of running out of memory.\n+\n+### Insert values\n+\n+A method to insert one row at a time:\n+```\n+  /**\n+   * Insert a single row into the relevant stream/table.\n+   *\n+   * @param streamName name of stream/table.\n+   * @param row the row to insert.\n+   * @return a future that completes once the request has been processed.\n+   */\n+  CompletableFuture<Void> insertInto(String streamName, Map<String, Object> row);\n+```\n+\n+A method to stream inserts (via the `/inserts-stream` endpoint):\n+```\n+  CompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<List<Object>> insertsPublisher);\n+}\n+```\n+where `InsertResponse` is as follows:\n+```\n+public interface InsertResponse {\n+\n+  /**\n+   * Whether the row was successfully inserted or not.\n+   */\n+  boolean isSuccessful();\n+\n+  /**\n+   * Unique sequence number for the row in the stream of inserts.\n+   */\n+  int getSequenceNum();\n+\n+  /**\n+   * If unsuccessful, the error message.\n+   */\n+  String getErrorMessage();\n+\n+  /**\n+   * If unsuccessful, the error code.\n+   */\n+  int getErrorCode();\n+\n+}\n+```\n+\n+### DDL/DML operations\n+\n+#### `CREATE <STREAM/TABLE>`, `CREATE <STREAM/TABLE> ... AS SELECT`, `INSERT INTO`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Execute DDL statement: `CREATE STREAM`, `CREATE TABLE`\n+   */\n+  CompletableFuture<DdlResponse> executeDdl(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql, Map<String, Object> properties);\n+\n+```\n+with\n+```\n+public interface DdlResponse {\n+\n+  enum Status { QUEUED, PARSING, EXECUTING, RUNNING, TERMINATED, SUCCESS, ERROR }\n+  \n+  Status getStatus();\n+  \n+  String getStatusMessage();\n+  \n+  long getCommandSequenceNumber();\n+\n+  String getCommandId();\n+}\n+```\n+and `DmlResponse` is identical.\n+\n+I don't love this proposal since `DDL` and `DML` aren't used throughout our docs but I'm not a huge fan of the alternatives I considered either, such as\n+```\n+  CompletableFuture<CreateSourceResponse> createStream(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createStream(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql, Map<String, Object> properties);\n+```\n+\n+In this version, the implementations of `createStream(...)` and `createTable(...)` would be identical and could be replaced with a single `createSource(...)`\n+but the name of this method feels confusing. As with the previous proposal, `CreateSourceResponse` and `InsertIntoResponse` are identical.\n+\n+Other alternatives include separating `CREATE <STREAM/TABLE>` and `CREATE <STREAM/TABLE> ... AS SELECT` into separate methods, but that feels unnecessarily complex.\n+\n+#### `DROP <STREAM/TABLE>`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Drop stream. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName);\n+\n+  /**\n+   * Drop stream. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName, boolean deleteTopic);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName, boolean deleteTopic);\n+```\n+where `DropSourceResponse` is actually the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse` above.\n+\n+Again, the implementations of `dropStream(...)` and `dropTable(...)` would be the same so we could instead have a single `dropSource(...)`, but the naming might be confusing.\n+\n+If we choose to keep them separate, there's an open question of whether the client should validate that `dropStream(...)` is not used to drop a table, and vice versa.\n+IMO such validation would be introducing complexity without much benefit, though this point of ambiguity makes me prefer a single `dropSource(...)` if we can agree on a method name that's not confusing.\n+\n+Note that users can also execute `DROP <STREAM/TABLE>` requests via `executeDdl(...)` or `executDml(...)` above.\n+\n+#### `TERMINATE <queryId>`\n+\n+```\n+  CompletableFuture<TerminateQueryResponse> terminatePersistentQuery(String queryId);\n+```\n+where `TerminateQueryResponse` is again the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse`/`DropSourceResponse` above.\n+\n+The method name `terminatePersistenQuery(...)` is to distinguish from `terminatePushQuery(...)` below.\n+\n+#### Connectors\n+\n+```\n+  CompletableFuture<ConnectorInfo> createSourceConnector(String name, Map<String, String> properties);\n+\n+  CompletableFuture<ConnectorInfo> createSinkConnector(String name, Map<String, String> properties);\n+\n+  CompletableFuture<Void> dropConnector(String name);\n+```\n+where `ConnectorInfo` is from an Apache Kafka module ([link](https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/entities/ConnectorInfo.java)).\n+\n+Or would we rather not have a dependency on Apache Kafka in the ksqlDB client interfaces?\n+\n+### Admin operations\n+\n+#### `SHOW TOPICS`\n+\n+```\n+  CompletableFuture<List<TopicInfo>> listTopics();\n+```\n+with\n+```\n+public interface TopicInfo {\n+\n+  String getName();\n+\n+  int getPartitions();\n+  \n+  List<Integer> getReplicasPerPartition();\n+\n+}\n+```\n+\n+#### `SHOW <STREAMS/TABLES>`\n+\n+```\n+  CompletableFuture<List<StreamInfo>> listStreams();\n+\n+  CompletableFuture<List<TableInfo>> listTables();\n+```\n+with\n+```\n+public interface StreamInfo {\n+\n+  String getName();\n+\n+  String getTopic();\n+\n+  String getFormat();\n+  \n+}\n+```\n+and\n+```\n+public interface TableInfo {\n+\n+  String getName();\n+\n+  String getTopic();\n+\n+  String getFormat();\n+\n+  boolean isWindowed();\n+  \n+}\n+```\n+\n+I'm not sure whether it makes more sense for `StreamInfo#getFormat()` and `TableInfo#getFormat()` to return a string or an enum value.\n+The latter would make it easier for the user to know the possible values, but we'd have to keep the list up to date and would also sacrifice forward compatibility.\n+\n+#### `SHOW QUERIES`\n+\n+```\n+  CompletableFuture<List<QueryInfo>> listQueries();\n+```\n+with\n+```\n+public interface QueryInfo {\n+\n+  boolean isPersistentQuery();\n+\n+  boolean isPushQuery();\n+\n+  /**\n+   * Query ID, used for control operations such as terminating the query\n+   */\n+  String getId();\n+\n+  String getSql();\n+\n+  /**\n+   * Name of sink, for a persistent query. Else, null.", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzODU4NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418138584", "bodyText": "not sure I see how this can be used programatically from a client... can we punt on introducing this method at all?", "author": "agavra", "createdAt": "2020-04-30T16:31:22Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated\n+\n+We may want to introduce a limit to the number of rows that may be returned from these `executeQuery()` methods,\n+in order to decrease the likelihood of running out of memory.\n+\n+### Insert values\n+\n+A method to insert one row at a time:\n+```\n+  /**\n+   * Insert a single row into the relevant stream/table.\n+   *\n+   * @param streamName name of stream/table.\n+   * @param row the row to insert.\n+   * @return a future that completes once the request has been processed.\n+   */\n+  CompletableFuture<Void> insertInto(String streamName, Map<String, Object> row);\n+```\n+\n+A method to stream inserts (via the `/inserts-stream` endpoint):\n+```\n+  CompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<List<Object>> insertsPublisher);\n+}\n+```\n+where `InsertResponse` is as follows:\n+```\n+public interface InsertResponse {\n+\n+  /**\n+   * Whether the row was successfully inserted or not.\n+   */\n+  boolean isSuccessful();\n+\n+  /**\n+   * Unique sequence number for the row in the stream of inserts.\n+   */\n+  int getSequenceNum();\n+\n+  /**\n+   * If unsuccessful, the error message.\n+   */\n+  String getErrorMessage();\n+\n+  /**\n+   * If unsuccessful, the error code.\n+   */\n+  int getErrorCode();\n+\n+}\n+```\n+\n+### DDL/DML operations\n+\n+#### `CREATE <STREAM/TABLE>`, `CREATE <STREAM/TABLE> ... AS SELECT`, `INSERT INTO`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Execute DDL statement: `CREATE STREAM`, `CREATE TABLE`\n+   */\n+  CompletableFuture<DdlResponse> executeDdl(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql, Map<String, Object> properties);\n+\n+```\n+with\n+```\n+public interface DdlResponse {\n+\n+  enum Status { QUEUED, PARSING, EXECUTING, RUNNING, TERMINATED, SUCCESS, ERROR }\n+  \n+  Status getStatus();\n+  \n+  String getStatusMessage();\n+  \n+  long getCommandSequenceNumber();\n+\n+  String getCommandId();\n+}\n+```\n+and `DmlResponse` is identical.\n+\n+I don't love this proposal since `DDL` and `DML` aren't used throughout our docs but I'm not a huge fan of the alternatives I considered either, such as\n+```\n+  CompletableFuture<CreateSourceResponse> createStream(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createStream(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql, Map<String, Object> properties);\n+```\n+\n+In this version, the implementations of `createStream(...)` and `createTable(...)` would be identical and could be replaced with a single `createSource(...)`\n+but the name of this method feels confusing. As with the previous proposal, `CreateSourceResponse` and `InsertIntoResponse` are identical.\n+\n+Other alternatives include separating `CREATE <STREAM/TABLE>` and `CREATE <STREAM/TABLE> ... AS SELECT` into separate methods, but that feels unnecessarily complex.\n+\n+#### `DROP <STREAM/TABLE>`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Drop stream. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName);\n+\n+  /**\n+   * Drop stream. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName, boolean deleteTopic);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName, boolean deleteTopic);\n+```\n+where `DropSourceResponse` is actually the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse` above.\n+\n+Again, the implementations of `dropStream(...)` and `dropTable(...)` would be the same so we could instead have a single `dropSource(...)`, but the naming might be confusing.\n+\n+If we choose to keep them separate, there's an open question of whether the client should validate that `dropStream(...)` is not used to drop a table, and vice versa.\n+IMO such validation would be introducing complexity without much benefit, though this point of ambiguity makes me prefer a single `dropSource(...)` if we can agree on a method name that's not confusing.\n+\n+Note that users can also execute `DROP <STREAM/TABLE>` requests via `executeDdl(...)` or `executDml(...)` above.\n+\n+#### `TERMINATE <queryId>`\n+\n+```\n+  CompletableFuture<TerminateQueryResponse> terminatePersistentQuery(String queryId);\n+```\n+where `TerminateQueryResponse` is again the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse`/`DropSourceResponse` above.\n+\n+The method name `terminatePersistenQuery(...)` is to distinguish from `terminatePushQuery(...)` below.\n+\n+#### Connectors\n+\n+```\n+  CompletableFuture<ConnectorInfo> createSourceConnector(String name, Map<String, String> properties);\n+\n+  CompletableFuture<ConnectorInfo> createSinkConnector(String name, Map<String, String> properties);\n+\n+  CompletableFuture<Void> dropConnector(String name);\n+```\n+where `ConnectorInfo` is from an Apache Kafka module ([link](https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/entities/ConnectorInfo.java)).\n+\n+Or would we rather not have a dependency on Apache Kafka in the ksqlDB client interfaces?\n+\n+### Admin operations\n+\n+#### `SHOW TOPICS`\n+\n+```\n+  CompletableFuture<List<TopicInfo>> listTopics();\n+```\n+with\n+```\n+public interface TopicInfo {\n+\n+  String getName();\n+\n+  int getPartitions();\n+  \n+  List<Integer> getReplicasPerPartition();\n+\n+}\n+```\n+\n+#### `SHOW <STREAMS/TABLES>`\n+\n+```\n+  CompletableFuture<List<StreamInfo>> listStreams();\n+\n+  CompletableFuture<List<TableInfo>> listTables();\n+```\n+with\n+```\n+public interface StreamInfo {\n+\n+  String getName();\n+\n+  String getTopic();\n+\n+  String getFormat();\n+  \n+}\n+```\n+and\n+```\n+public interface TableInfo {\n+\n+  String getName();\n+\n+  String getTopic();\n+\n+  String getFormat();\n+\n+  boolean isWindowed();\n+  \n+}\n+```\n+\n+I'm not sure whether it makes more sense for `StreamInfo#getFormat()` and `TableInfo#getFormat()` to return a string or an enum value.\n+The latter would make it easier for the user to know the possible values, but we'd have to keep the list up to date and would also sacrifice forward compatibility.\n+\n+#### `SHOW QUERIES`\n+\n+```\n+  CompletableFuture<List<QueryInfo>> listQueries();\n+```\n+with\n+```\n+public interface QueryInfo {\n+\n+  boolean isPersistentQuery();\n+\n+  boolean isPushQuery();\n+\n+  /**\n+   * Query ID, used for control operations such as terminating the query\n+   */\n+  String getId();\n+\n+  String getSql();\n+\n+  /**\n+   * Name of sink, for a persistent query. Else, null.\n+   */\n+  String getSink();\n+\n+  /**\n+   * Name of sink topic, for a persistent query. Else, null.\n+   */\n+  String getSinkTopic();\n+  \n+  /**\n+   * Map of query state (\"RUNNING\", \"ERROR\", or \"UNRESPONSIVE\") to the number of ksqlDB servers\n+   * on which this query is in each state.\n+   */\n+  Map<String, Integer> getServerStatusCounts();\n+\n+}\n+```\n+\n+Again, not sure whether it makes more sense to represent query states as strings, or to introduce an Enum and have `getServerStatusCounts()` return an EnumMap instead.", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE3OTM5Mg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418179392", "bodyText": "This is the only client method that exposes query status, so if a user wanted to check the health of their queries (either periodically, or if they suspect something is wrong) this is what they'd use. Are you saying checking query status isn't a typically client use case? (Not necessarily disagreeing, just trying to understand.)", "author": "vcrfxia", "createdAt": "2020-04-30T17:40:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzODU4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5MzA0Nw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418193047", "bodyText": "hmm, I'd be in favor of exposing less and then adding functionality as users request it (in line with Tim's less is more mantra)", "author": "agavra", "createdAt": "2020-04-30T18:03:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzODU4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgyOTY5NQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r419829695", "bodyText": "I also agree with the idea of initially exposing a minimal amount of environment/server metadata. If we expose as much as possible before users have expressed a need for it, we risk having to make breaking changes in the future if the way users eventually need to use it ends up being a bit different than we assumed.", "author": "derekjn", "createdAt": "2020-05-05T02:14:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzODU4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDAyNTgwOQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420025809", "bodyText": "less is more, repeat ad infinitum ;)", "author": "purplefox", "createdAt": "2020-05-05T11:00:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzODU4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYzODMyMw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420638323", "bodyText": "Makes sense, I've removed this.", "author": "vcrfxia", "createdAt": "2020-05-06T08:53:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzODU4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTAzOQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418139039", "bodyText": "again, let's punt on connect support - I think we should let connect build a java client if that's what we want to do. Seems weird to have a client that talks to ksql, which just delegates to a connect cluster", "author": "agavra", "createdAt": "2020-04-30T16:32:03Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated\n+\n+We may want to introduce a limit to the number of rows that may be returned from these `executeQuery()` methods,\n+in order to decrease the likelihood of running out of memory.\n+\n+### Insert values\n+\n+A method to insert one row at a time:\n+```\n+  /**\n+   * Insert a single row into the relevant stream/table.\n+   *\n+   * @param streamName name of stream/table.\n+   * @param row the row to insert.\n+   * @return a future that completes once the request has been processed.\n+   */\n+  CompletableFuture<Void> insertInto(String streamName, Map<String, Object> row);\n+```\n+\n+A method to stream inserts (via the `/inserts-stream` endpoint):\n+```\n+  CompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<List<Object>> insertsPublisher);\n+}\n+```\n+where `InsertResponse` is as follows:\n+```\n+public interface InsertResponse {\n+\n+  /**\n+   * Whether the row was successfully inserted or not.\n+   */\n+  boolean isSuccessful();\n+\n+  /**\n+   * Unique sequence number for the row in the stream of inserts.\n+   */\n+  int getSequenceNum();\n+\n+  /**\n+   * If unsuccessful, the error message.\n+   */\n+  String getErrorMessage();\n+\n+  /**\n+   * If unsuccessful, the error code.\n+   */\n+  int getErrorCode();\n+\n+}\n+```\n+\n+### DDL/DML operations\n+\n+#### `CREATE <STREAM/TABLE>`, `CREATE <STREAM/TABLE> ... AS SELECT`, `INSERT INTO`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Execute DDL statement: `CREATE STREAM`, `CREATE TABLE`\n+   */\n+  CompletableFuture<DdlResponse> executeDdl(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql, Map<String, Object> properties);\n+\n+```\n+with\n+```\n+public interface DdlResponse {\n+\n+  enum Status { QUEUED, PARSING, EXECUTING, RUNNING, TERMINATED, SUCCESS, ERROR }\n+  \n+  Status getStatus();\n+  \n+  String getStatusMessage();\n+  \n+  long getCommandSequenceNumber();\n+\n+  String getCommandId();\n+}\n+```\n+and `DmlResponse` is identical.\n+\n+I don't love this proposal since `DDL` and `DML` aren't used throughout our docs but I'm not a huge fan of the alternatives I considered either, such as\n+```\n+  CompletableFuture<CreateSourceResponse> createStream(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createStream(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql, Map<String, Object> properties);\n+```\n+\n+In this version, the implementations of `createStream(...)` and `createTable(...)` would be identical and could be replaced with a single `createSource(...)`\n+but the name of this method feels confusing. As with the previous proposal, `CreateSourceResponse` and `InsertIntoResponse` are identical.\n+\n+Other alternatives include separating `CREATE <STREAM/TABLE>` and `CREATE <STREAM/TABLE> ... AS SELECT` into separate methods, but that feels unnecessarily complex.\n+\n+#### `DROP <STREAM/TABLE>`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Drop stream. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName);\n+\n+  /**\n+   * Drop stream. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName, boolean deleteTopic);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName, boolean deleteTopic);\n+```\n+where `DropSourceResponse` is actually the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse` above.\n+\n+Again, the implementations of `dropStream(...)` and `dropTable(...)` would be the same so we could instead have a single `dropSource(...)`, but the naming might be confusing.\n+\n+If we choose to keep them separate, there's an open question of whether the client should validate that `dropStream(...)` is not used to drop a table, and vice versa.\n+IMO such validation would be introducing complexity without much benefit, though this point of ambiguity makes me prefer a single `dropSource(...)` if we can agree on a method name that's not confusing.\n+\n+Note that users can also execute `DROP <STREAM/TABLE>` requests via `executeDdl(...)` or `executDml(...)` above.\n+\n+#### `TERMINATE <queryId>`\n+\n+```\n+  CompletableFuture<TerminateQueryResponse> terminatePersistentQuery(String queryId);\n+```\n+where `TerminateQueryResponse` is again the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse`/`DropSourceResponse` above.\n+\n+The method name `terminatePersistenQuery(...)` is to distinguish from `terminatePushQuery(...)` below.\n+\n+#### Connectors\n+\n+```\n+  CompletableFuture<ConnectorInfo> createSourceConnector(String name, Map<String, String> properties);\n+\n+  CompletableFuture<ConnectorInfo> createSinkConnector(String name, Map<String, String> properties);\n+\n+  CompletableFuture<Void> dropConnector(String name);\n+```\n+where `ConnectorInfo` is from an Apache Kafka module ([link](https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/entities/ConnectorInfo.java)).\n+\n+Or would we rather not have a dependency on Apache Kafka in the ksqlDB client interfaces?\n+\n+### Admin operations\n+\n+#### `SHOW TOPICS`\n+\n+```\n+  CompletableFuture<List<TopicInfo>> listTopics();\n+```\n+with\n+```\n+public interface TopicInfo {\n+\n+  String getName();\n+\n+  int getPartitions();\n+  \n+  List<Integer> getReplicasPerPartition();\n+\n+}\n+```\n+\n+#### `SHOW <STREAMS/TABLES>`\n+\n+```\n+  CompletableFuture<List<StreamInfo>> listStreams();\n+\n+  CompletableFuture<List<TableInfo>> listTables();\n+```\n+with\n+```\n+public interface StreamInfo {\n+\n+  String getName();\n+\n+  String getTopic();\n+\n+  String getFormat();\n+  \n+}\n+```\n+and\n+```\n+public interface TableInfo {\n+\n+  String getName();\n+\n+  String getTopic();\n+\n+  String getFormat();\n+\n+  boolean isWindowed();\n+  \n+}\n+```\n+\n+I'm not sure whether it makes more sense for `StreamInfo#getFormat()` and `TableInfo#getFormat()` to return a string or an enum value.\n+The latter would make it easier for the user to know the possible values, but we'd have to keep the list up to date and would also sacrifice forward compatibility.\n+\n+#### `SHOW QUERIES`\n+\n+```\n+  CompletableFuture<List<QueryInfo>> listQueries();\n+```\n+with\n+```\n+public interface QueryInfo {\n+\n+  boolean isPersistentQuery();\n+\n+  boolean isPushQuery();\n+\n+  /**\n+   * Query ID, used for control operations such as terminating the query\n+   */\n+  String getId();\n+\n+  String getSql();\n+\n+  /**\n+   * Name of sink, for a persistent query. Else, null.\n+   */\n+  String getSink();\n+\n+  /**\n+   * Name of sink topic, for a persistent query. Else, null.\n+   */\n+  String getSinkTopic();\n+  \n+  /**\n+   * Map of query state (\"RUNNING\", \"ERROR\", or \"UNRESPONSIVE\") to the number of ksqlDB servers\n+   * on which this query is in each state.\n+   */\n+  Map<String, Integer> getServerStatusCounts();\n+\n+}\n+```\n+\n+Again, not sure whether it makes more sense to represent query states as strings, or to introduce an Enum and have `getServerStatusCounts()` return an EnumMap instead.\n+\n+Does having `getSink()` and `getSinkTopic()` return null in the case of push queries make sense, or would we prefer an empty string or an Optional instead?\n+\n+#### `SHOW CONNECTORS`", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTQzOQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418139439", "bodyText": "how do you get the queryId for a push query? (related to my comment above about how do you terminate push queries)", "author": "agavra", "createdAt": "2020-04-30T16:32:42Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated\n+\n+We may want to introduce a limit to the number of rows that may be returned from these `executeQuery()` methods,\n+in order to decrease the likelihood of running out of memory.\n+\n+### Insert values\n+\n+A method to insert one row at a time:\n+```\n+  /**\n+   * Insert a single row into the relevant stream/table.\n+   *\n+   * @param streamName name of stream/table.\n+   * @param row the row to insert.\n+   * @return a future that completes once the request has been processed.\n+   */\n+  CompletableFuture<Void> insertInto(String streamName, Map<String, Object> row);\n+```\n+\n+A method to stream inserts (via the `/inserts-stream` endpoint):\n+```\n+  CompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<List<Object>> insertsPublisher);\n+}\n+```\n+where `InsertResponse` is as follows:\n+```\n+public interface InsertResponse {\n+\n+  /**\n+   * Whether the row was successfully inserted or not.\n+   */\n+  boolean isSuccessful();\n+\n+  /**\n+   * Unique sequence number for the row in the stream of inserts.\n+   */\n+  int getSequenceNum();\n+\n+  /**\n+   * If unsuccessful, the error message.\n+   */\n+  String getErrorMessage();\n+\n+  /**\n+   * If unsuccessful, the error code.\n+   */\n+  int getErrorCode();\n+\n+}\n+```\n+\n+### DDL/DML operations\n+\n+#### `CREATE <STREAM/TABLE>`, `CREATE <STREAM/TABLE> ... AS SELECT`, `INSERT INTO`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Execute DDL statement: `CREATE STREAM`, `CREATE TABLE`\n+   */\n+  CompletableFuture<DdlResponse> executeDdl(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql, Map<String, Object> properties);\n+\n+```\n+with\n+```\n+public interface DdlResponse {\n+\n+  enum Status { QUEUED, PARSING, EXECUTING, RUNNING, TERMINATED, SUCCESS, ERROR }\n+  \n+  Status getStatus();\n+  \n+  String getStatusMessage();\n+  \n+  long getCommandSequenceNumber();\n+\n+  String getCommandId();\n+}\n+```\n+and `DmlResponse` is identical.\n+\n+I don't love this proposal since `DDL` and `DML` aren't used throughout our docs but I'm not a huge fan of the alternatives I considered either, such as\n+```\n+  CompletableFuture<CreateSourceResponse> createStream(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createStream(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql, Map<String, Object> properties);\n+```\n+\n+In this version, the implementations of `createStream(...)` and `createTable(...)` would be identical and could be replaced with a single `createSource(...)`\n+but the name of this method feels confusing. As with the previous proposal, `CreateSourceResponse` and `InsertIntoResponse` are identical.\n+\n+Other alternatives include separating `CREATE <STREAM/TABLE>` and `CREATE <STREAM/TABLE> ... AS SELECT` into separate methods, but that feels unnecessarily complex.\n+\n+#### `DROP <STREAM/TABLE>`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Drop stream. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName);\n+\n+  /**\n+   * Drop stream. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName, boolean deleteTopic);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName, boolean deleteTopic);\n+```\n+where `DropSourceResponse` is actually the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse` above.\n+\n+Again, the implementations of `dropStream(...)` and `dropTable(...)` would be the same so we could instead have a single `dropSource(...)`, but the naming might be confusing.\n+\n+If we choose to keep them separate, there's an open question of whether the client should validate that `dropStream(...)` is not used to drop a table, and vice versa.\n+IMO such validation would be introducing complexity without much benefit, though this point of ambiguity makes me prefer a single `dropSource(...)` if we can agree on a method name that's not confusing.\n+\n+Note that users can also execute `DROP <STREAM/TABLE>` requests via `executeDdl(...)` or `executDml(...)` above.\n+\n+#### `TERMINATE <queryId>`\n+\n+```\n+  CompletableFuture<TerminateQueryResponse> terminatePersistentQuery(String queryId);\n+```\n+where `TerminateQueryResponse` is again the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse`/`DropSourceResponse` above.\n+\n+The method name `terminatePersistenQuery(...)` is to distinguish from `terminatePushQuery(...)` below.\n+\n+#### Connectors\n+\n+```\n+  CompletableFuture<ConnectorInfo> createSourceConnector(String name, Map<String, String> properties);\n+\n+  CompletableFuture<ConnectorInfo> createSinkConnector(String name, Map<String, String> properties);\n+\n+  CompletableFuture<Void> dropConnector(String name);\n+```\n+where `ConnectorInfo` is from an Apache Kafka module ([link](https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/entities/ConnectorInfo.java)).\n+\n+Or would we rather not have a dependency on Apache Kafka in the ksqlDB client interfaces?\n+\n+### Admin operations\n+\n+#### `SHOW TOPICS`\n+\n+```\n+  CompletableFuture<List<TopicInfo>> listTopics();\n+```\n+with\n+```\n+public interface TopicInfo {\n+\n+  String getName();\n+\n+  int getPartitions();\n+  \n+  List<Integer> getReplicasPerPartition();\n+\n+}\n+```\n+\n+#### `SHOW <STREAMS/TABLES>`\n+\n+```\n+  CompletableFuture<List<StreamInfo>> listStreams();\n+\n+  CompletableFuture<List<TableInfo>> listTables();\n+```\n+with\n+```\n+public interface StreamInfo {\n+\n+  String getName();\n+\n+  String getTopic();\n+\n+  String getFormat();\n+  \n+}\n+```\n+and\n+```\n+public interface TableInfo {\n+\n+  String getName();\n+\n+  String getTopic();\n+\n+  String getFormat();\n+\n+  boolean isWindowed();\n+  \n+}\n+```\n+\n+I'm not sure whether it makes more sense for `StreamInfo#getFormat()` and `TableInfo#getFormat()` to return a string or an enum value.\n+The latter would make it easier for the user to know the possible values, but we'd have to keep the list up to date and would also sacrifice forward compatibility.\n+\n+#### `SHOW QUERIES`\n+\n+```\n+  CompletableFuture<List<QueryInfo>> listQueries();\n+```\n+with\n+```\n+public interface QueryInfo {\n+\n+  boolean isPersistentQuery();\n+\n+  boolean isPushQuery();\n+\n+  /**\n+   * Query ID, used for control operations such as terminating the query\n+   */\n+  String getId();\n+\n+  String getSql();\n+\n+  /**\n+   * Name of sink, for a persistent query. Else, null.\n+   */\n+  String getSink();\n+\n+  /**\n+   * Name of sink topic, for a persistent query. Else, null.\n+   */\n+  String getSinkTopic();\n+  \n+  /**\n+   * Map of query state (\"RUNNING\", \"ERROR\", or \"UNRESPONSIVE\") to the number of ksqlDB servers\n+   * on which this query is in each state.\n+   */\n+  Map<String, Integer> getServerStatusCounts();\n+\n+}\n+```\n+\n+Again, not sure whether it makes more sense to represent query states as strings, or to introduce an Enum and have `getServerStatusCounts()` return an EnumMap instead.\n+\n+Does having `getSink()` and `getSinkTopic()` return null in the case of push queries make sense, or would we prefer an empty string or an Optional instead?\n+\n+#### `SHOW CONNECTORS`\n+\n+```\n+  CompletableFuture<ConnectorList> listConnectors();\n+```\n+with\n+```\n+public interface ConnectorList {\n+  \n+  List<ConnectorInfo> getConnectors();\n+  \n+  /**\n+   * Any warnings returned by the server as a result of listing connectors.\n+   */\n+  List<String> getWarnings();\n+\n+}\n+```\n+and\n+```\n+public interface ConnectorInfo {\n+\n+  enum ConnectorType {\n+    SOURCE,\n+    SINK,\n+    UNKNOWN;\n+  }\n+\n+  String getName();\n+\n+  ConnectorType getType();\n+\n+  String getClassName();\n+\n+  String getState();\n+\n+}\n+```\n+\n+I don't love that the introduction of `ConnectorList` wrapped around `List<ConnectorInfo>` breaks the pattern established by `SHOW TOPICS`/`SHOW <STREAMS/TABLES>`/`SHOW QUERIES` but it seems important to propagate any server warnings to the user so the trade-off is worth it IMO.\n+\n+### Terminate push query\n+\n+```\n+  CompletableFuture<Void> terminatePushQuery(String queryId);", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE3OTc1NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418179754", "bodyText": "It's returned as part of the QueryResult from streamQuery(...)", "author": "vcrfxia", "createdAt": "2020-04-30T17:40:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTQzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1NTQ1MQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418255451", "bodyText": "Why do we need method for that? It seem to be much simpler, to just say (just to sketch the idea):\nQueryHandle handle = client.streamQuery(...):\nhandle.terminate(); // or maybe better `close()` -> QueryHandle could implement AutoClosable\n\nThis way, we don't even need to expose the queryId at all.", "author": "mjsax", "createdAt": "2020-04-30T20:00:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTQzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5MTQyNg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418291426", "bodyText": "The thing that's closing the query might not have access to the QueryHandle. It might be in a different process, on a different machine. Much easier to pass strings around.", "author": "purplefox", "createdAt": "2020-04-30T21:11:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTQzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMyMTA4OQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418321089", "bodyText": "Why would this be the case? If I issue a query, I would not allow anybody else to terminate my query. Can you elaborate on the use case?", "author": "mjsax", "createdAt": "2020-04-30T22:19:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTQzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODQ2OTYzNw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418469637", "bodyText": "I'm sure there are lots of cases. Maybe you have a distributed system where queries are created by one microservice, and you have another one that cleans up old queries, or closes them according to some criteria. These service could be on a completely different machine, or even written in a different language.", "author": "purplefox", "createdAt": "2020-05-01T09:00:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTQzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgzODE5MQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r419838191", "bodyText": "Sound like premature optimization for an unknown use case. I would prefer to keep the API tight, and if a real need arises, we can still expose the query ID later and extend the API accordingly. Thoughts?", "author": "mjsax", "createdAt": "2020-05-05T02:55:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTQzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDAyNTI5OQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420025299", "bodyText": "Disagree that this is an optimisation. It's the simplest way I can think of doing it. Returning an object seems somewhat more work, and limits the usefulness.", "author": "purplefox", "createdAt": "2020-05-05T10:59:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTQzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDMzNjI3Nw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420336277", "bodyText": "I guess this is subjective. I find dealing with \"Strings\" instead of proper object not simpler but clumsy. But I can only share/raise my opinion/preference.", "author": "mjsax", "createdAt": "2020-05-05T18:57:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTQzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTY3NQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418139675", "bodyText": "why is the return of the CompleteableFuture void? seems like we'd want to know if our terminate succeeded", "author": "agavra", "createdAt": "2020-04-30T16:33:05Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated\n+\n+We may want to introduce a limit to the number of rows that may be returned from these `executeQuery()` methods,\n+in order to decrease the likelihood of running out of memory.\n+\n+### Insert values\n+\n+A method to insert one row at a time:\n+```\n+  /**\n+   * Insert a single row into the relevant stream/table.\n+   *\n+   * @param streamName name of stream/table.\n+   * @param row the row to insert.\n+   * @return a future that completes once the request has been processed.\n+   */\n+  CompletableFuture<Void> insertInto(String streamName, Map<String, Object> row);\n+```\n+\n+A method to stream inserts (via the `/inserts-stream` endpoint):\n+```\n+  CompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<List<Object>> insertsPublisher);\n+}\n+```\n+where `InsertResponse` is as follows:\n+```\n+public interface InsertResponse {\n+\n+  /**\n+   * Whether the row was successfully inserted or not.\n+   */\n+  boolean isSuccessful();\n+\n+  /**\n+   * Unique sequence number for the row in the stream of inserts.\n+   */\n+  int getSequenceNum();\n+\n+  /**\n+   * If unsuccessful, the error message.\n+   */\n+  String getErrorMessage();\n+\n+  /**\n+   * If unsuccessful, the error code.\n+   */\n+  int getErrorCode();\n+\n+}\n+```\n+\n+### DDL/DML operations\n+\n+#### `CREATE <STREAM/TABLE>`, `CREATE <STREAM/TABLE> ... AS SELECT`, `INSERT INTO`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Execute DDL statement: `CREATE STREAM`, `CREATE TABLE`\n+   */\n+  CompletableFuture<DdlResponse> executeDdl(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql);\n+\n+  /**\n+   * Execute DML statement: `CREATE STREAM ... AS SELECT`, `CREATE TABLE ... AS SELECT`, `INSERT INTO`\n+   */\n+  CompletableFuture<DmlResponse> executeDml(String sql, Map<String, Object> properties);\n+\n+```\n+with\n+```\n+public interface DdlResponse {\n+\n+  enum Status { QUEUED, PARSING, EXECUTING, RUNNING, TERMINATED, SUCCESS, ERROR }\n+  \n+  Status getStatus();\n+  \n+  String getStatusMessage();\n+  \n+  long getCommandSequenceNumber();\n+\n+  String getCommandId();\n+}\n+```\n+and `DmlResponse` is identical.\n+\n+I don't love this proposal since `DDL` and `DML` aren't used throughout our docs but I'm not a huge fan of the alternatives I considered either, such as\n+```\n+  CompletableFuture<CreateSourceResponse> createStream(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createStream(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql);\n+\n+  CompletableFuture<CreateSourceResponse> createTable(String sql, Map<String, Object> properties);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql);\n+\n+  CompletableFuture<InsertIntoResponse> insertIntoSource(String sql, Map<String, Object> properties);\n+```\n+\n+In this version, the implementations of `createStream(...)` and `createTable(...)` would be identical and could be replaced with a single `createSource(...)`\n+but the name of this method feels confusing. As with the previous proposal, `CreateSourceResponse` and `InsertIntoResponse` are identical.\n+\n+Other alternatives include separating `CREATE <STREAM/TABLE>` and `CREATE <STREAM/TABLE> ... AS SELECT` into separate methods, but that feels unnecessarily complex.\n+\n+#### `DROP <STREAM/TABLE>`\n+\n+`Client` methods:\n+```\n+  /**\n+   * Drop stream. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName);\n+\n+  /**\n+   * Drop stream. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropStream(String streamName, boolean deleteTopic);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic will not be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName);\n+\n+  /**\n+   * Drop table. The underlying Kafka topic may optionally be deleted.\n+   */\n+  CompletableFuture<DropSourceResponse> dropTable(String tableName, boolean deleteTopic);\n+```\n+where `DropSourceResponse` is actually the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse` above.\n+\n+Again, the implementations of `dropStream(...)` and `dropTable(...)` would be the same so we could instead have a single `dropSource(...)`, but the naming might be confusing.\n+\n+If we choose to keep them separate, there's an open question of whether the client should validate that `dropStream(...)` is not used to drop a table, and vice versa.\n+IMO such validation would be introducing complexity without much benefit, though this point of ambiguity makes me prefer a single `dropSource(...)` if we can agree on a method name that's not confusing.\n+\n+Note that users can also execute `DROP <STREAM/TABLE>` requests via `executeDdl(...)` or `executDml(...)` above.\n+\n+#### `TERMINATE <queryId>`\n+\n+```\n+  CompletableFuture<TerminateQueryResponse> terminatePersistentQuery(String queryId);\n+```\n+where `TerminateQueryResponse` is again the same as `DdlResponse`/`DmlResponse`/`CreateSourceResponse`/`InsertIntoResponse`/`DropSourceResponse` above.\n+\n+The method name `terminatePersistenQuery(...)` is to distinguish from `terminatePushQuery(...)` below.\n+\n+#### Connectors\n+\n+```\n+  CompletableFuture<ConnectorInfo> createSourceConnector(String name, Map<String, String> properties);\n+\n+  CompletableFuture<ConnectorInfo> createSinkConnector(String name, Map<String, String> properties);\n+\n+  CompletableFuture<Void> dropConnector(String name);\n+```\n+where `ConnectorInfo` is from an Apache Kafka module ([link](https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/entities/ConnectorInfo.java)).\n+\n+Or would we rather not have a dependency on Apache Kafka in the ksqlDB client interfaces?\n+\n+### Admin operations\n+\n+#### `SHOW TOPICS`\n+\n+```\n+  CompletableFuture<List<TopicInfo>> listTopics();\n+```\n+with\n+```\n+public interface TopicInfo {\n+\n+  String getName();\n+\n+  int getPartitions();\n+  \n+  List<Integer> getReplicasPerPartition();\n+\n+}\n+```\n+\n+#### `SHOW <STREAMS/TABLES>`\n+\n+```\n+  CompletableFuture<List<StreamInfo>> listStreams();\n+\n+  CompletableFuture<List<TableInfo>> listTables();\n+```\n+with\n+```\n+public interface StreamInfo {\n+\n+  String getName();\n+\n+  String getTopic();\n+\n+  String getFormat();\n+  \n+}\n+```\n+and\n+```\n+public interface TableInfo {\n+\n+  String getName();\n+\n+  String getTopic();\n+\n+  String getFormat();\n+\n+  boolean isWindowed();\n+  \n+}\n+```\n+\n+I'm not sure whether it makes more sense for `StreamInfo#getFormat()` and `TableInfo#getFormat()` to return a string or an enum value.\n+The latter would make it easier for the user to know the possible values, but we'd have to keep the list up to date and would also sacrifice forward compatibility.\n+\n+#### `SHOW QUERIES`\n+\n+```\n+  CompletableFuture<List<QueryInfo>> listQueries();\n+```\n+with\n+```\n+public interface QueryInfo {\n+\n+  boolean isPersistentQuery();\n+\n+  boolean isPushQuery();\n+\n+  /**\n+   * Query ID, used for control operations such as terminating the query\n+   */\n+  String getId();\n+\n+  String getSql();\n+\n+  /**\n+   * Name of sink, for a persistent query. Else, null.\n+   */\n+  String getSink();\n+\n+  /**\n+   * Name of sink topic, for a persistent query. Else, null.\n+   */\n+  String getSinkTopic();\n+  \n+  /**\n+   * Map of query state (\"RUNNING\", \"ERROR\", or \"UNRESPONSIVE\") to the number of ksqlDB servers\n+   * on which this query is in each state.\n+   */\n+  Map<String, Integer> getServerStatusCounts();\n+\n+}\n+```\n+\n+Again, not sure whether it makes more sense to represent query states as strings, or to introduce an Enum and have `getServerStatusCounts()` return an EnumMap instead.\n+\n+Does having `getSink()` and `getSinkTopic()` return null in the case of push queries make sense, or would we prefer an empty string or an Optional instead?\n+\n+#### `SHOW CONNECTORS`\n+\n+```\n+  CompletableFuture<ConnectorList> listConnectors();\n+```\n+with\n+```\n+public interface ConnectorList {\n+  \n+  List<ConnectorInfo> getConnectors();\n+  \n+  /**\n+   * Any warnings returned by the server as a result of listing connectors.\n+   */\n+  List<String> getWarnings();\n+\n+}\n+```\n+and\n+```\n+public interface ConnectorInfo {\n+\n+  enum ConnectorType {\n+    SOURCE,\n+    SINK,\n+    UNKNOWN;\n+  }\n+\n+  String getName();\n+\n+  ConnectorType getType();\n+\n+  String getClassName();\n+\n+  String getState();\n+\n+}\n+```\n+\n+I don't love that the introduction of `ConnectorList` wrapped around `List<ConnectorInfo>` breaks the pattern established by `SHOW TOPICS`/`SHOW <STREAMS/TABLES>`/`SHOW QUERIES` but it seems important to propagate any server warnings to the user so the trade-off is worth it IMO.\n+\n+### Terminate push query\n+\n+```\n+  CompletableFuture<Void> terminatePushQuery(String queryId);", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE4MDE0Mg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418180142", "bodyText": "If the CompletableFuture succeeds, the request succeeded. If the CompletableFuture completes exceptionally, the request failed.", "author": "vcrfxia", "createdAt": "2020-04-30T17:41:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTY3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5NDI5MQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418194291", "bodyText": "in my personal preference, it's better to have it return an object that can contain more useful information (e.g. structured error messages) and not rely on exceptions", "author": "agavra", "createdAt": "2020-04-30T18:05:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTY3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5MTkyMA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418291920", "bodyText": "The CompletableFuture way of doing things is to use an exception for failure. If you call .get() on the CF, the exception will be thrown. Of course, if you want extra information you can create your own exception types with all the information that you require.", "author": "purplefox", "createdAt": "2020-04-30T21:12:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTY3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM0NTk0Mg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418345942", "bodyText": "if that's a standard i'm happy to defer to that - i havne't used the new CompletableFuture much tbh", "author": "agavra", "createdAt": "2020-04-30T23:31:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODEzOTY3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxNjUzMw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418216533", "bodyText": "What do you mean by \"streaming the result of a pull query\" ? Only push queries return a data stream?\nHaving said that, would it make sense to have two different methods for both query types, as both should return a different \"object\"?", "author": "mjsax", "createdAt": "2020-04-30T18:46:02Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0Nzc0Ng==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418247746", "bodyText": "\"Streaming the result\" just means receiving records one at a time. Today pull queries only return at most one record so the difference between streaming the result and not isn't meaningful, but this could change in the future.", "author": "vcrfxia", "createdAt": "2020-04-30T19:45:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxNjUzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NjIwNA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418266204", "bodyText": "Iteration through a result set of a pull query, is not streaming IMHO. Otherwise, each time you use an Iterator you would stream data.", "author": "mjsax", "createdAt": "2020-04-30T20:21:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxNjUzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5Mjc0Mw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418292743", "bodyText": "Whether a result is streamed or obtained as a batch is orthogonal as to whether it's a pull or a push query. You could have a pull query that returns millions of rows so it's not feasible to load them all in memory at once - you just want to spool them to disk. You could have a push query where you just want to receive the next 10 changes that happen to a table (push query with limit), so you want to receive the results as a batch.", "author": "purplefox", "createdAt": "2020-04-30T21:13:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxNjUzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMyNDM5MQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418324391", "bodyText": "I did not say anything about the internal implementation. I totally agree that buffering the full result for a large result of a pull query client side would not be a good implementation.\nFrom a user point of view, there is poll() or subscribe() and internally there are two \"transport mechanism we can pick -- and we can implement all 4 (at least 3; not sure if \"batch transfer\" makes sense for subscribe()), and the user should not care.\nI am just wondering if we should offer an API that mixes pull() and subscribe() and allow both for push and pull queries. IMHO, it convolutes the API. I guess it makes sense to allow people to poll() or subscribe() to a stream (ie, push query -- even if using poll() on a push shows that the name \"push query\" is really terrible... anyway). However, subscribing to a pull query does not really make sense to me because there is no data stream (even if the large data set might be transmitted incrementally from the server to the client).", "author": "mjsax", "createdAt": "2020-04-30T22:27:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxNjUzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODQ3MDUwOQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418470509", "bodyText": "I think you're getting hung up / confused about the word \"stream\" here. Whether something is \"streamed\" to a user or not, is nothing to do with the definition of \"stream\" in the ksqlDB mental model. They're different things.", "author": "purplefox", "createdAt": "2020-05-01T09:04:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxNjUzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgzODU2NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r419838564", "bodyText": "Well. Because we have data streams, maybe the wording should be done more carefully to avoid confusion?", "author": "mjsax", "createdAt": "2020-05-05T02:57:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxNjUzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxODQwNA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418218404", "bodyText": "For pull queries, this would block forever if the end of the result is reached? That might be a bad user experience. We could of course throw an exception, but that seems equally bad?\nHow does the JDBC interface handle this case (the also return a finite ResetSet one can iterate through)", "author": "mjsax", "createdAt": "2020-04-30T18:49:30Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5MzA3OA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418293078", "bodyText": "I believe it will return when the subscription is completed.", "author": "purplefox", "createdAt": "2020-04-30T21:14:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxODQwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMyNDY4Ng==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418324686", "bodyText": "What subscription? If you call poll() you don't subscribe?", "author": "mjsax", "createdAt": "2020-04-30T22:28:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxODQwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2MjE5MA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418362190", "bodyText": "If you call poll() there's an internal subscriber. Regardless of implementation, we should make it so that when the publisher is closed, poll() returns (which is the essence of what Tim is saying).", "author": "vcrfxia", "createdAt": "2020-05-01T00:29:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxODQwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgzNTc1OA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r419835758", "bodyText": "So people need to add null check on the result of poll() to cover this case?", "author": "mjsax", "createdAt": "2020-05-05T02:44:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxODQwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDAyNDQ5NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420024494", "bodyText": "They would have to do that anyway. null is always a valid return value of poll.", "author": "purplefox", "createdAt": "2020-05-05T10:58:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxODQwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDMzNDc0NQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420334745", "bodyText": "Can you elaborate? Why that?", "author": "mjsax", "createdAt": "2020-05-05T18:54:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIxODQwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIyMDQyMQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418220421", "bodyText": "What is Publisher exactly (ie, from which library -- or is it from the Java standard library?)", "author": "mjsax", "createdAt": "2020-04-30T18:53:09Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzE2NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418247164", "bodyText": "https://www.reactive-streams.org/reactive-streams-1.0.0-javadoc/org/reactivestreams/Publisher.html", "author": "vcrfxia", "createdAt": "2020-04-30T19:44:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIyMDQyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NDQzMw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418264433", "bodyText": "Thanks, can the KLIP clarify this directly?\nimport org.reactivestreams.Publisher;\n\npublic interface QueryResult extends Publisher<Row> {", "author": "mjsax", "createdAt": "2020-04-30T20:18:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIyMDQyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5MzIxOA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418293218", "bodyText": "As all based on reactive streams as described in KLIP-15", "author": "purplefox", "createdAt": "2020-04-30T21:14:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIyMDQyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMyNTE4MA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418325180", "bodyText": "Well, it's hard to keep everything in mind and it's code if you don't have to read all KLIPs to understand and new KLIP. It's an simple request to make the document more self-contained.", "author": "mjsax", "createdAt": "2020-04-30T22:29:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIyMDQyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIyMDY5MQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418220691", "bodyText": "Only one of the two methods will be allowed\n\nCan you elaborate?", "author": "mjsax", "createdAt": "2020-04-30T18:53:40Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0Njc5MA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418246790", "bodyText": "After a user calls queryResult.subscribe(...), subsequent calls to queryResult.poll(...) will throw an exception. The reverse is true as well.", "author": "vcrfxia", "createdAt": "2020-04-30T19:43:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIyMDY5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2MzY4Mg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418263682", "bodyText": "Hmmm... That introduces a hidden dependency and I would expect that it create issues. It might be better to have two different types of QueryResult?", "author": "mjsax", "createdAt": "2020-04-30T20:16:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIyMDY5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODQ3NTA0Mg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418475042", "bodyText": "Allowing results to be retrieved from a consumer using either an async approach (setting some kind of listener or subscriber) or using a sync approach (calling poll() method) on the same entity is a very common approach used by most messaging clients (e.g. JMS, AMQP), so will be familiar to many devs already. Path of least surprise. (And yes, we are writing a messaging client)", "author": "purplefox", "createdAt": "2020-05-01T09:21:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIyMDY5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgzOTUwNA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r419839504", "bodyText": "And yes, we are writing a messaging client\n\nDo we?", "author": "mjsax", "createdAt": "2020-05-05T03:02:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODIyMDY5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NDgzOA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418244838", "bodyText": "Should we introduce a proper type class (or enum) instead of String?", "author": "mjsax", "createdAt": "2020-04-30T19:39:35Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYyODQ4Mg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420628482", "bodyText": "Yup, see the discussion in #5236 (comment).", "author": "vcrfxia", "createdAt": "2020-05-06T08:35:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NDgzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NjA0OQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418246049", "bodyText": "I assume we return Integer instead if int to handle NULL ?\nWould it make sense to add isNull(int columnIndex) and isNotNull(int columnIndex), too? (also for columnName)", "author": "mjsax", "createdAt": "2020-04-30T19:41:55Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5MzQ3MQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418293471", "bodyText": "+1 isNull would be useful too", "author": "purplefox", "createdAt": "2020-04-30T21:15:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NjA0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYzMTEzNw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420631137", "bodyText": "Added isNull(...) but held off on adding isNotNull(...) since it seems redundant. Is it standard practice to include both even though one is simply the negation of the other?", "author": "vcrfxia", "createdAt": "2020-05-06T08:40:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NjA0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDgwOTY3MQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420809671", "bodyText": "I don't think isNotNull() really add much.", "author": "purplefox", "createdAt": "2020-05-06T13:54:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NjA0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTE5Mzg1NQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r421193855", "bodyText": "Was just an idea -- and if there is demand coming up,isNotNull() can always be added later.", "author": "mjsax", "createdAt": "2020-05-07T01:55:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NjA0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzI5OQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418247299", "bodyText": "Should there be helpers for nested types, too? Or is getObject() plus casting the intended way to handle them?", "author": "mjsax", "createdAt": "2020-04-30T19:44:24Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5MzY0OA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418293648", "bodyText": "For struct types, if we return a JsonObject that is a nested data structure.", "author": "purplefox", "createdAt": "2020-04-30T21:15:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzI5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMyNTkwOA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418325908", "bodyText": "But there is no method with that return type. Thus, I am asking if we should add a corresponding method, to avoid casting from Object to JsonObject (even if I am not sure, if we should return JsonObject but a kslqDB \"native\" type -- cf. the other comments).", "author": "mjsax", "createdAt": "2020-04-30T22:31:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzI5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODQ3MDkyNQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418470925", "bodyText": "Sure, I believe the intention is to do that.", "author": "purplefox", "createdAt": "2020-05-01T09:05:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzI5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgzODg1OA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r419838858", "bodyText": "\\cc @vcrfxia ?", "author": "mjsax", "createdAt": "2020-05-05T02:58:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzI5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYzMTY4Mw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420631683", "bodyText": "Added getKsqlObject() and getKsqlArray() per discussion (here and in #5236 (comment)).", "author": "vcrfxia", "createdAt": "2020-05-06T08:41:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzI5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDgxMTE1MA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420811150", "bodyText": "Maybe getStruct() would be better than getKsqlObject() ?", "author": "purplefox", "createdAt": "2020-05-06T13:56:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzI5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTMxMzUwMA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r421313500", "bodyText": "getStruct() seems it could be confusing since the same KsqlObject type is used to represent both the STRUCT and MAP ksql types.\n(To clarify: I'm not a fan of the name getKsqlObject() -- or KsqlObject for that matter -- either, but I'm not sure getStruct() is an improvement.)", "author": "vcrfxia", "createdAt": "2020-05-07T08:00:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzI5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjAxNzgxMw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r422017813", "bodyText": "getJsonObject() ?", "author": "purplefox", "createdAt": "2020-05-08T08:31:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzI5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjc3MjIyMA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r422772220", "bodyText": "Let's discuss in #5327 where I've added the new types. I haven't exposed the JSON methods on KsqlObject and KsqlArray in order to keep the exposed methods to a minimum, but it sounds like you prefer to expose those methods and rename the getters to getJsonObject() and getJsonArray(), which I'm happy with if we think the JSON methods are worth exposing.", "author": "vcrfxia", "createdAt": "2020-05-11T04:22:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzI5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzU5Nw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418247597", "bodyText": "What is the use case for this method? Should we not always return proper types?", "author": "mjsax", "createdAt": "2020-04-30T19:44:57Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5MzgzMA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418293830", "bodyText": "I think this is for the case where we don't know or care about the types.", "author": "purplefox", "createdAt": "2020-04-30T21:16:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzU5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYyOTcxNA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420629714", "bodyText": "This was important to have before we introduced getKsqlObject() (for returning map and struct types) and getKsqlArray() (for returning array types). Now that we've added those methods the need for a plain getObject() is less pressing, though it still seems useful to have a generic getter that works for any column type.\nMaybe we should rename this getValue() to avoid confusion with getKsqlObject().", "author": "vcrfxia", "createdAt": "2020-05-06T08:38:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzU5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDgxMTUxMA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420811510", "bodyText": "getValue() sounds good.", "author": "purplefox", "createdAt": "2020-05-06T13:56:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzU5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTE5MzM3NQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r421193375", "bodyText": "I like getValue(), too.", "author": "mjsax", "createdAt": "2020-05-07T01:53:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0NzU5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0ODg0OA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418248848", "bodyText": "Why can't we expose the nested data types?", "author": "mjsax", "createdAt": "2020-04-30T19:47:21Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5Mzk5Ng==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418293996", "bodyText": "Agreed, JsonObject/JsonArray", "author": "purplefox", "createdAt": "2020-04-30T21:16:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0ODg0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYzMjc0Ng==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420632746", "bodyText": "Resolved in https://github.com/confluentinc/ksql/pull/5236/files#r418247299", "author": "vcrfxia", "createdAt": "2020-05-06T08:43:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0ODg0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0OTkyOA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418249928", "bodyText": "\"push query\" and \"single batch (non-streaming)\" contradicts each other. Also the headline is \"Non-streaming\"", "author": "mjsax", "createdAt": "2020-04-30T19:49:22Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NDI4MA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418294280", "bodyText": "Disagree, the way the data is obtained is orthogonal to whether it's a push or a pull query.", "author": "purplefox", "createdAt": "2020-04-30T21:17:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0OTkyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMyNzA2OA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418327068", "bodyText": "I am not sure. A push query returns a data stream while a pull query return a result set.\nIt does not make sense to \"subscribe\" to a result set IMHO.", "author": "mjsax", "createdAt": "2020-04-30T22:34:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0OTkyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODQ3MTMwNA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418471304", "bodyText": "Again, I think you're confusing the meaning of \"stream\" in the ksqlDB server side mental model and whether results are \"streamed\" to the user. Like many words used in CS they unfortunately have multiple overloaded meanings when used in different contexts.", "author": "purplefox", "createdAt": "2020-05-01T09:07:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0OTkyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgzOTA2Mg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r419839062", "bodyText": "Again. Because of this, it would be helpful to chose the wording carefully to avoid confusion...", "author": "mjsax", "createdAt": "2020-05-05T03:00:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0OTkyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDYzNDMxMw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420634313", "bodyText": "@mjsax do you have thoughts on what might be better/clearer names?", "author": "vcrfxia", "createdAt": "2020-05-06T08:45:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0OTkyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDgxMjIwNQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420812205", "bodyText": "The API is based on reactive streams. These are streams, calling them anything else would be strange imho.", "author": "purplefox", "createdAt": "2020-05-06T13:57:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0OTkyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTE5NTI0Ng==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r421195246", "bodyText": "Cf #5236 (comment)", "author": "mjsax", "createdAt": "2020-05-07T02:00:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI0OTkyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MjUxNg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418252516", "bodyText": "Why List? Seems Set would be more appropriate for pull queries.", "author": "mjsax", "createdAt": "2020-04-30T19:54:31Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NDY2Ng==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418294666", "bodyText": "Pull query result sets can be ordered (we will support ORDER BY for pull queries at some point).", "author": "purplefox", "createdAt": "2020-04-30T21:17:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MjUxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMyNzIzMg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418327232", "bodyText": "Good point!", "author": "mjsax", "createdAt": "2020-04-30T22:34:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MjUxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418253419", "bodyText": "So basically the offset? This would not be unique. Do we think we need to expose the partition number, too?", "author": "mjsax", "createdAt": "2020-04-30T19:56:22Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);\n+\n+  boolean isComplete();\n+\n+  void close();\n+}\n+```\n+Note that `QueryResult` is a Reactive Streams `Publisher` so users can stream results. Users can also call `poll()` to receive\n+results in a synchronous fashion instead. Only one of the two methods will be allowed per `QueryResult` instance.\n+\n+The `Row` interface is as follows:\n+```\n+/**\n+ * A single record, returned as part of a query result.\n+ */\n+public interface Row {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  List<Object> values();\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Object getObject(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an Object.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Object getObject(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  String getString(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a string.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  String getString(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Integer getInt(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as an integer.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Integer getInt(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Long getLong(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a long.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Long getLong(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Double getDouble(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a double.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Double getDouble(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  Boolean getBoolean(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a boolean.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  Boolean getBoolean(String columnName);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnIndex index of column (1-indexed).\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(int columnIndex);\n+\n+  /**\n+   * Get the value for a particular column of the Row as a decimal.\n+   *\n+   * @param columnName name of column.\n+   * @return column value.\n+   */\n+  BigDecimal getDecimal(String columnName);\n+}\n+```\n+\n+We considered representing column types in a more structured form (rather than plain strings) to accomodate complex/nested data types but felt this added complexity would not be helpful for most use cases. (This would also require a server-side change, so it's a fair bit of additional work.)\n+\n+For `getDecimal(...)` in the `Row` interface, rather than trying to parse the column type to extract the precision and scale, we will simply convert the value to a BigDecimal without explicitly specifying the precision and scale. We could also add an option for users to specify the scale and precision in the getter, if we think that would be useful.\n+\n+We could also add `getList(...)` and `getMap(...)` methods to the `Row` interface, but it's not clear to me how valuable this would be given that the nested data types would not be known.\n+\n+Tim also proposed switching from generic Java types (`Map<String, Object>`, `List<Object>`) to Vert.x types (`JsonObject`, `JsonArray`) as the latter is more type-safe and the client already has a dependency on Vert.x anyway. The downside, though, is that then apps that use the client would be required to depend on Vert.x as well.\n+\n+### Transient queries -- Non-streaming\n+\n+The `Client` interface will also provide the following methods for receiving the results of a transient query (push or pull) in a single batch (non-streaming),\n+once the query has completed:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive all result rows together, once the query has\n+   * completed.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<List<Row>> executeQuery(String sql, Map<String, Object> properties);\n+```\n+\n+For a query to \"complete\" could mean:\n+* The query is a pull query\n+* The query is a push query with a limit clause, and the limit has been reached\n+* The query is a push query that has been terminated\n+\n+We may want to introduce a limit to the number of rows that may be returned from these `executeQuery()` methods,\n+in order to decrease the likelihood of running out of memory.\n+\n+### Insert values\n+\n+A method to insert one row at a time:\n+```\n+  /**\n+   * Insert a single row into the relevant stream/table.\n+   *\n+   * @param streamName name of stream/table.\n+   * @param row the row to insert.\n+   * @return a future that completes once the request has been processed.\n+   */\n+  CompletableFuture<Void> insertInto(String streamName, Map<String, Object> row);\n+```\n+\n+A method to stream inserts (via the `/inserts-stream` endpoint):\n+```\n+  CompletableFuture<Publisher<InsertResponse>> streamInserts(String streamName, Publisher<List<Object>> insertsPublisher);\n+}\n+```\n+where `InsertResponse` is as follows:\n+```\n+public interface InsertResponse {\n+\n+  /**\n+   * Whether the row was successfully inserted or not.\n+   */\n+  boolean isSuccessful();\n+\n+  /**\n+   * Unique sequence number for the row in the stream of inserts.\n+   */\n+  int getSequenceNum();", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1OTM1Ng==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418259356", "bodyText": "This is not the Kafka topic offset. This is the row number in the stream of inserts, meaning the user opens a connection to stream inserts, sends one row, gets an ack with sequence number 1 (I forget if this is 1-indexed or 0-indexed right now, have to check the code), sends another row, gets an ack with sequence number 2, etc.", "author": "vcrfxia", "createdAt": "2020-04-30T20:08:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI2NzQ0OA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418267448", "bodyText": "I see. Why do we expose this? Why would the user care?", "author": "mjsax", "createdAt": "2020-04-30T20:24:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI5NDk5MA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418294990", "bodyText": "This is so the user can correlate the ack with the insert they sent. E.g. they may want to take some action once they know the insert has been completed ok.", "author": "purplefox", "createdAt": "2020-04-30T21:18:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMyODY0MA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418328640", "bodyText": "What ack? The InsertResponse itself tells the user (via isSuccessful if the insert was sucessful or not)? I don't see any API where the user would pass in the sequence number of any API with an \"ack number\" that could be compared to this sequence number? Seems I am missing something?", "author": "mjsax", "createdAt": "2020-04-30T22:38:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODM2NDM5OQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418364399", "bodyText": "When a user calls streamInserts(...), they'll receive a Publisher<InsertResponse> that they can subscribe to in their app code and (asynchronously) take an action whenever a new ack is received. In this way, the user doesn't need to \"pass in the sequence number [to] any API\" in order to take actions based on acks. That logic would all live in the app code.", "author": "vcrfxia", "createdAt": "2020-05-01T00:37:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODQ3MjkyNA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418472924", "bodyText": "Acks can come back out of order. so the sequence number is necessary to correlate them with the corresponding inserts.", "author": "purplefox", "createdAt": "2020-05-01T09:13:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODQ3NjE2OQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418476169", "bodyText": "An alternative would be to provide an API, something like the following for streaming inserts:\nvoid streamInserts(String streamName, Publisher<Pair<List<Object>, CompletableFuture<Void>>> insertsPublisher);\n\nThe user would supply the cf for each insert, and would be notified via the cf on completion of the insert. This wouldn't require the user to do any correlation between inserts and acks themselves.", "author": "purplefox", "createdAt": "2020-05-01T09:26:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTgzNzIzNg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r419837236", "bodyText": "In this way, the user doesn't need to \"pass in the sequence number [to] any API\" in order to take actions based on acks.\n\nFor this case, exposing the sequence number does not seem to be helpful for the user?\n\nAcks can come back out of order. so the sequence number is necessary to correlate them with the corresponding inserts.\n\nShould we provide a stronger guarantee? Kafka itself also provides strong ordering guarantees. As a user, it seem desirable that the data is not reorder, ie, if I call streamInsert() twice (and data goes into the same partition) it should appended in the order of my calls?\nI like the idea to just register a callback thought. That is similar to what KafkaProducer does.", "author": "mjsax", "createdAt": "2020-05-05T02:51:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDAyMzc0MA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420023740", "bodyText": "Should we provide a stronger guarantee? Kafka itself also provides strong ordering guarantees. As a user, it seem desirable that the data is not reorder, ie, if I call streamInsert() twice (and data goes into the same partition)\n\nIt's not necessarily going to go in the same partition, it depends on the key. That's why the acks might be in a different order.", "author": "purplefox", "createdAt": "2020-05-05T10:56:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDMzMjk1MA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420332950", "bodyText": "Sure. On read I don't get any guarantee about the order if the writes went to different partitions. But for this case, the sequence number seems to be even less useful? It's seems to be client side counter? I still don't understand how this is useful? If the InsertResponse tells me that the write was successful I am good, otherwise I might retry. Why would I care about this number?", "author": "mjsax", "createdAt": "2020-05-05T18:51:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM1NjYzNw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420356637", "bodyText": "The sequence number is necessary because otherwise you don't know what send a particular InsertResponse refers to, as the InsertsResponses can come back in a different order to the sends.", "author": "purplefox", "createdAt": "2020-05-05T19:33:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM3MDc2Nw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420370767", "bodyText": "Still don't understand: How can I use this number to map back? When I provide an \"input record\" I don't know its sequence number upfront? So if I get a sequence number back, how can I map it to the record?\nOr are you saying that the sequence number start from zero each time streamInsert() is called, ie, it refers to the index of the input record in the provided List? For this case, the JavaDoc explanation should be more elaborate.", "author": "mjsax", "createdAt": "2020-05-05T20:00:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM4MDU4NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420380584", "bodyText": "Yes, the sequence number of the first insert you send is 0, then next one is 1, the next one 2 etc. That's all you need to correlate. Typically the user would use the sequence_number as the key in a map, so when the response comes back the value for the key can be looked up and some action can be taken.", "author": "purplefox", "createdAt": "2020-05-05T20:18:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDQzMzEyOQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420433129", "bodyText": "My question was:\n// fist call\nstreamInsert(A, B, C) -> 0, 1, 2\n\n// second call\nstreamInsert(D, E) -> 3, 4 // my original assumption\n// or\nstreamInsert(D, E) -> 0, 1 \n\nIf it's the former, I am still not sure how user would do the mapping. If it's the later, my original understanding was totally off making the discussion void. However, I would suggest to rename from sequendNumber to index and update the JavaDocs:\n/**\n  * Index of the the row from the original input `List` provided to `streamInsert()`.\n  */\nint getInputIndex();\n\n\"Sequence number\" might be rather confusing indicate that it is the position of the record in the stream that the records are appended to. Thoughts?\n\\cc @vcrfxia", "author": "mjsax", "createdAt": "2020-05-05T22:01:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDQzNzkwOQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420437909", "bodyText": "It's the latter.\nWhen you call streamInserts you have two streams (reactive streams). 1 - is the stream of inserts going to the server. 2 - is the stream of acks coming back from the server.\nEach insert in 1. has a sequence number 0, 1, 2, etc. The sequence number field in the acks refers to the sequence number in 1.\nDoes that clear things up?\nThere is no global sequence number, it just refers to the sequence in the sending stream.", "author": "purplefox", "createdAt": "2020-05-05T22:13:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDQzOTg4Mg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420439882", "bodyText": "Thanks that clears things up. The overloaded terminology of \"stream\" is really confusing.", "author": "mjsax", "createdAt": "2020-05-05T22:17:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDQ0ODQ3NA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420448474", "bodyText": "Reactive streams refers to streams of data sent from publishers to subscribers. gRPC also has streams. HTTP2 has streams too. They're all kind of similar. Then you have streams in ksqlDB/KS. Yep, lots of streams :)", "author": "purplefox", "createdAt": "2020-05-05T22:39:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODI1MzQxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE1ODkzNw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418158937", "bodyText": "It's been a bit since I've dealt with keystores and truststores, so maybe I'm missing something, but for a client, do you need a keystore?  In this case, it would be for authenticating the client to the server, which we currently do with basic auth.", "author": "AlanConfluent", "createdAt": "2020-04-30T17:05:37Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODMwMTQxNQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418301415", "bodyText": "A keystore is needed if TLS mutual auth is enabled, since then the server checks the client's certificate as well.", "author": "vcrfxia", "createdAt": "2020-04-30T21:32:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE1ODkzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5MTg2Nw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418191867", "bodyText": "Will this return null both if the stream is complete or if a timeout has occurred?  Wondering if it would be a bit cleaner in the common case to throw a TimeoutException?\nhttps://docs.oracle.com/javase/7/docs/api/java/util/concurrent/Future.html#get(long,%20java.util.concurrent.TimeUnit)", "author": "AlanConfluent", "createdAt": "2020-04-30T18:01:09Z", "path": "design-proposals/klip-26-java-client-interfaces.md", "diffHunk": "@@ -0,0 +1,715 @@\n+# KLIP 26 - Java client interfaces\n+\n+**Author**: Victoria Xia (@vcrfxia) | \n+**Release Target**: ksqlDB 0.10.0 | \n+**Status**: _In development_ | \n+**Discussion**: TBD\n+\n+**tl;dr:** _[KLIP 15](./klip-15-new-api-and-client.md) already made the case for why it makes sense\n+           to introduce a Java client for ksqlDB. This KLIP proposes interfaces for the client._\n+\n+## Motivation and background\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## What is in scope\n+\n+The Java client will support the following operations:\n+* Push query\n+* Pull query\n+* Select DDL/DML operations:\n+    * `CREATE STREAM`\n+    * `CREATE TABLE`\n+    * `CREATE STREAM ... AS SELECT`\n+    * `CREATE TABLE ... AS SELECT`\n+    * `DROP STREAM`\n+    * `DROP TABLE`\n+    * `INSERT INTO`\n+    * `TERMINATE <queryId>`\n+    * `CREATE CONNECTOR`\n+    * `DROP CONNECTOR`\n+* Select admin operations:\n+    * `SHOW TOPICS` (non-extended)\n+    * `SHOW STREAMS` (non-extended)\n+    * `SHOW TABLES` (non-extended)\n+    * `SHOW QUERIES` (non-extended)\n+    * `SHOW CONNECTORS`\n+* Insert values, i.e., insert rows into an existing stream/table\n+* Terminate push query (via the `/close-query` endpoint)\n+\n+The purpose of this KLIP is to reach agreement on the interfaces / public APIs.\n+Implementation details will not be covered.\n+\n+## What is not in scope\n+\n+This KLIP does not cover Java client support for the following:\n+* `DESCRIBE <stream/table>`, `DESCRIBE CONNECTOR`, `DESCRIBE FUNCTION`\n+* `EXPLAIN <queryId>`\n+* `PRINT <topic>`\n+* `SHOW TOPICS EXTENDED`, `SHOW <STREAMS/TABLES> EXTENDED`, `SHOW QUERIES EXTENDED`\n+* `CREATE TYPE`, `DROP TYPE`, `SHOW TYPES`\n+* `SHOW FUNCTIONS`, `SHOW PROPERTIES`\n+* `RUN SCRIPT`\n+* Use of other endpoints (info, healthcheck, terminate cluster, status, etc.)\n+\n+We can always add support for these operations in the future if desired.\n+\n+As above, implementation details are out of scope as the purpose of this KLIP is to reach agreement\n+on the interfaces / public APIs.\n+\n+## Value/Return\n+\n+See [KLIP 15](./klip-15-new-api-and-client.md).\n+\n+## Public APIS\n+\n+The following subsections describe the methods of the `Client` interface:\n+```\n+public interface Client {\n+    ...\n+}\n+```\n+\n+### Constructors\n+```\n+  static Client create(ClientOptions clientOptions) {\n+    return new ClientImpl(clientOptions);\n+  }\n+\n+  static Client create(ClientOptions clientOptions, Vertx vertx) {\n+    return new ClientImpl(clientOptions, vertx);\n+  }\n+```\n+\n+The Java client will be implemented as a Vert.x HttpClient. We expose a constructor that allows users to provide their own `Vertx` instance\n+in order to take advantage of a shared connection pool and other properties if desired.\n+\n+`ClientOptions` will initially be as follows:\n+```\n+public interface ClientOptions {\n+\n+  ClientOptions setHost(String host);\n+\n+  ClientOptions setPort(int port);\n+\n+  ClientOptions setUseTls(boolean useTls);\n+\n+  ClientOptions setUseClientAuth(boolean useClientAuth);\n+\n+  ClientOptions setTrustStore(String trustStorePath);\n+\n+  ClientOptions setTrustStorePassword(String trustStorePassword);\n+\n+  ClientOptions setKeyStore(String keyStorePath);\n+\n+  ClientOptions setKeyStorePassword(String keyStorePassword);\n+\n+  ClientOptions setBasicAuthCredentials(String username, String password);\n+\n+  String getHost();\n+\n+  int getPort();\n+\n+  boolean isUseTls();\n+\n+  boolean isUseClientAuth();\n+\n+  boolean isUseBasicAuth();\n+\n+  String getTrustStore();\n+\n+  String getTrustStorePassword();\n+\n+  String getKeyStore();\n+\n+  String getKeyStorePassword();\n+\n+  String getBasicAuthUsername();\n+\n+  String getBasicAuthPassword();\n+\n+  ClientOptions copy();\n+\n+  static ClientOptions create() {\n+    return new ClientOptionsImpl();\n+  }\n+}\n+```\n+\n+We can always add additional configuration options later. We may also wish to expose the Vert.x `HttpClientOptions` for\n+advanced users that wish to provide custom configs.\n+\n+### Transient queries -- Streaming\n+\n+The `Client` interface will provide the following methods for streaming the results of a transient (push or pull) query:\n+```\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql);\n+\n+  /**\n+   * Execute a query (push or pull) and receive the results one row at a time.\n+   *\n+   * @param sql statement of query to execute.\n+   * @param properties query properties.\n+   * @return query result.\n+   */\n+  CompletableFuture<QueryResult> streamQuery(String sql, Map<String, Object> properties);\n+```\n+where `QueryResult` is as follows:\n+```\n+/**\n+ * The result of a query (push or pull), streamed one row at time. Records may be consumed by either\n+ * subscribing to the publisher or polling (blocking) for one record at a time. These two methods of\n+ * consumption are mutually exclusive; only one method may be used (per QueryResult).\n+ */\n+public interface QueryResult extends Publisher<Row> {\n+\n+  List<String> columnNames();\n+\n+  List<String> columnTypes();\n+\n+  String queryID();\n+\n+  /**\n+   * Block until a row becomes available.\n+   *\n+   * @return the row.\n+   */\n+  Row poll();\n+\n+  /**\n+   * Block until a row becomes available or the timeout has elapsed.\n+   *\n+   * @param timeout amount of to wait for a row. Non-positive values are interpreted as no timeout.\n+   * @param timeUnit unit for timeout param.\n+   * @return the row, if available; else, null.\n+   */\n+  Row poll(long timeout, TimeUnit timeUnit);", "originalCommit": "aed38d5836550829f7fd459df31b47aaf7e5ad45", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODkyMjg4Ng==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r418922886", "bodyText": "I would prefer it to return null in case of timeout. The timeout here is not an exceptional condition, e.g. it would be common for the user to call poll with a low timeout to keep the callers thread live (maybe it needs to poll multiple consumers? Aside: Personally I don't like the synchronous way, but many people do, and it's the way Kafka consumers are accessed, so users will likely be used to this access style).\nwhile (true) {\n  for (Consumer consumer: consumers) {\n     Row row = consumer.poll(0);\n     if (row != null) {\n       doSomethingWithRow(row);\n     }\n  }\n}\n\nIn the above example it's expected that row will be null, probably in most cases. It's not an exceptional condition. (Returning null (or some other return value representing no value) is pretty common in these kind of polling APIs).\nIf the method threw an exception it would make the above code somewhat more complex, also performance wise, creating and throwing exceptions is quite expensive (mainly due to stack trace population).", "author": "purplefox", "createdAt": "2020-05-02T06:58:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5MTg2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTg0MDY5Nw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r419840697", "bodyText": "It might be reasonable to treat a timeout as non exceptional. However, returning null seems like an anti-pattern to me. In doubt, the return type should be an Optinal?\n\nand it's the way Kafka consumers are accessed, so users will likely be used to this access style\n\nThe example is not how KafkaConsumer works: poll() returns a not-null ConsumerRecords object that implement Iterable -- thus, there would never be a null returned to the application.", "author": "mjsax", "createdAt": "2020-05-05T03:08:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5MTg2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTg0MjU4NQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r419842585", "bodyText": "Btw: instead of using two parameters, it would be simpler to use a single Duration.\nOne more after thought: the parameter name \"timeout\" might sound like an \"exceptional condition\", thus, we could also pick a different name like maxBlock or similar? Just a random thought.", "author": "mjsax", "createdAt": "2020-05-05T03:17:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5MTg2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDAyMjM0Mw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420022343", "bodyText": "The example is not how KafkaConsumer works: poll() returns a not-null ConsumerRecords object that implement Iterable -- thus, there would never be a null returned to the application.\n\nThe sentence was referring to the Kafka consumer being accessed in a synchronous way and not throwing an exception.", "author": "purplefox", "createdAt": "2020-05-05T10:53:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5MTg2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDMyODk2NQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420328965", "bodyText": "The Kafka consumer is always sync in poll() and never throws a TimeoutException. If the poll() wait time expires, it just returns a ConsumerRecords object with zero records in it.", "author": "mjsax", "createdAt": "2020-05-05T18:44:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5MTg2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDMzNDMzNQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420334335", "bodyText": "However, returning null seems like an anti-pattern to me. In doubt, the return type should be an Optional?\n\nAh the old \"null vs optional debate\"! Personally, I'm not a massive fan of Optional, I think the hype around dealing with nulls, is.. well, overhyped.\nMaybe I'm just old school, I learnt my Java before Optional existed and tbh, I never really recognised the problem it was fixing as an actually problem I had ever really seen that much or really cared about.\nAlso, for performance sensitive code, returning an Optional creates garbage unlike returning null. So for the more performance minded users this may be a turn-off.\nHaving said that, I wouldn't consider it the end of the world if we used Optional here.", "author": "purplefox", "createdAt": "2020-05-05T18:54:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5MTg2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM0MDg5Nw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420340897", "bodyText": "IMHO, it's always good to avoid null to pro-actively avoid NPEs. And I doubt that it will be an actual performance concern. But I am not religious about it, and if we want to use null so be it; I just have the impression that \"modern Java\" is moving to use Optional and it might be good to align to this development.", "author": "mjsax", "createdAt": "2020-05-05T19:05:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5MTg2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM1MTcyNg==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420351726", "bodyText": "One of the silly things about Optional imho:\nYes, it prevents NPE, but then if you call .get() on the optional and it doesn't have a value it throws NoSuchElementException!\nSo you're just trading the NPE for some other exception. Seems rather pointless to me! All you've gained is a bit more code and slightly worse performance.\nIt's only if you use Optional in a completely functional way. I.e never call get() and use the methods that take different actions based on whether the value is set or not, that it has value. But it's rarely used completely in that way in my experience.", "author": "purplefox", "createdAt": "2020-05-05T19:24:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5MTg2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM2NzQyNw==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420367427", "bodyText": "Well, I think the advantage is that the return type itself documents if it might be null or not. Hence, the overall contract should be that any non-optional return type is never null. This make the contract of nullable explicit; otherwise, you always need to check for null just to be sure (of course, it's documented in the JavaDocs, but a code level contract seems preferable to a \"comment contract\".\nBut as so often: it's subjective.", "author": "mjsax", "createdAt": "2020-05-05T19:53:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5MTg2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM3MTExMA==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420371110", "bodyText": "Hence, the overall contract should be that any non-optional return type is never null.\n\n\nImho, unless these kinds of contracts are enforced by the compiler (as they are with Rust or Kotlin) they have little value imho. But we agree on one thing - it's subjective :)", "author": "purplefox", "createdAt": "2020-05-05T20:00:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5MTg2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDM3MjQ5OQ==", "url": "https://github.com/confluentinc/ksql/pull/5236#discussion_r420372499", "bodyText": "Agree. Compiler enforcement would be best! (Similar for \"read only\" objects... Java is just very bad at those things...)", "author": "mjsax", "createdAt": "2020-05-05T20:03:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5MTg2Nw=="}], "type": "inlineReview"}, {"oid": "efc58b7c30c8fe0bf1d11150260b0518ec0b45d6", "url": "https://github.com/confluentinc/ksql/commit/efc58b7c30c8fe0bf1d11150260b0518ec0b45d6", "message": "chore: clear up DDL/DML confusion. remove unneeded fields. add commandSeqNum", "committedDate": "2020-05-06T01:41:56Z", "type": "commit"}, {"oid": "bf95f3b7c0d142581c475bc3acd107a3c1f0761c", "url": "https://github.com/confluentinc/ksql/commit/bf95f3b7c0d142581c475bc3acd107a3c1f0761c", "message": "chore: return queryId from executeQuery()", "committedDate": "2020-05-06T01:48:59Z", "type": "commit"}, {"oid": "8069dbf256e9ff29b57871998260c93b428d636d", "url": "https://github.com/confluentinc/ksql/commit/8069dbf256e9ff29b57871998260c93b428d636d", "message": "chore: add ColumnType", "committedDate": "2020-05-06T07:14:00Z", "type": "commit"}, {"oid": "cf93bc3def69770ec3d3de22a6c0d7dfc7d5bb8b", "url": "https://github.com/confluentinc/ksql/commit/cf93bc3def69770ec3d3de22a6c0d7dfc7d5bb8b", "message": "chore: add wrapper around raw types", "committedDate": "2020-05-06T08:04:13Z", "type": "commit"}, {"oid": "71202cf4efa35be303209e71da23ce363f9dce39", "url": "https://github.com/confluentinc/ksql/commit/71202cf4efa35be303209e71da23ce363f9dce39", "message": "chore: more feedback", "committedDate": "2020-05-06T08:25:17Z", "type": "commit"}, {"oid": "f447ce9002ada1f992080685f3262cbda4faf1b1", "url": "https://github.com/confluentinc/ksql/commit/f447ce9002ada1f992080685f3262cbda4faf1b1", "message": "Merge branch 'master' into klip-26", "committedDate": "2020-05-06T08:26:11Z", "type": "commit"}, {"oid": "34f0b20ab5aaed577a799290c6c96541266a4a4f", "url": "https://github.com/confluentinc/ksql/commit/34f0b20ab5aaed577a799290c6c96541266a4a4f", "message": "chore: rename Row interface getter", "committedDate": "2020-05-07T07:37:45Z", "type": "commit"}, {"oid": "0e94d765ec60d016aa71d32cbe26e1e58c9abbda", "url": "https://github.com/confluentinc/ksql/commit/0e94d765ec60d016aa71d32cbe26e1e58c9abbda", "message": "chore: managing connectors is now out of scope", "committedDate": "2020-05-07T07:50:18Z", "type": "commit"}, {"oid": "6afa3cd50527005c7640e3cc89e020b030b6cda4", "url": "https://github.com/confluentinc/ksql/commit/6afa3cd50527005c7640e3cc89e020b030b6cda4", "message": "chore: switch timeout to Duration, rename to BatchedQueryResult", "committedDate": "2020-05-11T03:48:35Z", "type": "commit"}]}