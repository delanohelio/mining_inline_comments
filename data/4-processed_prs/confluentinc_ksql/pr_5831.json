{"pr_number": 5831, "pr_title": "feat: Replay command topic to local file to backup KSQL Metastore", "pr_createdAt": "2020-07-15T15:02:18Z", "pr_url": "https://github.com/confluentinc/ksql/pull/5831", "timeline": [{"oid": "8e1da4df3b5e3b1df802ded577d7d9774da98412", "url": "https://github.com/confluentinc/ksql/commit/8e1da4df3b5e3b1df802ded577d7d9774da98412", "message": "feat: metastore backups", "committedDate": "2020-07-15T15:15:10Z", "type": "forcePushed"}, {"oid": "8c8b54c857d38e8c304b5e7c6415063ecfe60c12", "url": "https://github.com/confluentinc/ksql/commit/8c8b54c857d38e8c304b5e7c6415063ecfe60c12", "message": "feat: metastore backups", "committedDate": "2020-07-15T17:45:32Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQzMDQ2MA==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455430460", "bodyText": "can we test what happens if the command itself has a newline in it (or is it possible for the commandId to have the KEY_VALUE_SEPARATOR in it - I don't think so)? I know it will make it harder to replay the file, but it might make it safer if we have an encoding: commandIdSize (4 bytes) | commandSize (4 byte) | commandId | Command\nanother (perhaps better) option is that because we know that the CommandID and the Command are valid JSON, we can just read one valid JSON then the next (see https://stackoverflow.com/a/37395419/2258040) and we don't even have to worry about newlines (which we can add anyway to make it easier for humans to read)\nI might be too paranoid, let me know if you don't think this is a problem.", "author": "agavra", "createdAt": "2020-07-15T23:54:35Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/BackupReplayFile.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import io.confluent.ksql.execution.json.PlanJsonMapper;\n+import io.confluent.ksql.rest.entity.CommandId;\n+import io.confluent.ksql.rest.server.computation.Command;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.Pair;\n+\n+import java.io.BufferedWriter;\n+import java.io.Closeable;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.io.OutputStreamWriter;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+\n+/**\n+ * A file that is used by the backup service to replay command_topic commands.\n+ */\n+public class BackupReplayFile implements Closeable {\n+  private static final ObjectMapper MAPPER = PlanJsonMapper.INSTANCE.get();\n+  private static final String KEY_VALUE_SEPARATOR = \":\";\n+\n+  private final File file;\n+  private final BufferedWriter writer;\n+\n+  public BackupReplayFile(final File file) {\n+    this.file = Objects.requireNonNull(file, \"file\");\n+    this.writer = createWriter(file);\n+  }\n+\n+  private static BufferedWriter createWriter(final File file) {\n+    try {\n+      return new BufferedWriter(new OutputStreamWriter(\n+          new FileOutputStream(file, true),\n+          StandardCharsets.UTF_8)\n+      );\n+    } catch (final FileNotFoundException e) {\n+      throw new KsqlException(\n+          String.format(\"Failed to create replay file: %s\", file.getAbsolutePath()), e);\n+    }\n+  }\n+\n+  public String getPath() {\n+    return file.getAbsolutePath();\n+  }\n+\n+  public void write(final CommandId commandId, final Command command) throws IOException {\n+    writer.write(MAPPER.writeValueAsString(commandId));\n+    writer.write(KEY_VALUE_SEPARATOR);\n+    writer.write(MAPPER.writeValueAsString(command));\n+    writer.write(\"\\n\");\n+    writer.flush();\n+  }\n+\n+  public void write(final List<Pair<CommandId, Command>> records) throws IOException {\n+    for (final Pair<CommandId, Command> record : records) {\n+      write(record.left, record.right);\n+    }\n+  }\n+\n+  public List<Pair<CommandId, Command>> readRecords() throws IOException {\n+    final List<Pair<CommandId, Command>> commands = new ArrayList<>();\n+    for (final String line : Files.readAllLines(file.toPath(), StandardCharsets.UTF_8)) {", "originalCommit": "8c8b54c857d38e8c304b5e7c6415063ecfe60c12", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ3NTcxOQ==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455475719", "bodyText": "Cool, I was looking on something like that. However, that format will not work with the plan of restoring the topic manually using this command:\n$ kafka-topic --create --topic $COMMAND_TOPIC --partitions 1 --replication-factor 3\n$ kafka-console-producer --broker-list localhost:9092 --topic $COMMAND_TOPIC \\\n        --property \"parse.key=true\" --property \"key.separator=:\" < $BACKUP_FILE\n\nIf we have time, we could add a ksql-restore command that reads the file using your proposal (which I prefer). Perhaps a next release? I'm not sure if we can do it in a compatible way. Just changing the file name might be enough probably.", "author": "spena", "createdAt": "2020-07-16T02:41:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQzMDQ2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTk1MjU3Mg==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455952572", "bodyText": "Does the proposed restore command work if the command has newlines? If not, then we need to fix that right?", "author": "rodesai", "createdAt": "2020-07-16T17:28:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQzMDQ2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTk2NTA5NQ==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455965095", "bodyText": "@rodesai There's a test that verifies that in BackupReplayFileTest.shouldWriteRecordWithNewLineCharacterInCommand.", "author": "spena", "createdAt": "2020-07-16T17:49:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQzMDQ2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA2MjAxNg==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r456062016", "bodyText": "As discussed offline, according to the standard it's not possible for a json string field to have an embedded newline, so we should be good here. I still think a more explicit format (like what @agavra suggested) is safer (even if it means the backup file isn't immediately usable). Up to you.", "author": "rodesai", "createdAt": "2020-07-16T20:35:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQzMDQ2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQzMTcwNA==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455431704", "bodyText": "nit (my preference, feel free to reject): might make the code a little cleaner if instead of an Optional we made CommandTopicBackup an interface and passed in a no-op implementation - that we way don't have ifPresent everywhere", "author": "agavra", "createdAt": "2020-07-15T23:58:37Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/CommandTopic.java", "diffHunk": "@@ -41,40 +41,52 @@\n \n   private Consumer<CommandId, Command> commandConsumer = null;\n   private final String commandTopicName;\n+  private Optional<CommandTopicBackup> commandTopicBackup;\n \n   public CommandTopic(\n       final String commandTopicName,\n-      final Map<String, Object> kafkaConsumerProperties\n+      final Map<String, Object> kafkaConsumerProperties,\n+      final Optional<CommandTopicBackup> commandTopicBackup", "originalCommit": "8c8b54c857d38e8c304b5e7c6415063ecfe60c12", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg3NjE3OQ==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455876179", "bodyText": "Done. I like it too.", "author": "spena", "createdAt": "2020-07-16T15:30:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQzMTcwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQzNzU1MQ==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455437551", "bodyText": "another code style thing which might make this a little easier to read:\nFile latestFile = Arrays.stream(files).max(Comparator.comparing(CommandTopicBackup::extractTimestamp));", "author": "agavra", "createdAt": "2020-07-16T00:17:56Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/CommandTopicBackup.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.rest.entity.CommandId;\n+import io.confluent.ksql.rest.server.computation.Command;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.Pair;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Backup service that replays the KSQL command_topic to a local file. A new backup file is\n+ * created whenever a new command does not match the actual backup file. Previously replayed\n+ * messages read up to this new command will be written to the new file. This ensures a new\n+ * complete backup of the command_topic is created.\n+ */\n+public class CommandTopicBackup {\n+  private static final Logger LOG = LoggerFactory.getLogger(CommandTopicBackup.class);\n+  private static final Ticker CURRENT_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+  private static final String PREFIX = \"backup_\";\n+\n+  private final File backupLocation;\n+  private final String topicName;\n+  private final Ticker ticker;\n+\n+  private BackupReplayFile replayFile;\n+  private List<Pair<CommandId, Command>> latestReplay;\n+  private int latestReplayIdx;\n+\n+  public CommandTopicBackup(final String location, final String topicName) {\n+    this(location, topicName, CURRENT_MILLIS_TICKER);\n+  }\n+\n+  public CommandTopicBackup(final String location, final String topicName, final Ticker ticker) {\n+    final File dir = new File(Objects.requireNonNull(location, \"location\"));\n+    if (!dir.exists() || !dir.isDirectory()) {\n+      throw new KsqlException(String.format(\n+          \"Backup location '%s' does not exist or it is not a directory.\", location));\n+    }\n+\n+    this.backupLocation = dir;\n+    this.topicName = Objects.requireNonNull(topicName, \"topicName\");\n+    this.ticker = Objects.requireNonNull(ticker, \"ticker\");\n+  }\n+\n+  public void initialize() {\n+    replayFile = openOrCreateReplayFile();\n+\n+    try {\n+      latestReplay = replayFile.readRecords();\n+    } catch (final IOException e) {\n+      LOG.warn(\"Failed to read the latest backup from {}. Continue with a new file. Error = {}\",\n+          replayFile.getPath(), e.getMessage());\n+\n+      replayFile = newReplayFile();\n+      latestReplay = Collections.emptyList();\n+    }\n+\n+    latestReplayIdx = 0;\n+    LOG.info(\"Command topic will be backup on file: {}\", replayFile.getPath());\n+  }\n+\n+  public void close() {\n+    try {\n+      replayFile.close();\n+    } catch (final IOException e) {\n+      LOG.warn(\"Failed closing the backup file {}. Error = {}\",\n+          replayFile.getPath(), e.getMessage());\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  BackupReplayFile getReplayFile() {\n+    return replayFile;\n+  }\n+\n+  public void writeRecord(final ConsumerRecord<CommandId, Command> record) {\n+    if (latestReplayIdx < latestReplay.size()) {\n+      final Pair<CommandId, Command> latestReplayRecord = latestReplay.get(latestReplayIdx);\n+      if (record.key().equals(latestReplayRecord.left)\n+          && record.value().equals(latestReplayRecord.right)) {\n+        // Ignore backup because record was already replayed\n+        latestReplayIdx++;\n+        return;\n+      } else {\n+        LOG.info(\"Previous command topic backup does not match the new command topic data. \"\n+            + \"A new backup file will be created.\");\n+        createNewBackupFile();\n+        LOG.info(\"New backup file created: {}\", replayFile.getPath());\n+      }\n+    } else if (latestReplayIdx > 0) {\n+      // clear latest replay from memory\n+      latestReplay.clear();\n+      latestReplayIdx = 0;\n+    }\n+\n+    try {\n+      replayFile.write(record.key(), record.value());\n+    } catch (final IOException e) {\n+      LOG.warn(\"Failed to write to file {}. The command topic backup is not complete. \"\n+              + \"Make sure the file exists and has permissions to write. KSQL must be restarted \"\n+              + \"afterwards to complete the backup process. Error = {}\",\n+          replayFile.getPath(), e.getMessage());\n+    }\n+  }\n+\n+  private void createNewBackupFile() {\n+    try {\n+      replayFile.close();\n+    } catch (IOException e) {\n+      LOG.warn(\"Couldn't close the current backup file {}. Error = {}\",\n+          replayFile.getPath(), e.getMessage());\n+    }\n+\n+    replayFile = newReplayFile();\n+\n+    if (latestReplay.size() > 0 && latestReplayIdx > 0) {\n+      try {\n+        replayFile.write(latestReplay.subList(0, latestReplayIdx));\n+      } catch (final IOException e) {\n+        LOG.warn(\"Couldn't write the latest replayed commands to the new backup file {}. \"\n+                + \"Make sure the file exists and has permissions to write. \"\n+                + \"KSQL must be restarted afterwards to complete the backup process. Error = {}\",\n+            replayFile.getPath(), e.getMessage());\n+      }\n+    }\n+\n+    // clear latest replay from memory\n+    latestReplay.clear();\n+    latestReplayIdx = 0;\n+  }\n+\n+  @VisibleForTesting\n+  BackupReplayFile openOrCreateReplayFile() {\n+    final Optional<BackupReplayFile> latestFile = latestReplayFile();\n+    if (latestFile.isPresent()) {\n+      return latestFile.get();\n+    }\n+\n+    return newReplayFile();\n+  }\n+\n+  private BackupReplayFile newReplayFile() {\n+    return new BackupReplayFile(Paths.get(\n+        backupLocation.getAbsolutePath(),\n+        String.format(\"%s%s_%s\", PREFIX, topicName, ticker.read())\n+    ).toFile());\n+  }\n+\n+  private Optional<BackupReplayFile> latestReplayFile() {\n+    final String prefixFilename = String.format(\"%s%s_\", PREFIX, topicName);\n+    final File[] files = backupLocation.listFiles(\n+        (f, name) -> name.toLowerCase().startsWith(prefixFilename));\n+\n+    File latestBakFile = null;\n+    if (files != null) {\n+      long latestTs = 0;\n+      for (int i = 0; i < files.length; i++) {\n+        final File bakFile = files[i];\n+        final String bakTimestamp = bakFile.getName().substring(prefixFilename.length());\n+\n+        try {\n+          final Long ts = Long.valueOf(bakTimestamp);\n+          if (ts > latestTs) {\n+            latestTs = ts;\n+            latestBakFile = bakFile;\n+          }\n+        } catch (final NumberFormatException e) {\n+          LOG.warn(\n+              \"Invalid timestamp '{}' found in backup replay file (file ignored): {}\",\n+              bakTimestamp, bakFile.getName());\n+          continue;\n+        }\n+      }\n+    }", "originalCommit": "8c8b54c857d38e8c304b5e7c6415063ecfe60c12", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ4MDkxMw==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455480913", "bodyText": "Looks nice!. But, how do I ignore a extractTimestamp that failed? Say file is file_123xx. I would need to extract the timestamp as String, then a filter that checks isNumeric, then a map to convert to Long, then a max(). Is there a better way to ignore it like your code?", "author": "spena", "createdAt": "2020-07-16T03:01:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQzNzU1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg5NjE4Nw==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455896187", "bodyText": "good point... I'm not long certain this is any better than what you have, but one option is to make extractTimestamp return Long.MIN_VALUE if there's a failure and ensuring the one we got at the end is valid. Feel free to just close this comment :)", "author": "agavra", "createdAt": "2020-07-16T15:59:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQzNzU1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ0MTA1Mw==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455441053", "bodyText": "while the logic here is correct, it took me a while to understand what it was doing - it might make this code easier to read if you had a method isRestoring() and then separated the restore logic into a checkIfRecordInLatestReplay method", "author": "agavra", "createdAt": "2020-07-16T00:30:18Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/CommandTopicBackup.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.rest.entity.CommandId;\n+import io.confluent.ksql.rest.server.computation.Command;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.Pair;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Backup service that replays the KSQL command_topic to a local file. A new backup file is\n+ * created whenever a new command does not match the actual backup file. Previously replayed\n+ * messages read up to this new command will be written to the new file. This ensures a new\n+ * complete backup of the command_topic is created.\n+ */\n+public class CommandTopicBackup {\n+  private static final Logger LOG = LoggerFactory.getLogger(CommandTopicBackup.class);\n+  private static final Ticker CURRENT_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+  private static final String PREFIX = \"backup_\";\n+\n+  private final File backupLocation;\n+  private final String topicName;\n+  private final Ticker ticker;\n+\n+  private BackupReplayFile replayFile;\n+  private List<Pair<CommandId, Command>> latestReplay;\n+  private int latestReplayIdx;\n+\n+  public CommandTopicBackup(final String location, final String topicName) {\n+    this(location, topicName, CURRENT_MILLIS_TICKER);\n+  }\n+\n+  public CommandTopicBackup(final String location, final String topicName, final Ticker ticker) {\n+    final File dir = new File(Objects.requireNonNull(location, \"location\"));\n+    if (!dir.exists() || !dir.isDirectory()) {\n+      throw new KsqlException(String.format(\n+          \"Backup location '%s' does not exist or it is not a directory.\", location));\n+    }\n+\n+    this.backupLocation = dir;\n+    this.topicName = Objects.requireNonNull(topicName, \"topicName\");\n+    this.ticker = Objects.requireNonNull(ticker, \"ticker\");\n+  }\n+\n+  public void initialize() {\n+    replayFile = openOrCreateReplayFile();\n+\n+    try {\n+      latestReplay = replayFile.readRecords();\n+    } catch (final IOException e) {\n+      LOG.warn(\"Failed to read the latest backup from {}. Continue with a new file. Error = {}\",\n+          replayFile.getPath(), e.getMessage());\n+\n+      replayFile = newReplayFile();\n+      latestReplay = Collections.emptyList();\n+    }\n+\n+    latestReplayIdx = 0;\n+    LOG.info(\"Command topic will be backup on file: {}\", replayFile.getPath());\n+  }\n+\n+  public void close() {\n+    try {\n+      replayFile.close();\n+    } catch (final IOException e) {\n+      LOG.warn(\"Failed closing the backup file {}. Error = {}\",\n+          replayFile.getPath(), e.getMessage());\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  BackupReplayFile getReplayFile() {\n+    return replayFile;\n+  }\n+\n+  public void writeRecord(final ConsumerRecord<CommandId, Command> record) {", "originalCommit": "8c8b54c857d38e8c304b5e7c6415063ecfe60c12", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg3NjMwNQ==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455876305", "bodyText": "Done.", "author": "spena", "createdAt": "2020-07-16T15:30:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ0MTA1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ0MTcwNQ==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455441705", "bodyText": "Collections.emptyList will throw an exception if clear gets called on it. While I don't think it's possible for this situation to be hit because latestReplayIdx should never be greater than latestReplay.size() we might want to change this to latestReaply.size() > 0 instead", "author": "agavra", "createdAt": "2020-07-16T00:32:33Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/CommandTopicBackup.java", "diffHunk": "@@ -0,0 +1,210 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.rest.entity.CommandId;\n+import io.confluent.ksql.rest.server.computation.Command;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.Pair;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Backup service that replays the KSQL command_topic to a local file. A new backup file is\n+ * created whenever a new command does not match the actual backup file. Previously replayed\n+ * messages read up to this new command will be written to the new file. This ensures a new\n+ * complete backup of the command_topic is created.\n+ */\n+public class CommandTopicBackup {\n+  private static final Logger LOG = LoggerFactory.getLogger(CommandTopicBackup.class);\n+  private static final Ticker CURRENT_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+  private static final String PREFIX = \"backup_\";\n+\n+  private final File backupLocation;\n+  private final String topicName;\n+  private final Ticker ticker;\n+\n+  private BackupReplayFile replayFile;\n+  private List<Pair<CommandId, Command>> latestReplay;\n+  private int latestReplayIdx;\n+\n+  public CommandTopicBackup(final String location, final String topicName) {\n+    this(location, topicName, CURRENT_MILLIS_TICKER);\n+  }\n+\n+  public CommandTopicBackup(final String location, final String topicName, final Ticker ticker) {\n+    final File dir = new File(Objects.requireNonNull(location, \"location\"));\n+    if (!dir.exists() || !dir.isDirectory()) {\n+      throw new KsqlException(String.format(\n+          \"Backup location '%s' does not exist or it is not a directory.\", location));\n+    }\n+\n+    this.backupLocation = dir;\n+    this.topicName = Objects.requireNonNull(topicName, \"topicName\");\n+    this.ticker = Objects.requireNonNull(ticker, \"ticker\");\n+  }\n+\n+  public void initialize() {\n+    replayFile = openOrCreateReplayFile();\n+\n+    try {\n+      latestReplay = replayFile.readRecords();\n+    } catch (final IOException e) {\n+      LOG.warn(\"Failed to read the latest backup from {}. Continue with a new file. Error = {}\",\n+          replayFile.getPath(), e.getMessage());\n+\n+      replayFile = newReplayFile();\n+      latestReplay = Collections.emptyList();\n+    }\n+\n+    latestReplayIdx = 0;\n+    LOG.info(\"Command topic will be backup on file: {}\", replayFile.getPath());\n+  }\n+\n+  public void close() {\n+    try {\n+      replayFile.close();\n+    } catch (final IOException e) {\n+      LOG.warn(\"Failed closing the backup file {}. Error = {}\",\n+          replayFile.getPath(), e.getMessage());\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  BackupReplayFile getReplayFile() {\n+    return replayFile;\n+  }\n+\n+  public void writeRecord(final ConsumerRecord<CommandId, Command> record) {\n+    if (latestReplayIdx < latestReplay.size()) {\n+      final Pair<CommandId, Command> latestReplayRecord = latestReplay.get(latestReplayIdx);\n+      if (record.key().equals(latestReplayRecord.left)\n+          && record.value().equals(latestReplayRecord.right)) {\n+        // Ignore backup because record was already replayed\n+        latestReplayIdx++;\n+        return;\n+      } else {\n+        LOG.info(\"Previous command topic backup does not match the new command topic data. \"\n+            + \"A new backup file will be created.\");\n+        createNewBackupFile();\n+        LOG.info(\"New backup file created: {}\", replayFile.getPath());\n+      }\n+    } else if (latestReplayIdx > 0) {\n+      // clear latest replay from memory\n+      latestReplay.clear();", "originalCommit": "8c8b54c857d38e8c304b5e7c6415063ecfe60c12", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg3NjM2Mg==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455876362", "bodyText": "Done.", "author": "spena", "createdAt": "2020-07-16T15:31:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ0MTcwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ0MzAzMQ==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455443031", "bodyText": "let's add a test where the command has the newline character (e.g. CREATE STREAM foo (id INT, \"evil \\n field\" INT)...)", "author": "agavra", "createdAt": "2020-07-16T00:37:46Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/BackupReplayFileTest.java", "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import io.confluent.ksql.rest.entity.CommandId;\n+import io.confluent.ksql.rest.server.computation.Command;\n+import io.confluent.ksql.util.Pair;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.runner.RunWith;\n+import org.mockito.junit.MockitoJUnitRunner;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Optional;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class BackupReplayFileTest {\n+  private static final String KEY_VALUE_SEPARATOR = \":\";\n+  private static final String REPLAY_FILE_NAME = \"backup_command_topic_1\";\n+\n+  @Rule\n+  public TemporaryFolder backupLocation = new TemporaryFolder();\n+\n+  private BackupReplayFile replayFile;\n+  private File internalReplayFile;\n+\n+  @Before\n+  public void setup() throws IOException {\n+    internalReplayFile = backupLocation.newFile(REPLAY_FILE_NAME);\n+    replayFile = new BackupReplayFile(internalReplayFile);\n+  }\n+\n+  @Test\n+  public void shouldGetFilePath() {\n+    // When\n+    final String path = replayFile.getPath();\n+\n+    // Then\n+    assertThat(path, is(String.format(\n+        \"%s/%s\", backupLocation.getRoot().getAbsolutePath(), REPLAY_FILE_NAME)));\n+  }\n+\n+  @Test\n+  public void shouldWriteRecordToFile() throws IOException {\n+    // Given\n+    final Pair<CommandId, Command> record = newStreamRecord(\"stream1\");\n+\n+    // When\n+    replayFile.write(record.left, record.right);\n+\n+    // Then\n+    final List<String> commands = Files.readAllLines(internalReplayFile.toPath());\n+    assertThat(commands.size(), is(1));\n+    assertThat(commands.get(0), is(\n+        \"\\\"stream/stream1/create\\\"\" + KEY_VALUE_SEPARATOR\n+            + \"{\\\"statement\\\":\\\"CREATE STREAM stream1 (id INT) WITH (kafka_topic='stream1\\\"}\"\n+    ));\n+  }\n+\n+  @Test\n+  public void shouldWriteListOfRecordsTofile() throws IOException {\n+    // Given\n+    final Pair<CommandId, Command> record1 = newStreamRecord(\"stream1\");\n+    final Pair<CommandId, Command> record2 = newStreamRecord(\"stream2\");\n+\n+    // When\n+    replayFile.write(Arrays.asList(record1, record2));\n+\n+    // Then\n+    final List<String> commands = Files.readAllLines(internalReplayFile.toPath());\n+    assertThat(commands.size(), is(2));\n+    assertThat(commands.get(0), is(\n+        \"\\\"stream/stream1/create\\\"\" + KEY_VALUE_SEPARATOR\n+            + \"{\\\"statement\\\":\\\"CREATE STREAM stream1 (id INT) WITH (kafka_topic='stream1\\\"}\"\n+    ));\n+    assertThat(commands.get(1), is(\n+        \"\\\"stream/stream2/create\\\"\" + KEY_VALUE_SEPARATOR\n+            + \"{\\\"statement\\\":\\\"CREATE STREAM stream2 (id INT) WITH (kafka_topic='stream2\\\"}\"\n+    ));\n+  }\n+\n+  @Test\n+  public void shouldBeEmptyWhenReadAllCommandsFromEmptyFile() throws IOException {\n+    // When\n+    final List<?> commands = replayFile.readRecords();\n+\n+    // Then\n+    assertThat(commands.size(), is(0));\n+  }\n+\n+  @Test\n+  public void shouldReadCommandsFromFile() throws IOException {\n+    // Given\n+    final Pair<CommandId, Command> record1 = newStreamRecord(\"stream1\");\n+    final Pair<CommandId, Command> record2 = newStreamRecord(\"stream2\");\n+    Files.write(internalReplayFile.toPath(),\n+        String.format(\"%s%s%s%n%s%s%s\",\n+            \"\\\"stream/stream1/create\\\"\",\n+            KEY_VALUE_SEPARATOR,\n+            \"{\\\"statement\\\":\\\"CREATE STREAM stream1 (id INT) WITH (kafka_topic='stream1\\\"}\",\n+            \"\\\"stream/stream2/create\\\"\",\n+            KEY_VALUE_SEPARATOR,\n+            \"{\\\"statement\\\":\\\"CREATE STREAM stream2 (id INT) WITH (kafka_topic='stream2\\\"}\"\n+            ).getBytes(StandardCharsets.UTF_8));\n+\n+    // When\n+    final List<Pair<CommandId, Command>> commands = replayFile.readRecords();\n+\n+    // Then\n+    assertThat(commands.size(), is(2));\n+    assertThat(commands.get(0).left, is(record1.left));\n+    assertThat(commands.get(0).right, is(record1.right));\n+    assertThat(commands.get(1).left, is(record2.left));\n+    assertThat(commands.get(1).right, is(record2.right));\n+  }\n+\n+  private Pair<CommandId, Command> newStreamRecord(final String streamName) {\n+    final CommandId commandId = new CommandId(\n+        CommandId.Type.STREAM, streamName, CommandId.Action.CREATE);\n+    final Command command = new Command(\n+        String.format(\"CREATE STREAM %s (id INT) WITH (kafka_topic='%s\", streamName, streamName),", "originalCommit": "8c8b54c857d38e8c304b5e7c6415063ecfe60c12", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg3NjQ1NQ==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455876455", "bodyText": "Done.", "author": "spena", "createdAt": "2020-07-16T15:31:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ0MzAzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ0NDUyNA==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455444524", "bodyText": "can we add a test where the backup file is corrupted and we can't properly read it?", "author": "agavra", "createdAt": "2020-07-16T00:43:37Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/CommandTopicBackupTest.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.rest.entity.CommandId;\n+import io.confluent.ksql.rest.server.computation.Command;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.Pair;\n+import org.apache.kafka.clients.consumer.ConsumerRecord;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnitRunner;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Optional;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.not;\n+import static org.junit.Assert.assertThrows;\n+import static org.mockito.Mockito.when;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class CommandTopicBackupTest {\n+  private static final String COMMAND_TOPIC_NAME = \"command_topic\";\n+\n+  private Pair<CommandId, Command> command1 = newStreamRecord(\"stream1\");\n+  private Pair<CommandId, Command> command2 = newStreamRecord(\"stream2\");\n+  private Pair<CommandId, Command> command3 = newStreamRecord(\"stream3\");\n+\n+  @Mock\n+  private Ticker ticker;\n+\n+  @Rule\n+  public TemporaryFolder backupLocation = new TemporaryFolder();\n+\n+  private CommandTopicBackup commandTopicBackup;\n+\n+  @Before\n+  public void setup() {\n+    commandTopicBackup = new CommandTopicBackup(", "originalCommit": "8c8b54c857d38e8c304b5e7c6415063ecfe60c12", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ0NTE4OA==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455445188", "bodyText": "what's meant by private KSQL directories here?", "author": "rodesai", "createdAt": "2020-07-16T00:46:01Z", "path": "ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConfig.java", "diffHunk": "@@ -290,6 +290,18 @@\n   public static final String KSQL_CREATE_OR_REPLACE_ENABLED_DOC =\n       \"Feature flag for CREATE OR REPLACE\";\n \n+  public static final String KSQL_ENABLE_METASTORE_BACKUP = \"ksql.enable.metastore.backup\";\n+  public static final Boolean KSQL_ENABLE_METASTORE_BACKUP_DEFAULT = false;\n+  public static final String KSQL_ENABLE_METASTORE_BACKUP_DOC = \"Enable the KSQL metastore \"\n+      + \"backup service. The backup replays the KSQL command_topic to a file located in the \"\n+      + \"same KSQL node. By default, the backup files are located in the private KSQL \"", "originalCommit": "8c8b54c857d38e8c304b5e7c6415063ecfe60c12", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ3NDQzMg==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455474432", "bodyText": "I will remove that default. I had in mind a directory inside the directories created by the TGZ package, like /tmp/confluent.XXXX/ksql/backups, but then I thought that is not the case for RPM/DEB packages and Cloud. So I removed the default, and forgot to remove the comment.", "author": "spena", "createdAt": "2020-07-16T02:36:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ0NTE4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg3NjcxMg==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455876712", "bodyText": "Done. Removed comments about private directories.", "author": "spena", "createdAt": "2020-07-16T15:31:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ0NTE4OA=="}], "type": "inlineReview"}, {"oid": "f91953fb4491c36bee764c7676ed8db8f031a938", "url": "https://github.com/confluentinc/ksql/commit/f91953fb4491c36bee764c7676ed8db8f031a938", "message": "feat: metastore backups", "committedDate": "2020-07-16T15:34:37Z", "type": "commit"}, {"oid": "c4357c713ce795e7739e239c41842735e24a601d", "url": "https://github.com/confluentinc/ksql/commit/c4357c713ce795e7739e239c41842735e24a601d", "message": "fix: address 1st PR feedback\n\n- New CommandTopicBackupNoOp to replace Optional parameter\n- Refactor writeRecord() logic that checks if record was replayed before\n- Minor fixes", "committedDate": "2020-07-16T15:43:32Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg5ODA4MQ==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455898081", "bodyText": "I think my concern was more about reading record with new line characters to make sure that File.readLines works properly", "author": "agavra", "createdAt": "2020-07-16T16:02:00Z", "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/BackupReplayFileTest.java", "diffHunk": "@@ -0,0 +1,173 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import io.confluent.ksql.rest.entity.CommandId;\n+import io.confluent.ksql.rest.server.computation.Command;\n+import io.confluent.ksql.util.Pair;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.runner.RunWith;\n+import org.mockito.junit.MockitoJUnitRunner;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Optional;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class BackupReplayFileTest {\n+  private static final String KEY_VALUE_SEPARATOR = \":\";\n+  private static final String REPLAY_FILE_NAME = \"backup_command_topic_1\";\n+\n+  @Rule\n+  public TemporaryFolder backupLocation = new TemporaryFolder();\n+\n+  private BackupReplayFile replayFile;\n+  private File internalReplayFile;\n+\n+  @Before\n+  public void setup() throws IOException {\n+    internalReplayFile = backupLocation.newFile(REPLAY_FILE_NAME);\n+    replayFile = new BackupReplayFile(internalReplayFile);\n+  }\n+\n+  @Test\n+  public void shouldGetFilePath() {\n+    // When\n+    final String path = replayFile.getPath();\n+\n+    // Then\n+    assertThat(path, is(String.format(\n+        \"%s/%s\", backupLocation.getRoot().getAbsolutePath(), REPLAY_FILE_NAME)));\n+  }\n+\n+  @Test\n+  public void shouldWriteRecord() throws IOException {\n+    // Given\n+    final Pair<CommandId, Command> record = newStreamRecord(\"stream1\");\n+\n+    // When\n+    replayFile.write(record.left, record.right);\n+\n+    // Then\n+    final List<String> commands = Files.readAllLines(internalReplayFile.toPath());\n+    assertThat(commands.size(), is(1));\n+    assertThat(commands.get(0), is(\n+        \"\\\"stream/stream1/create\\\"\" + KEY_VALUE_SEPARATOR\n+            + \"{\\\"statement\\\":\\\"CREATE STREAM stream1 (id INT) WITH (kafka_topic='stream1')\\\"}\"\n+    ));\n+  }\n+\n+  @Test\n+  public void shouldWriteListOfRecords() throws IOException {\n+    // Given\n+    final Pair<CommandId, Command> record1 = newStreamRecord(\"stream1\");\n+    final Pair<CommandId, Command> record2 = newStreamRecord(\"stream2\");\n+\n+    // When\n+    replayFile.write(Arrays.asList(record1, record2));\n+\n+    // Then\n+    final List<String> commands = Files.readAllLines(internalReplayFile.toPath());\n+    assertThat(commands.size(), is(2));\n+    assertThat(commands.get(0), is(\n+        \"\\\"stream/stream1/create\\\"\" + KEY_VALUE_SEPARATOR\n+            + \"{\\\"statement\\\":\\\"CREATE STREAM stream1 (id INT) WITH (kafka_topic='stream1')\\\"}\"\n+    ));\n+    assertThat(commands.get(1), is(\n+        \"\\\"stream/stream2/create\\\"\" + KEY_VALUE_SEPARATOR\n+            + \"{\\\"statement\\\":\\\"CREATE STREAM stream2 (id INT) WITH (kafka_topic='stream2')\\\"}\"\n+    ));\n+  }\n+\n+  @Test\n+  public void shouldWriteRecordWithNewLineCharacterInCommand() throws IOException {", "originalCommit": "c4357c713ce795e7739e239c41842735e24a601d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTk1NTE4MQ==", "url": "https://github.com/confluentinc/ksql/pull/5831#discussion_r455955181", "bodyText": "The only way to make it fail is to add a \\n directly in the file, like this:\nfinal String commandWithNewLineChar = \"\\\"stream/stream1/create\\\"\" + KEY_VALUE_SEPARATOR\n        + \"{\\\"statement\\\":\\\"CREATE STREAM stream1 (id\\n INT) WITH (kafka_topic='stream1')\\\"}\";\n\nFiles.write(internalReplayFile.toPath(),\n        commandWithNewLineChar.getBytes(StandardCharsets.UTF_8));\n\nFile.readLines will read the line up to the id\\n. The deserializer fails because the command line is not valid. In these cases, the CommandTopicBackup will catch the error, log it, and create a new backup file as this current one is corrupted.\nI don't think we'll see a scenario with the \\n character like that. Say KSQL supports the \\n, then the backup will write the \\n like the shouldWriteRecordWithNewLineCharacterInCommand, and readLines will work fine. But if a user goes directly to the file and modifies the \\n, and the file gets corrupted, which is expected to fail.", "author": "spena", "createdAt": "2020-07-16T17:33:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg5ODA4MQ=="}], "type": "inlineReview"}, {"oid": "b4b7dabb562a21a6e02db7db0cb78052e5b55c7f", "url": "https://github.com/confluentinc/ksql/commit/b4b7dabb562a21a6e02db7db0cb78052e5b55c7f", "message": "fix: address 1st PR feedback\n\n- New CommandTopicBackupNoOp to replace Optional parameter\n- Refactor writeRecord() logic that checks if record was replayed before\n- Minor fixes", "committedDate": "2020-07-16T16:13:52Z", "type": "commit"}, {"oid": "b4b7dabb562a21a6e02db7db0cb78052e5b55c7f", "url": "https://github.com/confluentinc/ksql/commit/b4b7dabb562a21a6e02db7db0cb78052e5b55c7f", "message": "fix: address 1st PR feedback\n\n- New CommandTopicBackupNoOp to replace Optional parameter\n- Refactor writeRecord() logic that checks if record was replayed before\n- Minor fixes", "committedDate": "2020-07-16T16:13:52Z", "type": "forcePushed"}]}