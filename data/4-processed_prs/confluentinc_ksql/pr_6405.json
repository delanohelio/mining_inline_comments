{"pr_number": 6405, "pr_title": "feat: avoid spurious tombstones in table output", "pr_createdAt": "2020-10-12T12:02:44Z", "pr_url": "https://github.com/confluentinc/ksql/pull/6405", "timeline": [{"oid": "a10e5eb2d83655465608d011e5290218886b18cc", "url": "https://github.com/confluentinc/ksql/commit/a10e5eb2d83655465608d011e5290218886b18cc", "message": "chore: fix master build\n\nAK commit https://github.com/apache/kafka/pull/9156 avoids filters emitting spurious tombstones. This means the sink topic now only receives the records for the two rows that pass the filter, not the other three rows. Hence the `waitForUniqueUserRows` call now only waits for the two records to be produced before running the test.\n\nAdditionally, the name of the test was actually misleading as the logic in `KsqlMaterialization` to filter any records not passing the HAVING clause is actually installed as part of running the SQL in the test case, so those records are filtered from any pull request anyway.", "committedDate": "2020-10-12T12:02:08Z", "type": "commit"}, {"oid": "cc7f1daf712e364ce52310acfda761049ebf62d4", "url": "https://github.com/confluentinc/ksql/commit/cc7f1daf712e364ce52310acfda761049ebf62d4", "message": "feat: avoid supurious tombstones\n\nfixes: fixes: https://github.com/confluentinc/ksql/issues/3558", "committedDate": "2020-10-12T13:31:15Z", "type": "commit"}, {"oid": "fcee2d41efacf01a7816a96cb05e074190fcd143", "url": "https://github.com/confluentinc/ksql/commit/fcee2d41efacf01a7816a96cb05e074190fcd143", "message": "test: updated test & historical plans", "committedDate": "2020-10-12T13:31:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwNDI1NA==", "url": "https://github.com/confluentinc/ksql/pull/6405#discussion_r503304254", "bodyText": "Note: test name and comments were misleading as the extra steps KsqlMaterialization adds to handle the HAVING clause are installed as part of this test.", "author": "big-andy-coates", "createdAt": "2020-10-12T13:41:28Z", "path": "ksqldb-engine/src/test/java/io/confluent/ksql/materialization/ks/KsMaterializationFunctionalTest.java", "diffHunk": "@@ -619,8 +619,9 @@ public void shouldQueryMaterializedTableWithMultipleAggregationColumns() {\n   }\n \n   @Test\n-  public void shouldIgnoreHavingClause() {\n-    // Note: HAVING clause are handled centrally by KsqlMaterialization\n+  public void shouldHandleHavingClause() {\n+    // Note: HAVING clause are handled centrally by KsqlMaterialization. This logic will have been\n+    // installed as part of building the below statement:", "originalCommit": "a10e5eb2d83655465608d011e5290218886b18cc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwNDU4Mw==", "url": "https://github.com/confluentinc/ksql/pull/6405#discussion_r503304583", "bodyText": "The number of expected rows is now reduced as we no longer produce spurious tombstones.", "author": "big-andy-coates", "createdAt": "2020-10-12T13:42:01Z", "path": "ksqldb-engine/src/test/java/io/confluent/ksql/materialization/ks/KsMaterializationFunctionalTest.java", "diffHunk": "@@ -632,7 +633,11 @@ public void shouldIgnoreHavingClause() {\n \n     final LogicalSchema schema = schema(\"COUNT\", SqlTypes.BIGINT);\n \n-    final Map<String, GenericRow> rows = waitForUniqueUserRows(STRING_DESERIALIZER, schema);\n+    final int matches = (int) USER_DATA_PROVIDER.data().values().stream()\n+        .filter(row -> ((Long) row.get(0)) > 2)\n+        .count();\n+\n+    final Map<String, GenericRow> rows = waitForUniqueUserRows(matches, STRING_DESERIALIZER, schema);", "originalCommit": "a10e5eb2d83655465608d011e5290218886b18cc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwNTAyNw==", "url": "https://github.com/confluentinc/ksql/pull/6405#discussion_r503305027", "bodyText": "Get's against the table for filtered out rows should return nothing.", "author": "big-andy-coates", "createdAt": "2020-10-12T13:42:39Z", "path": "ksqldb-engine/src/test/java/io/confluent/ksql/materialization/ks/KsMaterializationFunctionalTest.java", "diffHunk": "@@ -641,16 +646,22 @@ public void shouldIgnoreHavingClause() {\n     final MaterializedTable table = materialization.nonWindowed();\n \n     rows.forEach((rowKey, value) -> {\n+      // Rows passing the HAVING clause:\n       final Struct key = asKeyStruct(rowKey, query.getPhysicalSchema());\n \n-      final Optional<Row> expected = Optional.ofNullable(value)\n-          .map(v -> Row.of(schema, key, v, -1L));\n-\n       final Optional<Row> row = withRetry(() -> table.get(key));\n-      assertThat(row.map(Row::schema), is(expected.map(Row::schema)));\n-      assertThat(row.map(Row::key), is(expected.map(Row::key)));\n-      assertThat(row.map(Row::value), is(expected.map(Row::value)));\n+      assertThat(row.map(Row::schema), is(Optional.of(schema)));\n+      assertThat(row.map(Row::key), is(Optional.of(key)));\n+      assertThat(row.map(Row::value), is(Optional.of(value)));\n     });\n+\n+    USER_DATA_PROVIDER.data().entries().stream()\n+        .filter(e -> !rows.containsKey(e.getKey().getString(\"USERID\")))\n+        .forEach(e -> {\n+          // Rows filtered by the HAVING clause:\n+          final Optional<Row> row = withRetry(() -> table.get(e.getKey()));\n+          assertThat(row, is(Optional.empty()));\n+        });", "originalCommit": "a10e5eb2d83655465608d011e5290218886b18cc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwNjUyOA==", "url": "https://github.com/confluentinc/ksql/pull/6405#discussion_r503306528", "bodyText": "Kafka Streams does not expect the aggregator to mutate its parameters. The streams code is passing in the \"old value\", which ksqlDB was then mutating and returning as the \"new value\". This meant, when then function returned, the old and new values matched.  This is obviously bad!\nCode now takes a copy and mutates that.  There is a perf hit, obviously, but it's unavoidable.", "author": "big-andy-coates", "createdAt": "2020-10-12T13:44:56Z", "path": "ksqldb-execution/src/main/java/io/confluent/ksql/execution/function/udaf/KudafAggregator.java", "diffHunk": "@@ -52,9 +52,11 @@ public KudafAggregator(\n \n   @Override\n   public GenericRow apply(final K k, final GenericRow rowValue, final GenericRow aggRowValue) {\n+    final GenericRow result = GenericRow.fromList(aggRowValue.values());", "originalCommit": "cc7f1daf712e364ce52310acfda761049ebf62d4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NDkwOA==", "url": "https://github.com/confluentinc/ksql/pull/6405#discussion_r503394908", "bodyText": "Not sure I understand -- why did the old code work, in that case? Or did something change on the Streams side recently?", "author": "vcrfxia", "createdAt": "2020-10-12T16:06:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwNjUyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzQwNjM3Ng==", "url": "https://github.com/confluentinc/ksql/pull/6405#discussion_r503406376", "bodyText": "The old code works because we were never enabling the sending of old values. We now do, to avoid the spurious tombstones.", "author": "big-andy-coates", "createdAt": "2020-10-12T16:28:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwNjUyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzQ2Mjc1NQ==", "url": "https://github.com/confluentinc/ksql/pull/6405#discussion_r503462755", "bodyText": "Sorry, still not understanding. What was being sent before, if not the old values? Was this method even being called, previously?", "author": "vcrfxia", "createdAt": "2020-10-12T18:22:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwNjUyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzUwODM4OA==", "url": "https://github.com/confluentinc/ksql/pull/6405#discussion_r503508388", "bodyText": "The processing nodes in the streams topology can optionally include the old/previous value, as well as the new/current value, to child nodes.  This is not on by default.  An upstream change to how table filters is handled means this is now turned on.\nThe streams code for aggregation looks something like:\nV process(K key, Change<V> change) {\n   // Get old value from store:\n   final V oldAgg = store.get(key);\n\n   // Undo any previous value:\n  final T intermediateAgg = value.oldValue != null && oldAgg != null\n    ? remove.apply(key, value.oldValue, oldAgg)\n    : oldAgg;\n\n   // Then add the new value\n   final T newAgg;\n   if (value.newValue != null) {\n       final T initializedAgg = intermediateAgg == null\n         ?  initializer.apply();\n          : intermediateAgg;\n\n       newAgg = add.apply(key, value.newValue, initializedAgg);\n   } else {\n       newAgg = intermediateAgg;\n   }\n\n   // update the store with the new value. & forard\n   store.put(key, newAgg);\n   tupleForwarder.maybeForward(key, newAgg, sendOldValues ? oldAgg : null);\n}\n\nThe two calls: remove.apply(key, value.oldValue, oldAgg) and add.apply(key, value.newValue, initializedAgg) are calling out to ksqlDB code.  If these calls directly mutate the oldAgg or initializedAgg parameters passed, rather than creating copies, then the old and new values forwarded to child nodes will match. i.e. in    tupleForwarder.maybeForward(key, newAgg, sendOldValues ? oldAgg : null), the parameters newAgg and oldAgg will have the same updated value, rather than oldAgg holding the previous value.  This breaks downstream processes, which expect the old and new value.\nPreviously the nodes weren't configured to send old values, so where just sending null for the old value and downstream could handle this correctly.", "author": "big-andy-coates", "createdAt": "2020-10-12T20:07:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwNjUyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMwNjYxNw==", "url": "https://github.com/confluentinc/ksql/pull/6405#discussion_r503306617", "bodyText": "As above.", "author": "big-andy-coates", "createdAt": "2020-10-12T13:45:03Z", "path": "ksqldb-execution/src/main/java/io/confluent/ksql/execution/function/udaf/KudafUndoAggregator.java", "diffHunk": "@@ -51,17 +51,19 @@ public KudafUndoAggregator(\n   @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n   @Override\n   public GenericRow apply(final Struct k, final GenericRow rowValue, final GenericRow aggRowValue) {\n+    final GenericRow result = GenericRow.fromList(aggRowValue.values());", "originalCommit": "cc7f1daf712e364ce52310acfda761049ebf62d4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8bc96c1a5a40aa633d407290c3170f10109f5c84", "url": "https://github.com/confluentinc/ksql/commit/8bc96c1a5a40aa633d407290c3170f10109f5c84", "message": "test: temp disable historical plans that fail", "committedDate": "2020-10-12T16:25:52Z", "type": "commit"}, {"oid": "64480bfe7f7615e31227fbf9c963b488790c9be1", "url": "https://github.com/confluentinc/ksql/commit/64480bfe7f7615e31227fbf9c963b488790c9be1", "message": "test: disable _correct_ tests ;)", "committedDate": "2020-10-12T18:49:41Z", "type": "commit"}]}