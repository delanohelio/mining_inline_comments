{"pr_number": 6700, "pr_title": "docs: docs for AVRO and JSON_SR keys", "pr_createdAt": "2020-12-02T01:16:46Z", "pr_url": "https://github.com/confluentinc/ksql/pull/6700", "timeline": [{"oid": "39931a1a6cc425eb38429e198ea82b07c4672e53", "url": "https://github.com/confluentinc/ksql/commit/39931a1a6cc425eb38429e198ea82b07c4672e53", "message": "docs: docs for AVRO and JSON_SR keys", "committedDate": "2020-12-02T01:15:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg3MjEzMw==", "url": "https://github.com/confluentinc/ksql/pull/6700#discussion_r533872133", "bodyText": "should we also mention FORMAT='AVRO'? I suspect this might be somewhat common", "author": "agavra", "createdAt": "2020-12-02T03:27:03Z", "path": "docs/concepts/schemas.md", "diffHunk": "@@ -141,6 +136,27 @@ time the statement is first executed.\n \r\n #### With a key column\r\n \r\n+The following statement shows how to create a new `pageviews` stream by reading\r\n+from a {{ site.ak }} topic that has Avro-formatted key and message values.\r\n+\r\n+```sql\r\n+CREATE STREAM pageviews WITH (\r\n+    KAFKA_TOPIC='pageviews-avro-topic',\r\n+    KEY_FORMAT='AVRO',\r\n+    VALUE_FORMAT='AVRO'\r", "originalCommit": "39931a1a6cc425eb38429e198ea82b07c4672e53", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDM4ODg5OA==", "url": "https://github.com/confluentinc/ksql/pull/6700#discussion_r534388898", "bodyText": "Were you imagining a tip saying that this is equivalent to simply specifying FORMAT, updating these examples to use FORMAT, or something else? The FORMAT property is documented in https://github.com/confluentinc/ksql/blob/master/docs/developer-guide/ksqldb-reference/create-stream.md (and similar for CT, CSAS, and CTAS) which feels like the more appropriate place to formally introduce it, but I can certainly slip in a mention of it here as well.", "author": "vcrfxia", "createdAt": "2020-12-02T18:28:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg3MjEzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI1NDExMA==", "url": "https://github.com/confluentinc/ksql/pull/6700#discussion_r536254110", "bodyText": "Discussed offline -- leaving this as is for now. Will see if we can consolidate information about keys into a natural place in a subsequent PR.", "author": "vcrfxia", "createdAt": "2020-12-04T17:20:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzg3MjEzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMxMjY2OA==", "url": "https://github.com/confluentinc/ksql/pull/6700#discussion_r534312668", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If declaring a stream or table with a key format that is different from its\n          \n          \n            \n            If you're declaring a stream or table with a key format that's different from its", "author": "JimGalasyn", "createdAt": "2020-12-02T16:37:45Z", "path": "docs/concepts/schemas.md", "diffHunk": "@@ -77,30 +77,25 @@ ksqlDB is [configured to use it](../operate-and-deploy/installation/server-confi\n \r\n Here's what you can do with schema inference in ksqlDB:\r\n \r\n--   Declare streams and tables on {{ site.ak }} topics with supported value formats by using \r\n-    `CREATE STREAM` and `CREATE TABLE` statements, without needing to declare the value columns.\r\n+-   Declare streams and tables on {{ site.ak }} topics with supported key and value formats by using \r\n+    `CREATE STREAM` and `CREATE TABLE` statements, without needing to declare the key and/or value columns.\r\n -   Declare derived views with `CREATE STREAM AS SELECT` and `CREATE TABLE AS SELECT` statements.\r\n     The schema of the view is registered in {{ site.sr }} automatically.\r\n -   Convert data to different formats with `CREATE STREAM AS SELECT` and\r\n     `CREATE TABLE AS SELECT` statements, by declaring the required output\r\n     format in the `WITH` clause. For example, you can convert a stream from\r\n     Avro to JSON.\r\n \r\n-Only the schema of the message *value* can be retrieved from {{ site.sr }}. Message\r\n-*keys* must be compatible with the [`KAFKA` format](../developer-guide/serialization.md#kafka)\r\n-to be accessible within ksqlDB. ksqlDB ignores schemas that have been registered\r\n-for message keys. \r\n-\r\n !!! note\r\n-    Message *keys* in Avro and Protobuf are not supported. If your message keys\r\n+    Message *keys* in Protobuf are not supported. If your message keys\r\n     are in an unsupported format, see [What to do if your key is not set or is in a different format](../developer-guide/syntax-reference.md#what-to-do-if-your-key-is-not-set-or-is-in-a-different-format). \r\n-    JSON message keys can be accessed by defining the key as a single `STRING` value, which will \r\n-    contain the JSON document.\r\n     \r\n-Although ksqlDB doesn't support loading the message key's schema from {{ site.sr }},\r\n-you can provide the key column definition within the `CREATE TABLE` or `CREATE STREAM`\r\n-statement, if the data records are compatible with ksqlDB. This is known as\r\n-_partial schema inference_, because the key schema is provided explicitly.\r\n+If declaring a stream or table with a key format that is different from its\r", "originalCommit": "39931a1a6cc425eb38429e198ea82b07c4672e53", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMxMzA4NQ==", "url": "https://github.com/confluentinc/ksql/pull/6700#discussion_r534313085", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            from m {{ site.sr }}. This is known as _partial schema inference_. To infer value columns\n          \n          \n            \n            from {{ site.sr }}. This is known as _partial schema inference_. To infer value columns", "author": "JimGalasyn", "createdAt": "2020-12-02T16:38:21Z", "path": "docs/concepts/schemas.md", "diffHunk": "@@ -77,30 +77,25 @@ ksqlDB is [configured to use it](../operate-and-deploy/installation/server-confi\n \r\n Here's what you can do with schema inference in ksqlDB:\r\n \r\n--   Declare streams and tables on {{ site.ak }} topics with supported value formats by using \r\n-    `CREATE STREAM` and `CREATE TABLE` statements, without needing to declare the value columns.\r\n+-   Declare streams and tables on {{ site.ak }} topics with supported key and value formats by using \r\n+    `CREATE STREAM` and `CREATE TABLE` statements, without needing to declare the key and/or value columns.\r\n -   Declare derived views with `CREATE STREAM AS SELECT` and `CREATE TABLE AS SELECT` statements.\r\n     The schema of the view is registered in {{ site.sr }} automatically.\r\n -   Convert data to different formats with `CREATE STREAM AS SELECT` and\r\n     `CREATE TABLE AS SELECT` statements, by declaring the required output\r\n     format in the `WITH` clause. For example, you can convert a stream from\r\n     Avro to JSON.\r\n \r\n-Only the schema of the message *value* can be retrieved from {{ site.sr }}. Message\r\n-*keys* must be compatible with the [`KAFKA` format](../developer-guide/serialization.md#kafka)\r\n-to be accessible within ksqlDB. ksqlDB ignores schemas that have been registered\r\n-for message keys. \r\n-\r\n !!! note\r\n-    Message *keys* in Avro and Protobuf are not supported. If your message keys\r\n+    Message *keys* in Protobuf are not supported. If your message keys\r\n     are in an unsupported format, see [What to do if your key is not set or is in a different format](../developer-guide/syntax-reference.md#what-to-do-if-your-key-is-not-set-or-is-in-a-different-format). \r\n-    JSON message keys can be accessed by defining the key as a single `STRING` value, which will \r\n-    contain the JSON document.\r\n     \r\n-Although ksqlDB doesn't support loading the message key's schema from {{ site.sr }},\r\n-you can provide the key column definition within the `CREATE TABLE` or `CREATE STREAM`\r\n-statement, if the data records are compatible with ksqlDB. This is known as\r\n-_partial schema inference_, because the key schema is provided explicitly.\r\n+If declaring a stream or table with a key format that is different from its\r\n+value format, and only one of the two formats supports schema inference,\r\n+you can explicitly provide the columns for the format that does not support schema inference\r\n+while still having ksqlDB load columns for the format that does support schema inference\r\n+from m {{ site.sr }}. This is known as _partial schema inference_. To infer value columns\r", "originalCommit": "39931a1a6cc425eb38429e198ea82b07c4672e53", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d29d7e6b67966d9e93cdc07d0ae4dc793bbb8cc1", "url": "https://github.com/confluentinc/ksql/commit/d29d7e6b67966d9e93cdc07d0ae4dc793bbb8cc1", "message": "chore: feedback", "committedDate": "2020-12-02T19:10:32Z", "type": "commit"}]}