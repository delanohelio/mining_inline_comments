{"pr_number": 5807, "pr_title": "feat: add service to restart failed persistent queries", "pr_createdAt": "2020-07-09T19:43:18Z", "pr_url": "https://github.com/confluentinc/ksql/pull/5807", "timeline": [{"oid": "fba960455d241c91ca985172d9c6216846b5569d", "url": "https://github.com/confluentinc/ksql/commit/fba960455d241c91ca985172d9c6216846b5569d", "message": "feat: add service to restart failed persistent queries", "committedDate": "2020-07-09T19:29:46Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjUyOTY4Nw==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r452529687", "bodyText": "Just wondering, we restart queries that are in NOT_RUNNING state initially. But here, we keep trying for queries that are in ERROR state. Why? How can a restart recover from an error?", "author": "vpapavas", "createdAt": "2020-07-09T22:44:18Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.io.Closeable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final long BASE_WAITING_TIME_MS = 10000;\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlConfig,\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, \"QueryMonitor\")),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlConfig ksqlConfig,\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffMaxMs = ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS);\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    ksqlEngine.getPersistentQueries().stream()\n+        .forEach(query -> {\n+          final QueryId queryId = query.getQueryId();\n+          final KafkaStreams.State queryState = query.getState();\n+\n+          // If the query was restarted previously, check if it needs another restart; or if the\n+          // query is now up and running, then remove it from the restart list.\n+          if (queriesRetries.containsKey(queryId)) {\n+            final RetryEvent retryEvent = queriesRetries.get(queryId);\n+            if (ticker.read() > retryEvent.nextRestartTimeMs()) {\n+              if (queryState == KafkaStreams.State.ERROR) {", "originalCommit": "fba960455d241c91ca985172d9c6216846b5569d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA1MjI2OA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r453052268", "bodyText": "Currently, when a query goes into ERROR state, it stays there forever. There are errors like network latencies or misconfigured topics permissions, etc, that could cause this. In the case of network latencies, for instance, this retry mechanism will keep restarting the query until the network latency issue is gone, thus recovering a query from an error.\nOther user errors such as misconfigured ACLs, can also be restarted until the issue is fixed by the user. The user will wait up to 2min after the fix to see the query running again (after the restart).", "author": "spena", "createdAt": "2020-07-10T20:01:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjUyOTY4Nw=="}], "type": "inlineReview"}, {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "url": "https://github.com/confluentinc/ksql/commit/b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "message": "feat: add service to restart failed persistent queries", "committedDate": "2020-07-10T20:05:25Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg2Njk2NA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r454866964", "bodyText": "This needs to be properly synchronized with the rest of the engine. For example, what happens if the command-runner thread terminates a query while the command runner thread is restarting it?", "author": "rodesai", "createdAt": "2020-07-15T08:03:31Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java", "diffHunk": "@@ -252,6 +258,39 @@ public static boolean isExecutableStatement(final Statement statement) {\n         || statement instanceof Query;\n   }\n \n+  /**\n+   * Resets a query internal KafkaStreams so it can be restarted.\n+   * </p>\n+   * When a KafkaStreams has been stopped, it cannot be started again. To allow a restart,\n+   * the rest creates a new new KafkaStreams with the same topology and configs.\n+   *\n+   * @param queryId the queryId to reset.\n+   */\n+  public void resetQuery(final QueryId queryId) {", "originalCommit": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1NzgyNg==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455457826", "bodyText": "I think if we had this, then treating a restart as register/unregister becomes much safer - and if we do that we can leverage the path for query upgrades and harden it for both the restart case and the true upgrade case", "author": "agavra", "createdAt": "2020-07-16T01:34:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg2Njk2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTI2NDY1Nw==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455264657", "bodyText": "I don't think unregistering/re-registering is the right approach here. This effectively removes the query from the namespace, so for example, a query listing in between unregister and register would fail. Why do we even need to unregister/register? If we could just restart a query (as described below) that would not be required.", "author": "rodesai", "createdAt": "2020-07-15T18:42:14Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java", "diffHunk": "@@ -252,6 +258,39 @@ public static boolean isExecutableStatement(final Statement statement) {\n         || statement instanceof Query;\n   }\n \n+  /**\n+   * Resets a query internal KafkaStreams so it can be restarted.\n+   * </p>\n+   * When a KafkaStreams has been stopped, it cannot be started again. To allow a restart,\n+   * the rest creates a new new KafkaStreams with the same topology and configs.\n+   *\n+   * @param queryId the queryId to reset.\n+   */\n+  public void resetQuery(final QueryId queryId) {\n+    if (primaryContext.getPersistentQueries().containsKey(queryId)) {\n+      final PersistentQueryMetadata query = primaryContext.getPersistentQueries().get(queryId);\n+      if (query.getState() != State.NOT_RUNNING) {\n+        throw new IllegalStateException(\n+            String.format(\"Cannot reset query with application id: %s because is in %s state\",\n+                query.getQueryApplicationId(), query.getState()));\n+      }\n+\n+      // Unregister the query to replace it with a new PersistentQueryMetadata\n+      primaryContext.unregisterQuery(query);", "originalCommit": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTI2OTY3Nw==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455269677", "bodyText": "I'd encapsulate this logic into the query class and add a restart method there.", "author": "rodesai", "createdAt": "2020-07-15T18:51:06Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java", "diffHunk": "@@ -252,6 +258,39 @@ public static boolean isExecutableStatement(final Statement statement) {\n         || statement instanceof Query;\n   }\n \n+  /**\n+   * Resets a query internal KafkaStreams so it can be restarted.\n+   * </p>\n+   * When a KafkaStreams has been stopped, it cannot be started again. To allow a restart,\n+   * the rest creates a new new KafkaStreams with the same topology and configs.\n+   *\n+   * @param queryId the queryId to reset.\n+   */\n+  public void resetQuery(final QueryId queryId) {\n+    if (primaryContext.getPersistentQueries().containsKey(queryId)) {\n+      final PersistentQueryMetadata query = primaryContext.getPersistentQueries().get(queryId);\n+      if (query.getState() != State.NOT_RUNNING) {\n+        throw new IllegalStateException(\n+            String.format(\"Cannot reset query with application id: %s because is in %s state\",\n+                query.getQueryApplicationId(), query.getState()));\n+      }\n+\n+      // Unregister the query to replace it with a new PersistentQueryMetadata\n+      primaryContext.unregisterQuery(query);\n+      // this.unregisterQuery() is called from withing primaryContext.unregisterQuery()\n+\n+      final Topology topology = query.getTopology();", "originalCommit": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU3NDk1Ng==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r456574956", "bodyText": "I initially encapsulated this logic there, but I had a design problem with it. The QueryMetadata accepts a KafkaStreams object which I think should be immutable. If I have a restart command, then I would need to reset the internal KafkaStreams by creating a new one on every restart.\nI was thinking of creating the KafkaStreams inside the QueryMetadata instead of passing it as a parameter, but that KafkaStreams is used by the MaterializationProvider, which is created before constructing the QueryMetadata. Btw, I now need to replace the KafkaStreams from the MaterializationProvider too (see QueryExecutor.buildQuery).\nI need more refactoring on these classes.", "author": "spena", "createdAt": "2020-07-17T17:24:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTI2OTY3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyNjk3NA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r459126974", "bodyText": "@rodesai Done. I encapsulate the logic in a restart() method now.", "author": "spena", "createdAt": "2020-07-22T22:49:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTI2OTY3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1MTY3Nw==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455451677", "bodyText": "I think we should piggy-back on the work in #5766 for query upgrades; we could consider a restart as an upgrade which just upgrades to itself. That way we could reuse the \"replace query\" codepath that I worked on for that - specifically if you call registerQuery with a query with the same ID it will close the old one and register the new one. Also unregister remains private, which I think is an important abstraction detail", "author": "agavra", "createdAt": "2020-07-16T01:11:06Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineContext.java", "diffHunk": "@@ -227,7 +227,7 @@ void registerQuery(final QueryMetadata query) {\n     }\n   }\n \n-  private void unregisterQuery(final QueryMetadata query) {\n+  void unregisterQuery(final QueryMetadata query) {", "originalCommit": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ4NjM1MA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455486350", "bodyText": "Interesting - what would that look like? We'd need some API in QueryMetadata for cloning the existing query. And then we'd pass the cloned query to registerQuery?", "author": "rodesai", "createdAt": "2020-07-16T03:21:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1MTY3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTg5MTU1NA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455891554", "bodyText": "yup, as long as it has the same queryId it would handle replacing (and closing) the old one. the big benefit is that we get to harden both paths with one go (issues such as #5807 (comment) which I didn't think about when implementing query upgrades)", "author": "agavra", "createdAt": "2020-07-16T15:52:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1MTY3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU3MTY5Mw==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r456571693", "bodyText": "I'm not sure if the EngineContext.registerQuery will work @agavra.\nLooking at it, it does two things that should not happen:\n\ncalls oldQuery.close() which cleans-up the state directory (we need to keep this state directory on restarts)\nupdates the metastore source and sink names (it will fail if the source/sink are already registered)\n\nShould the metastore.updateForPersistentQuery() fail in the above case? Can I refactor it to continue if the source and sink are already there?\nI could avoid calling the unregisterQuery to prevent the clean by refactoring the registerQuery to optional clean-up the state directory and do not fail on updating the metastore. One thing, why does the registerQuery closes an old query instead of failing if the queryID is already registered? Shouldn't that be the case like the metastore update?", "author": "spena", "createdAt": "2020-07-17T17:17:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1MTY3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjYwNjA1OA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r456606058", "bodyText": "calls oldQuery.close() which cleans-up the state directory (we need to keep this state directory on restarts)\n\nThis needs to be changed either way (plus the current code calls stop which does the clean up as well as I mentioned below).\n\nupdates the metastore source and sink names (it will fail if the source/sink are already registered)\n\nThat's no longer the case after the query upgrade work is done, as along as you set allowReplace to true\n\nOne thing, why does the registerQuery closes an old query instead of failing if the queryID is already registered? Shouldn't that be the case like the metastore update?\n\nAs with above, this changed with the work for query upgrades", "author": "agavra", "createdAt": "2020-07-17T18:27:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1MTY3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyNjc5MQ==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r459126791", "bodyText": "@agavra I refactored the code and moved the restart to the PersistentQueryMetadata. Instead of unregistering/registering the query or piggyback on the query upgrades, I just made sure to restart the internal Kafka streams.\nI had to refactor some code to make it work, like:\n\nencapsulating the creation of the Kafka streams in the QueryMetadata and PersistentQueryMetadata (for restarts).\nre-create the materialization provider in the PersistentQueryMetadata on restarts.\npass the KafkaStreamsBuilder from the QueryExecutor to the QueryMetadata for building KafkaStreams", "author": "spena", "createdAt": "2020-07-22T22:48:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1MTY3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1MzY1MA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455453650", "bodyText": "instead of having the try/catch around the entire batch should we try/catch each individual query restart? that way if there's some issue causing the very first one to restart we won't just keep trying only the very first one", "author": "agavra", "createdAt": "2020-07-16T01:18:44Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.io.Closeable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final long BASE_WAITING_TIME_MS = 10000;\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlConfig,\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, \"QueryMonitor\")),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlConfig ksqlConfig,\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffMaxMs = ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS);\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    ksqlEngine.getPersistentQueries().stream()\n+        .forEach(query -> {\n+          final QueryId queryId = query.getQueryId();\n+          final KafkaStreams.State queryState = query.getState();\n+\n+          // If the query was restarted previously, check if it needs another restart; or if the\n+          // query is now up and running, then remove it from the restart list.\n+          if (queriesRetries.containsKey(queryId)) {\n+            final RetryEvent retryEvent = queriesRetries.get(queryId);\n+            if (ticker.read() > retryEvent.nextRestartTimeMs()) {\n+              if (queryState == KafkaStreams.State.ERROR) {\n+                // Retry again if it's still in ERROR state\n+                retryEvent.restart();\n+              } else {\n+                // Query is not in ERROR state anymore.\n+                queriesRetries.remove(queryId);\n+              }\n+            }\n+          } else if (queryState == KafkaStreams.State.ERROR) {\n+            // Restart new query in ERROR state, and add it to the list of retries.\n+            final RetryEvent retryEvent = new RetryEvent(\n+                ksqlEngine, queryId, BASE_WAITING_TIME_MS, retryBackoffMaxMs, ticker);\n+\n+            queriesRetries.put(queryId, retryEvent);\n+            retryEvent.restart();\n+          }\n+        });\n+  }\n+\n+  private class Runner implements Runnable {\n+    @Override\n+    public void run() {\n+      LOG.info(\"KSQL query monitor started.\");\n+\n+      while (!closed) {\n+        try {\n+          restartFailedQueries();", "originalCommit": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyNTQxMg==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r459125412", "bodyText": "Done. I added the try/catch in the RetryEvent.", "author": "spena", "createdAt": "2020-07-22T22:44:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1MzY1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1Mzg4Nw==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455453887", "bodyText": "nit: consider using AbstractExecutionThreadService to manage the lifecycle of this class", "author": "agavra", "createdAt": "2020-07-16T01:19:40Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.io.Closeable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {", "originalCommit": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1NTE3NA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455455174", "bodyText": "I don't think we want to be calling stop here - we should introduce a new method to make sure that KafkaStreams.cleanUp() isn't called. If I understand correctly this will actually clean up the state store directory and cause it to restore all of that state from the changelog topic (or expose doClose publicly with a better name).\nI suppose there's a consideration where the error is caused by a corrupted state store (e.g. as was the case with #5673) and cleaning it up might help. We might want to try this after N failed retries.\nthis will also close the state listener, which will remove all of the metrics (which could be problematic for alerting reasons)", "author": "agavra", "createdAt": "2020-07-16T01:24:23Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.io.Closeable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final long BASE_WAITING_TIME_MS = 10000;\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlConfig,\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, \"QueryMonitor\")),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlConfig ksqlConfig,\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffMaxMs = ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS);\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    ksqlEngine.getPersistentQueries().stream()\n+        .forEach(query -> {\n+          final QueryId queryId = query.getQueryId();\n+          final KafkaStreams.State queryState = query.getState();\n+\n+          // If the query was restarted previously, check if it needs another restart; or if the\n+          // query is now up and running, then remove it from the restart list.\n+          if (queriesRetries.containsKey(queryId)) {\n+            final RetryEvent retryEvent = queriesRetries.get(queryId);\n+            if (ticker.read() > retryEvent.nextRestartTimeMs()) {\n+              if (queryState == KafkaStreams.State.ERROR) {\n+                // Retry again if it's still in ERROR state\n+                retryEvent.restart();\n+              } else {\n+                // Query is not in ERROR state anymore.\n+                queriesRetries.remove(queryId);\n+              }\n+            }\n+          } else if (queryState == KafkaStreams.State.ERROR) {\n+            // Restart new query in ERROR state, and add it to the list of retries.\n+            final RetryEvent retryEvent = new RetryEvent(\n+                ksqlEngine, queryId, BASE_WAITING_TIME_MS, retryBackoffMaxMs, ticker);\n+\n+            queriesRetries.put(queryId, retryEvent);\n+            retryEvent.restart();\n+          }\n+        });\n+  }\n+\n+  private class Runner implements Runnable {\n+    @Override\n+    public void run() {\n+      LOG.info(\"KSQL query monitor started.\");\n+\n+      while (!closed) {\n+        try {\n+          restartFailedQueries();\n+        } catch (final Exception e) {\n+          LOG.warn(\"KSQL query monitor found an error attempting to restart failed queries.\", e);\n+        }\n+      }\n+    }\n+  }\n+\n+  static class RetryEvent {\n+    private final KsqlEngine ksqlEngine;\n+    private final QueryId queryId;\n+    private final Ticker ticker;\n+\n+    private int numRetries = 0;\n+    private long waitingTimeMs;\n+    private long expiryTimeMs;\n+    private long retryBackoffMaxMs;\n+    private long baseWaitingTimeMs;\n+\n+    RetryEvent(\n+        final KsqlEngine ksqlEngine,\n+        final QueryId queryId,\n+        final long baseWaitingTimeMs,\n+        final long retryBackoffMaxMs,\n+        final Ticker ticker\n+    ) {\n+      this.ksqlEngine = ksqlEngine;\n+      this.queryId = queryId;\n+      this.ticker = ticker;\n+\n+      this.baseWaitingTimeMs = baseWaitingTimeMs;\n+      this.waitingTimeMs = baseWaitingTimeMs;\n+      this.expiryTimeMs = ticker.read() + baseWaitingTimeMs;\n+      this.retryBackoffMaxMs = retryBackoffMaxMs;\n+    }\n+\n+    public long nextRestartTimeMs() {\n+      return expiryTimeMs;\n+    }\n+\n+    public int getNumRetries() {\n+      return numRetries;\n+    }\n+\n+    public void restart() {\n+      numRetries++;\n+\n+      LOG.info(\"Restarting query {} (attempt #{})\", queryId, numRetries);\n+\n+      // Stop the queryId using the current QueryMetadata\n+      ksqlEngine.getPersistentQuery(queryId).ifPresent(q -> q.stop());", "originalCommit": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyNTIxNw==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r459125217", "bodyText": "I added a new method restart in the PersistentQueryMetadata to handle the close/reset of the KafkaStreams without cleaning it up.", "author": "spena", "createdAt": "2020-07-22T22:44:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1NTE3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1NTc2OQ==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455455769", "bodyText": "what happens if we fail after closing the kafka streams query but before we call reset query? then the kafka streams application will be DEAD or PENDING_SHUTDOWN and we wouldn't try restarting it again. I think we should make sure that this block is transactional - either all of it happens, or none of it happens. That might be a challenge, but I think it's important", "author": "agavra", "createdAt": "2020-07-16T01:26:31Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.io.Closeable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final long BASE_WAITING_TIME_MS = 10000;\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlConfig,\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, \"QueryMonitor\")),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlConfig ksqlConfig,\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffMaxMs = ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS);\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    ksqlEngine.getPersistentQueries().stream()\n+        .forEach(query -> {\n+          final QueryId queryId = query.getQueryId();\n+          final KafkaStreams.State queryState = query.getState();\n+\n+          // If the query was restarted previously, check if it needs another restart; or if the\n+          // query is now up and running, then remove it from the restart list.\n+          if (queriesRetries.containsKey(queryId)) {\n+            final RetryEvent retryEvent = queriesRetries.get(queryId);\n+            if (ticker.read() > retryEvent.nextRestartTimeMs()) {\n+              if (queryState == KafkaStreams.State.ERROR) {\n+                // Retry again if it's still in ERROR state\n+                retryEvent.restart();\n+              } else {\n+                // Query is not in ERROR state anymore.\n+                queriesRetries.remove(queryId);\n+              }\n+            }\n+          } else if (queryState == KafkaStreams.State.ERROR) {\n+            // Restart new query in ERROR state, and add it to the list of retries.\n+            final RetryEvent retryEvent = new RetryEvent(\n+                ksqlEngine, queryId, BASE_WAITING_TIME_MS, retryBackoffMaxMs, ticker);\n+\n+            queriesRetries.put(queryId, retryEvent);\n+            retryEvent.restart();\n+          }\n+        });\n+  }\n+\n+  private class Runner implements Runnable {\n+    @Override\n+    public void run() {\n+      LOG.info(\"KSQL query monitor started.\");\n+\n+      while (!closed) {\n+        try {\n+          restartFailedQueries();\n+        } catch (final Exception e) {\n+          LOG.warn(\"KSQL query monitor found an error attempting to restart failed queries.\", e);\n+        }\n+      }\n+    }\n+  }\n+\n+  static class RetryEvent {\n+    private final KsqlEngine ksqlEngine;\n+    private final QueryId queryId;\n+    private final Ticker ticker;\n+\n+    private int numRetries = 0;\n+    private long waitingTimeMs;\n+    private long expiryTimeMs;\n+    private long retryBackoffMaxMs;\n+    private long baseWaitingTimeMs;\n+\n+    RetryEvent(\n+        final KsqlEngine ksqlEngine,\n+        final QueryId queryId,\n+        final long baseWaitingTimeMs,\n+        final long retryBackoffMaxMs,\n+        final Ticker ticker\n+    ) {\n+      this.ksqlEngine = ksqlEngine;\n+      this.queryId = queryId;\n+      this.ticker = ticker;\n+\n+      this.baseWaitingTimeMs = baseWaitingTimeMs;\n+      this.waitingTimeMs = baseWaitingTimeMs;\n+      this.expiryTimeMs = ticker.read() + baseWaitingTimeMs;\n+      this.retryBackoffMaxMs = retryBackoffMaxMs;\n+    }\n+\n+    public long nextRestartTimeMs() {\n+      return expiryTimeMs;\n+    }\n+\n+    public int getNumRetries() {\n+      return numRetries;\n+    }\n+\n+    public void restart() {\n+      numRetries++;\n+\n+      LOG.info(\"Restarting query {} (attempt #{})\", queryId, numRetries);\n+\n+      // Stop the queryId using the current QueryMetadata\n+      ksqlEngine.getPersistentQuery(queryId).ifPresent(q -> q.stop());\n+\n+      // Reset the internal KafkaStreams query. This creates a new QueryMetadata.\n+      ksqlEngine.resetQuery(queryId);", "originalCommit": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1NzQwNg==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455457406", "bodyText": "can be done in a different PR, but please create a ticket to make sure that we track these in our metrics - it would be good to see - and I think it should also be something that we can expose to the users so they know that they're in a crash-back-off loop", "author": "agavra", "createdAt": "2020-07-16T01:32:22Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.io.Closeable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final long BASE_WAITING_TIME_MS = 10000;\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlConfig,\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, \"QueryMonitor\")),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlConfig ksqlConfig,\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffMaxMs = ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS);\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    ksqlEngine.getPersistentQueries().stream()\n+        .forEach(query -> {\n+          final QueryId queryId = query.getQueryId();\n+          final KafkaStreams.State queryState = query.getState();\n+\n+          // If the query was restarted previously, check if it needs another restart; or if the\n+          // query is now up and running, then remove it from the restart list.\n+          if (queriesRetries.containsKey(queryId)) {\n+            final RetryEvent retryEvent = queriesRetries.get(queryId);\n+            if (ticker.read() > retryEvent.nextRestartTimeMs()) {\n+              if (queryState == KafkaStreams.State.ERROR) {\n+                // Retry again if it's still in ERROR state\n+                retryEvent.restart();\n+              } else {\n+                // Query is not in ERROR state anymore.\n+                queriesRetries.remove(queryId);\n+              }\n+            }\n+          } else if (queryState == KafkaStreams.State.ERROR) {\n+            // Restart new query in ERROR state, and add it to the list of retries.\n+            final RetryEvent retryEvent = new RetryEvent(\n+                ksqlEngine, queryId, BASE_WAITING_TIME_MS, retryBackoffMaxMs, ticker);\n+\n+            queriesRetries.put(queryId, retryEvent);\n+            retryEvent.restart();\n+          }\n+        });\n+  }\n+\n+  private class Runner implements Runnable {\n+    @Override\n+    public void run() {\n+      LOG.info(\"KSQL query monitor started.\");\n+\n+      while (!closed) {\n+        try {\n+          restartFailedQueries();\n+        } catch (final Exception e) {\n+          LOG.warn(\"KSQL query monitor found an error attempting to restart failed queries.\", e);\n+        }\n+      }\n+    }\n+  }\n+\n+  static class RetryEvent {\n+    private final KsqlEngine ksqlEngine;\n+    private final QueryId queryId;\n+    private final Ticker ticker;\n+\n+    private int numRetries = 0;", "originalCommit": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE0NDkwOQ==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r456144909", "bodyText": "do we also want to check what type of error happened? you can get the errors that happened with QueryMetadata#getQueryErrors and they may be classified as USER errors, in which case restarting them is unlikely to help. We can also be conservative and just retry them anyway.", "author": "agavra", "createdAt": "2020-07-17T00:05:32Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.io.Closeable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final long BASE_WAITING_TIME_MS = 10000;\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlConfig,\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, \"QueryMonitor\")),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlConfig ksqlConfig,\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffMaxMs = ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS);\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    ksqlEngine.getPersistentQueries().stream()\n+        .forEach(query -> {\n+          final QueryId queryId = query.getQueryId();\n+          final KafkaStreams.State queryState = query.getState();\n+\n+          // If the query was restarted previously, check if it needs another restart; or if the\n+          // query is now up and running, then remove it from the restart list.\n+          if (queriesRetries.containsKey(queryId)) {\n+            final RetryEvent retryEvent = queriesRetries.get(queryId);\n+            if (ticker.read() > retryEvent.nextRestartTimeMs()) {\n+              if (queryState == KafkaStreams.State.ERROR) {\n+                // Retry again if it's still in ERROR state\n+                retryEvent.restart();", "originalCommit": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU3NjIwNg==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r456576206", "bodyText": "That was the idea initially. @rodesai has a different opinion that retrying user errors might help users fixing their issues and let ksql restart the query a few minutes later. But users might just re-create them manually.", "author": "spena", "createdAt": "2020-07-17T17:26:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE0NDkwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjU4NTQzMQ==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r456585431", "bodyText": "I had the following reasons:\n\nWe currently don't provide users a way to restart queries via the API/UI\nWe might mis-categorize a system error as a user error\nI don't see a downside to just retrying them internally", "author": "rodesai", "createdAt": "2020-07-17T17:45:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE0NDkwOQ=="}], "type": "inlineReview"}, {"oid": "c82776c90bfd25662b22ba8c00794ca5162e0513", "url": "https://github.com/confluentinc/ksql/commit/c82776c90bfd25662b22ba8c00794ca5162e0513", "message": "fix: address 1st round of reviews", "committedDate": "2020-07-22T22:41:28Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyNzUzOA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r459127538", "bodyText": "I added a few MS sleep just to not keep walking through the failed queries too often.", "author": "spena", "createdAt": "2020-07-22T22:50:52Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -137,10 +151,12 @@ public void run() {\n       LOG.info(\"KSQL query monitor started.\");\n \n       while (!closed) {\n+        restartFailedQueries();\n+\n         try {\n-          restartFailedQueries();\n+          Thread.sleep(500);", "originalCommit": "c82776c90bfd25662b22ba8c00794ca5162e0513", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk3NTM0NA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r461975344", "bodyText": "nit: move this block to its own method called something like maybeRestartQuery", "author": "rodesai", "createdAt": "2020-07-29T00:52:19Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import io.confluent.ksql.util.QueryMetadata;\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffInitialMs;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, QueryMonitor.class.getName())),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_INITIAL_MS),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final long retryBackoffInitialMs,\n+      final long retryBackoffMaxMs,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffInitialMs = retryBackoffInitialMs;\n+    this.retryBackoffMaxMs = retryBackoffMaxMs;\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    // Collect a list of new queries in ERROR state\n+    ksqlEngine.getPersistentQueries().stream()\n+        .filter(query -> query.getState() == KafkaStreams.State.ERROR)\n+        .filter(query -> !queriesRetries.containsKey(query.getQueryId()))\n+        .map(QueryMetadata::getQueryId)\n+        .forEach(queryId -> queriesRetries.put(queryId, newRetryEvent(queryId)));\n+\n+    // Restart queries that has passed the waiting timeout\n+    final List<QueryId> deleteRetryEvents = new ArrayList<>();\n+    queriesRetries.entrySet().stream()\n+        .forEach(mapEntry -> {\n+          final QueryId queryId = mapEntry.getKey();", "originalCommit": "c82776c90bfd25662b22ba8c00794ca5162e0513", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYwOTk1Mg==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r462609952", "bodyText": "Done.", "author": "spena", "createdAt": "2020-07-29T21:49:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk3NTM0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk3NjE5NQ==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r461976195", "bodyText": "kind fo nit: we may want some threshold here, otherwise it's possible we will never apply any backoff if it takes a long time to hit a given error. Basically there are 2 intervals we care about:\n\nthe next time we retry (retryEvent.nextRetsartTimeMs)\nhow long a query is up and running before which we stamp it as \"healthy\". Currently we're just using 2x however long we waited last time. Which is maybe ok - but let's make that more explicit in the code by adding a method to retryEvent like queryHealthyTime and making sure the query is not in ERROR state after whatever that returns. They we can possibly make that configurable in a follow up.", "author": "rodesai", "createdAt": "2020-07-29T00:55:40Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import io.confluent.ksql.util.QueryMetadata;\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffInitialMs;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, QueryMonitor.class.getName())),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_INITIAL_MS),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final long retryBackoffInitialMs,\n+      final long retryBackoffMaxMs,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffInitialMs = retryBackoffInitialMs;\n+    this.retryBackoffMaxMs = retryBackoffMaxMs;\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    // Collect a list of new queries in ERROR state\n+    ksqlEngine.getPersistentQueries().stream()\n+        .filter(query -> query.getState() == KafkaStreams.State.ERROR)\n+        .filter(query -> !queriesRetries.containsKey(query.getQueryId()))\n+        .map(QueryMetadata::getQueryId)\n+        .forEach(queryId -> queriesRetries.put(queryId, newRetryEvent(queryId)));\n+\n+    // Restart queries that has passed the waiting timeout\n+    final List<QueryId> deleteRetryEvents = new ArrayList<>();\n+    queriesRetries.entrySet().stream()\n+        .forEach(mapEntry -> {\n+          final QueryId queryId = mapEntry.getKey();\n+          final RetryEvent retryEvent = mapEntry.getValue();\n+          final Optional<PersistentQueryMetadata> query = ksqlEngine.getPersistentQuery(queryId);\n+\n+          // Query was terminated manually if no present\n+          if (!query.isPresent()) {\n+            deleteRetryEvents.add(queryId);\n+          } else if (ticker.read() > retryEvent.nextRestartTimeMs()) {\n+            if (query.get().getState() == KafkaStreams.State.ERROR) {\n+              // Retry again if it's still in ERROR state\n+              retryEvent.restart();\n+            } else {", "originalCommit": "c82776c90bfd25662b22ba8c00794ca5162e0513", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYxNTgwOA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r462615808", "bodyText": "I don't understand the queryHealthyTime part. The QueryMonitor isn't stamping queries as healthy. It is just restarting them. Or do you want to keep the queryErrors and numRetries during the queryHealthyTime in case the query is in ERROR state again after the backoff period has passed but before the query healthy time?\nBtw, I saw in the query error handling docs and it says that we might change the state of the query to RUNNING once it has passed the healthy time. Can we change this logic once that's implemented?", "author": "spena", "createdAt": "2020-07-29T22:02:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk3NjE5NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY1NzMzNA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r462657334", "bodyText": "Can we change this logic once that's implemented?\n\nSure - I was just suggesting a minor refactor to make the distinction between the thresholds more clear. So instead of:\n         if (!query.isPresent()) {\n            deleteRetryEvents.add(queryId);\n          } else if (ticker.read() > retryEvent.nextRestartTimeMs() && query.get().getState() == KafkaStreams.State.ERROR) {\n              // Retry again if it's still in ERROR state\n              retryEvent.restart();\n           } else if (ticker.read() > retryEvent.queryHealthyTime()) {\n                query.ifPresent(QueryMetadata::clearErrors);\n               deleteRetryEvents.add(queryId);\n           }\n\nwhere queryHealthyTime just returns the same value as nextRestartTimeMs for now. Just a suggestion.", "author": "rodesai", "createdAt": "2020-07-30T00:02:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk3NjE5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk3NjQ4Mw==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r461976483", "bodyText": "nit: this seems like a long initial wait. Maybe 15 or 30 seconds to start with?", "author": "rodesai", "createdAt": "2020-07-29T00:56:44Z", "path": "ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConfig.java", "diffHunk": "@@ -308,6 +308,17 @@\n   public static final String KSQL_SUPPRESS_ENABLED_DOC =\n       \"Feature flag for suppression, specifically EMIT FINAL\";\n \n+  public static final String KSQL_QUERY_RETRY_BACKOFF_INITIAL_MS\n+      = \"ksql.query.retry.backoff.initial.ms\";\n+  public static final Long KSQL_QUERY_RETRY_BACKOFF_INITIAL_MS_DEFAULT = 60000L;", "originalCommit": "c82776c90bfd25662b22ba8c00794ca5162e0513", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYwOTg4Mg==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r462609882", "bodyText": "Done. Lower it to 30secs.", "author": "spena", "createdAt": "2020-07-29T21:49:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk3NjQ4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk3Nzg3Mg==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r461977872", "bodyText": "we don't want to clear errors here, right? Otherwise when in a retry loop we may not actually return any errors back. I think it would be better to accumulate them (up to a certain size/time bound)", "author": "rodesai", "createdAt": "2020-07-29T01:02:19Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/util/QueryMetadata.java", "diffHunk": "@@ -208,6 +217,37 @@ public KsqlQueryType getQueryType() {\n     return KsqlQueryType.PERSISTENT;\n   }\n \n+  public String getTopologyDescription() {\n+    return topology.describe().toString();\n+  }\n+\n+  public List<QueryError> getQueryErrors() {\n+    return ImmutableList.copyOf(queryErrors);\n+  }\n+\n+  protected boolean isClosed() {\n+    return closed;\n+  }\n+\n+  protected KafkaStreams getKafkaStreams() {\n+    return kafkaStreams;\n+  }\n+\n+  protected void resetKafkaStreams(final KafkaStreams kafkaStreams) {\n+    this.kafkaStreams = kafkaStreams;\n+    queryErrors.clear();", "originalCommit": "c82776c90bfd25662b22ba8c00794ca5162e0513", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYwOTAyNg==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r462609026", "bodyText": "Done.\nI added a change in the QueryMetadata to replace the Set with an EvictionQueue that has a max. size. The max. size is configurable with ksql.query.error.max.queue.size (default: 10).\nI'm not sure if we need the Set just to avoid repeatable error messages. Perhaps is useful if we keep every error reported after every restart even if they're the same?\nThis error queue is cleared on the QueryMonitor after the retry waiting time expires. I still don't know why we would like to keep the errors for a longer period,. I see keeping them during the duration of the retry waiting period useful.", "author": "spena", "createdAt": "2020-07-29T21:47:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk3Nzg3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjY1NTI5MA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r462655290", "bodyText": "I agree a Set doesn't make sense. It's useful to be able to see all the errors and when they occurred.", "author": "rodesai", "createdAt": "2020-07-29T23:56:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk3Nzg3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk4MzUzOA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r461983538", "bodyText": "we should add a test case to ensure that the query monitor deals with terminated queries correctly.", "author": "rodesai", "createdAt": "2020-07-29T01:24:19Z", "path": "ksqldb-engine/src/test/java/io/confluent/ksql/engine/QueryMonitorTest.java", "diffHunk": "@@ -0,0 +1,245 @@\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.InOrder;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnitRunner;\n+\n+import java.util.Arrays;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+\n+import static org.apache.kafka.streams.KafkaStreams.State.ERROR;\n+import static org.apache.kafka.streams.KafkaStreams.State.RUNNING;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyLong;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.inOrder;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.never;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class QueryMonitorTest {", "originalCommit": "c82776c90bfd25662b22ba8c00794ca5162e0513", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjYwNzgyNA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r462607824", "bodyText": "Done. shouldNoRestartQueryThatWasManuallyTerminated", "author": "spena", "createdAt": "2020-07-29T21:44:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk4MzUzOA=="}], "type": "inlineReview"}, {"oid": "66440ee6d27457b7def7408fa1e70ad4ca85a67d", "url": "https://github.com/confluentinc/ksql/commit/66440ee6d27457b7def7408fa1e70ad4ca85a67d", "message": "fix: 2nd round of feedback", "committedDate": "2020-07-29T21:42:35Z", "type": "forcePushed"}, {"oid": "2160b820a5eec74fc4996ff9e378ebedf7ec8e2d", "url": "https://github.com/confluentinc/ksql/commit/2160b820a5eec74fc4996ff9e378ebedf7ec8e2d", "message": "fix: 2nd round of feedback", "committedDate": "2020-07-29T21:44:09Z", "type": "forcePushed"}, {"oid": "82b6fd6d4901dc39a6f24089f75d741a53a19ea2", "url": "https://github.com/confluentinc/ksql/commit/82b6fd6d4901dc39a6f24089f75d741a53a19ea2", "message": "feat: add service to restart failed persistent queries", "committedDate": "2020-07-31T17:36:23Z", "type": "commit"}, {"oid": "88bb6d76c8e072879269942167744f2d90e126ba", "url": "https://github.com/confluentinc/ksql/commit/88bb6d76c8e072879269942167744f2d90e126ba", "message": "feat: add retry.initial.backoff.ms config + increase max. time", "committedDate": "2020-07-31T17:36:23Z", "type": "commit"}, {"oid": "c41fad9525ba2b4fc0f99c0251134c01d43c2725", "url": "https://github.com/confluentinc/ksql/commit/c41fad9525ba2b4fc0f99c0251134c01d43c2725", "message": "refactor: wrap 3 sink params into 1 DataSource in PersistentQueryMetadata", "committedDate": "2020-07-31T17:36:23Z", "type": "commit"}, {"oid": "a2a39318eff4af7836b69cc692e1cee8c27f0d98", "url": "https://github.com/confluentinc/ksql/commit/a2a39318eff4af7836b69cc692e1cee8c27f0d98", "message": "fix: address 1st round of reviews", "committedDate": "2020-07-31T17:36:23Z", "type": "commit"}, {"oid": "b0fd58f1c04149ab1916c11e3e8e070b05a29bd5", "url": "https://github.com/confluentinc/ksql/commit/b0fd58f1c04149ab1916c11e3e8e070b05a29bd5", "message": "fix: 2nd round of feedback", "committedDate": "2020-07-31T17:39:03Z", "type": "commit"}, {"oid": "7cec7b98d26dccd7246089cc35ce156d7f74c10f", "url": "https://github.com/confluentinc/ksql/commit/7cec7b98d26dccd7246089cc35ce156d7f74c10f", "message": "chore: add queryHealthyTime() to RetryEvent", "committedDate": "2020-07-31T17:49:38Z", "type": "commit"}, {"oid": "7cec7b98d26dccd7246089cc35ce156d7f74c10f", "url": "https://github.com/confluentinc/ksql/commit/7cec7b98d26dccd7246089cc35ce156d7f74c10f", "message": "chore: add queryHealthyTime() to RetryEvent", "committedDate": "2020-07-31T17:49:38Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc1MjU3MQ==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r463752571", "bodyText": "i think InterruptedException is the only valid exception here, which we should catch and respect", "author": "agavra", "createdAt": "2020-07-31T17:59:39Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import io.confluent.ksql.util.QueryMetadata;\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffInitialMs;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, QueryMonitor.class.getName())),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_INITIAL_MS),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final long retryBackoffInitialMs,\n+      final long retryBackoffMaxMs,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffInitialMs = retryBackoffInitialMs;\n+    this.retryBackoffMaxMs = retryBackoffMaxMs;\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    // Collect a list of new queries in ERROR state\n+    ksqlEngine.getPersistentQueries().stream()\n+        .filter(QueryMetadata::isError)\n+        .filter(query -> !queriesRetries.containsKey(query.getQueryId()))\n+        .map(QueryMetadata::getQueryId)\n+        .forEach(queryId -> queriesRetries.put(queryId, newRetryEvent(queryId)));\n+\n+    maybeRestartQueries();\n+  }\n+\n+  private void maybeRestartQueries() {\n+    final long now = ticker.read();\n+\n+    // Restart queries that has passed the waiting timeout\n+    final List<QueryId> deleteRetryEvents = new ArrayList<>();\n+    queriesRetries.entrySet().stream()\n+        .forEach(mapEntry -> {\n+          final QueryId queryId = mapEntry.getKey();\n+          final RetryEvent retryEvent = mapEntry.getValue();\n+          final Optional<PersistentQueryMetadata> query = ksqlEngine.getPersistentQuery(queryId);\n+\n+          // Query was terminated manually if no present\n+          if (!query.isPresent()) {\n+            deleteRetryEvents.add(queryId);\n+          } else if (query.get().isError() && now > retryEvent.nextRestartTimeMs()) {\n+            // Retry again if it's still in ERROR state\n+            retryEvent.restart();\n+          } else if (now > retryEvent.queryHealthyTime()) {\n+            // Clean the errors queue & delete the query from future retries now the query is\n+            // healthy\n+            query.ifPresent(QueryMetadata::clearErrors);\n+            deleteRetryEvents.add(queryId);\n+          }\n+        });\n+\n+    deleteRetryEvents.stream().forEach(queriesRetries::remove);\n+  }\n+\n+  private RetryEvent newRetryEvent(final QueryId queryId) {\n+    return new RetryEvent(ksqlEngine, queryId, retryBackoffInitialMs, retryBackoffMaxMs, ticker);\n+  }\n+\n+  private class Runner implements Runnable {\n+    @Override\n+    public void run() {\n+      LOG.info(\"KSQL query monitor started.\");\n+\n+      while (!closed) {\n+        restartFailedQueries();\n+\n+        try {\n+          Thread.sleep(500);\n+        } catch (final Exception e) {\n+          // ignore.", "originalCommit": "7cec7b98d26dccd7246089cc35ce156d7f74c10f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg1MjI0Nw==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r463852247", "bodyText": "Done", "author": "spena", "createdAt": "2020-07-31T21:21:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc1MjU3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc1OTYwOA==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r463759608", "bodyText": "might be good to add a summary log line here (e.g. restarted queries [X, Y], marked queries [Z] as healthy, could not find queries [A])", "author": "agavra", "createdAt": "2020-07-31T18:14:52Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import io.confluent.ksql.util.QueryMetadata;\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffInitialMs;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, QueryMonitor.class.getName())),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_INITIAL_MS),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final long retryBackoffInitialMs,\n+      final long retryBackoffMaxMs,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffInitialMs = retryBackoffInitialMs;\n+    this.retryBackoffMaxMs = retryBackoffMaxMs;\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    // Collect a list of new queries in ERROR state\n+    ksqlEngine.getPersistentQueries().stream()\n+        .filter(QueryMetadata::isError)\n+        .filter(query -> !queriesRetries.containsKey(query.getQueryId()))\n+        .map(QueryMetadata::getQueryId)\n+        .forEach(queryId -> queriesRetries.put(queryId, newRetryEvent(queryId)));\n+\n+    maybeRestartQueries();\n+  }\n+\n+  private void maybeRestartQueries() {\n+    final long now = ticker.read();\n+\n+    // Restart queries that has passed the waiting timeout\n+    final List<QueryId> deleteRetryEvents = new ArrayList<>();\n+    queriesRetries.entrySet().stream()\n+        .forEach(mapEntry -> {\n+          final QueryId queryId = mapEntry.getKey();\n+          final RetryEvent retryEvent = mapEntry.getValue();\n+          final Optional<PersistentQueryMetadata> query = ksqlEngine.getPersistentQuery(queryId);\n+\n+          // Query was terminated manually if no present\n+          if (!query.isPresent()) {\n+            deleteRetryEvents.add(queryId);\n+          } else if (query.get().isError() && now > retryEvent.nextRestartTimeMs()) {\n+            // Retry again if it's still in ERROR state\n+            retryEvent.restart();\n+          } else if (now > retryEvent.queryHealthyTime()) {\n+            // Clean the errors queue & delete the query from future retries now the query is\n+            // healthy\n+            query.ifPresent(QueryMetadata::clearErrors);\n+            deleteRetryEvents.add(queryId);\n+          }\n+        });\n+\n+    deleteRetryEvents.stream().forEach(queriesRetries::remove);", "originalCommit": "7cec7b98d26dccd7246089cc35ce156d7f74c10f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc2MzA2Ng==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r463763066", "bodyText": "we might want to make restart return something and just have the getPersistentQuery(queryId) call inside restart so that we don't have a race which would cause the lookup below to return something different (e.g. in the case of deletions or query upgrade) than what's here", "author": "agavra", "createdAt": "2020-07-31T18:22:26Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import io.confluent.ksql.util.QueryMetadata;\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffInitialMs;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, QueryMonitor.class.getName())),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_INITIAL_MS),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final long retryBackoffInitialMs,\n+      final long retryBackoffMaxMs,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffInitialMs = retryBackoffInitialMs;\n+    this.retryBackoffMaxMs = retryBackoffMaxMs;\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    // Collect a list of new queries in ERROR state\n+    ksqlEngine.getPersistentQueries().stream()\n+        .filter(QueryMetadata::isError)\n+        .filter(query -> !queriesRetries.containsKey(query.getQueryId()))\n+        .map(QueryMetadata::getQueryId)\n+        .forEach(queryId -> queriesRetries.put(queryId, newRetryEvent(queryId)));\n+\n+    maybeRestartQueries();\n+  }\n+\n+  private void maybeRestartQueries() {\n+    final long now = ticker.read();\n+\n+    // Restart queries that has passed the waiting timeout\n+    final List<QueryId> deleteRetryEvents = new ArrayList<>();\n+    queriesRetries.entrySet().stream()\n+        .forEach(mapEntry -> {\n+          final QueryId queryId = mapEntry.getKey();\n+          final RetryEvent retryEvent = mapEntry.getValue();\n+          final Optional<PersistentQueryMetadata> query = ksqlEngine.getPersistentQuery(queryId);\n+\n+          // Query was terminated manually if no present\n+          if (!query.isPresent()) {\n+            deleteRetryEvents.add(queryId);", "originalCommit": "7cec7b98d26dccd7246089cc35ce156d7f74c10f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDUxNjc1Mw==", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r464516753", "bodyText": "I will fix this in a follow-up.\nI identified a non-problematic issue that I want to fix, so will do both in another PR + more logging.", "author": "spena", "createdAt": "2020-08-03T16:16:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc2MzA2Ng=="}], "type": "inlineReview"}, {"oid": "0abdf8efd7ee58e7ee4c0d9b2fba7fbc67ad50d0", "url": "https://github.com/confluentinc/ksql/commit/0abdf8efd7ee58e7ee4c0d9b2fba7fbc67ad50d0", "message": "chore: stop QueryMonitor if Thread.sleep is interrupted", "committedDate": "2020-07-31T21:20:27Z", "type": "commit"}]}