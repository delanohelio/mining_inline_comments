{"pr_number": 6375, "pr_title": "feat: Implement a physical plan builder and physical plan for pull queries", "pr_createdAt": "2020-10-07T20:43:22Z", "pr_url": "https://github.com/confluentinc/ksql/pull/6375", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwNDAzOA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502704038", "bodyText": "Can you genericize this so that you don't have to return Object?", "author": "AlanConfluent", "createdAt": "2020-10-09T22:54:24Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+public abstract class AbstractPhysicalOperator {\n+\n+  public abstract void open();\n+\n+  // Scan returns TableRow, Project returns List<List<?>>", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcyMjE2OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502722169", "bodyText": "Unfortunately, I haven't found a better way since two different operators need to return each TableRow and the other List<List<?>>", "author": "vpapavas", "createdAt": "2020-10-10T00:35:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwNDAzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwNzA3NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502707074", "bodyText": "So we're just using the existing, unchanged LogicalPlanner to begin with?  Looking through it, it probably handles the basic logical nodes we would want.  I can see us doing more of our analysis and error checking there (e.g. not more than one key comparison for pull queries, etc. rather than doing it in the physical planner since that seems too far downstream).   If we handle more complex operations in the future, we'd obviously want to have a logical component.", "author": "AlanConfluent", "createdAt": "2020-10-09T23:08:05Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -221,6 +314,41 @@ private ExecutorPlans planQuery(\n     return new ExecutorPlans(logicalPlan, physicalPlan);\n   }\n \n+  private LogicalPlanNode buildAndValidateLogicalPlan(\n+      final ConfiguredStatement<?> statement,\n+      final ImmutableAnalysis analysis,\n+      final KsqlConfig config\n+  ) {\n+    final OutputNode outputNode = new LogicalPlanner(config, analysis, engineContext.getMetaStore())", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcyMjQwMQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502722401", "bodyText": "Yes. The logical plan nodes are there but they all have AST expressions and miss the analysis that is done for instance in the PhysicalPlanBuilder. A lot of that code in there should be moved to the logical plan", "author": "vpapavas", "createdAt": "2020-10-10T00:37:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwNzA3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwNzQ5OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502707499", "bodyText": "Maybe pull this out to its own class?", "author": "AlanConfluent", "createdAt": "2020-10-09T23:10:05Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -403,4 +531,66 @@ private String buildPlanSummary(final QueryId queryId, final ExecutionStep<?> pl\n     return new PlanSummary(queryId, config.getConfig(false), engineContext.getMetaStore())\n         .summarize(plan);\n   }\n+\n+  private static final class ColumnReferenceRewriter\n+      extends VisitParentExpressionVisitor<Optional<Expression>, Context<Void>> {\n+\n+    private ColumnReferenceRewriter() {\n+      super(Optional.empty());\n+    }\n+\n+    @Override\n+    public Optional<Expression> visitQualifiedColumnReference(\n+        final QualifiedColumnReferenceExp node,\n+        final Context<Void> ctx\n+    ) {\n+      return Optional.of(new UnqualifiedColumnReferenceExp(node.getColumnName()));\n+    }\n+  }\n+\n+  private static final class ConfigRoutingOptions implements RoutingOptions {", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc2MDgyNg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r505760826", "bodyText": "+1", "author": "guozhangwang", "createdAt": "2020-10-15T18:39:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwNzQ5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwOTAwNw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502709007", "bodyText": "Is this not the type of logic that would live in the logical planner? Or at least in buildAndValidateLogicalPlan", "author": "AlanConfluent", "createdAt": "2020-10-09T23:17:20Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -118,6 +139,78 @@ ExecuteResult execute(final KsqlPlan plan) {\n     return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n   }\n \n+  PullQueryResult executePullQuery(\n+      final KsqlExecutionContext ksqlEngine,\n+      final ConfiguredStatement<Query> statement,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final Map<String, Object> requestProperties,\n+      final Optional<Boolean> isInternalRequest,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    if (!statement.getStatement().isPullQuery()) {\n+      throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n+    }\n+    final SessionConfig sessionConfig = statement.getSessionConfig();\n+    if (!sessionConfig.getConfig(false)\n+        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n+      throw new KsqlStatementException(\n+          \"Pull queries are disabled.\"\n+              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n+              + System.lineSeparator()\n+              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n+              + \"this feature.\",\n+          statement.getStatementText());\n+    }\n+\n+    final RoutingOptions routingOptions = new ConfigRoutingOptions(\n+        sessionConfig.getConfig(true),\n+        requestProperties\n+    );\n+    final RateLimiter rateLimiter = RateLimiter.create(sessionConfig.getConfig(true).getInt(\n+        KsqlConfig.KSQL_QUERY_PULL_MAX_QPS_CONFIG));\n+    // If internal listeners are in use, we require the request to come from that listener to\n+    // treat it as having been forwarded.\n+    final boolean isAlreadyForwarded = routingOptions.skipForwardRequest()\n+        // Trust the forward request option if isInternalRequest isn't available.\n+        && isInternalRequest.orElse(true);\n+\n+    // Only check the rate limit at the forwarding host\n+    if (!isAlreadyForwarded) {\n+      checkRateLimit(rateLimiter);\n+    }\n+\n+\n+    try {\n+      final QueryAnalyzer queryAnalyzer = new QueryAnalyzer(engineContext.getMetaStore(), \"\");\n+      final ImmutableAnalysis analysis = new RewrittenAnalysis(\n+          queryAnalyzer.analyze(statement.getStatement(), Optional.empty()),\n+          new ColumnReferenceRewriter()::process\n+      );", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcyMzE3Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502723176", "bodyText": "The analyzer is a different step from the logical plan.", "author": "vpapavas", "createdAt": "2020-10-10T00:44:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwOTAwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc1OTgwNQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r505759805", "bodyText": "I thought the plan is to have a single code path for logical plans across all queries. But this new function is only for pull queries, whereas for other queries we are still using QueryEngine#buildQueryLogicalPlan.", "author": "guozhangwang", "createdAt": "2020-10-15T18:37:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwOTAwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc2ODI2NQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r509768265", "bodyText": "Yes but they are doing the same thing with respect to the logical planner i.e. calling the same methods to build the logical plan. The difference is in the Analyzer where for pull queries there is something different done, that's why I had to create a new method. The analyzer part will be cleaned up in a later PR once we get more clarity about what we need from push queries as well.", "author": "vpapavas", "createdAt": "2020-10-21T22:37:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwOTAwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwOTcwOA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502709708", "bodyText": "This analysis exposes all of the parser expressions.  Isn't that something that should be at the logical planner layer?  I would assume that the physical planner would take some logical nodes which have all of the relevant data extracted from the expressions.\nMaybe this is just a first step, and there's still some intermixing of layers, but I just thought I would ask.", "author": "AlanConfluent", "createdAt": "2020-10-09T23:20:43Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -221,6 +314,41 @@ private ExecutorPlans planQuery(\n     return new ExecutorPlans(logicalPlan, physicalPlan);\n   }\n \n+  private LogicalPlanNode buildAndValidateLogicalPlan(\n+      final ConfiguredStatement<?> statement,\n+      final ImmutableAnalysis analysis,\n+      final KsqlConfig config\n+  ) {\n+    final OutputNode outputNode = new LogicalPlanner(config, analysis, engineContext.getMetaStore())\n+        .buildPlan();\n+    return new LogicalPlanNode(\n+        statement.getStatementText(),\n+        Optional.of(outputNode)\n+    );\n+  }\n+\n+  private PullPhysicalPlan buildPullPhysicalPlan(\n+      final KsqlExecutionContext ksqlEngine,\n+      final LogicalPlanNode logicalPlan,\n+      final KsqlConfig config,\n+      final ImmutableAnalysis analysis,", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcyMjgxOA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502722818", "bodyText": "The analyzer performs some initial validation and categorization and is a different step happening before the logical plan. The logical planner exposes as well parser expressions but inside logical nodes. That's what I want to change. So that at the physical planner we don't deal with any AST expressions anymore, only logical entities.", "author": "vpapavas", "createdAt": "2020-10-10T00:41:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcwOTcwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcxMTY1Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502711656", "bodyText": "Is there anything that sanity checks the order in which these methods will be called?  For example, will whereInfo be set at this point?\nI guess we know this will be processed last because it's the source node, but it might make sense to assert some of the invariants you're assuming to begin with (e.g. whereInfo != null)", "author": "AlanConfluent", "createdAt": "2020-10-09T23:30:28Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,342 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.SingleKeyTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.SingleKeyWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private Struct key;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),\n+        queryId,\n+        key,\n+        mat,\n+        routingFilterFactory,\n+        routingOptions,\n+        statement,\n+        serviceContext);\n+  }\n+\n+  private ProjectOperator translateProjectNode(final ProjectNode logicalNode) {\n+    LogicalSchema outputSchema = null;\n+    boolean isStar = false;\n+    if (isSelectStar(statement.getStatement().getSelect())) {\n+      isStar = true;\n+      outputSchema = buildSchema(mat.schema(), mat.windowType().isPresent());\n+    } else {\n+      final List<SelectExpression> projection = analysis.getSelectItems().stream()\n+          .map(SingleColumn.class::cast)\n+          .map(si -> SelectExpression\n+              .of(si.getAlias().orElseThrow(IllegalStateException::new), si.getExpression()))\n+          .collect(Collectors.toList());\n+\n+      outputSchema = selectOutputSchema(\n+          executionContext, projection, mat.windowType());\n+    }\n+    return new ProjectOperator(\n+      config,\n+      metaStore,\n+      mat,\n+      analysis,\n+      executionContext,\n+      contextStacker,\n+      logicalNode,\n+      outputSchema,\n+      isStar);\n+  }\n+\n+  private SelectOperator translateFilterNode(final FilterNode logicalNode) {\n+    whereInfo = WhereInfo.extractWhereInfo(logicalNode, analysis, persistentQueryMetadata);\n+    return new SelectOperator(logicalNode);\n+  }\n+\n+  private AbstractPhysicalOperator translateDataSourceNode(\n+      final DataSourceNode logicalNode,\n+      final PersistentQueryMetadata persistentQueryMetadata\n+  ) {\n+\n+    key = asKeyStruct(", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcyMjg5Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502722896", "bodyText": "I can add some sanity checks", "author": "vpapavas", "createdAt": "2020-10-10T00:41:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcxMTY1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcxMzI5NQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502713295", "bodyText": "I assume this doesn't currently do anything because this is done at the rocksdb layer?", "author": "AlanConfluent", "createdAt": "2020-10-09T23:38:59Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/SelectOperator.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import java.util.Objects;\n+\n+public class SelectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final FilterNode logicalNode;\n+  private AbstractPhysicalOperator child;\n+\n+  public SelectOperator(final FilterNode logicalNode) {\n+    this.logicalNode = Objects.requireNonNull(logicalNode);\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+  }\n+\n+  @Override\n+  public Object next() {\n+    return child.next();", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcyMzA0MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r502723041", "bodyText": "This doesn't do anything because currently we only support single key equality and nothing else in the WHERE clause. When we make it more general and allow others stuff as well, (like functions) we will need to add logic here.", "author": "vpapavas", "createdAt": "2020-10-10T00:43:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjcxMzI5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTcyNjkxOA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r505726918", "bodyText": "Just curious is it intentional to use different terms for types of queries? It seems:\n\nExecuteResult execute is for persistent push query\nTransientQueryMetadata executeQuery is for transient push query\nPullQueryResult executePullQuery is for pull query\n\nThe return class name, and the function names are all very different.", "author": "guozhangwang", "createdAt": "2020-10-15T17:45:59Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java", "diffHunk": "@@ -114,6 +118,15 @@ TransientQueryMetadata executeQuery(\n       ConfiguredStatement<Query> statement\n   );\n \n+  PullQueryResult executePullQuery(", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc3NzgyNQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r509777825", "bodyText": "Yeah, I don't know what to tell you :)", "author": "vpapavas", "createdAt": "2020-10-21T22:50:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTcyNjkxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTczMDIxMQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r505730211", "bodyText": "nit: is there a line breaker or space needed before the statement text?", "author": "guozhangwang", "createdAt": "2020-10-15T17:51:30Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -118,6 +139,78 @@ ExecuteResult execute(final KsqlPlan plan) {\n     return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n   }\n \n+  PullQueryResult executePullQuery(\n+      final KsqlExecutionContext ksqlEngine,\n+      final ConfiguredStatement<Query> statement,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final Map<String, Object> requestProperties,\n+      final Optional<Boolean> isInternalRequest,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    if (!statement.getStatement().isPullQuery()) {\n+      throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n+    }\n+    final SessionConfig sessionConfig = statement.getSessionConfig();\n+    if (!sessionConfig.getConfig(false)\n+        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n+      throw new KsqlStatementException(\n+          \"Pull queries are disabled.\"\n+              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n+              + System.lineSeparator()\n+              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n+              + \"this feature.\",\n+          statement.getStatementText());", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTczMzQzOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r505733439", "bodyText": "Is it okay to create a new rate limiter per query execution? It seems it does not use a global shared counter, so an individual rate limiter would only act for that single query and may never fail.", "author": "guozhangwang", "createdAt": "2020-10-15T17:56:41Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -118,6 +139,78 @@ ExecuteResult execute(final KsqlPlan plan) {\n     return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n   }\n \n+  PullQueryResult executePullQuery(\n+      final KsqlExecutionContext ksqlEngine,\n+      final ConfiguredStatement<Query> statement,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final Map<String, Object> requestProperties,\n+      final Optional<Boolean> isInternalRequest,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    if (!statement.getStatement().isPullQuery()) {\n+      throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n+    }\n+    final SessionConfig sessionConfig = statement.getSessionConfig();\n+    if (!sessionConfig.getConfig(false)\n+        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n+      throw new KsqlStatementException(\n+          \"Pull queries are disabled.\"\n+              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n+              + System.lineSeparator()\n+              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n+              + \"this feature.\",\n+          statement.getStatementText());\n+    }\n+\n+    final RoutingOptions routingOptions = new ConfigRoutingOptions(\n+        sessionConfig.getConfig(true),\n+        requestProperties\n+    );\n+    final RateLimiter rateLimiter = RateLimiter.create(sessionConfig.getConfig(true).getInt(\n+        KsqlConfig.KSQL_QUERY_PULL_MAX_QPS_CONFIG));\n+    // If internal listeners are in use, we require the request to come from that listener to\n+    // treat it as having been forwarded.\n+    final boolean isAlreadyForwarded = routingOptions.skipForwardRequest()\n+        // Trust the forward request option if isInternalRequest isn't available.\n+        && isInternalRequest.orElse(true);\n+\n+    // Only check the rate limit at the forwarding host\n+    if (!isAlreadyForwarded) {", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc4NTI4OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r509785289", "bodyText": "You are right, I fixed it to be created only once.", "author": "vpapavas", "createdAt": "2020-10-21T23:06:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTczMzQzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc2NDgyNQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r505764825", "bodyText": "Another question for my own education: what's the difference between this class and QueryEngine? It seems the latter is only for persistent and transient push queries?", "author": "guozhangwang", "createdAt": "2020-10-15T18:46:04Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java", "diffHunk": "@@ -246,6 +250,30 @@ public TransientQueryMetadata executeQuery(\n     }\n   }\n \n+  @Override\n+  public PullQueryResult executePullQuery(", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc2NzM1NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r505767354", "bodyText": "Is this going to be used beyond pull queries in the future?", "author": "guozhangwang", "createdAt": "2020-10-15T18:50:32Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+public abstract class AbstractPhysicalOperator {", "originalCommit": "3085b85e04a7667838ebf0a56093a2c4d046fa63", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc3MTIzNQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r509771235", "bodyText": "Yes, for push queries if the use the same physical plan builder", "author": "vpapavas", "createdAt": "2020-10-21T22:41:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTc2NzM1NA=="}], "type": "inlineReview"}, {"oid": "976bb4de2b89a498903d1931d9f182608846f0e5", "url": "https://github.com/confluentinc/ksql/commit/976bb4de2b89a498903d1931d9f182608846f0e5", "message": "Address comments", "committedDate": "2020-10-26T19:00:50Z", "type": "forcePushed"}, {"oid": "be69d38620a9d72a17eab4913083890652b3684b", "url": "https://github.com/confluentinc/ksql/commit/be69d38620a9d72a17eab4913083890652b3684b", "message": "trying to fix rqt test", "committedDate": "2020-10-28T22:26:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwNTA2MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516205060", "bodyText": "Aren't these only used in tests?  I think they can still be package private.", "author": "AlanConfluent", "createdAt": "2020-11-02T19:28:11Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/internal/PullQueryExecutorMetrics.java", "diffHunk": "@@ -108,11 +108,11 @@ public void recordResponseSize(final double value) {\n     this.responseSizeSensor.record(value);\n   }\n \n-  List<Sensor> getSensors() {\n+  public List<Sensor> getSensors() {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjMwMjI2MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516302261", "bodyText": "No, they actually need to be public.", "author": "vpapavas", "createdAt": "2020-11-02T22:43:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwNTA2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwNTEyOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516205129", "bodyText": "Same here", "author": "AlanConfluent", "createdAt": "2020-11-02T19:28:19Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/internal/PullQueryExecutorMetrics.java", "diffHunk": "@@ -108,11 +108,11 @@ public void recordResponseSize(final double value) {\n     this.responseSizeSensor.record(value);\n   }\n \n-  List<Sensor> getSensors() {\n+  public List<Sensor> getSensors() {\n     return sensors;\n   }\n \n-  Metrics getMetrics() {\n+  public Metrics getMetrics() {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwODM1OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516208359", "bodyText": "You've created multiple RateLimiters, effectively allowing the rate limit only over each particular endpoint.  Can this be pushed down to a common place, such as the EngineExecutor?", "author": "AlanConfluent", "createdAt": "2020-11-02T19:34:40Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java", "diffHunk": "@@ -153,6 +163,7 @@ public void configure(final KsqlConfig config) {\n     }\n \n     ksqlConfig = config;\n+    rateLimiter = RateLimiter.create(ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_MAX_QPS_CONFIG));", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM3ODYwOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516378609", "bodyText": "If I put in the EngineExecutor it will be per pull query (that's where I had it initially). I moved it to the KsqlRestApplication", "author": "vpapavas", "createdAt": "2020-11-03T01:09:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwODM1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxODU0MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516418541", "bodyText": "@vpapavas did you mean to push a more recent udpate? some of your comments, like this one, don't seem to be resolved", "author": "agavra", "createdAt": "2020-11-03T04:08:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwODM1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwODU1MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516208550", "bodyText": "Remove commented code?", "author": "AlanConfluent", "createdAt": "2020-11-02T19:34:57Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java", "diffHunk": "@@ -266,9 +277,24 @@ private EndpointResponse handlePullQuery(\n     final ConfiguredStatement<Query> configured = ConfiguredStatement\n         .of(statement, SessionConfig.of(ksqlConfig, configOverrides));\n \n-    final PullQueryResult result = pullQueryExecutor.execute(\n+    final PullQueryResult result = ksqlEngine.executePullQuery(\n+        serviceContext,\n+        routingFilterFactory,\n+        configured,\n+        requestProperties,\n+        isInternalRequest,\n+        pullQueryMetrics,\n+        rateLimiter);\n+    final TableRows tableRows = new TableRows(\n+        statement.getStatementText(),\n+        result.getQueryId(),\n+        result.getSchema(),\n+        result.getTableRows());\n+\n+\n+    /*final PullQueryResult result = pullQueryExecutor.execute(", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMDMyOA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516210328", "bodyText": "Is there any reason this can't be:\nfinal TableRows tableRows = result.getTableRows();", "author": "AlanConfluent", "createdAt": "2020-11-02T19:38:36Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/StreamedQueryResource.java", "diffHunk": "@@ -266,9 +277,24 @@ private EndpointResponse handlePullQuery(\n     final ConfiguredStatement<Query> configured = ConfiguredStatement\n         .of(statement, SessionConfig.of(ksqlConfig, configOverrides));\n \n-    final PullQueryResult result = pullQueryExecutor.execute(\n+    final PullQueryResult result = ksqlEngine.executePullQuery(\n+        serviceContext,\n+        routingFilterFactory,\n+        configured,\n+        requestProperties,\n+        isInternalRequest,\n+        pullQueryMetrics,\n+        rateLimiter);\n+    final TableRows tableRows = new TableRows(", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM3OTM4Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516379383", "bodyText": "The PullQueryResult of the pull physical plan is a different class than the PullQueryResult of PullQueryExecutor. The first doesn't have visibility to TableRows that's why I have to create them in StreamedQueryResource", "author": "vpapavas", "createdAt": "2020-11-03T01:12:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMDMyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMzAwNQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516213005", "bodyText": "Is this a programming error if this hits?  If so, might want to throw an IllegalStateException or at least log a warning if this can reasonably be ignored?", "author": "AlanConfluent", "createdAt": "2020-11-02T19:43:48Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries\n+      if (currentLogicalNode.getSources().isEmpty()) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM3MDAwMg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516370002", "bodyText": "No, it's not an error. This is just to check that we have reached the leaf of the LogicalPlan and we can stop the translation to physical", "author": "vpapavas", "createdAt": "2020-11-03T00:50:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMzAwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzczMTExNw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517731117", "bodyText": "I see.  Will the logic while (currentLogicalNode.getSources() != null) { ever be false?  Walking through the code, it looks like it wouldn't be and this is the main exit from the loop.  If so, maybe it makes sense to either make it while (true) so it's obvious this is the way the iteration ends.", "author": "AlanConfluent", "createdAt": "2020-11-05T01:37:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxMzAwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxODE2OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516218169", "bodyText": "Do we want to assert that dataSourceOperator isn't null before passing it off to the PullPhysicalPlan?", "author": "AlanConfluent", "createdAt": "2020-11-02T19:53:32Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),\n+        queryId,\n+        keys,\n+        mat,\n+        dataSourceOperator);", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxOTA5Nw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516219097", "bodyText": "Can you add some comments to new interfaces just to make it easy to understand for people new to the code?", "author": "AlanConfluent", "createdAt": "2020-11-02T19:55:16Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/DataSourceOperator.java", "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import java.util.List;\n+\n+public interface DataSourceOperator {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyMzU0Nw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516223547", "bodyText": "getWindowBounds is always present if it's windowed, regardless of what the bounds on the window are, right?  This is effectively an isWindowed check.", "author": "AlanConfluent", "createdAt": "2020-11-02T20:04:07Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),\n+        queryId,\n+        keys,\n+        mat,\n+        dataSourceOperator);\n+  }\n+\n+  private ProjectOperator translateProjectNode(final ProjectNode logicalNode) {\n+    LogicalSchema outputSchema = null;\n+    boolean isStar = false;\n+    if (isSelectStar(statement.getStatement().getSelect())) {\n+      isStar = true;\n+      outputSchema = buildSchema(mat.schema(), mat.windowType().isPresent());\n+    } else {\n+      final List<SelectExpression> projection = analysis.getSelectItems().stream()\n+          .map(SingleColumn.class::cast)\n+          .map(si -> SelectExpression\n+              .of(si.getAlias().orElseThrow(IllegalStateException::new), si.getExpression()))\n+          .collect(Collectors.toList());\n+\n+      outputSchema = selectOutputSchema(\n+          executionContext, projection, mat.windowType());\n+    }\n+    return new ProjectOperator(\n+      config,\n+      metaStore,\n+      mat,\n+      analysis,\n+      executionContext,\n+      contextStacker,\n+      logicalNode,\n+      outputSchema,\n+      isStar);\n+  }\n+\n+  private SelectOperator translateFilterNode(final FilterNode logicalNode) {\n+    whereInfo = WhereInfo.extractWhereInfo(analysis, persistentQueryMetadata);\n+    return new SelectOperator(logicalNode);\n+  }\n+\n+  private AbstractPhysicalOperator translateDataSourceNode(\n+      final DataSourceNode logicalNode,\n+      final PersistentQueryMetadata persistentQueryMetadata\n+  ) {\n+    if (whereInfo == null) {\n+      throw new KsqlException(\"Pull queries must have a WHERE clause\");\n+    }\n+    keys = whereInfo.getKeysBound().stream()\n+        .map(keyBound -> asKeyStruct(keyBound, persistentQueryMetadata.getPhysicalSchema()))\n+        .collect(ImmutableList.toImmutableList());\n+\n+    if (!whereInfo.getWindowBounds().isPresent()) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM2OTE5MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516369191", "bodyText": "If there are no window-bounds in the query, the query is not windowed. So, yes this is a isWindowed check", "author": "vpapavas", "createdAt": "2020-11-03T00:48:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyMzU0Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMzc3NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516403774", "bodyText": "in that case, can we create a method in WhereInfo called isWindowed?", "author": "agavra", "createdAt": "2020-11-03T02:57:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyMzU0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyNTMzNQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516225335", "bodyText": "This wrapping looks a little funny", "author": "AlanConfluent", "createdAt": "2020-11-02T20:07:33Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class ProjectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final MetaStore metaStore;\n+  private final Materialization mat;\n+  private final ImmutableAnalysis analysis;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final LogicalSchema outputSchema;\n+  private final boolean isSelectStar;\n+\n+  private AbstractPhysicalOperator child;\n+  private ProjectNode logicalNode;\n+  private TableRow row;\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  private Function<TableRow, GenericRow> preSelectTransform;\n+\n+  public ProjectOperator(\n+      final KsqlConfig ksqlConfig,\n+      final MetaStore metaStore,\n+      final Materialization mat,\n+      final ImmutableAnalysis analysis,\n+      final KsqlExecutionContext executionContext,\n+      final Stacker contextStacker,\n+      final ProjectNode logicalNode,\n+      final LogicalSchema outputSchema,\n+      final boolean isSelectStar\n+\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"config\");\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n+    this.logicalNode = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.isSelectStar = isSelectStar;\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+    if (isSelectStar) {\n+      return;\n+    }\n+\n+    final LogicalSchema inputSchema = mat.schema();\n+\n+    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(SystemColumns::isSystemColumn);\n+    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(inputSchema::isKeyColumn);\n+\n+    final LogicalSchema intermediateSchema;\n+    if (noSystemColumns && noKeyColumns) {\n+      intermediateSchema = inputSchema;\n+      preSelectTransform = TableRow::value;\n+    } else {\n+      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n+      final boolean windowed = mat.windowType().isPresent();\n+\n+      intermediateSchema = inputSchema\n+          .withPseudoAndKeyColsInValue(windowed);\n+\n+      preSelectTransform = row -> {\n+        final Struct key = row.key();\n+        final GenericRow value = row.value();\n+\n+        final List<Object> keyFields = key.schema().fields().stream()\n+            .map(key::get)\n+            .collect(Collectors.toList());\n+\n+        value.ensureAdditionalCapacity(\n+            1 // ROWTIME\n+                + keyFields.size()", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyNTYxNw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516225617", "bodyText": "Unnecessary return?", "author": "AlanConfluent", "createdAt": "2020-11-02T20:08:06Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class ProjectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final MetaStore metaStore;\n+  private final Materialization mat;\n+  private final ImmutableAnalysis analysis;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final LogicalSchema outputSchema;\n+  private final boolean isSelectStar;\n+\n+  private AbstractPhysicalOperator child;\n+  private ProjectNode logicalNode;\n+  private TableRow row;\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  private Function<TableRow, GenericRow> preSelectTransform;\n+\n+  public ProjectOperator(\n+      final KsqlConfig ksqlConfig,\n+      final MetaStore metaStore,\n+      final Materialization mat,\n+      final ImmutableAnalysis analysis,\n+      final KsqlExecutionContext executionContext,\n+      final Stacker contextStacker,\n+      final ProjectNode logicalNode,\n+      final LogicalSchema outputSchema,\n+      final boolean isSelectStar\n+\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"config\");\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n+    this.logicalNode = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.isSelectStar = isSelectStar;\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+    if (isSelectStar) {\n+      return;\n+    }\n+\n+    final LogicalSchema inputSchema = mat.schema();\n+\n+    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(SystemColumns::isSystemColumn);\n+    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(inputSchema::isKeyColumn);\n+\n+    final LogicalSchema intermediateSchema;\n+    if (noSystemColumns && noKeyColumns) {\n+      intermediateSchema = inputSchema;\n+      preSelectTransform = TableRow::value;\n+    } else {\n+      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n+      final boolean windowed = mat.windowType().isPresent();\n+\n+      intermediateSchema = inputSchema\n+          .withPseudoAndKeyColsInValue(windowed);\n+\n+      preSelectTransform = row -> {\n+        final Struct key = row.key();\n+        final GenericRow value = row.value();\n+\n+        final List<Object> keyFields = key.schema().fields().stream()\n+            .map(key::get)\n+            .collect(Collectors.toList());\n+\n+        value.ensureAdditionalCapacity(\n+            1 // ROWTIME\n+                + keyFields.size()\n+                + row.window().map(w -> 2).orElse(0)\n+        );\n+\n+        value.append(row.rowTime());\n+        value.appendAll(keyFields);\n+\n+        row.window().ifPresent(window -> {\n+          value.append(window.start().toEpochMilli());\n+          value.append(window.end().toEpochMilli());\n+        });\n+\n+        return value;\n+      };\n+    }\n+\n+    final SelectValueMapper<Object> select = SelectValueMapperFactory.create(\n+        logicalNode.getSelectExpressions(),\n+        intermediateSchema,\n+        ksqlConfig,\n+        metaStore\n+    );\n+\n+    final ProcessingLogger logger = executionContext\n+        .getProcessingLogContext()\n+        .getLoggerFactory()\n+        .getLogger(\n+            QueryLoggerUtil.queryLoggerName(\n+                QueryType.PULL_QUERY, contextStacker.push(\"PROJECT\").getQueryContext())\n+        );\n+\n+    transformer = select.getTransformer(logger);\n+\n+    return;", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyNjYyMQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516226621", "bodyText": "Remove comment?", "author": "AlanConfluent", "createdAt": "2020-11-02T20:10:13Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class ProjectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final MetaStore metaStore;\n+  private final Materialization mat;\n+  private final ImmutableAnalysis analysis;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final LogicalSchema outputSchema;\n+  private final boolean isSelectStar;\n+\n+  private AbstractPhysicalOperator child;\n+  private ProjectNode logicalNode;\n+  private TableRow row;\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  private Function<TableRow, GenericRow> preSelectTransform;\n+\n+  public ProjectOperator(\n+      final KsqlConfig ksqlConfig,\n+      final MetaStore metaStore,\n+      final Materialization mat,\n+      final ImmutableAnalysis analysis,\n+      final KsqlExecutionContext executionContext,\n+      final Stacker contextStacker,\n+      final ProjectNode logicalNode,\n+      final LogicalSchema outputSchema,\n+      final boolean isSelectStar\n+\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"config\");\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n+    this.logicalNode = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.isSelectStar = isSelectStar;\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+    if (isSelectStar) {\n+      return;\n+    }\n+\n+    final LogicalSchema inputSchema = mat.schema();\n+\n+    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(SystemColumns::isSystemColumn);\n+    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(inputSchema::isKeyColumn);\n+\n+    final LogicalSchema intermediateSchema;\n+    if (noSystemColumns && noKeyColumns) {\n+      intermediateSchema = inputSchema;\n+      preSelectTransform = TableRow::value;\n+    } else {\n+      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n+      final boolean windowed = mat.windowType().isPresent();\n+\n+      intermediateSchema = inputSchema\n+          .withPseudoAndKeyColsInValue(windowed);\n+\n+      preSelectTransform = row -> {\n+        final Struct key = row.key();\n+        final GenericRow value = row.value();\n+\n+        final List<Object> keyFields = key.schema().fields().stream()\n+            .map(key::get)\n+            .collect(Collectors.toList());\n+\n+        value.ensureAdditionalCapacity(\n+            1 // ROWTIME\n+                + keyFields.size()\n+                + row.window().map(w -> 2).orElse(0)\n+        );\n+\n+        value.append(row.rowTime());\n+        value.appendAll(keyFields);\n+\n+        row.window().ifPresent(window -> {\n+          value.append(window.start().toEpochMilli());\n+          value.append(window.end().toEpochMilli());\n+        });\n+\n+        return value;\n+      };\n+    }\n+\n+    final SelectValueMapper<Object> select = SelectValueMapperFactory.create(\n+        logicalNode.getSelectExpressions(),\n+        intermediateSchema,\n+        ksqlConfig,\n+        metaStore\n+    );\n+\n+    final ProcessingLogger logger = executionContext\n+        .getProcessingLogContext()\n+        .getLoggerFactory()\n+        .getLogger(\n+            QueryLoggerUtil.queryLoggerName(\n+                QueryType.PULL_QUERY, contextStacker.push(\"PROJECT\").getQueryContext())\n+        );\n+\n+    transformer = select.getTransformer(logger);\n+\n+    return;\n+  }\n+\n+  @Override\n+  public Object next() {\n+    row = (TableRow)child.next();\n+    if (row == null) {\n+      return null;\n+    }\n+    if (isSelectStar) {\n+      // return List<?>\n+      return createRow(row);\n+    }\n+    final GenericRow intermediate = preSelectTransform.apply(row);\n+\n+    final GenericRow mapped = transformer.transform(\n+        row.key(),\n+        intermediate,\n+        new PullProcessingContext(row.rowTime())\n+    );\n+    validateProjection(mapped, outputSchema);\n+\n+    // return List<?>", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyNjkyMQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516226921", "bodyText": "Extra line", "author": "AlanConfluent", "createdAt": "2020-11-02T20:10:53Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class ProjectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final MetaStore metaStore;\n+  private final Materialization mat;\n+  private final ImmutableAnalysis analysis;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final LogicalSchema outputSchema;\n+  private final boolean isSelectStar;\n+\n+  private AbstractPhysicalOperator child;\n+  private ProjectNode logicalNode;\n+  private TableRow row;\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  private Function<TableRow, GenericRow> preSelectTransform;\n+\n+  public ProjectOperator(\n+      final KsqlConfig ksqlConfig,\n+      final MetaStore metaStore,\n+      final Materialization mat,\n+      final ImmutableAnalysis analysis,\n+      final KsqlExecutionContext executionContext,\n+      final Stacker contextStacker,\n+      final ProjectNode logicalNode,\n+      final LogicalSchema outputSchema,\n+      final boolean isSelectStar\n+\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"config\");\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n+    this.logicalNode = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.isSelectStar = isSelectStar;\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+    if (isSelectStar) {\n+      return;\n+    }\n+\n+    final LogicalSchema inputSchema = mat.schema();\n+\n+    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(SystemColumns::isSystemColumn);\n+    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(inputSchema::isKeyColumn);\n+\n+    final LogicalSchema intermediateSchema;\n+    if (noSystemColumns && noKeyColumns) {\n+      intermediateSchema = inputSchema;\n+      preSelectTransform = TableRow::value;\n+    } else {\n+      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n+      final boolean windowed = mat.windowType().isPresent();\n+\n+      intermediateSchema = inputSchema\n+          .withPseudoAndKeyColsInValue(windowed);\n+\n+      preSelectTransform = row -> {\n+        final Struct key = row.key();\n+        final GenericRow value = row.value();\n+\n+        final List<Object> keyFields = key.schema().fields().stream()\n+            .map(key::get)\n+            .collect(Collectors.toList());\n+\n+        value.ensureAdditionalCapacity(\n+            1 // ROWTIME\n+                + keyFields.size()\n+                + row.window().map(w -> 2).orElse(0)\n+        );\n+\n+        value.append(row.rowTime());\n+        value.appendAll(keyFields);\n+\n+        row.window().ifPresent(window -> {\n+          value.append(window.start().toEpochMilli());\n+          value.append(window.end().toEpochMilli());\n+        });\n+\n+        return value;\n+      };\n+    }\n+\n+    final SelectValueMapper<Object> select = SelectValueMapperFactory.create(\n+        logicalNode.getSelectExpressions(),\n+        intermediateSchema,\n+        ksqlConfig,\n+        metaStore\n+    );\n+\n+    final ProcessingLogger logger = executionContext\n+        .getProcessingLogContext()\n+        .getLoggerFactory()\n+        .getLogger(\n+            QueryLoggerUtil.queryLoggerName(\n+                QueryType.PULL_QUERY, contextStacker.push(\"PROJECT\").getQueryContext())\n+        );\n+\n+    transformer = select.getTransformer(logger);\n+\n+    return;\n+  }\n+\n+  @Override\n+  public Object next() {\n+    row = (TableRow)child.next();\n+    if (row == null) {\n+      return null;\n+    }\n+    if (isSelectStar) {\n+      // return List<?>\n+      return createRow(row);\n+    }\n+    final GenericRow intermediate = preSelectTransform.apply(row);\n+\n+    final GenericRow mapped = transformer.transform(\n+        row.key(),\n+        intermediate,\n+        new PullProcessingContext(row.rowTime())\n+    );\n+    validateProjection(mapped, outputSchema);\n+\n+    // return List<?>\n+    return mapped.values();\n+  }\n+\n+  @Override\n+  public void close() {\n+    child.close();\n+  }\n+\n+  @Override\n+  public void addChild(final AbstractPhysicalOperator child) {\n+    this.child = child;\n+  }\n+\n+\n+  @Override\n+  public AbstractPhysicalOperator getChild() {\n+    return child;\n+  }\n+\n+  public LogicalSchema getOutputSchema() {\n+    return outputSchema;\n+  }\n+\n+  private void validateProjection(\n+      final GenericRow fullRow,\n+      final LogicalSchema schema\n+  ) {\n+    final int actual = fullRow.size();\n+    final int expected = schema.columns().size();\n+    if (actual != expected) {\n+      throw new IllegalStateException(\"Row column count mismatch.\"\n+                                          + \" expected:\" + expected\n+                                          + \", got:\" + actual\n+      );\n+    }\n+  }\n+\n+  private List<?> createRow(final TableRow row) {\n+    final List<Object> rowList = new ArrayList<>();\n+\n+    keyFields(row.key()).forEach(rowList::add);\n+\n+    row.window().ifPresent(window -> {\n+      rowList.add(window.start().toEpochMilli());\n+      rowList.add(window.end().toEpochMilli());\n+    });\n+\n+    rowList.addAll(row.value().values());\n+\n+    return rowList;\n+  }\n+\n+  private Stream<?> keyFields(final Struct key) {\n+    return key.schema().fields().stream().map(key::get);\n+  }\n+", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMDQ5MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516230490", "bodyText": "It's slightly funny to do the real work in open and then just dish out the cached rows on each next.  Since the interface is row oriented, we could also keep track of the key we're on and then do the actual single key lookup on each call to next.  In theory, this allows for \"back pressure\" and avoiding a burst a work since we could do it incrementally and on demand.", "author": "AlanConfluent", "createdAt": "2020-11-02T20:18:20Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.Row;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KeyedTableLookupOperator\n+    extends AbstractPhysicalOperator\n+    implements UnaryPhysicalOperator, DataSourceOperator {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(KeyedTableLookupOperator.class);\n+\n+  private final Materialization mat;\n+  private final DataSourceNode logicalOperator;\n+\n+  private List<KsqlPartitionLocation> partitionLocations;\n+  private Iterator<Row> resultIterator;\n+\n+  public KeyedTableLookupOperator(\n+      final Materialization mat,\n+      final DataSourceNode logicalNode\n+  ) {\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+  }\n+\n+  @Override\n+  public void open() {\n+    final List<Row> result = new ArrayList<>();\n+    for (KsqlPartitionLocation location : partitionLocations) {\n+      if (!location.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Table lookup queries should be done with keys\");\n+      }\n+      for (Struct key : location.getKeys().get()) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM2NzQyMw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516367423", "bodyText": "There are multiple locations and keys, so we need to keep track of both in next and exhaust both iterators. I made the change, lmk how it looks", "author": "vpapavas", "createdAt": "2020-11-03T00:44:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMDQ5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNTg2Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516415866", "bodyText": "+1 to what @AlanConfluent said - it doesn't look like the code has updated to do what Alan is saying?", "author": "agavra", "createdAt": "2020-11-03T03:55:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMDQ5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQyNTM4Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516425386", "bodyText": "I first commented and then waited for the tests to pass before pushing. Unfortunately, it took longer than expected :(", "author": "vpapavas", "createdAt": "2020-11-03T04:42:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMDQ5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMDg3Nw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516230877", "bodyText": "Throw an exception since this should be a leaf?", "author": "AlanConfluent", "createdAt": "2020-11-02T20:19:09Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.Row;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KeyedTableLookupOperator\n+    extends AbstractPhysicalOperator\n+    implements UnaryPhysicalOperator, DataSourceOperator {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(KeyedTableLookupOperator.class);\n+\n+  private final Materialization mat;\n+  private final DataSourceNode logicalOperator;\n+\n+  private List<KsqlPartitionLocation> partitionLocations;\n+  private Iterator<Row> resultIterator;\n+\n+  public KeyedTableLookupOperator(\n+      final Materialization mat,\n+      final DataSourceNode logicalNode\n+  ) {\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+  }\n+\n+  @Override\n+  public void open() {\n+    final List<Row> result = new ArrayList<>();\n+    for (KsqlPartitionLocation location : partitionLocations) {\n+      if (!location.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Table lookup queries should be done with keys\");\n+      }\n+      for (Struct key : location.getKeys().get()) {\n+        final List<Row> rows = mat.nonWindowed()\n+            .get(key, location.getPartition())\n+            .map(ImmutableList::of)\n+            .orElse(ImmutableList.of());\n+        result.addAll(rows);\n+      }\n+    }\n+\n+    resultIterator = result.iterator();\n+  }\n+\n+  @Override\n+  public Object next() {\n+    if (resultIterator.hasNext()) {\n+      return resultIterator.next();\n+    }\n+    return null;\n+  }\n+\n+  @Override\n+  public void close() {\n+\n+  }\n+\n+  @Override\n+  public void addChild(final AbstractPhysicalOperator child) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMTA3MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516231071", "bodyText": "Similar question as for non windowed.", "author": "AlanConfluent", "createdAt": "2020-11-02T20:19:30Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.streams.materialization.WindowedRow;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo.WindowBounds;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KeyedWindowedTableLookupOperator\n+    extends AbstractPhysicalOperator\n+    implements UnaryPhysicalOperator, DataSourceOperator {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      KeyedWindowedTableLookupOperator.class);\n+\n+  private final Materialization mat;\n+  private final DataSourceNode logicalOperator;\n+  private final WindowBounds windowBounds;\n+\n+  private List<KsqlPartitionLocation> partitionLocations;\n+  private List<? extends TableRow> result;\n+  private Iterator<? extends TableRow> resultIterator;\n+\n+  public KeyedWindowedTableLookupOperator(\n+      final Materialization mat,\n+      final DataSourceNode logicalNode,\n+      final WindowBounds windowBounds\n+  ) {\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.windowBounds = Objects.requireNonNull(windowBounds, \"windowBounds\");\n+  }\n+\n+  @Override\n+  public void open() {\n+    final List<WindowedRow> result = new ArrayList<>();\n+    for (KsqlPartitionLocation location : partitionLocations) {\n+      if (!location.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Window queries should be done with keys\");\n+      }\n+      for (Struct key : location.getKeys().get()) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMTE4Mg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516231182", "bodyText": "Throw an exception if this is meant to be a leaf?", "author": "AlanConfluent", "createdAt": "2020-11-02T20:19:45Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.streams.materialization.WindowedRow;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo.WindowBounds;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KeyedWindowedTableLookupOperator\n+    extends AbstractPhysicalOperator\n+    implements UnaryPhysicalOperator, DataSourceOperator {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      KeyedWindowedTableLookupOperator.class);\n+\n+  private final Materialization mat;\n+  private final DataSourceNode logicalOperator;\n+  private final WindowBounds windowBounds;\n+\n+  private List<KsqlPartitionLocation> partitionLocations;\n+  private List<? extends TableRow> result;\n+  private Iterator<? extends TableRow> resultIterator;\n+\n+  public KeyedWindowedTableLookupOperator(\n+      final Materialization mat,\n+      final DataSourceNode logicalNode,\n+      final WindowBounds windowBounds\n+  ) {\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.windowBounds = Objects.requireNonNull(windowBounds, \"windowBounds\");\n+  }\n+\n+  @Override\n+  public void open() {\n+    final List<WindowedRow> result = new ArrayList<>();\n+    for (KsqlPartitionLocation location : partitionLocations) {\n+      if (!location.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Window queries should be done with keys\");\n+      }\n+      for (Struct key : location.getKeys().get()) {\n+        final List<WindowedRow> rows = mat.windowed()\n+            .get(key, location.getPartition(), windowBounds.getStart(), windowBounds.getEnd());\n+        result.addAll(rows);\n+      }\n+    }\n+    resultIterator = result.iterator();\n+  }\n+\n+  @Override\n+  public Object next() {\n+    if (resultIterator.hasNext()) {\n+      return resultIterator.next();\n+    }\n+    return null;\n+  }\n+\n+  @Override\n+  public void close() {\n+\n+  }\n+\n+  @Override\n+  public void addChild(final AbstractPhysicalOperator child) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NDQzMA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516394430", "bodyText": "as discussed with @guozhangwang offline, it would be good if we improved our javadoc around these classes! (same applies to the rest of the PR)", "author": "agavra", "createdAt": "2020-11-03T02:15:38Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java", "diffHunk": "@@ -125,6 +129,16 @@ TransientQueryMetadata executeQuery(\n       ConfiguredStatement<Query> statement\n   );\n \n+  PullQueryResult executePullQuery(", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NDkxMQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516394911", "bodyText": "Optional<Boolean> feels very clunky, and makes me thing that we're mixing together multiple APIs in one. At a minimum, since the values are either true or false, we should require that all callers of this method explicitly handle the optional (either passing true or false) - otherwise we allow callers to be undecided and default to one or the other, which doesn't seem right.\nAlternatively, we might want to consider to methods executePullQuery and executedInternallPullQuery or executedForwardedPullQuery to make the distinction clear", "author": "agavra", "createdAt": "2020-11-03T02:17:52Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java", "diffHunk": "@@ -125,6 +129,16 @@ TransientQueryMetadata executeQuery(\n       ConfiguredStatement<Query> statement\n   );\n \n+  PullQueryResult executePullQuery(\n+      ServiceContext serviceContext,\n+      RoutingFilterFactory routingFilterFactory,\n+      ConfiguredStatement<Query> statement,\n+      Map<String, Object> requestProperties,\n+      Optional<Boolean> isInternalRequest,", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQzMjQ2OA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516432468", "bodyText": "I am not sure I understand why it is clunky but @AlanConfluent wrote this code: Alan do you have any background information here of why this needs to be Optional? Can it be replaced with boolean? I see in ServerVerticle:isInternalRequest that it could just as easily return boolean (true if is internal, false otherwise), right?\n  private static Optional<Boolean> isInternalRequest(final RoutingContext routingContext) {\n    return Optional.ofNullable(routingContext.get(CONTEXT_DATA_IS_INTERNAL));\n  }", "author": "vpapavas", "createdAt": "2020-11-03T05:18:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NDkxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwNjg3Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517006876", "bodyText": "+1. From the code it seems we can always determine whether the flag is set or not, and there's no scenarios where it is \"undecided\" or \"unknown\".", "author": "guozhangwang", "createdAt": "2020-11-03T23:04:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NDkxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcxNjM3OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517716379", "bodyText": "In some areas of code, it was necessary to see whether the internal interface was enabled at all.  Effectively, it's a 3 state flag: Internal interface not in use at all, internal interface in use and this request is internal, and internal interface in use and this request is not internal.  If you look at how it's being used in the code it's this:\nfinal boolean isAlreadyForwarded = routingOptions.skipForwardRequest()\n          // Trust the forward request option if isInternalRequest isn't available.\n          && isInternalRequest.orElse(true);\n\nSo, if the interface isn't in use, the value defaults to true, not false.  If you want to do this at the calling layer, that's fine.  Also, if this three state thing isn's clear, it could be wrapped in a class that makes it clearer.", "author": "AlanConfluent", "createdAt": "2020-11-05T00:47:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NDkxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyMzEzMg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517723132", "bodyText": "that makes sense @AlanConfluent  thanks for the clarification, I think it would be nice to wrap it in an enum representing these three states (or in a class like you suggest) but this can be done in a follow-up (or now, if you're eager!)", "author": "agavra", "createdAt": "2020-11-05T01:10:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NDkxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NTUxNA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516395514", "bodyText": "why are passing in both a ConfiguredStatement and requestProperties? The ConfiguredStatement should contain the requestProperties within it (indirectly via the SessionConfig)", "author": "agavra", "createdAt": "2020-11-03T02:20:31Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java", "diffHunk": "@@ -125,6 +129,16 @@ TransientQueryMetadata executeQuery(\n       ConfiguredStatement<Query> statement\n   );\n \n+  PullQueryResult executePullQuery(\n+      ServiceContext serviceContext,\n+      RoutingFilterFactory routingFilterFactory,\n+      ConfiguredStatement<Query> statement,\n+      Map<String, Object> requestProperties,", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQzMDM3OA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516430378", "bodyText": "The SessionConfig contains the overrides not the request properties, right?", "author": "vpapavas", "createdAt": "2020-11-03T05:07:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NTUxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwMzQxNA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517703414", "bodyText": "ah yes, you are right.", "author": "agavra", "createdAt": "2020-11-05T00:04:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NTUxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NjU1Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516396553", "bodyText": "it seems odd that whomever is calling this method passes in the rateLimiter, it should be up to the engine to decide whether or not a query is rate limited, no? That way, we need to make sure that the same rate limiter is always being passed. If the engine (or whatever the leaf that executes this method call) \"owns\" the rate limiter, we can make sure we don't accidentally bypass this.\nEDIT: I see that @AlanConfluent pointed out something similar here https://github.com/confluentinc/ksql/pull/6375/files#r516208359 - which I think \"proves\" my point that this design isn't safe! If we want to \"bypass\" the rate limiter, then we should be creating a sandbox of the engine context with a new rate limiter.", "author": "agavra", "createdAt": "2020-11-03T02:25:13Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java", "diffHunk": "@@ -125,6 +129,16 @@ TransientQueryMetadata executeQuery(\n       ConfiguredStatement<Query> statement\n   );\n \n+  PullQueryResult executePullQuery(\n+      ServiceContext serviceContext,\n+      RoutingFilterFactory routingFilterFactory,\n+      ConfiguredStatement<Query> statement,\n+      Map<String, Object> requestProperties,\n+      Optional<Boolean> isInternalRequest,\n+      Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n+      RateLimiter rateLimiter", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQyODU4MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516428581", "bodyText": "I am not sure I am following what you mean.\nThe rateLimiter (after my last changes) is created once in the KsqlRestApplication and then used in StreamedQueryResource and WsQueryEndpoint.  After that, the logic of how it is applied hasn't changed from the PullQueryExecutor: it is used for every pull query. The same rateLimiter is being used for every pull query since it is created once.\nI don't understand what you are saying that the design isn't safe. Alan's comment was about the StreamedQueryResource and WsQueryEndpoint having a different rateLimiter whereas we wanted to limit on their combined pull queries.", "author": "vpapavas", "createdAt": "2020-11-03T04:59:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NjU1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwODE2Mg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517008162", "bodyText": "I also found that maintaining this object at one class while only \"executing\" its logic in another class a bit weird. Generally speaking, if the rate limiter is maintained at the KsqlRestApplication (which indicates we think the rate limiter is per Rest application not per engine) then it can just be applied at that layer rather than passing it through to KsqlEngine and applied at this lower level, unless there's any blockers prevent us from doing so.", "author": "guozhangwang", "createdAt": "2020-11-03T23:07:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NjU1Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM3MDA0NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523370044", "bodyText": "I don't think it can be applied at the KsqlRestApplication as we don't know there whether a request is a pull query or not.", "author": "vpapavas", "createdAt": "2020-11-14T03:44:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NjU1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NzM1Nw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516397357", "bodyText": "this comment is saying what the code below does, but as someone unfamiliar with the context here I still have no idea why! would be good to rephrase this giving some more context. It's also contradicted with the line below (we don't actually require this?)", "author": "agavra", "createdAt": "2020-11-03T02:29:01Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -116,6 +137,82 @@ ExecuteResult execute(final KsqlPlan plan) {\n     return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n   }\n \n+  PullQueryResult executePullQuery(\n+      final KsqlExecutionContext ksqlEngine,\n+      final ConfiguredStatement<Query> statement,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final Map<String, Object> requestProperties,\n+      final Optional<Boolean> isInternalRequest,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n+      final RateLimiter rateLimiter\n+  ) {\n+\n+    if (!statement.getStatement().isPullQuery()) {\n+      throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n+    }\n+    final SessionConfig sessionConfig = statement.getSessionConfig();\n+    if (!sessionConfig.getConfig(false)\n+        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n+      throw new KsqlStatementException(\n+          \"Pull queries are disabled.\"\n+              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n+              + System.lineSeparator()\n+              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n+              + \"this feature.\"\n+              + System.lineSeparator(),\n+          statement.getStatementText());\n+    }\n+\n+    final RoutingOptions routingOptions = new PullQueryConfigRoutingOptions(\n+        sessionConfig.getConfig(false),\n+        statement.getSessionConfig().getOverrides(),\n+        requestProperties\n+    );\n+\n+    // If internal listeners are in use, we require the request to come from that listener to\n+    // treat it as having been forwarded.", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAyNDg2Mg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517024862", "bodyText": "nit: I think maybe renaming the variable as \"doNotForward\" could help readers to understand :) Myself spent some time to realize that we only do forwarding ONCE, so isAlreadyForwarded == WillNotForwardAgain. But the name isAlreadyForwarded does not necessarily indicate so.", "author": "guozhangwang", "createdAt": "2020-11-04T00:01:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NzM1Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzM2OTk0NQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523369945", "bodyText": "It true that we forward only once but this variable is not used to achieve this. It only checks if the request is a forwarded one or not to apply the rate limiting. So, isAlreadyForwarded == don't apply rate limiting", "author": "vpapavas", "createdAt": "2020-11-14T03:42:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NzM1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5OTUyOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516399529", "bodyText": "passing this into another class is often the sign that we're breaking abstraction barriers. Is there anything inside this class we need that we can just pass in directly?", "author": "agavra", "createdAt": "2020-11-03T02:38:32Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java", "diffHunk": "@@ -250,6 +254,32 @@ public TransientQueryMetadata executeQuery(\n     }\n   }\n \n+  @Override\n+  public PullQueryResult executePullQuery(\n+      final ServiceContext serviceContext,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final ConfiguredStatement<Query> statement,\n+      final Map<String, Object> requestProperties,\n+      final Optional<Boolean> isInternalRequest,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n+      final RateLimiter rateLimiter\n+  ) {\n+    return EngineExecutor\n+        .create(\n+            primaryContext,\n+            serviceContext,\n+            statement.getSessionConfig()\n+        )\n+        .executePullQuery(\n+            this,", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg3NzY0MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516877640", "bodyText": "Refactored to not pass this", "author": "vpapavas", "createdAt": "2020-11-03T18:37:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5OTUyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5OTk5Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516399996", "bodyText": "why do we bother passing in the key here? the key is only ever KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING", "author": "agavra", "createdAt": "2020-11-03T02:40:27Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public class PullQueryConfigRoutingOptions implements RoutingOptions {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final Map<String, ?> configOverrides;\n+  private final Map<String, ?> requestProperties;\n+\n+  PullQueryConfigRoutingOptions(\n+      final KsqlConfig ksqlConfig,\n+      final Map<String, ?> configOverrides,\n+      final Map<String, ?> requestProperties\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.configOverrides = configOverrides;\n+    this.requestProperties = Objects.requireNonNull(requestProperties, \"requestProperties\");\n+  }\n+\n+  private long getLong(final String key) {\n+    if (configOverrides.containsKey(key)) {\n+      return (Long) configOverrides.get(key);\n+    }\n+    return ksqlConfig.getLong(key);\n+  }\n+\n+  private boolean getForwardedFlag(final String key) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg4MjE2NQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516882165", "bodyText": "Fixed", "author": "vpapavas", "createdAt": "2020-11-03T18:45:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5OTk5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMDI2MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516400260", "bodyText": "might make sense to javadoc this (especially how it plays together with all the other \"plans\" in ksql)", "author": "agavra", "createdAt": "2020-11-03T02:41:47Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class PullPhysicalPlan {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMDk3OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516400979", "bodyText": "nit: instead of having mutable state, it's usually easier to reason about code that just passes down the variables (i.e. make these local final and just pass them down into methods that need them). that way we don't need to think about \"what if one of these changes?\"", "author": "agavra", "createdAt": "2020-11-03T02:44:51Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg5MjY2OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516892669", "bodyText": "Fixed", "author": "vpapavas", "createdAt": "2020-11-03T19:04:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMDk3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMTY0OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516401649", "bodyText": "let's handle this explicitly instead of just a comment :) (e.g. check that the root node is indeed a KsqlBareOutputNode and throw an exception if it's a KsqlStructuredDataOutputNode, which should only be created for C*AS statemetns)", "author": "agavra", "createdAt": "2020-11-03T02:47:58Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMjI5NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516402294", "bodyText": "going forward, it would be really cool if we could have a PlanNode#getType so that you can implement this as a switch statement. That makes sure that if anyone adds a new type of node it would automatically be covered here", "author": "agavra", "createdAt": "2020-11-03T02:50:59Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzOTM0Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517039346", "bodyText": "+1 :)", "author": "guozhangwang", "createdAt": "2020-11-04T00:54:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMjI5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMjM4Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516402383", "bodyText": "let's make this a better exception! What if the user saw this \ud83d\ude40", "author": "agavra", "createdAt": "2020-11-03T02:51:20Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMjY2Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516402666", "bodyText": "as with above, we should codify this in code. if it has more than one source, let's throw an explicit error instead of failing soft. then we can remove the comment as the code is self-documenting. Imagine we supported join pull queries going forward, it would be much easier to write a test and then just see where it explicitly throws an exception instead of trying to figure out where it silently failed \ud83e\udd2d", "author": "agavra", "createdAt": "2020-11-03T02:52:38Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMzA2Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516403063", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private LogicalSchema buildSchema(\n          \n          \n            \n              private LogicalSchema buildSelectStarSchema(", "author": "agavra", "createdAt": "2020-11-03T02:54:20Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),\n+        queryId,\n+        keys,\n+        mat,\n+        dataSourceOperator);\n+  }\n+\n+  private ProjectOperator translateProjectNode(final ProjectNode logicalNode) {\n+    LogicalSchema outputSchema = null;\n+    boolean isStar = false;\n+    if (isSelectStar(statement.getStatement().getSelect())) {\n+      isStar = true;\n+      outputSchema = buildSchema(mat.schema(), mat.windowType().isPresent());\n+    } else {\n+      final List<SelectExpression> projection = analysis.getSelectItems().stream()\n+          .map(SingleColumn.class::cast)\n+          .map(si -> SelectExpression\n+              .of(si.getAlias().orElseThrow(IllegalStateException::new), si.getExpression()))\n+          .collect(Collectors.toList());\n+\n+      outputSchema = selectOutputSchema(\n+          executionContext, projection, mat.windowType());\n+    }\n+    return new ProjectOperator(\n+      config,\n+      metaStore,\n+      mat,\n+      analysis,\n+      executionContext,\n+      contextStacker,\n+      logicalNode,\n+      outputSchema,\n+      isStar);\n+  }\n+\n+  private SelectOperator translateFilterNode(final FilterNode logicalNode) {\n+    whereInfo = WhereInfo.extractWhereInfo(analysis, persistentQueryMetadata);\n+    return new SelectOperator(logicalNode);\n+  }\n+\n+  private AbstractPhysicalOperator translateDataSourceNode(\n+      final DataSourceNode logicalNode,\n+      final PersistentQueryMetadata persistentQueryMetadata\n+  ) {\n+    if (whereInfo == null) {\n+      throw new KsqlException(\"Pull queries must have a WHERE clause\");\n+    }\n+    keys = whereInfo.getKeysBound().stream()\n+        .map(keyBound -> asKeyStruct(keyBound, persistentQueryMetadata.getPhysicalSchema()))\n+        .collect(ImmutableList.toImmutableList());\n+\n+    if (!whereInfo.getWindowBounds().isPresent()) {\n+      return new KeyedTableLookupOperator(mat, logicalNode);\n+    } else {\n+      return new KeyedWindowedTableLookupOperator(\n+          mat, logicalNode, whereInfo.getWindowBounds().get());\n+    }\n+  }\n+\n+  private PersistentQueryMetadata findMaterializingQuery(\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis\n+  ) {\n+    final MetaStore metaStore = executionContext.getMetaStore();\n+\n+    final SourceName sourceName = getSourceName(analysis);\n+\n+    final Set<String> queries = metaStore.getQueriesWithSink(sourceName);\n+    if (queries.isEmpty()) {\n+      throw notMaterializedException(sourceName);\n+    }\n+    if (queries.size() > 1) {\n+      throw new KsqlException(\n+        \"Multiple queries currently materialize '\" + sourceName + \"'.\"\n+        + \" KSQL currently only supports pull queries when the table has only been\"\n+        + \" materialized once.\");\n+    }\n+\n+    final QueryId queryId = new QueryId(Iterables.get(queries, 0));\n+\n+    final PersistentQueryMetadata query = executionContext\n+        .getPersistentQuery(queryId)\n+        .orElseThrow(() -> new KsqlException(\"Materializing query has been stopped\"));\n+\n+    if (query.getDataSourceType() != DataSourceType.KTABLE) {\n+      throw new KsqlException(\"Pull queries are not supported on streams.\");\n+    }\n+\n+    return query;\n+  }\n+\n+  private SourceName getSourceName(final ImmutableAnalysis analysis) {\n+    final DataSource source = analysis.getFrom().getDataSource();\n+    return source.getName();\n+  }\n+\n+  private KsqlException notMaterializedException(final SourceName sourceTable) {\n+    return new KsqlException(\n+        \"Can't pull from \" + sourceTable + \" as it's not a materialized table.\"\n+            + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n+    );\n+  }\n+\n+  private Struct asKeyStruct(final Object keyValue, final PhysicalSchema physicalSchema) {\n+    final ConnectSchema keySchema = ConnectSchemas\n+        .columnsToConnectSchema(physicalSchema.keySchema().columns());\n+\n+    final Field keyField = Iterables.getOnlyElement(keySchema.fields());\n+\n+    final Struct key = new Struct(keySchema);\n+    key.put(keyField, keyValue);\n+    return key;\n+  }\n+\n+  private LogicalSchema selectOutputSchema(\n+      final KsqlExecutionContext executionContext,\n+      final List<SelectExpression> selectExpressions,\n+      final Optional<WindowType> windowType\n+  ) {\n+    final Builder schemaBuilder = LogicalSchema.builder();\n+\n+    // Copy meta & key columns into the value schema as SelectValueMapper expects it:\n+    final LogicalSchema schema = mat.schema()\n+        .withPseudoAndKeyColsInValue(windowType.isPresent());\n+\n+    final ExpressionTypeManager expressionTypeManager =\n+        new ExpressionTypeManager(schema, executionContext.getMetaStore());\n+\n+    for (final SelectExpression select : selectExpressions) {\n+      final SqlType type = expressionTypeManager.getExpressionSqlType(select.getExpression());\n+\n+      if (mat.schema().isKeyColumn(select.getAlias())\n+          || select.getAlias().equals(SystemColumns.WINDOWSTART_NAME)\n+          || select.getAlias().equals(SystemColumns.WINDOWEND_NAME)\n+      ) {\n+        schemaBuilder.keyColumn(select.getAlias(), type);\n+      } else {\n+        schemaBuilder.valueColumn(select.getAlias(), type);\n+      }\n+    }\n+    return schemaBuilder.build();\n+  }\n+\n+  private boolean isSelectStar(final Select select) {\n+    final boolean someStars = select.getSelectItems().stream()\n+        .anyMatch(s -> s instanceof AllColumns);\n+\n+    if (someStars && select.getSelectItems().size() != 1) {\n+      throw new KsqlException(\"Pull queries only support wildcards in the projects \"\n+                                  + \"if they are the only expression\");\n+    }\n+\n+    return someStars;\n+  }\n+\n+  private QueryId uniqueQueryId() {\n+    return new QueryId(\"query_\" + System.currentTimeMillis());\n+  }\n+\n+  private LogicalSchema buildSchema(", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMzMwOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516403309", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                LogicalSchema outputSchema = null;\n          \n          \n            \n                final LogicalSchema outputSchema = null;", "author": "agavra", "createdAt": "2020-11-03T02:55:11Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),\n+        queryId,\n+        keys,\n+        mat,\n+        dataSourceOperator);\n+  }\n+\n+  private ProjectOperator translateProjectNode(final ProjectNode logicalNode) {\n+    LogicalSchema outputSchema = null;", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg5Nzk4NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516897984", "bodyText": "It can't be final", "author": "vpapavas", "createdAt": "2020-11-03T19:14:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMzMwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0MDA4Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517040083", "bodyText": "I think you can actually: https://stackoverflow.com/questions/46574275/declare-a-final-variable-based-on-a-condition-and-use-it-in-lambda-in-java", "author": "guozhangwang", "createdAt": "2020-11-04T00:57:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMzMwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMzQ1Mg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516403452", "bodyText": "shouldn't building the output schema be part of the logical nodes, not the physical?", "author": "agavra", "createdAt": "2020-11-03T02:55:52Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,345 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      // For now assume only single source which is the case for pull queries\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),\n+        queryId,\n+        keys,\n+        mat,\n+        dataSourceOperator);\n+  }\n+\n+  private ProjectOperator translateProjectNode(final ProjectNode logicalNode) {\n+    LogicalSchema outputSchema = null;\n+    boolean isStar = false;\n+    if (isSelectStar(statement.getStatement().getSelect())) {\n+      isStar = true;\n+      outputSchema = buildSchema(mat.schema(), mat.windowType().isPresent());", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg5NzQ1Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516897453", "bodyText": "Yes! All this code is going to move to the logical plan with the refactoring I will do after this PR is merged", "author": "vpapavas", "createdAt": "2020-11-03T19:13:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQwMzQ1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxMDY3Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516410673", "bodyText": "would be good to have a javadoc for this", "author": "agavra", "createdAt": "2020-11-03T03:30:00Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/AbstractPhysicalOperator.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+public abstract class AbstractPhysicalOperator {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0Mzc5MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517043790", "bodyText": "BTW Why declare it as abstract class not interface??", "author": "guozhangwang", "createdAt": "2020-11-04T01:12:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxMDY3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxMzY1NQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516413655", "bodyText": "how are we going to debug this if it happens? should we include information on which node we sent it to? the request? etc...", "author": "agavra", "createdAt": "2020-11-03T03:44:46Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HARouting.class);\n+  private final ExecutorService executorService;\n+  private final KsqlConfig ksqlConfig;\n+  private final PullPhysicalPlan pullPhysicalPlan;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+  private final ServiceContext serviceContext;\n+  private final LogicalSchema outputSchema;\n+  private final QueryId queryId;\n+  private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n+\n+  public HARouting(\n+      final KsqlConfig ksqlConfig,\n+      final PullPhysicalPlan pullPhysicalPlan,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final LogicalSchema outputSchema,\n+      final QueryId queryId,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.pullPhysicalPlan = Objects.requireNonNull(pullPhysicalPlan, \"pullPhysicalPlan\");\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.pullQueryMetrics = Objects.requireNonNull(pullQueryMetrics, \"pullQueryMetrics\");\n+    executorService = Executors.newFixedThreadPool(\n+        ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_THREAD_POOL_SIZE_CONFIG)\n+    );\n+  }\n+\n+  public PullQueryResult handlePullQuery() throws InterruptedException {\n+    final List<KsqlPartitionLocation> locations = pullPhysicalPlan.getMaterialization().locator()\n+        .locate(\n+            pullPhysicalPlan.getKeys(),\n+            routingOptions,\n+            routingFilterFactory\n+    );\n+\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n+      LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n+                statement.getStatementText());\n+      throw new MaterializationException(String.format(\n+          \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n+          statement.getStatementText()));\n+    }\n+\n+    // The source nodes associated with each of the rows\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlPartitionLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n+    for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n+      final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlPartitionLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        futures.put(node, executorService.submit(() -> {\n+          return routeQuery(\n+              node, entry.getValue(), statement, serviceContext, routingOptions, pullQueryMetrics);\n+        }));\n+      }\n+\n+      // Go through all of the results of the requests, either aggregating rows or adding\n+      // the locations to the nextRoundRemaining list.\n+      final ImmutableList.Builder<KsqlPartitionLocation> nextRoundRemaining\n+          = ImmutableList.builder();\n+      for (Map.Entry<KsqlNode, Future<PullQueryResult>> entry : futures.entrySet()) {\n+        final Future<PullQueryResult> future = entry.getValue();\n+        final KsqlNode node = entry.getKey();\n+        try {\n+          final PullQueryResult result = future.get();\n+          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n+          schemas.add(result.getSchema());\n+          tableRows.addAll(result.getTableRows());\n+        } catch (ExecutionException e) {\n+          LOG.warn(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n+                   statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n+          nextRoundRemaining.addAll(groupedByHost.get(node));\n+        }\n+      }\n+      remainingLocations = nextRoundRemaining.build();\n+\n+      // If there are no partition locations remaining, then we're done.\n+      if (remainingLocations.size() == 0) {\n+        validateSchemas(schemas);\n+        return new PullQueryResult(\n+            tableRows,\n+            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes),\n+            Iterables.getLast(schemas),\n+            queryId);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Groups all of the partition locations by the round-th entry in their prioritized list\n+   * of host nodes.\n+   * @param statement the statement from which this request came\n+   * @param locations the list of partition locations to parse\n+   * @param round which round this is\n+   * @return A map of node to list of partition locations\n+   */\n+  private Map<KsqlNode, List<KsqlPartitionLocation>> groupByHost(\n+      final ConfiguredStatement<Query> statement,\n+      final List<KsqlPartitionLocation> locations,\n+      final int round) {\n+    final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost = new LinkedHashMap<>();\n+    for (KsqlPartitionLocation location : locations) {\n+      // If one of the partitions required is out of nodes, then we cannot continue.\n+      if (round >= location.getNodes().size()) {\n+        throw new MaterializationException(String.format(\n+            \"Unable to execute pull query: %s. Exhausted standby hosts to try.\",\n+            statement.getStatementText()));\n+      }\n+      final KsqlNode nextHost = location.getNodes().get(round);\n+      groupedByHost.computeIfAbsent(nextHost, h -> new ArrayList<>()).add(location);\n+    }\n+    return groupedByHost;\n+  }\n+\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    PullQueryResult routeQuery(\n+        KsqlNode node,\n+        List<KsqlPartitionLocation> locations,\n+        ConfiguredStatement<Query> statement,\n+        ServiceContext serviceContext,\n+        RoutingOptions routingOptions,\n+        Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+    );\n+  }\n+\n+  private PullQueryResult routeQuery(\n+      final KsqlNode node,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final RoutingOptions routingOptions,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+    List<List<?>> rows = null;\n+    if (node.isLocal()) {\n+      LOG.debug(\"Query {} executed locally at host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordLocalRequests(1));\n+      rows = pullPhysicalPlan.execute(locations, pullQueryMetrics);\n+\n+    } else {\n+      LOG.debug(\"Query {} routed to host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordRemoteRequests(1));\n+      rows = forwardTo(node, locations, statement, serviceContext);\n+    }\n+    final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n+        routingOptions.isDebugRequest()\n+            ? Collections.nCopies(rows.size(), node) : null);\n+    return new PullQueryResult(\n+        rows,\n+        debugNodes,\n+        outputSchema,\n+        queryId);\n+  }\n+\n+  private static List<List<?>> forwardTo(\n+      final KsqlNode owner,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext\n+  ) {\n+\n+    // Specify the partitions we specifically want to read.  This will prevent reading unintended\n+    // standby data when we are reading active for example.\n+    final String partitions = locations.stream()\n+        .map(location -> Integer.toString(location.getPartition()))\n+        .collect(Collectors.joining(\",\"));\n+    // Add skip forward flag to properties\n+    final Map<String, Object> requestProperties = ImmutableMap.of(\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING, true,\n+        KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true,\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS, partitions);\n+    final RestResponse<List<StreamedRow>> response = serviceContext\n+        .getKsqlClient()\n+        .makeQueryRequest(\n+            owner.location(),\n+            statement.getStatementText(),\n+            statement.getSessionConfig().getOverrides(),\n+            requestProperties\n+        );\n+\n+    if (response.isErroneous()) {\n+      throw new KsqlServerException(\"Forwarding attempt failed: \" + response.getErrorMessage());", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxMzcyOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516413729", "bodyText": "what could cause this? similarly to the above error, we should include information on the node that we sent to, the request etc... at a minimum, we should log it at the error level if we believe this is 100% our fault (can't be a user error)\nalso, we should probably have something like \"Invalid empty response from forwarding call to {}: Expected a header row\" (reading this code, I wasn't sure why an empty response is invalid - i assumed it meant no response)", "author": "agavra", "createdAt": "2020-11-03T03:45:05Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HARouting.class);\n+  private final ExecutorService executorService;\n+  private final KsqlConfig ksqlConfig;\n+  private final PullPhysicalPlan pullPhysicalPlan;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+  private final ServiceContext serviceContext;\n+  private final LogicalSchema outputSchema;\n+  private final QueryId queryId;\n+  private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n+\n+  public HARouting(\n+      final KsqlConfig ksqlConfig,\n+      final PullPhysicalPlan pullPhysicalPlan,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final LogicalSchema outputSchema,\n+      final QueryId queryId,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.pullPhysicalPlan = Objects.requireNonNull(pullPhysicalPlan, \"pullPhysicalPlan\");\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.pullQueryMetrics = Objects.requireNonNull(pullQueryMetrics, \"pullQueryMetrics\");\n+    executorService = Executors.newFixedThreadPool(\n+        ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_THREAD_POOL_SIZE_CONFIG)\n+    );\n+  }\n+\n+  public PullQueryResult handlePullQuery() throws InterruptedException {\n+    final List<KsqlPartitionLocation> locations = pullPhysicalPlan.getMaterialization().locator()\n+        .locate(\n+            pullPhysicalPlan.getKeys(),\n+            routingOptions,\n+            routingFilterFactory\n+    );\n+\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n+      LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n+                statement.getStatementText());\n+      throw new MaterializationException(String.format(\n+          \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n+          statement.getStatementText()));\n+    }\n+\n+    // The source nodes associated with each of the rows\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlPartitionLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n+    for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n+      final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlPartitionLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        futures.put(node, executorService.submit(() -> {\n+          return routeQuery(\n+              node, entry.getValue(), statement, serviceContext, routingOptions, pullQueryMetrics);\n+        }));\n+      }\n+\n+      // Go through all of the results of the requests, either aggregating rows or adding\n+      // the locations to the nextRoundRemaining list.\n+      final ImmutableList.Builder<KsqlPartitionLocation> nextRoundRemaining\n+          = ImmutableList.builder();\n+      for (Map.Entry<KsqlNode, Future<PullQueryResult>> entry : futures.entrySet()) {\n+        final Future<PullQueryResult> future = entry.getValue();\n+        final KsqlNode node = entry.getKey();\n+        try {\n+          final PullQueryResult result = future.get();\n+          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n+          schemas.add(result.getSchema());\n+          tableRows.addAll(result.getTableRows());\n+        } catch (ExecutionException e) {\n+          LOG.warn(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n+                   statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n+          nextRoundRemaining.addAll(groupedByHost.get(node));\n+        }\n+      }\n+      remainingLocations = nextRoundRemaining.build();\n+\n+      // If there are no partition locations remaining, then we're done.\n+      if (remainingLocations.size() == 0) {\n+        validateSchemas(schemas);\n+        return new PullQueryResult(\n+            tableRows,\n+            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes),\n+            Iterables.getLast(schemas),\n+            queryId);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Groups all of the partition locations by the round-th entry in their prioritized list\n+   * of host nodes.\n+   * @param statement the statement from which this request came\n+   * @param locations the list of partition locations to parse\n+   * @param round which round this is\n+   * @return A map of node to list of partition locations\n+   */\n+  private Map<KsqlNode, List<KsqlPartitionLocation>> groupByHost(\n+      final ConfiguredStatement<Query> statement,\n+      final List<KsqlPartitionLocation> locations,\n+      final int round) {\n+    final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost = new LinkedHashMap<>();\n+    for (KsqlPartitionLocation location : locations) {\n+      // If one of the partitions required is out of nodes, then we cannot continue.\n+      if (round >= location.getNodes().size()) {\n+        throw new MaterializationException(String.format(\n+            \"Unable to execute pull query: %s. Exhausted standby hosts to try.\",\n+            statement.getStatementText()));\n+      }\n+      final KsqlNode nextHost = location.getNodes().get(round);\n+      groupedByHost.computeIfAbsent(nextHost, h -> new ArrayList<>()).add(location);\n+    }\n+    return groupedByHost;\n+  }\n+\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    PullQueryResult routeQuery(\n+        KsqlNode node,\n+        List<KsqlPartitionLocation> locations,\n+        ConfiguredStatement<Query> statement,\n+        ServiceContext serviceContext,\n+        RoutingOptions routingOptions,\n+        Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+    );\n+  }\n+\n+  private PullQueryResult routeQuery(\n+      final KsqlNode node,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final RoutingOptions routingOptions,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+    List<List<?>> rows = null;\n+    if (node.isLocal()) {\n+      LOG.debug(\"Query {} executed locally at host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordLocalRequests(1));\n+      rows = pullPhysicalPlan.execute(locations, pullQueryMetrics);\n+\n+    } else {\n+      LOG.debug(\"Query {} routed to host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordRemoteRequests(1));\n+      rows = forwardTo(node, locations, statement, serviceContext);\n+    }\n+    final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n+        routingOptions.isDebugRequest()\n+            ? Collections.nCopies(rows.size(), node) : null);\n+    return new PullQueryResult(\n+        rows,\n+        debugNodes,\n+        outputSchema,\n+        queryId);\n+  }\n+\n+  private static List<List<?>> forwardTo(\n+      final KsqlNode owner,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext\n+  ) {\n+\n+    // Specify the partitions we specifically want to read.  This will prevent reading unintended\n+    // standby data when we are reading active for example.\n+    final String partitions = locations.stream()\n+        .map(location -> Integer.toString(location.getPartition()))\n+        .collect(Collectors.joining(\",\"));\n+    // Add skip forward flag to properties\n+    final Map<String, Object> requestProperties = ImmutableMap.of(\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING, true,\n+        KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true,\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS, partitions);\n+    final RestResponse<List<StreamedRow>> response = serviceContext\n+        .getKsqlClient()\n+        .makeQueryRequest(\n+            owner.location(),\n+            statement.getStatementText(),\n+            statement.getSessionConfig().getOverrides(),\n+            requestProperties\n+        );\n+\n+    if (response.isErroneous()) {\n+      throw new KsqlServerException(\"Forwarding attempt failed: \" + response.getErrorMessage());\n+    }\n+\n+    final List<StreamedRow> streamedRows = response.getResponse();\n+    if (streamedRows.isEmpty()) {\n+      throw new KsqlServerException(\"Invalid empty response from forwarding call\");", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNDY4MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516414681", "bodyText": "same as above, let's explain a little more in this error message so that we can debug it if it happens", "author": "agavra", "createdAt": "2020-11-03T03:49:17Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HARouting.class);\n+  private final ExecutorService executorService;\n+  private final KsqlConfig ksqlConfig;\n+  private final PullPhysicalPlan pullPhysicalPlan;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+  private final ServiceContext serviceContext;\n+  private final LogicalSchema outputSchema;\n+  private final QueryId queryId;\n+  private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n+\n+  public HARouting(\n+      final KsqlConfig ksqlConfig,\n+      final PullPhysicalPlan pullPhysicalPlan,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final LogicalSchema outputSchema,\n+      final QueryId queryId,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.pullPhysicalPlan = Objects.requireNonNull(pullPhysicalPlan, \"pullPhysicalPlan\");\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.pullQueryMetrics = Objects.requireNonNull(pullQueryMetrics, \"pullQueryMetrics\");\n+    executorService = Executors.newFixedThreadPool(\n+        ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_THREAD_POOL_SIZE_CONFIG)\n+    );\n+  }\n+\n+  public PullQueryResult handlePullQuery() throws InterruptedException {\n+    final List<KsqlPartitionLocation> locations = pullPhysicalPlan.getMaterialization().locator()\n+        .locate(\n+            pullPhysicalPlan.getKeys(),\n+            routingOptions,\n+            routingFilterFactory\n+    );\n+\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n+      LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n+                statement.getStatementText());\n+      throw new MaterializationException(String.format(\n+          \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n+          statement.getStatementText()));\n+    }\n+\n+    // The source nodes associated with each of the rows\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlPartitionLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n+    for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n+      final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlPartitionLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        futures.put(node, executorService.submit(() -> {\n+          return routeQuery(\n+              node, entry.getValue(), statement, serviceContext, routingOptions, pullQueryMetrics);\n+        }));\n+      }\n+\n+      // Go through all of the results of the requests, either aggregating rows or adding\n+      // the locations to the nextRoundRemaining list.\n+      final ImmutableList.Builder<KsqlPartitionLocation> nextRoundRemaining\n+          = ImmutableList.builder();\n+      for (Map.Entry<KsqlNode, Future<PullQueryResult>> entry : futures.entrySet()) {\n+        final Future<PullQueryResult> future = entry.getValue();\n+        final KsqlNode node = entry.getKey();\n+        try {\n+          final PullQueryResult result = future.get();\n+          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n+          schemas.add(result.getSchema());\n+          tableRows.addAll(result.getTableRows());\n+        } catch (ExecutionException e) {\n+          LOG.warn(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n+                   statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n+          nextRoundRemaining.addAll(groupedByHost.get(node));\n+        }\n+      }\n+      remainingLocations = nextRoundRemaining.build();\n+\n+      // If there are no partition locations remaining, then we're done.\n+      if (remainingLocations.size() == 0) {\n+        validateSchemas(schemas);\n+        return new PullQueryResult(\n+            tableRows,\n+            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes),\n+            Iterables.getLast(schemas),\n+            queryId);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Groups all of the partition locations by the round-th entry in their prioritized list\n+   * of host nodes.\n+   * @param statement the statement from which this request came\n+   * @param locations the list of partition locations to parse\n+   * @param round which round this is\n+   * @return A map of node to list of partition locations\n+   */\n+  private Map<KsqlNode, List<KsqlPartitionLocation>> groupByHost(\n+      final ConfiguredStatement<Query> statement,\n+      final List<KsqlPartitionLocation> locations,\n+      final int round) {\n+    final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost = new LinkedHashMap<>();\n+    for (KsqlPartitionLocation location : locations) {\n+      // If one of the partitions required is out of nodes, then we cannot continue.\n+      if (round >= location.getNodes().size()) {\n+        throw new MaterializationException(String.format(\n+            \"Unable to execute pull query: %s. Exhausted standby hosts to try.\",\n+            statement.getStatementText()));\n+      }\n+      final KsqlNode nextHost = location.getNodes().get(round);\n+      groupedByHost.computeIfAbsent(nextHost, h -> new ArrayList<>()).add(location);\n+    }\n+    return groupedByHost;\n+  }\n+\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    PullQueryResult routeQuery(\n+        KsqlNode node,\n+        List<KsqlPartitionLocation> locations,\n+        ConfiguredStatement<Query> statement,\n+        ServiceContext serviceContext,\n+        RoutingOptions routingOptions,\n+        Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+    );\n+  }\n+\n+  private PullQueryResult routeQuery(\n+      final KsqlNode node,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final RoutingOptions routingOptions,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+    List<List<?>> rows = null;\n+    if (node.isLocal()) {\n+      LOG.debug(\"Query {} executed locally at host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordLocalRequests(1));\n+      rows = pullPhysicalPlan.execute(locations, pullQueryMetrics);\n+\n+    } else {\n+      LOG.debug(\"Query {} routed to host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordRemoteRequests(1));\n+      rows = forwardTo(node, locations, statement, serviceContext);\n+    }\n+    final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n+        routingOptions.isDebugRequest()\n+            ? Collections.nCopies(rows.size(), node) : null);\n+    return new PullQueryResult(\n+        rows,\n+        debugNodes,\n+        outputSchema,\n+        queryId);\n+  }\n+\n+  private static List<List<?>> forwardTo(\n+      final KsqlNode owner,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext\n+  ) {\n+\n+    // Specify the partitions we specifically want to read.  This will prevent reading unintended\n+    // standby data when we are reading active for example.\n+    final String partitions = locations.stream()\n+        .map(location -> Integer.toString(location.getPartition()))\n+        .collect(Collectors.joining(\",\"));\n+    // Add skip forward flag to properties\n+    final Map<String, Object> requestProperties = ImmutableMap.of(\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING, true,\n+        KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true,\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS, partitions);\n+    final RestResponse<List<StreamedRow>> response = serviceContext\n+        .getKsqlClient()\n+        .makeQueryRequest(\n+            owner.location(),\n+            statement.getStatementText(),\n+            statement.getSessionConfig().getOverrides(),\n+            requestProperties\n+        );\n+\n+    if (response.isErroneous()) {\n+      throw new KsqlServerException(\"Forwarding attempt failed: \" + response.getErrorMessage());\n+    }\n+\n+    final List<StreamedRow> streamedRows = response.getResponse();\n+    if (streamedRows.isEmpty()) {\n+      throw new KsqlServerException(\"Invalid empty response from forwarding call\");\n+    }\n+\n+    final List<List<?>> rows = new ArrayList<>();\n+\n+    for (final StreamedRow row : streamedRows.subList(1, streamedRows.size())) {\n+      if (row.getErrorMessage().isPresent()) {\n+        throw new KsqlStatementException(\n+            row.getErrorMessage().get().getMessage(),\n+            statement.getStatementText()\n+        );\n+      }\n+\n+      if (!row.getRow().isPresent()) {\n+        throw new KsqlServerException(\"Unexpected forwarding response\");", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNTEzMg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516415132", "bodyText": "we should include information on which host each conflicting schema was on so that we can debug it, and it probably makes sense to also print the schemas that differed.\nAlso, what happens if a pull query is issued in the middle of a query upgrade? It's possible that some nodes have the old schema and some have the new schema - the new schema should be backwards compatible with the old one. Out of scope for this PR, but can you create a ticket to track this?", "author": "agavra", "createdAt": "2020-11-03T03:51:33Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HARouting.class);\n+  private final ExecutorService executorService;\n+  private final KsqlConfig ksqlConfig;\n+  private final PullPhysicalPlan pullPhysicalPlan;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+  private final ServiceContext serviceContext;\n+  private final LogicalSchema outputSchema;\n+  private final QueryId queryId;\n+  private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n+\n+  public HARouting(\n+      final KsqlConfig ksqlConfig,\n+      final PullPhysicalPlan pullPhysicalPlan,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final LogicalSchema outputSchema,\n+      final QueryId queryId,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.pullPhysicalPlan = Objects.requireNonNull(pullPhysicalPlan, \"pullPhysicalPlan\");\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.pullQueryMetrics = Objects.requireNonNull(pullQueryMetrics, \"pullQueryMetrics\");\n+    executorService = Executors.newFixedThreadPool(\n+        ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_THREAD_POOL_SIZE_CONFIG)\n+    );\n+  }\n+\n+  public PullQueryResult handlePullQuery() throws InterruptedException {\n+    final List<KsqlPartitionLocation> locations = pullPhysicalPlan.getMaterialization().locator()\n+        .locate(\n+            pullPhysicalPlan.getKeys(),\n+            routingOptions,\n+            routingFilterFactory\n+    );\n+\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n+      LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n+                statement.getStatementText());\n+      throw new MaterializationException(String.format(\n+          \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n+          statement.getStatementText()));\n+    }\n+\n+    // The source nodes associated with each of the rows\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlPartitionLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n+    for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n+      final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlPartitionLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        futures.put(node, executorService.submit(() -> {\n+          return routeQuery(\n+              node, entry.getValue(), statement, serviceContext, routingOptions, pullQueryMetrics);\n+        }));\n+      }\n+\n+      // Go through all of the results of the requests, either aggregating rows or adding\n+      // the locations to the nextRoundRemaining list.\n+      final ImmutableList.Builder<KsqlPartitionLocation> nextRoundRemaining\n+          = ImmutableList.builder();\n+      for (Map.Entry<KsqlNode, Future<PullQueryResult>> entry : futures.entrySet()) {\n+        final Future<PullQueryResult> future = entry.getValue();\n+        final KsqlNode node = entry.getKey();\n+        try {\n+          final PullQueryResult result = future.get();\n+          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n+          schemas.add(result.getSchema());\n+          tableRows.addAll(result.getTableRows());\n+        } catch (ExecutionException e) {\n+          LOG.warn(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n+                   statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n+          nextRoundRemaining.addAll(groupedByHost.get(node));\n+        }\n+      }\n+      remainingLocations = nextRoundRemaining.build();\n+\n+      // If there are no partition locations remaining, then we're done.\n+      if (remainingLocations.size() == 0) {\n+        validateSchemas(schemas);\n+        return new PullQueryResult(\n+            tableRows,\n+            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes),\n+            Iterables.getLast(schemas),\n+            queryId);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Groups all of the partition locations by the round-th entry in their prioritized list\n+   * of host nodes.\n+   * @param statement the statement from which this request came\n+   * @param locations the list of partition locations to parse\n+   * @param round which round this is\n+   * @return A map of node to list of partition locations\n+   */\n+  private Map<KsqlNode, List<KsqlPartitionLocation>> groupByHost(\n+      final ConfiguredStatement<Query> statement,\n+      final List<KsqlPartitionLocation> locations,\n+      final int round) {\n+    final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost = new LinkedHashMap<>();\n+    for (KsqlPartitionLocation location : locations) {\n+      // If one of the partitions required is out of nodes, then we cannot continue.\n+      if (round >= location.getNodes().size()) {\n+        throw new MaterializationException(String.format(\n+            \"Unable to execute pull query: %s. Exhausted standby hosts to try.\",\n+            statement.getStatementText()));\n+      }\n+      final KsqlNode nextHost = location.getNodes().get(round);\n+      groupedByHost.computeIfAbsent(nextHost, h -> new ArrayList<>()).add(location);\n+    }\n+    return groupedByHost;\n+  }\n+\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    PullQueryResult routeQuery(\n+        KsqlNode node,\n+        List<KsqlPartitionLocation> locations,\n+        ConfiguredStatement<Query> statement,\n+        ServiceContext serviceContext,\n+        RoutingOptions routingOptions,\n+        Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+    );\n+  }\n+\n+  private PullQueryResult routeQuery(\n+      final KsqlNode node,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final RoutingOptions routingOptions,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+    List<List<?>> rows = null;\n+    if (node.isLocal()) {\n+      LOG.debug(\"Query {} executed locally at host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordLocalRequests(1));\n+      rows = pullPhysicalPlan.execute(locations, pullQueryMetrics);\n+\n+    } else {\n+      LOG.debug(\"Query {} routed to host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordRemoteRequests(1));\n+      rows = forwardTo(node, locations, statement, serviceContext);\n+    }\n+    final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n+        routingOptions.isDebugRequest()\n+            ? Collections.nCopies(rows.size(), node) : null);\n+    return new PullQueryResult(\n+        rows,\n+        debugNodes,\n+        outputSchema,\n+        queryId);\n+  }\n+\n+  private static List<List<?>> forwardTo(\n+      final KsqlNode owner,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext\n+  ) {\n+\n+    // Specify the partitions we specifically want to read.  This will prevent reading unintended\n+    // standby data when we are reading active for example.\n+    final String partitions = locations.stream()\n+        .map(location -> Integer.toString(location.getPartition()))\n+        .collect(Collectors.joining(\",\"));\n+    // Add skip forward flag to properties\n+    final Map<String, Object> requestProperties = ImmutableMap.of(\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING, true,\n+        KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true,\n+        KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS, partitions);\n+    final RestResponse<List<StreamedRow>> response = serviceContext\n+        .getKsqlClient()\n+        .makeQueryRequest(\n+            owner.location(),\n+            statement.getStatementText(),\n+            statement.getSessionConfig().getOverrides(),\n+            requestProperties\n+        );\n+\n+    if (response.isErroneous()) {\n+      throw new KsqlServerException(\"Forwarding attempt failed: \" + response.getErrorMessage());\n+    }\n+\n+    final List<StreamedRow> streamedRows = response.getResponse();\n+    if (streamedRows.isEmpty()) {\n+      throw new KsqlServerException(\"Invalid empty response from forwarding call\");\n+    }\n+\n+    final List<List<?>> rows = new ArrayList<>();\n+\n+    for (final StreamedRow row : streamedRows.subList(1, streamedRows.size())) {\n+      if (row.getErrorMessage().isPresent()) {\n+        throw new KsqlStatementException(\n+            row.getErrorMessage().get().getMessage(),\n+            statement.getStatementText()\n+        );\n+      }\n+\n+      if (!row.getRow().isPresent()) {\n+        throw new KsqlServerException(\"Unexpected forwarding response\");\n+      }\n+\n+      rows.add(row.getRow().get().values());\n+    }\n+\n+    return rows;\n+  }\n+\n+  private void validateSchemas(final List<LogicalSchema> schemas) {\n+    final LogicalSchema schema = Iterables.getLast(schemas);\n+    for (LogicalSchema s : schemas) {\n+      if (!schema.equals(s)) {\n+        throw new KsqlException(\"Schemas from different hosts should be identical\");", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxOTMyNg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517019326", "bodyText": "Tracked in #6571", "author": "vpapavas", "createdAt": "2020-11-03T23:42:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNTEzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNTYyNg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516415626", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  for (Struct key : location.getKeys().get()) {\n          \n          \n            \n                  for (final Struct key : location.getKeys().get()) {\n          \n      \n    \n    \n  \n\nDo we have checkstyle off for these classes? this should be failing I think", "author": "agavra", "createdAt": "2020-11-03T03:54:09Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.Row;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KeyedTableLookupOperator\n+    extends AbstractPhysicalOperator\n+    implements UnaryPhysicalOperator, DataSourceOperator {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(KeyedTableLookupOperator.class);\n+\n+  private final Materialization mat;\n+  private final DataSourceNode logicalOperator;\n+\n+  private List<KsqlPartitionLocation> partitionLocations;\n+  private Iterator<Row> resultIterator;\n+\n+  public KeyedTableLookupOperator(\n+      final Materialization mat,\n+      final DataSourceNode logicalNode\n+  ) {\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+  }\n+\n+  @Override\n+  public void open() {\n+    final List<Row> result = new ArrayList<>();\n+    for (KsqlPartitionLocation location : partitionLocations) {\n+      if (!location.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Table lookup queries should be done with keys\");\n+      }\n+      for (Struct key : location.getKeys().get()) {", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNjA5OA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516416098", "bodyText": "would be nice to javadoc this - especially since it's mutable state. Why can't the locations be passed to the methods that need them?", "author": "agavra", "createdAt": "2020-11-03T03:56:26Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/DataSourceOperator.java", "diffHunk": "@@ -0,0 +1,26 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import java.util.List;\n+\n+public interface DataSourceOperator {\n+\n+  List<KsqlPartitionLocation> getPartitionLocations();\n+\n+  void setPartitionLocations(List<KsqlPartitionLocation> partitionLocations);", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNjcxOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516416719", "bodyText": "nit: these comments aren't really helpful", "author": "agavra", "createdAt": "2020-11-03T03:59:20Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class ProjectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final MetaStore metaStore;\n+  private final Materialization mat;\n+  private final ImmutableAnalysis analysis;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final LogicalSchema outputSchema;\n+  private final boolean isSelectStar;\n+\n+  private AbstractPhysicalOperator child;\n+  private ProjectNode logicalNode;\n+  private TableRow row;\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  private Function<TableRow, GenericRow> preSelectTransform;\n+\n+  public ProjectOperator(\n+      final KsqlConfig ksqlConfig,\n+      final MetaStore metaStore,\n+      final Materialization mat,\n+      final ImmutableAnalysis analysis,\n+      final KsqlExecutionContext executionContext,\n+      final Stacker contextStacker,\n+      final ProjectNode logicalNode,\n+      final LogicalSchema outputSchema,\n+      final boolean isSelectStar\n+\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"config\");\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n+    this.logicalNode = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.isSelectStar = isSelectStar;\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+    if (isSelectStar) {\n+      return;\n+    }\n+\n+    final LogicalSchema inputSchema = mat.schema();\n+\n+    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(SystemColumns::isSystemColumn);\n+    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(inputSchema::isKeyColumn);\n+\n+    final LogicalSchema intermediateSchema;\n+    if (noSystemColumns && noKeyColumns) {\n+      intermediateSchema = inputSchema;\n+      preSelectTransform = TableRow::value;\n+    } else {\n+      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n+      final boolean windowed = mat.windowType().isPresent();\n+\n+      intermediateSchema = inputSchema\n+          .withPseudoAndKeyColsInValue(windowed);\n+\n+      preSelectTransform = row -> {\n+        final Struct key = row.key();\n+        final GenericRow value = row.value();\n+\n+        final List<Object> keyFields = key.schema().fields().stream()\n+            .map(key::get)\n+            .collect(Collectors.toList());\n+\n+        value.ensureAdditionalCapacity(\n+            1 // ROWTIME\n+                + keyFields.size()\n+                + row.window().map(w -> 2).orElse(0)\n+        );\n+\n+        value.append(row.rowTime());\n+        value.appendAll(keyFields);\n+\n+        row.window().ifPresent(window -> {\n+          value.append(window.start().toEpochMilli());\n+          value.append(window.end().toEpochMilli());\n+        });\n+\n+        return value;\n+      };\n+    }\n+\n+    final SelectValueMapper<Object> select = SelectValueMapperFactory.create(\n+        logicalNode.getSelectExpressions(),\n+        intermediateSchema,\n+        ksqlConfig,\n+        metaStore\n+    );\n+\n+    final ProcessingLogger logger = executionContext\n+        .getProcessingLogContext()\n+        .getLoggerFactory()\n+        .getLogger(\n+            QueryLoggerUtil.queryLoggerName(\n+                QueryType.PULL_QUERY, contextStacker.push(\"PROJECT\").getQueryContext())\n+        );\n+\n+    transformer = select.getTransformer(logger);\n+\n+    return;\n+  }\n+\n+  @Override\n+  public Object next() {\n+    row = (TableRow)child.next();\n+    if (row == null) {\n+      return null;\n+    }\n+    if (isSelectStar) {\n+      // return List<?>", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNjg0OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516416849", "bodyText": "if child is already non-null, should we throw?", "author": "agavra", "createdAt": "2020-11-03T03:59:51Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class ProjectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final MetaStore metaStore;\n+  private final Materialization mat;\n+  private final ImmutableAnalysis analysis;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final LogicalSchema outputSchema;\n+  private final boolean isSelectStar;\n+\n+  private AbstractPhysicalOperator child;\n+  private ProjectNode logicalNode;\n+  private TableRow row;\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  private Function<TableRow, GenericRow> preSelectTransform;\n+\n+  public ProjectOperator(\n+      final KsqlConfig ksqlConfig,\n+      final MetaStore metaStore,\n+      final Materialization mat,\n+      final ImmutableAnalysis analysis,\n+      final KsqlExecutionContext executionContext,\n+      final Stacker contextStacker,\n+      final ProjectNode logicalNode,\n+      final LogicalSchema outputSchema,\n+      final boolean isSelectStar\n+\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"config\");\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n+    this.logicalNode = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.isSelectStar = isSelectStar;\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+    if (isSelectStar) {\n+      return;\n+    }\n+\n+    final LogicalSchema inputSchema = mat.schema();\n+\n+    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(SystemColumns::isSystemColumn);\n+    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(inputSchema::isKeyColumn);\n+\n+    final LogicalSchema intermediateSchema;\n+    if (noSystemColumns && noKeyColumns) {\n+      intermediateSchema = inputSchema;\n+      preSelectTransform = TableRow::value;\n+    } else {\n+      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n+      final boolean windowed = mat.windowType().isPresent();\n+\n+      intermediateSchema = inputSchema\n+          .withPseudoAndKeyColsInValue(windowed);\n+\n+      preSelectTransform = row -> {\n+        final Struct key = row.key();\n+        final GenericRow value = row.value();\n+\n+        final List<Object> keyFields = key.schema().fields().stream()\n+            .map(key::get)\n+            .collect(Collectors.toList());\n+\n+        value.ensureAdditionalCapacity(\n+            1 // ROWTIME\n+                + keyFields.size()\n+                + row.window().map(w -> 2).orElse(0)\n+        );\n+\n+        value.append(row.rowTime());\n+        value.appendAll(keyFields);\n+\n+        row.window().ifPresent(window -> {\n+          value.append(window.start().toEpochMilli());\n+          value.append(window.end().toEpochMilli());\n+        });\n+\n+        return value;\n+      };\n+    }\n+\n+    final SelectValueMapper<Object> select = SelectValueMapperFactory.create(\n+        logicalNode.getSelectExpressions(),\n+        intermediateSchema,\n+        ksqlConfig,\n+        metaStore\n+    );\n+\n+    final ProcessingLogger logger = executionContext\n+        .getProcessingLogContext()\n+        .getLoggerFactory()\n+        .getLogger(\n+            QueryLoggerUtil.queryLoggerName(\n+                QueryType.PULL_QUERY, contextStacker.push(\"PROJECT\").getQueryContext())\n+        );\n+\n+    transformer = select.getTransformer(logger);\n+\n+    return;\n+  }\n+\n+  @Override\n+  public Object next() {\n+    row = (TableRow)child.next();\n+    if (row == null) {\n+      return null;\n+    }\n+    if (isSelectStar) {\n+      // return List<?>\n+      return createRow(row);\n+    }\n+    final GenericRow intermediate = preSelectTransform.apply(row);\n+\n+    final GenericRow mapped = transformer.transform(\n+        row.key(),\n+        intermediate,\n+        new PullProcessingContext(row.rowTime())\n+    );\n+    validateProjection(mapped, outputSchema);\n+\n+    // return List<?>\n+    return mapped.values();\n+  }\n+\n+  @Override\n+  public void close() {\n+    child.close();\n+  }\n+\n+  @Override\n+  public void addChild(final AbstractPhysicalOperator child) {\n+    this.child = child;", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxNzQ0Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516417443", "bodyText": "why are we using getLast here? did we intend to use getOnlyElement?", "author": "agavra", "createdAt": "2020-11-03T04:02:42Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/WhereInfo.java", "diffHunk": "@@ -0,0 +1,542 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.collect.BoundType;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.collect.Iterables;\n+import com.google.common.collect.Range;\n+import com.google.common.collect.Sets;\n+import com.google.common.collect.Sets.SetView;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.expression.tree.ComparisonExpression;\n+import io.confluent.ksql.execution.expression.tree.ComparisonExpression.Type;\n+import io.confluent.ksql.execution.expression.tree.Expression;\n+import io.confluent.ksql.execution.expression.tree.InPredicate;\n+import io.confluent.ksql.execution.expression.tree.IntegerLiteral;\n+import io.confluent.ksql.execution.expression.tree.Literal;\n+import io.confluent.ksql.execution.expression.tree.LogicalBinaryExpression;\n+import io.confluent.ksql.execution.expression.tree.LongLiteral;\n+import io.confluent.ksql.execution.expression.tree.NullLiteral;\n+import io.confluent.ksql.execution.expression.tree.StringLiteral;\n+import io.confluent.ksql.execution.expression.tree.UnqualifiedColumnReferenceExp;\n+import io.confluent.ksql.name.ColumnName;\n+import io.confluent.ksql.schema.ksql.Column;\n+import io.confluent.ksql.schema.ksql.DefaultSqlValueCoercer;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.utils.FormatOptions;\n+import io.confluent.ksql.util.GrammaticalJoiner;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import io.confluent.ksql.util.timestamp.PartialStringToTimestampParser;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public final class WhereInfo {\n+\n+  private static final Set<Type> VALID_WINDOW_BOUNDS_TYPES = ImmutableSet.of(\n+      Type.EQUAL,\n+      Type.GREATER_THAN,\n+      Type.GREATER_THAN_OR_EQUAL,\n+      Type.LESS_THAN,\n+      Type.LESS_THAN_OR_EQUAL\n+  );\n+\n+  private static final String VALID_WINDOW_BOUNDS_COLUMNS =\n+      GrammaticalJoiner.and().join(SystemColumns.windowBoundsColumnNames());\n+\n+  private static final String VALID_WINDOW_BOUNDS_TYPES_STRING =\n+      GrammaticalJoiner.and().join(VALID_WINDOW_BOUNDS_TYPES);\n+\n+\n+  private final List<Object> keysBound;\n+  private final Optional<WindowBounds> windowBounds;\n+\n+  private WhereInfo(\n+      final List<Object> keysBound,\n+      final Optional<WindowBounds> windowBounds\n+  ) {\n+    this.keysBound = keysBound;\n+    this.windowBounds = Objects.requireNonNull(windowBounds);\n+  }\n+\n+  public static WhereInfo extractWhereInfo(\n+      final ImmutableAnalysis analysis,\n+      final PersistentQueryMetadata query\n+  ) {\n+    final boolean windowed = query.getResultTopic().getKeyFormat().isWindowed();\n+\n+    final Expression where = analysis.getWhereExpression()\n+        .orElseThrow(() -> invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final KeyAndWindowBounds keyAndWindowBounds = extractComparisons(where, query);\n+    final List<ComparisonExpression> keyComparison = keyAndWindowBounds.getKeyColExpression();\n+    final List<InPredicate> inPredicate = keyAndWindowBounds.getInPredicate();\n+    if (keyComparison.size() == 0 && inPredicate.size() == 0) {\n+      throw invalidWhereClauseException(\"WHERE clause missing key column\", windowed);\n+    } else if ((keyComparison.size() + inPredicate.size()) > 1) {\n+      throw invalidWhereClauseException(\"Multiple bounds on key column\", windowed);\n+    }\n+\n+    final List<Object> keys;\n+    if (keyComparison.size() > 0) {\n+      keys = ImmutableList.of(\n+          extractKeyWhereClause(keyComparison, windowed, query.getLogicalSchema()));\n+    } else {\n+      keys = extractKeysFromInPredicate(inPredicate, windowed, query.getLogicalSchema());\n+    }\n+\n+    if (!windowed) {\n+      if (keyAndWindowBounds.getWindowStartExpression().size() > 0\n+          || keyAndWindowBounds.getWindowEndExpression().size() > 0) {\n+        throw invalidWhereClauseException(\"Unsupported WHERE clause\", false);\n+      }\n+\n+      return new WhereInfo(keys, Optional.empty());\n+    }\n+\n+    final WindowBounds windowBounds =\n+        extractWhereClauseWindowBounds(keyAndWindowBounds);\n+\n+    return new WhereInfo(keys, Optional.of(windowBounds));\n+  }\n+\n+  public List<Object> getKeysBound() {\n+    return keysBound;\n+  }\n+\n+  private static List<Object> extractKeysFromInPredicate(\n+      final List<InPredicate> inPredicates,\n+      final boolean windowed,\n+      final LogicalSchema schema\n+  ) {\n+    final InPredicate inPredicate = Iterables.getLast(inPredicates);", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxODI5NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516418294", "bodyText": "uh - shouldn't we be using the result of this? otherwise we're just executing the pull query twice, right? once here and once on line 92?\nalso now that this refactor is done, can we get rid of PullQueryExecutor?", "author": "agavra", "createdAt": "2020-11-03T04:06:36Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/PullQueryPublisher.java", "diffHunk": "@@ -42,32 +45,50 @@\n \n class PullQueryPublisher implements Flow.Publisher<Collection<StreamedRow>> {\n \n+  private final KsqlEngine ksqlEngine;\n   private final ServiceContext serviceContext;\n   private final ConfiguredStatement<Query> query;\n   private final PullQueryExecutor pullQueryExecutor;\n   private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n   private final long startTimeNanos;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RateLimiter rateLimiter;\n \n   @VisibleForTesting\n   PullQueryPublisher(\n+      final KsqlEngine ksqlEngine,\n       final ServiceContext serviceContext,\n       final ConfiguredStatement<Query> query,\n       final PullQueryExecutor pullQueryExecutor,\n       final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n-      final long startTimeNanos\n+      final long startTimeNanos,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RateLimiter rateLimiter\n   ) {\n+    this.ksqlEngine = requireNonNull(ksqlEngine, \"ksqlEngine\");\n     this.serviceContext = requireNonNull(serviceContext, \"serviceContext\");\n     this.query = requireNonNull(query, \"query\");\n     this.pullQueryExecutor = requireNonNull(pullQueryExecutor, \"pullQueryExecutor\");\n     this.pullQueryMetrics = pullQueryMetrics;\n     this.startTimeNanos = startTimeNanos;\n+    this.routingFilterFactory = requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.rateLimiter = requireNonNull(rateLimiter, \"rateLimiter\");\n   }\n \n   @Override\n   public synchronized void subscribe(final Subscriber<Collection<StreamedRow>> subscriber) {\n     final PullQuerySubscription subscription = new PullQuerySubscription(\n         subscriber,\n         () -> {\n+          ksqlEngine.executePullQuery(", "originalCommit": "be69d38620a9d72a17eab4913083890652b3684b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQzMzM0MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516433340", "bodyText": "Yes, I still need to remove all the PullQueryExecutor code. I am leaving it for last because it helps with debugging to verify what the correct behavior should be.", "author": "vpapavas", "createdAt": "2020-11-03T05:22:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQxODI5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg1MzE1Mg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r516853152", "bodyText": "Does anyone know what the code below is doing and why it is needed?", "author": "vpapavas", "createdAt": "2020-11-03T17:54:01Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/ProjectOperator.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil;\n+import io.confluent.ksql.execution.context.QueryLoggerUtil.QueryType;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.TableRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class ProjectOperator extends AbstractPhysicalOperator implements UnaryPhysicalOperator {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final MetaStore metaStore;\n+  private final Materialization mat;\n+  private final ImmutableAnalysis analysis;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final LogicalSchema outputSchema;\n+  private final boolean isSelectStar;\n+\n+  private AbstractPhysicalOperator child;\n+  private ProjectNode logicalNode;\n+  private TableRow row;\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  private Function<TableRow, GenericRow> preSelectTransform;\n+\n+  public ProjectOperator(\n+      final KsqlConfig ksqlConfig,\n+      final MetaStore metaStore,\n+      final Materialization mat,\n+      final ImmutableAnalysis analysis,\n+      final KsqlExecutionContext executionContext,\n+      final Stacker contextStacker,\n+      final ProjectNode logicalNode,\n+      final LogicalSchema outputSchema,\n+      final boolean isSelectStar\n+\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"config\");\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.contextStacker = Objects.requireNonNull(contextStacker, \"contextStacker\");\n+    this.logicalNode = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.isSelectStar = isSelectStar;\n+  }\n+\n+  @Override\n+  public void open() {\n+    child.open();\n+    if (isSelectStar) {\n+      return;\n+    }\n+\n+    final LogicalSchema inputSchema = mat.schema();\n+\n+    final boolean noSystemColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(SystemColumns::isSystemColumn);\n+    final boolean noKeyColumns = analysis.getSelectColumnNames().stream()\n+        .noneMatch(inputSchema::isKeyColumn);\n+\n+    final LogicalSchema intermediateSchema;\n+    if (noSystemColumns && noKeyColumns) {\n+      intermediateSchema = inputSchema;\n+      preSelectTransform = TableRow::value;\n+    } else {\n+      // SelectValueMapper requires the rowTime & key fields in the value schema :(\n+      final boolean windowed = mat.windowType().isPresent();\n+\n+      intermediateSchema = inputSchema\n+          .withPseudoAndKeyColsInValue(windowed);\n+\n+      preSelectTransform = row -> {\n+        final Struct key = row.key();\n+        final GenericRow value = row.value();\n+\n+        final List<Object> keyFields = key.schema().fields().stream()\n+            .map(key::get)\n+            .collect(Collectors.toList());\n+\n+        value.ensureAdditionalCapacity(\n+            1 // ROWTIME\n+            + keyFields.size()\n+            + row.window().map(w -> 2).orElse(0)\n+        );\n+\n+        value.append(row.rowTime());\n+        value.appendAll(keyFields);\n+\n+        row.window().ifPresent(window -> {\n+          value.append(window.start().toEpochMilli());\n+          value.append(window.end().toEpochMilli());\n+        });\n+\n+        return value;\n+      };\n+    }\n+\n+    final SelectValueMapper<Object> select = SelectValueMapperFactory.create(\n+        logicalNode.getSelectExpressions(),\n+        intermediateSchema,\n+        ksqlConfig,\n+        metaStore\n+    );\n+", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyMjcxOA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517722718", "bodyText": "I think because SelectValueMapper is shared with persistent queries and it expects this so it can write errors to the processing topic.  I'm not sure if we really would want that for pull queries or if it's just shoehorned in here because the code is shared.", "author": "AlanConfluent", "createdAt": "2020-11-05T01:08:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg1MzE1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwODkzNw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517008937", "bodyText": "There are several fields that seem not used: routingFilterFactory, serviceContext, routingOptions. If we plan to only add their usage in other PRs let's just remove them for now in this PR.", "author": "guozhangwang", "createdAt": "2020-11-03T23:10:04Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAwOTc3OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517009779", "bodyText": "See my other comment: routingFilterFactory is passed but not used.", "author": "guozhangwang", "createdAt": "2020-11-03T23:12:30Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -116,6 +137,82 @@ ExecuteResult execute(final KsqlPlan plan) {\n     return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n   }\n \n+  PullQueryResult executePullQuery(\n+      final KsqlExecutionContext ksqlEngine,\n+      final ConfiguredStatement<Query> statement,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final Map<String, Object> requestProperties,\n+      final Optional<Boolean> isInternalRequest,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics,\n+      final RateLimiter rateLimiter\n+  ) {\n+\n+    if (!statement.getStatement().isPullQuery()) {\n+      throw new IllegalArgumentException(\"Executor can only handle pull queries\");\n+    }\n+    final SessionConfig sessionConfig = statement.getSessionConfig();\n+    if (!sessionConfig.getConfig(false)\n+        .getBoolean(KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG)) {\n+      throw new KsqlStatementException(\n+          \"Pull queries are disabled.\"\n+              + PullQueryValidator.PULL_QUERY_SYNTAX_HELP\n+              + System.lineSeparator()\n+              + \"Please set \" + KsqlConfig.KSQL_PULL_QUERIES_ENABLE_CONFIG + \"=true to enable \"\n+              + \"this feature.\"\n+              + System.lineSeparator(),\n+          statement.getStatementText());\n+    }\n+\n+    final RoutingOptions routingOptions = new PullQueryConfigRoutingOptions(\n+        sessionConfig.getConfig(false),\n+        statement.getSessionConfig().getOverrides(),\n+        requestProperties\n+    );\n+\n+    // If internal listeners are in use, we require the request to come from that listener to\n+    // treat it as having been forwarded.\n+    final boolean isAlreadyForwarded = routingOptions.skipForwardRequest()\n+        // Trust the forward request option if isInternalRequest isn't available.\n+        && isInternalRequest.orElse(true);\n+\n+    // Only check the rate limit at the forwarding host\n+    if (!isAlreadyForwarded) {\n+      checkRateLimit(rateLimiter);\n+    }\n+\n+\n+    try {\n+      final QueryAnalyzer queryAnalyzer = new QueryAnalyzer(engineContext.getMetaStore(), \"\");\n+      final ImmutableAnalysis analysis = new RewrittenAnalysis(\n+          queryAnalyzer.analyze(statement.getStatement(), Optional.empty()),\n+          new ColumnReferenceRewriter()::process\n+      );\n+      final KsqlConfig ksqlConfig = sessionConfig.getConfig(false);\n+      final LogicalPlanNode logicalPlan = buildAndValidateLogicalPlan(\n+          statement, analysis, ksqlConfig);\n+      final PullPhysicalPlan physicalPlan = buildPullPhysicalPlan(\n+          ksqlEngine,\n+          logicalPlan,\n+          ksqlConfig,\n+          analysis,\n+          routingFilterFactory,", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxMzI0Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517013243", "bodyText": "This is a meta comment: I feel it is a sub-optimal code pattern to pass objects around multiple classes just to trigger their functions at different occasions :) pullQueryMetrics here is an example: we pass it along through many classes, just to trigger its recording functions at processLocal/Remote/Error. I think this class can be created and maintained by a single class and all its triggering can happen at that class. In this example I'm thinking KsqlEngine alone can be the one maintaining this object.", "author": "guozhangwang", "createdAt": "2020-11-03T23:23:11Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java", "diffHunk": "@@ -125,6 +129,16 @@ TransientQueryMetadata executeQuery(\n       ConfiguredStatement<Query> statement\n   );\n \n+  PullQueryResult executePullQuery(\n+      ServiceContext serviceContext,\n+      RoutingFilterFactory routingFilterFactory,\n+      ConfiguredStatement<Query> statement,\n+      Map<String, Object> requestProperties,\n+      Optional<Boolean> isInternalRequest,\n+      Optional<PullQueryExecutorMetrics> pullQueryMetrics,", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI3ODI0NQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523278245", "bodyText": "pullQueryMetrics is actually used in many classes and not only KsqlEngine. The most important one is OldApiUtils where we measures the size of the request/response and the only access to this is through the KsqlRestApplication. The same for the other endpoints where we want to measure latency. The only access point is KsqlRestApplication.", "author": "vpapavas", "createdAt": "2020-11-13T23:07:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxMzI0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxNTQ4OA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517015488", "bodyText": "@agavra @vpapavas for my own education: what part of the query execution logic we put in KsqlEngine and which we put in EngineExecutor? Right now it seems we just use the former as the entry class and directly call the corresponding function (with the same method name) in the latter. Why not just consolidate them into a single class?", "author": "guozhangwang", "createdAt": "2020-11-03T23:30:04Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineExecutor.java", "diffHunk": "@@ -116,6 +137,82 @@ ExecuteResult execute(final KsqlPlan plan) {\n     return ExecuteResult.of(executePersistentQuery(queryPlan, plan.getStatementText()));\n   }\n \n+  PullQueryResult executePullQuery(", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAyOTcyMg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517029722", "bodyText": "This is another meta thought: when I read the blog post https://www.confluent.io/blog/ksqldb-pull-queries-high-availability/ I thought the \"forwarding\" is not to forward the original query statement to the other server, but to forward the already built physical query plan to the node which we already know host the required partition. But after I digested this piece I realized it was actually the former case.\nI'm wondering if this is a better design, such that we only do query compilation / routing at a single point, which is the server when the request from client is firstly received (say, server A), after server A compiled the query statement it will decide which server to route to (say, server B), then route the compiled physical plan to server B, and server B would blindly execute the query and return results. If an error returned indicating server B is not available any more, the server A would re-determine the routing, and so on.\nThe key point here is that only the single node (the entry server A) would do the compilation and routing, therefore we do not need the isInternalRequest boolean any more.", "author": "guozhangwang", "createdAt": "2020-11-04T00:18:34Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/KsqlExecutionContext.java", "diffHunk": "@@ -125,6 +129,16 @@ TransientQueryMetadata executeQuery(\n       ConfiguredStatement<Query> statement\n   );\n \n+  PullQueryResult executePullQuery(", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI1NzUzNg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523257536", "bodyText": "Yes, I thought about this as well. It's a tradeoff between sending larger messages (the physical plan vs the query) and computation. If we do want to make this change, this would be part of a larger refactoring, and not part of this PR.\nThe routing already works as you describe, in the sense that server B executes the request locally. If it fails, server A will try another server.", "author": "vpapavas", "createdAt": "2020-11-13T22:02:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAyOTcyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI3NTg2OA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523275868", "bodyText": "Yeah this is totally a meta thing which is not to be addressed in this PR. I left it here just to dump my wild thoughts here for future references.\nRegarding the trade-off, I think with some encoding the number of bytes that we need to transmit between servers with the physical plan would not be orders of magnitude larger (my bold claim, of course :P) but the benefit that only one single server makes the compilation decision to achieve consistent behavior could be huge.", "author": "guozhangwang", "createdAt": "2020-11-13T22:59:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAyOTcyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMjAwOA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517032008", "bodyText": "It is a bit weird to actually \"execute\" the query in a routeQuery method. Maybe just name it executeOrRouteQuery?\nAlso please see my other comment about the query forwarding: I'd suggest we only forward the the compiled physical query plan to the destination node.", "author": "guozhangwang", "createdAt": "2020-11-04T00:26:54Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HARouting.class);\n+  private final ExecutorService executorService;\n+  private final KsqlConfig ksqlConfig;\n+  private final PullPhysicalPlan pullPhysicalPlan;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+  private final ServiceContext serviceContext;\n+  private final LogicalSchema outputSchema;\n+  private final QueryId queryId;\n+  private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n+\n+  public HARouting(\n+      final KsqlConfig ksqlConfig,\n+      final PullPhysicalPlan pullPhysicalPlan,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final LogicalSchema outputSchema,\n+      final QueryId queryId,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.pullPhysicalPlan = Objects.requireNonNull(pullPhysicalPlan, \"pullPhysicalPlan\");\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.pullQueryMetrics = Objects.requireNonNull(pullQueryMetrics, \"pullQueryMetrics\");\n+    executorService = Executors.newFixedThreadPool(\n+        ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_THREAD_POOL_SIZE_CONFIG)\n+    );\n+  }\n+\n+  public PullQueryResult handlePullQuery() throws InterruptedException {\n+    final List<KsqlPartitionLocation> locations = pullPhysicalPlan.getMaterialization().locator()\n+        .locate(\n+            pullPhysicalPlan.getKeys(),\n+            routingOptions,\n+            routingFilterFactory\n+    );\n+\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n+      LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n+                statement.getStatementText());\n+      throw new MaterializationException(String.format(\n+          \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n+          statement.getStatementText()));\n+    }\n+\n+    // The source nodes associated with each of the rows\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlPartitionLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n+    for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n+      final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlPartitionLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        futures.put(node, executorService.submit(() -> {\n+          return routeQuery(\n+              node, entry.getValue(), statement, serviceContext, routingOptions, pullQueryMetrics);", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMjUwMw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517032503", "bodyText": "Why make this function as a synchronous round-trip? Could we do it in a nio, i.e. only send the request, and then allowing the service executor thread to move on to the next partition, and later loop back and check on the socket whether resp is received.", "author": "guozhangwang", "createdAt": "2020-11-04T00:28:51Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HARouting.class);\n+  private final ExecutorService executorService;\n+  private final KsqlConfig ksqlConfig;\n+  private final PullPhysicalPlan pullPhysicalPlan;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+  private final ServiceContext serviceContext;\n+  private final LogicalSchema outputSchema;\n+  private final QueryId queryId;\n+  private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n+\n+  public HARouting(\n+      final KsqlConfig ksqlConfig,\n+      final PullPhysicalPlan pullPhysicalPlan,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final LogicalSchema outputSchema,\n+      final QueryId queryId,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.pullPhysicalPlan = Objects.requireNonNull(pullPhysicalPlan, \"pullPhysicalPlan\");\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.outputSchema = Objects.requireNonNull(outputSchema, \"outputSchema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.pullQueryMetrics = Objects.requireNonNull(pullQueryMetrics, \"pullQueryMetrics\");\n+    executorService = Executors.newFixedThreadPool(\n+        ksqlConfig.getInt(KsqlConfig.KSQL_QUERY_PULL_THREAD_POOL_SIZE_CONFIG)\n+    );\n+  }\n+\n+  public PullQueryResult handlePullQuery() throws InterruptedException {\n+    final List<KsqlPartitionLocation> locations = pullPhysicalPlan.getMaterialization().locator()\n+        .locate(\n+            pullPhysicalPlan.getKeys(),\n+            routingOptions,\n+            routingFilterFactory\n+    );\n+\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n+      LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n+                statement.getStatementText());\n+      throw new MaterializationException(String.format(\n+          \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n+          statement.getStatementText()));\n+    }\n+\n+    // The source nodes associated with each of the rows\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    // Each of the table rows returned, aggregated across nodes\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    // Each of the schemas returned, aggregated across nodes\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlPartitionLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    // For each round, each set of partition location objects is grouped by host, and all\n+    // keys associated with that host are batched together. For any requests that fail,\n+    // the partition location objects will be added to remainingLocations, and the next round\n+    // will attempt to fetch them from the next node in their prioritized list.\n+    // For example, locations might be:\n+    // [ Partition 0 <Host 1, Host 2>,\n+    //   Partition 1 <Host 2, Host 1>,\n+    //   Partition 2 <Host 1, Host 2> ]\n+    // In Round 0, fetch from Host 1: [Partition 0, Partition 2], from Host 2: [Partition 1]\n+    // If everything succeeds, we're done.  If Host 1 failed, then we'd have a Round 1:\n+    // In Round 1, fetch from Host 2: [Partition 0, Partition 2].\n+    for (int round = 0; ; round++) {\n+      // Group all partition location objects by their nth round node\n+      final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      // Make requests to each host, specifying the partitions we're interested in from\n+      // this host.\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlPartitionLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        futures.put(node, executorService.submit(() -> {\n+          return routeQuery(\n+              node, entry.getValue(), statement, serviceContext, routingOptions, pullQueryMetrics);\n+        }));\n+      }\n+\n+      // Go through all of the results of the requests, either aggregating rows or adding\n+      // the locations to the nextRoundRemaining list.\n+      final ImmutableList.Builder<KsqlPartitionLocation> nextRoundRemaining\n+          = ImmutableList.builder();\n+      for (Map.Entry<KsqlNode, Future<PullQueryResult>> entry : futures.entrySet()) {\n+        final Future<PullQueryResult> future = entry.getValue();\n+        final KsqlNode node = entry.getKey();\n+        try {\n+          final PullQueryResult result = future.get();\n+          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n+          schemas.add(result.getSchema());\n+          tableRows.addAll(result.getTableRows());\n+        } catch (ExecutionException e) {\n+          LOG.warn(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n+                   statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n+          nextRoundRemaining.addAll(groupedByHost.get(node));\n+        }\n+      }\n+      remainingLocations = nextRoundRemaining.build();\n+\n+      // If there are no partition locations remaining, then we're done.\n+      if (remainingLocations.size() == 0) {\n+        validateSchemas(schemas);\n+        return new PullQueryResult(\n+            tableRows,\n+            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes),\n+            Iterables.getLast(schemas),\n+            queryId);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Groups all of the partition locations by the round-th entry in their prioritized list\n+   * of host nodes.\n+   * @param statement the statement from which this request came\n+   * @param locations the list of partition locations to parse\n+   * @param round which round this is\n+   * @return A map of node to list of partition locations\n+   */\n+  private Map<KsqlNode, List<KsqlPartitionLocation>> groupByHost(\n+      final ConfiguredStatement<Query> statement,\n+      final List<KsqlPartitionLocation> locations,\n+      final int round) {\n+    final Map<KsqlNode, List<KsqlPartitionLocation>> groupedByHost = new LinkedHashMap<>();\n+    for (KsqlPartitionLocation location : locations) {\n+      // If one of the partitions required is out of nodes, then we cannot continue.\n+      if (round >= location.getNodes().size()) {\n+        throw new MaterializationException(String.format(\n+            \"Unable to execute pull query: %s. Exhausted standby hosts to try.\",\n+            statement.getStatementText()));\n+      }\n+      final KsqlNode nextHost = location.getNodes().get(round);\n+      groupedByHost.computeIfAbsent(nextHost, h -> new ArrayList<>()).add(location);\n+    }\n+    return groupedByHost;\n+  }\n+\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    PullQueryResult routeQuery(\n+        KsqlNode node,\n+        List<KsqlPartitionLocation> locations,\n+        ConfiguredStatement<Query> statement,\n+        ServiceContext serviceContext,\n+        RoutingOptions routingOptions,\n+        Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+    );\n+  }\n+\n+  private PullQueryResult routeQuery(\n+      final KsqlNode node,\n+      final List<KsqlPartitionLocation> locations,\n+      final ConfiguredStatement<Query> statement,\n+      final ServiceContext serviceContext,\n+      final RoutingOptions routingOptions,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics\n+  ) {\n+    List<List<?>> rows = null;\n+    if (node.isLocal()) {\n+      LOG.debug(\"Query {} executed locally at host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordLocalRequests(1));\n+      rows = pullPhysicalPlan.execute(locations, pullQueryMetrics);\n+\n+    } else {\n+      LOG.debug(\"Query {} routed to host {} at timestamp {}.\",\n+                statement.getStatementText(), node.location(), System.currentTimeMillis());\n+      pullQueryMetrics\n+          .ifPresent(queryExecutorMetrics -> queryExecutorMetrics.recordRemoteRequests(1));\n+      rows = forwardTo(node, locations, statement, serviceContext);\n+    }\n+    final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n+        routingOptions.isDebugRequest()\n+            ? Collections.nCopies(rows.size(), node) : null);\n+    return new PullQueryResult(\n+        rows,\n+        debugNodes,\n+        outputSchema,\n+        queryId);\n+  }\n+\n+  private static List<List<?>> forwardTo(", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyNDkxMQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517724911", "bodyText": "Currently, we do multiple requests in parallel using the executorService.  We should maybe make this logic use async rather than a threadpool and futures, but it accomplishes the same thing at the moment.", "author": "AlanConfluent", "createdAt": "2020-11-05T01:16:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMjUwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzc4MTA4Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517781086", "bodyText": "Yeah I agree the current code achieves the same thing, but using a threadpool of 100 threads by default could be costly than using a single thread (or at most, we only need one thread per destination socket). Anyways, as I mentioned in the meta comment I feel this is not necessarily the scope of the PR and we can just refactor it later if people agree to the approach.", "author": "guozhangwang", "createdAt": "2020-11-05T04:08:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMjUwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzMzUxNA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517033514", "bodyText": "About the code structure: I'd suggest we extract the execute-query-if-local out of this class into EngineExecutor directly, and only do forwarding in this class.\nAlso as a follow-up improvement the forwarding can be done in an async way: for each partition that needs forwarding, do that in NIO instead of sync round-trips similar to Kafka: just poll on the socket doing reads and writes when necessary, and then upon completely receiving the resp complete the registered future.", "author": "guozhangwang", "createdAt": "2020-11-04T00:32:34Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNTU3OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517035579", "bodyText": "nit: space after //.", "author": "guozhangwang", "createdAt": "2020-11-04T00:40:36Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNjg4Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517036883", "bodyText": "The method names are not consistent here: if we want to just want getters, then I'd suggest renaming to getIfSkipForwardRequest and GetIfDebugRequest respectively.", "author": "guozhangwang", "createdAt": "2020-11-04T00:45:20Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public class PullQueryConfigRoutingOptions implements RoutingOptions {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final Map<String, ?> configOverrides;\n+  private final Map<String, ?> requestProperties;\n+\n+  PullQueryConfigRoutingOptions(\n+      final KsqlConfig ksqlConfig,\n+      final Map<String, ?> configOverrides,\n+      final Map<String, ?> requestProperties\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.configOverrides = configOverrides;\n+    this.requestProperties = Objects.requireNonNull(requestProperties, \"requestProperties\");\n+  }\n+\n+  private long getLong(final String key) {\n+    if (configOverrides.containsKey(key)) {\n+      return (Long) configOverrides.get(key);\n+    }\n+    return ksqlConfig.getLong(key);\n+  }\n+\n+  private boolean getForwardedFlag(final String key) {\n+    if (requestProperties.containsKey(key)) {\n+      return (Boolean) requestProperties.get(key);\n+    }\n+    return KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING_DEFAULT;\n+  }\n+\n+  public boolean isDebugRequest() {\n+    if (requestProperties.containsKey(KsqlRequestConfig.KSQL_DEBUG_REQUEST)) {\n+      return (Boolean) requestProperties.get(KsqlRequestConfig.KSQL_DEBUG_REQUEST);\n+    }\n+    return KsqlRequestConfig.KSQL_DEBUG_REQUEST_DEFAULT;\n+  }\n+\n+  @Override\n+  public Set<Integer> getPartitions() {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNjk2Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517036963", "bodyText": "This name is confusing, better be getMaxOffsetLagAllowed.", "author": "guozhangwang", "createdAt": "2020-11-04T00:45:39Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/PullQueryConfigRoutingOptions.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public class PullQueryConfigRoutingOptions implements RoutingOptions {\n+\n+  private final KsqlConfig ksqlConfig;\n+  private final Map<String, ?> configOverrides;\n+  private final Map<String, ?> requestProperties;\n+\n+  PullQueryConfigRoutingOptions(\n+      final KsqlConfig ksqlConfig,\n+      final Map<String, ?> configOverrides,\n+      final Map<String, ?> requestProperties\n+  ) {\n+    this.ksqlConfig = Objects.requireNonNull(ksqlConfig, \"ksqlConfig\");\n+    this.configOverrides = configOverrides;\n+    this.requestProperties = Objects.requireNonNull(requestProperties, \"requestProperties\");\n+  }\n+\n+  private long getLong(final String key) {\n+    if (configOverrides.containsKey(key)) {\n+      return (Long) configOverrides.get(key);\n+    }\n+    return ksqlConfig.getLong(key);\n+  }\n+\n+  private boolean getForwardedFlag(final String key) {\n+    if (requestProperties.containsKey(key)) {\n+      return (Boolean) requestProperties.get(key);\n+    }\n+    return KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_SKIP_FORWARDING_DEFAULT;\n+  }\n+\n+  public boolean isDebugRequest() {\n+    if (requestProperties.containsKey(KsqlRequestConfig.KSQL_DEBUG_REQUEST)) {\n+      return (Boolean) requestProperties.get(KsqlRequestConfig.KSQL_DEBUG_REQUEST);\n+    }\n+    return KsqlRequestConfig.KSQL_DEBUG_REQUEST_DEFAULT;\n+  }\n+\n+  @Override\n+  public Set<Integer> getPartitions() {\n+    if (requestProperties.containsKey(KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS)) {\n+      @SuppressWarnings(\"unchecked\")\n+      final List<String> partitions = (List<String>) requestProperties.get(\n+          KsqlRequestConfig.KSQL_REQUEST_QUERY_PULL_PARTITIONS);\n+      return partitions.stream()\n+          .map(partition -> {\n+            try {\n+              return Integer.parseInt(partition);\n+            } catch (NumberFormatException e) {\n+              throw new IllegalStateException(\"Internal request got a bad partition \"\n+                                                  + partition);\n+            }\n+          }).collect(Collectors.toSet());\n+    }\n+    return Collections.emptySet();\n+  }\n+\n+  @Override\n+  public long getOffsetLagAllowed() {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNzE5OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517037199", "bodyText": "nit: some times we use space after // and some times we do not, better be consistent here. Maybe just always use space?", "author": "guozhangwang", "createdAt": "2020-11-04T00:46:35Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class PullPhysicalPlan {\n+  private final AbstractPhysicalOperator root;\n+  private final LogicalSchema schema;\n+  private final QueryId queryId;\n+  private final List<Struct> keys;\n+  private final Materialization mat;\n+  private final DataSourceOperator dataSourceOperator;\n+\n+  public PullPhysicalPlan(\n+      final AbstractPhysicalOperator root,\n+      final LogicalSchema schema,\n+      final QueryId queryId,\n+      final List<Struct> keys,\n+      final Materialization mat,\n+      final DataSourceOperator dataSourceOperator\n+  ) {\n+    this.root = Objects.requireNonNull(root, \"root\");\n+    this.schema = Objects.requireNonNull(schema, \"schema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.keys = Objects.requireNonNull(keys, \"keys\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.dataSourceOperator = Objects.requireNonNull(\n+        dataSourceOperator, \"dataSourceOperator\");\n+  }\n+\n+  public List<List<?>> execute(\n+      final List<KsqlPartitionLocation> locations,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics) {\n+\n+    //We only know at runtime which partitions to get from which node.", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzODM4Mg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517038382", "bodyText": "Also, just want to point out that in the future the specific host's store capabilities would also be taken into consideration when compiling the pull query, which means we would be able to know locations at compilation time, not only at runtime.", "author": "guozhangwang", "createdAt": "2020-11-04T00:51:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNzE5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzNzQ2Nw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517037467", "bodyText": "pullQueryMetrics not used.", "author": "guozhangwang", "createdAt": "2020-11-04T00:47:47Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class PullPhysicalPlan {\n+  private final AbstractPhysicalOperator root;\n+  private final LogicalSchema schema;\n+  private final QueryId queryId;\n+  private final List<Struct> keys;\n+  private final Materialization mat;\n+  private final DataSourceOperator dataSourceOperator;\n+\n+  public PullPhysicalPlan(\n+      final AbstractPhysicalOperator root,\n+      final LogicalSchema schema,\n+      final QueryId queryId,\n+      final List<Struct> keys,\n+      final Materialization mat,\n+      final DataSourceOperator dataSourceOperator\n+  ) {\n+    this.root = Objects.requireNonNull(root, \"root\");\n+    this.schema = Objects.requireNonNull(schema, \"schema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.keys = Objects.requireNonNull(keys, \"keys\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.dataSourceOperator = Objects.requireNonNull(\n+        dataSourceOperator, \"dataSourceOperator\");\n+  }\n+\n+  public List<List<?>> execute(\n+      final List<KsqlPartitionLocation> locations,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics) {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzOTA3Mw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517039073", "bodyText": "This sort of validates my thoughts: the location can be inferred at compilation time since it is part of the plan anyways, as we get them via pullPhysicalPlan.getMaterialization().locator(), we can just put into the routing factory / options as part of the physical plan compilation.", "author": "guozhangwang", "createdAt": "2020-11-04T00:53:43Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class PullPhysicalPlan {\n+  private final AbstractPhysicalOperator root;\n+  private final LogicalSchema schema;\n+  private final QueryId queryId;\n+  private final List<Struct> keys;\n+  private final Materialization mat;\n+  private final DataSourceOperator dataSourceOperator;\n+\n+  public PullPhysicalPlan(\n+      final AbstractPhysicalOperator root,\n+      final LogicalSchema schema,\n+      final QueryId queryId,\n+      final List<Struct> keys,\n+      final Materialization mat,\n+      final DataSourceOperator dataSourceOperator\n+  ) {\n+    this.root = Objects.requireNonNull(root, \"root\");\n+    this.schema = Objects.requireNonNull(schema, \"schema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.keys = Objects.requireNonNull(keys, \"keys\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.dataSourceOperator = Objects.requireNonNull(\n+        dataSourceOperator, \"dataSourceOperator\");\n+  }\n+\n+  public List<List<?>> execute(\n+      final List<KsqlPartitionLocation> locations,\n+      final Optional<PullQueryExecutorMetrics> pullQueryMetrics) {\n+\n+    //We only know at runtime which partitions to get from which node.\n+    //That's why we need to set this explicitly for the dataSource operators\n+    dataSourceOperator.setPartitionLocations(locations);\n+\n+    open();\n+    final List<List<?>> localResult = new ArrayList<>();\n+    List<?> row = null;\n+    while ((row = (List<?>)next()) != null) {\n+      localResult.add(row);\n+    }\n+    close();\n+\n+    return localResult;\n+  }\n+\n+  private void open() {\n+    root.open();\n+  }\n+\n+  private Object next() {\n+    return root.next();\n+  }\n+\n+  private void close() {\n+    root.close();\n+  }\n+\n+  public Materialization getMaterialization() {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI5NTk0NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523295944", "bodyText": "I don't understand how figuring out the hosts/partitions can be done at compile time. First we compile the query into a physical plan and then we try to route it. Depending on which node is down, the location changes at runtime.", "author": "vpapavas", "createdAt": "2020-11-14T00:12:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzOTA3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzOTc2Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517039766", "bodyText": "I'd suggest we declare rootPhysicalOp as currentPhysicalOp , and then at line 156 check that currentPhysicalOp instanceof currentPhysicalOp before assigning, so that we can fail fast.", "author": "guozhangwang", "createdAt": "2020-11-04T00:56:18Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      // For now assume only single source which is the case for pull queries\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    if (dataSourceOperator == null) {\n+      throw new IllegalStateException(\"DataSourceOperator cannot be null in Pull physical plan\");\n+    }\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI5NDk1OA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523294958", "bodyText": "I am not following here. I need a pointer to the root operator of the physical plan.", "author": "vpapavas", "createdAt": "2020-11-14T00:08:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAzOTc2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0MDczOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517040739", "bodyText": "Could we also include the actual getDataSourceType as well.\nAlso, for other thrown exceptions, I find that we tend to not include some key information into the exception message that may make debugging harder. I'd suggest as a rule of thumb to always include all variable values if they participate in the condition that leads to exception.", "author": "guozhangwang", "createdAt": "2020-11-04T01:00:17Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(\n+      final MetaStore metaStore,\n+      final KsqlConfig config,\n+      final ServiceContext serviceContext,\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis,\n+      final RoutingFilterFactory routingFilterFactory,\n+      final RoutingOptions routingOptions,\n+      final ConfiguredStatement<Query> statement\n+  ) {\n+    this.metaStore = Objects.requireNonNull(metaStore, \"metaStore\");\n+    this.config = Objects.requireNonNull(config, \"config\");\n+    this.serviceContext = Objects.requireNonNull(serviceContext, \"serviceContext\");\n+    this.executionContext = Objects.requireNonNull(executionContext, \"executionContext\");\n+    this.analysis = Objects.requireNonNull(analysis, \"analysis\");\n+    this.contextStacker = new Stacker();\n+    this.routingFilterFactory =\n+        Objects.requireNonNull(routingFilterFactory, \"routingFilterFactory\");\n+    this.routingOptions = Objects.requireNonNull(routingOptions, \"routingOptions\");\n+    this.statement = Objects.requireNonNull(statement, \"statement\");\n+  }\n+\n+  /**\n+   * Visits the logical plan top-down to build the physical plan.\n+   * @param logicalPlanNode the logical plan root node\n+   * @return the root node of the tree of physical operators\n+   */\n+  public PullPhysicalPlan buildPullPhysicalPlan(final LogicalPlanNode logicalPlanNode) {\n+    DataSourceOperator dataSourceOperator = null;\n+    persistentQueryMetadata = findMaterializingQuery(executionContext, analysis);\n+    queryId = uniqueQueryId();\n+    mat = persistentQueryMetadata\n+        .getMaterialization(queryId, contextStacker)\n+        .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n+\n+    //Basic validation, should be moved to logical plan builder\n+    final boolean windowed = persistentQueryMetadata.getResultTopic().getKeyFormat().isWindowed();\n+    analysis.getWhereExpression()\n+        .orElseThrow(() -> WhereInfo.invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n+\n+    final OutputNode outputNode = logicalPlanNode.getNode()\n+        .orElseThrow(() -> new IllegalArgumentException(\"Need an output node to build a plan\"));\n+    // The root node of the logical plan is always a KsqlBareOutputNode. Seems it only applies\n+    // the LIMIT? skip KsqlBareOutputNode for now\n+    PlanNode currentLogicalNode = outputNode.getSource();\n+    AbstractPhysicalOperator prevPhysicalOp = null;\n+    AbstractPhysicalOperator rootPhysicalOp = null;\n+    while (currentLogicalNode.getSources() != null) {\n+\n+      AbstractPhysicalOperator currentPhysicalOp = null;\n+      if (currentLogicalNode instanceof ProjectNode) {\n+        currentPhysicalOp = translateProjectNode((ProjectNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof FilterNode) {\n+        currentPhysicalOp = translateFilterNode((FilterNode)currentLogicalNode);\n+      } else if (currentLogicalNode instanceof DataSourceNode) {\n+        currentPhysicalOp = translateDataSourceNode(\n+            (DataSourceNode) currentLogicalNode, persistentQueryMetadata);\n+        dataSourceOperator = (DataSourceOperator)currentPhysicalOp;\n+      } else {\n+        throw new KsqlException(\"Unrecognized logical node.\");\n+      }\n+\n+      if (prevPhysicalOp == null) {\n+        rootPhysicalOp = currentPhysicalOp;\n+      } else {\n+        prevPhysicalOp.addChild(currentPhysicalOp);\n+      }\n+      prevPhysicalOp = currentPhysicalOp;\n+      if (currentLogicalNode.getSources().isEmpty()) {\n+        break;\n+      }\n+      // For now assume only single source which is the case for pull queries\n+      currentLogicalNode = currentLogicalNode.getSources().get(0);\n+    }\n+\n+    if (dataSourceOperator == null) {\n+      throw new IllegalStateException(\"DataSourceOperator cannot be null in Pull physical plan\");\n+    }\n+    return new PullPhysicalPlan(\n+        rootPhysicalOp,\n+        ((ProjectOperator)rootPhysicalOp).getOutputSchema(),\n+        queryId,\n+        keys,\n+        mat,\n+        dataSourceOperator);\n+  }\n+\n+  private ProjectOperator translateProjectNode(final ProjectNode logicalNode) {\n+    LogicalSchema outputSchema = null;\n+    boolean isStar = false;\n+    if (isSelectStar(statement.getStatement().getSelect())) {\n+      isStar = true;\n+      outputSchema = buildSchema(mat.schema(), mat.windowType().isPresent());\n+    } else {\n+      final List<SelectExpression> projection = analysis.getSelectItems().stream()\n+          .map(SingleColumn.class::cast)\n+          .map(si -> SelectExpression\n+              .of(si.getAlias().orElseThrow(IllegalStateException::new), si.getExpression()))\n+          .collect(Collectors.toList());\n+\n+      outputSchema = selectOutputSchema(\n+          executionContext, projection, mat.windowType());\n+    }\n+    return new ProjectOperator(\n+      config,\n+      metaStore,\n+      mat,\n+      analysis,\n+      executionContext,\n+      contextStacker,\n+      logicalNode,\n+      outputSchema,\n+      isStar);\n+  }\n+\n+  private SelectOperator translateFilterNode(final FilterNode logicalNode) {\n+    whereInfo = WhereInfo.extractWhereInfo(analysis, persistentQueryMetadata);\n+    return new SelectOperator(logicalNode);\n+  }\n+\n+  private AbstractPhysicalOperator translateDataSourceNode(\n+      final DataSourceNode logicalNode,\n+      final PersistentQueryMetadata persistentQueryMetadata\n+  ) {\n+    if (whereInfo == null) {\n+      throw new KsqlException(\"Pull queries must have a WHERE clause\");\n+    }\n+    keys = whereInfo.getKeysBound().stream()\n+        .map(keyBound -> asKeyStruct(keyBound, persistentQueryMetadata.getPhysicalSchema()))\n+        .collect(ImmutableList.toImmutableList());\n+\n+    if (!whereInfo.getWindowBounds().isPresent()) {\n+      return new KeyedTableLookupOperator(mat, logicalNode);\n+    } else {\n+      return new KeyedWindowedTableLookupOperator(\n+          mat, logicalNode, whereInfo.getWindowBounds().get());\n+    }\n+  }\n+\n+  private PersistentQueryMetadata findMaterializingQuery(\n+      final KsqlExecutionContext executionContext,\n+      final ImmutableAnalysis analysis\n+  ) {\n+    final MetaStore metaStore = executionContext.getMetaStore();\n+\n+    final SourceName sourceName = getSourceName(analysis);\n+\n+    final Set<String> queries = metaStore.getQueriesWithSink(sourceName);\n+    if (queries.isEmpty()) {\n+      throw notMaterializedException(sourceName);\n+    }\n+    if (queries.size() > 1) {\n+      throw new KsqlException(\n+        \"Multiple queries currently materialize '\" + sourceName + \"'.\"\n+        + \" KSQL currently only supports pull queries when the table has only been\"\n+        + \" materialized once.\");\n+    }\n+\n+    final QueryId queryId = new QueryId(Iterables.get(queries, 0));\n+\n+    final PersistentQueryMetadata query = executionContext\n+        .getPersistentQuery(queryId)\n+        .orElseThrow(() -> new KsqlException(\"Materializing query has been stopped\"));\n+\n+    if (query.getDataSourceType() != DataSourceType.KTABLE) {\n+      throw new KsqlException(\"Pull queries are not supported on streams.\");", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0MjY5MA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517042690", "bodyText": "Javadoc for this class regarding 1) what metadata it contains, 2) what assumption it makes (e.g.  what root operator should be`) would be highly appreciated :)", "author": "guozhangwang", "createdAt": "2020-11-04T01:08:30Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+\n+public class PullPhysicalPlan {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0MzEwMw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517043103", "bodyText": "Javadoc for this class regarding the common pattern of the generated physical plan (e.g. should it always be a scan -> filter), what validation it does, what metadata (e.g. materialization) it relies on would be highly appreciated :)", "author": "guozhangwang", "createdAt": "2020-11-04T01:10:05Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlanBuilder.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.KsqlExecutionContext;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.context.QueryContext.Stacker;\n+import io.confluent.ksql.execution.plan.SelectExpression;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.util.ExpressionTypeManager;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.metastore.model.DataSource;\n+import io.confluent.ksql.metastore.model.DataSource.DataSourceType;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.SourceName;\n+import io.confluent.ksql.parser.tree.AllColumns;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Select;\n+import io.confluent.ksql.parser.tree.SingleColumn;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.KeyedWindowedTableLookupOperator;\n+import io.confluent.ksql.physical.pull.operators.ProjectOperator;\n+import io.confluent.ksql.physical.pull.operators.SelectOperator;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo;\n+import io.confluent.ksql.planner.LogicalPlanNode;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import io.confluent.ksql.planner.plan.FilterNode;\n+import io.confluent.ksql.planner.plan.OutputNode;\n+import io.confluent.ksql.planner.plan.PlanNode;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.LogicalSchema.Builder;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.ksql.types.SqlType;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.connect.ConnectSchemas;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.ConnectSchema;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Struct;\n+\n+// CHECKSTYLE_RULES.OFF: ClassDataAbstractionCoupling\n+public class PullPhysicalPlanBuilder {\n+  // CHECKSTYLE_RULES.ON: ClassDataAbstractionCoupling\n+\n+  private final MetaStore metaStore;\n+  private final KsqlConfig config;\n+  private final ServiceContext serviceContext;\n+  private final KsqlExecutionContext executionContext;\n+  private final Stacker contextStacker;\n+  private final ImmutableAnalysis analysis;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+\n+  private WhereInfo whereInfo;\n+  private PersistentQueryMetadata persistentQueryMetadata;\n+  private  QueryId queryId;\n+  private Materialization mat;\n+  private List<Struct> keys;\n+\n+  public PullPhysicalPlanBuilder(", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI5NjY0MQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523296641", "bodyText": "The metadata/validation information is going to change with the next PR so I'd rather add it when the code is done. I don't want to end up with wrong javadocs.", "author": "vpapavas", "createdAt": "2020-11-14T00:15:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0MzEwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA0Mzk4OQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517043989", "bodyText": "Javadocs regarding which metadata it wraps in is appreciated.", "author": "guozhangwang", "createdAt": "2020-11-04T01:13:05Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/WhereInfo.java", "diffHunk": "@@ -0,0 +1,542 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.collect.BoundType;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.collect.Iterables;\n+import com.google.common.collect.Range;\n+import com.google.common.collect.Sets;\n+import com.google.common.collect.Sets.SetView;\n+import io.confluent.ksql.analyzer.ImmutableAnalysis;\n+import io.confluent.ksql.analyzer.PullQueryValidator;\n+import io.confluent.ksql.execution.expression.tree.ComparisonExpression;\n+import io.confluent.ksql.execution.expression.tree.ComparisonExpression.Type;\n+import io.confluent.ksql.execution.expression.tree.Expression;\n+import io.confluent.ksql.execution.expression.tree.InPredicate;\n+import io.confluent.ksql.execution.expression.tree.IntegerLiteral;\n+import io.confluent.ksql.execution.expression.tree.Literal;\n+import io.confluent.ksql.execution.expression.tree.LogicalBinaryExpression;\n+import io.confluent.ksql.execution.expression.tree.LongLiteral;\n+import io.confluent.ksql.execution.expression.tree.NullLiteral;\n+import io.confluent.ksql.execution.expression.tree.StringLiteral;\n+import io.confluent.ksql.execution.expression.tree.UnqualifiedColumnReferenceExp;\n+import io.confluent.ksql.name.ColumnName;\n+import io.confluent.ksql.schema.ksql.Column;\n+import io.confluent.ksql.schema.ksql.DefaultSqlValueCoercer;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.SystemColumns;\n+import io.confluent.ksql.schema.utils.FormatOptions;\n+import io.confluent.ksql.util.GrammaticalJoiner;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import io.confluent.ksql.util.timestamp.PartialStringToTimestampParser;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public final class WhereInfo {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcxOTc3NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517719774", "bodyText": "I think much of PullQueryExecutor.UnitTests tests this.  It would be good to create a HARoutingTest with that logic.", "author": "AlanConfluent", "createdAt": "2020-11-05T00:58:34Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/HARouting.java", "diffHunk": "@@ -0,0 +1,318 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.execution.streams.RoutingFilter.RoutingFilterFactory;\n+import io.confluent.ksql.execution.streams.RoutingOptions;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.MaterializationException;\n+import io.confluent.ksql.internal.PullQueryExecutorMetrics;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.physical.pull.PullPhysicalPlan;\n+import io.confluent.ksql.physical.pull.PullQueryResult;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.rest.client.RestResponse;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.statement.ConfiguredStatement;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.KsqlServerException;\n+import io.confluent.ksql.util.KsqlStatementException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public final class HARouting {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(HARouting.class);\n+  private final ExecutorService executorService;\n+  private final KsqlConfig ksqlConfig;\n+  private final PullPhysicalPlan pullPhysicalPlan;\n+  private final RoutingFilterFactory routingFilterFactory;\n+  private final RoutingOptions routingOptions;\n+  private final ConfiguredStatement<Query> statement;\n+  private final ServiceContext serviceContext;\n+  private final LogicalSchema outputSchema;\n+  private final QueryId queryId;\n+  private final Optional<PullQueryExecutorMetrics> pullQueryMetrics;\n+\n+  public HARouting(", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyMTI4Nw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517721287", "bodyText": "What if resultIterator.hasNext() is false, but keyIterator.hasNext() is true?  You would return null below when there might be more.  It seems like you could recursively call next() after setting up the nextKey and resultIterator.", "author": "AlanConfluent", "createdAt": "2020-11-05T01:03:47Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedWindowedTableLookupOperator.java", "diffHunk": "@@ -0,0 +1,137 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.WindowedRow;\n+import io.confluent.ksql.physical.pull.operators.WhereInfo.WindowBounds;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KeyedWindowedTableLookupOperator\n+    extends AbstractPhysicalOperator\n+    implements UnaryPhysicalOperator, DataSourceOperator {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(\n+      KeyedWindowedTableLookupOperator.class);\n+\n+  private final Materialization mat;\n+  private final DataSourceNode logicalOperator;\n+  private final WindowBounds windowBounds;\n+\n+  private List<KsqlPartitionLocation> partitionLocations;\n+  private Iterator<WindowedRow> resultIterator;\n+  private Iterator<Struct> keyIterator;\n+  private Iterator<KsqlPartitionLocation> partitionLocationIterator;\n+  private KsqlPartitionLocation nextLocation;\n+  private Struct nextKey;\n+\n+\n+  public KeyedWindowedTableLookupOperator(\n+      final Materialization mat,\n+      final DataSourceNode logicalNode,\n+      final WindowBounds windowBounds\n+  ) {\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.windowBounds = Objects.requireNonNull(windowBounds, \"windowBounds\");\n+  }\n+\n+  @Override\n+  public void open() {\n+    partitionLocationIterator = partitionLocations.iterator();\n+    if (partitionLocationIterator.hasNext()) {\n+      nextLocation = partitionLocationIterator.next();\n+      if (!nextLocation.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Table windowed queries should be done with keys\");\n+      }\n+      keyIterator = nextLocation.getKeys().get().iterator();\n+      if (keyIterator.hasNext()) {\n+        nextKey = keyIterator.next();\n+        resultIterator = mat.windowed().get(\n+            nextKey,\n+            nextLocation.getPartition(),\n+            windowBounds.getStart(),\n+            windowBounds.getEnd())\n+            .iterator();\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public Object next() {\n+    if (resultIterator.hasNext()) {\n+      return resultIterator.next();\n+    }\n+    // Exhausted resultIterator\n+    if (!keyIterator.hasNext()) {\n+      if (partitionLocationIterator.hasNext()) {\n+        nextLocation = partitionLocationIterator.next();\n+      } else {\n+        // Exhausted all iterators\n+        return null;\n+      }\n+      if (!nextLocation.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Table lookup queries should be done with keys\");\n+      }\n+      keyIterator = nextLocation.getKeys().get().iterator();\n+    }\n+    nextKey = keyIterator.next();\n+    resultIterator = mat.windowed().get(\n+        nextKey,\n+        nextLocation.getPartition(),\n+        windowBounds.getStart(),\n+        windowBounds.getEnd())\n+        .iterator();\n+    if (resultIterator.hasNext()) {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMwMDU0NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r523300544", "bodyText": "resultIterator.hasNext() is false, but keyIterator.hasNext() is true it will go to line 91 and get the next keyIterator keyIterator.next(). Am I missing something?", "author": "vpapavas", "createdAt": "2020-11-14T00:34:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyMTI4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0NDYyNA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r524544624", "bodyText": "If you were to call this.next() again, it would do what you're saying and see that there are more keys, but from what I can see, it doesn't do that by default (and hence my recursive comment).\nSpecifically, imagine you're looking up two keys, 1 and 2.  If you do resultIterator = mat.windowed().get( .. for 1 and get nothing, resultIterator.hasNext() will be false, and you'll fall through to return null below.\nI guess maybe that's the correct if you want to return nulls for empty lookups, but then you have to do a null check with the caller.  I was effectively imagining that you would just continue on to the next non empty iterator.", "author": "AlanConfluent", "createdAt": "2020-11-16T20:14:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyMTI4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyMTQ1Ng==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517721456", "bodyText": "This has the same issue as in KeyedWindowedTableLookupOperator", "author": "AlanConfluent", "createdAt": "2020-11-05T01:04:17Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperator.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import com.google.common.collect.ImmutableList;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.Row;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class KeyedTableLookupOperator\n+    extends AbstractPhysicalOperator\n+    implements UnaryPhysicalOperator, DataSourceOperator {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(KeyedTableLookupOperator.class);\n+\n+  private final Materialization mat;\n+  private final DataSourceNode logicalOperator;\n+\n+  private List<KsqlPartitionLocation> partitionLocations;\n+  private Iterator<Row> resultIterator;\n+  private Iterator<Struct> keyIterator;\n+  private Iterator<KsqlPartitionLocation> partitionLocationIterator;\n+  private KsqlPartitionLocation nextLocation;\n+  private Struct nextKey;\n+\n+  public KeyedTableLookupOperator(\n+      final Materialization mat,\n+      final DataSourceNode logicalNode\n+  ) {\n+    this.logicalOperator = Objects.requireNonNull(logicalNode, \"logicalNode\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+  }\n+\n+  @Override\n+  public void open() {\n+    partitionLocationIterator = partitionLocations.iterator();\n+    if (partitionLocationIterator.hasNext()) {\n+      nextLocation = partitionLocationIterator.next();\n+      if (!nextLocation.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Table lookup queries should be done with keys\");\n+      }\n+      keyIterator = nextLocation.getKeys().get().iterator();\n+      if (keyIterator.hasNext()) {\n+        nextKey = keyIterator.next();\n+        resultIterator = mat.nonWindowed()\n+            .get(nextKey, nextLocation.getPartition())\n+            .map(ImmutableList::of)\n+            .orElse(ImmutableList.of()).iterator();\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public Object next() {\n+    if (resultIterator.hasNext()) {\n+      return resultIterator.next();\n+    }\n+    // Exhausted resultIterator\n+    if (!keyIterator.hasNext()) {\n+      if (partitionLocationIterator.hasNext()) {\n+        nextLocation = partitionLocationIterator.next();\n+      } else {\n+        // Exhausted all iterators\n+        return null;\n+      }\n+      if (!nextLocation.getKeys().isPresent()) {\n+        throw new IllegalStateException(\"Table lookup queries should be done with keys\");\n+      }\n+      keyIterator = nextLocation.getKeys().get().iterator();\n+    }\n+    nextKey = keyIterator.next();\n+    resultIterator = mat.nonWindowed()\n+        .get(nextKey, nextLocation.getPartition())\n+        .map(ImmutableList::of)\n+        .orElse(ImmutableList.of()).iterator();\n+    if (resultIterator.hasNext()) {", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcyNjM3Nw==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r517726377", "bodyText": "Do you want to delete this file and it's test file?  (Of couse, it would be great to migrate all of those tests to their updated places).", "author": "AlanConfluent", "createdAt": "2020-11-05T01:21:29Z", "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -65,6 +65,7 @@\n import io.confluent.ksql.execution.transform.select.SelectValueMapper;", "originalCommit": "a136296c32a6279a7563d9f9d273437f67fdaf56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "url": "https://github.com/confluentinc/ksql/commit/41ebdf23c573246bfe8b9b11d0e5b0d61a811f3d", "message": "tests pass", "committedDate": "2020-11-16T19:00:08Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0ODE2NA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r524548164", "bodyText": "Here is where you do the null check.  My original thinking was mostly that if you cannot reference which key this is returning null for, there's not really any point in returning null at all.  Maybe you feel differently.", "author": "AlanConfluent", "createdAt": "2020-11-16T20:21:14Z", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/physical/pull/PullPhysicalPlan.java", "diffHunk": "@@ -0,0 +1,109 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull;\n+\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.physical.pull.operators.AbstractPhysicalOperator;\n+import io.confluent.ksql.physical.pull.operators.DataSourceOperator;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Objects;\n+import org.apache.kafka.connect.data.Struct;\n+\n+/**\n+ * Represents the physical plan for pull queries. It is a tree of physical operators that gets\n+ * created from the translation of the logical plan.\n+ * The root operator is always a ProjectOperator whereas the leaves are scan operators that scan\n+ * the data stores.\n+ */\n+public class PullPhysicalPlan {\n+  private final AbstractPhysicalOperator root;\n+  private final LogicalSchema schema;\n+  private final QueryId queryId;\n+  private final List<Struct> keys;\n+  private final Materialization mat;\n+  private final DataSourceOperator dataSourceOperator;\n+\n+  public PullPhysicalPlan(\n+      final AbstractPhysicalOperator root,\n+      final LogicalSchema schema,\n+      final QueryId queryId,\n+      final List<Struct> keys,\n+      final Materialization mat,\n+      final DataSourceOperator dataSourceOperator\n+  ) {\n+    this.root = Objects.requireNonNull(root, \"root\");\n+    this.schema = Objects.requireNonNull(schema, \"schema\");\n+    this.queryId = Objects.requireNonNull(queryId, \"queryId\");\n+    this.keys = Objects.requireNonNull(keys, \"keys\");\n+    this.mat = Objects.requireNonNull(mat, \"mat\");\n+    this.dataSourceOperator = Objects.requireNonNull(\n+        dataSourceOperator, \"dataSourceOperator\");\n+  }\n+\n+  public List<List<?>> execute(\n+      final List<KsqlPartitionLocation> locations) {\n+\n+    // We only know at runtime which partitions to get from which node.\n+    // That's why we need to set this explicitly for the dataSource operators\n+    dataSourceOperator.setPartitionLocations(locations);\n+\n+    open();\n+    final List<List<?>> localResult = new ArrayList<>();\n+    List<?> row = null;\n+    while ((row = (List<?>)next()) != null) {", "originalCommit": "0b69065fad8de495182284c27ef6cebc05ac0655", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgxMDExOQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r524810119", "bodyText": "You were right, I wasn't handling correctly the case where a key does not exist in the sate store. Fixed it now", "author": "vpapavas", "createdAt": "2020-11-17T00:41:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0ODE2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgzMTM0OA==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r524831348", "bodyText": "@Before runs before every test, not once before all the tests. If you want these to be populated once, which I think you do, it should be in the constructor", "author": "agavra", "createdAt": "2020-11-17T01:45:21Z", "path": "ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/KeyedTableLookupOperatorTest.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright 2018 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Mockito.when;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlNode;\n+import io.confluent.ksql.execution.streams.materialization.Locator.KsqlPartitionLocation;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.MaterializedTable;\n+import io.confluent.ksql.execution.streams.materialization.Row;\n+import io.confluent.ksql.execution.streams.materialization.ks.KsLocator;\n+import io.confluent.ksql.planner.plan.DataSourceNode;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnitRunner;\n+\n+@SuppressWarnings({\"UnstableApiUsage\", \"unchecked\"})\n+@RunWith(MockitoJUnitRunner.class)\n+public class KeyedTableLookupOperatorTest {\n+\n+  private final List<KsqlPartitionLocation> singleKeyPartitionLocations = new ArrayList<>();\n+  private final List<KsqlPartitionLocation> multipleKeysPartitionLocations = new ArrayList<>();\n+\n+  @Mock\n+  private KsqlNode node1;\n+  @Mock\n+  private KsqlNode node2;\n+  @Mock\n+  private KsqlNode node3;\n+  @Mock\n+  private Materialization materialization;\n+  @Mock\n+  private MaterializedTable nonWindowedTable;\n+  @Mock\n+  private DataSourceNode logicalNode;\n+  @Mock\n+  private Struct KEY1;\n+  @Mock\n+  private Struct KEY2;\n+  @Mock\n+  private Struct KEY3;\n+  @Mock\n+  private Struct KEY4;\n+  @Mock\n+  private Row ROW1;\n+  @Mock\n+  private Row ROW3;\n+  @Mock\n+  private Row ROW4;\n+\n+\n+  @Before", "originalCommit": "d84172b973e336c5403a1b95541c043a9cf31842", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgzMzI5Mg==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r524833292", "bodyText": "I think it makes sense to add an assert that selectValueMapper was never called (Mockito.verifyNoInteractions(selectValueMapper)). This will (1) make sure we're not calling unnecessary code, and (2) makes the test easier to understand (I asked myself why we didn't need to mock out the mapper for this method)", "author": "agavra", "createdAt": "2020-11-17T01:51:21Z", "path": "ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/ProjectOperatorTest.java", "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+import com.google.common.collect.Range;\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.Row;\n+import io.confluent.ksql.execution.streams.materialization.Window;\n+import io.confluent.ksql.execution.streams.materialization.WindowedRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory.SelectValueMapperFactorySupplier;\n+import io.confluent.ksql.execution.util.StructKeyUtil;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.ColumnName;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+import org.apache.kafka.streams.kstream.Windowed;\n+import org.apache.kafka.streams.kstream.internals.TimeWindow;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnitRunner;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class ProjectOperatorTest {\n+\n+  private static final LogicalSchema SCHEMA = LogicalSchema.builder()\n+      .keyColumn(ColumnName.of(\"k0\"), SqlTypes.STRING)\n+      .valueColumn(ColumnName.of(\"v0\"), SqlTypes.STRING)\n+      .valueColumn(ColumnName.of(\"v1\"), SqlTypes.STRING)\n+      .build();\n+\n+  private static final Struct A_KEY = StructKeyUtil\n+      .keyBuilder(ColumnName.of(\"k0\"), SqlTypes.STRING).build(\"k\", 0);\n+  private static final long A_ROWTIME = 12335L;\n+\n+  private static final Window A_WINDOW = Window.of(Instant.now(), Instant.now().plusMillis(10));\n+  private static final TimeWindow STREAM_WINDOW = new TimeWindow(\n+      A_WINDOW.start().toEpochMilli(),\n+      A_WINDOW.end().toEpochMilli()\n+  );\n+\n+  @Mock\n+  private KsqlConfig ksqlConfig;\n+  @Mock\n+  private MetaStore metaStore;\n+  @Mock\n+  private ProcessingLogger logger;\n+  @Mock\n+  private Materialization mat;\n+  @Mock\n+  private LogicalSchema outputSchema;\n+  @Mock\n+  private SelectValueMapperFactorySupplier selectValueMapperFactorySupplier;\n+  @Mock\n+  private ProjectNode logicalNode;\n+  @Mock\n+  private AbstractPhysicalOperator child;\n+  @Mock\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  @Mock\n+  private SelectValueMapper<Object> selectValueMapper;\n+\n+  @Test\n+  public void shouldProjectAllColumnsWhenSelectStarNonWindowed() {\n+    // Given:\n+    final ProjectOperator projectOperator = new ProjectOperator(\n+        ksqlConfig,\n+        metaStore,\n+        logger,\n+        mat,\n+        logicalNode,\n+        outputSchema,\n+        true,\n+        false,\n+        false,\n+        selectValueMapperFactorySupplier);\n+    projectOperator.addChild(child);\n+    final Row row = Row.of(\n+        SCHEMA,\n+        A_KEY,\n+        GenericRow.genericRow(\"a\", \"b\"),\n+        A_ROWTIME\n+    );\n+    when(child.next()).thenReturn(row);\n+    projectOperator.open();\n+\n+    // Then:\n+    final List<Object> rowList = new ArrayList<>();\n+    row.key().schema().fields().stream().map(row.key()::get).forEach(rowList::add);\n+    rowList.addAll(row.value().values());\n+    assertThat(projectOperator.next(), is(rowList));", "originalCommit": "d84172b973e336c5403a1b95541c043a9cf31842", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDgzNDMzMQ==", "url": "https://github.com/confluentinc/ksql/pull/6375#discussion_r524834331", "bodyText": "nit: this applies to all tests, but this is what belongs in the //When: part (it makes it easy to identify what is setup and what the test is actually doing. I know this PR has gone on for a while so I won't ask you to refactor all the tests, but going forward it makes tests really easy to read when then //When portion contains the code that you're testing.\nFor example:\n// When:\nList<?> result = projectOperator.next();\n\n// Then:\nfinal List<Object> expected = new ArrayList<>();\nwindowedRow.key().schema().fields().stream().map(windowedRow.key()::get).forEach(expected::add);\nexpected.add(windowedRow.window().get().start().toEpochMilli());\nexpected.add(windowedRow.window().get().end().toEpochMilli());\nexpected.addAll(windowedRow.value().values());\nassertThat(result, is(expected)); \nCompare that with:\n// Then:\nfinal List<Object> expected = new ArrayList<>();\nwindowedRow.key().schema().fields().stream().map(windowedRow.key()::get).forEach(expected::add);\nexpected.add(windowedRow.window().get().start().toEpochMilli());\nexpected.add(windowedRow.window().get().end().toEpochMilli());\nexpected.addAll(windowedRow.value().values());\nassertThat(result, is(rowList)); \nassertThat(projectOperator.next(), is(expected)); \nFor the second one I need to dig in to figure out what is the production code being called.", "author": "agavra", "createdAt": "2020-11-17T01:54:53Z", "path": "ksqldb-engine/src/test/java/io/confluent/ksql/physical/pull/operators/ProjectOperatorTest.java", "diffHunk": "@@ -0,0 +1,356 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.physical.pull.operators;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+import com.google.common.collect.Range;\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.execution.streams.materialization.Materialization;\n+import io.confluent.ksql.execution.streams.materialization.PullProcessingContext;\n+import io.confluent.ksql.execution.streams.materialization.Row;\n+import io.confluent.ksql.execution.streams.materialization.Window;\n+import io.confluent.ksql.execution.streams.materialization.WindowedRow;\n+import io.confluent.ksql.execution.transform.KsqlTransformer;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapper;\n+import io.confluent.ksql.execution.transform.select.SelectValueMapperFactory.SelectValueMapperFactorySupplier;\n+import io.confluent.ksql.execution.util.StructKeyUtil;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.metastore.MetaStore;\n+import io.confluent.ksql.model.WindowType;\n+import io.confluent.ksql.name.ColumnName;\n+import io.confluent.ksql.planner.plan.ProjectNode;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+import org.apache.kafka.connect.data.Struct;\n+import org.apache.kafka.streams.kstream.Windowed;\n+import org.apache.kafka.streams.kstream.internals.TimeWindow;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnitRunner;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class ProjectOperatorTest {\n+\n+  private static final LogicalSchema SCHEMA = LogicalSchema.builder()\n+      .keyColumn(ColumnName.of(\"k0\"), SqlTypes.STRING)\n+      .valueColumn(ColumnName.of(\"v0\"), SqlTypes.STRING)\n+      .valueColumn(ColumnName.of(\"v1\"), SqlTypes.STRING)\n+      .build();\n+\n+  private static final Struct A_KEY = StructKeyUtil\n+      .keyBuilder(ColumnName.of(\"k0\"), SqlTypes.STRING).build(\"k\", 0);\n+  private static final long A_ROWTIME = 12335L;\n+\n+  private static final Window A_WINDOW = Window.of(Instant.now(), Instant.now().plusMillis(10));\n+  private static final TimeWindow STREAM_WINDOW = new TimeWindow(\n+      A_WINDOW.start().toEpochMilli(),\n+      A_WINDOW.end().toEpochMilli()\n+  );\n+\n+  @Mock\n+  private KsqlConfig ksqlConfig;\n+  @Mock\n+  private MetaStore metaStore;\n+  @Mock\n+  private ProcessingLogger logger;\n+  @Mock\n+  private Materialization mat;\n+  @Mock\n+  private LogicalSchema outputSchema;\n+  @Mock\n+  private SelectValueMapperFactorySupplier selectValueMapperFactorySupplier;\n+  @Mock\n+  private ProjectNode logicalNode;\n+  @Mock\n+  private AbstractPhysicalOperator child;\n+  @Mock\n+  private KsqlTransformer<Object, GenericRow> transformer;\n+  @Mock\n+  private SelectValueMapper<Object> selectValueMapper;\n+\n+  @Test\n+  public void shouldProjectAllColumnsWhenSelectStarNonWindowed() {\n+    // Given:\n+    final ProjectOperator projectOperator = new ProjectOperator(\n+        ksqlConfig,\n+        metaStore,\n+        logger,\n+        mat,\n+        logicalNode,\n+        outputSchema,\n+        true,\n+        false,\n+        false,\n+        selectValueMapperFactorySupplier);\n+    projectOperator.addChild(child);\n+    final Row row = Row.of(\n+        SCHEMA,\n+        A_KEY,\n+        GenericRow.genericRow(\"a\", \"b\"),\n+        A_ROWTIME\n+    );\n+    when(child.next()).thenReturn(row);\n+    projectOperator.open();\n+\n+    // Then:\n+    final List<Object> rowList = new ArrayList<>();\n+    row.key().schema().fields().stream().map(row.key()::get).forEach(rowList::add);\n+    rowList.addAll(row.value().values());\n+    assertThat(projectOperator.next(), is(rowList));\n+  }\n+\n+  @Test\n+  public void shouldProjectAllColumnsWhenSelectStarWindowed() {\n+    // Given:\n+    final ProjectOperator projectOperator = new ProjectOperator(\n+        ksqlConfig,\n+        metaStore,\n+        logger,\n+        mat,\n+        logicalNode,\n+        outputSchema,\n+        true,\n+        true,\n+        false,\n+        selectValueMapperFactorySupplier);\n+    projectOperator.addChild(child);\n+    final WindowedRow windowedRow = WindowedRow.of(\n+        SCHEMA,\n+        new Windowed<>(A_KEY, STREAM_WINDOW),\n+        GenericRow.genericRow(\"a\", \"b\"),\n+        A_ROWTIME\n+    );\n+    when(child.next()).thenReturn(windowedRow);\n+    projectOperator.open();\n+\n+    // Then:\n+    final List<Object> rowList = new ArrayList<>();\n+    windowedRow.key().schema().fields().stream().map(windowedRow.key()::get).forEach(rowList::add);\n+    rowList.add(windowedRow.window().get().start().toEpochMilli());\n+    rowList.add(windowedRow.window().get().end().toEpochMilli());\n+    rowList.addAll(windowedRow.value().values());\n+    assertThat(projectOperator.next(), is(rowList));\n+  }\n+\n+  @Test\n+  public void shouldCallTransformWithCorrectArguments() {\n+    // Given:\n+    final ProjectOperator projectOperator = new ProjectOperator(\n+        ksqlConfig,\n+        metaStore,\n+        logger,\n+        mat,\n+        logicalNode,\n+        SCHEMA,\n+        false,\n+        false,\n+        true,\n+        selectValueMapperFactorySupplier);\n+    projectOperator.addChild(child);\n+    final Row row = Row.of(\n+        SCHEMA,\n+        A_KEY,\n+        GenericRow.genericRow(\"a\", \"b\"),\n+        A_ROWTIME\n+    );\n+    when(child.next()).thenReturn(row);\n+    when(selectValueMapperFactorySupplier.create(any(), any(), any(), any()))\n+        .thenReturn(selectValueMapper);\n+    when(selectValueMapper.getTransformer(logger)).thenReturn(transformer);\n+    when(transformer.transform(any(), any(), any())).thenReturn(GenericRow.genericRow(\"k\", \"a\", \"b\"));\n+    when(mat.schema()).thenReturn(SCHEMA);\n+    projectOperator.open();\n+    projectOperator.next();", "originalCommit": "d84172b973e336c5403a1b95541c043a9cf31842", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "4672c3d67d24bcad993664b0d44e28b45151ac23", "url": "https://github.com/confluentinc/ksql/commit/4672c3d67d24bcad993664b0d44e28b45151ac23", "message": "first iteration on pull physical plan\n\nadded ha routing and windowed table\n\nfix checkstyle\n\nall tests pass\n\nremove comments\n\nfix regression in engineexecutor\n\nAddress comments\n\nrefactoring to include in predicate changes\n\nfixing tests\n\ntrying to fix rqt test\n\naddress alan's comments\n\nfixed import\n\naddress almog's comments\n\nadd tests for operators\n\nadding test for project operator\n\nadded test for HA routing\n\naddress comments and add tests\n\ntests pass\n\nstyling and remove unnecessary changes\n\nfix bug in next of lookup operators", "committedDate": "2020-11-17T23:31:05Z", "type": "commit"}, {"oid": "6aab39a243472d5256f849fd4d07c3305fe5c349", "url": "https://github.com/confluentinc/ksql/commit/6aab39a243472d5256f849fd4d07c3305fe5c349", "message": "improved tests", "committedDate": "2020-11-17T23:31:08Z", "type": "commit"}, {"oid": "6aab39a243472d5256f849fd4d07c3305fe5c349", "url": "https://github.com/confluentinc/ksql/commit/6aab39a243472d5256f849fd4d07c3305fe5c349", "message": "improved tests", "committedDate": "2020-11-17T23:31:08Z", "type": "forcePushed"}, {"oid": "e3493f4c369b4ce8bf07886f3c9c1ece8152fb33", "url": "https://github.com/confluentinc/ksql/commit/e3493f4c369b4ce8bf07886f3c9c1ece8152fb33", "message": "fix compilation error", "committedDate": "2020-11-18T01:17:59Z", "type": "commit"}, {"oid": "4488fb328573a66f4cefb3e76f4d25c7114df5f7", "url": "https://github.com/confluentinc/ksql/commit/4488fb328573a66f4cefb3e76f4d25c7114df5f7", "message": "wrong error message", "committedDate": "2020-11-18T04:20:55Z", "type": "commit"}, {"oid": "5044d1e7215e1049039e1b344cb4fbcc87e0bf1e", "url": "https://github.com/confluentinc/ksql/commit/5044d1e7215e1049039e1b344cb4fbcc87e0bf1e", "message": "empty: trying to fix jenkins", "committedDate": "2020-11-18T18:27:34Z", "type": "commit"}]}