{"pr_number": 2853, "pr_title": "Small optimization for Page compression / decompression", "pr_createdAt": "2020-08-25T01:30:48Z", "pr_url": "https://github.com/h2database/h2database/pull/2853", "timeline": [{"oid": "e7c427a888648c7668d3a6e696b260c9aeb0b828", "url": "https://github.com/h2database/h2database/commit/e7c427a888648c7668d3a6e696b260c9aeb0b828", "message": "introduce input array offset to Compressor and eliminate array creation and copiing", "committedDate": "2020-08-25T01:03:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjA0NzU5Ng==", "url": "https://github.com/h2database/h2database/pull/2853#discussion_r476047596", "bodyText": "I didn't check it, but I guess it should be pos = buff.arrayOffset() + buff.position(). Maybe offset is always 0 with our current code, but who knows how it can be changed in the future.", "author": "katzyn", "createdAt": "2020-08-25T01:41:49Z", "path": "h2/src/main/org/h2/mvstore/Page.java", "diffHunk": "@@ -619,11 +619,18 @@ private void read(ByteBuffer buff) {\n             }\n             int lenAdd = DataUtils.readVarInt(buff);\n             int compLen = buff.remaining();\n-            byte[] comp = Utils.newBytes(compLen);\n-            buff.get(comp);\n+            byte[] comp;\n+            int pos = 0;\n+            if (buff.hasArray()) {\n+                comp = buff.array();\n+                pos = buff.position();", "originalCommit": "e7c427a888648c7668d3a6e696b260c9aeb0b828", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjA0ODg2Ng==", "url": "https://github.com/h2database/h2database/pull/2853#discussion_r476048866", "bodyText": "Here we need pos = byteBuffer.arrayOffset() + compressStart I guess.", "author": "katzyn", "createdAt": "2020-08-25T01:43:44Z", "path": "h2/src/main/org/h2/mvstore/Page.java", "diffHunk": "@@ -709,10 +716,18 @@ protected final int write(Chunk chunk, WriteBuffer buff, List<Long> toc) {\n                     compressor = store.getCompressorHigh();\n                     compressType = DataUtils.PAGE_COMPRESSED_HIGH;\n                 }\n-                byte[] exp = new byte[expLen];\n-                buff.position(compressStart).get(exp);\n                 byte[] comp = new byte[expLen * 2];\n-                int compLen = compressor.compress(exp, expLen, comp, 0);\n+                ByteBuffer byteBuffer = buff.getBuffer();\n+                int pos = 0;\n+                byte[] exp;\n+                if (byteBuffer.hasArray()) {\n+                    exp = byteBuffer.array();\n+                    pos = compressStart;", "originalCommit": "e7c427a888648c7668d3a6e696b260c9aeb0b828", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjA3NTMyOQ==", "url": "https://github.com/h2database/h2database/pull/2853#discussion_r476075329", "bodyText": "Indeed, it's currently always zero, added", "author": "andreitokar", "createdAt": "2020-08-25T02:23:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjA0ODg2Ng=="}], "type": "inlineReview"}, {"oid": "1fdb7b5e1cf2cc3dcf78213e398155c08edd27ee", "url": "https://github.com/h2database/h2database/commit/1fdb7b5e1cf2cc3dcf78213e398155c08edd27ee", "message": "add buffer.arrayOffset()", "committedDate": "2020-08-25T02:22:26Z", "type": "commit"}]}