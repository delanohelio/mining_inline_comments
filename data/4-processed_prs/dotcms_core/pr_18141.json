{"pr_number": 18141, "pr_title": "Issue 17976 fixes", "pr_createdAt": "2020-03-16T15:16:45Z", "pr_url": "https://github.com/dotCMS/core/pull/18141", "timeline": [{"oid": "b3438c42c6b9d05efa48e19ef9a9e2ee54c8ae08", "url": "https://github.com/dotCMS/core/commit/b3438c42c6b9d05efa48e19ef9a9e2ee54c8ae08", "message": "#17976", "committedDate": "2020-03-13T14:30:22Z", "type": "commit"}, {"oid": "79914fcafa2fb297ae568ee60a33a11b774c1f8a", "url": "https://github.com/dotCMS/core/commit/79914fcafa2fb297ae568ee60a33a11b774c1f8a", "message": "#17976 fix indexing non-default lang", "committedDate": "2020-03-13T18:18:23Z", "type": "commit"}, {"oid": "150d16af52443a6a91d95b279480d042ff66db67", "url": "https://github.com/dotCMS/core/commit/150d16af52443a6a91d95b279480d042ff66db67", "message": "#17976 adding concurrency  support.", "committedDate": "2020-03-16T14:38:08Z", "type": "commit"}, {"oid": "665016576f43724d2aa070ab028f588ca153dc4d", "url": "https://github.com/dotCMS/core/commit/665016576f43724d2aa070ab028f588ca153dc4d", "message": "#17976 logger clean up", "committedDate": "2020-03-16T14:55:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzEwODQwNw==", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393108407", "bodyText": "rename to bundlerStatus", "author": "jdotcms", "createdAt": "2020-03-16T15:26:42Z", "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -129,182 +134,213 @@ public void run(final JobExecutionContext jobContext) throws JobExecutionExcepti\n \n         HibernateUtil.startTransaction();\n \n-        final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n-\n-        String jobId = (String) dataMap.get(JOB_ID);\n-        if (jobId == null) {\n-            jobId = dataMap.getString(QUARTZ_JOB_NAME);\n-        }\n-\n-        final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n-        final String[] indexHosts;\n-        final Object obj = (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n-        if (obj instanceof String) {\n-            indexHosts = new String[]{(String) obj};\n-        } else {\n-            indexHosts = (String[]) obj;\n-        }\n-\n-        final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n-\n-        final User userToRun = userAPI.getSystemUser();\n-\n-        final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n-                .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n-\n-        String path = dataMap.getString(PATHS);\n-        final List<String> paths = new ArrayList<>();\n-        if (path != null) {\n-            path = path.replace(',', '\\r');\n-            path = path.replace('\\n', '\\r');\n-            for (String x : path.split(\"\\r\")) {\n-                if (UtilMethods.isSet(x)) {\n-                    paths.add(x);\n-                }\n+        final PreparedJobContext preparedJobContext = prepareJob(jobContext);\n+        synchronized (preparedJobContext.lockKey()) {\n+            for (final SiteSearchConfig config : preparedJobContext.getConfigs()) {\n+                publisherAPI.publish(config, status);\n             }\n         }\n-        final boolean isRunNowJob = dataMap.getBooleanFromString(RUN_NOW);\n-        // Run now jobs can not get the incremental treatment.\n-        final IndexMetaData indexMetaData = getIndexMetaData(dataMap.getString(INDEX_ALIAS));\n-        final String newIndexName;\n-        final String indexName;\n-\n-        final String jobName = dataMap.getString(QUARTZ_JOB_NAME);\n-        final Date startDate, endDate;\n-        final List<SiteSearchAudit> recentAudits = isRunNowJob ? Collections.emptyList()\n-                : siteSearchAuditAPI.findRecentAudits(jobId, 0, 1);\n-\n-        final boolean incremental = (incrementalParam && !isRunNowJob && !indexMetaData.isNewIndex() && !indexMetaData.isEmpty() && !recentAudits.isEmpty());\n-        //We can only run incrementally if all the above pre-requisites are met.\n-        if (incremental) {\n-            //Incremental mode is useful only if there's already an index previously built.\n-            //Incremental mode also implies that we have to have a date range to work on.\n-            //So if we have an empty index or we lack of audit data we can not run incrementally.\n-            //Even if the user wants to.\n-            newIndexName = null;\n-            endDate = jobContext.getFireTime();\n-            startDate = recentAudits.get(0).getFireDate();\n-            //For incremental jobs, we write the bundle to the same folder every time.\n-            bundleId = StringUtils.camelCaseLower(jobName);\n-            //We'll be working directly into the final index.\n-            indexName = indexMetaData.getIndexName();\n-        } else {\n-            //Set null explicitly just in case\n-            startDate = endDate = null;\n-            // For non-incremental jobs. We create a new folder using a date stamp.\n-            // But even if this run was executed non-incrementally for not having met any of the pre-requisits\n-            // The job originally was meant to run incrementally therefore the results must be stored in the job specific folder.\n-            // So they will still be available in the next round.\n-            bundleId = incrementalParam ? StringUtils.camelCaseLower(jobName) :\n-            // Otherwise it is safe to create a unique time-stamp like folder name.\n-                       UtilMethods.dateToJDBC(new Date()).replace(':', '-').replace(' ', '_');\n-            // We use a new index name only on non-incremental\n-            newIndexName = newIndexName();\n-            final String newAlias = indexMetaData.isNewIndex() ? indexMetaData.getAlias() : null ;\n-            siteSearchAPI.createSiteSearchIndex(newIndexName, newAlias, 1);\n-            // This is the old index we will swap from.\n-            // if it doesnt exist. It doesnt matter here since we will end up with the new one.\n-            indexName = indexMetaData.getIndexName();\n-        }\n-\n-        Logger.info(SiteSearchJobImpl.class, () -> String\n-                .format(\" Incremental mode [%s]. current index is `%s`. new index is `%s`. bundle id is `%s` \",\n-                        BooleanUtils.toStringYesNo(incremental), indexName ,\n-                        UtilMethods.isSet(newIndexName) ? newIndexName : \"N/A\",\n-                        bundleId));\n-\n-        final List<Host> hosts;\n-        if (indexAll) {\n-            hosts = hostAPI.findAll(userToRun, true);\n-        } else {\n-            hosts = Stream.of(indexHosts).map(h -> {\n-                try {\n-                   return hostAPI.find(h, userToRun, true);\n-                } catch (DotDataException | DotSecurityException e) {\n-                    Logger.error(SiteSearchJobImpl.class, e);\n-                }\n-                return null;\n-            }).filter(Objects::nonNull).collect(Collectors.toList());\n-        }\n-\n-        final List<String> languageToIndex = Arrays.asList((String[])dataMap.get(LANG_TO_INDEX));\n-        final ListIterator<String> listIterator = languageToIndex.listIterator();\n-        while (listIterator.hasNext()) {\n-            final String lang = listIterator.next();\n-            final SiteSearchConfig config = new SiteSearchConfig();\n-            config.setJobId(jobId);\n-            config.setLanguage(Long.parseLong(lang));\n-            config.setJobName(jobName);\n-            config.setHosts(hosts);\n-            config.setNewIndexName(newIndexName);\n-            config.setIndexName(indexName);\n-            config.setId(bundleId);\n-            config.setStartDate(startDate);\n-            config.setEndDate(endDate);\n-            config.setIncremental(incremental);\n-            config.setUser(userToRun);\n-\n-            if(include) {\n-                config.setIncludePatterns(paths);\n-            } else {\n-                config.setExcludePatterns(paths);\n-            }\n \n-            //We should always replace the index when performing on non-incremental mode.\n-            //That means we drop the old one and re-use the alias.\n-            //But we only activate the new index when the old one was the default.\n-            //Or there wasn't any previous index.\n-            //it must be done on the last round of our loop.\n-            final boolean switchIndex = !incremental && !listIterator.hasNext();\n-            config.setSwitchIndexWhenDone(switchIndex);\n-            publisherAPI.publish(config, status);\n-        }\n+        try {\n \n-        int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n-        for (final BundlerStatus bs : status.getBundlerStatuses()) {\n-            if (bs.getBundlerClass().equals(FileAssetBundler.class.getName())) {\n-                filesCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(URLMapBundler.class.getName())) {\n-                urlmapCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(HTMLPageAsContentBundler.class.getName())) {\n-                pagesCount += bs.getTotal();\n-            }\n-        }\n+                int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n+                for (final BundlerStatus bs : status.getBundlerStatuses()) {", "originalCommit": "665016576f43724d2aa070ab028f588ca153dc4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExODc4NQ==", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393118785", "bodyText": "ok", "author": "fabrizzio-dotCMS", "createdAt": "2020-03-16T15:41:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzEwODQwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExMjk4OQ==", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393112989", "bodyText": "Is a synchronization block enough? At the end of the day, the SiteSearchJob in quartz should be a Stateful job.  A Stateful job can only be run one at a time in a whole cluster. This is an important distinction as for most of our Quartz Jobs we do not want them to be run simultaneously in a clustered environment by different servers.", "author": "wezell", "createdAt": "2020-03-16T15:33:04Z", "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -52,6 +55,8 @@\n \n public class SiteSearchJobImpl {", "originalCommit": "665016576f43724d2aa070ab028f588ca153dc4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExNzAyNA==", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393117024", "bodyText": "Let's say you schedule 2 jobs to run every  30mins (Even if they're meant to work on a different index). They will eventually sync-up and start to use the same code at the same time leading to tons of issues.  for such case synchronization is required.", "author": "fabrizzio-dotCMS", "createdAt": "2020-03-16T15:38:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExMjk4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExMzQ5Mw==", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393113493", "bodyText": "this could be handle in a method such as\nindexHosts = ConversionUtils.toArrayString (dataMap.get(INDEX_HOST));", "author": "jdotcms", "createdAt": "2020-03-16T15:33:44Z", "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -129,182 +134,213 @@ public void run(final JobExecutionContext jobContext) throws JobExecutionExcepti\n \n         HibernateUtil.startTransaction();\n \n-        final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n-\n-        String jobId = (String) dataMap.get(JOB_ID);\n-        if (jobId == null) {\n-            jobId = dataMap.getString(QUARTZ_JOB_NAME);\n-        }\n-\n-        final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n-        final String[] indexHosts;\n-        final Object obj = (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n-        if (obj instanceof String) {\n-            indexHosts = new String[]{(String) obj};\n-        } else {\n-            indexHosts = (String[]) obj;\n-        }\n-\n-        final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n-\n-        final User userToRun = userAPI.getSystemUser();\n-\n-        final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n-                .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n-\n-        String path = dataMap.getString(PATHS);\n-        final List<String> paths = new ArrayList<>();\n-        if (path != null) {\n-            path = path.replace(',', '\\r');\n-            path = path.replace('\\n', '\\r');\n-            for (String x : path.split(\"\\r\")) {\n-                if (UtilMethods.isSet(x)) {\n-                    paths.add(x);\n-                }\n+        final PreparedJobContext preparedJobContext = prepareJob(jobContext);\n+        synchronized (preparedJobContext.lockKey()) {\n+            for (final SiteSearchConfig config : preparedJobContext.getConfigs()) {\n+                publisherAPI.publish(config, status);\n             }\n         }\n-        final boolean isRunNowJob = dataMap.getBooleanFromString(RUN_NOW);\n-        // Run now jobs can not get the incremental treatment.\n-        final IndexMetaData indexMetaData = getIndexMetaData(dataMap.getString(INDEX_ALIAS));\n-        final String newIndexName;\n-        final String indexName;\n-\n-        final String jobName = dataMap.getString(QUARTZ_JOB_NAME);\n-        final Date startDate, endDate;\n-        final List<SiteSearchAudit> recentAudits = isRunNowJob ? Collections.emptyList()\n-                : siteSearchAuditAPI.findRecentAudits(jobId, 0, 1);\n-\n-        final boolean incremental = (incrementalParam && !isRunNowJob && !indexMetaData.isNewIndex() && !indexMetaData.isEmpty() && !recentAudits.isEmpty());\n-        //We can only run incrementally if all the above pre-requisites are met.\n-        if (incremental) {\n-            //Incremental mode is useful only if there's already an index previously built.\n-            //Incremental mode also implies that we have to have a date range to work on.\n-            //So if we have an empty index or we lack of audit data we can not run incrementally.\n-            //Even if the user wants to.\n-            newIndexName = null;\n-            endDate = jobContext.getFireTime();\n-            startDate = recentAudits.get(0).getFireDate();\n-            //For incremental jobs, we write the bundle to the same folder every time.\n-            bundleId = StringUtils.camelCaseLower(jobName);\n-            //We'll be working directly into the final index.\n-            indexName = indexMetaData.getIndexName();\n-        } else {\n-            //Set null explicitly just in case\n-            startDate = endDate = null;\n-            // For non-incremental jobs. We create a new folder using a date stamp.\n-            // But even if this run was executed non-incrementally for not having met any of the pre-requisits\n-            // The job originally was meant to run incrementally therefore the results must be stored in the job specific folder.\n-            // So they will still be available in the next round.\n-            bundleId = incrementalParam ? StringUtils.camelCaseLower(jobName) :\n-            // Otherwise it is safe to create a unique time-stamp like folder name.\n-                       UtilMethods.dateToJDBC(new Date()).replace(':', '-').replace(' ', '_');\n-            // We use a new index name only on non-incremental\n-            newIndexName = newIndexName();\n-            final String newAlias = indexMetaData.isNewIndex() ? indexMetaData.getAlias() : null ;\n-            siteSearchAPI.createSiteSearchIndex(newIndexName, newAlias, 1);\n-            // This is the old index we will swap from.\n-            // if it doesnt exist. It doesnt matter here since we will end up with the new one.\n-            indexName = indexMetaData.getIndexName();\n-        }\n-\n-        Logger.info(SiteSearchJobImpl.class, () -> String\n-                .format(\" Incremental mode [%s]. current index is `%s`. new index is `%s`. bundle id is `%s` \",\n-                        BooleanUtils.toStringYesNo(incremental), indexName ,\n-                        UtilMethods.isSet(newIndexName) ? newIndexName : \"N/A\",\n-                        bundleId));\n-\n-        final List<Host> hosts;\n-        if (indexAll) {\n-            hosts = hostAPI.findAll(userToRun, true);\n-        } else {\n-            hosts = Stream.of(indexHosts).map(h -> {\n-                try {\n-                   return hostAPI.find(h, userToRun, true);\n-                } catch (DotDataException | DotSecurityException e) {\n-                    Logger.error(SiteSearchJobImpl.class, e);\n-                }\n-                return null;\n-            }).filter(Objects::nonNull).collect(Collectors.toList());\n-        }\n-\n-        final List<String> languageToIndex = Arrays.asList((String[])dataMap.get(LANG_TO_INDEX));\n-        final ListIterator<String> listIterator = languageToIndex.listIterator();\n-        while (listIterator.hasNext()) {\n-            final String lang = listIterator.next();\n-            final SiteSearchConfig config = new SiteSearchConfig();\n-            config.setJobId(jobId);\n-            config.setLanguage(Long.parseLong(lang));\n-            config.setJobName(jobName);\n-            config.setHosts(hosts);\n-            config.setNewIndexName(newIndexName);\n-            config.setIndexName(indexName);\n-            config.setId(bundleId);\n-            config.setStartDate(startDate);\n-            config.setEndDate(endDate);\n-            config.setIncremental(incremental);\n-            config.setUser(userToRun);\n-\n-            if(include) {\n-                config.setIncludePatterns(paths);\n-            } else {\n-                config.setExcludePatterns(paths);\n-            }\n \n-            //We should always replace the index when performing on non-incremental mode.\n-            //That means we drop the old one and re-use the alias.\n-            //But we only activate the new index when the old one was the default.\n-            //Or there wasn't any previous index.\n-            //it must be done on the last round of our loop.\n-            final boolean switchIndex = !incremental && !listIterator.hasNext();\n-            config.setSwitchIndexWhenDone(switchIndex);\n-            publisherAPI.publish(config, status);\n-        }\n+        try {\n \n-        int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n-        for (final BundlerStatus bs : status.getBundlerStatuses()) {\n-            if (bs.getBundlerClass().equals(FileAssetBundler.class.getName())) {\n-                filesCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(URLMapBundler.class.getName())) {\n-                urlmapCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(HTMLPageAsContentBundler.class.getName())) {\n-                pagesCount += bs.getTotal();\n-            }\n-        }\n+                int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n+                for (final BundlerStatus bs : status.getBundlerStatuses()) {\n+                    if (bs.getBundlerClass().equals(FileAssetBundler.class.getName())) {\n+                        filesCount += bs.getTotal();\n+                    } else if (bs.getBundlerClass().equals(URLMapBundler.class.getName())) {\n+                        urlmapCount += bs.getTotal();\n+                    } else if (bs.getBundlerClass()\n+                            .equals(HTMLPageAsContentBundler.class.getName())) {\n+                        pagesCount += bs.getTotal();\n+                    }\n+                }\n \n-        try {\n-            final SiteSearchAudit audit = new SiteSearchAudit();\n-            audit.setPagesCount(pagesCount);\n-            audit.setFilesCount(filesCount);\n-            audit.setUrlmapsCount(urlmapCount);\n-            audit.setAllHosts(indexAll);\n-            audit.setFireDate(jobContext.getFireTime());\n-            audit.setHostList(UtilMethods.join(indexHosts,\",\",true));\n-            audit.setIncremental(incremental);\n-            audit.setStartDate(startDate);\n-            audit.setEndDate(endDate);\n-            audit.setIndexName( UtilMethods.isSet(newIndexName) ? newIndexName :  indexName );\n-            audit.setJobId(jobId);\n-            audit.setJobName(dataMap.getString(QUARTZ_JOB_NAME));\n-            audit.setLangList(UtilMethods.join(languageToIndex,\",\"));\n-            audit.setPath(paths.size() > 0 ? UtilMethods.join(paths,\",\") : \"/*\");\n-            audit.setPathInclude(include);\n-            siteSearchAuditAPI.save(audit);\n-        }\n-        catch(DotDataException ex) {\n-            Logger.error(this, \"can't save audit data\",ex);\n-        }\n-        finally {\n+                final SiteSearchAudit audit = new SiteSearchAudit();\n+                audit.setPagesCount(pagesCount);\n+                audit.setFilesCount(filesCount);\n+                audit.setUrlmapsCount(urlmapCount);\n+                audit.setAllHosts(preparedJobContext.isIndexAll());\n+                audit.setFireDate(jobContext.getFireTime());\n+                audit.setHostList(preparedJobContext.getJoinedHosts());\n+                audit.setIncremental(preparedJobContext.isIncremental());\n+                audit.setStartDate(preparedJobContext.getStartDate());\n+                audit.setEndDate(preparedJobContext.getEndDate());\n+                audit.setIndexName(\n+                        UtilMethods.isSet(preparedJobContext.getNewIndexName()) ? preparedJobContext\n+                                .getNewIndexName() : preparedJobContext.getIndexName());\n+                audit.setJobId(preparedJobContext.getJobId());\n+                audit.setJobName(preparedJobContext.getJobName());\n+                audit.setLangList(preparedJobContext.getLangList());\n+                audit.setPath(preparedJobContext.getPaths());\n+                audit.setPathInclude(preparedJobContext.isPathInclude());\n+                siteSearchAuditAPI.save(audit);\n+\n+\n+        } catch (DotDataException ex) {\n+            Logger.error(this, \"can't save audit data\", ex);\n+        } finally {\n             HibernateUtil.closeSession();\n         }\n-\n         date = DateUtil.getCurrentDate();\n         ActivityLogger.logInfo(getClass(), \"Job Finished\", \"User: \" +userAPI.getSystemUser().getUserId()+ \"; Date: \" + date + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME  );\n         AdminLogger.log(getClass(), \"Job Finished\", \"User: \" +userAPI.getSystemUser().getUserId()+ \"; Date: \" + date + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME );\n     }\n \n+     private synchronized PreparedJobContext prepareJob(final JobExecutionContext jobContext)\n+             throws DotDataException, IOException, DotSecurityException {\n+\n+         final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n+         String jobId = (String) dataMap.get(JOB_ID);\n+         if (jobId == null) {\n+             jobId = dataMap.getString(QUARTZ_JOB_NAME);\n+         }\n+\n+         final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n+         final String[] indexHosts;\n+         final Object obj = (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];", "originalCommit": "665016576f43724d2aa070ab028f588ca153dc4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExODcxMA==", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393118710", "bodyText": "nah", "author": "fabrizzio-dotCMS", "createdAt": "2020-03-16T15:41:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExMzQ5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExNDM3MA==", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393114370", "bodyText": "rename to pathToken or so", "author": "jdotcms", "createdAt": "2020-03-16T15:35:04Z", "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -129,182 +134,213 @@ public void run(final JobExecutionContext jobContext) throws JobExecutionExcepti\n \n         HibernateUtil.startTransaction();\n \n-        final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n-\n-        String jobId = (String) dataMap.get(JOB_ID);\n-        if (jobId == null) {\n-            jobId = dataMap.getString(QUARTZ_JOB_NAME);\n-        }\n-\n-        final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n-        final String[] indexHosts;\n-        final Object obj = (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n-        if (obj instanceof String) {\n-            indexHosts = new String[]{(String) obj};\n-        } else {\n-            indexHosts = (String[]) obj;\n-        }\n-\n-        final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n-\n-        final User userToRun = userAPI.getSystemUser();\n-\n-        final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n-                .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n-\n-        String path = dataMap.getString(PATHS);\n-        final List<String> paths = new ArrayList<>();\n-        if (path != null) {\n-            path = path.replace(',', '\\r');\n-            path = path.replace('\\n', '\\r');\n-            for (String x : path.split(\"\\r\")) {\n-                if (UtilMethods.isSet(x)) {\n-                    paths.add(x);\n-                }\n+        final PreparedJobContext preparedJobContext = prepareJob(jobContext);\n+        synchronized (preparedJobContext.lockKey()) {\n+            for (final SiteSearchConfig config : preparedJobContext.getConfigs()) {\n+                publisherAPI.publish(config, status);\n             }\n         }\n-        final boolean isRunNowJob = dataMap.getBooleanFromString(RUN_NOW);\n-        // Run now jobs can not get the incremental treatment.\n-        final IndexMetaData indexMetaData = getIndexMetaData(dataMap.getString(INDEX_ALIAS));\n-        final String newIndexName;\n-        final String indexName;\n-\n-        final String jobName = dataMap.getString(QUARTZ_JOB_NAME);\n-        final Date startDate, endDate;\n-        final List<SiteSearchAudit> recentAudits = isRunNowJob ? Collections.emptyList()\n-                : siteSearchAuditAPI.findRecentAudits(jobId, 0, 1);\n-\n-        final boolean incremental = (incrementalParam && !isRunNowJob && !indexMetaData.isNewIndex() && !indexMetaData.isEmpty() && !recentAudits.isEmpty());\n-        //We can only run incrementally if all the above pre-requisites are met.\n-        if (incremental) {\n-            //Incremental mode is useful only if there's already an index previously built.\n-            //Incremental mode also implies that we have to have a date range to work on.\n-            //So if we have an empty index or we lack of audit data we can not run incrementally.\n-            //Even if the user wants to.\n-            newIndexName = null;\n-            endDate = jobContext.getFireTime();\n-            startDate = recentAudits.get(0).getFireDate();\n-            //For incremental jobs, we write the bundle to the same folder every time.\n-            bundleId = StringUtils.camelCaseLower(jobName);\n-            //We'll be working directly into the final index.\n-            indexName = indexMetaData.getIndexName();\n-        } else {\n-            //Set null explicitly just in case\n-            startDate = endDate = null;\n-            // For non-incremental jobs. We create a new folder using a date stamp.\n-            // But even if this run was executed non-incrementally for not having met any of the pre-requisits\n-            // The job originally was meant to run incrementally therefore the results must be stored in the job specific folder.\n-            // So they will still be available in the next round.\n-            bundleId = incrementalParam ? StringUtils.camelCaseLower(jobName) :\n-            // Otherwise it is safe to create a unique time-stamp like folder name.\n-                       UtilMethods.dateToJDBC(new Date()).replace(':', '-').replace(' ', '_');\n-            // We use a new index name only on non-incremental\n-            newIndexName = newIndexName();\n-            final String newAlias = indexMetaData.isNewIndex() ? indexMetaData.getAlias() : null ;\n-            siteSearchAPI.createSiteSearchIndex(newIndexName, newAlias, 1);\n-            // This is the old index we will swap from.\n-            // if it doesnt exist. It doesnt matter here since we will end up with the new one.\n-            indexName = indexMetaData.getIndexName();\n-        }\n-\n-        Logger.info(SiteSearchJobImpl.class, () -> String\n-                .format(\" Incremental mode [%s]. current index is `%s`. new index is `%s`. bundle id is `%s` \",\n-                        BooleanUtils.toStringYesNo(incremental), indexName ,\n-                        UtilMethods.isSet(newIndexName) ? newIndexName : \"N/A\",\n-                        bundleId));\n-\n-        final List<Host> hosts;\n-        if (indexAll) {\n-            hosts = hostAPI.findAll(userToRun, true);\n-        } else {\n-            hosts = Stream.of(indexHosts).map(h -> {\n-                try {\n-                   return hostAPI.find(h, userToRun, true);\n-                } catch (DotDataException | DotSecurityException e) {\n-                    Logger.error(SiteSearchJobImpl.class, e);\n-                }\n-                return null;\n-            }).filter(Objects::nonNull).collect(Collectors.toList());\n-        }\n-\n-        final List<String> languageToIndex = Arrays.asList((String[])dataMap.get(LANG_TO_INDEX));\n-        final ListIterator<String> listIterator = languageToIndex.listIterator();\n-        while (listIterator.hasNext()) {\n-            final String lang = listIterator.next();\n-            final SiteSearchConfig config = new SiteSearchConfig();\n-            config.setJobId(jobId);\n-            config.setLanguage(Long.parseLong(lang));\n-            config.setJobName(jobName);\n-            config.setHosts(hosts);\n-            config.setNewIndexName(newIndexName);\n-            config.setIndexName(indexName);\n-            config.setId(bundleId);\n-            config.setStartDate(startDate);\n-            config.setEndDate(endDate);\n-            config.setIncremental(incremental);\n-            config.setUser(userToRun);\n-\n-            if(include) {\n-                config.setIncludePatterns(paths);\n-            } else {\n-                config.setExcludePatterns(paths);\n-            }\n \n-            //We should always replace the index when performing on non-incremental mode.\n-            //That means we drop the old one and re-use the alias.\n-            //But we only activate the new index when the old one was the default.\n-            //Or there wasn't any previous index.\n-            //it must be done on the last round of our loop.\n-            final boolean switchIndex = !incremental && !listIterator.hasNext();\n-            config.setSwitchIndexWhenDone(switchIndex);\n-            publisherAPI.publish(config, status);\n-        }\n+        try {\n \n-        int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n-        for (final BundlerStatus bs : status.getBundlerStatuses()) {\n-            if (bs.getBundlerClass().equals(FileAssetBundler.class.getName())) {\n-                filesCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(URLMapBundler.class.getName())) {\n-                urlmapCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(HTMLPageAsContentBundler.class.getName())) {\n-                pagesCount += bs.getTotal();\n-            }\n-        }\n+                int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n+                for (final BundlerStatus bs : status.getBundlerStatuses()) {\n+                    if (bs.getBundlerClass().equals(FileAssetBundler.class.getName())) {\n+                        filesCount += bs.getTotal();\n+                    } else if (bs.getBundlerClass().equals(URLMapBundler.class.getName())) {\n+                        urlmapCount += bs.getTotal();\n+                    } else if (bs.getBundlerClass()\n+                            .equals(HTMLPageAsContentBundler.class.getName())) {\n+                        pagesCount += bs.getTotal();\n+                    }\n+                }\n \n-        try {\n-            final SiteSearchAudit audit = new SiteSearchAudit();\n-            audit.setPagesCount(pagesCount);\n-            audit.setFilesCount(filesCount);\n-            audit.setUrlmapsCount(urlmapCount);\n-            audit.setAllHosts(indexAll);\n-            audit.setFireDate(jobContext.getFireTime());\n-            audit.setHostList(UtilMethods.join(indexHosts,\",\",true));\n-            audit.setIncremental(incremental);\n-            audit.setStartDate(startDate);\n-            audit.setEndDate(endDate);\n-            audit.setIndexName( UtilMethods.isSet(newIndexName) ? newIndexName :  indexName );\n-            audit.setJobId(jobId);\n-            audit.setJobName(dataMap.getString(QUARTZ_JOB_NAME));\n-            audit.setLangList(UtilMethods.join(languageToIndex,\",\"));\n-            audit.setPath(paths.size() > 0 ? UtilMethods.join(paths,\",\") : \"/*\");\n-            audit.setPathInclude(include);\n-            siteSearchAuditAPI.save(audit);\n-        }\n-        catch(DotDataException ex) {\n-            Logger.error(this, \"can't save audit data\",ex);\n-        }\n-        finally {\n+                final SiteSearchAudit audit = new SiteSearchAudit();\n+                audit.setPagesCount(pagesCount);\n+                audit.setFilesCount(filesCount);\n+                audit.setUrlmapsCount(urlmapCount);\n+                audit.setAllHosts(preparedJobContext.isIndexAll());\n+                audit.setFireDate(jobContext.getFireTime());\n+                audit.setHostList(preparedJobContext.getJoinedHosts());\n+                audit.setIncremental(preparedJobContext.isIncremental());\n+                audit.setStartDate(preparedJobContext.getStartDate());\n+                audit.setEndDate(preparedJobContext.getEndDate());\n+                audit.setIndexName(\n+                        UtilMethods.isSet(preparedJobContext.getNewIndexName()) ? preparedJobContext\n+                                .getNewIndexName() : preparedJobContext.getIndexName());\n+                audit.setJobId(preparedJobContext.getJobId());\n+                audit.setJobName(preparedJobContext.getJobName());\n+                audit.setLangList(preparedJobContext.getLangList());\n+                audit.setPath(preparedJobContext.getPaths());\n+                audit.setPathInclude(preparedJobContext.isPathInclude());\n+                siteSearchAuditAPI.save(audit);\n+\n+\n+        } catch (DotDataException ex) {\n+            Logger.error(this, \"can't save audit data\", ex);\n+        } finally {\n             HibernateUtil.closeSession();\n         }\n-\n         date = DateUtil.getCurrentDate();\n         ActivityLogger.logInfo(getClass(), \"Job Finished\", \"User: \" +userAPI.getSystemUser().getUserId()+ \"; Date: \" + date + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME  );\n         AdminLogger.log(getClass(), \"Job Finished\", \"User: \" +userAPI.getSystemUser().getUserId()+ \"; Date: \" + date + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME );\n     }\n \n+     private synchronized PreparedJobContext prepareJob(final JobExecutionContext jobContext)\n+             throws DotDataException, IOException, DotSecurityException {\n+\n+         final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n+         String jobId = (String) dataMap.get(JOB_ID);\n+         if (jobId == null) {\n+             jobId = dataMap.getString(QUARTZ_JOB_NAME);\n+         }\n+\n+         final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n+         final String[] indexHosts;\n+         final Object obj = (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n+         if (obj instanceof String) {\n+             indexHosts = new String[]{(String) obj};\n+         } else {\n+             indexHosts = (String[]) obj;\n+         }\n+\n+         final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n+\n+         final User userToRun = userAPI.getSystemUser();\n+\n+         final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n+                 .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n+\n+         String path = dataMap.getString(PATHS);\n+         final List<String> paths = new ArrayList<>();\n+         if (path != null) {\n+             path = path.replace(',', '\\r');\n+             path = path.replace('\\n', '\\r');\n+             for (String x : path.split(\"\\r\")) {", "originalCommit": "665016576f43724d2aa070ab028f588ca153dc4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExNDQ4Mg==", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393114482", "bodyText": "and set to final", "author": "jdotcms", "createdAt": "2020-03-16T15:35:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExNDM3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExODYwMg==", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393118602", "bodyText": "legacy code I'd rather not change", "author": "fabrizzio-dotCMS", "createdAt": "2020-03-16T15:41:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzExNDM3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzEyMDc5MQ==", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393120791", "bodyText": "perfect candidate for a builder", "author": "jdotcms", "createdAt": "2020-03-16T15:44:01Z", "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -371,4 +407,106 @@ public boolean isEmpty() {\n         }\n     }\n \n+    static class PreparedJobContext{\n+\n+        private final String indexName;\n+        private final String newIndexName;\n+        private final boolean indexAll;\n+        private final String joinedHosts;\n+        private final boolean incremental;\n+        private final Date startDate;\n+        private final Date endDate;\n+        private final String jobId;\n+        private final String jobName;\n+        private final String langList;\n+        private final String paths;\n+        private final boolean pathInclude;\n+        private final List<SiteSearchConfig> configs;\n+\n+        PreparedJobContext(", "originalCommit": "665016576f43724d2aa070ab028f588ca153dc4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzEyNjA5OA==", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r393126098", "bodyText": "yeah, I thought so too, but I was in a rush refactoring to make this thread-safe.. So at the end, I would end up replacing this call\nreturn new PreparedJobContext(indexName, newIndexName, indexAll, joinedHosts, incremental, startDate, endDate, jobId, jobName, langList, pathsAsString, include, builder.build() ); to the constructor by a builder ??\nSo all I needed was an immutable method to return data. But if you think it is I'll put it in a builder", "author": "fabrizzio-dotCMS", "createdAt": "2020-03-16T15:51:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzEyMDc5MQ=="}], "type": "inlineReview"}, {"oid": "dbee0449e006af7075299e43b7c094e383f6690d", "url": "https://github.com/dotCMS/core/commit/dbee0449e006af7075299e43b7c094e383f6690d", "message": "#17976  feedback", "committedDate": "2020-03-16T15:44:14Z", "type": "commit"}, {"oid": "de21d996220f7296d06472749c355b116fff2693", "url": "https://github.com/dotCMS/core/commit/de21d996220f7296d06472749c355b116fff2693", "message": "#17976 save point", "committedDate": "2020-03-18T17:25:09Z", "type": "commit"}, {"oid": "c24d0bc153ba91945ce03e93354009e02d5fb934", "url": "https://github.com/dotCMS/core/commit/c24d0bc153ba91945ce03e93354009e02d5fb934", "message": "#17976 new unique site-search index name generation strategy", "committedDate": "2020-03-18T22:18:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDY3NDU0MQ==", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r394674541", "bodyText": "Issue found: Substitute calls to size() == 0 (or size() != 0, size() > 0, size() < 1) with calls to isEmpty()", "author": "dev-dotcms", "createdAt": "2020-03-18T22:26:29Z", "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -128,186 +141,246 @@ public void run(final JobExecutionContext jobContext) throws JobExecutionExcepti\n                         + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME);\n \n         HibernateUtil.startTransaction();\n+        try {\n+            final PreparedJobContext preparedJobContext = prepareJob(jobContext);\n+            synchronized (preparedJobContext.lockKey()) {\n+                for (final SiteSearchConfig config : preparedJobContext.getConfigs()) {\n+                    publisherAPI.publish(config, status);\n+                }\n \n-        final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n+                try {\n \n-        String jobId = (String) dataMap.get(JOB_ID);\n-        if (jobId == null) {\n-            jobId = dataMap.getString(QUARTZ_JOB_NAME);\n+                    int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n+                    for (final BundlerStatus bundlerStatus : status.getBundlerStatuses()) {\n+                        if (bundlerStatus.getBundlerClass()\n+                                .equals(FileAssetBundler.class.getName())) {\n+                            filesCount += bundlerStatus.getTotal();\n+                        } else if (bundlerStatus.getBundlerClass()\n+                                .equals(URLMapBundler.class.getName())) {\n+                            urlmapCount += bundlerStatus.getTotal();\n+                        } else if (bundlerStatus.getBundlerClass()\n+                                .equals(HTMLPageAsContentBundler.class.getName())) {\n+                            pagesCount += bundlerStatus.getTotal();\n+                        }\n+                    }\n+\n+                    final SiteSearchAudit audit = new SiteSearchAudit();\n+                    audit.setPagesCount(pagesCount);\n+                    audit.setFilesCount(filesCount);\n+                    audit.setUrlmapsCount(urlmapCount);\n+                    audit.setAllHosts(preparedJobContext.isIndexAll());\n+                    audit.setFireDate(jobContext.getFireTime());\n+                    audit.setHostList(preparedJobContext.getJoinedHosts());\n+                    audit.setIncremental(preparedJobContext.isIncremental());\n+                    audit.setStartDate(preparedJobContext.getStartDate());\n+                    audit.setEndDate(preparedJobContext.getEndDate());\n+                    audit.setIndexName(\n+                            UtilMethods.isSet(preparedJobContext.getNewIndexName())\n+                                    ? preparedJobContext\n+                                    .getNewIndexName() : preparedJobContext.getIndexName());\n+                    audit.setJobId(preparedJobContext.getJobId());\n+                    audit.setJobName(preparedJobContext.getJobName());\n+                    audit.setLangList(preparedJobContext.getLangList());\n+                    audit.setPath(preparedJobContext.getPaths());\n+                    audit.setPathInclude(preparedJobContext.isPathInclude());\n+                    siteSearchAuditAPI.save(audit);\n+\n+                } catch (DotDataException ex) {\n+                    Logger.error(this, \"can't save audit data\", ex);\n+                }\n+            }\n+        } finally {\n+            HibernateUtil.closeSession();\n         }\n+        date = DateUtil.getCurrentDate();\n+        ActivityLogger.logInfo(getClass(), \"Job Finished\",\n+                \"User: \" + userAPI.getSystemUser().getUserId() + \"; Date: \" + date\n+                        + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME);\n+        AdminLogger.log(getClass(), \"Job Finished\",\n+                \"User: \" + userAPI.getSystemUser().getUserId() + \"; Date: \" + date\n+                        + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME);\n+    }\n \n-        final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n-        final String[] indexHosts;\n-        final Object obj = (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n-        if (obj instanceof String) {\n-            indexHosts = new String[]{(String) obj};\n-        } else {\n-            indexHosts = (String[]) obj;\n-        }\n+    private PreparedJobContext prepareJob(final JobExecutionContext jobContext)\n+            throws DotDataException, IOException, DotSecurityException {\n+        synchronized (SiteSearchJobImpl.class) {\n+            final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n+            String jobId = (String) dataMap.get(JOB_ID);\n+            if (jobId == null) {\n+                jobId = dataMap.getString(QUARTZ_JOB_NAME);\n+            }\n \n-        final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n+            final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n+            final String[] indexHosts;\n+            final Object obj =\n+                    (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n+            if (obj instanceof String) {\n+                indexHosts = new String[]{(String) obj};\n+            } else {\n+                indexHosts = (String[]) obj;\n+            }\n \n-        final User userToRun = userAPI.getSystemUser();\n+            final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n \n-        final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n-                .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n+            final User userToRun = userAPI.getSystemUser();\n \n-        String path = dataMap.getString(PATHS);\n-        final List<String> paths = new ArrayList<>();\n-        if (path != null) {\n-            path = path.replace(',', '\\r');\n-            path = path.replace('\\n', '\\r');\n-            for (String x : path.split(\"\\r\")) {\n-                if (UtilMethods.isSet(x)) {\n-                    paths.add(x);\n-                }\n-            }\n-        }\n-        final boolean isRunNowJob = dataMap.getBooleanFromString(RUN_NOW);\n-        // Run now jobs can not get the incremental treatment.\n-        final IndexMetaData indexMetaData = getIndexMetaData(dataMap.getString(INDEX_ALIAS));\n-        final String newIndexName;\n-        final String indexName;\n-\n-        final String jobName = dataMap.getString(QUARTZ_JOB_NAME);\n-        final Date startDate, endDate;\n-        final List<SiteSearchAudit> recentAudits = isRunNowJob ? Collections.emptyList()\n-                : siteSearchAuditAPI.findRecentAudits(jobId, 0, 1);\n-\n-        final boolean incremental = (incrementalParam && !isRunNowJob && !indexMetaData.isNewIndex() && !indexMetaData.isEmpty() && !recentAudits.isEmpty());\n-        //We can only run incrementally if all the above pre-requisites are met.\n-        if (incremental) {\n-            //Incremental mode is useful only if there's already an index previously built.\n-            //Incremental mode also implies that we have to have a date range to work on.\n-            //So if we have an empty index or we lack of audit data we can not run incrementally.\n-            //Even if the user wants to.\n-            newIndexName = null;\n-            endDate = jobContext.getFireTime();\n-            startDate = recentAudits.get(0).getFireDate();\n-            //For incremental jobs, we write the bundle to the same folder every time.\n-            bundleId = StringUtils.camelCaseLower(jobName);\n-            //We'll be working directly into the final index.\n-            indexName = indexMetaData.getIndexName();\n-        } else {\n-            //Set null explicitly just in case\n-            startDate = endDate = null;\n-            // For non-incremental jobs. We create a new folder using a date stamp.\n-            // But even if this run was executed non-incrementally for not having met any of the pre-requisits\n-            // The job originally was meant to run incrementally therefore the results must be stored in the job specific folder.\n-            // So they will still be available in the next round.\n-            bundleId = incrementalParam ? StringUtils.camelCaseLower(jobName) :\n-            // Otherwise it is safe to create a unique time-stamp like folder name.\n-                       UtilMethods.dateToJDBC(new Date()).replace(':', '-').replace(' ', '_');\n-            // We use a new index name only on non-incremental\n-            newIndexName = newIndexName();\n-            final String newAlias = indexMetaData.isNewIndex() ? indexMetaData.getAlias() : null ;\n-            siteSearchAPI.createSiteSearchIndex(newIndexName, newAlias, 1);\n-            // This is the old index we will swap from.\n-            // if it doesnt exist. It doesnt matter here since we will end up with the new one.\n-            indexName = indexMetaData.getIndexName();\n-        }\n+            final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n+                    .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n \n-        Logger.info(SiteSearchJobImpl.class, () -> String\n-                .format(\" Incremental mode [%s]. current index is `%s`. new index is `%s`. bundle id is `%s` \",\n-                        BooleanUtils.toStringYesNo(incremental), indexName ,\n-                        UtilMethods.isSet(newIndexName) ? newIndexName : \"N/A\",\n-                        bundleId));\n-\n-        final List<Host> hosts;\n-        if (indexAll) {\n-            hosts = hostAPI.findAll(userToRun, true);\n-        } else {\n-            hosts = Stream.of(indexHosts).map(h -> {\n-                try {\n-                   return hostAPI.find(h, userToRun, true);\n-                } catch (DotDataException | DotSecurityException e) {\n-                    Logger.error(SiteSearchJobImpl.class, e);\n+            String path = dataMap.getString(PATHS);\n+            final List<String> paths = new ArrayList<>();\n+            if (path != null) {\n+                path = path.replace(',', '\\r');\n+                path = path.replace('\\n', '\\r');\n+                for (String x : path.split(\"\\r\")) {\n+                    if (UtilMethods.isSet(x)) {\n+                        paths.add(x);\n+                    }\n                 }\n-                return null;\n-            }).filter(Objects::nonNull).collect(Collectors.toList());\n-        }\n+            }\n+            final boolean isRunNowJob = dataMap.getBooleanFromString(RUN_NOW);\n+            // Run now jobs can not get the incremental treatment.\n+            final String indexAlias = dataMap.getString(INDEX_ALIAS);\n+            final IndexMetaData indexMetaData = getIndexMetaData(indexAlias);\n+            final String newIndexName;\n+            final String indexName;\n+\n+            final String jobName = dataMap.getString(QUARTZ_JOB_NAME);\n+            final Date startDate, endDate;\n+            final List<SiteSearchAudit> recentAudits = isRunNowJob ? Collections.emptyList()\n+                    : siteSearchAuditAPI.findRecentAudits(jobId, 0, 1);\n+\n+            final boolean incremental = (incrementalParam && !isRunNowJob && !indexMetaData\n+                    .isNewIndex() && !indexMetaData.isEmpty() && !recentAudits.isEmpty());\n+            //We can only run incrementally if all the above pre-requisites are met.\n+            if (incremental) {\n+                //Incremental mode is useful only if there's already an index previously built.\n+                //Incremental mode also implies that we have to have a date range to work on.\n+                //So if we have an empty index or we lack of audit data we can not run incrementally.\n+                //Even if the user wants to.\n+                newIndexName = null;\n+                endDate = jobContext.getFireTime();\n+                startDate = recentAudits.get(0).getFireDate();\n+                //For incremental jobs, we write the bundle to the same folder every time.\n+                bundleId = StringUtils.camelCaseLower(jobName);\n+                //We'll be working directly into the final index.\n+                indexName = indexMetaData.getIndexName();\n+            } else {\n+                //Set null explicitly just in case\n+                startDate = endDate = null;\n+                // For non-incremental jobs. We create a new folder using a date stamp.\n+                // But even if this run was executed non-incrementally for not having met any of the pre-requisits\n+                // The job originally was meant to run incrementally therefore the results must be stored in the job specific folder.\n+                // So they will still be available in the next round.\n+                bundleId = incrementalParam ? StringUtils.camelCaseLower(jobName) :\n+                        // Otherwise it is safe to create a unique  folder name.\n+                        uniqueFolderName();\n+                // We use a new index name only on non-incremental\n+                newIndexName = newIndexName();\n+                final String newAlias =\n+                        indexMetaData.isNewIndex() ? indexMetaData.getAlias() : null;\n+                siteSearchAPI.createSiteSearchIndex(newIndexName, newAlias, 1);\n+                // This is the old index we will swap from.\n+                // if it doesnt exist. It doesnt matter here since we will end up with the new one.\n+                indexName = indexMetaData.getIndexName();\n+            }\n \n-        final List<String> languageToIndex = Arrays.asList((String[])dataMap.get(LANG_TO_INDEX));\n-        final ListIterator<String> listIterator = languageToIndex.listIterator();\n-        while (listIterator.hasNext()) {\n-            final String lang = listIterator.next();\n-            final SiteSearchConfig config = new SiteSearchConfig();\n-            config.setJobId(jobId);\n-            config.setLanguage(Long.parseLong(lang));\n-            config.setJobName(jobName);\n-            config.setHosts(hosts);\n-            config.setNewIndexName(newIndexName);\n-            config.setIndexName(indexName);\n-            config.setId(bundleId);\n-            config.setStartDate(startDate);\n-            config.setEndDate(endDate);\n-            config.setIncremental(incremental);\n-            config.setUser(userToRun);\n-\n-            if(include) {\n-                config.setIncludePatterns(paths);\n+            Logger.info(SiteSearchJobImpl.class, () -> String\n+                    .format(\"Incremental mode [%s]. current index is `%s`. new index is `%s`. alias is `%s`  bundle id is `%s` \",\n+                            BooleanUtils.toStringYesNo(incremental), indexName,\n+                            UtilMethods.isSet(newIndexName) ? newIndexName : \"N/A\",\n+                            indexAlias,\n+                            bundleId)\n+            );\n+\n+            final List<Host> hosts;\n+            if (indexAll) {\n+                hosts = hostAPI.findAll(userToRun, true);\n             } else {\n-                config.setExcludePatterns(paths);\n+                hosts = Stream.of(indexHosts).map(h -> {\n+                    try {\n+                        return hostAPI.find(h, userToRun, true);\n+                    } catch (DotDataException | DotSecurityException e) {\n+                        Logger.error(SiteSearchJobImpl.class, e);\n+                    }\n+                    return null;\n+                }).filter(Objects::nonNull).collect(Collectors.toList());\n             }\n \n-            //We should always replace the index when performing on non-incremental mode.\n-            //That means we drop the old one and re-use the alias.\n-            //But we only activate the new index when the old one was the default.\n-            //Or there wasn't any previous index.\n-            //it must be done on the last round of our loop.\n-            final boolean switchIndex = !incremental && !listIterator.hasNext();\n-            config.setSwitchIndexWhenDone(switchIndex);\n-            publisherAPI.publish(config, status);\n-        }\n+            final Builder<SiteSearchConfig> builder = ImmutableList.builder();\n+\n+            final List<String> languageToIndex = Arrays\n+                    .asList((String[]) dataMap.get(LANG_TO_INDEX));\n+            final ListIterator<String> listIterator = languageToIndex.listIterator();\n+            while (listIterator.hasNext()) {\n+                final String lang = listIterator.next();\n+                final SiteSearchConfig config = new SiteSearchConfig();\n+                config.setJobId(jobId);\n+                config.setLanguage(Long.parseLong(lang));\n+                config.setJobName(jobName);\n+                config.setHosts(hosts);\n+                config.setNewIndexName(newIndexName);\n+                config.setIndexName(indexName);\n+                config.setIndexAlias(indexAlias);\n+                config.setId(bundleId);\n+                config.setStartDate(startDate);\n+                config.setEndDate(endDate);\n+                config.setIncremental(incremental);\n+                config.setUser(userToRun);\n+\n+                if (include) {\n+                    config.setIncludePatterns(paths);\n+                } else {\n+                    config.setExcludePatterns(paths);\n+                }\n \n-        int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n-        for (final BundlerStatus bs : status.getBundlerStatuses()) {\n-            if (bs.getBundlerClass().equals(FileAssetBundler.class.getName())) {\n-                filesCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(URLMapBundler.class.getName())) {\n-                urlmapCount += bs.getTotal();\n-            } else if (bs.getBundlerClass().equals(HTMLPageAsContentBundler.class.getName())) {\n-                pagesCount += bs.getTotal();\n+                //We should always replace the index when performing on non-incremental mode.\n+                //That means we drop the old one and re-use the alias.\n+                //But we only activate the new index when the old one was the default.\n+                //Or there wasn't any previous index.\n+                //it must be done on the last round of our loop.\n+                final boolean switchIndex = !incremental && !listIterator.hasNext();\n+                config.setSwitchIndexWhenDone(switchIndex);\n+                builder.add(config);\n             }\n+            final String joinedHosts = UtilMethods.join(indexHosts, \",\", true);\n+            final String langList = UtilMethods.join(languageToIndex, \",\");\n+            final String pathsAsString = paths.size() > 0 ? UtilMethods.join(paths, \",\") : \"/*\";", "originalCommit": "c24d0bc153ba91945ce03e93354009e02d5fb934", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDY3NDU0NQ==", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r394674545", "bodyText": "Issue found: Useless parentheses.", "author": "dev-dotcms", "createdAt": "2020-03-18T22:26:30Z", "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -128,186 +141,246 @@ public void run(final JobExecutionContext jobContext) throws JobExecutionExcepti\n                         + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME);\n \n         HibernateUtil.startTransaction();\n+        try {\n+            final PreparedJobContext preparedJobContext = prepareJob(jobContext);\n+            synchronized (preparedJobContext.lockKey()) {\n+                for (final SiteSearchConfig config : preparedJobContext.getConfigs()) {\n+                    publisherAPI.publish(config, status);\n+                }\n \n-        final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n+                try {\n \n-        String jobId = (String) dataMap.get(JOB_ID);\n-        if (jobId == null) {\n-            jobId = dataMap.getString(QUARTZ_JOB_NAME);\n+                    int filesCount = 0, pagesCount = 0, urlmapCount = 0;\n+                    for (final BundlerStatus bundlerStatus : status.getBundlerStatuses()) {\n+                        if (bundlerStatus.getBundlerClass()\n+                                .equals(FileAssetBundler.class.getName())) {\n+                            filesCount += bundlerStatus.getTotal();\n+                        } else if (bundlerStatus.getBundlerClass()\n+                                .equals(URLMapBundler.class.getName())) {\n+                            urlmapCount += bundlerStatus.getTotal();\n+                        } else if (bundlerStatus.getBundlerClass()\n+                                .equals(HTMLPageAsContentBundler.class.getName())) {\n+                            pagesCount += bundlerStatus.getTotal();\n+                        }\n+                    }\n+\n+                    final SiteSearchAudit audit = new SiteSearchAudit();\n+                    audit.setPagesCount(pagesCount);\n+                    audit.setFilesCount(filesCount);\n+                    audit.setUrlmapsCount(urlmapCount);\n+                    audit.setAllHosts(preparedJobContext.isIndexAll());\n+                    audit.setFireDate(jobContext.getFireTime());\n+                    audit.setHostList(preparedJobContext.getJoinedHosts());\n+                    audit.setIncremental(preparedJobContext.isIncremental());\n+                    audit.setStartDate(preparedJobContext.getStartDate());\n+                    audit.setEndDate(preparedJobContext.getEndDate());\n+                    audit.setIndexName(\n+                            UtilMethods.isSet(preparedJobContext.getNewIndexName())\n+                                    ? preparedJobContext\n+                                    .getNewIndexName() : preparedJobContext.getIndexName());\n+                    audit.setJobId(preparedJobContext.getJobId());\n+                    audit.setJobName(preparedJobContext.getJobName());\n+                    audit.setLangList(preparedJobContext.getLangList());\n+                    audit.setPath(preparedJobContext.getPaths());\n+                    audit.setPathInclude(preparedJobContext.isPathInclude());\n+                    siteSearchAuditAPI.save(audit);\n+\n+                } catch (DotDataException ex) {\n+                    Logger.error(this, \"can't save audit data\", ex);\n+                }\n+            }\n+        } finally {\n+            HibernateUtil.closeSession();\n         }\n+        date = DateUtil.getCurrentDate();\n+        ActivityLogger.logInfo(getClass(), \"Job Finished\",\n+                \"User: \" + userAPI.getSystemUser().getUserId() + \"; Date: \" + date\n+                        + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME);\n+        AdminLogger.log(getClass(), \"Job Finished\",\n+                \"User: \" + userAPI.getSystemUser().getUserId() + \"; Date: \" + date\n+                        + \"; Job Identifier: \" + SiteSearchAPI.ES_SITE_SEARCH_NAME);\n+    }\n \n-        final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n-        final String[] indexHosts;\n-        final Object obj = (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n-        if (obj instanceof String) {\n-            indexHosts = new String[]{(String) obj};\n-        } else {\n-            indexHosts = (String[]) obj;\n-        }\n+    private PreparedJobContext prepareJob(final JobExecutionContext jobContext)\n+            throws DotDataException, IOException, DotSecurityException {\n+        synchronized (SiteSearchJobImpl.class) {\n+            final JobDataMap dataMap = jobContext.getJobDetail().getJobDataMap();\n+            String jobId = (String) dataMap.get(JOB_ID);\n+            if (jobId == null) {\n+                jobId = dataMap.getString(QUARTZ_JOB_NAME);\n+            }\n \n-        final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n+            final boolean indexAll = UtilMethods.isSet((String) dataMap.get(INDEX_ALL));\n+            final String[] indexHosts;\n+            final Object obj =\n+                    (dataMap.get(INDEX_HOST) != null) ? dataMap.get(INDEX_HOST) : new String[0];\n+            if (obj instanceof String) {\n+                indexHosts = new String[]{(String) obj};\n+            } else {\n+                indexHosts = (String[]) obj;\n+            }\n \n-        final User userToRun = userAPI.getSystemUser();\n+            final boolean incrementalParam = dataMap.getBooleanFromString(INCREMENTAL);\n \n-        final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n-                .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n+            final User userToRun = userAPI.getSystemUser();\n \n-        String path = dataMap.getString(PATHS);\n-        final List<String> paths = new ArrayList<>();\n-        if (path != null) {\n-            path = path.replace(',', '\\r');\n-            path = path.replace('\\n', '\\r');\n-            for (String x : path.split(\"\\r\")) {\n-                if (UtilMethods.isSet(x)) {\n-                    paths.add(x);\n-                }\n-            }\n-        }\n-        final boolean isRunNowJob = dataMap.getBooleanFromString(RUN_NOW);\n-        // Run now jobs can not get the incremental treatment.\n-        final IndexMetaData indexMetaData = getIndexMetaData(dataMap.getString(INDEX_ALIAS));\n-        final String newIndexName;\n-        final String indexName;\n-\n-        final String jobName = dataMap.getString(QUARTZ_JOB_NAME);\n-        final Date startDate, endDate;\n-        final List<SiteSearchAudit> recentAudits = isRunNowJob ? Collections.emptyList()\n-                : siteSearchAuditAPI.findRecentAudits(jobId, 0, 1);\n-\n-        final boolean incremental = (incrementalParam && !isRunNowJob && !indexMetaData.isNewIndex() && !indexMetaData.isEmpty() && !recentAudits.isEmpty());\n-        //We can only run incrementally if all the above pre-requisites are met.\n-        if (incremental) {\n-            //Incremental mode is useful only if there's already an index previously built.\n-            //Incremental mode also implies that we have to have a date range to work on.\n-            //So if we have an empty index or we lack of audit data we can not run incrementally.\n-            //Even if the user wants to.\n-            newIndexName = null;\n-            endDate = jobContext.getFireTime();\n-            startDate = recentAudits.get(0).getFireDate();\n-            //For incremental jobs, we write the bundle to the same folder every time.\n-            bundleId = StringUtils.camelCaseLower(jobName);\n-            //We'll be working directly into the final index.\n-            indexName = indexMetaData.getIndexName();\n-        } else {\n-            //Set null explicitly just in case\n-            startDate = endDate = null;\n-            // For non-incremental jobs. We create a new folder using a date stamp.\n-            // But even if this run was executed non-incrementally for not having met any of the pre-requisits\n-            // The job originally was meant to run incrementally therefore the results must be stored in the job specific folder.\n-            // So they will still be available in the next round.\n-            bundleId = incrementalParam ? StringUtils.camelCaseLower(jobName) :\n-            // Otherwise it is safe to create a unique time-stamp like folder name.\n-                       UtilMethods.dateToJDBC(new Date()).replace(':', '-').replace(' ', '_');\n-            // We use a new index name only on non-incremental\n-            newIndexName = newIndexName();\n-            final String newAlias = indexMetaData.isNewIndex() ? indexMetaData.getAlias() : null ;\n-            siteSearchAPI.createSiteSearchIndex(newIndexName, newAlias, 1);\n-            // This is the old index we will swap from.\n-            // if it doesnt exist. It doesnt matter here since we will end up with the new one.\n-            indexName = indexMetaData.getIndexName();\n-        }\n+            final boolean include = (\"all\".equals(dataMap.getString(INCLUDE_EXCLUDE)) || INCLUDE\n+                    .equals(dataMap.getString(INCLUDE_EXCLUDE)));\n \n-        Logger.info(SiteSearchJobImpl.class, () -> String\n-                .format(\" Incremental mode [%s]. current index is `%s`. new index is `%s`. bundle id is `%s` \",\n-                        BooleanUtils.toStringYesNo(incremental), indexName ,\n-                        UtilMethods.isSet(newIndexName) ? newIndexName : \"N/A\",\n-                        bundleId));\n-\n-        final List<Host> hosts;\n-        if (indexAll) {\n-            hosts = hostAPI.findAll(userToRun, true);\n-        } else {\n-            hosts = Stream.of(indexHosts).map(h -> {\n-                try {\n-                   return hostAPI.find(h, userToRun, true);\n-                } catch (DotDataException | DotSecurityException e) {\n-                    Logger.error(SiteSearchJobImpl.class, e);\n+            String path = dataMap.getString(PATHS);\n+            final List<String> paths = new ArrayList<>();\n+            if (path != null) {\n+                path = path.replace(',', '\\r');\n+                path = path.replace('\\n', '\\r');\n+                for (String x : path.split(\"\\r\")) {\n+                    if (UtilMethods.isSet(x)) {\n+                        paths.add(x);\n+                    }\n                 }\n-                return null;\n-            }).filter(Objects::nonNull).collect(Collectors.toList());\n-        }\n+            }\n+            final boolean isRunNowJob = dataMap.getBooleanFromString(RUN_NOW);\n+            // Run now jobs can not get the incremental treatment.\n+            final String indexAlias = dataMap.getString(INDEX_ALIAS);\n+            final IndexMetaData indexMetaData = getIndexMetaData(indexAlias);\n+            final String newIndexName;\n+            final String indexName;\n+\n+            final String jobName = dataMap.getString(QUARTZ_JOB_NAME);\n+            final Date startDate, endDate;\n+            final List<SiteSearchAudit> recentAudits = isRunNowJob ? Collections.emptyList()\n+                    : siteSearchAuditAPI.findRecentAudits(jobId, 0, 1);\n+\n+            final boolean incremental = (incrementalParam && !isRunNowJob && !indexMetaData", "originalCommit": "c24d0bc153ba91945ce03e93354009e02d5fb934", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDY3NDU1Mg==", "url": "https://github.com/dotCMS/core/pull/18141#discussion_r394674552", "bodyText": "Issue found: Useless parentheses.", "author": "dev-dotcms", "createdAt": "2020-03-18T22:26:31Z", "path": "dotCMS/src/main/java/com/dotcms/publishing/job/SiteSearchJobImpl.java", "diffHunk": "@@ -371,4 +444,106 @@ public boolean isEmpty() {\n         }\n     }\n \n+    static class PreparedJobContext{\n+\n+        private final String indexName;\n+        private final String newIndexName;\n+        private final boolean indexAll;\n+        private final String joinedHosts;\n+        private final boolean incremental;\n+        private final Date startDate;\n+        private final Date endDate;\n+        private final String jobId;\n+        private final String jobName;\n+        private final String langList;\n+        private final String paths;\n+        private final boolean pathInclude;\n+        private final List<SiteSearchConfig> configs;\n+\n+        PreparedJobContext(\n+                final String indexName,\n+                final String newIndexName,\n+                final boolean indexAll,\n+                final String joinedHosts,\n+                final boolean incremental,\n+                final Date startDate,\n+                final Date endDate,\n+                final String jobId,\n+                final String jobName,\n+                final String langList,\n+                final String paths,\n+                final boolean pathInclude,\n+                final List<SiteSearchConfig> configs) {\n+            this.indexName = indexName;\n+            this.newIndexName = newIndexName;\n+            this.indexAll = indexAll;\n+            this.joinedHosts = joinedHosts;\n+            this.incremental = incremental;\n+            this.startDate = startDate;\n+            this.endDate = endDate;\n+            this.jobId = jobId;\n+            this.jobName = jobName;\n+            this.langList = langList;\n+            this.configs = configs;\n+            this.pathInclude = pathInclude;\n+            this.paths = paths;\n+        }\n+\n+        String getIndexName() {\n+            return indexName;\n+        }\n+\n+        List<SiteSearchConfig> getConfigs() {\n+            return configs;\n+        }\n+\n+        String getNewIndexName() {\n+            return newIndexName;\n+        }\n+\n+        boolean isIndexAll() {\n+            return indexAll;\n+        }\n+\n+        String getJoinedHosts() {\n+            return joinedHosts;\n+        }\n+\n+        boolean isIncremental() {\n+            return incremental;\n+        }\n+\n+        Date getStartDate() {\n+            return startDate;\n+        }\n+\n+        Date getEndDate() {\n+            return endDate;\n+        }\n+\n+        String getJobId() {\n+            return jobId;\n+        }\n+\n+        String getJobName() {\n+            return jobName;\n+        }\n+\n+        String getLangList() {\n+            return langList;\n+        }\n+\n+        public String getPaths() {\n+            return paths;\n+        }\n+\n+        boolean isPathInclude() {\n+            return pathInclude;\n+        }\n+\n+        String lockKey(){\n+           return ( UtilMethods.isSet(indexName) ? indexName  : newIndexName );", "originalCommit": "c24d0bc153ba91945ce03e93354009e02d5fb934", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}