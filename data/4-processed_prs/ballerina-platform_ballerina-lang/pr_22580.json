{"pr_number": 22580, "pr_title": "Fix API docs in module Kafka", "pr_createdAt": "2020-04-10T10:50:05Z", "pr_url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580", "timeline": [{"oid": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "url": "https://github.com/ballerina-platform/ballerina-lang/commit/b06faff2e26df2b7f459e50adc977b8fed7c72e5", "message": "Fix API docs in module Kafka", "committedDate": "2020-04-10T10:49:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1MzYxMg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406753612", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n          \n          \n            \n                # + return - <span class=\"x x-first x-last\">`kafka:ConsumerError</span>` if an error is encountered while starting the server<span class=\"x x-first x-last\"> or else nil</span>", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:19:04Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1MTM1MQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407851351", "bodyText": "Fixed in all places.", "author": "aashikam", "createdAt": "2020-04-14T03:54:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1MzYxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1MzgxMg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406753812", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered during the listener stopping process\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered during the listener stopping process or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:19:37Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n     public function __start() returns error? {\n         return start(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1MzkyOQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406753929", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered during the listener stopping process\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered during the listener stopping process or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:19:57Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n     public function __start() returns error? {\n         return start(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __gracefulStop() returns error? {\n         return stop(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NDE5Ng==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406754196", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered while attaching the service, returns nil otherwise\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered while attaching the service or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:20:39Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n     public function __start() returns error? {\n         return start(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __gracefulStop() returns error? {\n         return stop(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __immediateStop() returns error? {\n         return stop(self);\n     }\n \n-    # Gets called every time a service attaches itself to this listener.\n+    # Gets called every time a service attaches itself to the listener.\n     #\n-    # + s - The type of the service to be registered.\n-    # + name - Name of the service.\n-    # + return - An `error` if encounters an error while attaching the service, returns nil otherwise.\n+    # + s - The service to be attached\n+    # + name - Name of the service\n+    # + return - An `error` if an error is encountered while attaching the service, returns nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NDMzOQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406754339", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - An `error` if an error is encountered while detaching a service or nil\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered while detaching a service or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:21:03Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -207,40 +205,40 @@ public type Consumer client object {\n         checkpanic self.init(config);\n     }\n \n-    # Starts the registered service.\n+    # Starts the registered services.\n     #\n-    # + return - An `error` if encounters an error while starting the server, returns nil otherwise.\n+    # + return - An `error` if an error is encountered while starting the server, returns nil otherwise\n     public function __start() returns error? {\n         return start(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __gracefulStop() returns error? {\n         return stop(self);\n     }\n \n     # Stops the kafka listener.\n     #\n-    # + return - An `error` if an error occurred during the listener stopping process\n+    # + return - An `error` if an error is encountered during the listener stopping process\n     public function __immediateStop() returns error? {\n         return stop(self);\n     }\n \n-    # Gets called every time a service attaches itself to this listener.\n+    # Gets called every time a service attaches itself to the listener.\n     #\n-    # + s - The type of the service to be registered.\n-    # + name - Name of the service.\n-    # + return - An `error` if encounters an error while attaching the service, returns nil otherwise.\n+    # + s - The service to be attached\n+    # + name - Name of the service\n+    # + return - An `error` if an error is encountered while attaching the service, returns nil otherwise\n     public function __attach(service s, string? name = ()) returns error? {\n         return register(self, s, name);\n     }\n \n     # Detaches a consumer service from the listener.\n     #\n     # + s - The service to be detached\n-    # + return - An `error` if an error occurred during detaching a service or `nil`\n+    # + return - An `error` if an error is encountered while detaching a service or nil", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NDQ2OA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406754468", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\">, returns nil otherwise</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\"> or else nil</span>", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:21:24Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -256,23 +254,29 @@ public type Consumer client object {\n \n     # Assigns consumer to a set of topic partitions.\n     #\n-    # + partitions - Topic partitions to be assigned.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Topic partitions to be assigned\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NDYxNA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406754614", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\">, returns nil otherwise</span>\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\"> or else nil</span>", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:21:47Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -256,23 +254,29 @@ public type Consumer client object {\n \n     # Assigns consumer to a set of topic partitions.\n     #\n-    # + partitions - Topic partitions to be assigned.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Topic partitions to be assigned\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function assign(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerAssign(self, partitions);\n     }\n \n-    # Closes consumer connection to the external Kafka broker.\n-    #\n-    # + duration - Timeout duration for the close operation execution.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Closes consumer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->close();\n+# ```\n+#\n+# + duration - Timeout duration for the close operation execution\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1MjMxMA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407852310", "bodyText": "Fixed in all places", "author": "aashikam", "createdAt": "2020-04-14T03:58:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NDYxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTIwNA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755204", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\">, returns nil otherwise</span>\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\"> or else nil</span>", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:23:32Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -256,23 +254,29 @@ public type Consumer client object {\n \n     # Assigns consumer to a set of topic partitions.\n     #\n-    # + partitions - Topic partitions to be assigned.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Topic partitions to be assigned\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function assign(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerAssign(self, partitions);\n     }\n \n-    # Closes consumer connection to the external Kafka broker.\n-    #\n-    # + duration - Timeout duration for the close operation execution.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Closes consumer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->close();\n+# ```\n+#\n+# + duration - Timeout duration for the close operation execution\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function close(public int duration = -1) returns ConsumerError? {\n         return consumerClose(self, duration);\n     }\n \n-    # Commits current consumed offsets for consumer.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Commits current consumed offsets for consumer.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->commit();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTI5OQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755299", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\">, returns nil otherwise.</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\"> or else nil</span>", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:23:44Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTM2MQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755361", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\">, returns nil otherwise</span>\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered<span class=\"x x-first x-last\"> or else nil</span>", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:23:53Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTUzMA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755530", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of assigned partitions for the consumer if executes successfully<span class=\"x x-first x-last\">, </span>`kafka:ConsumerError`<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n            # + return - Array of assigned partitions for the consumer if executes successfully<span class=\"x x-first x-last\">  or else </span>`kafka:ConsumerError`", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:24:17Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTkyNg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406755926", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #            `kafka:ConsumerError`<span class=\"x x-first x-last\"> if the operation fails</span>\n          \n          \n            \n            #            `kafka:ConsumerError`", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:25:25Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1Mjc1OQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407852759", "bodyText": "Fixed in all places", "author": "aashikam", "createdAt": "2020-04-14T04:00:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NTkyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjA0NQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756045", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n          \n          \n            \n                #            operation fails\n          \n          \n            \n                # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError`", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:25:42Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjA5Mg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756092", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - Committed offset for the consumer for the given partition if executes successfully or else\n          \n          \n            \n                #            `kafka:ConsumerError`<span class=\"x x-first x-last\"> if the operation fails</span>\n          \n          \n            \n                # + return - Committed offset for the consumer for the given partition if executes successfully or else\n          \n          \n            \n                #            `kafka:ConsumerError`", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:25:51Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjE3OQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756179", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n          \n          \n            \n                #            operation fails\n          \n          \n            \n                # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError`", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:26:07Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjI0MQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756241", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n          \n          \n            \n            #           `kafka:ConsumerError`<span class=\"x x-first x-last\"> if the operation fails</span>\n          \n          \n            \n            # + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n          \n          \n            \n            #           `kafka:ConsumerError`", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:26:18Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjMzMw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756333", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n          \n          \n            \n                #            the operation fails\n          \n          \n            \n                # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError`", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:26:35Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjQxOQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756419", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n          \n          \n            \n            #            the operation fails\n          \n          \n            \n            # + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError`", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:26:47Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NjUwMQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406756501", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n          \n          \n            \n            #            operation fails\n          \n          \n            \n            # + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError`", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:26:58Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1OTc2NA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406759764", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n          \n          \n            \n            #            operation fails\n          \n          \n            \n            # + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError`", "author": "ThisaruGuruge", "createdAt": "2020-04-10T13:34:49Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3MzQwNQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406773405", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:08:03Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3MzUwOQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406773509", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n          \n          \n            \n            #            fails\n          \n          \n            \n            # + return - Array of consumer records if executed successfully or else `kafka:ConsumerError`", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:08:19Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3Mzc3NQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406773775", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:08:53Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3MzgyNg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406773826", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:09:02Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDA1OA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774058", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + offset - The `PartitionOffset` to seek\n          \n          \n            \n                # + offset - The `<span class=\"x x-first x-last\">kafka:</span>PartitionOffset` to seek", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:09:37Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDM3OA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774378", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:10:19Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDQzNQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774435", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:10:28Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDUyMg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774522", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:10:42Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToEnd(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToEnd(self, partitions);\n     }\n \n-    # Subscribes the consumer to the provided set of topics.\n-    #\n-    # + topics - Array of topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the provided set of topics.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribe([\"kafka-topic-1\", \"kafka-topic-2\"]);\n+# ```\n+#\n+# + topics - Array of topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDY0Ng==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774646", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:11:00Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToEnd(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToEnd(self, partitions);\n     }\n \n-    # Subscribes the consumer to the provided set of topics.\n-    #\n-    # + topics - Array of topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the provided set of topics.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribe([\"kafka-topic-1\", \"kafka-topic-2\"]);\n+# ```\n+#\n+# + topics - Array of topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribe(string[] topics) returns ConsumerError? {\n         return consumerSubscribe(self, topics);\n     }\n \n-    # Subscribes the consumer to the topics which matches to the provided pattern.\n-    #\n-    # + regex - Pattern which should be matched with the topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the topics which matches to the provided pattern.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribeToPattern(\"kafka.*\");\n+# ```\n+#\n+# + regex - Pattern which should be matched with the topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDg4MA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774880", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ConsumerError` if an error is encountered or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:11:33Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToEnd(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToEnd(self, partitions);\n     }\n \n-    # Subscribes the consumer to the provided set of topics.\n-    #\n-    # + topics - Array of topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the provided set of topics.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribe([\"kafka-topic-1\", \"kafka-topic-2\"]);\n+# ```\n+#\n+# + topics - Array of topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribe(string[] topics) returns ConsumerError? {\n         return consumerSubscribe(self, topics);\n     }\n \n-    # Subscribes the consumer to the topics which matches to the provided pattern.\n-    #\n-    # + regex - Pattern which should be matched with the topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the topics which matches to the provided pattern.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribeToPattern(\"kafka.*\");\n+# ```\n+#\n+# + regex - Pattern which should be matched with the topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribeToPattern(string regex) returns ConsumerError? {\n         return consumerSubscribeToPattern(self, java:fromString(regex));\n     }\n \n-    # Subscribes to consumer to the provided set of topics with rebalance listening is enabled.\n+    # Subscribes to the provided set of topics with rebalance listening enabled.\n     # This function can be used inside a service, to subscribe to a set of topics, while rebalancing the patition\n     # assignment of the consumers.\n     #\n-    # + topics - Array of topics to be subscribed.\n-    # + onPartitionsRevoked - Function which will be executed if partitions are revoked from this consumer.\n-    # + onPartitionsAssigned - Function which will be executed if partitions are assigned this consumer.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + topics - Array of topics to be subscribed to\n+    # + onPartitionsRevoked - Function which will be executed if partitions are revoked from this consumer\n+    # + onPartitionsAssigned - Function which will be executed if partitions are assigned this consumer\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NDk0OA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406774948", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n            # + return - `kafka:ConsumerError` if an error is encountered or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:11:43Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/consumer.bal", "diffHunk": "@@ -281,179 +285,218 @@ public type Consumer client object {\n     #\n     # + duration - Timeout duration for the commit operation execution.\n     # + offsets - Offsets to be commited.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise.\n     public remote function commitOffset(PartitionOffset[] offsets, public int duration = -1) returns ConsumerError? {\n         return consumerCommitOffset(self, offsets, duration);\n     }\n \n-    # Connects consumer to the provided host in the consumer configs.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Connects consumer to the provided host in the consumer configs.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->connect();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered, returns nil otherwise\n     public remote function connect() returns ConsumerError? {\n         return consumerConnect(self);\n     }\n \n-    # Returns the currently assigned partitions for the consumer.\n-    #\n-    # + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise.\n+# Retrieves the currently assigned partitions for the consumer.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getAssignment();\n+# ```\n+#\n+# + return - Array of assigned partitions for the consumer if executes successfully, `kafka:ConsumerError` otherwise\n     public remote function getAssignment() returns TopicPartition[]|ConsumerError {\n         return consumerGetAssignment(self);\n     }\n \n-    # Returns the available list of topics for a particular consumer.\n-    #\n-    # + duration - Timeout duration for the get available topics execution.\n-    # + return - Array of topics currently available (authorized) for the consumer to subscribe, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the available list of topics for a particular consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getAvailableTopics();\n+# ```\n+#\n+# + duration - Timeout duration for the get available topics execution\n+# + return - Array of topics currently available (authorized) for the consumer to subscribe or else\n+#           `kafka:ConsumerError` if the operation fails\n     public remote function getAvailableTopics(public int duration = -1) returns string[]|ConsumerError {\n         return consumerGetAvailableTopics(self, duration);\n     }\n \n-    # Returns start offsets for given set of partitions.\n+    # Retrieves the start offsets for given set of partitions.\n     #\n-    # + partitions - Array of topic partitions to get the starting offsets.\n-    # + duration - Timeout duration for the get beginning offsets execution.\n-    # + return - Starting offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Array of topic partitions to get the starting offsets\n+    # + duration - Timeout duration for the get beginning offsets execution\n+    # + return - Starting offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getBeginningOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetBeginningOffsets(self, partitions, duration);\n     }\n \n-    # Returns last committed offsets for the given topic partitions.\n+    # Retrieves the last committed offsets for the given topic partitions.\n     #\n-    # + partition - Topic partition in which the committed offset is returned for consumer.\n-    # + duration - Timeout duration for the get committed offset operation to execute.\n-    # + return - Committed offset for the consumer for the given partition if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the committed offset is returned for consumer\n+    # + duration - Timeout duration for the get committed offset operation to execute\n+    # + return - Committed offset for the consumer for the given partition if executes successfully or else\n+    #            `kafka:ConsumerError` if the operation fails\n     public remote function getCommittedOffset(TopicPartition partition, public int duration = -1)\n     returns PartitionOffset|ConsumerError {\n         return consumerGetCommittedOffset(self, partition, duration);\n     }\n \n-    # Returns last offsets for given set of partitions.\n+    # Retrieves the last offsets for given set of partitions.\n     #\n-    # + partitions - Set of partitions to get the last offsets.\n-    # + duration - Timeout duration for the get end offsets operation to execute.\n-    # + return - End offsets for the given partitions if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+    # + partitions - Set of partitions to get the last offsets\n+    # + duration - Timeout duration for the get end offsets operation to execute\n+    # + return - End offsets for the given partitions if executes successfully or else `kafka:ConsumerError` if the\n+    #            operation fails\n     public remote function getEndOffsets(TopicPartition[] partitions, public int duration = -1)\n     returns PartitionOffset[]|ConsumerError {\n         return consumerGetEndOffsets(self, partitions, duration);\n     }\n \n-    # Returns the partitions, which are currently paused.\n-    #\n-    # + return - Set of partitions paused from message retrieval if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the partitions, which are currently paused.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getPausedPartitions();\n+# ```\n+#\n+# + return - Set of partitions paused from message retrieval if executes successfully or else\n+#            `kafka:ConsumerError` if the operation fails\n     public remote function getPausedPartitions() returns TopicPartition[]|ConsumerError {\n         return consumerGetPausedPartitions(self);\n     }\n \n-    # Returns the offset of the next record that will be fetched, if a records exists in that position.\n+    # Retrieves the offset of the next record that will be fetched, if a records exists in that position.\n     #\n-    # + partition - Topic partition in which the position is required.\n-    # + duration - Timeout duration for the get position offset operation to execute.\n-    # + return - Offset which will be fetched next (if a records exists in that offset), returns `kafka:ConsumerError` if the operation fails.\n+    # + partition - The `TopicPartition` in which the position is required\n+    # + duration - Timeout duration for the get position offset operation to execute\n+    # + return - Offset which will be fetched next (if a records exists in that offset) or else `kafka:ConsumerError` if\n+    #            the operation fails\n     public remote function getPositionOffset(TopicPartition partition, public int duration = -1)\n     returns int|ConsumerError {\n         return consumerGetPositionOffset(self, partition, duration);\n     }\n \n-    # Returns set of topics which are currently subscribed by the consumer.\n-    #\n-    # + return - Array of subscribed topics for the consumer if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of topics which are currently subscribed by the consumer.\n+# ```ballerina\n+# string[]|kafka:ConsumerError result = consumer->getSubscription();\n+# ```\n+#\n+# + return - Array of subscribed topics for the consumer if executes successfully or else `kafka:ConsumerError` if\n+#            the operation fails\n     public remote function getSubscription() returns string[]|ConsumerError {\n         return consumerGetSubscription(self);\n     }\n \n-    # Retrieve the set of partitions in which the topic belongs.\n-    #\n-    # + topic - Given topic for partition information is needed.\n-    # + duration - Timeout duration for the get topic partitions operation to execute.\n-    # + return - Array of partitions for the given topic if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Retrieves the set of partitions in which the topic belongs to.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ConsumerError result = consumer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - The topic for which the partition information is needed\n+# + duration - Timeout duration for the get topic partitions operation to execute\n+# + return - Array of partitions for the given topic if executes successfully or else `kafka:ConsumerError` if the\n+#            operation fails\n     public remote function getTopicPartitions(string topic, public int duration = -1)\n     returns TopicPartition[]|ConsumerError {\n         return consumerGetTopicPartitions(self, java:fromString(topic), duration);\n     }\n \n-    # Pause consumer retrieving messages from set of partitions.\n+    # Pauses retrieving messages from a set of partitions.\n     #\n-    # + partitions - Set of partitions to pause the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to pause the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function pause(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerPause(self, partitions);\n     }\n \n-    # Poll the consumer for external broker for records.\n-    #\n-    # + timeoutValue - Polling time in milliseconds.\n-    # + return - Array of consumer records if executes successfully, returns `kafka:ConsumerError` if the operation fails.\n+# Polls the consumer for external broker for records.\n+# ```ballerina\n+# kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+# ```\n+#\n+# + timeoutValue - Polling time in milliseconds\n+# + return - Array of consumer records if executed successfully or else `kafka:ConsumerError` if the operation\n+#            fails\n     public remote function poll(int timeoutValue) returns ConsumerRecord[]|ConsumerError {\n         return consumerPoll(self, timeoutValue);\n     }\n \n-    # Resume consumer retrieving messages from set of partitions which were paused earlier.\n+    # Resumes consumer retrieving messages from set of partitions which were paused earlier.\n     #\n-    # + partitions - Set of partitions to resume the retrieval of messages.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - Partitions to resume the retrieval of messages\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function resume(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerResume(self, partitions);\n     }\n \n-    # Seek for a given offset in a topic partition.\n+    # Seeks for a given offset in a topic partition.\n     #\n-    # + offset - PartitionOffset to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + offset - The `PartitionOffset` to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seek(PartitionOffset offset) returns ConsumerError? {\n         return consumerSeek(self, offset);\n     }\n \n-    # Seek the beginning of the offsets for the given set of topic partitions.\n+    # Seeks the beginning of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToBeginning(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToBeginning(self, partitions);\n     }\n \n-    # Seek end of the offsets for the given set of topic partitions.\n+    # Seeks end of the offsets for the given set of topic partitions.\n     #\n-    # + partitions - Set of topic partitions to seek.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + partitions - The set of topic partitions to seek\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function seekToEnd(TopicPartition[] partitions) returns ConsumerError? {\n         return consumerSeekToEnd(self, partitions);\n     }\n \n-    # Subscribes the consumer to the provided set of topics.\n-    #\n-    # + topics - Array of topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the provided set of topics.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribe([\"kafka-topic-1\", \"kafka-topic-2\"]);\n+# ```\n+#\n+# + topics - Array of topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribe(string[] topics) returns ConsumerError? {\n         return consumerSubscribe(self, topics);\n     }\n \n-    # Subscribes the consumer to the topics which matches to the provided pattern.\n-    #\n-    # + regex - Pattern which should be matched with the topics to be subscribed.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Subscribes the consumer to the topics which matches to the provided pattern.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->subscribeToPattern(\"kafka.*\");\n+# ```\n+#\n+# + regex - Pattern which should be matched with the topics to be subscribed to\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribeToPattern(string regex) returns ConsumerError? {\n         return consumerSubscribeToPattern(self, java:fromString(regex));\n     }\n \n-    # Subscribes to consumer to the provided set of topics with rebalance listening is enabled.\n+    # Subscribes to the provided set of topics with rebalance listening enabled.\n     # This function can be used inside a service, to subscribe to a set of topics, while rebalancing the patition\n     # assignment of the consumers.\n     #\n-    # + topics - Array of topics to be subscribed.\n-    # + onPartitionsRevoked - Function which will be executed if partitions are revoked from this consumer.\n-    # + onPartitionsAssigned - Function which will be executed if partitions are assigned this consumer.\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+    # + topics - Array of topics to be subscribed to\n+    # + onPartitionsRevoked - Function which will be executed if partitions are revoked from this consumer\n+    # + onPartitionsAssigned - Function which will be executed if partitions are assigned this consumer\n+    # + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise\n     public remote function subscribeWithPartitionRebalance(string[] topics,\n         function(Consumer consumer, TopicPartition[] partitions) onPartitionsRevoked,\n         function(Consumer consumer, TopicPartition[] partitions) onPartitionsAssigned)\n     returns ConsumerError? {\n         return consumerSubscribeWithPartitionRebalance(self, topics, onPartitionsRevoked, onPartitionsAssigned);\n     }\n \n-    # Unsubscribe the consumer from all the topic subscriptions.\n-    #\n-    # + return - `kafka:ConsumerError` if encounters an error, returns nil otherwise.\n+# Unsubscribes from all the topic subscriptions.\n+# ```ballerina\n+# kafka:ConsumerError? result = consumer->unsubscribe();\n+# ```\n+#\n+# + return - `kafka:ConsumerError` if an error is encountered or else nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjAxMA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776010", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Commits <span class=\"x x-first x-last\">consumer </span>consumed <span class=\"x x-first x-last\">offsets to offset topic</span>.\n          \n          \n            \n                # Commits <span class=\"x x-first x-last\">the offsets </span>consumed <span class=\"x x-first x-last\">by the provided consumer</span>.", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:14:07Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1Mzc4Ng==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407853786", "bodyText": "Fixed", "author": "aashikam", "createdAt": "2020-04-14T04:04:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjAxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjEwMg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776102", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ProducerError` if committing the consumer failed or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ProducerError` if committing the consumer failed or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:14:21Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1MzkyOQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407853929", "bodyText": "Fixed in all places", "author": "aashikam", "createdAt": "2020-04-14T04:05:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjEwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjUxNQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776515", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n                # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:15:22Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjgxOA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776818", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Flushes batch of records.\n          \n          \n            \n            # Flushes <span class=\"x x-first x-last\">the </span>batch of records<span class=\"x x-first x-last\"> already sent to the broker by the producer</span>.", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:16:04Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1NDA1Mg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407854052", "bodyText": "Fixed", "author": "aashikam", "createdAt": "2020-04-14T04:05:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjgxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NjkxMA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406776910", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ProducerError` if records couldn't be flushed or else nil<span class=\"x x-first x-last\"> otherwise</span>\n          \n          \n            \n            # + return - `kafka:ProducerError` if records couldn't be flushed or else nil", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:16:17Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NzIwMg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406777202", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Retrieves <span class=\"x x-first x-last\">given </span>topic partition information.\n          \n          \n            \n            # Retrieves topic partition information<span class=\"x x-first x-last\"> for the provided topic</span>.", "author": "ThisaruGuruge", "createdAt": "2020-04-10T14:17:04Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1NDE2Mw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407854163", "bodyText": "Fixed", "author": "aashikam", "createdAt": "2020-04-14T04:06:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc3NzIwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4Njk3OQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406786979", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             To do so, download the necessary dependencies and <span class=\"x x-first x-last\">put</span> them inside the `resources\n          \n          \n            \n             To do so, download the necessary dependencies and <span class=\"x x-first x-last\">add</span> them inside the `resources", "author": "praneesha", "createdAt": "2020-04-10T14:38:52Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -89,10 +21,9 @@ cd kafka_avro_sample\n ballerina add producer\n ballerina add consumer\n ```\n-\n- #### Dependencies\n+ ##### Dependencies\n  To use Avro, you need to add the necessary dependencies to the Ballerina project you created. \n-To do so, download the necessary dependencies and put them inside the `resources\n+ To do so, download the necessary dependencies and put them inside the `resources", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1NDMxNA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407854314", "bodyText": "Fixed", "author": "aashikam", "createdAt": "2020-04-14T04:06:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4Njk3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzEwMA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787100", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now, the directory structure will look like follows<span class=\"x x-first x-last\">. (Some</span> of the files are ignored)\n          \n          \n            \n            Now, the directory structure will look like follows<span class=\"x x-first x-last\"> (some</span> of the files are ignored)<span class=\"x x-first x-last\">.</span>", "author": "praneesha", "createdAt": "2020-04-10T14:39:08Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -154,7 +85,7 @@ To do so, download the necessary dependencies and put them inside the `resources\n      groupId = \"com.fasterxml.jackson.core\"\n ```\n \n-Now, the directory structure will look like follows. (Some of the files ignored)\n+Now, the directory structure will look like follows. (Some of the files are ignored)", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1NDQ0MQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407854441", "bodyText": "Fixed", "author": "aashikam", "createdAt": "2020-04-14T04:07:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzEwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzIwOQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787209", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Represents topic partition position in which consumed record is stored.\n          \n          \n            \n            # Represents <span class=\"x x-first x-last\">the </span>topic partition position in which<span class=\"x x-first x-last\"> the</span> consumed record is stored.", "author": "praneesha", "createdAt": "2020-04-10T14:39:24Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1NDU4Mw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407854583", "bodyText": "Fixed", "author": "aashikam", "createdAt": "2020-04-14T04:08:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzIwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzI3OA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787278", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + offset - Offset in which record is stored in partition\n          \n          \n            \n            # + offset - Offset in which <span class=\"x x-first x-last\">the </span>record is stored in<span class=\"x x-first x-last\"> the</span> partition", "author": "praneesha", "createdAt": "2020-04-10T14:39:34Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg1NDc1OA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407854758", "bodyText": "Fixed", "author": "aashikam", "createdAt": "2020-04-14T04:08:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzI3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzQxMg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787412", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + keyStore - Configurations associated with KeyStore\n          \n          \n            \n            # + keyStore - Configurations associated with <span class=\"x x-first x-last\">the </span>KeyStore", "author": "praneesha", "createdAt": "2020-04-10T14:39:51Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzQ1MA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787450", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + trustStore - Configurations associated with TrustStore\n          \n          \n            \n            # + trustStore - Configurations associated with <span class=\"x x-first x-last\">the </span>TrustStore", "author": "praneesha", "createdAt": "2020-04-10T14:39:57Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4NzUwNA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787504", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + protocol - Configurations related to SSL/TLS protocol and version to be used\n          \n          \n            \n            # + protocol - Configurations related to <span class=\"x x-first x-last\">the </span>SSL/TLS protocol and<span class=\"x x-first x-last\"> the</span> version to be used", "author": "praneesha", "createdAt": "2020-04-10T14:40:06Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4Nzc4Ng==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787786", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n          \n          \n            \n            # + sslKeyPassword - The password of the private key in the key store file. This is optional for <span class=\"x x-first x-last\">the </span>client", "author": "praneesha", "createdAt": "2020-04-10T14:40:38Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4Nzk0OQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406787949", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n          \n          \n            \n            # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC<span class=\"x x-first x-last\">,</span> and key", "author": "praneesha", "createdAt": "2020-04-10T14:41:03Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODMzNQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788335", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                     or SSL network protocol. By default all the available cipher suites are supported\n          \n          \n            \n            #                     or SSL network protocol. By default<span class=\"x x-first x-last\">,</span> all the available cipher suites are supported", "author": "praneesha", "createdAt": "2020-04-10T14:42:00Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default all the available cipher suites are supported", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODQ5OQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788499", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n          \n          \n            \n            # + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate <span class=\"x x-first x-last\">the </span>server hostname using<span class=\"x x-first x-last\"> the</span> server", "author": "praneesha", "createdAt": "2020-04-10T14:42:24Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default all the available cipher suites are supported\n # + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODYxMw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788613", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations\n          \n          \n            \n            # + sslSecureRandomImplementation - The <span class=\"x x-first x-last\">`</span>SecureRandom<span class=\"x x-first x-last\">`</span> PRNG implementation to use for SSL cryptography operations", "author": "praneesha", "createdAt": "2020-04-10T14:42:39Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents topic partition position in which consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which record is stored in partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with KeyStore\n+# + trustStore - Configurations associated with TrustStore\n+# + protocol - Configurations related to SSL/TLS protocol and version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for client\n # + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default all the available cipher suites are supported\n # + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                                        certificate\n+# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODY2NA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788664", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configurations related to KeyStore.\n          \n          \n            \n            # Configurations related to <span class=\"x x-first x-last\">the </span>KeyStore.", "author": "praneesha", "createdAt": "2020-04-10T14:42:47Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODg3NA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788874", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + keyStoreType - The file format of KeyStore file. This is optional for client\n          \n          \n            \n            # + keyStoreType - The file format of <span class=\"x x-first x-last\">the </span>KeyStore file. This is optional for<span class=\"x x-first x-last\"> the</span> client", "author": "praneesha", "createdAt": "2020-04-10T14:43:15Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4ODk0MQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406788941", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n          \n          \n            \n            # + location - The location of the KeyStore file. This is optional for <span class=\"x x-first x-last\">the </span>client and can be used for two-way", "author": "praneesha", "createdAt": "2020-04-10T14:43:25Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTAxOQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789019", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #              authentication for client\n          \n          \n            \n            #              authentication for <span class=\"x x-first x-last\">the </span>client", "author": "praneesha", "createdAt": "2020-04-10T14:43:33Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTExMQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789111", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + password - The store password for the KeyStore file. This is optional for client and only needed if\n          \n          \n            \n            # + password - The store password for the KeyStore file. This is optional for <span class=\"x x-first x-last\">the </span>client and<span class=\"x x-first x-last\"> is</span> only needed if", "author": "praneesha", "createdAt": "2020-04-10T14:43:44Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTE5Nw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789197", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #              ssl.keystore.location is configured\n          \n          \n            \n            #              <span class=\"x x-first x-last\">the `</span>ssl.keystore.location<span class=\"x x-first x-last\">`</span> is configured", "author": "praneesha", "createdAt": "2020-04-10T14:43:55Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTMxNg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789316", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. <span class=\"x x-first x-last\">Default</span> value is the key\n          \n          \n            \n            # + keyManagerAlgorithm - The algorithm used by <span class=\"x x-first x-last\">the </span>key manager factory for SSL connections. <span class=\"x x-first x-last\">The default</span> value is the key", "author": "praneesha", "createdAt": "2020-04-10T14:44:09Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTM2Mw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789363", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                         manager factory algorithm configured for the JVM\n          \n          \n            \n            #                         manager factory algorithm configured for the JVM", "author": "praneesha", "createdAt": "2020-04-10T14:44:17Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTQxNA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789414", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configurations related to TrustStore.\n          \n          \n            \n            # Configurations related to <span class=\"x x-first x-last\">the </span>TrustStore.", "author": "praneesha", "createdAt": "2020-04-10T14:44:25Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTUzNg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789536", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + trustStoreType - The file format of the TrustStore file\n          \n          \n            \n            # + trustStoreType - The file format of the TrustStore file\n          \n      \n    \n    \n  \n\nAdd fullstops for all descriptions.", "author": "praneesha", "createdAt": "2020-04-10T14:44:43Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTYyMA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789620", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n          \n          \n            \n            # + password - The password for the TrustStore file. If a password is not set<span class=\"x x-first x-last\">,</span> access to the TrustStore is still", "author": "praneesha", "createdAt": "2020-04-10T14:44:54Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTY4Ng==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789686", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #              available<span class=\"x x-first x-last\">,</span> but integrity checking is disabled\n          \n          \n            \n            #              available but integrity checking is disabled", "author": "praneesha", "createdAt": "2020-04-10T14:45:03Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTgwMA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789800", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. <span class=\"x x-first x-last\">Default</span> value is the trust\n          \n          \n            \n            # + trustManagerAlgorithm - The algorithm used by <span class=\"x x-first x-last\">the </span>trust manager factory for SSL connections. <span class=\"x x-first x-last\">The default</span> value is the trust", "author": "praneesha", "createdAt": "2020-04-10T14:45:19Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTg5NQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789895", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configurations related to SSL/TLS protocol and the versions to be used.\n          \n          \n            \n            # Configurations related to <span class=\"x x-first x-last\">the </span>SSL/TLS protocol and the versions to be used.", "author": "praneesha", "createdAt": "2020-04-10T14:45:33Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                           manager factory algorithm configured for the Java Virtual Machine\n public type TrustStore record {|\n     string trustStoreType?; // SSL_TRUSTSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_TRUSTSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_TRUSTSTORE_PASSWORD_CONFIG 3\n     string trustManagerAlgorithm?; // SSL_TRUSTMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# A record for configuring SSL/TLS protocol and version to be used.\n+# Configurations related to SSL/TLS protocol and the versions to be used.", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc4OTk4OQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406789989", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslProtocol - The SSL protocol used to generate the SSLContext. <span class=\"x x-first x-last\">Default</span> setting is TLS, which is fine for most\n          \n          \n            \n            # + sslProtocol - The SSL protocol used to generate the SSLContext. <span class=\"x x-first x-last\">The default</span> setting is TLS, which is fine for most", "author": "praneesha", "createdAt": "2020-04-10T14:45:47Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                           manager factory algorithm configured for the Java Virtual Machine\n public type TrustStore record {|\n     string trustStoreType?; // SSL_TRUSTSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_TRUSTSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_TRUSTSTORE_PASSWORD_CONFIG 3\n     string trustManagerAlgorithm?; // SSL_TRUSTMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# A record for configuring SSL/TLS protocol and version to be used.\n+# Configurations related to SSL/TLS protocol and the versions to be used.\n #\n-# + securityProtocol - Protocol used to communicate with brokers.\n+# + securityProtocol - Protocol used to communicate with brokers\n # + sslProtocol - The SSL protocol used to generate the SSLContext. Default setting is TLS, which is fine for most", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc5MDIyOQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406790229", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                 cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported\n          \n          \n            \n            #                 cases. Allowed values in recent JVMs are TLS, TLSv1.1<span class=\"x x-first x-last\">,</span> and TLSv1.2. <span class=\"x x-first x-last\">Also, </span>SSL, SSLv2<span class=\"x x-first x-last\">,</span> and SSLv3 may be supported", "author": "praneesha", "createdAt": "2020-04-10T14:46:25Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                           manager factory algorithm configured for the Java Virtual Machine\n public type TrustStore record {|\n     string trustStoreType?; // SSL_TRUSTSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_TRUSTSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_TRUSTSTORE_PASSWORD_CONFIG 3\n     string trustManagerAlgorithm?; // SSL_TRUSTMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# A record for configuring SSL/TLS protocol and version to be used.\n+# Configurations related to SSL/TLS protocol and the versions to be used.\n #\n-# + securityProtocol - Protocol used to communicate with brokers.\n+# + securityProtocol - Protocol used to communicate with brokers\n # + sslProtocol - The SSL protocol used to generate the SSLContext. Default setting is TLS, which is fine for most\n-#               cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported\n-#               in older JVMs, but their usage is discouraged due to known security vulnerabilities.\n-# + sslProtocolVersions - The list of protocols enabled for SSL connections.\n+#                 cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc5MDI4Nw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406790287", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                 in older JVMs<span class=\"x x-first x-last\">,</span> but their usage is discouraged due to known security vulnerabilities\n          \n          \n            \n            #                 in older JVMs but their usage is discouraged due to known security vulnerabilities", "author": "praneesha", "createdAt": "2020-04-10T14:46:33Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.\n #\n-# + keyStoreType - The file format of the key store file. This is optional for client.\n-# + location - The location of the key store file. This is optional for client and can be used for two-way\n-#               authentication for client.\n-# + password - The store password for the key store file. This is optional for client and only needed if\n-#               ssl.keystore.location is configured.\n+# + keyStoreType - The file format of KeyStore file. This is optional for client\n+# + location - The location of the KeyStore file. This is optional for client and can be used for two-way\n+#              authentication for client\n+# + password - The store password for the KeyStore file. This is optional for client and only needed if\n+#              ssl.keystore.location is configured\n # + keyManagerAlgorithm - The algorithm used by key manager factory for SSL connections. Default value is the key\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                         manager factory algorithm configured for the JVM\n public type KeyStore record {|\n     string keyStoreType?; // SSL_KEYSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_KEYSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_KEYSTORE_PASSWORD_CONFIG 3\n     string keyManagerAlgorithm?; // SSL_KEYMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# Record for providing trust-store related configurations.\n+# Configurations related to TrustStore.\n #\n-# + trustStoreType - The file format of the trust store file.\n-# + location - The location of the trust store file.\n-# + password - The password for the trust store file. If a password is not set access to the trust-store is still\n-#               available, but integrity checking is disabled.\n+# + trustStoreType - The file format of the TrustStore file\n+# + location - The location of the TrustStore file\n+# + password - The password for the TrustStore file. If a password is not set access to the TrustStore is still\n+#              available, but integrity checking is disabled\n # + trustManagerAlgorithm - The algorithm used by trust manager factory for SSL connections. Default value is the trust\n-#               manager factory algorithm configured for the Java Virtual Machine.\n+#                           manager factory algorithm configured for the Java Virtual Machine\n public type TrustStore record {|\n     string trustStoreType?; // SSL_TRUSTSTORE_TYPE_CONFIG 1\n     string location = \"\"; // SSL_TRUSTSTORE_LOCATION_CONFIG 2\n     string password = \"\"; // SSL_TRUSTSTORE_PASSWORD_CONFIG 3\n     string trustManagerAlgorithm?; // SSL_TRUSTMANAGER_ALGORITHM_CONFIG 4\n |};\n \n-# A record for configuring SSL/TLS protocol and version to be used.\n+# Configurations related to SSL/TLS protocol and the versions to be used.\n #\n-# + securityProtocol - Protocol used to communicate with brokers.\n+# + securityProtocol - Protocol used to communicate with brokers\n # + sslProtocol - The SSL protocol used to generate the SSLContext. Default setting is TLS, which is fine for most\n-#               cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported\n-#               in older JVMs, but their usage is discouraged due to known security vulnerabilities.\n-# + sslProtocolVersions - The list of protocols enabled for SSL connections.\n+#                 cases. Allowed values in recent JVMs are TLS, TLSv1.1 and TLSv1.2. SSL, SSLv2 and SSLv3 may be supported\n+#                 in older JVMs, but their usage is discouraged due to known security vulnerabilities", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwMzM0Mg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406803342", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + data - Data which should be deserialized\n          \n          \n            \n                # + data - Data<span class=\"x x-first x-last\">,</span> which should be deserialized", "author": "praneesha", "createdAt": "2020-04-10T15:15:52Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/deserializer.bal", "diffHunk": "@@ -17,12 +17,12 @@\n # Represents a Kafka deserializer object. This object can be used to create custom deserializers for Ballerina Kafka\n # consumers.\n public type Deserializer abstract object {\n-    # Close the deserialization process. This function runs after the deserialization process is done.\n+    # Closes the deserialization process. This function runs after the deserialization process is done.\n     public function close();\n \n-    # Deserialize the provided data. Implement this to deserialize `byte[]` and return any data type.\n+    # Deserializes the provided data. Implement this to deserialize `byte[]` and return any data type.\n     #\n-    # + data - Data which should be deserialized.\n-    # + return - Deserialized value.\n+    # + data - Data which should be deserialized", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwMzQzMw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406803433", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            // Isolation levels\n          \n          \n            \n            // Isolation levels<span class=\"x x-first x-last\">.</span>", "author": "praneesha", "createdAt": "2020-04-10T15:16:02Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -46,10 +46,10 @@ public const DES_CUSTOM = \"CUSTOM\";\n public const DES_AVRO = \"AVRO\";\n \n // Isolation levels", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwMzU0Nw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406803547", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configures the consumer to read all the messages<span class=\"x x-first x-last\">,</span> even the aborted ones.\n          \n          \n            \n            # Configures the consumer to read all the messages even the aborted ones.", "author": "praneesha", "createdAt": "2020-04-10T15:16:17Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -46,10 +46,10 @@ public const DES_CUSTOM = \"CUSTOM\";\n public const DES_AVRO = \"AVRO\";\n \n // Isolation levels\n-# Consumer isolation level value 'read_committed'\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n public const ISOLATION_COMMITTED = \"read_committed\";\n \n-# Consumer isolation level value 'read_uncommitted'\n+# Configures the consumer to read all the messages, even the aborted ones.", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNjQ1Nw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406806457", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            // Producer related constants\n          \n          \n            \n            // Producer related constants<span class=\"x x-first x-last\">.</span>", "author": "praneesha", "createdAt": "2020-04-10T15:22:52Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -46,10 +46,10 @@ public const DES_CUSTOM = \"CUSTOM\";\n public const DES_AVRO = \"AVRO\";\n \n // Isolation levels\n-# Consumer isolation level value 'read_committed'\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n public const ISOLATION_COMMITTED = \"read_committed\";\n \n-# Consumer isolation level value 'read_uncommitted'\n+# Configures the consumer to read all the messages, even the aborted ones.\n public const ISOLATION_UNCOMMITTED = \"read_uncommitted\";\n \n // Producer related constants", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNjUxNA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406806514", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            // Compression types\n          \n          \n            \n            // Compression types<span class=\"x x-first x-last\">.</span>", "author": "praneesha", "createdAt": "2020-04-10T15:22:58Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -86,17 +86,17 @@ public const SER_CUSTOM = \"CUSTOM\";\n public const SER_AVRO = \"AVRO\";\n \n // Compression types", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNjcyOA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406806728", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Represents Kafka Producer configuration.\n          \n          \n            \n            # Represents <span class=\"x x-first x-last\">the </span>Kafka Producer configuration.", "author": "praneesha", "createdAt": "2020-04-10T15:23:29Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNjg3OQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406806879", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n          \n          \n            \n            # + partitionerClass - Partitioner class to be used to select <span class=\"x x-first x-last\">the </span>partition to which the message is sent", "author": "praneesha", "createdAt": "2020-04-10T15:23:46Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzE1OA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807158", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + keySerializer - Custom serializer object to serialize <span class=\"x x-first x-last\">kafka</span> keys. This should<span class=\"x x-first x-last\"> be</span> implement the `kafka:Serializer`\n          \n          \n            \n            # + keySerializer - Custom serializer object to serialize <span class=\"x x-first x-last\">Kafka</span> keys. This should implement the `kafka:Serializer`", "author": "praneesha", "createdAt": "2020-04-10T15:24:19Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzI0NA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807244", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + valueSerializer - Custom serializer object to serialize <span class=\"x x-first x-last\">kafka</span> values. This should<span class=\"x x-first x-last\"> be</span> implement the\n          \n          \n            \n            # + valueSerializer - Custom serializer object to serialize <span class=\"x x-first x-last\">Kafka</span> values. This should implement the", "author": "praneesha", "createdAt": "2020-04-10T15:24:34Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzUwMA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807500", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + schemaRegistryUrl - Avro schema registry <span class=\"x x-first x-last\">url</span>. Use this field to specify schema registry <span class=\"x x-first x-last\">url</span> if Avro serializer\n          \n          \n            \n            # + schemaRegistryUrl - Avro schema registry <span class=\"x x-first x-last\">URL</span>. Use this field to specify <span class=\"x x-first x-last\">the </span>schema registry <span class=\"x x-first x-last\">URL</span> if<span class=\"x x-first x-last\"> the</span> Avro serializer", "author": "praneesha", "createdAt": "2020-04-10T15:25:09Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url if Avro serializer", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzgzMQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807831", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + maxBlock - Maximum block time which the <span class=\"x x-first x-last\">send</span> is blocked<span class=\"x x-first x-last\">,</span> when the buffer is full\n          \n          \n            \n            # + maxBlock - Maximum block time <span class=\"x x-first x-last\">during </span>which the <span class=\"x x-first x-last\">sending</span> is blocked when the buffer is full", "author": "praneesha", "createdAt": "2020-04-10T15:25:55Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url if Avro serializer\n+#                       is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time which the send is blocked, when the buffer is full", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwNzkxMA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406807910", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + requestTimeoutInMillis - Wait time for response of a request\n          \n          \n            \n            # + requestTimeoutInMillis - Wait time for <span class=\"x x-first x-last\">the </span>response of a request", "author": "praneesha", "createdAt": "2020-04-10T15:26:07Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url if Avro serializer\n+#                       is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time which the send is blocked, when the buffer is full\n+# + requestTimeoutInMillis - Wait time for response of a request", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwODE3Nw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406808177", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + metricsSampleWindowInMillis - Time window for a metrics sample to <span class=\"x x-first x-last\">computed</span> over\n          \n          \n            \n            # + metricsSampleWindowInMillis - Time window for a metrics sample to <span class=\"x x-first x-last\">compute</span> over", "author": "praneesha", "createdAt": "2020-04-10T15:26:47Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                         user-defined serializer\n # + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n+#                   object\n # + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url if Avro serializer\n+#                       is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time which the send is blocked, when the buffer is full\n+# + requestTimeoutInMillis - Wait time for response of a request\n+# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata\n+# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwODU1Ng==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406808556", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + schemaString - The string which defines the Avro schema\n          \n          \n            \n            # + schemaString - The string<span class=\"x x-first x-last\">,</span> which defines the Avro schema", "author": "praneesha", "createdAt": "2020-04-10T15:27:36Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -100,26 +100,27 @@ public type ProducerConfiguration record {|\n |};\n \n # Defines a records to send data using Avro serialization.\n-# + schemaString - The string which defines the Avro schema.\n-# + dataRecord - Records which should be serialized using Avro.\n+#\n+# + schemaString - The string which defines the Avro schema", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwODYxMQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406808611", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + dataRecord - Records which should be serialized using Avro\n          \n          \n            \n            # + dataRecord - Records<span class=\"x x-first x-last\">,</span> which should be serialized using Avro", "author": "praneesha", "createdAt": "2020-04-10T15:27:45Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -100,26 +100,27 @@ public type ProducerConfiguration record {|\n |};\n \n # Defines a records to send data using Avro serialization.\n-# + schemaString - The string which defines the Avro schema.\n-# + dataRecord - Records which should be serialized using Avro.\n+#\n+# + schemaString - The string which defines the Avro schema\n+# + dataRecord - Records which should be serialized using Avro", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwODgwMg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406808802", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Closes producer connection to the external Kafka broker.\n          \n          \n            \n            # Closes <span class=\"x x-first x-last\">the </span>producer connection to the external Kafka broker.", "author": "praneesha", "createdAt": "2020-04-10T15:28:11Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTA0Nw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809047", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Commits consumer consumed offsets to offset topic.\n          \n          \n            \n                # Commits consumer consumed offsets to <span class=\"x x-first x-last\">the </span>offset topic.", "author": "praneesha", "createdAt": "2020-04-10T15:28:42Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTI2OA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809268", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + consumer - Consumer which needs offsets to be committed\n          \n          \n            \n                # + consumer - Consumer<span class=\"x x-first x-last\">,</span> which needs offsets to be committed", "author": "praneesha", "createdAt": "2020-04-10T15:29:12Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTc2Ng==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809766", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + topic - Topic which the partition information is given\n          \n          \n            \n            # + topic - Topic <span class=\"x x-first x-last\">to </span>which the partition information is given", "author": "praneesha", "createdAt": "2020-04-10T15:30:18Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTg0Nw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809847", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n          \n          \n            \n            # + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if <span class=\"x x-first x-last\">the </span>operation fails", "author": "praneesha", "createdAt": "2020-04-10T15:30:29Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTkwNQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809905", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Produces records to Kafka server.\n          \n          \n            \n            # Produces records to <span class=\"x x-first x-last\">the </span>Kafka server.", "author": "praneesha", "createdAt": "2020-04-10T15:30:38Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to Kafka server.", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgwOTk3Mg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406809972", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + topic - Topic to which the record will be appended <span class=\"x x-first x-last\">to</span>\n          \n          \n            \n            # + topic - Topic to which the record will be appended", "author": "praneesha", "createdAt": "2020-04-10T15:30:46Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to Kafka server.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->send(\"Hello World, Ballerina\", \"kafka-topic\");\n+# ```\n+#\n+# + value - Record contents\n+# + topic - Topic to which the record will be appended to", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgxMDA3MA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406810070", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + timestamp - Timestamp of the record<span class=\"x x-first x-last\">,</span> in milliseconds since epoch\n          \n          \n            \n            # + timestamp - Timestamp of the record in milliseconds since epoch", "author": "praneesha", "createdAt": "2020-04-10T15:30:55Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to Kafka server.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->send(\"Hello World, Ballerina\", \"kafka-topic\");\n+# ```\n+#\n+# + value - Record contents\n+# + topic - Topic to which the record will be appended to\n+# + key - Key that will be included in the record\n+# + partition - Partition to which the record should be sent\n+# + timestamp - Timestamp of the record, in milliseconds since epoch", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgxMDEzNQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406810135", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return -  `kafka:ProducerError` if send action fails to send data or else nil <span class=\"x x-first x-last\">otherwise</span>\n          \n          \n            \n            # + return -  `kafka:ProducerError` if send action fails to send data or else nil", "author": "praneesha", "createdAt": "2020-04-10T15:31:07Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits consumer consumed offsets to offset topic.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else nil otherwise\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else nil otherwise\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes batch of records.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else nil otherwise\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves given topic partition information.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to Kafka server.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->send(\"Hello World, Ballerina\", \"kafka-topic\");\n+# ```\n+#\n+# + value - Record contents\n+# + topic - Topic to which the record will be appended to\n+# + key - Key that will be included in the record\n+# + partition - Partition to which the record should be sent\n+# + timestamp - Timestamp of the record, in milliseconds since epoch\n+# + return -  `kafka:ProducerError` if send action fails to send data or else nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgxMDIzOQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406810239", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + data - Data which should be serialized\n          \n          \n            \n                # + data - Data<span class=\"x x-first x-last\">,</span> which should be serialized", "author": "praneesha", "createdAt": "2020-04-10T15:31:22Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "diffHunk": "@@ -17,13 +17,13 @@\n # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka\n # producers.\n public type Serializer abstract object {\n-    # Close the serialization process. This function runs after the serialization process is done.\n+    # Closes the serialization process. This function runs after the serialization process is done.\n     public function close();\n \n-    # Serialize the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n+    # Serializes the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n     # Kafka producer.\n     #\n-    # + data - Data which should be serialized.\n-    # + return - Serialized `byte[]` value.\n+    # + data - Data which should be serialized", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgxMDcxNw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r406810717", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n          \n          \n            \n            # + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise\n          \n      \n    \n    \n  \n\nPlease replace all occurrences of \"nil\" with \"()\".", "author": "praneesha", "createdAt": "2020-04-10T15:32:33Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else nil otherwise", "originalCommit": "b06faff2e26df2b7f459e50adc977b8fed7c72e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzg2MTM4Ng==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r407861386", "bodyText": "Fixed in all places", "author": "aashikam", "createdAt": "2020-04-14T04:34:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjgxMDcxNw=="}], "type": "inlineReview"}, {"oid": "68e58f2d9f4ec969c01575be4e0b120a2f60e9f6", "url": "https://github.com/ballerina-platform/ballerina-lang/commit/68e58f2d9f4ec969c01575be4e0b120a2f60e9f6", "message": "Add changes from code review", "committedDate": "2020-04-14T04:53:36Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODAwMzYwMQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408003601", "bodyText": "Shall we make the module.md structure similar to the other messaging modules. Add code snippets to the usages.\n\nhttps://github.com/daneshk/ballerina/blob/nats-docs-updates/stdlib/messaging/nats/src/main/ballerina/src/nats/Module.md\nhttps://github.com/daneshk/ballerina/blob/rabbitmq-docs-updates/stdlib/messaging/rabbitmq/src/main/ballerina/src/rabbitmq/Module.md", "author": "daneshk", "createdAt": "2020-04-14T09:41:15Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,15 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer", "originalCommit": "68e58f2d9f4ec969c01575be4e0b120a2f60e9f6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU2ODA4Mw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408568083", "bodyText": "Fixed in d473036", "author": "aashikam", "createdAt": "2020-04-15T04:05:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODAwMzYwMQ=="}], "type": "inlineReview"}, {"oid": "4d422b3c0dcdce0b16499e06276f1a335a83dbca", "url": "https://github.com/ballerina-platform/ballerina-lang/commit/4d422b3c0dcdce0b16499e06276f1a335a83dbca", "message": "Merge branch 'stdlib-doc-hackathon' of https://github.com/ballerina-platform/ballerina-lang into kafka-docs", "committedDate": "2020-04-15T03:49:48Z", "type": "commit"}, {"oid": "d4730360c31d2d785c78586af3fd7631ca0a3506", "url": "https://github.com/ballerina-platform/ballerina-lang/commit/d4730360c31d2d785c78586af3fd7631ca0a3506", "message": "Add basic usages to Module.md", "committedDate": "2020-04-15T04:04:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDI4OQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614289", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            This module supports <span class=\"x x-first x-last\">kafka</span> 1.x.x and 2.0.0 versions.\n          \n          \n            \n            This module supports <span class=\"x x-first x-last\">Kafka</span> 1.x.x and 2.0.0 versions.", "author": "praneesha", "createdAt": "2020-04-15T06:43:38Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDQ0MQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614441", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            2. Use `kafka:Producer` to publish messages. \n          \n          \n            \n            2. Use <span class=\"x x-first x-last\">the </span>`kafka:Producer` to publish messages.", "author": "praneesha", "createdAt": "2020-04-15T06:43:56Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer\n+For information on the operations, which you can perform with this module, see the below **Functions**.\n+For examples on the usage of the operations, see the following. \n+* [Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer.html) \n+* [Consumer Service Example](https://ballerina.io/learn/by-example/kafka_message_consumer_service.html)\n+* [Consumer Client Example](https://ballerina.io/learn/by-example/kafka_message_consumer_simple.html)\n+* [Consumer Groups Example](https://ballerina.io/learn/by-example/kafka_message_consumer_group_service.html) \n+* [Transactional Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer_transactional.html)\n \n-Following is a simple service which is subscribed to a topic 'test-kafka-topic' on remote Kafka broker cluster.\n+#### Basic Usages\n \n-```ballerina\n-import ballerina/io;\n-import ballerina/kafka;\n-import ballerina/lang. 'string;\n+##### Publishing Messages\n \n-kafka:ConsumerConfiguration consumerConfigs = {\n-    bootstrapServers:\"localhost:9092\",\n-    groupId:\"group-id\",\n-    topics:[\"test-kafka-topic\"],\n-    pollingIntervalInMillis:1000\n+1. Initialize the Kafka message producer.\n+```ballerina\n+kafka:ProducerConfiguration producerConfiguration = {\n+    bootstrapServers: \"localhost:9092\",\n+    clientId: \"basic-producer\",\n+    acks: \"all\",\n+    retryCount: 3,\n+    valueSerializerType: kafka:SER_STRING,\n+    keySerializerType: kafka:SER_INT\n };\n \n-listener kafka:Consumer consumer = new(consumerConfigs);\n-\n-service kafkaService on consumer {\n-\n-    resource function onMessage(kafka:ConsumerAction consumerAction,\n-                  kafka:ConsumerRecord[] records) {\n-        // Dispatched set of Kafka records to service, We process each one by one.\n-        foreach var kafkaRecord in records {\n-            processKafkaRecord(kafkaRecord);\n-        }\n-    }\n-}\n-\n-function processKafkaRecord(kafka:ConsumerRecord kafkaRecord) {\n-    var value = kafkaRecord.value;\n-    if (value is byte[]) {\n-        string | error msg = 'string:fromBytes(serializedMsg);\n-        if (msg is string) {\n-            // Print the retrieved Kafka record.\n-            io:println(\"Topic: \", kafkaRecord.topic, \" Received Message: \", msg);\n-        } else {\n-            log:printError(\"Error occurred while converting message data\", msg);\n-        }\n-    }\n-}\n-````\n-\n-### Kafka Producer\n+kafka:Producer kafkaProducer = new (producerConfiguration);\n+```\n+2. Use `kafka:Producer` to publish messages. ", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDU0Mg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614542", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            2. Use `kafka:Consumer` as a simple record consumer.\n          \n          \n            \n            2. Use <span class=\"x x-first x-last\">the </span>`kafka:Consumer` as a simple record consumer.", "author": "praneesha", "createdAt": "2020-04-15T06:44:08Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer\n+For information on the operations, which you can perform with this module, see the below **Functions**.\n+For examples on the usage of the operations, see the following. \n+* [Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer.html) \n+* [Consumer Service Example](https://ballerina.io/learn/by-example/kafka_message_consumer_service.html)\n+* [Consumer Client Example](https://ballerina.io/learn/by-example/kafka_message_consumer_simple.html)\n+* [Consumer Groups Example](https://ballerina.io/learn/by-example/kafka_message_consumer_group_service.html) \n+* [Transactional Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer_transactional.html)\n \n-Following is a simple service which is subscribed to a topic 'test-kafka-topic' on remote Kafka broker cluster.\n+#### Basic Usages\n \n-```ballerina\n-import ballerina/io;\n-import ballerina/kafka;\n-import ballerina/lang. 'string;\n+##### Publishing Messages\n \n-kafka:ConsumerConfiguration consumerConfigs = {\n-    bootstrapServers:\"localhost:9092\",\n-    groupId:\"group-id\",\n-    topics:[\"test-kafka-topic\"],\n-    pollingIntervalInMillis:1000\n+1. Initialize the Kafka message producer.\n+```ballerina\n+kafka:ProducerConfiguration producerConfiguration = {\n+    bootstrapServers: \"localhost:9092\",\n+    clientId: \"basic-producer\",\n+    acks: \"all\",\n+    retryCount: 3,\n+    valueSerializerType: kafka:SER_STRING,\n+    keySerializerType: kafka:SER_INT\n };\n \n-listener kafka:Consumer consumer = new(consumerConfigs);\n-\n-service kafkaService on consumer {\n-\n-    resource function onMessage(kafka:ConsumerAction consumerAction,\n-                  kafka:ConsumerRecord[] records) {\n-        // Dispatched set of Kafka records to service, We process each one by one.\n-        foreach var kafkaRecord in records {\n-            processKafkaRecord(kafkaRecord);\n-        }\n-    }\n-}\n-\n-function processKafkaRecord(kafka:ConsumerRecord kafkaRecord) {\n-    var value = kafkaRecord.value;\n-    if (value is byte[]) {\n-        string | error msg = 'string:fromBytes(serializedMsg);\n-        if (msg is string) {\n-            // Print the retrieved Kafka record.\n-            io:println(\"Topic: \", kafkaRecord.topic, \" Received Message: \", msg);\n-        } else {\n-            log:printError(\"Error occurred while converting message data\", msg);\n-        }\n-    }\n-}\n-````\n-\n-### Kafka Producer\n+kafka:Producer kafkaProducer = new (producerConfiguration);\n+```\n+2. Use `kafka:Producer` to publish messages. \n+```ballerina\n+string message = \"Hello World, Ballerina\";\n+kafka:ProducerError? result = kafkaProducer->send(message, \"kafka-topic\", key = 1);\n+```\n \n-Following is a simple program which publishes a message to 'test-kafka-topic' topic in a remote Kafka broker cluster.\n+##### Consuming Messages\n \n+1. Initializing the Kafka message consumer. \n ```ballerina\n-import ballerina/kafka;\n-\n-kafka:ProducerConfiguration producerConfigs = {\n-    // Here we create a producer configs with optional parameters \n-    // client.id - used for broker side logging.\n-    // acks - number of acknowledgments for request complete,\n-    // retryCount - number of retries if record send fails.\n+kafka:ConsumerConfiguration consumerConfiguration = {\n     bootstrapServers: \"localhost:9092\",\n-    clientId:\"basic-producer\",\n-    acks:\"all\",\n-    retryCount:3\n+    groupId: \"group-id\",\n+    offsetReset: \"earliest\",\n+    topics: [\"kafka-topic\"]\n };\n \n-kafka:Producer kafkaProducer = new(producerConfigs);\n+kafka:Consumer consumer = new (consumerConfiguration);\n+```\n+2. Use `kafka:Consumer` as a simple record consumer.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDU3NQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614575", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            3. Use `kafka:Consumer` as a listener.\n          \n          \n            \n            3. Use <span class=\"x x-first x-last\">the </span>`kafka:Consumer` as a listener.", "author": "praneesha", "createdAt": "2020-04-15T06:44:14Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer\n+For information on the operations, which you can perform with this module, see the below **Functions**.\n+For examples on the usage of the operations, see the following. \n+* [Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer.html) \n+* [Consumer Service Example](https://ballerina.io/learn/by-example/kafka_message_consumer_service.html)\n+* [Consumer Client Example](https://ballerina.io/learn/by-example/kafka_message_consumer_simple.html)\n+* [Consumer Groups Example](https://ballerina.io/learn/by-example/kafka_message_consumer_group_service.html) \n+* [Transactional Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer_transactional.html)\n \n-Following is a simple service which is subscribed to a topic 'test-kafka-topic' on remote Kafka broker cluster.\n+#### Basic Usages\n \n-```ballerina\n-import ballerina/io;\n-import ballerina/kafka;\n-import ballerina/lang. 'string;\n+##### Publishing Messages\n \n-kafka:ConsumerConfiguration consumerConfigs = {\n-    bootstrapServers:\"localhost:9092\",\n-    groupId:\"group-id\",\n-    topics:[\"test-kafka-topic\"],\n-    pollingIntervalInMillis:1000\n+1. Initialize the Kafka message producer.\n+```ballerina\n+kafka:ProducerConfiguration producerConfiguration = {\n+    bootstrapServers: \"localhost:9092\",\n+    clientId: \"basic-producer\",\n+    acks: \"all\",\n+    retryCount: 3,\n+    valueSerializerType: kafka:SER_STRING,\n+    keySerializerType: kafka:SER_INT\n };\n \n-listener kafka:Consumer consumer = new(consumerConfigs);\n-\n-service kafkaService on consumer {\n-\n-    resource function onMessage(kafka:ConsumerAction consumerAction,\n-                  kafka:ConsumerRecord[] records) {\n-        // Dispatched set of Kafka records to service, We process each one by one.\n-        foreach var kafkaRecord in records {\n-            processKafkaRecord(kafkaRecord);\n-        }\n-    }\n-}\n-\n-function processKafkaRecord(kafka:ConsumerRecord kafkaRecord) {\n-    var value = kafkaRecord.value;\n-    if (value is byte[]) {\n-        string | error msg = 'string:fromBytes(serializedMsg);\n-        if (msg is string) {\n-            // Print the retrieved Kafka record.\n-            io:println(\"Topic: \", kafkaRecord.topic, \" Received Message: \", msg);\n-        } else {\n-            log:printError(\"Error occurred while converting message data\", msg);\n-        }\n-    }\n-}\n-````\n-\n-### Kafka Producer\n+kafka:Producer kafkaProducer = new (producerConfiguration);\n+```\n+2. Use `kafka:Producer` to publish messages. \n+```ballerina\n+string message = \"Hello World, Ballerina\";\n+kafka:ProducerError? result = kafkaProducer->send(message, \"kafka-topic\", key = 1);\n+```\n \n-Following is a simple program which publishes a message to 'test-kafka-topic' topic in a remote Kafka broker cluster.\n+##### Consuming Messages\n \n+1. Initializing the Kafka message consumer. \n ```ballerina\n-import ballerina/kafka;\n-\n-kafka:ProducerConfiguration producerConfigs = {\n-    // Here we create a producer configs with optional parameters \n-    // client.id - used for broker side logging.\n-    // acks - number of acknowledgments for request complete,\n-    // retryCount - number of retries if record send fails.\n+kafka:ConsumerConfiguration consumerConfiguration = {\n     bootstrapServers: \"localhost:9092\",\n-    clientId:\"basic-producer\",\n-    acks:\"all\",\n-    retryCount:3\n+    groupId: \"group-id\",\n+    offsetReset: \"earliest\",\n+    topics: [\"kafka-topic\"]\n };\n \n-kafka:Producer kafkaProducer = new(producerConfigs);\n+kafka:Consumer consumer = new (consumerConfiguration);\n+```\n+2. Use `kafka:Consumer` as a simple record consumer.\n+```ballerina\n+kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+```\n+3. Use `kafka:Consumer` as a listener.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDY2Mg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614662", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To try this, <span class=\"x x-first x-last\">let's </span>create a new Ballerina project and two modules inside it.\n          \n          \n            \n            To try this, create a new Ballerina project and two modules inside it.", "author": "praneesha", "createdAt": "2020-04-15T06:44:30Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -1,83 +1,68 @@\n-## Module overview\n-\n This module is used to interact with Kafka Brokers via Kafka Consumer and Kafka Producer clients.\n This module supports kafka 1.x.x and 2.0.0 versions.\n \n-## Samples\n-### Simple Kafka Consumer\n+For information on the operations, which you can perform with this module, see the below **Functions**.\n+For examples on the usage of the operations, see the following. \n+* [Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer.html) \n+* [Consumer Service Example](https://ballerina.io/learn/by-example/kafka_message_consumer_service.html)\n+* [Consumer Client Example](https://ballerina.io/learn/by-example/kafka_message_consumer_simple.html)\n+* [Consumer Groups Example](https://ballerina.io/learn/by-example/kafka_message_consumer_group_service.html) \n+* [Transactional Producer Example](https://ballerina.io/learn/by-example/kafka_message_producer_transactional.html)\n \n-Following is a simple service which is subscribed to a topic 'test-kafka-topic' on remote Kafka broker cluster.\n+#### Basic Usages\n \n-```ballerina\n-import ballerina/io;\n-import ballerina/kafka;\n-import ballerina/lang. 'string;\n+##### Publishing Messages\n \n-kafka:ConsumerConfiguration consumerConfigs = {\n-    bootstrapServers:\"localhost:9092\",\n-    groupId:\"group-id\",\n-    topics:[\"test-kafka-topic\"],\n-    pollingIntervalInMillis:1000\n+1. Initialize the Kafka message producer.\n+```ballerina\n+kafka:ProducerConfiguration producerConfiguration = {\n+    bootstrapServers: \"localhost:9092\",\n+    clientId: \"basic-producer\",\n+    acks: \"all\",\n+    retryCount: 3,\n+    valueSerializerType: kafka:SER_STRING,\n+    keySerializerType: kafka:SER_INT\n };\n \n-listener kafka:Consumer consumer = new(consumerConfigs);\n-\n-service kafkaService on consumer {\n-\n-    resource function onMessage(kafka:ConsumerAction consumerAction,\n-                  kafka:ConsumerRecord[] records) {\n-        // Dispatched set of Kafka records to service, We process each one by one.\n-        foreach var kafkaRecord in records {\n-            processKafkaRecord(kafkaRecord);\n-        }\n-    }\n-}\n-\n-function processKafkaRecord(kafka:ConsumerRecord kafkaRecord) {\n-    var value = kafkaRecord.value;\n-    if (value is byte[]) {\n-        string | error msg = 'string:fromBytes(serializedMsg);\n-        if (msg is string) {\n-            // Print the retrieved Kafka record.\n-            io:println(\"Topic: \", kafkaRecord.topic, \" Received Message: \", msg);\n-        } else {\n-            log:printError(\"Error occurred while converting message data\", msg);\n-        }\n-    }\n-}\n-````\n-\n-### Kafka Producer\n+kafka:Producer kafkaProducer = new (producerConfiguration);\n+```\n+2. Use `kafka:Producer` to publish messages. \n+```ballerina\n+string message = \"Hello World, Ballerina\";\n+kafka:ProducerError? result = kafkaProducer->send(message, \"kafka-topic\", key = 1);\n+```\n \n-Following is a simple program which publishes a message to 'test-kafka-topic' topic in a remote Kafka broker cluster.\n+##### Consuming Messages\n \n+1. Initializing the Kafka message consumer. \n ```ballerina\n-import ballerina/kafka;\n-\n-kafka:ProducerConfiguration producerConfigs = {\n-    // Here we create a producer configs with optional parameters \n-    // client.id - used for broker side logging.\n-    // acks - number of acknowledgments for request complete,\n-    // retryCount - number of retries if record send fails.\n+kafka:ConsumerConfiguration consumerConfiguration = {\n     bootstrapServers: \"localhost:9092\",\n-    clientId:\"basic-producer\",\n-    acks:\"all\",\n-    retryCount:3\n+    groupId: \"group-id\",\n+    offsetReset: \"earliest\",\n+    topics: [\"kafka-topic\"]\n };\n \n-kafka:Producer kafkaProducer = new(producerConfigs);\n+kafka:Consumer consumer = new (consumerConfiguration);\n+```\n+2. Use `kafka:Consumer` as a simple record consumer.\n+```ballerina\n+kafka:ConsumerRecord[]|kafka:ConsumerError result = consumer->poll(1000);\n+```\n+3. Use `kafka:Consumer` as a listener.\n+```ballerina\n+listener kafka:Consumer consumer = new (consumerConfiguration);\n \n-function main () {\n-    string msg = \"Hello World, Ballerina\";\n-    byte[] serializedMsg = msg.toByteArray(\"UTF-8\");\n-    var sendResult = kafkaProducer->send(serializedMsg, \"test-kafka-topic\");\n-    if (sendResult is error) {\n-        log:printError(\"Kafka producer failed to send data\", err = sendResult);\n+service kafkaService on consumer {\n+    // This resource will be executed when a message is published to the\n+    // subscribed topic/topics.\n+    resource function onMessage(kafka:Consumer kafkaConsumer,\n+            kafka:ConsumerRecord[] records) {\n     }\n }\n ```\n \n-### Send Data Using Avro\n+#### Send Data Using Avro\n The Ballerina Kafka module supports Avro serialization and deserialization.\n \n To try this, let's create a new Ballerina project and two modules inside it.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNDk5NQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408614995", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Now, the directory structure will look like <span class=\"x x-first x-last\">follows</span> (some of the files are ignored).\n          \n          \n            \n            Now, the directory structure will look like <span class=\"x x-first x-last\">below</span> (some of the files are ignored).", "author": "praneesha", "createdAt": "2020-04-15T06:45:19Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -154,7 +138,7 @@ To do so, download the necessary dependencies and put them inside the `resources\n      groupId = \"com.fasterxml.jackson.core\"\n ```\n \n-Now, the directory structure will look like follows. (Some of the files ignored)\n+Now, the directory structure will look like follows (some of the files are ignored).", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTE1OA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615158", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The Consumer will return `kafka:AvroGenericRecord` with the data received from Avro.\n          \n          \n            \n            The Consumer will return <span class=\"x x-first x-last\">a </span>`kafka:AvroGenericRecord` with the data received from Avro.", "author": "praneesha", "createdAt": "2020-04-15T06:45:39Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/Module.md", "diffHunk": "@@ -225,7 +209,7 @@ public function main() {\n }\n ```\n \n-#### Avro Consumer\n+##### Avro Consumer\n The Kafka implementation of Ballerina currently supports Avro deserialization only for generic records.\n The Consumer will return `kafka:AvroGenericRecord` with the data received from Avro.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTIzOQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615239", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + partition - `kafka:TopicPartition` to which the record is related\n          \n          \n            \n            # + partition - <span class=\"x x-first x-last\">The </span>`kafka:TopicPartition` to which the record is related", "author": "praneesha", "createdAt": "2020-04-15T06:45:53Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTQ1MQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615451", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslCipherSuites - A list of <span class=\"x x-first x-last\">cipher</span> suites. This is a named combination of authentication, encryption, MAC, and key\n          \n          \n            \n            # + sslCipherSuites - A list of <span class=\"x x-first x-last\">Cipher</span> suites. This is a named combination of<span class=\"x x-first x-last\"> the</span> authentication, encryption, MAC, and key", "author": "praneesha", "createdAt": "2020-04-15T06:46:25Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which the record is stored in the partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with the KeyStore\n+# + trustStore - Configurations associated with the TrustStore\n+# + protocol - Configurations related to the SSL/TLS protocol and the version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n-# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n-# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for the client\n+# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC, and key", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTU2OQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615569", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                     exchange <span class=\"x x-first x-last\">algorithm</span> used to negotiate the security settings for a network connection using TLS\n          \n          \n            \n            #                     exchange <span class=\"x x-first x-last\">algorithms</span> used to negotiate the security settings for a network connection using<span class=\"x x-first x-last\"> the</span> TLS", "author": "praneesha", "createdAt": "2020-04-15T06:46:45Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which the record is stored in the partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with the KeyStore\n+# + trustStore - Configurations associated with the TrustStore\n+# + protocol - Configurations related to the SSL/TLS protocol and the version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n-# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n-# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for the client\n+# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC, and key\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTY4OA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615688", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #                     or SSL network <span class=\"x x-first x-last\">protocol</span>. By default, all the available <span class=\"x x-first x-last\">cipher</span> suites are supported\n          \n          \n            \n            #                     or SSL network <span class=\"x x-first x-last\">protocols</span>. By default, all the available <span class=\"x x-first x-last\">Cipher</span> suites are supported", "author": "praneesha", "createdAt": "2020-04-15T06:47:02Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which the record is stored in the partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with the KeyStore\n+# + trustStore - Configurations associated with the TrustStore\n+# + protocol - Configurations related to the SSL/TLS protocol and the version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n-# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n-# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for the client\n+# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC, and key\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default, all the available cipher suites are supported", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTg0Nw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615847", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + sslSecureRandomImplementation - The `SecureRandom` PRNG implementation to use for SSL cryptography operations\n          \n          \n            \n            # + sslSecureRandomImplementation - The `SecureRandom` PRNG implementation to use for <span class=\"x x-first x-last\">the </span>SSL cryptography operations", "author": "praneesha", "createdAt": "2020-04-15T06:47:23Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -14,38 +14,38 @@\n // specific language governing permissions and limitations\n // under the License.\n \n-# This type represents topic partition position in which consumed record is stored.\n+# Represents the topic partition position in which the consumed record is stored.\n #\n-# + partition - TopicPartition which record is related.\n-# + offset - Offset in which record is stored in partition.\n+# + partition - `kafka:TopicPartition` to which the record is related\n+# + offset - Offset in which the record is stored in the partition\n public type PartitionOffset record {|\n     TopicPartition partition;\n     int offset;\n |};\n \n-# This type represents a topic partition.\n+# Represents a topic partition.\n #\n-# + topic - Topic which partition is related.\n-# + partition - Index for the partition.\n+# + topic - Topic to which the partition is related\n+# + partition - Index for the partition\n public type TopicPartition record {|\n     string topic;\n     int partition;\n |};\n \n-# Provides configurations for facilitating secure communication with the Kafka server.\n+# Configurations for facilitating secure communication with the Kafka server.\n #\n-# + keyStore - Configurations associated with KeyStore.\n-# + trustStore - Configurations associated with TrustStore.\n-# + protocol - Configurations related to SSL/TLS protocol and version to be used.\n+# + keyStore - Configurations associated with the KeyStore\n+# + trustStore - Configurations associated with the TrustStore\n+# + protocol - Configurations related to the SSL/TLS protocol and the version to be used\n # + sslProvider - The name of the security provider used for SSL connections. Default value is the default security\n-#               provider of the JVM.\n-# + sslKeyPassword - The password of the private key in the key store file. This is optional for client.\n-# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC and key\n-#               exchange algorithm used to negotiate the security settings for a network connection using TLS or SSL\n-#               network protocol. By default all the available cipher suites are supported.\n-# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate server hostname using server\n-#               certificate.\n-# + sslSecureRandomImplementation - The SecureRandom PRNG implementation to use for SSL cryptography operations.\n+#                 provider of the JVM\n+# + sslKeyPassword - The password of the private key in the key store file. This is optional for the client\n+# + sslCipherSuites - A list of cipher suites. This is a named combination of authentication, encryption, MAC, and key\n+#                     exchange algorithm used to negotiate the security settings for a network connection using TLS\n+#                     or SSL network protocol. By default, all the available cipher suites are supported\n+# + sslEndpointIdentificationAlgorithm - The endpoint identification algorithm to validate the server hostname using\n+#                                        the server certificate\n+# + sslSecureRandomImplementation - The `SecureRandom` PRNG implementation to use for SSL cryptography operations", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNTkwNQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408615905", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configurations related to KeyStore.\n          \n          \n            \n            # Configurations related to <span class=\"x x-first x-last\">the </span>KeyStore.", "author": "praneesha", "createdAt": "2020-04-15T06:47:31Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/commons.bal", "diffHunk": "@@ -57,44 +57,44 @@ public type SecureSocket record {|\n     string sslSecureRandomImplementation?; // SSL_SECURE_RANDOM_IMPLEMENTATION_CONFIG 5\n |};\n \n-# Record for providing key-store related configurations.\n+# Configurations related to KeyStore.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjU1OQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616559", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Deserializes the provided data. Implement this to deserialize `byte[]` and return any data type.\n          \n          \n            \n                # Deserializes the provided data. Implement this to deserialize <span class=\"x x-first x-last\">a </span>`byte[]` and return any data type.", "author": "praneesha", "createdAt": "2020-04-15T06:48:56Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/deserializer.bal", "diffHunk": "@@ -17,12 +17,12 @@\n # Represents a Kafka deserializer object. This object can be used to create custom deserializers for Ballerina Kafka\n # consumers.\n public type Deserializer abstract object {\n-    # Close the deserialization process. This function runs after the deserialization process is done.\n+    # Closes the deserialization process. This function runs after the deserialization process is done.\n     public function close();\n \n-    # Deserialize the provided data. Implement this to deserialize `byte[]` and return any data type.\n+    # Deserializes the provided data. Implement this to deserialize `byte[]` and return any data type.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjY2Nw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616667", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - <span class=\"x x-first x-last\">Deserialized</span> value\n          \n          \n            \n                # + return - <span class=\"x x-first x-last\">The deserialized</span> value", "author": "praneesha", "createdAt": "2020-04-15T06:49:11Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/deserializer.bal", "diffHunk": "@@ -17,12 +17,12 @@\n # Represents a Kafka deserializer object. This object can be used to create custom deserializers for Ballerina Kafka\n # consumers.\n public type Deserializer abstract object {\n-    # Close the deserialization process. This function runs after the deserialization process is done.\n+    # Closes the deserialization process. This function runs after the deserialization process is done.\n     public function close();\n \n-    # Deserialize the provided data. Implement this to deserialize `byte[]` and return any data type.\n+    # Deserializes the provided data. Implement this to deserialize `byte[]` and return any data type.\n     #\n-    # + data - Data which should be deserialized.\n-    # + return - Deserialized value.\n+    # + data - Data, which should be deserialized\n+    # + return - Deserialized value", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjc2Nw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616767", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n          \n          \n            \n            # Configures the consumer to read the committed messages only in <span class=\"x x-first x-last\">the </span>transactional mode when poll() is called.", "author": "praneesha", "createdAt": "2020-04-15T06:49:26Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -45,15 +45,15 @@ public const DES_CUSTOM = \"CUSTOM\";\n # Apache Avro deserializer.\n public const DES_AVRO = \"AVRO\";\n \n-// Isolation levels\n-# Consumer isolation level value 'read_committed'\n+// Isolation levels.\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjg1NA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616854", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            // Producer<span class=\"x x-first x-last\"> </span>related constants.\n          \n          \n            \n            // Producer<span class=\"x x-first x-last\">-</span>related constants.", "author": "praneesha", "createdAt": "2020-04-15T06:49:35Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -45,15 +45,15 @@ public const DES_CUSTOM = \"CUSTOM\";\n # Apache Avro deserializer.\n public const DES_AVRO = \"AVRO\";\n \n-// Isolation levels\n-# Consumer isolation level value 'read_committed'\n+// Isolation levels.\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n public const ISOLATION_COMMITTED = \"read_committed\";\n \n-# Consumer isolation level value 'read_uncommitted'\n+# Configures the consumer to read all the messages even the aborted ones.\n public const ISOLATION_UNCOMMITTED = \"read_uncommitted\";\n \n-// Producer related constants\n-// Produce Ack types\n+// Producer related constants.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNjk2Mw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408616963", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Producer acknowledgement type 'all'. This will <span class=\"x x-first x-last\">gurantee</span> that the record will not be lost as long as at least one\n          \n          \n            \n            # Producer acknowledgement type <span class=\"x x-first x-last\">is </span>'all'. This will <span class=\"x x-first x-last\">guarantee</span> that the record will not be lost as long as at least one", "author": "praneesha", "createdAt": "2020-04-15T06:49:50Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -45,15 +45,15 @@ public const DES_CUSTOM = \"CUSTOM\";\n # Apache Avro deserializer.\n public const DES_AVRO = \"AVRO\";\n \n-// Isolation levels\n-# Consumer isolation level value 'read_committed'\n+// Isolation levels.\n+# Configures the consumer to read the committed messages only in transactional mode when poll() is called.\n public const ISOLATION_COMMITTED = \"read_committed\";\n \n-# Consumer isolation level value 'read_uncommitted'\n+# Configures the consumer to read all the messages even the aborted ones.\n public const ISOLATION_UNCOMMITTED = \"read_uncommitted\";\n \n-// Producer related constants\n-// Produce Ack types\n+// Producer related constants.\n+// Produce Ack types.\n # Producer acknowledgement type 'all'. This will gurantee that the record will not be lost as long as at least one", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzIxMQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617211", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # local log <span class=\"x x-first x-last\">but </span>will respond without <span class=\"x x-first x-last\">awaiting </span>full acknowledgement from all followers.\n          \n          \n            \n            # <span class=\"x x-first x-last\">A </span>local log will respond without <span class=\"x x-first x-last\">waiting FOR </span>full acknowledgement from all<span class=\"x x-first x-last\"> the</span> followers.", "author": "praneesha", "createdAt": "2020-04-15T06:50:27Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -66,7 +66,7 @@ public const ACKS_NONE = \"0\";\n # local log but will respond without awaiting full acknowledgement from all followers.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzMxMw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617313", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Apache <span class=\"x x-first x-last\">avro</span> serializer.\n          \n          \n            \n            # Apache <span class=\"x x-first x-last\">Avro</span> serializer.", "author": "praneesha", "createdAt": "2020-04-15T06:50:39Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_constants.bal", "diffHunk": "@@ -85,18 +85,18 @@ public const SER_CUSTOM = \"CUSTOM\";\n # Apache avro serializer.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzQ3NA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617474", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Error type specific to `kafka:Consumer` object functions.\n          \n          \n            \n            # Error type specific to <span class=\"x x-first x-last\">the </span>`kafka:Consumer` object functions.", "author": "praneesha", "createdAt": "2020-04-15T06:51:00Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_errors.bal", "diffHunk": "@@ -16,29 +16,29 @@\n \n # Represents the details of an error.\n #\n-# + message - The error message.\n-# + cause - Cause of the error.\n+# + message - The description of the error occurred\n+# + cause - Cause of the error\n public type Detail record {\n     string message;\n     error cause?;\n };\n \n-# Defines a Kafka consumer related error\n+# Used as the error reason for the `kafka:ConsumerError` type.\n public const CONSUMER_ERROR = \"{ballerina/kafka}ConsumerError\";\n \n-# Represents a Kafka consumer related error\n+# Error type specific to `kafka:Consumer` object functions.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzUzMw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617533", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Error type specific to `kafka:Producer` object functions.\n          \n          \n            \n            # Error type specific to <span class=\"x x-first x-last\">the </span>`kafka:Producer` object functions.", "author": "praneesha", "createdAt": "2020-04-15T06:51:08Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/kafka_errors.bal", "diffHunk": "@@ -16,29 +16,29 @@\n \n # Represents the details of an error.\n #\n-# + message - The error message.\n-# + cause - Cause of the error.\n+# + message - The description of the error occurred\n+# + cause - Cause of the error\n public type Detail record {\n     string message;\n     error cause?;\n };\n \n-# Defines a Kafka consumer related error\n+# Used as the error reason for the `kafka:ConsumerError` type.\n public const CONSUMER_ERROR = \"{ballerina/kafka}ConsumerError\";\n \n-# Represents a Kafka consumer related error\n+# Error type specific to `kafka:Consumer` object functions.\n public type ConsumerError error<CONSUMER_ERROR, Detail>;\n \n-# Defines a Kafka producer related error\n+# Used as the error reason for the `kafka:ProducerError` type.\n public const PRODUCER_ERROR = \"{ballerina/kafka}ProducerError\";\n \n-# Represents a Kafka producer related error\n+# Error type specific to `kafka:Producer` object functions.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxNzgyOA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408617828", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + valueSerializer - Custom serializer object to serialize Kafka values. This should <span class=\"x x-first x-last\">be </span>implement the\n          \n          \n            \n            # + valueSerializer - Custom serializer object to serialize Kafka values. This should implement the", "author": "praneesha", "createdAt": "2020-04-15T06:51:53Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents the Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select the partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n-# + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n-# + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                         user-defined serializer\n+# + keySerializer - Custom serializer object to serialize Kafka keys. This should implement the `kafka:Serializer`\n+#                   object\n+# + valueSerializer - Custom serializer object to serialize Kafka values. This should be implement the", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxODQ4Ng==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408618486", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + metricsNumSamples - Number of samples maintained to compute metrics\n          \n          \n            \n            # + metricsNumSamples - Number of samples maintained to compute <span class=\"x x-first x-last\">the </span>metrics", "author": "praneesha", "createdAt": "2020-04-15T06:53:16Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents the Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select the partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n-# + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n-# + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                         user-defined serializer\n+# + keySerializer - Custom serializer object to serialize Kafka keys. This should implement the `kafka:Serializer`\n+#                   object\n+# + valueSerializer - Custom serializer object to serialize Kafka values. This should be implement the\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry URL. Use this field to specify the schema registry URL if the Avro\n+#                       serializer is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time during which the sending is blocked, when the buffer is full\n+# + requestTimeoutInMillis - Wait time for the response of a request\n+# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata\n+# + metricsSampleWindowInMillis - Time window for a metrics sample to compute over\n+# + metricsNumSamples - Number of samples maintained to compute metrics", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxODUzNg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408618536", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + maxBlock - Maximum block time during which the sending is blocked<span class=\"x x-first x-last\">,</span> when the buffer is full\n          \n          \n            \n            # + maxBlock - Maximum block time during which the sending is blocked when the buffer is full", "author": "praneesha", "createdAt": "2020-04-15T06:53:21Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents the Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select the partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n-# + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n-# + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                         user-defined serializer\n+# + keySerializer - Custom serializer object to serialize Kafka keys. This should implement the `kafka:Serializer`\n+#                   object\n+# + valueSerializer - Custom serializer object to serialize Kafka values. This should be implement the\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry URL. Use this field to specify the schema registry URL if the Avro\n+#                       serializer is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time during which the sending is blocked, when the buffer is full", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxODY0MA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408618640", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + connectionsMaxIdleTimeInMillis - Close idle connections after <span class=\"x x-first x-last\">the</span> number of milliseconds\n          \n          \n            \n            # + connectionsMaxIdleTimeInMillis - Close <span class=\"x x-first x-last\">the </span>idle connections after <span class=\"x x-first x-last\">this</span> number of milliseconds", "author": "praneesha", "createdAt": "2020-04-15T06:53:35Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -17,47 +17,47 @@\n import ballerina/system;\n import ballerina/java;\n \n-# Struct which represents Kafka Producer configuration.\n+# Represents the Kafka Producer configuration.\n #\n-# + bootstrapServers - List of remote server endpoints of Kafka brokers.\n-# + acks - Number of acknowledgments. This can be either `kafka:ACKS_ALL`, `kafka:ACKS_SINGLE` or `kafka:ACKS_NONE`.\n-# + compressionType - Compression type to be used for messages.\n-# + clientId - Identifier to be used for server side logging.\n-# + metricsRecordingLevel - Metrics recording level.\n-# + metricReporterClasses - Metrics reporter classes.\n-# + partitionerClass - Partitioner class to be used to select partition to which the message is sent.\n-# + interceptorClasses - Interceptor classes to be used before sending records.\n-# + transactionalId - Transactional ID to be used in transactional delivery.\n+# + bootstrapServers - List of remote server endpoints of Kafka brokers\n+# + acks - Number of acknowledgments\n+# + compressionType - Compression type to be used for messages\n+# + clientId - Identifier to be used for server side logging\n+# + metricsRecordingLevel - Metrics recording level\n+# + metricReporterClasses - Metrics reporter classes\n+# + partitionerClass - Partitioner class to be used to select the partition to which the message is sent\n+# + interceptorClasses - Interceptor classes to be used before sending records\n+# + transactionalId - Transactional ID to be used in transactional delivery\n # + keySerializerType - Serializer used for the Kafka record key. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n+#                       user-defined serializer\n # + valueSerializerType - Serializer used for the Kafka record value. This can be either `kafka:SerializerType` or a\n-#       user-defined serializer.\n-# + keySerializer - Custom serializer object to serialize kafka keys. This should be implement the `kafka:Serializer`\n-#       object.\n-# + valueSerializer - Custom serializer object to serialize kafka values. This should be implement the\n-#       `kafka:Serializer` object.\n-# + schemaRegistryUrl - Avro schema registry url. Use this field to specify schema registry url, if Avro serializer\n-#       is used.\n-# + bufferMemory - Total bytes of memory the producer can use to buffer records.\n-# + retryCount - Number of retries to resend a record.\n-# + batchSize - Number of records to be batched for a single request. Use 0 for no batching.\n-# + linger - Delay to allow other records to be batched.\n-# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF).\n-# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF).\n-# + maxRequestSize - The maximum size of a request in bytes.\n-# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect.\n-# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting.\n-# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request.\n-# + maxBlock - Maximum block time which the send is blocked, when the buffer is full.\n-# + requestTimeoutInMillis - Wait time for response of a request.\n-# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata.\n-# + metricsSampleWindowInMillis - Time window for a metrics sample to computed over.\n-# + metricsNumSamples - Number of samples maintained to compute metrics.\n-# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection.\n-# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds.\n-# + transactionTimeoutInMillis - Timeout for transaction status update from the producer.\n-# + enableIdempotence - Exactly one copy of each message is written in the stream when enabled.\n-# + secureSocket - Configurations related to SSL/TLS.\n+#                         user-defined serializer\n+# + keySerializer - Custom serializer object to serialize Kafka keys. This should implement the `kafka:Serializer`\n+#                   object\n+# + valueSerializer - Custom serializer object to serialize Kafka values. This should be implement the\n+#                     `kafka:Serializer` object\n+# + schemaRegistryUrl - Avro schema registry URL. Use this field to specify the schema registry URL if the Avro\n+#                       serializer is used\n+# + bufferMemory - Total bytes of memory the producer can use to buffer records\n+# + retryCount - Number of retries to resend a record\n+# + batchSize - Number of records to be batched for a single request. Use 0 for no batching\n+# + linger - Delay to allow other records to be batched\n+# + sendBuffer - Size of the TCP send buffer (SO_SNDBUF)\n+# + receiveBuffer - Size of the TCP receive buffer (SO_RCVBUF)\n+# + maxRequestSize - The maximum size of a request in bytes\n+# + reconnectBackoffTimeInMillis - Time to wait before attempting to reconnect\n+# + reconnectBackoffMaxTimeInMillis - Maximum amount of time in milliseconds to wait when reconnecting\n+# + retryBackoffTimeInMillis - Time to wait before attempting to retry a failed request\n+# + maxBlock - Maximum block time during which the sending is blocked, when the buffer is full\n+# + requestTimeoutInMillis - Wait time for the response of a request\n+# + metadataMaxAgeInMillis - Maximum time to force a refresh of metadata\n+# + metricsSampleWindowInMillis - Time window for a metrics sample to compute over\n+# + metricsNumSamples - Number of samples maintained to compute metrics\n+# + maxInFlightRequestsPerConnection - Maximum number of unacknowledged requests on a single connection\n+# + connectionsMaxIdleTimeInMillis - Close idle connections after the number of milliseconds", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTA0NA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619044", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ProducerError` if closing the producer is failed or else ()\n          \n          \n            \n            # + return - <span class=\"x x-first x-last\">A </span>`kafka:ProducerError` if closing the producer is failed or else ()", "author": "praneesha", "createdAt": "2020-04-15T06:54:26Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTE2Mw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619163", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n          \n          \n            \n                # + return - <span class=\"x x-first x-last\">A</span>`kafka:ProducerError` if committing the consumer failed or else ()", "author": "praneesha", "createdAt": "2020-04-15T06:54:44Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTIyNA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619224", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Commits consumer offsets in given transaction.\n          \n          \n            \n                # Commits <span class=\"x x-first x-last\">the </span>consumer offsets in<span class=\"x x-first x-last\"> a</span> given transaction.", "author": "praneesha", "createdAt": "2020-04-15T06:54:53Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTMyMg==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619322", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + offsets - Consumer offsets to commit for given transaction\n          \n          \n            \n                # + offsets - Consumer offsets to commit for <span class=\"x x-first x-last\">a </span>given transaction", "author": "praneesha", "createdAt": "2020-04-15T06:55:08Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTM1OQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619359", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + groupID - Consumer group <span class=\"x x-first x-last\">id</span>\n          \n          \n            \n                # + groupID - Consumer group <span class=\"x x-first x-last\">ID</span>", "author": "praneesha", "createdAt": "2020-04-15T06:55:14Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTQxOA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619418", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n          \n          \n            \n                # + return - <span class=\"x x-first x-last\">A </span>`kafka:ProducerError` if committing consumer offsets failed or else ()", "author": "praneesha", "createdAt": "2020-04-15T06:55:22Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTQ5OA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619498", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n          \n          \n            \n            # + return - <span class=\"x x-first x-last\">A </span>`kafka:ProducerError` if records couldn't be flushed or else ()", "author": "praneesha", "createdAt": "2020-04-15T06:55:33Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTU1Mw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619553", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Retrieves topic partition information for the provided topic.\n          \n          \n            \n            # Retrieves <span class=\"x x-first x-last\">the </span>topic partition information for the provided topic.", "author": "praneesha", "createdAt": "2020-04-15T06:55:42Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves topic partition information for the provided topic.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTYxMQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619611", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + topic - Topic <span class=\"x x-first x-last\">to</span> which the partition information is given\n          \n          \n            \n            # + topic - Topic <span class=\"x x-first x-last\">of</span> which the partition information is given", "author": "praneesha", "createdAt": "2020-04-15T06:55:52Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves topic partition information for the provided topic.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic to which the partition information is given", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTczNQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619735", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n          \n          \n            \n            # + return - <span class=\"x x-first x-last\">A </span>`kafka:TopicPartition` array for the given topic or else <span class=\"x x-first x-last\">a </span>`kafka:ProducerError` if<span class=\"x x-first x-last\"> the</span> operation fails", "author": "praneesha", "createdAt": "2020-04-15T06:56:07Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves topic partition information for the provided topic.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic to which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTg0Ng==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619846", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # + return -  `kafka:ProducerError` if send action fails to send data or else ()\n          \n          \n            \n            # + return -  <span class=\"x x-first x-last\">A </span>`kafka:ProducerError` if send action fails to send data or else ()", "author": "praneesha", "createdAt": "2020-04-15T06:56:25Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/producer.bal", "diffHunk": "@@ -173,53 +174,65 @@ public type Producer client object {\n \n     public string connectorId = system:uuid();\n \n-    # Closes producer connection to the external Kafka broker.\n-    #\n-    # + return - `kafka:ProducerError` if closing the producer failed, nil otherwise.\n+# Closes the producer connection to the external Kafka broker.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->close();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if closing the producer is failed or else ()\n     public remote function close() returns ProducerError? {\n         return producerClose(self);\n     }\n \n-    # Commits consumer action which commits consumer consumed offsets to offset topic.\n+    # Commits the offsets consumed by the provided consumer.\n     #\n-    # + consumer - Consumer which needs offsets to be committed.\n-    # + return - `kafka:ProducerError` if committing the consumer failed, nil otherwise.\n+    # + consumer - Consumer, which needs offsets to be committed\n+    # + return - `kafka:ProducerError` if committing the consumer failed or else ()\n     public remote function commitConsumer(Consumer consumer) returns ProducerError? {\n         return producerCommitConsumer(self, consumer);\n     }\n \n-    # CommitConsumerOffsets action which commits consumer offsets in given transaction.\n+    # Commits consumer offsets in given transaction.\n     #\n-    # + offsets - Consumer offsets to commit for given transaction.\n-    # + groupID - Consumer group id.\n-    # + return - `kafka:ProducerError` if committing consumer offsets failed, nil otherwise.\n+    # + offsets - Consumer offsets to commit for given transaction\n+    # + groupID - Consumer group id\n+    # + return - `kafka:ProducerError` if committing consumer offsets failed or else ()\n     public remote function commitConsumerOffsets(PartitionOffset[] offsets, string groupID) returns ProducerError? {\n         return producerCommitConsumerOffsets(self, offsets, java:fromString(groupID));\n     }\n \n-    # Flush action which flush batch of records.\n-    #\n-    # + return - `kafka:ProducerError` if records couldn't be flushed, nil otherwise.\n+# Flushes the batch of records already sent to the broker by the producer.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->flushRecords();\n+# ```\n+#\n+# + return - `kafka:ProducerError` if records couldn't be flushed or else ()\n     public remote function flushRecords() returns ProducerError? {\n         return producerFlushRecords(self);\n     }\n \n-    # GetTopicPartitions action which returns given topic partition information.\n-    #\n-    # + topic - Topic which the partition information is given.\n-    # + return - `kafka:TopicPartition` array for the given topic, returns `kafka:ProducerError` if operation fails.\n+# Retrieves topic partition information for the provided topic.\n+# ```ballerina\n+# kafka:TopicPartition[]|kafka:ProducerError result = producer->getTopicPartitions(\"kafka-topic\");\n+# ```\n+#\n+# + topic - Topic to which the partition information is given\n+# + return - `kafka:TopicPartition` array for the given topic or else `kafka:ProducerError` if operation fails\n     public remote function getTopicPartitions(string topic) returns TopicPartition[]|ProducerError {\n         return producerGetTopicPartitions(self, java:fromString(topic));\n     }\n \n-    # Simple Send action which produce records to Kafka server.\n-    #\n-    # + value - Record contents.\n-    # + topic - Topic to which the record will be appended to.\n-    # + key - Key that will be included in the record.\n-    # + partition - Partition to which the record should be sent.\n-    # + timestamp - Timestamp of the record, in milliseconds since epoch.\n-    # + return - Returns `kafka:ProducerError` if send action fails to send data, nil otherwise.\n+# Produces records to the Kafka server.\n+# ```ballerina\n+# kafka:ProducerError? result = producer->send(\"Hello World, Ballerina\", \"kafka-topic\");\n+# ```\n+#\n+# + value - Record contents\n+# + topic - Topic to which the record will be appended\n+# + key - Key that will be included in the record\n+# + partition - Partition to which the record should be sent\n+# + timestamp - Timestamp of the record in milliseconds since epoch\n+# + return -  `kafka:ProducerError` if send action fails to send data or else ()", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYxOTk0Mw==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408619943", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka\n          \n          \n            \n            # Represents a Kafka serializer object. This object can be used to create custom serializers for <span class=\"x x-first x-last\">the </span>Ballerina Kafka", "author": "praneesha", "createdAt": "2020-04-15T06:56:37Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "diffHunk": "@@ -17,13 +17,13 @@\n # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyMDA2NA==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408620064", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Serializes the provided data. Implement this to serialize any data type<span class=\"x x-first x-last\">,</span> and return the `byte[]` value to use in\n          \n          \n            \n                # Serializes the provided data. Implement this to serialize any data type and return the `byte[]` value to use in", "author": "praneesha", "createdAt": "2020-04-15T06:56:51Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "diffHunk": "@@ -17,13 +17,13 @@\n # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka\n # producers.\n public type Serializer abstract object {\n-    # Close the serialization process. This function runs after the serialization process is done.\n+    # Closes the serialization process. This function runs after the serialization process is done.\n     public function close();\n \n-    # Serialize the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n+    # Serializes the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyMDExOQ==", "url": "https://github.com/ballerina-platform/ballerina-lang/pull/22580#discussion_r408620119", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                # Kafka producer.\n          \n          \n            \n                # <span class=\"x x-first x-last\">the </span>Kafka producer.", "author": "praneesha", "createdAt": "2020-04-15T06:56:58Z", "path": "stdlib/messaging/kafka/src/main/ballerina/src/kafka/serializer.bal", "diffHunk": "@@ -17,13 +17,13 @@\n # Represents a Kafka serializer object. This object can be used to create custom serializers for Ballerina Kafka\n # producers.\n public type Serializer abstract object {\n-    # Close the serialization process. This function runs after the serialization process is done.\n+    # Closes the serialization process. This function runs after the serialization process is done.\n     public function close();\n \n-    # Serialize the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n+    # Serializes the provided data. Implement this to serialize any data type, and return the `byte[]` value to use in\n     # Kafka producer.", "originalCommit": "d4730360c31d2d785c78586af3fd7631ca0a3506", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "20fcdbea0f1975a9de332abd138583bbddbbf5d3", "url": "https://github.com/ballerina-platform/ballerina-lang/commit/20fcdbea0f1975a9de332abd138583bbddbbf5d3", "message": "Apply suggestions from code review\n\nCo-Authored-By: praneesha <praneesha@wso2.com>", "committedDate": "2020-04-15T13:37:55Z", "type": "commit"}]}