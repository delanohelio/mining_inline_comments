{"pr_number": 849, "pr_title": "PARQUET-1954: TCP connection leak in parquet dump", "pr_createdAt": "2020-12-15T14:39:26Z", "pr_url": "https://github.com/apache/parquet-mr/pull/849", "timeline": [{"oid": "029ae9a7799bdb7f755a7a177d750733c2ec7271", "url": "https://github.com/apache/parquet-mr/commit/029ae9a7799bdb7f755a7a177d750733c2ec7271", "message": "PARQUET-1954: TCP connection leak in parquet dump", "committedDate": "2020-12-15T13:21:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4NTg3MQ==", "url": "https://github.com/apache/parquet-mr/pull/849#discussion_r543485871", "bodyText": "If an I/O exception occurs in the ParquetFileReader constructor then you might try to close the previous reader object. I would guess there is no problem with invoking close multiple times on the same object but who knows? It might be a good idea to reset the reference so you would not close the same object again. Another idea would be to use try-with-resources for the code part where the reader is really needed.", "author": "gszadovszky", "createdAt": "2020-12-15T16:18:10Z", "path": "parquet-tools/src/main/java/org/apache/parquet/tools/command/DumpCommand.java", "diffHunk": "@@ -165,48 +165,47 @@ public static void dump(PrettyPrintWriter out, ParquetMetadata meta, MessageType\n \n         ParquetFileReader freader = null;\n         if (showmd) {\n+          long group = 0;\n+          for (BlockMetaData block : blocks) {\n             try {\n-                long group = 0;\n-                for (BlockMetaData block : blocks) {\n-                    if (group != 0) out.println();\n-                    out.format(\"row group %d%n\", group++);\n-                    out.rule('-');\n-\n-\n-                    List<ColumnChunkMetaData> ccmds = block.getColumns();\n-                    if (showColumns != null) {\n-                        ccmds = new ArrayList<ColumnChunkMetaData>();\n-                        for (ColumnChunkMetaData ccmd : block.getColumns()) {\n-                            String path = Joiner.on('.').skipNulls().join(ccmd.getPath().toArray());\n-                            if (showColumns.contains(path)) {\n-                                ccmds.add(ccmd);\n-                            }\n-                        }\n-                    }\n-\n-                    MetadataUtils.showDetails(out, ccmds);\n+              if (group != 0)\n+                out.println();\n+              out.format(\"row group %d%n\", group++);\n+              out.rule('-');\n+\n+              List<ColumnChunkMetaData> ccmds = block.getColumns();\n+              if (showColumns != null) {\n+                ccmds = new ArrayList<ColumnChunkMetaData>();\n+                for (ColumnChunkMetaData ccmd : block.getColumns()) {\n+                  String path = Joiner.on('.').skipNulls().join(ccmd.getPath().toArray());\n+                  if (showColumns.contains(path)) {\n+                    ccmds.add(ccmd);\n+                  }\n+                }\n+              }\n \n-                    List<BlockMetaData> rblocks = Collections.singletonList(block);\n-                    freader = new ParquetFileReader(\n-                        conf, meta.getFileMetaData(), inpath, rblocks, columns);\n-                    PageReadStore store = freader.readNextRowGroup();\n-                    while (store != null) {\n-                        out.incrementTabLevel();\n-                        for (ColumnDescriptor column : columns) {\n-                            out.println();\n-                            dump(out, store, column);\n-                        }\n-                        out.decrementTabLevel();\n+              MetadataUtils.showDetails(out, ccmds);\n \n-                        store = freader.readNextRowGroup();\n-                    }\n-                    out.flushColumns();\n+              List<BlockMetaData> rblocks = Collections.singletonList(block);\n+              freader = new ParquetFileReader(conf, meta.getFileMetaData(), inpath, rblocks, columns);\n+              PageReadStore store = freader.readNextRowGroup();\n+              while (store != null) {\n+                out.incrementTabLevel();\n+                for (ColumnDescriptor column : columns) {\n+                  out.println();\n+                  dump(out, store, column);\n                 }\n+                out.decrementTabLevel();\n+\n+                store = freader.readNextRowGroup();\n+              }\n+              out.flushColumns();\n             } finally {\n-                if (freader != null) {\n-                    freader.close();\n-                }\n+              if (freader != null) {\n+                freader.close();", "originalCommit": "029ae9a7799bdb7f755a7a177d750733c2ec7271", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzg3NTY4Nw==", "url": "https://github.com/apache/parquet-mr/pull/849#discussion_r543875687", "bodyText": "This is the memory used before and after fix this bug:", "author": "StefanXiepj", "createdAt": "2020-12-16T03:14:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4NTg3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDE1MjA5MA==", "url": "https://github.com/apache/parquet-mr/pull/849#discussion_r544152090", "bodyText": "I did not say your fix is not working. What I suggest is to avoid closing a reader twice if an issue happens in the ParquetFileReader constructor.", "author": "gszadovszky", "createdAt": "2020-12-16T09:41:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4NTg3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDc4MjczNg==", "url": "https://github.com/apache/parquet-mr/pull/849#discussion_r544782736", "bodyText": "yeah yeah,  thx for your review, i am sorry, please forgive me. Do you mean we can fix it like this:\n            ...\n            } finally {\n              if (freader != null) {\n                freader.close();\n                // reset current reader is null, avoid closing a reader twice\n                freader = null;\n              }\n            }\n\nor\ntry(ParquetFileReader freader = \n    new ParquetFileReader(conf, meta.getFileMetaData(), inpath, rblocks, columns)){\n    // do something where the freader is really needed.\n}\n\nis right ?", "author": "StefanXiepj", "createdAt": "2020-12-17T03:21:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4NTg3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTI3OTc3MA==", "url": "https://github.com/apache/parquet-mr/pull/849#discussion_r549279770", "bodyText": "hi, @gszadovszky Could you help me to review this PR ? thanks.", "author": "StefanXiepj", "createdAt": "2020-12-28T09:33:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4NTg3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTI5NTY0NA==", "url": "https://github.com/apache/parquet-mr/pull/849#discussion_r549295644", "bodyText": "The ParquetFileReader is Closeable, I would suggest using the try-with-resource pattern: https://docs.oracle.com/javase/tutorial/essential/exceptions/tryResourceClose.html\nAs @gszadovszky already suggested.", "author": "Fokko", "createdAt": "2020-12-28T10:25:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4NTg3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTU5MjUxMA==", "url": "https://github.com/apache/parquet-mr/pull/849#discussion_r549592510", "bodyText": "@Fokko thanks for your suggestion, can you review it again?", "author": "StefanXiepj", "createdAt": "2020-12-29T07:02:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ4NTg3MQ=="}], "type": "inlineReview"}, {"oid": "511b4e8893fd164b9a238620a1dd14a9508a5635", "url": "https://github.com/apache/parquet-mr/commit/511b4e8893fd164b9a238620a1dd14a9508a5635", "message": "reset freader is null, avoid closing a reader twice", "committedDate": "2020-12-17T03:31:36Z", "type": "commit"}, {"oid": "1de703df6ef9046cf3d5a62f8ae4a293a5c1dce5", "url": "https://github.com/apache/parquet-mr/commit/1de703df6ef9046cf3d5a62f8ae4a293a5c1dce5", "message": "using the try-with-resource pattern", "committedDate": "2020-12-29T06:55:09Z", "type": "commit"}]}