{"pr_number": 1971, "pr_title": "Dbz 2782 sql server connector edit", "pr_createdAt": "2020-11-21T03:20:13Z", "pr_url": "https://github.com/debezium/debezium/pull/1971", "timeline": [{"oid": "932c480e846229775f2306c4ec0e4005e77b14db", "url": "https://github.com/debezium/debezium/commit/932c480e846229775f2306c4ec0e4005e77b14db", "message": "DBZ-2782 Update to comply with CCS style; edit annotations, links.", "committedDate": "2020-11-21T03:08:57Z", "type": "commit"}, {"oid": "064e0141eb65416d0be663ab4ae0b0309944367a", "url": "https://github.com/debezium/debezium/commit/064e0141eb65416d0be663ab4ae0b0309944367a", "message": "DBZ-2782 Fix typo, reword downstream list intro.", "committedDate": "2020-11-21T03:15:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU3ODg0MA==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528578840", "bodyText": "@roldanbob Word tracking and tracked can be really confusing in SSQL Server context as SQL Server supports change data capture we rely upon and Change Tracking (https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/about-change-tracking-sql-server?view=sql-server-ver15) which is similar but distinct feature", "author": "jpechane", "createdAt": "2020-11-23T09:49:51Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -18,82 +21,121 @@ Want to help us further hone and improve it? link:/docs/contribute/[Learn how].\n toc::[]\n endif::community[]\n \n-{prodname}'s SQL Server Connector can monitor and record the row-level changes in the schemas of a SQL Server database.\n+The {prodname} SQL Server connector captures row-level changes that occur in the schemas of a SQL Server database.\n+\n+ifdef::product[]\n+For details about the {prodname} SQL Server connector and its use, see following topics: \n+\n+* xref:overview-of-debezium-sql-server-connector[]\n+* xref:how-debezium-sql-server-connectors-work[]\n+* xref:descriptions-of-debezium-sql-server-connector-data-change-events[]\n+* xref:how-debezium-SQL Server-connectors-map-data-types[]\n+* xref:setting-up-sql-server-for-use-with-the-debezium-sql-server-connector[]\n+* xref:deploying-debezium-sql-server-connectors[]\n+* xref:Monitoring {prodname} SQL Server connector performance[]\n+* xref:how-debezium-postgresql-connectors-handle-faults-and-problems[]\n+\n+endif::product[]\n+\n+The first time that the {prodname} SQL Server connector connects to a SQL Server database or cluster, it takes a consistent snapshot of the schemas in the database.\n+After the initial snapshot is complete, the connector continuously captures row-level changes for `INSERT`, `UPDATE`, or `DELETE` operations that are committed to tracked SQL Server databases. ", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU4Mjg0MA==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528582840", "bodyText": "Here again the word monitored is used which was replaced in introduction. The terminologiy should be unified.", "author": "jpechane", "createdAt": "2020-11-23T09:56:04Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -18,82 +21,121 @@ Want to help us further hone and improve it? link:/docs/contribute/[Learn how].\n toc::[]\n endif::community[]\n \n-{prodname}'s SQL Server Connector can monitor and record the row-level changes in the schemas of a SQL Server database.\n+The {prodname} SQL Server connector captures row-level changes that occur in the schemas of a SQL Server database.\n+\n+ifdef::product[]\n+For details about the {prodname} SQL Server connector and its use, see following topics: \n+\n+* xref:overview-of-debezium-sql-server-connector[]\n+* xref:how-debezium-sql-server-connectors-work[]\n+* xref:descriptions-of-debezium-sql-server-connector-data-change-events[]\n+* xref:how-debezium-SQL Server-connectors-map-data-types[]\n+* xref:setting-up-sql-server-for-use-with-the-debezium-sql-server-connector[]\n+* xref:deploying-debezium-sql-server-connectors[]\n+* xref:Monitoring {prodname} SQL Server connector performance[]\n+* xref:how-debezium-postgresql-connectors-handle-faults-and-problems[]\n+\n+endif::product[]\n+\n+The first time that the {prodname} SQL Server connector connects to a SQL Server database or cluster, it takes a consistent snapshot of the schemas in the database.\n+After the initial snapshot is complete, the connector continuously captures row-level changes for `INSERT`, `UPDATE`, or `DELETE` operations that are committed to tracked SQL Server databases. \n+The connector produces events for each data change operation, and streams them to Kafka topics. \n+The connector streams all of the events for a table to a dedicated Kafka topic.\n+Applications and services can then consume data change event records from that topic.\n \n-The first time it connects to a SQL Server database/cluster, it reads a consistent snapshot of all of the schemas.\n-When that snapshot is complete, the connector continuously streams the changes that were committed to SQL Server and generates corresponding insert, update and delete events.\n-All of the events for each table are recorded in a separate Kafka topic, where they can be easily consumed by applications and services.\n \n // Type: concept\n // Title: Overview of {prodname} SQL Server connector \n // ModuleID: overview-of-debezium-sql-server-connector\n [[sqlserver-overview]]\n == Overview\n \n-The functionality of the connector is based upon https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/about-change-data-capture-sql-server?view=sql-server-2017[change data capture] feature provided by SQL Server Standard (https://blogs.msdn.microsoft.com/sqlreleaseservices/sql-server-2016-service-pack-1-sp1-released/[since SQL Server 2016 SP1]) or Enterprise edition.\n-Using this mechanism a SQL Server capture process monitors all databases and tables the user is interested in and stores the changes into specifically created _CDC_ tables that have stored procedure facade.\n-\n-The database operator must https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/enable-and-disable-change-data-capture-sql-server?view=sql-server-2017[enable] _CDC_ for the table(s) that should be captured by the connector.\n-The connector then produces a _change event_ for every row-level insert, update, and delete operation that was published via the _CDC API_, recording all the change events for each table in a separate Kafka topic.\n-The client applications read the Kafka topics that correspond to the database tables they're interested in following, and react to every row-level event it sees in those topics.\n-\n-The database operator normally enables _CDC_ in the mid-life of a database an/or table.\n-This means that the connector does not have the complete history of all changes that have been made to the database.\n-Therefore, when the SQL Server connector first connects to a particular SQL Server database, it starts by performing a _consistent snapshot_ of each of the database schemas.\n-After the connector completes the snapshot, it continues streaming changes from the exact point at which the snapshot was made.\n-This way, we start with a consistent view of all of the data, yet continue reading without having lost any of the changes made while the snapshot was taking place.\n-\n-The connector is also tolerant of failures.\n-As the connector reads changes and produces events, it records the position in the database log (_LSN / Log Sequence Number_), that is associated with _CDC_ record, with each event.\n-If the connector stops for any reason (including communication failures, network problems, or crashes), upon restart it simply continues reading the _CDC_ tables where it last left off.\n-This includes snapshots: if the snapshot was not completed when the connector is stopped, upon restart it begins a new snapshot.\n+The {prodname} SQL Server connector is based on the https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/about-change-data-capture-sql-server?view=sql-server-2017[change data capture] \n+feature that is available in https://blogs.msdn.microsoft.com/sqlreleaseservices/sql-server-2016-service-pack-1-sp1-released/[SQL Server 2016 Service Pack 1 (SP1) and later] Standard edition or Enterprise edition.\n+The SQL Server capture process monitors designated databases and tables, and stores the changes into specifically created _change tables_ that have stored procedure facades.\n+\n+To enable the {prodname} SQL Server connector to capture change event records for database operations, \n+you must first enable change data capture on the SQL Server database. \n+CDC must be enabled on both the database and on each table that you want to track.\n+After you set up CDC on the source database, the connector can capture row-level `INSERT`, `UPDATE`, and `DELETE` operations  \n+that occur in the database.\n+The connector writes event records for each source table to a Kafka topic especially dedicated to that table.\n+One topic exists for each tracked table.\n+Client applications read the Kafka topics for the database tables that they follow, and can respond to the row-level events they they consume from those topics.\n+\n+The first time that the connector connects to a SQL Server database or cluster, it takes a consistent snapshot of the schemas for all tables for which it is configured to capture changes,\n+and streams this state to Kafka.\n+After the snapshot is complete, the connector continuously captures subsequent row-level changes that occur.\n+By first establishing a consistent view of all of the data, the connector can continue reading without having lost any of the changes that were made while the snapshot was taking place.\n+\n+The {prodname} SQL Server connector is tolerant of failures.\n+As the connector reads changes and produces events, it records the position in the database log (_LSN / Log Sequence Number_) for each event.\n+If the connector stops for any reason (including communication failures, network problems, or crashes), after a restart the connector resumes reading the SQL Server _CDC_ tables from the last point that it read.\n+Fault tolerance also applies to snapshots. \n+That is, if the connector stops during a snapshot, the connector begins a news snapshot when it restarts.\n \n // Type: assembly\n // ModuleID: how-debezium-sql-server-connectors-work\n // Title: How {prodname} SQL Server connectors work\n [[how-the-sqlserver-connector-works]]\n == How the SQL Server connector works\n \n+To optimally configure and run a {prodname} SQL Server connector, it is helpful to understand how the connector performs snapshots, streams change events, determines Kafka topic names, and uses metadata. \n+ifdef::product[]\n+For details about how the connector works, see the following sections: \n+\n+* xref:how-debezium-sql-server-connectors-perform-database-snapshots[]\n+* xref:how-the-debezium-sql-server-connector-reads-change-data-tables[]\n+* xref:default-names-of-kafka-topics-that-receive-debezium-sql-server-change-event-records[]\n+* xref:how-the-debezium-SQL Server connector-uses-the-schema-change-topic[]\n+* xref:descriptions-of-debezium-sql-server-connector-data-change-events[]\n+* xref:debezium-sql-server-connector-generated-events-that-represent-transaction-boundaries[]\n+* xref:how-debezium-SQL Server-connectors-map-data-types[]\n+endif::product[]\n+\n // Type: concept\n // ModuleID: how-debezium-sql-server-connectors-perform-database-snapshots\n // Title: How {prodname} SQL Server connectors perform database snapshots\n [[sqlserver-snapshots]]\n === Snapshots\n \n-SQL Server CDC is not designed to store the complete history of database changes.\n-It is thus necessary that {prodname} establishes the baseline of current database content and streams it to the Kafka.\n-This is achieved via a process called snapshotting.\n+SQL Server CDC is not designed to store a complete history of database changes.\n+For the {prodname} SQL Server connector to establish a baseline for the current state of the database, \n+it uses a process called _snapshotting_.\n \n-By default (snapshotting mode *initial*) the connector will upon the first startup perform an initial _consistent snapshot_ of the database\n-(meaning the structure and data within any tables to be captured as per the connector's filter configuration).\n+You can configure how the connector creates snapshots.\n+By default, the connector's snapshot mode is set to `initial`. \n+Based on this `initial` snapshot mode, the first time that the connector starts, it performs an initial _consistent snapshot_ of the database.\n+This initial snapshot captures the structure and data for any tables that match the criteria defined by the `include` and `exclude` properties that are configured for the connector (for example, `table.include.list`, `column.include.list`, `table.exclude.list`, and so forth).\n \n-Each snapshot consists of the following steps:\n+When the connector creates a snapshot, it completes the following tasks:\n \n-1. Determine the tables to be captured\n-2. Obtain a lock on each of the monitored tables to ensure that no structural changes can occur to any of the tables.\n+1. Determines the tables to be captured.\n+2. Obtains a lock on each of the monitored tables to ensure that no structural changes can occur to any of the tables.", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU4NjE1OQ==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528586159", "bodyText": "We should generally use \"capture\" (discussed with @TovaCohen some time ago). \"monitoring\" refers to (JMX) monitoring and \"tracking\", yeah, it's potentially confusing.", "author": "gunnarmorling", "createdAt": "2020-11-23T10:01:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU4Mjg0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU4OTc2Mw==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528589763", "bodyText": "Probably needs an empty line above, otherwise don't render correctly.", "author": "jpechane", "createdAt": "2020-11-23T10:06:54Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -966,21 +1029,34 @@ Following is an example of what a message looks like:\n ----\n \n // Type: reference\n-// ModuleID: how-the-debezium-SQL Server-connectors-map-data-types\n-// Title: How the {prodname} SQL Server connectors map data types\n+// ModuleID: how-debezium-SQL Server-connectors-map-data-types\n+// Title: How {prodname} SQL Server connectors map data types\n [[sqlserver-data-types]]\n === Data type mappings\n \n-As described above, the SQL Server connector represents the changes to rows with events that are structured like the table in which the row exist.\n-The event contains a field for each column value, and how that value is represented in the event depends on the SQL data type of the column. This section describes this mapping.\n+The {prodname} SQL Server connector represents changes to table row data by producing events that are structured like the table in which the row exists.\n+Each event contains fields to represent the column values for the row. \n+The way in which an event represents the column values for an operation depends on the SQL data type of the column. \n+In the event, the connector maps the fields for each SQL Server data type to both a _literal type_ and a _semantic type_. \n+\n+The connector can map SQL Server data types to both _literal_ and _semantic_ types.\n+Literal type:: Describes how the value is literally represented by using Kafka Connect schema types, namely `INT8`, `INT16`, `INT32`, `INT64`, `FLOAT32`, `FLOAT64`, `BOOLEAN`, `STRING`, `BYTES`, `ARRAY`, `MAP`, and `STRUCT`.", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MDU5OA==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528590598", "bodyText": "Should go into conditional block below", "author": "jpechane", "createdAt": "2020-11-23T10:08:19Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -1213,19 +1289,51 @@ The `connect.decimal.precision` schema parameter contains an integer that repres\n [[setting-up-sqlserver]]\n == Setting up SQL Server\n \n-Before using the SQL Server connector to monitor the changes committed on SQL Server, first enable _CDC_ on a monitored database.\n-Please bear in mind that _CDC_ cannot be enabled for the `primary` database.\n+For {prodname} to capture change events from SQL Server tables, a SQL Server administrator with the necessary privileges must first run a query to enable CDC on the database. \n+The administrator must then enable CDC for each table to be tracked.   \n+\n+For details about setting up SQL Server for use with the {prodname} connector, see the following sections:", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MTI2Nw==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528591267", "bodyText": "Needs an empty line before?", "author": "jpechane", "createdAt": "2020-11-23T10:09:33Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -966,21 +1029,34 @@ Following is an example of what a message looks like:\n ----\n \n // Type: reference\n-// ModuleID: how-the-debezium-SQL Server-connectors-map-data-types\n-// Title: How the {prodname} SQL Server connectors map data types\n+// ModuleID: how-debezium-SQL Server-connectors-map-data-types\n+// Title: How {prodname} SQL Server connectors map data types\n [[sqlserver-data-types]]\n === Data type mappings\n \n-As described above, the SQL Server connector represents the changes to rows with events that are structured like the table in which the row exist.\n-The event contains a field for each column value, and how that value is represented in the event depends on the SQL data type of the column. This section describes this mapping.\n+The {prodname} SQL Server connector represents changes to table row data by producing events that are structured like the table in which the row exists.\n+Each event contains fields to represent the column values for the row. \n+The way in which an event represents the column values for an operation depends on the SQL data type of the column. \n+In the event, the connector maps the fields for each SQL Server data type to both a _literal type_ and a _semantic type_. \n+\n+The connector can map SQL Server data types to both _literal_ and _semantic_ types.\n+Literal type:: Describes how the value is literally represented by using Kafka Connect schema types, namely `INT8`, `INT16`, `INT32`, `INT64`, `FLOAT32`, `FLOAT64`, `BOOLEAN`, `STRING`, `BYTES`, `ARRAY`, `MAP`, and `STRUCT`.\n+Semantic type:: Describes how the Kafka Connect schema captures the _meaning_ of the field using the name of the Kafka Connect schema for the field.\n+\n+ifdef::product[]\n+For more information about data type mappings, see the following sections:\n+* xref:sqlserver-basic-values[]", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU4ODc3Mw==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528588773", "bodyText": "Worth mentioning that the offset is committed periodically, not after each change event. I.e. there may be some duplicates after a crash.", "author": "gunnarmorling", "createdAt": "2020-11-23T10:05:20Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -18,82 +21,121 @@ Want to help us further hone and improve it? link:/docs/contribute/[Learn how].\n toc::[]\n endif::community[]\n \n-{prodname}'s SQL Server Connector can monitor and record the row-level changes in the schemas of a SQL Server database.\n+The {prodname} SQL Server connector captures row-level changes that occur in the schemas of a SQL Server database.\n+\n+ifdef::product[]\n+For details about the {prodname} SQL Server connector and its use, see following topics: \n+\n+* xref:overview-of-debezium-sql-server-connector[]\n+* xref:how-debezium-sql-server-connectors-work[]\n+* xref:descriptions-of-debezium-sql-server-connector-data-change-events[]\n+* xref:how-debezium-SQL Server-connectors-map-data-types[]\n+* xref:setting-up-sql-server-for-use-with-the-debezium-sql-server-connector[]\n+* xref:deploying-debezium-sql-server-connectors[]\n+* xref:Monitoring {prodname} SQL Server connector performance[]\n+* xref:how-debezium-postgresql-connectors-handle-faults-and-problems[]\n+\n+endif::product[]\n+\n+The first time that the {prodname} SQL Server connector connects to a SQL Server database or cluster, it takes a consistent snapshot of the schemas in the database.\n+After the initial snapshot is complete, the connector continuously captures row-level changes for `INSERT`, `UPDATE`, or `DELETE` operations that are committed to tracked SQL Server databases. \n+The connector produces events for each data change operation, and streams them to Kafka topics. \n+The connector streams all of the events for a table to a dedicated Kafka topic.\n+Applications and services can then consume data change event records from that topic.\n \n-The first time it connects to a SQL Server database/cluster, it reads a consistent snapshot of all of the schemas.\n-When that snapshot is complete, the connector continuously streams the changes that were committed to SQL Server and generates corresponding insert, update and delete events.\n-All of the events for each table are recorded in a separate Kafka topic, where they can be easily consumed by applications and services.\n \n // Type: concept\n // Title: Overview of {prodname} SQL Server connector \n // ModuleID: overview-of-debezium-sql-server-connector\n [[sqlserver-overview]]\n == Overview\n \n-The functionality of the connector is based upon https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/about-change-data-capture-sql-server?view=sql-server-2017[change data capture] feature provided by SQL Server Standard (https://blogs.msdn.microsoft.com/sqlreleaseservices/sql-server-2016-service-pack-1-sp1-released/[since SQL Server 2016 SP1]) or Enterprise edition.\n-Using this mechanism a SQL Server capture process monitors all databases and tables the user is interested in and stores the changes into specifically created _CDC_ tables that have stored procedure facade.\n-\n-The database operator must https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/enable-and-disable-change-data-capture-sql-server?view=sql-server-2017[enable] _CDC_ for the table(s) that should be captured by the connector.\n-The connector then produces a _change event_ for every row-level insert, update, and delete operation that was published via the _CDC API_, recording all the change events for each table in a separate Kafka topic.\n-The client applications read the Kafka topics that correspond to the database tables they're interested in following, and react to every row-level event it sees in those topics.\n-\n-The database operator normally enables _CDC_ in the mid-life of a database an/or table.\n-This means that the connector does not have the complete history of all changes that have been made to the database.\n-Therefore, when the SQL Server connector first connects to a particular SQL Server database, it starts by performing a _consistent snapshot_ of each of the database schemas.\n-After the connector completes the snapshot, it continues streaming changes from the exact point at which the snapshot was made.\n-This way, we start with a consistent view of all of the data, yet continue reading without having lost any of the changes made while the snapshot was taking place.\n-\n-The connector is also tolerant of failures.\n-As the connector reads changes and produces events, it records the position in the database log (_LSN / Log Sequence Number_), that is associated with _CDC_ record, with each event.\n-If the connector stops for any reason (including communication failures, network problems, or crashes), upon restart it simply continues reading the _CDC_ tables where it last left off.\n-This includes snapshots: if the snapshot was not completed when the connector is stopped, upon restart it begins a new snapshot.\n+The {prodname} SQL Server connector is based on the https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/about-change-data-capture-sql-server?view=sql-server-2017[change data capture] \n+feature that is available in https://blogs.msdn.microsoft.com/sqlreleaseservices/sql-server-2016-service-pack-1-sp1-released/[SQL Server 2016 Service Pack 1 (SP1) and later] Standard edition or Enterprise edition.\n+The SQL Server capture process monitors designated databases and tables, and stores the changes into specifically created _change tables_ that have stored procedure facades.\n+\n+To enable the {prodname} SQL Server connector to capture change event records for database operations, \n+you must first enable change data capture on the SQL Server database. \n+CDC must be enabled on both the database and on each table that you want to track.\n+After you set up CDC on the source database, the connector can capture row-level `INSERT`, `UPDATE`, and `DELETE` operations  \n+that occur in the database.\n+The connector writes event records for each source table to a Kafka topic especially dedicated to that table.\n+One topic exists for each tracked table.\n+Client applications read the Kafka topics for the database tables that they follow, and can respond to the row-level events they they consume from those topics.\n+\n+The first time that the connector connects to a SQL Server database or cluster, it takes a consistent snapshot of the schemas for all tables for which it is configured to capture changes,\n+and streams this state to Kafka.\n+After the snapshot is complete, the connector continuously captures subsequent row-level changes that occur.\n+By first establishing a consistent view of all of the data, the connector can continue reading without having lost any of the changes that were made while the snapshot was taking place.\n+\n+The {prodname} SQL Server connector is tolerant of failures.\n+As the connector reads changes and produces events, it records the position in the database log (_LSN / Log Sequence Number_) for each event.\n+If the connector stops for any reason (including communication failures, network problems, or crashes), after a restart the connector resumes reading the SQL Server _CDC_ tables from the last point that it read.", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MDA5NA==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528590094", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            4. The connector store the maximum LSN and restarts the process from Step 1.\n          \n          \n            \n            4. The connector stores the maximum LSN and restarts the process from Step 1.", "author": "gunnarmorling", "createdAt": "2020-11-23T10:07:25Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -18,82 +21,121 @@ Want to help us further hone and improve it? link:/docs/contribute/[Learn how].\n toc::[]\n endif::community[]\n \n-{prodname}'s SQL Server Connector can monitor and record the row-level changes in the schemas of a SQL Server database.\n+The {prodname} SQL Server connector captures row-level changes that occur in the schemas of a SQL Server database.\n+\n+ifdef::product[]\n+For details about the {prodname} SQL Server connector and its use, see following topics: \n+\n+* xref:overview-of-debezium-sql-server-connector[]\n+* xref:how-debezium-sql-server-connectors-work[]\n+* xref:descriptions-of-debezium-sql-server-connector-data-change-events[]\n+* xref:how-debezium-SQL Server-connectors-map-data-types[]\n+* xref:setting-up-sql-server-for-use-with-the-debezium-sql-server-connector[]\n+* xref:deploying-debezium-sql-server-connectors[]\n+* xref:Monitoring {prodname} SQL Server connector performance[]\n+* xref:how-debezium-postgresql-connectors-handle-faults-and-problems[]\n+\n+endif::product[]\n+\n+The first time that the {prodname} SQL Server connector connects to a SQL Server database or cluster, it takes a consistent snapshot of the schemas in the database.\n+After the initial snapshot is complete, the connector continuously captures row-level changes for `INSERT`, `UPDATE`, or `DELETE` operations that are committed to tracked SQL Server databases. \n+The connector produces events for each data change operation, and streams them to Kafka topics. \n+The connector streams all of the events for a table to a dedicated Kafka topic.\n+Applications and services can then consume data change event records from that topic.\n \n-The first time it connects to a SQL Server database/cluster, it reads a consistent snapshot of all of the schemas.\n-When that snapshot is complete, the connector continuously streams the changes that were committed to SQL Server and generates corresponding insert, update and delete events.\n-All of the events for each table are recorded in a separate Kafka topic, where they can be easily consumed by applications and services.\n \n // Type: concept\n // Title: Overview of {prodname} SQL Server connector \n // ModuleID: overview-of-debezium-sql-server-connector\n [[sqlserver-overview]]\n == Overview\n \n-The functionality of the connector is based upon https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/about-change-data-capture-sql-server?view=sql-server-2017[change data capture] feature provided by SQL Server Standard (https://blogs.msdn.microsoft.com/sqlreleaseservices/sql-server-2016-service-pack-1-sp1-released/[since SQL Server 2016 SP1]) or Enterprise edition.\n-Using this mechanism a SQL Server capture process monitors all databases and tables the user is interested in and stores the changes into specifically created _CDC_ tables that have stored procedure facade.\n-\n-The database operator must https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/enable-and-disable-change-data-capture-sql-server?view=sql-server-2017[enable] _CDC_ for the table(s) that should be captured by the connector.\n-The connector then produces a _change event_ for every row-level insert, update, and delete operation that was published via the _CDC API_, recording all the change events for each table in a separate Kafka topic.\n-The client applications read the Kafka topics that correspond to the database tables they're interested in following, and react to every row-level event it sees in those topics.\n-\n-The database operator normally enables _CDC_ in the mid-life of a database an/or table.\n-This means that the connector does not have the complete history of all changes that have been made to the database.\n-Therefore, when the SQL Server connector first connects to a particular SQL Server database, it starts by performing a _consistent snapshot_ of each of the database schemas.\n-After the connector completes the snapshot, it continues streaming changes from the exact point at which the snapshot was made.\n-This way, we start with a consistent view of all of the data, yet continue reading without having lost any of the changes made while the snapshot was taking place.\n-\n-The connector is also tolerant of failures.\n-As the connector reads changes and produces events, it records the position in the database log (_LSN / Log Sequence Number_), that is associated with _CDC_ record, with each event.\n-If the connector stops for any reason (including communication failures, network problems, or crashes), upon restart it simply continues reading the _CDC_ tables where it last left off.\n-This includes snapshots: if the snapshot was not completed when the connector is stopped, upon restart it begins a new snapshot.\n+The {prodname} SQL Server connector is based on the https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/about-change-data-capture-sql-server?view=sql-server-2017[change data capture] \n+feature that is available in https://blogs.msdn.microsoft.com/sqlreleaseservices/sql-server-2016-service-pack-1-sp1-released/[SQL Server 2016 Service Pack 1 (SP1) and later] Standard edition or Enterprise edition.\n+The SQL Server capture process monitors designated databases and tables, and stores the changes into specifically created _change tables_ that have stored procedure facades.\n+\n+To enable the {prodname} SQL Server connector to capture change event records for database operations, \n+you must first enable change data capture on the SQL Server database. \n+CDC must be enabled on both the database and on each table that you want to track.\n+After you set up CDC on the source database, the connector can capture row-level `INSERT`, `UPDATE`, and `DELETE` operations  \n+that occur in the database.\n+The connector writes event records for each source table to a Kafka topic especially dedicated to that table.\n+One topic exists for each tracked table.\n+Client applications read the Kafka topics for the database tables that they follow, and can respond to the row-level events they they consume from those topics.\n+\n+The first time that the connector connects to a SQL Server database or cluster, it takes a consistent snapshot of the schemas for all tables for which it is configured to capture changes,\n+and streams this state to Kafka.\n+After the snapshot is complete, the connector continuously captures subsequent row-level changes that occur.\n+By first establishing a consistent view of all of the data, the connector can continue reading without having lost any of the changes that were made while the snapshot was taking place.\n+\n+The {prodname} SQL Server connector is tolerant of failures.\n+As the connector reads changes and produces events, it records the position in the database log (_LSN / Log Sequence Number_) for each event.\n+If the connector stops for any reason (including communication failures, network problems, or crashes), after a restart the connector resumes reading the SQL Server _CDC_ tables from the last point that it read.\n+Fault tolerance also applies to snapshots. \n+That is, if the connector stops during a snapshot, the connector begins a news snapshot when it restarts.\n \n // Type: assembly\n // ModuleID: how-debezium-sql-server-connectors-work\n // Title: How {prodname} SQL Server connectors work\n [[how-the-sqlserver-connector-works]]\n == How the SQL Server connector works\n \n+To optimally configure and run a {prodname} SQL Server connector, it is helpful to understand how the connector performs snapshots, streams change events, determines Kafka topic names, and uses metadata. \n+ifdef::product[]\n+For details about how the connector works, see the following sections: \n+\n+* xref:how-debezium-sql-server-connectors-perform-database-snapshots[]\n+* xref:how-the-debezium-sql-server-connector-reads-change-data-tables[]\n+* xref:default-names-of-kafka-topics-that-receive-debezium-sql-server-change-event-records[]\n+* xref:how-the-debezium-SQL Server connector-uses-the-schema-change-topic[]\n+* xref:descriptions-of-debezium-sql-server-connector-data-change-events[]\n+* xref:debezium-sql-server-connector-generated-events-that-represent-transaction-boundaries[]\n+* xref:how-debezium-SQL Server-connectors-map-data-types[]\n+endif::product[]\n+\n // Type: concept\n // ModuleID: how-debezium-sql-server-connectors-perform-database-snapshots\n // Title: How {prodname} SQL Server connectors perform database snapshots\n [[sqlserver-snapshots]]\n === Snapshots\n \n-SQL Server CDC is not designed to store the complete history of database changes.\n-It is thus necessary that {prodname} establishes the baseline of current database content and streams it to the Kafka.\n-This is achieved via a process called snapshotting.\n+SQL Server CDC is not designed to store a complete history of database changes.\n+For the {prodname} SQL Server connector to establish a baseline for the current state of the database, \n+it uses a process called _snapshotting_.\n \n-By default (snapshotting mode *initial*) the connector will upon the first startup perform an initial _consistent snapshot_ of the database\n-(meaning the structure and data within any tables to be captured as per the connector's filter configuration).\n+You can configure how the connector creates snapshots.\n+By default, the connector's snapshot mode is set to `initial`. \n+Based on this `initial` snapshot mode, the first time that the connector starts, it performs an initial _consistent snapshot_ of the database.\n+This initial snapshot captures the structure and data for any tables that match the criteria defined by the `include` and `exclude` properties that are configured for the connector (for example, `table.include.list`, `column.include.list`, `table.exclude.list`, and so forth).\n \n-Each snapshot consists of the following steps:\n+When the connector creates a snapshot, it completes the following tasks:\n \n-1. Determine the tables to be captured\n-2. Obtain a lock on each of the monitored tables to ensure that no structural changes can occur to any of the tables.\n+1. Determines the tables to be captured.\n+2. Obtains a lock on each of the monitored tables to ensure that no structural changes can occur to any of the tables.\n The level of the lock is determined by `snapshot.isolation.mode` configuration option.\n-3. Read the maximum LSN (\"log sequence number\") position in the server's transaction log.\n-4. Capture the structure of all relevant tables.\n-5. Optionally release the locks obtained in step 2, i.e. the locks are held usually only for a short period of time.\n-6. Scan all of the relevant database tables and schemas as valid at the LSN position read in step 3, and generate a `READ` event for each row and write that event to the appropriate table-specific Kafka topic.\n-7. Record the successful completion of the snapshot in the connector offsets.\n+3. Reads the maximum log sequence number (LSN) position in the server's transaction log.\n+4. Captures the structure of all relevant tables.\n+5. Releases the locks obtained in Step 2, if necessary. In most cases, locks are held for only a short period of time.\n+6. Scans all of the relevant database tables and schemas based on the LSN position that it read in Step 3, generates a `READ` event for each row, and writes the events to the Kafka topic for the table.\n+7. Records the successful completion of the snapshot in the connector offsets.\n+\n \n // Type: concept\n // ModuleID: how-the-debezium-sql-server-connector-reads-change-data-tables\n // Title: How {prodname} SQL Server connectors read change data tables\n === Reading the change data tables\n \n-Upon first start-up, the connector takes a structural snapshot of the structure of the captured tables\n-and persists this information in its internal database history topic.\n-Then the connector identifies a change table for each of the source tables and executes the main loop\n+When the connector first starts, it takes a structural snapshot of the structure of the captured tables\n+and persists this information to its internal database history topic.\n+The connector then identifies a change table for each source table, and completes the following steps.\n \n-1. For each change table read all changes that were created between last stored maximum LSN and current maximum LSN\n-2. Order the read changes incrementally according to commit LSN and change LSN.\n-This ensures that the changes are replayed by {prodname} in the same order as were made to the database.\n-3. Pass commit and change LSNs as offsets to Kafka Connect.\n-4. Store the maximum LSN and repeat the loop.\n+1. For each change table, the connector read all of the changes that were created between the last stored maximum LSN and the current maximum LSN.\n+2. The connector sorts the changes that it reads in ascending order, based on the values of their commit LSN and change LSN.\n+This sorting ensures that the changes are replayed by {prodname} in the order in which they occurred in the database.\n+3. The connector passes the commit and change LSNs as offsets to Kafka Connect.\n+4. The connector store the maximum LSN and restarts the process from Step 1.", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MDY0Nw==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528590647", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The SQL Server connector writes events for all `INSERT`, `UPDATE`, and `DELETE` operations on a single table to a single Kafka topic. \n          \n          \n            \n            The SQL Server connector writes events for all `INSERT`, `UPDATE`, and `DELETE` operations for a given table to a single Kafka topic.", "author": "gunnarmorling", "createdAt": "2020-11-23T10:08:24Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -103,9 +145,16 @@ The connector is able to detect whether CDC is enabled or disabled for included\n [[sqlserver-topic-names]]\n === Topic names\n \n-The SQL Server connector writes events for all insert, update, and delete operations on a single table to a single Kafka topic. The name of the Kafka topics always takes the form _serverName_._schemaName_._tableName_, where _serverName_ is the logical name of the connector as specified with the `database.server.name` configuration property, _schemaName_ is the name of the schema where the operation occurred, and _tableName_ is the name of the database table on which the operation occurred.\n+The SQL Server connector writes events for all `INSERT`, `UPDATE`, and `DELETE` operations on a single table to a single Kafka topic. ", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MDg5OQ==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528590899", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The name of the Kafka topics always takes the form _serverName_._schemaName_._tableName_.\n          \n          \n            \n            The name of the Kafka topics by default takes the form _serverName_._schemaName_._tableName_.\n          \n      \n    \n    \n  \n\n(the logic table router can adjust this)", "author": "gunnarmorling", "createdAt": "2020-11-23T10:08:50Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -103,9 +145,16 @@ The connector is able to detect whether CDC is enabled or disabled for included\n [[sqlserver-topic-names]]\n === Topic names\n \n-The SQL Server connector writes events for all insert, update, and delete operations on a single table to a single Kafka topic. The name of the Kafka topics always takes the form _serverName_._schemaName_._tableName_, where _serverName_ is the logical name of the connector as specified with the `database.server.name` configuration property, _schemaName_ is the name of the schema where the operation occurred, and _tableName_ is the name of the database table on which the operation occurred.\n+The SQL Server connector writes events for all `INSERT`, `UPDATE`, and `DELETE` operations on a single table to a single Kafka topic. \n+The name of the Kafka topics always takes the form _serverName_._schemaName_._tableName_.", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODk0MjIwNQ==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528942205", "bodyText": "I made the change to specify that it's the default vs. an always thing.\nWhen you say that the logic table router can adjust the default behavior ...\nIs this configured through Custom topic auto creation?", "author": "roldanbob", "createdAt": "2020-11-23T19:24:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MDg5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTIzNjU3NQ==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r529236575", "bodyText": "@gunnarmorling IMHO the naminig always takes the described form unless an SMT is used. Now the wording implies that it is something that can be change by configuration.", "author": "jpechane", "createdAt": "2020-11-24T06:46:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MDg5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTQyMTMwOQ==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r529421309", "bodyText": "Is this configured through Custom topic auto creation?\n\nI meant the logical topic router, see here: https://debezium.io/documentation/reference/1.3/configuration/topic-routing.html. So it should be something like this:\n\nThe name of the Kafka topics by default takes the form serverName.schemaName.tableName. If this default isn't suitable for your requirements, you can customize the topic naming by using the logical topic routing SMT (link)...", "author": "gunnarmorling", "createdAt": "2020-11-24T10:30:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MDg5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MTQ4MA==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528591480", "bodyText": "See comment elsewhere re \"tracked\". Worth a generic grep.", "author": "gunnarmorling", "createdAt": "2020-11-23T10:09:51Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -1213,19 +1289,51 @@ The `connect.decimal.precision` schema parameter contains an integer that repres\n [[setting-up-sqlserver]]\n == Setting up SQL Server\n \n-Before using the SQL Server connector to monitor the changes committed on SQL Server, first enable _CDC_ on a monitored database.\n-Please bear in mind that _CDC_ cannot be enabled for the `primary` database.\n+For {prodname} to capture change events from SQL Server tables, a SQL Server administrator with the necessary privileges must first run a query to enable CDC on the database. \n+The administrator must then enable CDC for each table to be tracked.   \n+\n+For details about setting up SQL Server for use with the {prodname} connector, see the following sections:\n+\n+ifdef::product[]\n+* xref:enabling-cdc-on the-sql-server-database[]\n+* xref:enabling-cdc-on-a-sql-server-table[]\n+* xref:verifying-debezium-connector-access-to-the-cdc-table[]\n+* xref:debezium-sql-server-connector-on-azure[]\n+endif::product[]\n+\n+After CDC is applied, it captures all of the `INSERT`, `UPDATE`, and `DELETE` operations that are committed to tracked tables.", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MzUxNQ==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528593515", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            <.> Specifies the name of the table that you want to track.\n          \n          \n            \n            <.> Specifies the name of the table that you want to capture.", "author": "gunnarmorling", "createdAt": "2020-11-23T10:13:25Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -1236,52 +1344,98 @@ GO\n // ModuleID: enabling-cdc-on-a-sql-server-table\n === Enabling CDC on a SQL Server table\n \n-Then enable _CDC_ for each table that you plan to monitor.\n+A SQL Server administrator must enable change data capture on the source tables that you want to track.\n+The database must already be enabled for CDC.\n+To enable CDC on a table, a SQL Server administrator runs the stored procedure `sys.sp_cdc_enable_table` for the table.\n+The stored procedures can be run by using SQL Server Management Studio, or by using Transact-SQL.\n+SQL Server CDC must be enabled for every table that you want to track. \n+\n+.Prerequisites\n+* CDC is enabled on the SQL Server database.\n+* The SQL Server Agent is running.  \n+* You are a member of the `db_owner` fixed database role for the database. \n \n+.Procedure\n+. From the *View* menu in SQL Server Management Studio, click *Template Explorer*.\n+. In the *Template Browser*, expand *SQL Server Templates*.\n+. Expand *Change Data Capture > Configuration*, and then click *Enable Table Specifying Filegroup Option*.  \n+. In the template, replace the table name in the `USE` statement with the name of the table that you want to track.\n+. Run the stored procedure `sys.sp_cdc_enable_table`.\n++ \n+The following example shows how to enable CDC for the table `MyTable`:\n++\n+.Example: Enabling CDC for a SQL Server table\n [source,sql]\n ----\n--- ====\n--- Enable a Table Specifying Filegroup Option Template\n--- ====\n USE MyDB\n GO\n \n EXEC sys.sp_cdc_enable_table\n @source_schema = N'dbo',\n-@source_name   = N'MyTable',\n-@role_name     = N'MyRole',\n-@filegroup_name = N'MyDB_CT',\n+@source_name   = N'MyTable', //<.>\n+@role_name     = N'MyRole',  //<.>\n+@filegroup_name = N'MyDB_CT',//<.>\n @supports_net_changes = 0\n GO\n ----\n+<.> Specifies the name of the table that you want to track.", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5Mzk2MA==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528593960", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            // Title: URefreshing capture tables after a schema change \n          \n          \n            \n            // Title: Refreshing capture tables after a schema change", "author": "gunnarmorling", "createdAt": "2020-11-23T10:14:08Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -1900,80 +2072,90 @@ database.history.consumer.ssl.key.password=test1234\n \n Be sure to consult the {link-kafka-docs}.html[Kafka documentation] for all of the configuration properties for Kafka producers and consumers. (The SQL Server connector does use the {link-kafka-docs}.html#newconsumerconfigs[new consumer].)\n \n+\n // Type: assembly\n-// ModuleID: updates-to-refresh-capture-tables-after-a-schema-change\n-// Title: Updates required to refresh capture tables after a schema change \n+// ModuleID: refreshing-capture-tables-after-a-schema-change\n+// Title: URefreshing capture tables after a schema change ", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5NDc2NA==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528594764", "bodyText": "I think the title casing still is rather inconsistent. I don't think we used upper-casing most of the times. So perhaps refrain from doing it here, or do it consistently everywhere?", "author": "gunnarmorling", "createdAt": "2020-11-23T10:15:26Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -2098,7 +2279,7 @@ include::{partialsdir}/modules/all-connectors/ref-connector-monitoring-streaming\n // ModuleID: debezium-sql-server-connector-schema-history-metrics\n // Title: {prodname} SQL Server connector schema history metrics\n [[sqlserver-schema-history-metrics]]\n-==== Schema history metrics\n+==== Schema History Metrics", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MjU3OA==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528592578", "bodyText": "Wrong apostrophes?", "author": "jpechane", "createdAt": "2020-11-23T10:11:42Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -1213,19 +1289,51 @@ The `connect.decimal.precision` schema parameter contains an integer that repres\n [[setting-up-sqlserver]]\n == Setting up SQL Server\n \n-Before using the SQL Server connector to monitor the changes committed on SQL Server, first enable _CDC_ on a monitored database.\n-Please bear in mind that _CDC_ cannot be enabled for the `primary` database.\n+For {prodname} to capture change events from SQL Server tables, a SQL Server administrator with the necessary privileges must first run a query to enable CDC on the database. \n+The administrator must then enable CDC for each table to be tracked.   \n+\n+For details about setting up SQL Server for use with the {prodname} connector, see the following sections:\n+\n+ifdef::product[]\n+* xref:enabling-cdc-on the-sql-server-database[]\n+* xref:enabling-cdc-on-a-sql-server-table[]\n+* xref:verifying-debezium-connector-access-to-the-cdc-table[]\n+* xref:debezium-sql-server-connector-on-azure[]\n+endif::product[]\n+\n+After CDC is applied, it captures all of the `INSERT`, `UPDATE`, and `DELETE` operations that are committed to tracked tables.\n+The {prodname} connector can then capture these events and emit them to Kafka topics.\n \n // Type: procedure\n // ModuleID: enabling-cdc-on the-sql-server-database\n === Enabling CDC on the SQL Server database\n \n+Before you can enable CDC for a table, you must enable it for the SQL Server database.\n+A SQL Server administrator enables CDC by running a system stored procedure. \n+System stored procedures can be run by using SQL Server Management Studio, or by using Transact-SQL.\n+\n+.Prerequisites\n+* You are a member of the _sysadmin_ fixed server role for the SQL Server.\n+* You are a db_owner of the database. \n+* The SQL Server Agent is running.  \n+\n+NOTE: The SQL Server CDC feature tracks changes to user-created tables only. You cannot enable CDC on the SQL Server `master` database.\n+\n+.Procedure\n+\n+. From the *View* menu in SQL Server Management Studio, click *Template Explorer*.\n+. In the *Template Browser*, expand *SQL Server Templates*.\n+. Expand *Change Data Capture > Configuration* and then click *Enable Database for CDC*.  \n+. In the template, replace the database name in the `USE` statement with the name of the database that you want to enable for CDC.\n+. Run the stored procedure `sys.sp_cdc_enable_db` to enable the database for CDC.\n++\n+After the database is enabled for CDC, a schema with the name \u2018cdc\u2019 is created, along with a CDC user, metadata tables, and other system objects.", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5NDM0NQ==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528594345", "bodyText": "Emphasize around CDC can be removed", "author": "jpechane", "createdAt": "2020-11-23T10:14:44Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -1236,52 +1344,98 @@ GO\n // ModuleID: enabling-cdc-on-a-sql-server-table\n === Enabling CDC on a SQL Server table\n \n-Then enable _CDC_ for each table that you plan to monitor.\n+A SQL Server administrator must enable change data capture on the source tables that you want to track.\n+The database must already be enabled for CDC.\n+To enable CDC on a table, a SQL Server administrator runs the stored procedure `sys.sp_cdc_enable_table` for the table.\n+The stored procedures can be run by using SQL Server Management Studio, or by using Transact-SQL.\n+SQL Server CDC must be enabled for every table that you want to track. \n+\n+.Prerequisites\n+* CDC is enabled on the SQL Server database.\n+* The SQL Server Agent is running.  \n+* You are a member of the `db_owner` fixed database role for the database. \n \n+.Procedure\n+. From the *View* menu in SQL Server Management Studio, click *Template Explorer*.\n+. In the *Template Browser*, expand *SQL Server Templates*.\n+. Expand *Change Data Capture > Configuration*, and then click *Enable Table Specifying Filegroup Option*.  \n+. In the template, replace the table name in the `USE` statement with the name of the table that you want to track.\n+. Run the stored procedure `sys.sp_cdc_enable_table`.\n++ \n+The following example shows how to enable CDC for the table `MyTable`:\n++\n+.Example: Enabling CDC for a SQL Server table\n [source,sql]\n ----\n--- ====\n--- Enable a Table Specifying Filegroup Option Template\n--- ====\n USE MyDB\n GO\n \n EXEC sys.sp_cdc_enable_table\n @source_schema = N'dbo',\n-@source_name   = N'MyTable',\n-@role_name     = N'MyRole',\n-@filegroup_name = N'MyDB_CT',\n+@source_name   = N'MyTable', //<.>\n+@role_name     = N'MyRole',  //<.>\n+@filegroup_name = N'MyDB_CT',//<.>\n @supports_net_changes = 0\n GO\n ----\n+<.> Specifies the name of the table that you want to track.\n+<.> Specifies a role `MyRole` to which you can add users to whom you want to grant `SELECT` permission on the captured columns of the source table. \n+Users in the `sysadmin` or `db_owner` role also have access to the specified change tables. Set the value of `@role_name` to `NULL`, to allow only members in the `sysadmin` or `db_owner` to have full access to captured information.\n+<.> Specifies the `filegroup` where SQL Server places the change table for the captured table. \n+The named `filegroup` must already exist. \n+It is best not to locate change tables in the same `filegroup` that you use for source tables.\n+\n \n // Type: procedure\n // ModuleID: verifying-debezium-connector-access-to-the-cdc-table\n-=== Verifying that the user has access to the CDC table\n+=== Verifying that the user has access to the _CDC_ table", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5NTE3NA==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528595174", "bodyText": "Same as above", "author": "jpechane", "createdAt": "2020-11-23T10:16:10Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -1236,52 +1344,98 @@ GO\n // ModuleID: enabling-cdc-on-a-sql-server-table\n === Enabling CDC on a SQL Server table\n \n-Then enable _CDC_ for each table that you plan to monitor.\n+A SQL Server administrator must enable change data capture on the source tables that you want to track.\n+The database must already be enabled for CDC.\n+To enable CDC on a table, a SQL Server administrator runs the stored procedure `sys.sp_cdc_enable_table` for the table.\n+The stored procedures can be run by using SQL Server Management Studio, or by using Transact-SQL.\n+SQL Server CDC must be enabled for every table that you want to track. \n+\n+.Prerequisites\n+* CDC is enabled on the SQL Server database.\n+* The SQL Server Agent is running.  \n+* You are a member of the `db_owner` fixed database role for the database. \n \n+.Procedure\n+. From the *View* menu in SQL Server Management Studio, click *Template Explorer*.\n+. In the *Template Browser*, expand *SQL Server Templates*.\n+. Expand *Change Data Capture > Configuration*, and then click *Enable Table Specifying Filegroup Option*.  \n+. In the template, replace the table name in the `USE` statement with the name of the table that you want to track.\n+. Run the stored procedure `sys.sp_cdc_enable_table`.\n++ \n+The following example shows how to enable CDC for the table `MyTable`:\n++\n+.Example: Enabling CDC for a SQL Server table\n [source,sql]\n ----\n--- ====\n--- Enable a Table Specifying Filegroup Option Template\n--- ====\n USE MyDB\n GO\n \n EXEC sys.sp_cdc_enable_table\n @source_schema = N'dbo',\n-@source_name   = N'MyTable',\n-@role_name     = N'MyRole',\n-@filegroup_name = N'MyDB_CT',\n+@source_name   = N'MyTable', //<.>\n+@role_name     = N'MyRole',  //<.>\n+@filegroup_name = N'MyDB_CT',//<.>\n @supports_net_changes = 0\n GO\n ----\n+<.> Specifies the name of the table that you want to track.\n+<.> Specifies a role `MyRole` to which you can add users to whom you want to grant `SELECT` permission on the captured columns of the source table. \n+Users in the `sysadmin` or `db_owner` role also have access to the specified change tables. Set the value of `@role_name` to `NULL`, to allow only members in the `sysadmin` or `db_owner` to have full access to captured information.\n+<.> Specifies the `filegroup` where SQL Server places the change table for the captured table. \n+The named `filegroup` must already exist. \n+It is best not to locate change tables in the same `filegroup` that you use for source tables.\n+\n \n // Type: procedure\n // ModuleID: verifying-debezium-connector-access-to-the-cdc-table\n-=== Verifying that the user has access to the CDC table\n+=== Verifying that the user has access to the _CDC_ table\n+\n+A SQL Server administrator can run a system stored procedure to query a database or table to retrieve its CDC configuration information.\n+The stored procedures can be run by using SQL Server Management Studio, or by using Transact-SQL.\n+\n+.Prerequisites\n+* You have `SELECT` permission on all of the captured columns of the capture instance. \n+Members of the `db_owner` database role can view information for all of the defined capture instances.\n+* You have membership in any gating roles that are defined for the table information that the query includes. \n+\n+.Procedure\n \n-Verify that the user have access to the _CDC_ table.\n+. From the *View* menu in SQL Server Management Studio, click *Object Explorer*.\n+. From the Object Explorer, expand *Databases*, and then expand your database object, for example, *MyDB*. \n+. Expand *Programmability > Stored Procedures > System Stored Procedures*.\n+. Run the `sys.sp_cdc_help_change_data_capture` stored procedure to query the table.\n++\n+Queries should not return empty results.\n++\n+The following example runs the stored precedure `sys.sp_cdc_help_change_data_capture` on the database `MyDB`:\n++\n+.Example: Querying a table for CDC configuration information\n [source, sql]\n ----\n--- ====\n--- Verify the user of the connector have access, this query should not have empty result\n--- ====\n-\n+USE MyDB;\n+GO\n EXEC sys.sp_cdc_help_change_data_capture\n GO\n ----\n-If the result is empty then please make sure that the user has privileges to access both the capture instance and _CDC_ tables.\n++\n+The query returns configuration information for each table in the database that is enabled for CDC and that contains change data that the caller is authorized to access.\n+If the result is empty, verify that the user has privileges to access both the capture instance and the _CDC_ tables.", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5NzYyNw==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528597627", "bodyText": "Should be renderd for product only?", "author": "jpechane", "createdAt": "2020-11-23T10:20:13Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -1314,10 +1473,20 @@ Restart your Kafka Connect process to pick up the new JAR files.\n \n If you are working with immutable containers, see link:https://hub.docker.com/r/debezium/[{prodname}'s container images] for Zookeeper, Kafka, SQL Server and Kafka Connect with the SQL Server connector already installed and ready to run. You can also xref:operations/openshift.adoc[run {prodname} on Kubernetes and OpenShift].\n endif::community[]\n+For details about deploying the {prodname} SQL Server connector, see the following topics:", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5NzkyMw==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528597923", "bodyText": "Not MySQL", "author": "jpechane", "createdAt": "2020-11-23T10:20:45Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -1314,10 +1473,20 @@ Restart your Kafka Connect process to pick up the new JAR files.\n \n If you are working with immutable containers, see link:https://hub.docker.com/r/debezium/[{prodname}'s container images] for Zookeeper, Kafka, SQL Server and Kafka Connect with the SQL Server connector already installed and ready to run. You can also xref:operations/openshift.adoc[run {prodname} on Kubernetes and OpenShift].\n endif::community[]\n+For details about deploying the {prodname} SQL Server connector, see the following topics:\n+\n+* xref:installing-debezium-mysql-connectors[]\n+* xref:debezium-sql-server-connector-configuration-example[]\n+* xref:adding-sql-server-connector-configuration-to-kafka-connect[]\n+* xref:descriptions-of-debezium-sql-server-connector-configuration-properties[]\n \n ifdef::product[]\n To deploy a {prodname} SQL Server connector, install the {prodname} SQL Server connector archive, configure the connector, and start the connector by adding its configuration to Kafka Connect. \n \n+// Type: procedure\n+// Title: Installing {prodname} SQL Server connectors\n+[id=\"installing-debezium-mysql-connectors\"]", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODk1MDE4MA==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528950180", "bodyText": "Oh! Good catch! I didn't notice that at all. Thank you!", "author": "roldanbob", "createdAt": "2020-11-23T19:38:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5NzkyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYwMDMxMQ==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528600311", "bodyText": "Typo?", "author": "jpechane", "createdAt": "2020-11-23T10:24:48Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -1900,80 +2072,90 @@ database.history.consumer.ssl.key.password=test1234\n \n Be sure to consult the {link-kafka-docs}.html[Kafka documentation] for all of the configuration properties for Kafka producers and consumers. (The SQL Server connector does use the {link-kafka-docs}.html#newconsumerconfigs[new consumer].)\n \n+\n // Type: assembly\n-// ModuleID: updates-to-refresh-capture-tables-after-a-schema-change\n-// Title: Updates required to refresh capture tables after a schema change \n+// ModuleID: refreshing-capture-tables-after-a-schema-change\n+// Title: URefreshing capture tables after a schema change ", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYwMDk5Mg==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528600992", "bodyText": "Broken link", "author": "jpechane", "createdAt": "2020-11-23T10:25:56Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -1900,80 +2072,90 @@ database.history.consumer.ssl.key.password=test1234\n \n Be sure to consult the {link-kafka-docs}.html[Kafka documentation] for all of the configuration properties for Kafka producers and consumers. (The SQL Server connector does use the {link-kafka-docs}.html#newconsumerconfigs[new consumer].)\n \n+\n // Type: assembly\n-// ModuleID: updates-to-refresh-capture-tables-after-a-schema-change\n-// Title: Updates required to refresh capture tables after a schema change \n+// ModuleID: refreshing-capture-tables-after-a-schema-change\n+// Title: URefreshing capture tables after a schema change \n [[sqlserver-schema-evolution]]\n === Database schema evolution\n \n-{prodname} is able to capture schema changes over time.\n-Due to the way CDC is implemented in SQL Server, it is necessary to work in co-operation with a database operator in order to ensure the connector continues to produce data change events when the schema is updated.\n+When change data capture is enabled for a SQL Server table, as changes occur in the table, event records are persisted to a capture table on the server.\n+If you introduce a change in the structure of the source table change, for example, by adding a new column, that change is not dynamically reflected in the change table.\n+For as long as the capture table continues to use the outdated schema, the {prodname} connector is unable to emit data change events for the table correctly.\n+You must intervene to refresh the capture table to enable the connector to resume processing change events.   \n+ \n+Because of the way that CDC is implemented in SQL Server, you cannot use {prodname} to update capture tables.\n+To refresh capture tables, one must be a SQL Server database operator with elevated privileges can.\n+As a {prodname} user, you must coordinate tasks with the SQL Server database operator to complete the schema refresh and restore streaming to Kafka topics.    \n \n-As was already mentioned before, {prodname} uses SQL Server's change data capture functionality.\n-This means that SQL Server creates a capture table that contains all changes executed on the source table.\n-Unfortunately, the capture table is static and needs to be updated when the source table structure changes.\n-This update is not done by the connector itself but must be executed by an operator with elevated privileges.\n+You can use one of the following methods to update capture tables after a schema change:\n \n-There are generally two procedures how to execute the schema change:\n+* xref:cold-schema-updates[]. In cold schema updates, capture tables are updated after you stop {prodname}.\n+* xref:hot-schema-updates[]. In hot schema updates, capture tables are updated while {prodname} is running.", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODk1MjUxMw==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528952513", "bodyText": "Added missing hot-schema-updates anchor id.", "author": "roldanbob", "createdAt": "2020-11-23T19:42:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYwMDk5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYwMTgyNw==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528601827", "bodyText": "Is this correct sentence?", "author": "jpechane", "createdAt": "2020-11-23T10:27:22Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -1900,80 +2072,90 @@ database.history.consumer.ssl.key.password=test1234\n \n Be sure to consult the {link-kafka-docs}.html[Kafka documentation] for all of the configuration properties for Kafka producers and consumers. (The SQL Server connector does use the {link-kafka-docs}.html#newconsumerconfigs[new consumer].)\n \n+\n // Type: assembly\n-// ModuleID: updates-to-refresh-capture-tables-after-a-schema-change\n-// Title: Updates required to refresh capture tables after a schema change \n+// ModuleID: refreshing-capture-tables-after-a-schema-change\n+// Title: URefreshing capture tables after a schema change \n [[sqlserver-schema-evolution]]\n === Database schema evolution\n \n-{prodname} is able to capture schema changes over time.\n-Due to the way CDC is implemented in SQL Server, it is necessary to work in co-operation with a database operator in order to ensure the connector continues to produce data change events when the schema is updated.\n+When change data capture is enabled for a SQL Server table, as changes occur in the table, event records are persisted to a capture table on the server.\n+If you introduce a change in the structure of the source table change, for example, by adding a new column, that change is not dynamically reflected in the change table.\n+For as long as the capture table continues to use the outdated schema, the {prodname} connector is unable to emit data change events for the table correctly.\n+You must intervene to refresh the capture table to enable the connector to resume processing change events.   \n+ \n+Because of the way that CDC is implemented in SQL Server, you cannot use {prodname} to update capture tables.\n+To refresh capture tables, one must be a SQL Server database operator with elevated privileges can.", "originalCommit": "064e0141eb65416d0be663ab4ae0b0309944367a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODk1MzM5Mw==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r528953393", "bodyText": "Thanks for catching that. I removed the extra word at the end of the sentence.", "author": "roldanbob", "createdAt": "2020-11-23T19:44:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODYwMTgyNw=="}], "type": "inlineReview"}, {"oid": "11336ff946b795b4a72f57668f026884c4a98bc8", "url": "https://github.com/debezium/debezium/commit/11336ff946b795b4a72f57668f026884c4a98bc8", "message": "DBZ-2782 Update based on review. 1 outstanding comment re: topic names", "committedDate": "2020-11-23T19:49:26Z", "type": "commit"}, {"oid": "c2ff94b823bcaeeaa91fd6bed90f269bbf66ac59", "url": "https://github.com/debezium/debezium/commit/c2ff94b823bcaeeaa91fd6bed90f269bbf66ac59", "message": "DBZ-2782 Add info about customizing default topic naming + minor edits", "committedDate": "2020-11-24T17:05:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjY5NTA0MQ==", "url": "https://github.com/debezium/debezium/pull/1971#discussion_r532695041", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            That is, if the connector stops during a snapshot, the connector begins a news snapshot when it restarts.\n          \n          \n            \n            That is, if the connector stops during a snapshot, the connector begins a new snapshot when it restarts.", "author": "gunnarmorling", "createdAt": "2020-11-30T15:45:40Z", "path": "documentation/modules/ROOT/pages/connectors/sqlserver.adoc", "diffHunk": "@@ -18,82 +21,126 @@ Want to help us further hone and improve it? link:/docs/contribute/[Learn how].\n toc::[]\n endif::community[]\n \n-{prodname}'s SQL Server Connector can monitor and record the row-level changes in the schemas of a SQL Server database.\n+The {prodname} SQL Server connector captures row-level changes that occur in the schemas of a SQL Server database.\n+\n+ifdef::product[]\n+For details about the {prodname} SQL Server connector and its use, see following topics: \n+\n+* xref:overview-of-debezium-sql-server-connector[]\n+* xref:how-debezium-sql-server-connectors-work[]\n+* xref:descriptions-of-debezium-sql-server-connector-data-change-events[]\n+* xref:how-debezium-SQL Server-connectors-map-data-types[]\n+* xref:setting-up-sql-server-for-use-with-the-debezium-sql-server-connector[]\n+* xref:deploying-debezium-sql-server-connectors[]\n+* xref:Monitoring {prodname} SQL Server connector performance[]\n+* xref:how-debezium-postgresql-connectors-handle-faults-and-problems[]\n+\n+endif::product[]\n+\n+The first time that the {prodname} SQL Server connector connects to a SQL Server database or cluster, it takes a consistent snapshot of the schemas in the database.\n+After the initial snapshot is complete, the connector continuously captures row-level changes for `INSERT`, `UPDATE`, or `DELETE` operations that are committed to the SQL Server databases that are enabled for CDC. \n+The connector produces events for each data change operation, and streams them to Kafka topics. \n+The connector streams all of the events for a table to a dedicated Kafka topic.\n+Applications and services can then consume data change event records from that topic.\n \n-The first time it connects to a SQL Server database/cluster, it reads a consistent snapshot of all of the schemas.\n-When that snapshot is complete, the connector continuously streams the changes that were committed to SQL Server and generates corresponding insert, update and delete events.\n-All of the events for each table are recorded in a separate Kafka topic, where they can be easily consumed by applications and services.\n \n // Type: concept\n // Title: Overview of {prodname} SQL Server connector \n // ModuleID: overview-of-debezium-sql-server-connector\n [[sqlserver-overview]]\n == Overview\n \n-The functionality of the connector is based upon https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/about-change-data-capture-sql-server?view=sql-server-2017[change data capture] feature provided by SQL Server Standard (https://blogs.msdn.microsoft.com/sqlreleaseservices/sql-server-2016-service-pack-1-sp1-released/[since SQL Server 2016 SP1]) or Enterprise edition.\n-Using this mechanism a SQL Server capture process monitors all databases and tables the user is interested in and stores the changes into specifically created _CDC_ tables that have stored procedure facade.\n+The {prodname} SQL Server connector is based on the https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/about-change-data-capture-sql-server?view=sql-server-2017[change data capture] \n+feature that is available in https://blogs.msdn.microsoft.com/sqlreleaseservices/sql-server-2016-service-pack-1-sp1-released/[SQL Server 2016 Service Pack 1 (SP1) and later] Standard edition or Enterprise edition.\n+The SQL Server capture process monitors designated databases and tables, and stores the changes into specifically created _change tables_ that have stored procedure facades.\n+\n+To enable the {prodname} SQL Server connector to capture change event records for database operations, \n+you must first enable change data capture on the SQL Server database. \n+CDC must be enabled on both the database and on each table that you want to capture.\n+After you set up CDC on the source database, the connector can capture row-level `INSERT`, `UPDATE`, and `DELETE` operations  \n+that occur in the database.\n+The connector writes event records for each source table to a Kafka topic especially dedicated to that table.\n+One topic exists for each captured table.\n+Client applications read the Kafka topics for the database tables that they follow, and can respond to the row-level events they they consume from those topics.\n+\n+The first time that the connector connects to a SQL Server database or cluster, it takes a consistent snapshot of the schemas for all tables for which it is configured to capture changes,\n+and streams this state to Kafka.\n+After the snapshot is complete, the connector continuously captures subsequent row-level changes that occur.\n+By first establishing a consistent view of all of the data, the connector can continue reading without having lost any of the changes that were made while the snapshot was taking place.\n \n-The database operator must https://docs.microsoft.com/en-us/sql/relational-databases/track-changes/enable-and-disable-change-data-capture-sql-server?view=sql-server-2017[enable] _CDC_ for the table(s) that should be captured by the connector.\n-The connector then produces a _change event_ for every row-level insert, update, and delete operation that was published via the _CDC API_, recording all the change events for each table in a separate Kafka topic.\n-The client applications read the Kafka topics that correspond to the database tables they're interested in following, and react to every row-level event it sees in those topics.\n+The {prodname} SQL Server connector is tolerant of failures.\n+As the connector reads changes and produces events, it periodically records the position of events in the database log (_LSN / Log Sequence Number_).\n+If the connector stops for any reason (including communication failures, network problems, or crashes), after a restart the connector resumes reading the SQL Server _CDC_ tables from the last point that it read.\n \n-The database operator normally enables _CDC_ in the mid-life of a database an/or table.\n-This means that the connector does not have the complete history of all changes that have been made to the database.\n-Therefore, when the SQL Server connector first connects to a particular SQL Server database, it starts by performing a _consistent snapshot_ of each of the database schemas.\n-After the connector completes the snapshot, it continues streaming changes from the exact point at which the snapshot was made.\n-This way, we start with a consistent view of all of the data, yet continue reading without having lost any of the changes made while the snapshot was taking place.\n+NOTE: Offsets are committed periodically. \n+They are not committed at the time that a change event occurs. \n+As a result, following an outage, duplicate events might be generated.\n \n-The connector is also tolerant of failures.\n-As the connector reads changes and produces events, it records the position in the database log (_LSN / Log Sequence Number_), that is associated with _CDC_ record, with each event.\n-If the connector stops for any reason (including communication failures, network problems, or crashes), upon restart it simply continues reading the _CDC_ tables where it last left off.\n-This includes snapshots: if the snapshot was not completed when the connector is stopped, upon restart it begins a new snapshot.\n+Fault tolerance also applies to snapshots. \n+That is, if the connector stops during a snapshot, the connector begins a news snapshot when it restarts.", "originalCommit": "c2ff94b823bcaeeaa91fd6bed90f269bbf66ac59", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "05b3e6b0e187b561a9c49e5f2cd789d322e942ab", "url": "https://github.com/debezium/debezium/commit/05b3e6b0e187b561a9c49e5f2cd789d322e942ab", "message": "DBZ-2782 Typo fix", "committedDate": "2020-11-30T15:49:07Z", "type": "commit"}]}