{"pr_number": 10774, "pr_title": "Backport gateway related patches", "pr_createdAt": "2020-11-16T10:41:33Z", "pr_url": "https://github.com/crate/crate/pull/10774", "timeline": [{"oid": "1148e0740afdc9f7cb8e5dabcb520cbd1d6044d6", "url": "https://github.com/crate/crate/commit/1148e0740afdc9f7cb8e5dabcb520cbd1d6044d6", "message": "bp: Remove remaining TransportAction.execute calls from gateway code\n\nhttps://github.com/elastic/elasticsearch/commit/61de092679b8c2aed166b8e058df248a33608f06", "committedDate": "2020-11-16T15:57:30Z", "type": "commit"}, {"oid": "74dd6202ebd4cf23f6719581beef10226c7a1571", "url": "https://github.com/crate/crate/commit/74dd6202ebd4cf23f6719581beef10226c7a1571", "message": "Regenerate es-backports commit list and include gateway package", "committedDate": "2020-11-16T15:57:30Z", "type": "commit"}, {"oid": "f139aabfaf154149b3c0d220d48789c476fb4454", "url": "https://github.com/crate/crate/commit/f139aabfaf154149b3c0d220d48789c476fb4454", "message": "bp: Re-fetch shard info of primary when new node joins\n\nhttps://github.com/elastic/elasticsearch/commit/caaf02fda30af18f4cd14a078f3e1521ba8ee55e", "committedDate": "2020-11-16T15:57:30Z", "type": "commit"}, {"oid": "4c743d269e86ee0146f20fe9031350c28c096088", "url": "https://github.com/crate/crate/commit/4c743d269e86ee0146f20fe9031350c28c096088", "message": "Remove unused dependencies from Gateway", "committedDate": "2020-11-16T15:57:30Z", "type": "commit"}, {"oid": "7c73e9a08569e22ef53fc1e9c4bfce061b05d445", "url": "https://github.com/crate/crate/commit/7c73e9a08569e22ef53fc1e9c4bfce061b05d445", "message": "bp: Reset state recovery after successful recovery\n\nhttps://github.com/elastic/elasticsearch/commit/692245cc447d748b8233d588bb38cc261227d6f5", "committedDate": "2020-11-16T15:57:30Z", "type": "commit"}, {"oid": "e91639cf8561e048c59ba1947d24f323c6239445", "url": "https://github.com/crate/crate/commit/e91639cf8561e048c59ba1947d24f323c6239445", "message": "bp: Some Cleanup in o.e.gateway Package\n\nhttps://github.com/elastic/elasticsearch/commit/5cadfe7f119838276c91107a09607c3e9fc37a46", "committedDate": "2020-11-16T15:57:30Z", "type": "commit"}, {"oid": "84caa268f4d848f452f6ae556f12951a43a4760a", "url": "https://github.com/crate/crate/commit/84caa268f4d848f452f6ae556f12951a43a4760a", "message": "bp: Load metadata at start time not construction time\n\nhttps://github.com/elastic/elasticsearch/commit/9e3822a8622cfb50494b92a5e5674624da412211", "committedDate": "2020-11-16T15:57:30Z", "type": "commit"}, {"oid": "84caa268f4d848f452f6ae556f12951a43a4760a", "url": "https://github.com/crate/crate/commit/84caa268f4d848f452f6ae556f12951a43a4760a", "message": "bp: Load metadata at start time not construction time\n\nhttps://github.com/elastic/elasticsearch/commit/9e3822a8622cfb50494b92a5e5674624da412211", "committedDate": "2020-11-16T15:57:30Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0NDI5MA==", "url": "https://github.com/crate/crate/pull/10774#discussion_r524944290", "bodyText": "Why do we diverge here from elastic/elasticsearch@61de092#diff-4b3484e2c7a2e90b18ee27be05b638f9de273fa7976d1af077cfde3f353019caR54?\nAfaik it will set nodeIds only to the request to avoid streaming each bigger DiscoveryNode. Any reason to change this?", "author": "seut", "createdAt": "2020-11-17T07:52:48Z", "path": "server/src/main/java/org/elasticsearch/gateway/Gateway.java", "diffHunk": "@@ -41,22 +44,27 @@\n \n     private final ClusterService clusterService;\n \n-    private final TransportNodesListGatewayMetaState listGatewayMetaState;\n+    private final NodeClient client;\n \n     private final IndicesService indicesService;\n \n     public Gateway(final Settings settings, final ClusterService clusterService,\n-                   final TransportNodesListGatewayMetaState listGatewayMetaState,\n+                   final NodeClient client,\n                    final IndicesService indicesService) {\n         this.indicesService = indicesService;\n         this.clusterService = clusterService;\n-        this.listGatewayMetaState = listGatewayMetaState;\n+        this.client = client;\n     }\n \n     public void performStateRecovery(final GatewayStateRecoveredListener listener) throws GatewayException {\n-        DiscoveryNode[] discoveryNodes = clusterService.state().nodes().getMasterNodes().values().toArray(DiscoveryNode.class);\n-        LOGGER.trace(\"performing state recovery from {}\", discoveryNodes);\n-        final TransportNodesListGatewayMetaState.NodesGatewayMetaState nodesState = listGatewayMetaState.list(discoveryNodes, null).actionGet();\n+        final DiscoveryNode[] nodes = clusterService.state().nodes().getMasterNodes().values().toArray(DiscoveryNode.class);", "originalCommit": "1148e0740afdc9f7cb8e5dabcb520cbd1d6044d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk1ODk3OQ==", "url": "https://github.com/crate/crate/pull/10774#discussion_r524958979", "bodyText": "We changed this in  ed18312\nMaybe we could have gone the other way to avoid streaming the bigger DiscoveryNode. Maybe something to revisit later.", "author": "mfussenegger", "createdAt": "2020-11-17T08:13:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0NDI5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk2MDA3Mw==", "url": "https://github.com/crate/crate/pull/10774#discussion_r524960073", "bodyText": "I see, thanks for the info, wasn't aware of this.", "author": "seut", "createdAt": "2020-11-17T08:15:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0NDI5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk2MTQ4Nw==", "url": "https://github.com/crate/crate/pull/10774#discussion_r524961487", "bodyText": "I also forgot about it until I had to look why the cherry-pick conflicted :)", "author": "mfussenegger", "createdAt": "2020-11-17T08:18:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0NDI5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0Nzg4NQ==", "url": "https://github.com/crate/crate/pull/10774#discussion_r524947885", "bodyText": "debug traces? at least the original test does not contain it...", "author": "seut", "createdAt": "2020-11-17T08:00:09Z", "path": "server/src/test/java/org/elasticsearch/gateway/ReplicaShardAllocatorIT.java", "diffHunk": "@@ -0,0 +1,158 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.gateway;\n+\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasItem;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.elasticsearch.action.admin.indices.flush.SyncedFlushAction;\n+import org.elasticsearch.action.admin.indices.flush.SyncedFlushRequest;\n+import org.elasticsearch.action.admin.indices.flush.SyncedFlushResponse;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.index.seqno.ReplicationTracker;\n+import org.elasticsearch.indices.recovery.PeerRecoveryTargetService;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.InternalSettingsPlugin;\n+import org.elasticsearch.test.InternalTestCluster;\n+import org.elasticsearch.test.transport.MockTransportService;\n+import org.elasticsearch.transport.TransportService;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+\n+import io.crate.integrationtests.SQLTransportIntegrationTest;\n+\n+@ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST, numDataNodes = 0)\n+public class ReplicaShardAllocatorIT extends SQLTransportIntegrationTest {\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        var nodePlugins = new ArrayList<>(super.nodePlugins());\n+        nodePlugins.add(MockTransportService.TestPlugin.class);\n+        nodePlugins.add(InternalSettingsPlugin.class);\n+        return nodePlugins;\n+    }\n+\n+    /**\n+     * Ensure that we fetch the latest shard store from the primary when a new node joins so we won't cancel the current recovery\n+     * for the copy on the newly joined node unless we can perform a noop recovery with that node.\n+     */\n+    @Test\n+    @Ignore(\"Fails currently, maybe missing backports\")\n+    public void testRecentPrimaryInformation() throws Exception {\n+        String indexName = \"test\";\n+        String nodeWithPrimary = internalCluster().startNode();\n+\n+        execute(\"\"\"\n+            create table doc.test (x int)\n+            clustered into 1 shards with (\n+                number_of_replicas = 1,\n+                \"recovery.file_based_threshold\" = 1.0,\n+                \"global_checkpoint_sync.interval\" = '100ms',\n+                \"unassigned.node_left.delayed_timeout\" = '1ms'\n+            )\n+        \"\"\");\n+        String nodeWithReplica = internalCluster().startDataOnlyNode();\n+        DiscoveryNode discoNodeWithReplica = internalCluster().getInstance(ClusterService.class, nodeWithReplica).localNode();\n+        Settings nodeWithReplicaSettings = internalCluster().dataPathSettings(nodeWithReplica);\n+        ensureGreen(indexName);\n+        execute(\"insert into doc.test (x) values (?)\", new Object[][] {\n+            new Object[] { randomIntBetween(10, 100) },\n+            new Object[] { randomIntBetween(10, 100) },\n+        });\n+        assertBusy(() -> {\n+            SyncedFlushResponse syncedFlushResponse = client()\n+                .execute(SyncedFlushAction.INSTANCE, new SyncedFlushRequest(indexName))\n+                .actionGet(5, TimeUnit.SECONDS);\n+            assertThat(syncedFlushResponse.successfulShards(), equalTo(2));\n+        });\n+        internalCluster().stopRandomNode(InternalTestCluster.nameFilter(nodeWithReplica));\n+        if (randomBoolean()) {\n+            execute(\"insert into doc.test (x) values (?)\", new Object[][] {\n+                new Object[] { randomIntBetween(10, 100) },\n+                new Object[] { randomIntBetween(10, 100) },\n+            });\n+        }\n+        CountDownLatch blockRecovery = new CountDownLatch(1);\n+        CountDownLatch recoveryStarted = new CountDownLatch(1);\n+        MockTransportService transportServiceOnPrimary\n+            = (MockTransportService) internalCluster().getInstance(TransportService.class, nodeWithPrimary);\n+        transportServiceOnPrimary.addSendBehavior((connection, requestId, action, request, options) -> {\n+            if (PeerRecoveryTargetService.Actions.FILES_INFO.equals(action)) {\n+                recoveryStarted.countDown();\n+                try {\n+                    blockRecovery.await(5, TimeUnit.SECONDS);\n+                } catch (InterruptedException e) {\n+                    Thread.currentThread().interrupt();\n+                }\n+            }\n+            connection.sendRequest(requestId, action, request, options);\n+        });\n+        try {\n+            String newNode = internalCluster().startDataOnlyNode();\n+            recoveryStarted.await(5, TimeUnit.SECONDS);\n+            // Index more documents and flush to destroy sync_id and remove the retention lease (as file_based_recovery_threshold reached).\n+            execute(\"insert into doc.test (x) values (?)\", new Object[][] {\n+                new Object[] { randomIntBetween(10, 100) },\n+                new Object[] { randomIntBetween(10, 100) },\n+            });\n+            execute(\"optimize table doc.test with (flush = true, max_num_segments = 1)\");\n+            assertBusy(() -> {\n+                execute(\"select unnest(retention_leases['leases']['id']) from sys.shards where table_name = 'test'\");\n+                for (var row : response.rows()) {\n+                    assertThat(row[0], not(equalTo((ReplicationTracker.getPeerRecoveryRetentionLeaseId(discoNodeWithReplica.getId())))));\n+                }\n+            });\n+            // AllocationService only calls GatewayAllocator if there are unassigned shards\n+            execute(\"\"\"\n+                create table doc.dummy (x int)\n+                with (\"routing.allocation.require.attr\" = 'not-found')\n+            \"\"\");\n+            internalCluster().startDataOnlyNode(nodeWithReplicaSettings);\n+            // need to wait for events to ensure the reroute has happened since we perform it async when a new node joins.\n+            client().admin().cluster()\n+                .prepareHealth(indexName)\n+                .setWaitForYellowStatus()\n+                .setWaitForEvents(Priority.LANGUID)\n+                .execute()\n+                .get(5, TimeUnit.SECONDS);\n+            blockRecovery.countDown();\n+            ensureGreen(indexName);\n+            assertThat(internalCluster().nodesInclude(indexName), hasItem(newNode));\n+            //for (RecoveryState recovery : client().admin().indices().prepareRecoveries(indexName).get().shardRecoveryStates().get(indexName)) {", "originalCommit": "f139aabfaf154149b3c0d220d48789c476fb4454", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk1OTg1Ng==", "url": "https://github.com/crate/crate/pull/10774#discussion_r524959856", "bodyText": "Right - it came in later in a patch that we already applied - I commented it out because prepareRecoveries doesn't exist in CrateDB and the test currently fails as is before it gets to this line.\nAny suggestion how to handle it?  I suspected the failure my be related to other missing patches in the gateway area which is why I didn't spend too much time debugging.", "author": "mfussenegger", "createdAt": "2020-11-17T08:15:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0Nzg4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk2MTg2Nw==", "url": "https://github.com/crate/crate/pull/10774#discussion_r524961867", "bodyText": "I see. Shall we maybe create an issue for this test (which we could also use at the ignore annotation) to track it?", "author": "seut", "createdAt": "2020-11-17T08:18:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0Nzg4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk3NDIwNQ==", "url": "https://github.com/crate/crate/pull/10774#discussion_r524974205", "bodyText": "As discussed, we'll track that by a project card.", "author": "seut", "createdAt": "2020-11-17T08:39:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0Nzg4NQ=="}], "type": "inlineReview"}]}