{"pr_number": 1216, "pr_title": "Parallel Update Matching Stats & RoundRobin Queues for Queries", "pr_createdAt": "2020-06-02T13:12:40Z", "pr_url": "https://github.com/bakdata/conquery/pull/1216", "timeline": [{"oid": "15f9b62472b3e6c37d14726b95e015fbe831a7c8", "url": "https://github.com/bakdata/conquery/commit/15f9b62472b3e6c37d14726b95e015fbe831a7c8", "message": "Load datasets in parallel", "committedDate": "2020-06-02T13:12:05Z", "type": "commit"}, {"oid": "1d08c5d35f86e76d61db64aeef9156a70832339e", "url": "https://github.com/bakdata/conquery/commit/1d08c5d35f86e76d61db64aeef9156a70832339e", "message": "Merge branch 'develop' into feature/parallel-startup", "committedDate": "2020-06-02T13:12:47Z", "type": "commit"}, {"oid": "d6995b81b87706a05c9436c3381fda2a1f74f68d", "url": "https://github.com/bakdata/conquery/commit/d6995b81b87706a05c9436c3381fda2a1f74f68d", "message": "Each Worker has it's own JobManager now", "committedDate": "2020-06-02T14:22:28Z", "type": "commit"}, {"oid": "bce9c7fadcd42cfb1090824d914580a677ae5265", "url": "https://github.com/bakdata/conquery/commit/bce9c7fadcd42cfb1090824d914580a677ae5265", "message": "Each Worker has it's own JobManager now", "committedDate": "2020-06-02T14:46:51Z", "type": "commit"}, {"oid": "080eaad4e662cbc997251a87659e4eb749ad987d", "url": "https://github.com/bakdata/conquery/commit/080eaad4e662cbc997251a87659e4eb749ad987d", "message": "Refactor startup of JobManager and creation of Worker", "committedDate": "2020-06-03T07:05:40Z", "type": "commit"}, {"oid": "aa0d3d2fd8079ea2eedd36c1c09d458f912aa529", "url": "https://github.com/bakdata/conquery/commit/aa0d3d2fd8079ea2eedd36c1c09d458f912aa529", "message": "Add parallelism for loaders as well", "committedDate": "2020-06-03T08:01:17Z", "type": "commit"}, {"oid": "ddc74b252b5b08e4be57f6ac67308ace1ccad769", "url": "https://github.com/bakdata/conquery/commit/ddc74b252b5b08e4be57f6ac67308ace1ccad769", "message": "Merge aa0d3d2fd8079ea2eedd36c1c09d458f912aa529 into ba996c3747ed3bf0e4854acde49a6ac81a366eb5", "committedDate": "2020-06-03T08:01:26Z", "type": "commit"}, {"oid": "7e422adc66e4d6ff291e5eef4f2e1b43ceaa0637", "url": "https://github.com/bakdata/conquery/commit/7e422adc66e4d6ff291e5eef4f2e1b43ceaa0637", "message": "automatic update to docs", "committedDate": "2020-06-03T08:02:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDUwNTAxMA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r434505010", "bodyText": "Hier sollte es einen lognachricht geben, wenn ein store nicht geladen werden konnte", "author": "thoniTUB", "createdAt": "2020-06-03T11:44:02Z", "path": "backend/src/main/java/com/bakdata/conquery/commands/MasterCommand.java", "diffHunk": "@@ -92,16 +95,26 @@ public void run(ConqueryConfig config, Environment environment) {\n \t\tenvironment.lifecycle().manage(this);\n \n \t\tlog.info(\"Started meta storage\");\n-\t\tfor (File directory : config.getStorage().getDirectory().listFiles()) {\n-\t\t\tif (directory.getName().startsWith(\"dataset_\")) {\n+\n+\t\tExecutorService loaders = Executors.newFixedThreadPool(config.getPreprocessor().getThreads());\n+\n+\n+\t\tfor (File directory : config.getStorage().getDirectory().listFiles((file, name) -> name.startsWith(\"dataset_\"))) {\n+\t\t\tloaders.submit(() -> {\n \t\t\t\tNamespaceStorage datasetStorage = NamespaceStorage.tryLoad(validator, config.getStorage(), directory);\n-\t\t\t\tif (datasetStorage != null) {\n-\t\t\t\t\tNamespace ns = new Namespace(datasetStorage);\n-\t\t\t\t\tns.initMaintenance(maintenanceService);\n-\t\t\t\t\tnamespaces.add(ns);\n+\n+\t\t\t\tif (datasetStorage == null) {", "originalCommit": "7e422adc66e4d6ff291e5eef4f2e1b43ceaa0637", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDUwNzE5NQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r434507195", "bodyText": "Im SlaveCommand nimmst du config.getStorage().getThreads(). Das ist denke ich besser", "author": "thoniTUB", "createdAt": "2020-06-03T11:48:20Z", "path": "backend/src/main/java/com/bakdata/conquery/commands/MasterCommand.java", "diffHunk": "@@ -92,16 +95,26 @@ public void run(ConqueryConfig config, Environment environment) {\n \t\tenvironment.lifecycle().manage(this);\n \n \t\tlog.info(\"Started meta storage\");\n-\t\tfor (File directory : config.getStorage().getDirectory().listFiles()) {\n-\t\t\tif (directory.getName().startsWith(\"dataset_\")) {\n+\n+\t\tExecutorService loaders = Executors.newFixedThreadPool(config.getPreprocessor().getThreads());", "originalCommit": "7e422adc66e4d6ff291e5eef4f2e1b43ceaa0637", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDUwODQ5Nw==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r434508497", "bodyText": "kann hier nicht alles bis auf diese Zeile aus dem try-block raus", "author": "thoniTUB", "createdAt": "2020-06-03T11:50:56Z", "path": "backend/src/main/java/com/bakdata/conquery/commands/SlaveCommand.java", "diffHunk": "@@ -228,9 +242,18 @@ public void stop() throws Exception {\n \t}\n \tprivate void reportJobManagerStatus() {\n \t\ttry {\n-\t\t\tif(context!= null && context.isConnected()) {\n-\t\t\t\tcontext.trySend(new UpdateJobManagerStatus(jobManager.reportStatus()));\n+\t\t\tif (context == null || !context.isConnected()) {\n+\t\t\t\treturn;\n \t\t\t}\n+\n+\t\t\t// Collect the Slaves and all its workers jobs into a single queue\n+\t\t\tfinal JobManagerStatus jobManagerStatus = jobManager.reportStatus();\n+\n+\t\t\tfor (Worker worker : workers.getWorkers().values()) {\n+\t\t\t\tjobManagerStatus.getJobs().addAll(worker.getJobManager().reportStatus().getJobs());\n+\t\t\t}\n+\n+\t\t\tcontext.trySend(new UpdateJobManagerStatus(jobManagerStatus));", "originalCommit": "7e422adc66e4d6ff291e5eef4f2e1b43ceaa0637", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDUxNjcxOA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r434516718", "bodyText": "wie wir es besprochen haben, gibt es hier abh\u00e4ngigkeiten. Um die abh\u00e4ngigkeiten leicht zu managen, k\u00f6nntest du den executerservice an den store geben und der k\u00fcmmert sich selber darum auf welches store-loading er warten muss, bzw. welche er gleichzeitig starten kann.", "author": "thoniTUB", "createdAt": "2020-06-03T12:06:32Z", "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/ConqueryStorageImpl.java", "diffHunk": "@@ -47,12 +52,21 @@ public void loadData() {\n \t\tlog.info(\"Loading storage {} from {}\", this.getClass().getSimpleName(), directory);\n \n \t\ttry (final Timer.Context timer = JobMetrics.getStoreLoadingTimer()) {\n+\t\t\tfinal ExecutorService loaders = Executors.newFixedThreadPool(nThreads);\n+\n \t\t\tStopwatch all = Stopwatch.createStarted();\n \t\t\tfor (KeyIncludingStore<?, ?> store : stores) {", "originalCommit": "7e422adc66e4d6ff291e5eef4f2e1b43ceaa0637", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDU0MjUzNg==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r434542536", "bodyText": "Ich finde es nicht so toll wo die start und stop methoden f\u00fcr den manager aufgerufen werden", "author": "thoniTUB", "createdAt": "2020-06-03T12:52:04Z", "path": "backend/src/main/java/com/bakdata/conquery/models/worker/Worker.java", "diffHunk": "@@ -1,40 +1,54 @@\n package com.bakdata.conquery.models.worker;\n \n+import java.io.Closeable;\n+import java.io.IOException;\n+\n import com.bakdata.conquery.io.mina.MessageSender;\n import com.bakdata.conquery.io.mina.NetworkSession;\n import com.bakdata.conquery.io.xodus.WorkerStorage;\n+import com.bakdata.conquery.models.config.ConqueryConfig;\n import com.bakdata.conquery.models.events.BucketManager;\n import com.bakdata.conquery.models.jobs.JobManager;\n+import com.bakdata.conquery.models.jobs.SimpleJob;\n import com.bakdata.conquery.models.messages.namespaces.NamespaceMessage;\n import com.bakdata.conquery.models.messages.network.MasterMessage;\n import com.bakdata.conquery.models.messages.network.NetworkMessage;\n import com.bakdata.conquery.models.messages.network.specific.ForwardToNamespace;\n import com.bakdata.conquery.models.query.QueryExecutor;\n+import lombok.AccessLevel;\n import lombok.Getter;\n+import lombok.RequiredArgsConstructor;\n import lombok.Setter;\n \n-import java.io.Closeable;\n-import java.io.IOException;\n-\n+@RequiredArgsConstructor(access = AccessLevel.PRIVATE)\n public class Worker implements MessageSender.Transforming<NamespaceMessage, NetworkMessage<?>>, Closeable {\n+\n+\t@Getter\n+\tprivate final WorkerInformation info;\n+\n \t@Getter\n \tprivate final JobManager jobManager;\n+\n \t@Getter\n \tprivate final WorkerStorage storage;\n+\n \t@Getter\n \tprivate final QueryExecutor queryExecutor;\n-\t@Getter\n-\tprivate final WorkerInformation info;\n+\n \t@Setter\n \tprivate NetworkSession session;\n-\t\n-\tpublic Worker(WorkerInformation info, JobManager jobManager, WorkerStorage storage, QueryExecutor queryExecutor) {\n-\t\tthis.info = info;\n-\t\tthis.jobManager = jobManager;\n-\t\tthis.storage = storage;\n-\t\tBucketManager bucketManager = new BucketManager(jobManager, storage, this);\n+\n+\n+\tpublic static Worker createWorker(WorkerInformation info, WorkerStorage storage, ConqueryConfig config) {\n+\t\tfinal JobManager jobManager = new JobManager(info.getName());", "originalCommit": "7e422adc66e4d6ff291e5eef4f2e1b43ceaa0637", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "c68a84c1e1493db35482958ceff698c52f666701", "url": "https://github.com/bakdata/conquery/commit/c68a84c1e1493db35482958ceff698c52f666701", "message": "move parallel loading into WorkerStorageImpl", "committedDate": "2020-06-03T12:57:31Z", "type": "commit"}, {"oid": "d41d35667f2020b8320a2c032c51bffb559a07c5", "url": "https://github.com/bakdata/conquery/commit/d41d35667f2020b8320a2c032c51bffb559a07c5", "message": "wip: return stores as futures.", "committedDate": "2020-06-03T15:27:24Z", "type": "commit"}, {"oid": "58d33397cca8ff1ba68e496425f6c59928f153d6", "url": "https://github.com/bakdata/conquery/commit/58d33397cca8ff1ba68e496425f6c59928f153d6", "message": "fix loading order of storages", "committedDate": "2020-06-03T15:59:58Z", "type": "commit"}, {"oid": "2792d2102a5de424a5669fd4560e54e0378a1e81", "url": "https://github.com/bakdata/conquery/commit/2792d2102a5de424a5669fd4560e54e0378a1e81", "message": "small refactoring", "committedDate": "2020-06-04T10:06:58Z", "type": "commit"}, {"oid": "2be2828acb0d01aaff8c044568b5dedc7c733242", "url": "https://github.com/bakdata/conquery/commit/2be2828acb0d01aaff8c044568b5dedc7c733242", "message": "fix loading order", "committedDate": "2020-06-04T11:29:40Z", "type": "commit"}, {"oid": "eea0609de06df674842e056108d00eda09c645a9", "url": "https://github.com/bakdata/conquery/commit/eea0609de06df674842e056108d00eda09c645a9", "message": "Parallelize by Concepts instead of CBlocks for trivial parallelism", "committedDate": "2020-06-04T15:23:31Z", "type": "commit"}, {"oid": "9c5b86cea96016258f00621ee16c389b0287fdd0", "url": "https://github.com/bakdata/conquery/commit/9c5b86cea96016258f00621ee16c389b0287fdd0", "message": "fix not waiting for pool to shutdown", "committedDate": "2020-06-05T14:19:54Z", "type": "commit"}, {"oid": "ffec1b0ccd800661e228ad14de3cbbb735fc8ae1", "url": "https://github.com/bakdata/conquery/commit/ffec1b0ccd800661e228ad14de3cbbb735fc8ae1", "message": "Add ThreadPool to Worker and make UpdateMatchingStats use that one. TODO other slow jobs should use that one as well.", "committedDate": "2020-06-08T13:27:59Z", "type": "commit"}, {"oid": "3b08b236703696b9edfbe5e8afe19f92da4ac95c", "url": "https://github.com/bakdata/conquery/commit/3b08b236703696b9edfbe5e8afe19f92da4ac95c", "message": "Merge ffec1b0ccd800661e228ad14de3cbbb735fc8ae1 into f9809937bb56d6578449499b4fe786dd19715676", "committedDate": "2020-06-08T13:28:11Z", "type": "commit"}, {"oid": "b51c30ed2fd95f6adc82ca076701f74497935591", "url": "https://github.com/bakdata/conquery/commit/b51c30ed2fd95f6adc82ca076701f74497935591", "message": "automatic update to docs", "committedDate": "2020-06-08T13:30:03Z", "type": "commit"}, {"oid": "e8458d2ab81a9bf33bdabe269bfd93f9735fd634", "url": "https://github.com/bakdata/conquery/commit/e8458d2ab81a9bf33bdabe269bfd93f9735fd634", "message": "fix unescaped % in formatstr", "committedDate": "2020-06-09T07:48:27Z", "type": "commit"}, {"oid": "a02522cffd06fcc6fa3f75e9f803de8fa95d8033", "url": "https://github.com/bakdata/conquery/commit/a02522cffd06fcc6fa3f75e9f803de8fa95d8033", "message": "Merge remote-tracking branch 'origin/feature/parallel-startup' into feature/parallel-startup", "committedDate": "2020-06-09T07:50:30Z", "type": "commit"}, {"oid": "bf93449a8befc9c4c1eac91bd7f8c15f28a6c2de", "url": "https://github.com/bakdata/conquery/commit/bf93449a8befc9c4c1eac91bd7f8c15f28a6c2de", "message": "reduced polling time", "committedDate": "2020-06-12T10:26:15Z", "type": "commit"}, {"oid": "b2be32082902a5389c3f6e4cb7988e3185cf2cd0", "url": "https://github.com/bakdata/conquery/commit/b2be32082902a5389c3f6e4cb7988e3185cf2cd0", "message": "code review changes", "committedDate": "2020-06-15T09:57:17Z", "type": "commit"}, {"oid": "4b6adb4239db6774a5c4185dddc0044500d895bb", "url": "https://github.com/bakdata/conquery/commit/4b6adb4239db6774a5c4185dddc0044500d895bb", "message": "cleanup of loading", "committedDate": "2020-06-15T10:22:19Z", "type": "commit"}, {"oid": "d4bc76f89568523e2d3d01389ee58a8ec248c071", "url": "https://github.com/bakdata/conquery/commit/d4bc76f89568523e2d3d01389ee58a8ec248c071", "message": "SubJob Cleanup", "committedDate": "2020-06-15T11:11:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDg5MDY0Nw==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r440890647", "bodyText": "R\u00fcckgabewert checken, um Timeout zu \u00fcberpr\u00fcfen", "author": "thoniTUB", "createdAt": "2020-06-16T14:22:48Z", "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/ConqueryStorageImpl.java", "diffHunk": "@@ -40,34 +44,35 @@ public ConqueryStorageImpl(Validator validator, StorageConfig config, File direc\n \t\tthis.nThreads = config.getThreads();\n \t}\n \n-\tprotected void createStores(Collector<KeyIncludingStore<?,?>> collector) {\n-\t}\n+\tprotected abstract List<ListenableFuture<KeyIncludingStore<?,?>>> createStores(ListeningExecutorService pool)\n+\t\t\tthrows ExecutionException, InterruptedException;\n \n \t/**\n \t * Load all stores from disk.\n+\t *\n+\t * Create a ThreadPool that can be used to submit as many tasks in parallel as possible.\n \t */\n \t@Override\n-\tpublic void loadData() {\n-\t\tcreateStores(stores::add);\n+\tpublic final void loadData() {\n \t\tlog.info(\"Loading storage {} from {}\", this.getClass().getSimpleName(), directory);\n \n \t\ttry (final Timer.Context timer = JobMetrics.getStoreLoadingTimer()) {\n-\t\t\tfinal ExecutorService loaders = Executors.newFixedThreadPool(nThreads);\n+\t\t\tListeningExecutorService pool = MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(getNThreads()));\n \n \t\t\tStopwatch all = Stopwatch.createStarted();\n-\t\t\tfor (KeyIncludingStore<?, ?> store : stores) {\n-\t\t\t\tloaders.submit(store::loadData);\n-\t\t\t}\n \n-\t\t\tloaders.shutdown();\n-\t\t\tloaders.awaitTermination(1, TimeUnit.DAYS);\n+\t\t\tfinal List<ListenableFuture<KeyIncludingStore<?,?>>> loaded = createStores(pool);\n+\n+\t\t\tstores.addAll(Futures.allAsList(loaded).get());\n+\n+\t\t\tpool.shutdown();\n+\t\t\tpool.awaitTermination(1, TimeUnit.DAYS);", "originalCommit": "d4bc76f89568523e2d3d01389ee58a8ec248c071", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDg5NTM3OA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r440895378", "bodyText": "Doku", "author": "thoniTUB", "createdAt": "2020-06-16T14:29:01Z", "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/NamespacedStorageImpl.java", "diffHunk": "@@ -120,13 +126,26 @@ protected void createStores(Collector<KeyIncludingStore<?, ?>> collector) {\n \t\t\t});\n \n \n-\t\tcollector\n-\t\t\t.collect(dataset)\n-\t\t\t.collect(dictionaries)\n-\t\t\t.collect(concepts)\n-\t\t\t.collect(imports);\n+\t\tpool.submit(() -> {", "originalCommit": "d4bc76f89568523e2d3d01389ee58a8ec248c071", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk2NDkzMQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r440964931", "bodyText": "Der ImmutableList.builder von Guave ist hier vllt besser", "author": "thoniTUB", "createdAt": "2020-06-16T15:59:09Z", "path": "backend/src/main/java/com/bakdata/conquery/io/xodus/WorkerStorageImpl.java", "diffHunk": "@@ -41,18 +47,36 @@ public void setBucketManager(BucketManager bucketManager) {\n \t}\n \n \t@Override\n-\tprotected void createStores(Collector<KeyIncludingStore<?, ?>> collector) {\n-\t\tsuper.createStores(collector);\n+\tprotected List<ListenableFuture<KeyIncludingStore<?, ?>>> createStores(ListeningExecutorService pool) throws ExecutionException, InterruptedException {\n+\n+\t\t// Load all base data first, then load worker specific data.\n+\t\tfinal List<ListenableFuture<KeyIncludingStore<?, ?>>> stores = super.createStores(pool);\n+\t\tFutures.allAsList(stores).get();\n+\n+\n \t\tworker = StoreInfo.WORKER.singleton(getEnvironment(), getValidator());\n \t\tblocks = StoreInfo.BUCKETS.identifiable(getEnvironment(), getValidator(), getCentralRegistry());\n \t\tcBlocks = StoreInfo.C_BLOCKS.identifiable(getEnvironment(), getValidator(), getCentralRegistry());\n-\t\t\n-\t\tcollector\n-\t\t\t.collect(worker)\n-\t\t\t.collect(blocks)\n-\t\t\t.collect(cBlocks);\n+\n+\t\treturn ListUtils.union(", "originalCommit": "d4bc76f89568523e2d3d01389ee58a8ec248c071", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5409b3dc5cf44af230dffb67c9035b8acf548786", "url": "https://github.com/bakdata/conquery/commit/5409b3dc5cf44af230dffb67c9035b8acf548786", "message": "fix code style review changes. Mostly cleanup and missing documentation", "committedDate": "2020-06-17T12:22:04Z", "type": "commit"}, {"oid": "b8b408b48fc2988669f43b72b277441e909ecfe8", "url": "https://github.com/bakdata/conquery/commit/b8b408b48fc2988669f43b72b277441e909ecfe8", "message": "Merge branch 'develop' into feature/parallel-startup", "committedDate": "2020-06-17T12:22:20Z", "type": "commit"}, {"oid": "69e90c874ce4f99982139de012afdd807113dc8e", "url": "https://github.com/bakdata/conquery/commit/69e90c874ce4f99982139de012afdd807113dc8e", "message": "WIP implementation of RoundRobinQueue", "committedDate": "2020-06-25T16:43:35Z", "type": "commit"}, {"oid": "2baec7525ac604336c818caf9b95e0dfc3e2b57a", "url": "https://github.com/bakdata/conquery/commit/2baec7525ac604336c818caf9b95e0dfc3e2b57a", "message": "rewrite code to be lockfree", "committedDate": "2020-06-25T16:43:35Z", "type": "commit"}, {"oid": "3d29dac278d64bc84b8e2167f7b4772ba4c112e2", "url": "https://github.com/bakdata/conquery/commit/3d29dac278d64bc84b8e2167f7b4772ba4c112e2", "message": "Proper lock-minimal RoundRobinQueue and appropriate tests", "committedDate": "2020-06-25T16:43:35Z", "type": "commit"}, {"oid": "84a47c91610ca1c882b8a70104ed3379ebd667be", "url": "https://github.com/bakdata/conquery/commit/84a47c91610ca1c882b8a70104ed3379ebd667be", "message": "documentation and cleanup of RoundRobinQueue.java", "committedDate": "2020-06-26T06:56:34Z", "type": "commit"}, {"oid": "8d24aa34024293d880b91126dfa48930d97df0e6", "url": "https://github.com/bakdata/conquery/commit/8d24aa34024293d880b91126dfa48930d97df0e6", "message": "Cleanup:\n- Add logging to RoundRobinQueue\n- Remove Queue when Worker is removed.\n- Add configuration parameters for RoundRobinQueue+QueryExecutor allocation", "committedDate": "2020-06-26T09:08:57Z", "type": "commit"}, {"oid": "93b260c58a99e07bef09fc44b186e9e6fad30c59", "url": "https://github.com/bakdata/conquery/commit/93b260c58a99e07bef09fc44b186e9e6fad30c59", "message": "revert parallel loading", "committedDate": "2020-06-26T09:14:34Z", "type": "commit"}, {"oid": "80f16cf0befa29a92c835a487e21685788f42840", "url": "https://github.com/bakdata/conquery/commit/80f16cf0befa29a92c835a487e21685788f42840", "message": "fix RoundRobinQueue ordering and tests", "committedDate": "2020-06-26T09:21:32Z", "type": "commit"}, {"oid": "497e684b032955a93aa550e9494ce2da6222c292", "url": "https://github.com/bakdata/conquery/commit/497e684b032955a93aa550e9494ce2da6222c292", "message": "Merge remote-tracking branch 'origin/develop' into feature/parallel-startup\n\n# Conflicts:\n#\tbackend/src/main/java/com/bakdata/conquery/commands/SlaveCommand.java\n#\tbackend/src/main/java/com/bakdata/conquery/models/config/StorageConfig.java\n#\tbackend/src/main/java/com/bakdata/conquery/models/jobs/JobManager.java\n#\tbackend/src/main/java/com/bakdata/conquery/models/query/QueryExecutor.java\n#\tbackend/src/main/java/com/bakdata/conquery/models/worker/Worker.java\n#\tbackend/src/main/java/com/bakdata/conquery/models/worker/Workers.java\n#\tbackend/src/test/java/com/bakdata/conquery/util/support/StandaloneSupport.java\n#\tdocs/Config JSON.md", "committedDate": "2020-06-26T09:55:35Z", "type": "commit"}, {"oid": "458128c3d3e3fd8f09d5dffe65ec4fc700c5e60e", "url": "https://github.com/bakdata/conquery/commit/458128c3d3e3fd8f09d5dffe65ec4fc700c5e60e", "message": "Merge 497e684b032955a93aa550e9494ce2da6222c292 into 131665633092963a2e0b18569716be4229d05383", "committedDate": "2020-06-26T09:57:48Z", "type": "commit"}, {"oid": "adc87aaadfd3bd8f262426f6566954d923a0276a", "url": "https://github.com/bakdata/conquery/commit/adc87aaadfd3bd8f262426f6566954d923a0276a", "message": "automatic update to docs", "committedDate": "2020-06-26T09:59:57Z", "type": "commit"}, {"oid": "b4561282971c0dc2454f1cf6c5f6bc4112b3f90a", "url": "https://github.com/bakdata/conquery/commit/b4561282971c0dc2454f1cf6c5f6bc4112b3f90a", "message": "revert loading datasets in parallel", "committedDate": "2020-06-26T12:20:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyNjIxMw==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r446126213", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \tdefault Stream<QueryJob> executeOn(QueryExecutionContext context, Collection<Entity> entities, ShardResult result) {\n          \n          \n            \n            \tdefault Stream<QueryJob> executeOn(QueryExecutionContext context, Collection<Entity> entities) {", "author": "thoniTUB", "createdAt": "2020-06-26T11:25:46Z", "path": "backend/src/main/java/com/bakdata/conquery/models/query/queryplan/QueryPlan.java", "diffHunk": "@@ -8,12 +8,13 @@\n import com.bakdata.conquery.models.query.entity.Entity;\n import com.bakdata.conquery.models.query.queryplan.clone.CloneContext;\n import com.bakdata.conquery.models.query.results.EntityResult;\n+import com.bakdata.conquery.models.query.results.ShardResult;\n \n public interface QueryPlan {\n \n \tQueryPlan clone(CloneContext ctx);\n \n-\tdefault Stream<QueryJob> executeOn(QueryExecutionContext context, Collection<Entity> entities) {\n+\tdefault Stream<QueryJob> executeOn(QueryExecutionContext context, Collection<Entity> entities, ShardResult result) {", "originalCommit": "adc87aaadfd3bd8f262426f6566954d923a0276a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyNjkxOQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r446126919", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.executeOn(context, entries, result)\n          \n          \n            \n            \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.executeOn(context, entries)", "author": "thoniTUB", "createdAt": "2020-06-26T11:27:22Z", "path": "backend/src/main/java/com/bakdata/conquery/models/query/QueryExecutor.java", "diffHunk": "@@ -5,51 +5,48 @@\n import java.util.Collection;\n import java.util.List;\n import java.util.Map.Entry;\n-import java.util.concurrent.ThreadPoolExecutor;\n-import java.util.concurrent.TimeUnit;\n+import java.util.Queue;\n import java.util.stream.Collectors;\n \n-import com.bakdata.conquery.models.config.ConqueryConfig;\n import com.bakdata.conquery.models.identifiable.ids.specific.ManagedExecutionId;\n import com.bakdata.conquery.models.query.entity.Entity;\n import com.bakdata.conquery.models.query.queryplan.QueryPlan;\n import com.bakdata.conquery.models.query.results.EntityResult;\n import com.bakdata.conquery.models.query.results.ShardResult;\n import com.google.common.util.concurrent.Futures;\n import com.google.common.util.concurrent.ListenableFuture;\n-import com.google.common.util.concurrent.ListeningExecutorService;\n+import com.google.common.util.concurrent.ListenableFutureTask;\n import com.google.common.util.concurrent.MoreExecutors;\n+import lombok.Getter;\n+import lombok.RequiredArgsConstructor;\n import lombok.extern.slf4j.Slf4j;\n \n-@Slf4j\n+@Slf4j @RequiredArgsConstructor\n public class QueryExecutor implements Closeable {\n \n-\tprivate final ThreadPoolExecutor executor;\n-\tprivate final ListeningExecutorService pool;\n-\t\n-\tpublic QueryExecutor(ConqueryConfig config) {\n-\t\tthis.executor = config.getQueries().getExecutionPool().createService(\"Query Executor %d\");\n-\t\tthis.pool = MoreExecutors.listeningDecorator(executor);\n-\t}\n+\t@Getter\n+\tprivate final Queue<Runnable> jobs;\n \n \tpublic ShardResult execute(ShardResult result, QueryExecutionContext context, Entry<ManagedExecutionId, QueryPlan> entry) {\n \n-\t\treturn execute(result, context, entry, pool);\n+\t\treturn execute(result, context, entry, jobs);\n \t}\n \n-\tpublic static ShardResult execute(ShardResult result, QueryExecutionContext context, Entry<ManagedExecutionId, QueryPlan> entry, ListeningExecutorService executor) {\n+\tpublic static ShardResult execute(ShardResult result, QueryExecutionContext context, Entry<ManagedExecutionId, QueryPlan> entry, Queue<Runnable> jobs) {\n \t\tManagedExecutionId executionId = entry.getKey();\n \t\tCollection<Entity> entries = context.getStorage().getBucketManager().getEntities().values();\n \n \t\tif(entries.isEmpty()) {\n-\t\t\tlog.warn(\"entries for query {} are empty\", executionId);\n+\t\t\tlog.warn(\"entries for Query[{}] are empty\", executionId);\n \t\t}\n-\t\t\n-\t\tList<ListenableFuture<EntityResult>> futures = entry.getValue()\n-\t\t\t.executeOn(context, entries)\n-\t\t\t.map(executor::submit)\n-\t\t\t.collect(Collectors.toList());\n-\t\t\n+\n+\t\tList<ListenableFutureTask<EntityResult>> futures = entry.getValue()\n+\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t.executeOn(context, entries, result)", "originalCommit": "adc87aaadfd3bd8f262426f6566954d923a0276a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyNzUzMw==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r446127533", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \tpublic Workers(RoundRobinQueue<Runnable> queue, int threadPoolSize) {\n          \n          \n            \n            \t\tsuper();\n          \n          \n            \n            \t\tObjects.requireNonNull(queue, \"Queues may not be empty.\");\n          \n          \n            \n            \t\tqueryExecutorQueues = queue;\n          \n          \n            \n            \tpublic Workers(@NonNull RoundRobinQueue<Runnable> queue, int threadPoolSize) {\n          \n          \n            \n            \t\tsuper();\n          \n          \n            \n            \t\tqueryExecutorQueues = queue;", "author": "thoniTUB", "createdAt": "2020-06-26T11:28:57Z", "path": "backend/src/main/java/com/bakdata/conquery/models/worker/Workers.java", "diffHunk": "@@ -1,22 +1,48 @@\n package com.bakdata.conquery.models.worker;\n \n+import java.io.Closeable;\n+import java.io.IOException;\n import java.util.HashMap;\n import java.util.Map;\n import java.util.NoSuchElementException;\n import java.util.Objects;\n import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicInteger;\n \n import com.bakdata.conquery.models.identifiable.CentralRegistry;\n import com.bakdata.conquery.models.identifiable.ids.specific.DatasetId;\n import com.bakdata.conquery.models.identifiable.ids.specific.WorkerId;\n+import com.bakdata.conquery.util.RoundRobinQueue;\n import com.fasterxml.jackson.annotation.JsonIgnore;\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n import lombok.Getter;\n import lombok.Setter;\n+import lombok.SneakyThrows;\n import lombok.extern.slf4j.Slf4j;\n \n @Slf4j\n-public class Workers extends NamespaceCollection {\n+public class Workers extends NamespaceCollection implements Closeable {\n+\n+\tprivate final ThreadPoolExecutor queryThreadPool;\n+\n+\t@Getter\n+\tprivate final RoundRobinQueue<Runnable> queryExecutorQueues;\n+\n+\tpublic Workers(RoundRobinQueue<Runnable> queue, int threadPoolSize) {\n+\t\tsuper();\n+\t\tObjects.requireNonNull(queue, \"Queues may not be empty.\");\n+\t\tqueryExecutorQueues = queue;", "originalCommit": "adc87aaadfd3bd8f262426f6566954d923a0276a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyNzk1Mg==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r446127952", "bodyText": "Hier ist es mal Queue und mal Queues", "author": "thoniTUB", "createdAt": "2020-06-26T11:29:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEyNzUzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzMTM3OQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r446131379", "bodyText": "Hier ist die Formatierung futsch", "author": "thoniTUB", "createdAt": "2020-06-26T11:38:22Z", "path": "backend/src/test/java/com/bakdata/conquery/util/RoundRobinQueueTest.java", "diffHunk": "@@ -0,0 +1,280 @@\n+package com.bakdata.conquery.util;\n+\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.ThreadFactory;\n+import java.util.concurrent.TimeUnit;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.RepeatedTest;\n+import org.junit.jupiter.api.Test;\n+\n+@Slf4j\n+class RoundRobinQueueTest {\n+\n+    private static List<Throwable> EXCEPTIONS = new ArrayList<>();\n+\n+    private static ThreadFactory threadFactory =\n+            new ThreadFactoryBuilder()\n+                    .setUncaughtExceptionHandler((t, e) -> {\n+                        log.error(\"Exception Thread.\", e);\n+                        EXCEPTIONS.add(e);\n+                    }).build();\n+\n+    @BeforeEach\n+    public void reset() {\n+        EXCEPTIONS.clear();\n+    }\n+\n+    @AfterEach\n+    public void testEmpty(){\n+        assertThat(EXCEPTIONS).isEmpty();\n+    }\n+\n+\t@Test\n+\tpublic void test() {\n+\t\tfinal RoundRobinQueue<Integer> queue = new RoundRobinQueue<>(100);\n+\n+\t\tfinal Queue<Integer> first = queue.createQueue();\n+\t\tfinal Queue<Integer> second = queue.createQueue();\n+\n+\t\tfirst.add(1);\n+\t\tsecond.add(2);\n+\n+\t\tassertThat(queue.contains(1)).isTrue();\n+\t\tassertThat(queue.contains(2)).isTrue();\n+\t\tassertThat(queue.contains(3)).isFalse();\n+\n+\t\tfinal Iterator<Integer> iterator = queue.iterator();\n+\n+\t\tassertThat(iterator.next()).isEqualTo(1);\n+\t\tassertThat(first).isEmpty();\n+\t\tassertThat(iterator.next()).isEqualTo(2);\n+\t\tassertThat(second).isEmpty();\n+\t\tassertThat(iterator.next()).isEqualTo(null);\n+\t\tassertThat(queue).isEmpty();\n+\t}\n+\n+\t@Test\n+\tpublic void testIterator() {\n+\t\tfinal RoundRobinQueue<Integer> queue = new RoundRobinQueue<>(100);\n+\n+\t\tfinal Queue<Integer> first = queue.createQueue();\n+\t\tfinal Queue<Integer> second = queue.createQueue();\n+\n+\t\tfirst.add(1);\n+\t\tsecond.add(2);\n+\n+\t\tfinal List<Integer> out = new ArrayList<>();\n+\n+\t\tfor (Integer integer : queue) {\n+\t\t\tout.add(integer);\n+\t\t}\n+\n+\t\tassertThat(out).containsExactlyInAnyOrder(1, 2);\n+\t}\n+\n+\t@Test\n+\tpublic void testNewQueue() {\n+\t\tfinal RoundRobinQueue<Integer> queue = new RoundRobinQueue<>(100);\n+\n+\t\tfinal Queue<Integer> first = queue.createQueue();\n+\t\tfinal Queue<Integer> second = queue.createQueue();\n+\n+\t\tfirst.add(1);\n+\t\tsecond.add(2);\n+\n+\n+\t\tfinal Iterator<Integer> iterator = queue.iterator();\n+\n+\n+\t\tassertThat(iterator.next()).isEqualTo(1);\n+\t\tassertThat(iterator.next()).isEqualTo(2);\n+\t\tassertThat(iterator.next()).isEqualTo(null);\n+\n+\t\tfinal Queue<Integer> third = queue.createQueue();\n+\t\tthird.add(3);\n+\n+\n+\t\tassertThat(iterator.next()).isEqualTo(3);\n+\t}\n+\n+\n+\t@Test\n+\tpublic void parPutSynTake() throws InterruptedException {\n+\t\tfinal RoundRobinQueue<Integer> queue = new RoundRobinQueue<>(100);\n+\n+\t\tfinal Queue<Integer> first = queue.createQueue();\n+\t\tfinal Queue<Integer> second = queue.createQueue();\n+\n+\t\tfirst.add(1);\n+\t\tsecond.add(2);\n+\n+\t\tfinal Random waitMillis = new Random();\n+\n+        threadFactory.newThread(() -> {", "originalCommit": "adc87aaadfd3bd8f262426f6566954d923a0276a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzMTU3Nw==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r446131577", "bodyText": "Bitte kein Random im Test", "author": "thoniTUB", "createdAt": "2020-06-26T11:38:57Z", "path": "backend/src/test/java/com/bakdata/conquery/util/RoundRobinQueueTest.java", "diffHunk": "@@ -0,0 +1,280 @@\n+package com.bakdata.conquery.util;\n+\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.ThreadFactory;\n+import java.util.concurrent.TimeUnit;\n+\n+import com.google.common.util.concurrent.ThreadFactoryBuilder;\n+import lombok.extern.slf4j.Slf4j;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.RepeatedTest;\n+import org.junit.jupiter.api.Test;\n+\n+@Slf4j\n+class RoundRobinQueueTest {\n+\n+    private static List<Throwable> EXCEPTIONS = new ArrayList<>();\n+\n+    private static ThreadFactory threadFactory =\n+            new ThreadFactoryBuilder()\n+                    .setUncaughtExceptionHandler((t, e) -> {\n+                        log.error(\"Exception Thread.\", e);\n+                        EXCEPTIONS.add(e);\n+                    }).build();\n+\n+    @BeforeEach\n+    public void reset() {\n+        EXCEPTIONS.clear();\n+    }\n+\n+    @AfterEach\n+    public void testEmpty(){\n+        assertThat(EXCEPTIONS).isEmpty();\n+    }\n+\n+\t@Test\n+\tpublic void test() {\n+\t\tfinal RoundRobinQueue<Integer> queue = new RoundRobinQueue<>(100);\n+\n+\t\tfinal Queue<Integer> first = queue.createQueue();\n+\t\tfinal Queue<Integer> second = queue.createQueue();\n+\n+\t\tfirst.add(1);\n+\t\tsecond.add(2);\n+\n+\t\tassertThat(queue.contains(1)).isTrue();\n+\t\tassertThat(queue.contains(2)).isTrue();\n+\t\tassertThat(queue.contains(3)).isFalse();\n+\n+\t\tfinal Iterator<Integer> iterator = queue.iterator();\n+\n+\t\tassertThat(iterator.next()).isEqualTo(1);\n+\t\tassertThat(first).isEmpty();\n+\t\tassertThat(iterator.next()).isEqualTo(2);\n+\t\tassertThat(second).isEmpty();\n+\t\tassertThat(iterator.next()).isEqualTo(null);\n+\t\tassertThat(queue).isEmpty();\n+\t}\n+\n+\t@Test\n+\tpublic void testIterator() {\n+\t\tfinal RoundRobinQueue<Integer> queue = new RoundRobinQueue<>(100);\n+\n+\t\tfinal Queue<Integer> first = queue.createQueue();\n+\t\tfinal Queue<Integer> second = queue.createQueue();\n+\n+\t\tfirst.add(1);\n+\t\tsecond.add(2);\n+\n+\t\tfinal List<Integer> out = new ArrayList<>();\n+\n+\t\tfor (Integer integer : queue) {\n+\t\t\tout.add(integer);\n+\t\t}\n+\n+\t\tassertThat(out).containsExactlyInAnyOrder(1, 2);\n+\t}\n+\n+\t@Test\n+\tpublic void testNewQueue() {\n+\t\tfinal RoundRobinQueue<Integer> queue = new RoundRobinQueue<>(100);\n+\n+\t\tfinal Queue<Integer> first = queue.createQueue();\n+\t\tfinal Queue<Integer> second = queue.createQueue();\n+\n+\t\tfirst.add(1);\n+\t\tsecond.add(2);\n+\n+\n+\t\tfinal Iterator<Integer> iterator = queue.iterator();\n+\n+\n+\t\tassertThat(iterator.next()).isEqualTo(1);\n+\t\tassertThat(iterator.next()).isEqualTo(2);\n+\t\tassertThat(iterator.next()).isEqualTo(null);\n+\n+\t\tfinal Queue<Integer> third = queue.createQueue();\n+\t\tthird.add(3);\n+\n+\n+\t\tassertThat(iterator.next()).isEqualTo(3);\n+\t}\n+\n+\n+\t@Test\n+\tpublic void parPutSynTake() throws InterruptedException {\n+\t\tfinal RoundRobinQueue<Integer> queue = new RoundRobinQueue<>(100);\n+\n+\t\tfinal Queue<Integer> first = queue.createQueue();\n+\t\tfinal Queue<Integer> second = queue.createQueue();\n+\n+\t\tfirst.add(1);\n+\t\tsecond.add(2);\n+\n+\t\tfinal Random waitMillis = new Random();", "originalCommit": "adc87aaadfd3bd8f262426f6566954d923a0276a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzMzgzNA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r446133834", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public RoundRobinQueue(int capacity) {\n          \n          \n            \n                public RoundRobinQueue(@Min(1) int capacity) {", "author": "thoniTUB", "createdAt": "2020-06-26T11:44:27Z", "path": "backend/src/main/java/com/bakdata/conquery/util/RoundRobinQueue.java", "diffHunk": "@@ -0,0 +1,443 @@\n+package com.bakdata.conquery.util;\n+\n+import java.util.AbstractQueue;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+\n+import com.google.common.collect.ForwardingQueue;\n+import com.google.common.collect.Queues;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.commons.lang3.ArrayUtils;\n+import org.jetbrains.annotations.NotNull;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Class implementing a queue that is backed by multiple queues at once that are evenly processed, avoiding starvation of jobs when a single producer creates a lot of jobs.\n+ * @param <E>\n+ */\n+@Slf4j\n+// TODO: 26.06.2020 fk: migrate logging to trace\n+public class RoundRobinQueue<E> extends AbstractQueue<E> implements BlockingQueue<E> {\n+\n+\t/**\n+\t * The backing queues.\n+\t *\n+\t * @implNote null denotes no queue, and this queue must not be contiguously filled: Deletions just unset the queue so it is no longer processed.\n+\t */\n+    private final Queue<E>[] queues;\n+    private final Object signal = new Object();\n+\n+    /**\n+     * The index to start polling. This is remembered so we don't have a bias towards lower indices.\n+     */\n+    private final ThreadLocal<Integer> cycleIndex = ThreadLocal.withInitial(() -> 0);\n+\n+    public RoundRobinQueue(int capacity) {", "originalCommit": "adc87aaadfd3bd8f262426f6566954d923a0276a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzNDc1Nw==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r446134757", "bodyText": "M\u00fcsste die Kapazit\u00e4t nicht der Datasets entsprechen?", "author": "thoniTUB", "createdAt": "2020-06-26T11:46:48Z", "path": "backend/src/main/java/com/bakdata/conquery/commands/SlaveCommand.java", "diffHunk": "@@ -80,27 +86,42 @@ protected void run(Environment environment, Namespace namespace, ConqueryConfig\n \t\t\n \t\tscheduler.scheduleAtFixedRate(this::reportJobManagerStatus, 30, 1, TimeUnit.SECONDS);\n \n-\n \t\tthis.config = config;\n \n \t\tif(config.getStorage().getDirectory().mkdirs()){\n \t\t\tlog.warn(\"Had to create Storage Dir at `{}`\", config.getStorage().getDirectory());\n \t\t}\n \n-\t\tfor(File directory : config.getStorage().getDirectory().listFiles()) {\n-\t\t\tif(directory.getName().startsWith(\"worker_\")) {\n+\t\tworkers = new Workers(new RoundRobinQueue<>(config.getQueries().getRoundRobinQueueCapacity()), config.getQueries().getNThreads());", "originalCommit": "adc87aaadfd3bd8f262426f6566954d923a0276a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE1MjI0OQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r446152249", "bodyText": "aber die wei\u00dft du nicht beim starten und du willst ja auch neue datasets hinzuf\u00fcgen k\u00f6nnnen. Aber f\u00fcr unseren Fall w\u00fcrde ich das so setzen, bzw +1 oder so", "author": "awildturtok", "createdAt": "2020-06-26T12:26:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzNDc1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MzAzMw==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r446143033", "bodyText": "Format", "author": "thoniTUB", "createdAt": "2020-06-26T12:05:59Z", "path": "backend/src/main/java/com/bakdata/conquery/util/RoundRobinQueue.java", "diffHunk": "@@ -0,0 +1,443 @@\n+package com.bakdata.conquery.util;\n+\n+import java.util.AbstractQueue;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+\n+import com.google.common.collect.ForwardingQueue;\n+import com.google.common.collect.Queues;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.commons.lang3.ArrayUtils;\n+import org.jetbrains.annotations.NotNull;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Class implementing a queue that is backed by multiple queues at once that are evenly processed, avoiding starvation of jobs when a single producer creates a lot of jobs.\n+ * @param <E>\n+ */\n+@Slf4j\n+// TODO: 26.06.2020 fk: migrate logging to trace\n+public class RoundRobinQueue<E> extends AbstractQueue<E> implements BlockingQueue<E> {\n+\n+\t/**\n+\t * The backing queues.\n+\t *\n+\t * @implNote null denotes no queue, and this queue must not be contiguously filled: Deletions just unset the queue so it is no longer processed.\n+\t */\n+    private final Queue<E>[] queues;\n+    private final Object signal = new Object();\n+\n+    /**\n+     * The index to start polling. This is remembered so we don't have a bias towards lower indices.\n+     */\n+    private final ThreadLocal<Integer> cycleIndex = ThreadLocal.withInitial(() -> 0);\n+\n+    public RoundRobinQueue(int capacity) {\n+        super();\n+        queues = new Queue[capacity];\n+    }\n+\n+\t/**\n+\t * @return Maximum number of queues allowed in this queue.\n+\t */\n+\tpublic int getCapacity() {\n+\t\treturn queues.length;\n+\t}\n+\n+\t/**\n+\t * @return Number of sub-queues.\n+\t */\n+\tpublic int getNQueues() {\n+\t\treturn (int) Arrays.stream(queues).filter(Objects::nonNull).count();\n+\t}\n+\n+\n+\t/**\n+     * Helper class that notifies on {@code signal} when a new object is added to it queue, awakening waiting threads. This effectively implements a semaphore aroud {@code signal} as notify only awakens a single waiting thread.\n+     */\n+    @RequiredArgsConstructor\n+    private static class SignallingForwardingQueue<T> extends ForwardingQueue<T> {\n+\n+\t\t/**\n+\t\t * The original queue.\n+\t\t */\n+\t\t@NonNull\n+        private final Queue<T> base;\n+\n+\t\t/**\n+\t\t * The signal object to be notified on.\n+\t\t */\n+        private final Object signal;\n+\n+        @Override\n+        protected Queue<T> delegate() {\n+            return base;\n+        }\n+\n+\t\tprotected void doNotify() {\n+\t\t\tlog.trace(\"Awakening a thread for new Work.\");\n+\t\t\tsynchronized (signal) {\n+\t\t\t\tsignal.notify();\n+\t\t\t}\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to offer a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+\t\t@Override\n+        public boolean offer(T element) {\n+            final boolean offer = super.offer(element);\n+\n+            if (offer) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+            return offer;\n+        }\n+\n+\t\t/**\n+\t\t * Try to add a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+        @Override\n+        public boolean add(T element) {\n+            final boolean add = super.add(element);\n+\n+            if (add) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+            return add;\n+        }", "originalCommit": "adc87aaadfd3bd8f262426f6566954d923a0276a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NDAxMA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r446144010", "bodyText": "Du kannst in dieser Methode das Array auch neu anlegen und vergr\u00f6\u00dfern. Analog in der remove Methode verkleinern. Dann musst du dich nicht mit der festen Kapa rumschlagen.\nOder eine ArrayList. Solange get(i)=> O(1) hat sollte es doch kein Problem sein.", "author": "thoniTUB", "createdAt": "2020-06-26T12:08:29Z", "path": "backend/src/main/java/com/bakdata/conquery/util/RoundRobinQueue.java", "diffHunk": "@@ -0,0 +1,443 @@\n+package com.bakdata.conquery.util;\n+\n+import java.util.AbstractQueue;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+\n+import com.google.common.collect.ForwardingQueue;\n+import com.google.common.collect.Queues;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.commons.lang3.ArrayUtils;\n+import org.jetbrains.annotations.NotNull;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Class implementing a queue that is backed by multiple queues at once that are evenly processed, avoiding starvation of jobs when a single producer creates a lot of jobs.\n+ * @param <E>\n+ */\n+@Slf4j\n+// TODO: 26.06.2020 fk: migrate logging to trace\n+public class RoundRobinQueue<E> extends AbstractQueue<E> implements BlockingQueue<E> {\n+\n+\t/**\n+\t * The backing queues.\n+\t *\n+\t * @implNote null denotes no queue, and this queue must not be contiguously filled: Deletions just unset the queue so it is no longer processed.\n+\t */\n+    private final Queue<E>[] queues;\n+    private final Object signal = new Object();\n+\n+    /**\n+     * The index to start polling. This is remembered so we don't have a bias towards lower indices.\n+     */\n+    private final ThreadLocal<Integer> cycleIndex = ThreadLocal.withInitial(() -> 0);\n+\n+    public RoundRobinQueue(int capacity) {\n+        super();\n+        queues = new Queue[capacity];\n+    }\n+\n+\t/**\n+\t * @return Maximum number of queues allowed in this queue.\n+\t */\n+\tpublic int getCapacity() {\n+\t\treturn queues.length;\n+\t}\n+\n+\t/**\n+\t * @return Number of sub-queues.\n+\t */\n+\tpublic int getNQueues() {\n+\t\treturn (int) Arrays.stream(queues).filter(Objects::nonNull).count();\n+\t}\n+\n+\n+\t/**\n+     * Helper class that notifies on {@code signal} when a new object is added to it queue, awakening waiting threads. This effectively implements a semaphore aroud {@code signal} as notify only awakens a single waiting thread.\n+     */\n+    @RequiredArgsConstructor\n+    private static class SignallingForwardingQueue<T> extends ForwardingQueue<T> {\n+\n+\t\t/**\n+\t\t * The original queue.\n+\t\t */\n+\t\t@NonNull\n+        private final Queue<T> base;\n+\n+\t\t/**\n+\t\t * The signal object to be notified on.\n+\t\t */\n+        private final Object signal;\n+\n+        @Override\n+        protected Queue<T> delegate() {\n+            return base;\n+        }\n+\n+\t\tprotected void doNotify() {\n+\t\t\tlog.trace(\"Awakening a thread for new Work.\");\n+\t\t\tsynchronized (signal) {\n+\t\t\t\tsignal.notify();\n+\t\t\t}\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to offer a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+\t\t@Override\n+        public boolean offer(T element) {\n+            final boolean offer = super.offer(element);\n+\n+            if (offer) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+            return offer;\n+        }\n+\n+\t\t/**\n+\t\t * Try to add a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+        @Override\n+        public boolean add(T element) {\n+            final boolean add = super.add(element);\n+\n+            if (add) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+            return add;\n+        }\n+\n+\t\t/**\n+\t\t * Try to offer multiple elements to the queue, if successful notify all threads waiting on signal.\n+\t\t *\n+\t\t * @implNote this can actually cause some threads to receive nothing, as the collections size might be smaller than the number of waiting threads.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean addAll(Collection<? extends T> collection) {\n+\t\t\tfinal boolean addAll = super.addAll(collection);\n+\n+\t\t\tif(addAll){\n+\t\t\t\t//TODO does this cause problems?\n+\t\t\t\tsignal.notifyAll();\n+\t\t\t}\n+\n+\t\t\treturn addAll;\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Create a new queue adding it as sub-queue if there is a slot available.\n+\t * @throws IllegalStateException when no more slots are available.\n+\t * @return\n+\t */\n+    public Queue<E> createQueue() {\n+        // TODO: 25.06.2020 FK: add supplier as creation parameter\n+        final Queue<E> out = new SignallingForwardingQueue<E>(Queues.newConcurrentLinkedQueue(), signal);\n+\t\tfinal int free;\n+\n+        synchronized (queues) {\n+            free = ArrayUtils.indexOf(queues, null);", "originalCommit": "adc87aaadfd3bd8f262426f6566954d923a0276a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE1MzExMA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r446153110", "bodyText": "Wenn ich das array \u00e4ndere ist das aber eine racecondition in poll und dann ist das nicht mehr lock-free im consumer", "author": "awildturtok", "createdAt": "2020-06-26T12:28:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NDAxMA=="}], "type": "inlineReview"}, {"oid": "791161ccfab8061ff0b2219d29ea16dcaba7ca43", "url": "https://github.com/bakdata/conquery/commit/791161ccfab8061ff0b2219d29ea16dcaba7ca43", "message": "Update backend/src/main/java/com/bakdata/conquery/util/RoundRobinQueue.java\n\nCo-authored-by: MT <12283268+thoniTUB@users.noreply.github.com>", "committedDate": "2020-06-26T12:25:57Z", "type": "commit"}, {"oid": "c478e348c49ff59ed421535c4c308d37af69d056", "url": "https://github.com/bakdata/conquery/commit/c478e348c49ff59ed421535c4c308d37af69d056", "message": "Review Feedback/Cleanup:\n- Remove Random from tests\n- Code Style issues", "committedDate": "2020-06-26T12:42:46Z", "type": "commit"}, {"oid": "458f657b1f5b8a22cc180738d832000b5cc35d7a", "url": "https://github.com/bakdata/conquery/commit/458f657b1f5b8a22cc180738d832000b5cc35d7a", "message": "Merge branch 'develop' into feature/parallel-startup", "committedDate": "2020-06-26T12:43:25Z", "type": "commit"}, {"oid": "4948bd772c55da96dc46d0c9bed50acf67487224", "url": "https://github.com/bakdata/conquery/commit/4948bd772c55da96dc46d0c9bed50acf67487224", "message": "fixed error from refactoring", "committedDate": "2020-06-26T12:48:57Z", "type": "commit"}, {"oid": "b37e731ebeb7229c7f443b81c87915a409c8f36f", "url": "https://github.com/bakdata/conquery/commit/b37e731ebeb7229c7f443b81c87915a409c8f36f", "message": "allow copy-growth of RoundRobinQueue#queues by constant factor, but still disallow shrinking so we cannot go OutOfBounds in RoundRobinQueue#poll", "committedDate": "2020-06-26T14:04:01Z", "type": "commit"}, {"oid": "fee18fcd823347dafe1efc03e3dbf46e42a2c284", "url": "https://github.com/bakdata/conquery/commit/fee18fcd823347dafe1efc03e3dbf46e42a2c284", "message": "Merge b37e731ebeb7229c7f443b81c87915a409c8f36f into 38f25d427c672deebf66dffbf2d7aa2062f32024", "committedDate": "2020-06-26T14:04:14Z", "type": "commit"}, {"oid": "6ea2f7cc6d16e2c213ee4af4cf2985ebbc45f57e", "url": "https://github.com/bakdata/conquery/commit/6ea2f7cc6d16e2c213ee4af4cf2985ebbc45f57e", "message": "automatic update to docs", "committedDate": "2020-06-26T14:06:16Z", "type": "commit"}, {"oid": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "url": "https://github.com/bakdata/conquery/commit/311bb1045b5e524150ec2c4df3d81d4903db7ade", "message": "Merge branch 'develop' into feature/parallel-startup", "committedDate": "2020-06-29T08:41:45Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzA4MjkwNA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447082904", "bodyText": "Du k\u00f6nntest diese zweite Loop einsparen und dem der Task der oben submitted wird sein Ergebnis gleich in eine ConcurrentMap wirft.", "author": "thoniTUB", "createdAt": "2020-06-29T16:03:10Z", "path": "backend/src/main/java/com/bakdata/conquery/models/jobs/UpdateMatchingStats.java", "diffHunk": "@@ -34,60 +36,77 @@ public void execute() throws Exception {\n \t\t\treturn;\n \t\t}\n \n-\t\tlog.debug(\"Starting to update Matching stats with {}\", worker);\n+\t\tprogressReporter.setMax(worker.getStorage().getAllConcepts().size());\n \n-\t\tprogressReporter.setMax(worker.getStorage().getAllCBlocks().size());\n+\t\tlog.info(\"Starting to update Matching stats for {} Concepts\", worker.getStorage().getAllConcepts().size());\n+\n+\n+\t\tList<Future<Map<ConceptElementId<?>, MatchingStats.Entry>>> conceptMatches = new ArrayList<>();\n+\n+\t\tfor (Concept<?> concept :worker.getStorage().getAllConcepts()) {\n+\t\t\tconceptMatches.add(worker.getPool().submit(() -> calculateConceptMatches(concept)));\n+\t\t}\n+\n+\t\tworker.awaitSubJobTermination();\n+\n+\t\tlog.info(\"All threads are done.\");\n+\n+\t\tMap<ConceptElementId<?>, MatchingStats.Entry> messages = new HashMap<>();\n+\n+\t\tfor (Future<Map<ConceptElementId<?>, MatchingStats.Entry>> conceptMatch : conceptMatches) {", "originalCommit": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzA5MDcxNA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447090714", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t\t\t\t\tif (!(concept instanceof TreeConcept) || cBlock.getMostSpecificChildren() == null || cBlock.getMostSpecificChildren().get(event) == null) {\n          \n          \n            \n                      if(isCancelled()) {\n          \n          \n            \n                       \t\t\treturn null;\n          \n          \n            \n                       }\n          \n          \n            \n            \t\t\t\t\tif (!(concept instanceof TreeConcept) || cBlock.getMostSpecificChildren() == null || cBlock.getMostSpecificChildren().get(event) == null) {", "author": "thoniTUB", "createdAt": "2020-06-29T16:15:04Z", "path": "backend/src/main/java/com/bakdata/conquery/models/jobs/UpdateMatchingStats.java", "diffHunk": "@@ -34,60 +36,77 @@ public void execute() throws Exception {\n \t\t\treturn;\n \t\t}\n \n-\t\tlog.debug(\"Starting to update Matching stats with {}\", worker);\n+\t\tprogressReporter.setMax(worker.getStorage().getAllConcepts().size());\n \n-\t\tprogressReporter.setMax(worker.getStorage().getAllCBlocks().size());\n+\t\tlog.info(\"Starting to update Matching stats for {} Concepts\", worker.getStorage().getAllConcepts().size());\n+\n+\n+\t\tList<Future<Map<ConceptElementId<?>, MatchingStats.Entry>>> conceptMatches = new ArrayList<>();\n+\n+\t\tfor (Concept<?> concept :worker.getStorage().getAllConcepts()) {\n+\t\t\tconceptMatches.add(worker.getPool().submit(() -> calculateConceptMatches(concept)));\n+\t\t}\n+\n+\t\tworker.awaitSubJobTermination();\n+\n+\t\tlog.info(\"All threads are done.\");\n+\n+\t\tMap<ConceptElementId<?>, MatchingStats.Entry> messages = new HashMap<>();\n+\n+\t\tfor (Future<Map<ConceptElementId<?>, MatchingStats.Entry>> conceptMatch : conceptMatches) {\n+\t\t\tmessages.putAll(conceptMatch.get());\n+\t\t}\n+\n+\n+\t\tif (!messages.isEmpty()) {\n+\t\t\tworker.send(new UpdateElementMatchingStats(worker.getInfo().getId(), messages));\n+\t\t}\n+\n+\t\tprogressReporter.done();\n+\t}\n+\n+\tpublic Map<ConceptElementId<?>, MatchingStats.Entry> calculateConceptMatches(Concept<?> concept) {\n \n \t\tMap<ConceptElementId<?>, MatchingStats.Entry> messages = new HashMap<>();\n \n \t\tfor (CBlock cBlock : new ArrayList<>(worker.getStorage().getAllCBlocks())) {\n \n-\t\t\tif(isCancelled()) {\n-\t\t\t\tprogressReporter.done();\n-\t\t\t\treturn;\n-\t\t\t}\n+\t\t\tif(isCancelled())\n+\t\t\t\treturn null;\n+\n+\t\t\tif(!cBlock.getConnector().getConcept().equals(concept.getId()))\n+\t\t\t\tcontinue;\n \n-\t\t\tConcept<?> concept = worker.getStorage().getConcept(cBlock.getConnector().getConcept());\n \t\t\ttry {\n \t\t\t\tBucket bucket = worker.getStorage().getBucket(cBlock.getBucket());\n \t\t\t\tTable table = worker.getStorage().getDataset().getTables().get(bucket.getImp().getTable());\n-\t\t\t\t\n+\n \t\t\t\tfor (int event = 0; event < bucket.getNumberOfEvents(); event++) {\n-\t\t\t\t\tif (concept instanceof TreeConcept && cBlock.getMostSpecificChildren() != null) {\n-\t\t\t\t\t\tint[] localIds = cBlock.getMostSpecificChildren().get(event);\n-\t\t\t\t\t\tif (localIds != null) {\n-\t\t\t\t\t\t\tConceptTreeNode<?> e = ((TreeConcept) concept).getElementByLocalId(localIds);\n-\t\n-\t\t\t\t\t\t\twhile (e != null) {\n-\t\t\t\t\t\t\t\tmessages.computeIfAbsent(e.getId(), (x) -> new MatchingStats.Entry())\n-\t\t\t\t\t\t\t\t\t.addEvent(table, bucket, cBlock, event);\n-\t\t\t\t\t\t\t\te = e.getParent();\n-\t\t\t\t\t\t\t}\n-\t\t\t\t\t\t}\n-\t\t\t\t\t\telse {\n-\t\t\t\t\t\t\tmessages\n-\t\t\t\t\t\t\t\t.computeIfAbsent(concept.getId(), (x) -> new MatchingStats.Entry())\n+\t\t\t\t\tif (!(concept instanceof TreeConcept) || cBlock.getMostSpecificChildren() == null || cBlock.getMostSpecificChildren().get(event) == null) {", "originalCommit": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzA5MTk4MA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447091980", "bodyText": "Ich wei\u00df nicht ob wir laufende Tasks canceln wollen. Eigentlich will man doch auch festgehangene Tasks canceln", "author": "thoniTUB", "createdAt": "2020-06-29T16:16:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzA5MDcxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQ2MjUyMg==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447462522", "bodyText": "das gab es meines wissens nicht, dass man aufgehangene tasks abschie\u00dfen konnte.", "author": "awildturtok", "createdAt": "2020-06-30T07:17:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzA5MDcxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyMTY4Nw==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r448321687", "bodyText": "Ja das ist denke ich auch ein kompliziertes Thema, da jenach Job Rollbacks n\u00f6tig sein k\u00f6nnten.", "author": "thoniTUB", "createdAt": "2020-07-01T12:15:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzA5MDcxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzA5Mjg2NA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447092864", "bodyText": "Das printed leider nicht den Stacktrace", "author": "thoniTUB", "createdAt": "2020-06-29T16:18:21Z", "path": "backend/src/main/java/com/bakdata/conquery/models/messages/namespaces/specific/ExecuteQuery.java", "diffHunk": "@@ -56,7 +56,7 @@ public void react(Worker context) throws Exception {\n \t\t\t\tcontext.getQueryExecutor().execute(result, new QueryExecutionContext(context.getStorage()), entry);\n \t\t\t\tresult.getFuture().addListener(()->result.send(context), MoreExecutors.directExecutor());\n \t\t\t} catch(Exception e) {\n-\t\t\t\tlog.error(String.format(\"Error while executing {} (with subquery: {})\", execution.getId(), entry.getKey()), e );\n+\t\t\t\tlog.error(\"Error while executing {} (with subquery: {})\", execution.getId(), entry.getKey(), e );", "originalCommit": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQ2Mjc4Ng==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447462786", "bodyText": "Doch, der letzte Parameter wenn es ein Throwable ist wird geprinted", "author": "awildturtok", "createdAt": "2020-06-30T07:18:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzA5Mjg2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzEwMjYzMQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447102631", "bodyText": "Ich habe nochmal geschaut. Diese start-Methode wird nie direkt vom Lifecycle gestartet. Ich w\u00fcrde daher das Starten des slow- und fastExecutors in den Konstruktor packen. sonst ist das aufrufen der Startmethode immer etwas l\u00e4stiges, an das man sich erinnern muss, wenn man die Klasse benutzen will.", "author": "thoniTUB", "createdAt": "2020-06-29T16:33:31Z", "path": "backend/src/main/java/com/bakdata/conquery/models/messages/network/specific/AddWorker.java", "diffHunk": "@@ -39,12 +37,17 @@ public void react(Slave context) throws Exception {\n \t\tWorkerStorage workerStorage = new WorkerStorageImpl(context.getValidator(), config.getStorage(), dir);\n \t\tworkerStorage.loadData();\n \t\tworkerStorage.updateDataset(dataset);\n-\t\tWorker worker = new Worker(\n+\n+\n+\t\tWorker worker = Worker.createWorker(\n \t\t\tinfo,\n-\t\t\tcontext.getJobManager(),\n \t\t\tworkerStorage,\n-\t\t\tnew QueryExecutor(config)\n+\t\t\tconfig,\n+\t\t\tcontext.getWorkers().createQuerySubQueue()\n \t\t);\n+\n+\t\tworker.getJobManager().start();", "originalCommit": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzEwMzk5Ng==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447103996", "bodyText": "Hat dieser Pool noch etwas mit den Queries zu tun? Daf\u00fcr ist doch jetzt die Queue da, oder?", "author": "thoniTUB", "createdAt": "2020-06-29T16:35:57Z", "path": "backend/src/main/java/com/bakdata/conquery/models/worker/Worker.java", "diffHunk": "@@ -2,39 +2,69 @@\n \n import java.io.Closeable;\n import java.io.IOException;\n+import java.util.Queue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n \n import com.bakdata.conquery.io.mina.MessageSender;\n import com.bakdata.conquery.io.mina.NetworkSession;\n import com.bakdata.conquery.io.xodus.WorkerStorage;\n+import com.bakdata.conquery.models.config.ConqueryConfig;\n import com.bakdata.conquery.models.events.BucketManager;\n import com.bakdata.conquery.models.jobs.JobManager;\n+import com.bakdata.conquery.models.jobs.SimpleJob;\n import com.bakdata.conquery.models.messages.namespaces.NamespaceMessage;\n import com.bakdata.conquery.models.messages.network.MasterMessage;\n import com.bakdata.conquery.models.messages.network.NetworkMessage;\n import com.bakdata.conquery.models.messages.network.specific.ForwardToNamespace;\n import com.bakdata.conquery.models.query.QueryExecutor;\n+import com.google.common.util.concurrent.Uninterruptibles;\n+import lombok.AccessLevel;\n import lombok.Getter;\n+import lombok.RequiredArgsConstructor;\n import lombok.Setter;\n+import lombok.extern.slf4j.Slf4j;\n \n+@Slf4j\n+@RequiredArgsConstructor(access = AccessLevel.PRIVATE)\n public class Worker implements MessageSender.Transforming<NamespaceMessage, NetworkMessage<?>>, Closeable {\n+\n+\t@Getter\n+\tprivate final WorkerInformation info;\n+\n \t@Getter\n \tprivate final JobManager jobManager;\n+\n \t@Getter\n \tprivate final WorkerStorage storage;\n+\n \t@Getter\n \tprivate final QueryExecutor queryExecutor;\n+\n+\t/**\n+\t * Pool that can be used in Jobs to execute a job in parallel.\n+\t */\n \t@Getter\n-\tprivate final WorkerInformation info;\n+\tprivate final ThreadPoolExecutor pool;\n+\n \t@Setter\n \tprivate NetworkSession session;\n-\t\n-\tpublic Worker(WorkerInformation info, JobManager jobManager, WorkerStorage storage, QueryExecutor queryExecutor) {\n-\t\tthis.info = info;\n-\t\tthis.jobManager = jobManager;\n-\t\tthis.storage = storage;\n-\t\tBucketManager bucketManager = new BucketManager(jobManager, storage, this);\n+\n+\n+\tpublic static Worker createWorker(WorkerInformation info, WorkerStorage storage, ConqueryConfig config, Queue<Runnable> queryQueue) {\n+\t\tfinal JobManager jobManager = new JobManager(info.getName());\n+\t\tfinal BucketManager bucketManager = new BucketManager(jobManager, storage, info);\n+\n \t\tstorage.setBucketManager(bucketManager);\n-\t\tthis.queryExecutor = queryExecutor;\n+\t\tjobManager.addSlowJob(new SimpleJob(\"Update Block Manager\", bucketManager::fullUpdate));\n+\n+\n+\t\tfinal QueryExecutor queryExecutor = new QueryExecutor(queryQueue);\n+\n+\t\t// Second format-str is used by ThreadPool.\n+\t\tfinal ThreadPoolExecutor pool = config.getQueries().getExecutionPool().createService(String.format(\"Dataset[%s] Worker-Thread %%d\", info.getDataset()));", "originalCommit": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzEwOTQ0Nw==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447109447", "bodyText": "Vielleicht sollte der Pool nicht auf Worker ebene sein sondern dar\u00fcber, damit wir nicht so viele Threads haben.\nim Slavecommand machst du ja einen ThreadPool kurzfristig auf, den k\u00f6nntest du hier wieder verwenden.", "author": "thoniTUB", "createdAt": "2020-06-29T16:44:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzEwMzk5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY0NTI2OQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447645269", "bodyText": "Ist jetzt in Workers, war eine gute Idee", "author": "awildturtok", "createdAt": "2020-06-30T12:31:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzEwMzk5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE2ODU0NQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447168545", "bodyText": "Ich denke es ist hier besser direkt auf die Futures zu synchronisieren, anstatt der indirektion \u00fcber den worker.", "author": "thoniTUB", "createdAt": "2020-06-29T18:27:43Z", "path": "backend/src/main/java/com/bakdata/conquery/models/jobs/UpdateMatchingStats.java", "diffHunk": "@@ -34,60 +36,77 @@ public void execute() throws Exception {\n \t\t\treturn;\n \t\t}\n \n-\t\tlog.debug(\"Starting to update Matching stats with {}\", worker);\n+\t\tprogressReporter.setMax(worker.getStorage().getAllConcepts().size());\n \n-\t\tprogressReporter.setMax(worker.getStorage().getAllCBlocks().size());\n+\t\tlog.info(\"Starting to update Matching stats for {} Concepts\", worker.getStorage().getAllConcepts().size());\n+\n+\n+\t\tList<Future<Map<ConceptElementId<?>, MatchingStats.Entry>>> conceptMatches = new ArrayList<>();\n+\n+\t\tfor (Concept<?> concept :worker.getStorage().getAllConcepts()) {\n+\t\t\tconceptMatches.add(worker.getPool().submit(() -> calculateConceptMatches(concept)));\n+\t\t}\n+\n+\t\tworker.awaitSubJobTermination();", "originalCommit": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE4MTAzNQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447181035", "bodyText": "Mir wird angezeigt, dass die (double) casts nicht notwendig sind", "author": "thoniTUB", "createdAt": "2020-06-29T18:49:32Z", "path": "backend/src/main/java/com/bakdata/conquery/util/RoundRobinQueue.java", "diffHunk": "@@ -0,0 +1,457 @@\n+package com.bakdata.conquery.util;\n+\n+import java.util.AbstractQueue;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+\n+import javax.validation.constraints.Min;\n+\n+import com.google.common.collect.ForwardingQueue;\n+import com.google.common.collect.Queues;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.commons.lang3.ArrayUtils;\n+import org.jetbrains.annotations.NotNull;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Class implementing a queue that is backed by multiple queues at once that are evenly processed, avoiding starvation of jobs when a single producer creates a lot of jobs.\n+ *\n+ * @param <E>\n+ */\n+@Slf4j\n+// TODO: 26.06.2020 fk: migrate logging to trace\n+public class RoundRobinQueue<E> extends AbstractQueue<E> implements BlockingQueue<E> {\n+\n+\t/**\n+\t * If {@code queues} is full, it is grown by {@code GROWTH_FACTOR}.\n+\t */\n+\tprivate static final double GROWTH_FACTOR = 1.5d;\n+\n+\t/**\n+\t * The backing queues.\n+\t *\n+\t * @implNote null denotes no queue, and this queue must not be contiguously filled: Deletions just unset the queue so it is no longer processed.\n+\t */\n+\tprivate Queue<E>[] queues;\n+\tprivate final Object signal = new Object();\n+\n+\t/**\n+\t * The index to start polling. This is remembered so we don't have a bias towards lower indices.\n+\t */\n+\tprivate final ThreadLocal<Integer> cycleIndex = ThreadLocal.withInitial(() -> 0);\n+\n+\tpublic RoundRobinQueue(@Min(1) int capacity) {\n+\t\tsuper();\n+\t\tqueues = new Queue[capacity];\n+\t}\n+\n+\t/**\n+\t * @return Maximum number of queues allowed in this queue.\n+\t */\n+\tpublic int getCapacity() {\n+\t\treturn queues.length;\n+\t}\n+\n+\t/**\n+\t * @return Number of sub-queues.\n+\t */\n+\tpublic int getNQueues() {\n+\t\treturn (int) Arrays.stream(queues).filter(Objects::nonNull).count();\n+\t}\n+\n+\n+\t/**\n+\t * Helper class that notifies on {@code signal} when a new object is added to it queue, awakening waiting threads. This effectively implements a semaphore aroud {@code signal} as notify only awakens a single waiting thread.\n+\t */\n+\t@RequiredArgsConstructor\n+\tprivate static class SignallingForwardingQueue<T> extends ForwardingQueue<T> {\n+\n+\t\t/**\n+\t\t * The original queue.\n+\t\t */\n+\t\t@NonNull\n+\t\tprivate final Queue<T> base;\n+\n+\t\t/**\n+\t\t * The signal object to be notified on.\n+\t\t */\n+\t\tprivate final Object signal;\n+\n+\t\t@Override\n+\t\tprotected Queue<T> delegate() {\n+\t\t\treturn base;\n+\t\t}\n+\n+\t\tprotected void doNotify() {\n+\t\t\tlog.trace(\"Awakening a thread for new Work.\");\n+\t\t\tsynchronized (signal) {\n+\t\t\t\tsignal.notify();\n+\t\t\t}\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to offer a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean offer(T element) {\n+\t\t\tfinal boolean offer = super.offer(element);\n+\n+\t\t\tif (offer) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+\t\t\treturn offer;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to add a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean add(T element) {\n+\t\t\tfinal boolean add = super.add(element);\n+\n+\t\t\tif (add) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+\t\t\treturn add;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to offer multiple elements to the queue, if successful notify all threads waiting on signal.\n+\t\t *\n+\t\t * @implNote this can actually cause some threads to receive nothing, as the collections size might be smaller than the number of waiting threads.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean addAll(Collection<? extends T> collection) {\n+\t\t\tfinal boolean addAll = super.addAll(collection);\n+\n+\t\t\tif (addAll) {\n+\t\t\t\t//TODO does this cause problems?\n+\t\t\t\tsynchronized (signal) {\n+\t\t\t\t\tsignal.notifyAll();\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn addAll;\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Create a new queue adding it as sub-queue if there is a slot available.\n+\t *\n+\t * @return\n+\t * @throws IllegalStateException when no more slots are available.\n+\t */\n+\tpublic Queue<E> createQueue() {\n+\t\t// TODO: 25.06.2020 FK: add supplier as creation parameter\n+\t\tfinal Queue<E> out = new SignallingForwardingQueue<E>(Queues.newConcurrentLinkedQueue(), signal);\n+\t\tfinal int free;\n+\n+\t\tsynchronized (signal) {\n+\t\t\tfree = ArrayUtils.indexOf(queues, null);\n+\n+\t\t\tif (free == -1) {\n+\t\t\t\tlog.warn(\"Growing RoundRobinQueue to new size {}\", (int) ((double) getCapacity() * GROWTH_FACTOR));", "originalCommit": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY0NTUwOQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447645509", "bodyText": "Ich vertraue Typsystemen nicht gut genug f\u00fcr sowas, finde das so sauberer", "author": "awildturtok", "createdAt": "2020-06-30T12:32:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE4MTAzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE4NDU3Mw==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447184573", "bodyText": "Der Iterator leert diese Queue, dass sollte doch nicht so sein, oder?", "author": "thoniTUB", "createdAt": "2020-06-29T18:55:44Z", "path": "backend/src/main/java/com/bakdata/conquery/util/RoundRobinQueue.java", "diffHunk": "@@ -0,0 +1,457 @@\n+package com.bakdata.conquery.util;\n+\n+import java.util.AbstractQueue;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+\n+import javax.validation.constraints.Min;\n+\n+import com.google.common.collect.ForwardingQueue;\n+import com.google.common.collect.Queues;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.commons.lang3.ArrayUtils;\n+import org.jetbrains.annotations.NotNull;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Class implementing a queue that is backed by multiple queues at once that are evenly processed, avoiding starvation of jobs when a single producer creates a lot of jobs.\n+ *\n+ * @param <E>\n+ */\n+@Slf4j\n+// TODO: 26.06.2020 fk: migrate logging to trace\n+public class RoundRobinQueue<E> extends AbstractQueue<E> implements BlockingQueue<E> {\n+\n+\t/**\n+\t * If {@code queues} is full, it is grown by {@code GROWTH_FACTOR}.\n+\t */\n+\tprivate static final double GROWTH_FACTOR = 1.5d;\n+\n+\t/**\n+\t * The backing queues.\n+\t *\n+\t * @implNote null denotes no queue, and this queue must not be contiguously filled: Deletions just unset the queue so it is no longer processed.\n+\t */\n+\tprivate Queue<E>[] queues;\n+\tprivate final Object signal = new Object();\n+\n+\t/**\n+\t * The index to start polling. This is remembered so we don't have a bias towards lower indices.\n+\t */\n+\tprivate final ThreadLocal<Integer> cycleIndex = ThreadLocal.withInitial(() -> 0);\n+\n+\tpublic RoundRobinQueue(@Min(1) int capacity) {\n+\t\tsuper();\n+\t\tqueues = new Queue[capacity];\n+\t}\n+\n+\t/**\n+\t * @return Maximum number of queues allowed in this queue.\n+\t */\n+\tpublic int getCapacity() {\n+\t\treturn queues.length;\n+\t}\n+\n+\t/**\n+\t * @return Number of sub-queues.\n+\t */\n+\tpublic int getNQueues() {\n+\t\treturn (int) Arrays.stream(queues).filter(Objects::nonNull).count();\n+\t}\n+\n+\n+\t/**\n+\t * Helper class that notifies on {@code signal} when a new object is added to it queue, awakening waiting threads. This effectively implements a semaphore aroud {@code signal} as notify only awakens a single waiting thread.\n+\t */\n+\t@RequiredArgsConstructor\n+\tprivate static class SignallingForwardingQueue<T> extends ForwardingQueue<T> {\n+\n+\t\t/**\n+\t\t * The original queue.\n+\t\t */\n+\t\t@NonNull\n+\t\tprivate final Queue<T> base;\n+\n+\t\t/**\n+\t\t * The signal object to be notified on.\n+\t\t */\n+\t\tprivate final Object signal;\n+\n+\t\t@Override\n+\t\tprotected Queue<T> delegate() {\n+\t\t\treturn base;\n+\t\t}\n+\n+\t\tprotected void doNotify() {\n+\t\t\tlog.trace(\"Awakening a thread for new Work.\");\n+\t\t\tsynchronized (signal) {\n+\t\t\t\tsignal.notify();\n+\t\t\t}\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to offer a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean offer(T element) {\n+\t\t\tfinal boolean offer = super.offer(element);\n+\n+\t\t\tif (offer) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+\t\t\treturn offer;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to add a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean add(T element) {\n+\t\t\tfinal boolean add = super.add(element);\n+\n+\t\t\tif (add) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+\t\t\treturn add;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to offer multiple elements to the queue, if successful notify all threads waiting on signal.\n+\t\t *\n+\t\t * @implNote this can actually cause some threads to receive nothing, as the collections size might be smaller than the number of waiting threads.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean addAll(Collection<? extends T> collection) {\n+\t\t\tfinal boolean addAll = super.addAll(collection);\n+\n+\t\t\tif (addAll) {\n+\t\t\t\t//TODO does this cause problems?\n+\t\t\t\tsynchronized (signal) {\n+\t\t\t\t\tsignal.notifyAll();\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn addAll;\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Create a new queue adding it as sub-queue if there is a slot available.\n+\t *\n+\t * @return\n+\t * @throws IllegalStateException when no more slots are available.\n+\t */\n+\tpublic Queue<E> createQueue() {\n+\t\t// TODO: 25.06.2020 FK: add supplier as creation parameter\n+\t\tfinal Queue<E> out = new SignallingForwardingQueue<E>(Queues.newConcurrentLinkedQueue(), signal);\n+\t\tfinal int free;\n+\n+\t\tsynchronized (signal) {\n+\t\t\tfree = ArrayUtils.indexOf(queues, null);\n+\n+\t\t\tif (free == -1) {\n+\t\t\t\tlog.warn(\"Growing RoundRobinQueue to new size {}\", (int) ((double) getCapacity() * GROWTH_FACTOR));\n+\t\t\t\tqueues = Arrays.copyOf(queues, (int) ((double) getCapacity() * GROWTH_FACTOR));\n+\t\t\t}\n+\n+\t\t\tqueues[free] = out;\n+\t\t}\n+\n+\t\tlog.debug(\"Create a new Queue at {}. Now have {}\", free, getNQueues());\n+\n+\t\treturn out;\n+\t}\n+\n+\t/**\n+\t * Tries to remove the queue if it is inside.\n+\t *\n+\t * @param del the Queue to delete.\n+\t * @return true if the queue was deleted, false if not.\n+\t */\n+\tpublic boolean removeQueue(Queue<E> del) {\n+\t\tfinal int index;\n+\t\tsynchronized (signal) {\n+\t\t\tindex = ArrayUtils.indexOf(queues, del);\n+\n+\t\t\tif (index == -1) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\n+\t\t\tqueues[index] = null;\n+\t\t}\n+\n+\t\tlog.debug(\"Removing Queue at {}. Now have {}\", index, getNQueues());\n+\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * The number of elements over all queues.\n+\t */\n+\t@Override\n+\tpublic int size() {\n+\t\tint sum = 0;\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null) {\n+\t\t\t\tsum += queue.size();\n+\t\t\t}\n+\t\t}\n+\t\treturn sum;\n+\t}\n+\n+\t/**\n+\t * @return true, if all queues are empty.\n+\t */\n+\t@Override\n+\tpublic boolean isEmpty() {\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null && !queue.isEmpty()) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * @param o the Object to check.\n+\t * @return True, if any queue contains the element.\n+\t */\n+\t@Override\n+\tpublic boolean contains(Object o) {\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null && queue.contains(o)) {\n+\t\t\t\treturn true;\n+\t\t\t}\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * @param c the objects to check.\n+\t * @return True, if all objects are contained in any of the queues.\n+\t */\n+\t@Override\n+\tpublic boolean containsAll(@NotNull Collection<?> c) {\n+\t\tfor (Object o : c) {\n+\t\t\tif (!contains(o)) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * Create an iterator looping until the queues are empty.\n+\t */\n+\t@NotNull\n+\t@Override\n+\tpublic Iterator<E> iterator() {\n+\t\treturn new Iterator<E>() {\n+\t\t\t@Override\n+\t\t\tpublic boolean hasNext() {\n+\t\t\t\treturn !isEmpty();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic E next() {\n+\t\t\t\treturn poll();", "originalCommit": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE4Njk0MA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447186940", "bodyText": "Ich w\u00fcrde ihn weglassen, wenn er nicht gebraucht wird.", "author": "thoniTUB", "createdAt": "2020-06-29T18:59:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE4NDU3Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzUzNjc2MQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447536761", "bodyText": "So implementieren andere Queues es auch", "author": "awildturtok", "createdAt": "2020-06-30T09:15:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzE4NDU3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQyNDk3OQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447424979", "bodyText": "Ich w\u00fcrde das increment in eine extra Funktion auslagern, da du die Magic \u00f6fter machst.\nIch bin mir gerade auch nicht \u00fcber das  % (queues.length - 1) sicher. Wenn queues.length=1 ist, dann solltest du hier eine  ArithmeticException: / by zero bekommen.", "author": "thoniTUB", "createdAt": "2020-06-30T05:49:54Z", "path": "backend/src/main/java/com/bakdata/conquery/util/RoundRobinQueue.java", "diffHunk": "@@ -0,0 +1,457 @@\n+package com.bakdata.conquery.util;\n+\n+import java.util.AbstractQueue;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+\n+import javax.validation.constraints.Min;\n+\n+import com.google.common.collect.ForwardingQueue;\n+import com.google.common.collect.Queues;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.commons.lang3.ArrayUtils;\n+import org.jetbrains.annotations.NotNull;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Class implementing a queue that is backed by multiple queues at once that are evenly processed, avoiding starvation of jobs when a single producer creates a lot of jobs.\n+ *\n+ * @param <E>\n+ */\n+@Slf4j\n+// TODO: 26.06.2020 fk: migrate logging to trace\n+public class RoundRobinQueue<E> extends AbstractQueue<E> implements BlockingQueue<E> {\n+\n+\t/**\n+\t * If {@code queues} is full, it is grown by {@code GROWTH_FACTOR}.\n+\t */\n+\tprivate static final double GROWTH_FACTOR = 1.5d;\n+\n+\t/**\n+\t * The backing queues.\n+\t *\n+\t * @implNote null denotes no queue, and this queue must not be contiguously filled: Deletions just unset the queue so it is no longer processed.\n+\t */\n+\tprivate Queue<E>[] queues;\n+\tprivate final Object signal = new Object();\n+\n+\t/**\n+\t * The index to start polling. This is remembered so we don't have a bias towards lower indices.\n+\t */\n+\tprivate final ThreadLocal<Integer> cycleIndex = ThreadLocal.withInitial(() -> 0);\n+\n+\tpublic RoundRobinQueue(@Min(1) int capacity) {\n+\t\tsuper();\n+\t\tqueues = new Queue[capacity];\n+\t}\n+\n+\t/**\n+\t * @return Maximum number of queues allowed in this queue.\n+\t */\n+\tpublic int getCapacity() {\n+\t\treturn queues.length;\n+\t}\n+\n+\t/**\n+\t * @return Number of sub-queues.\n+\t */\n+\tpublic int getNQueues() {\n+\t\treturn (int) Arrays.stream(queues).filter(Objects::nonNull).count();\n+\t}\n+\n+\n+\t/**\n+\t * Helper class that notifies on {@code signal} when a new object is added to it queue, awakening waiting threads. This effectively implements a semaphore aroud {@code signal} as notify only awakens a single waiting thread.\n+\t */\n+\t@RequiredArgsConstructor\n+\tprivate static class SignallingForwardingQueue<T> extends ForwardingQueue<T> {\n+\n+\t\t/**\n+\t\t * The original queue.\n+\t\t */\n+\t\t@NonNull\n+\t\tprivate final Queue<T> base;\n+\n+\t\t/**\n+\t\t * The signal object to be notified on.\n+\t\t */\n+\t\tprivate final Object signal;\n+\n+\t\t@Override\n+\t\tprotected Queue<T> delegate() {\n+\t\t\treturn base;\n+\t\t}\n+\n+\t\tprotected void doNotify() {\n+\t\t\tlog.trace(\"Awakening a thread for new Work.\");\n+\t\t\tsynchronized (signal) {\n+\t\t\t\tsignal.notify();\n+\t\t\t}\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to offer a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean offer(T element) {\n+\t\t\tfinal boolean offer = super.offer(element);\n+\n+\t\t\tif (offer) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+\t\t\treturn offer;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to add a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean add(T element) {\n+\t\t\tfinal boolean add = super.add(element);\n+\n+\t\t\tif (add) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+\t\t\treturn add;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to offer multiple elements to the queue, if successful notify all threads waiting on signal.\n+\t\t *\n+\t\t * @implNote this can actually cause some threads to receive nothing, as the collections size might be smaller than the number of waiting threads.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean addAll(Collection<? extends T> collection) {\n+\t\t\tfinal boolean addAll = super.addAll(collection);\n+\n+\t\t\tif (addAll) {\n+\t\t\t\t//TODO does this cause problems?\n+\t\t\t\tsynchronized (signal) {\n+\t\t\t\t\tsignal.notifyAll();\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn addAll;\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Create a new queue adding it as sub-queue if there is a slot available.\n+\t *\n+\t * @return\n+\t * @throws IllegalStateException when no more slots are available.\n+\t */\n+\tpublic Queue<E> createQueue() {\n+\t\t// TODO: 25.06.2020 FK: add supplier as creation parameter\n+\t\tfinal Queue<E> out = new SignallingForwardingQueue<E>(Queues.newConcurrentLinkedQueue(), signal);\n+\t\tfinal int free;\n+\n+\t\tsynchronized (signal) {\n+\t\t\tfree = ArrayUtils.indexOf(queues, null);\n+\n+\t\t\tif (free == -1) {\n+\t\t\t\tlog.warn(\"Growing RoundRobinQueue to new size {}\", (int) ((double) getCapacity() * GROWTH_FACTOR));\n+\t\t\t\tqueues = Arrays.copyOf(queues, (int) ((double) getCapacity() * GROWTH_FACTOR));\n+\t\t\t}\n+\n+\t\t\tqueues[free] = out;\n+\t\t}\n+\n+\t\tlog.debug(\"Create a new Queue at {}. Now have {}\", free, getNQueues());\n+\n+\t\treturn out;\n+\t}\n+\n+\t/**\n+\t * Tries to remove the queue if it is inside.\n+\t *\n+\t * @param del the Queue to delete.\n+\t * @return true if the queue was deleted, false if not.\n+\t */\n+\tpublic boolean removeQueue(Queue<E> del) {\n+\t\tfinal int index;\n+\t\tsynchronized (signal) {\n+\t\t\tindex = ArrayUtils.indexOf(queues, del);\n+\n+\t\t\tif (index == -1) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\n+\t\t\tqueues[index] = null;\n+\t\t}\n+\n+\t\tlog.debug(\"Removing Queue at {}. Now have {}\", index, getNQueues());\n+\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * The number of elements over all queues.\n+\t */\n+\t@Override\n+\tpublic int size() {\n+\t\tint sum = 0;\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null) {\n+\t\t\t\tsum += queue.size();\n+\t\t\t}\n+\t\t}\n+\t\treturn sum;\n+\t}\n+\n+\t/**\n+\t * @return true, if all queues are empty.\n+\t */\n+\t@Override\n+\tpublic boolean isEmpty() {\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null && !queue.isEmpty()) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * @param o the Object to check.\n+\t * @return True, if any queue contains the element.\n+\t */\n+\t@Override\n+\tpublic boolean contains(Object o) {\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null && queue.contains(o)) {\n+\t\t\t\treturn true;\n+\t\t\t}\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * @param c the objects to check.\n+\t * @return True, if all objects are contained in any of the queues.\n+\t */\n+\t@Override\n+\tpublic boolean containsAll(@NotNull Collection<?> c) {\n+\t\tfor (Object o : c) {\n+\t\t\tif (!contains(o)) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * Create an iterator looping until the queues are empty.\n+\t */\n+\t@NotNull\n+\t@Override\n+\tpublic Iterator<E> iterator() {\n+\t\treturn new Iterator<E>() {\n+\t\t\t@Override\n+\t\t\tpublic boolean hasNext() {\n+\t\t\t\treturn !isEmpty();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic E next() {\n+\t\t\t\treturn poll();\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\t/**\n+\t * Take one element from the queue, blocking until there is a new object available.\n+\t *\n+\t * @implNote see {@link RoundRobinQueue::poll()} for implementation details.\n+\t */\n+\t@NotNull\n+\t@Override\n+\tpublic E take() throws InterruptedException {\n+\t\twhile (true) {\n+\t\t\tE out = poll();\n+\t\t\tif (out != null) {\n+\t\t\t\treturn out;\n+\t\t\t}\n+\n+\t\t\tlog.trace(\"Thread[{}], no element in Queue, waiting on Signal.\", Thread.currentThread().getName());\n+\n+\t\t\tsynchronized (signal) {\n+\t\t\t\tsignal.wait();\n+\t\t\t}\n+\n+\t\t\tlog.trace(\"Thread[{}] Awakened for new Work.\", Thread.currentThread().getName());\n+\t\t}\n+\t}\n+\n+\n+\t/**\n+\t * Try taking one element from the queue, blocking until there is a new object available, or the timeout expires.\n+\t *\n+\t * @implNote see {@link RoundRobinQueue::poll()} for implementation details.\n+\t */\n+\t@Nullable\n+\t@Override\n+\tpublic E poll(long timeout, @NotNull TimeUnit unit) throws InterruptedException {\n+\t\tE out = poll();\n+\n+\t\tif (out != null) {\n+\t\t\treturn out;\n+\t\t}\n+\n+\t\tlog.trace(\"Thread[{}], no element in Queue, waiting on Signal.\", Thread.currentThread().getName());\n+\n+\t\tsynchronized (signal) {\n+\t\t\tunit.timedWait(signal, timeout);\n+\t\t}\n+\n+\t\tlog.trace(\"Thread[{}] Awakened for new Work.\", Thread.currentThread().getName());\n+\n+\t\treturn poll();\n+\t}\n+\n+\n+\t/**\n+\t * Find an element in any queue. Start searching in a different queue each time.\n+\t */\n+\t@Override\n+\tpublic E poll() {\n+\t\t// The next queue we look poll\n+\t\tfinal int begin = cycleIndex.get();\n+\n+\t\tfor (int offset = 0; offset < queues.length; offset++) {\n+\t\t\tfinal int index = (begin + offset) % (queues.length - 1);", "originalCommit": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQyNjA5MA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447426090", "bodyText": "Eigentlich solltest du % queues.length wenn ich \u00fcberlege. Sonst l\u00e4sst du doch die letzte Queue aus", "author": "thoniTUB", "createdAt": "2020-06-30T05:53:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQyNDk3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzU1Mjc1NA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447552754", "bodyText": "stimmt! Wobei auslagern hier doof ist", "author": "awildturtok", "createdAt": "2020-06-30T09:41:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQyNDk3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQyNjU4NQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447426585", "bodyText": "Warum beginnst du hier bei 1?", "author": "thoniTUB", "createdAt": "2020-06-30T05:54:41Z", "path": "backend/src/main/java/com/bakdata/conquery/util/RoundRobinQueue.java", "diffHunk": "@@ -0,0 +1,457 @@\n+package com.bakdata.conquery.util;\n+\n+import java.util.AbstractQueue;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+\n+import javax.validation.constraints.Min;\n+\n+import com.google.common.collect.ForwardingQueue;\n+import com.google.common.collect.Queues;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.commons.lang3.ArrayUtils;\n+import org.jetbrains.annotations.NotNull;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Class implementing a queue that is backed by multiple queues at once that are evenly processed, avoiding starvation of jobs when a single producer creates a lot of jobs.\n+ *\n+ * @param <E>\n+ */\n+@Slf4j\n+// TODO: 26.06.2020 fk: migrate logging to trace\n+public class RoundRobinQueue<E> extends AbstractQueue<E> implements BlockingQueue<E> {\n+\n+\t/**\n+\t * If {@code queues} is full, it is grown by {@code GROWTH_FACTOR}.\n+\t */\n+\tprivate static final double GROWTH_FACTOR = 1.5d;\n+\n+\t/**\n+\t * The backing queues.\n+\t *\n+\t * @implNote null denotes no queue, and this queue must not be contiguously filled: Deletions just unset the queue so it is no longer processed.\n+\t */\n+\tprivate Queue<E>[] queues;\n+\tprivate final Object signal = new Object();\n+\n+\t/**\n+\t * The index to start polling. This is remembered so we don't have a bias towards lower indices.\n+\t */\n+\tprivate final ThreadLocal<Integer> cycleIndex = ThreadLocal.withInitial(() -> 0);\n+\n+\tpublic RoundRobinQueue(@Min(1) int capacity) {\n+\t\tsuper();\n+\t\tqueues = new Queue[capacity];\n+\t}\n+\n+\t/**\n+\t * @return Maximum number of queues allowed in this queue.\n+\t */\n+\tpublic int getCapacity() {\n+\t\treturn queues.length;\n+\t}\n+\n+\t/**\n+\t * @return Number of sub-queues.\n+\t */\n+\tpublic int getNQueues() {\n+\t\treturn (int) Arrays.stream(queues).filter(Objects::nonNull).count();\n+\t}\n+\n+\n+\t/**\n+\t * Helper class that notifies on {@code signal} when a new object is added to it queue, awakening waiting threads. This effectively implements a semaphore aroud {@code signal} as notify only awakens a single waiting thread.\n+\t */\n+\t@RequiredArgsConstructor\n+\tprivate static class SignallingForwardingQueue<T> extends ForwardingQueue<T> {\n+\n+\t\t/**\n+\t\t * The original queue.\n+\t\t */\n+\t\t@NonNull\n+\t\tprivate final Queue<T> base;\n+\n+\t\t/**\n+\t\t * The signal object to be notified on.\n+\t\t */\n+\t\tprivate final Object signal;\n+\n+\t\t@Override\n+\t\tprotected Queue<T> delegate() {\n+\t\t\treturn base;\n+\t\t}\n+\n+\t\tprotected void doNotify() {\n+\t\t\tlog.trace(\"Awakening a thread for new Work.\");\n+\t\t\tsynchronized (signal) {\n+\t\t\t\tsignal.notify();\n+\t\t\t}\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to offer a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean offer(T element) {\n+\t\t\tfinal boolean offer = super.offer(element);\n+\n+\t\t\tif (offer) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+\t\t\treturn offer;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to add a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean add(T element) {\n+\t\t\tfinal boolean add = super.add(element);\n+\n+\t\t\tif (add) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+\t\t\treturn add;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to offer multiple elements to the queue, if successful notify all threads waiting on signal.\n+\t\t *\n+\t\t * @implNote this can actually cause some threads to receive nothing, as the collections size might be smaller than the number of waiting threads.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean addAll(Collection<? extends T> collection) {\n+\t\t\tfinal boolean addAll = super.addAll(collection);\n+\n+\t\t\tif (addAll) {\n+\t\t\t\t//TODO does this cause problems?\n+\t\t\t\tsynchronized (signal) {\n+\t\t\t\t\tsignal.notifyAll();\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn addAll;\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Create a new queue adding it as sub-queue if there is a slot available.\n+\t *\n+\t * @return\n+\t * @throws IllegalStateException when no more slots are available.\n+\t */\n+\tpublic Queue<E> createQueue() {\n+\t\t// TODO: 25.06.2020 FK: add supplier as creation parameter\n+\t\tfinal Queue<E> out = new SignallingForwardingQueue<E>(Queues.newConcurrentLinkedQueue(), signal);\n+\t\tfinal int free;\n+\n+\t\tsynchronized (signal) {\n+\t\t\tfree = ArrayUtils.indexOf(queues, null);\n+\n+\t\t\tif (free == -1) {\n+\t\t\t\tlog.warn(\"Growing RoundRobinQueue to new size {}\", (int) ((double) getCapacity() * GROWTH_FACTOR));\n+\t\t\t\tqueues = Arrays.copyOf(queues, (int) ((double) getCapacity() * GROWTH_FACTOR));\n+\t\t\t}\n+\n+\t\t\tqueues[free] = out;\n+\t\t}\n+\n+\t\tlog.debug(\"Create a new Queue at {}. Now have {}\", free, getNQueues());\n+\n+\t\treturn out;\n+\t}\n+\n+\t/**\n+\t * Tries to remove the queue if it is inside.\n+\t *\n+\t * @param del the Queue to delete.\n+\t * @return true if the queue was deleted, false if not.\n+\t */\n+\tpublic boolean removeQueue(Queue<E> del) {\n+\t\tfinal int index;\n+\t\tsynchronized (signal) {\n+\t\t\tindex = ArrayUtils.indexOf(queues, del);\n+\n+\t\t\tif (index == -1) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\n+\t\t\tqueues[index] = null;\n+\t\t}\n+\n+\t\tlog.debug(\"Removing Queue at {}. Now have {}\", index, getNQueues());\n+\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * The number of elements over all queues.\n+\t */\n+\t@Override\n+\tpublic int size() {\n+\t\tint sum = 0;\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null) {\n+\t\t\t\tsum += queue.size();\n+\t\t\t}\n+\t\t}\n+\t\treturn sum;\n+\t}\n+\n+\t/**\n+\t * @return true, if all queues are empty.\n+\t */\n+\t@Override\n+\tpublic boolean isEmpty() {\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null && !queue.isEmpty()) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * @param o the Object to check.\n+\t * @return True, if any queue contains the element.\n+\t */\n+\t@Override\n+\tpublic boolean contains(Object o) {\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null && queue.contains(o)) {\n+\t\t\t\treturn true;\n+\t\t\t}\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * @param c the objects to check.\n+\t * @return True, if all objects are contained in any of the queues.\n+\t */\n+\t@Override\n+\tpublic boolean containsAll(@NotNull Collection<?> c) {\n+\t\tfor (Object o : c) {\n+\t\t\tif (!contains(o)) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * Create an iterator looping until the queues are empty.\n+\t */\n+\t@NotNull\n+\t@Override\n+\tpublic Iterator<E> iterator() {\n+\t\treturn new Iterator<E>() {\n+\t\t\t@Override\n+\t\t\tpublic boolean hasNext() {\n+\t\t\t\treturn !isEmpty();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic E next() {\n+\t\t\t\treturn poll();\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\t/**\n+\t * Take one element from the queue, blocking until there is a new object available.\n+\t *\n+\t * @implNote see {@link RoundRobinQueue::poll()} for implementation details.\n+\t */\n+\t@NotNull\n+\t@Override\n+\tpublic E take() throws InterruptedException {\n+\t\twhile (true) {\n+\t\t\tE out = poll();\n+\t\t\tif (out != null) {\n+\t\t\t\treturn out;\n+\t\t\t}\n+\n+\t\t\tlog.trace(\"Thread[{}], no element in Queue, waiting on Signal.\", Thread.currentThread().getName());\n+\n+\t\t\tsynchronized (signal) {\n+\t\t\t\tsignal.wait();\n+\t\t\t}\n+\n+\t\t\tlog.trace(\"Thread[{}] Awakened for new Work.\", Thread.currentThread().getName());\n+\t\t}\n+\t}\n+\n+\n+\t/**\n+\t * Try taking one element from the queue, blocking until there is a new object available, or the timeout expires.\n+\t *\n+\t * @implNote see {@link RoundRobinQueue::poll()} for implementation details.\n+\t */\n+\t@Nullable\n+\t@Override\n+\tpublic E poll(long timeout, @NotNull TimeUnit unit) throws InterruptedException {\n+\t\tE out = poll();\n+\n+\t\tif (out != null) {\n+\t\t\treturn out;\n+\t\t}\n+\n+\t\tlog.trace(\"Thread[{}], no element in Queue, waiting on Signal.\", Thread.currentThread().getName());\n+\n+\t\tsynchronized (signal) {\n+\t\t\tunit.timedWait(signal, timeout);\n+\t\t}\n+\n+\t\tlog.trace(\"Thread[{}] Awakened for new Work.\", Thread.currentThread().getName());\n+\n+\t\treturn poll();\n+\t}\n+\n+\n+\t/**\n+\t * Find an element in any queue. Start searching in a different queue each time.\n+\t */\n+\t@Override\n+\tpublic E poll() {\n+\t\t// The next queue we look poll\n+\t\tfinal int begin = cycleIndex.get();\n+\n+\t\tfor (int offset = 0; offset < queues.length; offset++) {\n+\t\t\tfinal int index = (begin + offset) % (queues.length - 1);\n+\t\t\tQueue<E> curr = queues[index];\n+\n+\t\t\tif (curr == null) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\n+\t\t\t// Poll once, if successful update the index of the last polled queue and return the polled element.\n+\t\t\tE out = curr.poll();\n+\n+\t\t\tif (out != null) {\n+\t\t\t\tlog.trace(\"Thread[{}] found Work in Queue[{}].\", Thread.currentThread().getName(), index);\n+\t\t\t\tcycleIndex.set(index + 1);\n+\t\t\t\treturn out;\n+\t\t\t}\n+\t\t}\n+\n+\t\tlog.trace(\"All Queues were empty.\");\n+\n+\n+\t\t// If no queue had elements, return null.\n+\t\treturn null;\n+\t}\n+\n+\n+\t/**\n+\t * Peek all queues for the next available element.\n+\t *\n+\t * @apiNote this method is NOT guaranteed to be stable: peeking multiple times will peek different queues.\n+\t * @implNote see {@link RoundRobinQueue::poll()} for implementation details.\n+\t */\n+\t@Override\n+\tpublic E peek() {\n+\t\tfinal int begin = cycleIndex.get();\n+\n+\t\tfor (int offset = 1; offset < queues.length; offset++) {", "originalCommit": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQyNzAxNA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447427014", "bodyText": "Ich denke, dass gerade der cycleIndex gewrapt werden sollte", "author": "thoniTUB", "createdAt": "2020-06-30T05:55:46Z", "path": "backend/src/main/java/com/bakdata/conquery/util/RoundRobinQueue.java", "diffHunk": "@@ -0,0 +1,457 @@\n+package com.bakdata.conquery.util;\n+\n+import java.util.AbstractQueue;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+\n+import javax.validation.constraints.Min;\n+\n+import com.google.common.collect.ForwardingQueue;\n+import com.google.common.collect.Queues;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.commons.lang3.ArrayUtils;\n+import org.jetbrains.annotations.NotNull;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Class implementing a queue that is backed by multiple queues at once that are evenly processed, avoiding starvation of jobs when a single producer creates a lot of jobs.\n+ *\n+ * @param <E>\n+ */\n+@Slf4j\n+// TODO: 26.06.2020 fk: migrate logging to trace\n+public class RoundRobinQueue<E> extends AbstractQueue<E> implements BlockingQueue<E> {\n+\n+\t/**\n+\t * If {@code queues} is full, it is grown by {@code GROWTH_FACTOR}.\n+\t */\n+\tprivate static final double GROWTH_FACTOR = 1.5d;\n+\n+\t/**\n+\t * The backing queues.\n+\t *\n+\t * @implNote null denotes no queue, and this queue must not be contiguously filled: Deletions just unset the queue so it is no longer processed.\n+\t */\n+\tprivate Queue<E>[] queues;\n+\tprivate final Object signal = new Object();\n+\n+\t/**\n+\t * The index to start polling. This is remembered so we don't have a bias towards lower indices.\n+\t */\n+\tprivate final ThreadLocal<Integer> cycleIndex = ThreadLocal.withInitial(() -> 0);\n+\n+\tpublic RoundRobinQueue(@Min(1) int capacity) {\n+\t\tsuper();\n+\t\tqueues = new Queue[capacity];\n+\t}\n+\n+\t/**\n+\t * @return Maximum number of queues allowed in this queue.\n+\t */\n+\tpublic int getCapacity() {\n+\t\treturn queues.length;\n+\t}\n+\n+\t/**\n+\t * @return Number of sub-queues.\n+\t */\n+\tpublic int getNQueues() {\n+\t\treturn (int) Arrays.stream(queues).filter(Objects::nonNull).count();\n+\t}\n+\n+\n+\t/**\n+\t * Helper class that notifies on {@code signal} when a new object is added to it queue, awakening waiting threads. This effectively implements a semaphore aroud {@code signal} as notify only awakens a single waiting thread.\n+\t */\n+\t@RequiredArgsConstructor\n+\tprivate static class SignallingForwardingQueue<T> extends ForwardingQueue<T> {\n+\n+\t\t/**\n+\t\t * The original queue.\n+\t\t */\n+\t\t@NonNull\n+\t\tprivate final Queue<T> base;\n+\n+\t\t/**\n+\t\t * The signal object to be notified on.\n+\t\t */\n+\t\tprivate final Object signal;\n+\n+\t\t@Override\n+\t\tprotected Queue<T> delegate() {\n+\t\t\treturn base;\n+\t\t}\n+\n+\t\tprotected void doNotify() {\n+\t\t\tlog.trace(\"Awakening a thread for new Work.\");\n+\t\t\tsynchronized (signal) {\n+\t\t\t\tsignal.notify();\n+\t\t\t}\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to offer a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean offer(T element) {\n+\t\t\tfinal boolean offer = super.offer(element);\n+\n+\t\t\tif (offer) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+\t\t\treturn offer;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to add a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean add(T element) {\n+\t\t\tfinal boolean add = super.add(element);\n+\n+\t\t\tif (add) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+\t\t\treturn add;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to offer multiple elements to the queue, if successful notify all threads waiting on signal.\n+\t\t *\n+\t\t * @implNote this can actually cause some threads to receive nothing, as the collections size might be smaller than the number of waiting threads.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean addAll(Collection<? extends T> collection) {\n+\t\t\tfinal boolean addAll = super.addAll(collection);\n+\n+\t\t\tif (addAll) {\n+\t\t\t\t//TODO does this cause problems?\n+\t\t\t\tsynchronized (signal) {\n+\t\t\t\t\tsignal.notifyAll();\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn addAll;\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Create a new queue adding it as sub-queue if there is a slot available.\n+\t *\n+\t * @return\n+\t * @throws IllegalStateException when no more slots are available.\n+\t */\n+\tpublic Queue<E> createQueue() {\n+\t\t// TODO: 25.06.2020 FK: add supplier as creation parameter\n+\t\tfinal Queue<E> out = new SignallingForwardingQueue<E>(Queues.newConcurrentLinkedQueue(), signal);\n+\t\tfinal int free;\n+\n+\t\tsynchronized (signal) {\n+\t\t\tfree = ArrayUtils.indexOf(queues, null);\n+\n+\t\t\tif (free == -1) {\n+\t\t\t\tlog.warn(\"Growing RoundRobinQueue to new size {}\", (int) ((double) getCapacity() * GROWTH_FACTOR));\n+\t\t\t\tqueues = Arrays.copyOf(queues, (int) ((double) getCapacity() * GROWTH_FACTOR));\n+\t\t\t}\n+\n+\t\t\tqueues[free] = out;\n+\t\t}\n+\n+\t\tlog.debug(\"Create a new Queue at {}. Now have {}\", free, getNQueues());\n+\n+\t\treturn out;\n+\t}\n+\n+\t/**\n+\t * Tries to remove the queue if it is inside.\n+\t *\n+\t * @param del the Queue to delete.\n+\t * @return true if the queue was deleted, false if not.\n+\t */\n+\tpublic boolean removeQueue(Queue<E> del) {\n+\t\tfinal int index;\n+\t\tsynchronized (signal) {\n+\t\t\tindex = ArrayUtils.indexOf(queues, del);\n+\n+\t\t\tif (index == -1) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\n+\t\t\tqueues[index] = null;\n+\t\t}\n+\n+\t\tlog.debug(\"Removing Queue at {}. Now have {}\", index, getNQueues());\n+\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * The number of elements over all queues.\n+\t */\n+\t@Override\n+\tpublic int size() {\n+\t\tint sum = 0;\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null) {\n+\t\t\t\tsum += queue.size();\n+\t\t\t}\n+\t\t}\n+\t\treturn sum;\n+\t}\n+\n+\t/**\n+\t * @return true, if all queues are empty.\n+\t */\n+\t@Override\n+\tpublic boolean isEmpty() {\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null && !queue.isEmpty()) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * @param o the Object to check.\n+\t * @return True, if any queue contains the element.\n+\t */\n+\t@Override\n+\tpublic boolean contains(Object o) {\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null && queue.contains(o)) {\n+\t\t\t\treturn true;\n+\t\t\t}\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * @param c the objects to check.\n+\t * @return True, if all objects are contained in any of the queues.\n+\t */\n+\t@Override\n+\tpublic boolean containsAll(@NotNull Collection<?> c) {\n+\t\tfor (Object o : c) {\n+\t\t\tif (!contains(o)) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * Create an iterator looping until the queues are empty.\n+\t */\n+\t@NotNull\n+\t@Override\n+\tpublic Iterator<E> iterator() {\n+\t\treturn new Iterator<E>() {\n+\t\t\t@Override\n+\t\t\tpublic boolean hasNext() {\n+\t\t\t\treturn !isEmpty();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic E next() {\n+\t\t\t\treturn poll();\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\t/**\n+\t * Take one element from the queue, blocking until there is a new object available.\n+\t *\n+\t * @implNote see {@link RoundRobinQueue::poll()} for implementation details.\n+\t */\n+\t@NotNull\n+\t@Override\n+\tpublic E take() throws InterruptedException {\n+\t\twhile (true) {\n+\t\t\tE out = poll();\n+\t\t\tif (out != null) {\n+\t\t\t\treturn out;\n+\t\t\t}\n+\n+\t\t\tlog.trace(\"Thread[{}], no element in Queue, waiting on Signal.\", Thread.currentThread().getName());\n+\n+\t\t\tsynchronized (signal) {\n+\t\t\t\tsignal.wait();\n+\t\t\t}\n+\n+\t\t\tlog.trace(\"Thread[{}] Awakened for new Work.\", Thread.currentThread().getName());\n+\t\t}\n+\t}\n+\n+\n+\t/**\n+\t * Try taking one element from the queue, blocking until there is a new object available, or the timeout expires.\n+\t *\n+\t * @implNote see {@link RoundRobinQueue::poll()} for implementation details.\n+\t */\n+\t@Nullable\n+\t@Override\n+\tpublic E poll(long timeout, @NotNull TimeUnit unit) throws InterruptedException {\n+\t\tE out = poll();\n+\n+\t\tif (out != null) {\n+\t\t\treturn out;\n+\t\t}\n+\n+\t\tlog.trace(\"Thread[{}], no element in Queue, waiting on Signal.\", Thread.currentThread().getName());\n+\n+\t\tsynchronized (signal) {\n+\t\t\tunit.timedWait(signal, timeout);\n+\t\t}\n+\n+\t\tlog.trace(\"Thread[{}] Awakened for new Work.\", Thread.currentThread().getName());\n+\n+\t\treturn poll();\n+\t}\n+\n+\n+\t/**\n+\t * Find an element in any queue. Start searching in a different queue each time.\n+\t */\n+\t@Override\n+\tpublic E poll() {\n+\t\t// The next queue we look poll\n+\t\tfinal int begin = cycleIndex.get();\n+\n+\t\tfor (int offset = 0; offset < queues.length; offset++) {\n+\t\t\tfinal int index = (begin + offset) % (queues.length - 1);\n+\t\t\tQueue<E> curr = queues[index];\n+\n+\t\t\tif (curr == null) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\n+\t\t\t// Poll once, if successful update the index of the last polled queue and return the polled element.\n+\t\t\tE out = curr.poll();\n+\n+\t\t\tif (out != null) {\n+\t\t\t\tlog.trace(\"Thread[{}] found Work in Queue[{}].\", Thread.currentThread().getName(), index);\n+\t\t\t\tcycleIndex.set(index + 1);", "originalCommit": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzU1MjU3MQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447552571", "bodyText": "ne weil der modulot wird beim zugriff auf die queues", "author": "awildturtok", "createdAt": "2020-06-30T09:41:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQyNzAxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQzNzE1OQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447437159", "bodyText": "Alle erste mal auf UnsupportedOperationException", "author": "thoniTUB", "createdAt": "2020-06-30T06:22:48Z", "path": "backend/src/main/java/com/bakdata/conquery/util/RoundRobinQueue.java", "diffHunk": "@@ -0,0 +1,457 @@\n+package com.bakdata.conquery.util;\n+\n+import java.util.AbstractQueue;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.Objects;\n+import java.util.Queue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.TimeUnit;\n+\n+import javax.validation.constraints.Min;\n+\n+import com.google.common.collect.ForwardingQueue;\n+import com.google.common.collect.Queues;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.extern.slf4j.Slf4j;\n+import org.apache.commons.lang3.ArrayUtils;\n+import org.jetbrains.annotations.NotNull;\n+import org.jetbrains.annotations.Nullable;\n+\n+/**\n+ * Class implementing a queue that is backed by multiple queues at once that are evenly processed, avoiding starvation of jobs when a single producer creates a lot of jobs.\n+ *\n+ * @param <E>\n+ */\n+@Slf4j\n+// TODO: 26.06.2020 fk: migrate logging to trace\n+public class RoundRobinQueue<E> extends AbstractQueue<E> implements BlockingQueue<E> {\n+\n+\t/**\n+\t * If {@code queues} is full, it is grown by {@code GROWTH_FACTOR}.\n+\t */\n+\tprivate static final double GROWTH_FACTOR = 1.5d;\n+\n+\t/**\n+\t * The backing queues.\n+\t *\n+\t * @implNote null denotes no queue, and this queue must not be contiguously filled: Deletions just unset the queue so it is no longer processed.\n+\t */\n+\tprivate Queue<E>[] queues;\n+\tprivate final Object signal = new Object();\n+\n+\t/**\n+\t * The index to start polling. This is remembered so we don't have a bias towards lower indices.\n+\t */\n+\tprivate final ThreadLocal<Integer> cycleIndex = ThreadLocal.withInitial(() -> 0);\n+\n+\tpublic RoundRobinQueue(@Min(1) int capacity) {\n+\t\tsuper();\n+\t\tqueues = new Queue[capacity];\n+\t}\n+\n+\t/**\n+\t * @return Maximum number of queues allowed in this queue.\n+\t */\n+\tpublic int getCapacity() {\n+\t\treturn queues.length;\n+\t}\n+\n+\t/**\n+\t * @return Number of sub-queues.\n+\t */\n+\tpublic int getNQueues() {\n+\t\treturn (int) Arrays.stream(queues).filter(Objects::nonNull).count();\n+\t}\n+\n+\n+\t/**\n+\t * Helper class that notifies on {@code signal} when a new object is added to it queue, awakening waiting threads. This effectively implements a semaphore aroud {@code signal} as notify only awakens a single waiting thread.\n+\t */\n+\t@RequiredArgsConstructor\n+\tprivate static class SignallingForwardingQueue<T> extends ForwardingQueue<T> {\n+\n+\t\t/**\n+\t\t * The original queue.\n+\t\t */\n+\t\t@NonNull\n+\t\tprivate final Queue<T> base;\n+\n+\t\t/**\n+\t\t * The signal object to be notified on.\n+\t\t */\n+\t\tprivate final Object signal;\n+\n+\t\t@Override\n+\t\tprotected Queue<T> delegate() {\n+\t\t\treturn base;\n+\t\t}\n+\n+\t\tprotected void doNotify() {\n+\t\t\tlog.trace(\"Awakening a thread for new Work.\");\n+\t\t\tsynchronized (signal) {\n+\t\t\t\tsignal.notify();\n+\t\t\t}\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to offer a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean offer(T element) {\n+\t\t\tfinal boolean offer = super.offer(element);\n+\n+\t\t\tif (offer) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+\t\t\treturn offer;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to add a new element to the queue, if successful notify on signal, awakening a waiting thread.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean add(T element) {\n+\t\t\tfinal boolean add = super.add(element);\n+\n+\t\t\tif (add) {\n+\t\t\t\tdoNotify();\n+\t\t\t}\n+\n+\t\t\treturn add;\n+\t\t}\n+\n+\t\t/**\n+\t\t * Try to offer multiple elements to the queue, if successful notify all threads waiting on signal.\n+\t\t *\n+\t\t * @implNote this can actually cause some threads to receive nothing, as the collections size might be smaller than the number of waiting threads.\n+\t\t */\n+\t\t@Override\n+\t\tpublic boolean addAll(Collection<? extends T> collection) {\n+\t\t\tfinal boolean addAll = super.addAll(collection);\n+\n+\t\t\tif (addAll) {\n+\t\t\t\t//TODO does this cause problems?\n+\t\t\t\tsynchronized (signal) {\n+\t\t\t\t\tsignal.notifyAll();\n+\t\t\t\t}\n+\t\t\t}\n+\n+\t\t\treturn addAll;\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Create a new queue adding it as sub-queue if there is a slot available.\n+\t *\n+\t * @return\n+\t * @throws IllegalStateException when no more slots are available.\n+\t */\n+\tpublic Queue<E> createQueue() {\n+\t\t// TODO: 25.06.2020 FK: add supplier as creation parameter\n+\t\tfinal Queue<E> out = new SignallingForwardingQueue<E>(Queues.newConcurrentLinkedQueue(), signal);\n+\t\tfinal int free;\n+\n+\t\tsynchronized (signal) {\n+\t\t\tfree = ArrayUtils.indexOf(queues, null);\n+\n+\t\t\tif (free == -1) {\n+\t\t\t\tlog.warn(\"Growing RoundRobinQueue to new size {}\", (int) ((double) getCapacity() * GROWTH_FACTOR));\n+\t\t\t\tqueues = Arrays.copyOf(queues, (int) ((double) getCapacity() * GROWTH_FACTOR));\n+\t\t\t}\n+\n+\t\t\tqueues[free] = out;\n+\t\t}\n+\n+\t\tlog.debug(\"Create a new Queue at {}. Now have {}\", free, getNQueues());\n+\n+\t\treturn out;\n+\t}\n+\n+\t/**\n+\t * Tries to remove the queue if it is inside.\n+\t *\n+\t * @param del the Queue to delete.\n+\t * @return true if the queue was deleted, false if not.\n+\t */\n+\tpublic boolean removeQueue(Queue<E> del) {\n+\t\tfinal int index;\n+\t\tsynchronized (signal) {\n+\t\t\tindex = ArrayUtils.indexOf(queues, del);\n+\n+\t\t\tif (index == -1) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\n+\t\t\tqueues[index] = null;\n+\t\t}\n+\n+\t\tlog.debug(\"Removing Queue at {}. Now have {}\", index, getNQueues());\n+\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * The number of elements over all queues.\n+\t */\n+\t@Override\n+\tpublic int size() {\n+\t\tint sum = 0;\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null) {\n+\t\t\t\tsum += queue.size();\n+\t\t\t}\n+\t\t}\n+\t\treturn sum;\n+\t}\n+\n+\t/**\n+\t * @return true, if all queues are empty.\n+\t */\n+\t@Override\n+\tpublic boolean isEmpty() {\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null && !queue.isEmpty()) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * @param o the Object to check.\n+\t * @return True, if any queue contains the element.\n+\t */\n+\t@Override\n+\tpublic boolean contains(Object o) {\n+\t\tfor (Queue<E> queue : queues) {\n+\t\t\tif (queue != null && queue.contains(o)) {\n+\t\t\t\treturn true;\n+\t\t\t}\n+\t\t}\n+\t\treturn false;\n+\t}\n+\n+\t/**\n+\t * @param c the objects to check.\n+\t * @return True, if all objects are contained in any of the queues.\n+\t */\n+\t@Override\n+\tpublic boolean containsAll(@NotNull Collection<?> c) {\n+\t\tfor (Object o : c) {\n+\t\t\tif (!contains(o)) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn true;\n+\t}\n+\n+\t/**\n+\t * Create an iterator looping until the queues are empty.\n+\t */\n+\t@NotNull\n+\t@Override\n+\tpublic Iterator<E> iterator() {\n+\t\treturn new Iterator<E>() {\n+\t\t\t@Override\n+\t\t\tpublic boolean hasNext() {\n+\t\t\t\treturn !isEmpty();\n+\t\t\t}\n+\n+\t\t\t@Override\n+\t\t\tpublic E next() {\n+\t\t\t\treturn poll();\n+\t\t\t}\n+\t\t};\n+\t}\n+\n+\t/**\n+\t * Take one element from the queue, blocking until there is a new object available.\n+\t *\n+\t * @implNote see {@link RoundRobinQueue::poll()} for implementation details.\n+\t */\n+\t@NotNull\n+\t@Override\n+\tpublic E take() throws InterruptedException {\n+\t\twhile (true) {\n+\t\t\tE out = poll();\n+\t\t\tif (out != null) {\n+\t\t\t\treturn out;\n+\t\t\t}\n+\n+\t\t\tlog.trace(\"Thread[{}], no element in Queue, waiting on Signal.\", Thread.currentThread().getName());\n+\n+\t\t\tsynchronized (signal) {\n+\t\t\t\tsignal.wait();\n+\t\t\t}\n+\n+\t\t\tlog.trace(\"Thread[{}] Awakened for new Work.\", Thread.currentThread().getName());\n+\t\t}\n+\t}\n+\n+\n+\t/**\n+\t * Try taking one element from the queue, blocking until there is a new object available, or the timeout expires.\n+\t *\n+\t * @implNote see {@link RoundRobinQueue::poll()} for implementation details.\n+\t */\n+\t@Nullable\n+\t@Override\n+\tpublic E poll(long timeout, @NotNull TimeUnit unit) throws InterruptedException {\n+\t\tE out = poll();\n+\n+\t\tif (out != null) {\n+\t\t\treturn out;\n+\t\t}\n+\n+\t\tlog.trace(\"Thread[{}], no element in Queue, waiting on Signal.\", Thread.currentThread().getName());\n+\n+\t\tsynchronized (signal) {\n+\t\t\tunit.timedWait(signal, timeout);\n+\t\t}\n+\n+\t\tlog.trace(\"Thread[{}] Awakened for new Work.\", Thread.currentThread().getName());\n+\n+\t\treturn poll();\n+\t}\n+\n+\n+\t/**\n+\t * Find an element in any queue. Start searching in a different queue each time.\n+\t */\n+\t@Override\n+\tpublic E poll() {\n+\t\t// The next queue we look poll\n+\t\tfinal int begin = cycleIndex.get();\n+\n+\t\tfor (int offset = 0; offset < queues.length; offset++) {\n+\t\t\tfinal int index = (begin + offset) % (queues.length - 1);\n+\t\t\tQueue<E> curr = queues[index];\n+\n+\t\t\tif (curr == null) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\n+\t\t\t// Poll once, if successful update the index of the last polled queue and return the polled element.\n+\t\t\tE out = curr.poll();\n+\n+\t\t\tif (out != null) {\n+\t\t\t\tlog.trace(\"Thread[{}] found Work in Queue[{}].\", Thread.currentThread().getName(), index);\n+\t\t\t\tcycleIndex.set(index + 1);\n+\t\t\t\treturn out;\n+\t\t\t}\n+\t\t}\n+\n+\t\tlog.trace(\"All Queues were empty.\");\n+\n+\n+\t\t// If no queue had elements, return null.\n+\t\treturn null;\n+\t}\n+\n+\n+\t/**\n+\t * Peek all queues for the next available element.\n+\t *\n+\t * @apiNote this method is NOT guaranteed to be stable: peeking multiple times will peek different queues.\n+\t * @implNote see {@link RoundRobinQueue::poll()} for implementation details.\n+\t */\n+\t@Override\n+\tpublic E peek() {\n+\t\tfinal int begin = cycleIndex.get();\n+\n+\t\tfor (int offset = 1; offset < queues.length; offset++) {\n+\t\t\tfinal int index = (begin + offset) % (queues.length - 1);\n+\t\t\tQueue<E> curr = queues[index];\n+\n+\t\t\tif (curr == null) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\n+\t\t\tE out = curr.peek();\n+\n+\t\t\tif (out != null) {\n+\t\t\t\tcycleIndex.set(index);\n+\t\t\t\treturn out;\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn null;\n+\t}\n+\n+\n+\t//=====================================\n+\t//=       Unsupported Methods         =\n+\t//=====================================\n+\n+\t@Override\n+\tpublic int drainTo(@NotNull Collection<? super E> c) {\n+\t\t// TODO: 25.06.2020 implement this?", "originalCommit": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQzNzM3OQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447437379", "bodyText": "Ist das sleep notwendig?", "author": "thoniTUB", "createdAt": "2020-06-30T06:23:28Z", "path": "backend/src/test/java/com/bakdata/conquery/integration/tests/MetadataCollectionTest.java", "diffHunk": "@@ -33,12 +32,9 @@ public void execute(StandaloneSupport conquery) throws Exception {\n \t\ttest.importRequiredData(conquery);\n \t\t\n \t\t//ensure the metadata is collected\n-\t\tfor(SlaveCommand slave : conquery.getSlaves()) {\n-\t\t\tslave.getWorkers().getWorkers().forEach((id, worker) -> {\n-\t\t\t\tworker.getJobManager().addSlowJob(new UpdateMatchingStats(worker));\n-\t\t\t});\n-\t\t}\n-\t\t\n+\t\tconquery.getNamespace().sendToAll(new UpdateMatchingStatsMessage());\n+\n+\t\tThread.sleep(5);", "originalCommit": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzU1Mzk0NQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447553945", "bodyText": "ups, nein war nur um zu testen wegen isBusy", "author": "awildturtok", "createdAt": "2020-06-30T09:43:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQzNzM3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzQ0MTY1OA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r447441658", "bodyText": "Die Funktion sollte denke ich weg und dadurch ersetzt werden dass Updatematching stats auf seine kreierten Jobs synchronisiert.", "author": "thoniTUB", "createdAt": "2020-06-30T06:33:39Z", "path": "backend/src/main/java/com/bakdata/conquery/models/worker/Worker.java", "diffHunk": "@@ -49,15 +79,23 @@ public MasterMessage transform(NamespaceMessage message) {\n \t\n \t@Override\n \tpublic void close() throws IOException {\n-\t\tqueryExecutor.close();\n+\t\tpool.shutdownNow();\n \t\tstorage.close();\n \t}\n \t\n \t@Override\n \tpublic String toString() {\n \t\treturn \"Worker[\" + info.getId() + \", \" + session.getLocalAddress() + \"]\";\n \t}\n+\n+\tpublic void awaitSubJobTermination() {", "originalCommit": "311bb1045b5e524150ec2c4df3d81d4903db7ade", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5c2647cca84fe39109ca49a839f1451a8556c907", "url": "https://github.com/bakdata/conquery/commit/5c2647cca84fe39109ca49a839f1451a8556c907", "message": "Review Feedback\n- Migrate Worker subJobPool to Workers\n- Minor cleanup with MDC in JobExecutor, and MetadataCollectionTest\n- Rework UpdateMatchingStats to no longer need a central gather step\n- Deprecated more Unsupported methods in RoundRobinQueue\n- Rework starting full Update of BlockManager", "committedDate": "2020-06-30T09:52:01Z", "type": "commit"}, {"oid": "c554f456fe34bc516b60a3c8c1c8532a247687d6", "url": "https://github.com/bakdata/conquery/commit/c554f456fe34bc516b60a3c8c1c8532a247687d6", "message": "minor errors fixed", "committedDate": "2020-06-30T09:54:08Z", "type": "commit"}, {"oid": "0be8f1bae8a09df95ab955a16d06339fac1fbdf5", "url": "https://github.com/bakdata/conquery/commit/0be8f1bae8a09df95ab955a16d06339fac1fbdf5", "message": "Merge branch 'develop' into feature/parallel-startup", "committedDate": "2020-06-30T10:23:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM0MzQ0NQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r448343445", "bodyText": ".getNThreads() oder .getThreads()", "author": "thoniTUB", "createdAt": "2020-07-01T12:56:07Z", "path": "backend/src/main/java/com/bakdata/conquery/commands/SlaveCommand.java", "diffHunk": "@@ -92,10 +90,7 @@ protected void run(Environment environment, Namespace namespace, ConqueryConfig\n \t\t\tlog.warn(\"Had to create Storage Dir at `{}`\", config.getStorage().getDirectory());\n \t\t}\n \n-\t\tworkers = new Workers(new RoundRobinQueue<>(config.getQueries().getRoundRobinQueueCapacity()), config.getQueries().getNThreads());\n-\n-\n-\t\tExecutorService loaders = Executors.newFixedThreadPool(config.getStorage().getThreads());\n+\t\tworkers = new Workers(new RoundRobinQueue<>(config.getQueries().getRoundRobinQueueCapacity()), config.getQueries().getNThreads(), config.getStorage().getThreads());", "originalCommit": "0be8f1bae8a09df95ab955a16d06339fac1fbdf5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MjM5NQ==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r448352395", "bodyText": "Wenn das immer gemacht wird, dann kann man die Job-Liste zu einem SortedSet machen, so dass schon gleich beim Inset nach dem Progress sortiert wird.", "author": "thoniTUB", "createdAt": "2020-07-01T13:11:49Z", "path": "backend/src/main/java/com/bakdata/conquery/commands/SlaveCommand.java", "diffHunk": "@@ -229,17 +245,29 @@ public void stop() throws Exception {\n \t\tlog.info(\"Connection was closed by master\");\n \t\tconnector.dispose();\n \t}\n+\n \tprivate void reportJobManagerStatus() {\n+\t\tif (context == null || !context.isConnected()) {\n+\t\t\treturn;\n+\t\t}\n+\n+\t\t// Collect the Slaves and all its workers jobs into a single queue\n+\t\tfinal JobManagerStatus jobManagerStatus = jobManager.reportStatus();\n+\n+\t\tfor (Worker worker : workers.getWorkers().values()) {\n+\t\t\tjobManagerStatus.getJobs().addAll(worker.getJobManager().reportStatus().getJobs());\n+\t\t}\n+\n+\t\tjobManagerStatus.getJobs().sort(Comparator.comparingDouble(js -> js.getProgressReporter().getProgress()));", "originalCommit": "0be8f1bae8a09df95ab955a16d06339fac1fbdf5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "6761856a33e003c06ba787e2fbc400a5c4faf8cc", "url": "https://github.com/bakdata/conquery/commit/6761856a33e003c06ba787e2fbc400a5c4faf8cc", "message": "- Cleanup NThreads/Threads variable naming\n- Rework JobStatus into SortedSet", "committedDate": "2020-07-01T14:10:05Z", "type": "commit"}, {"oid": "1656abdc11d8409da281b67e0f82e6b02e7c06a5", "url": "https://github.com/bakdata/conquery/commit/1656abdc11d8409da281b67e0f82e6b02e7c06a5", "message": "Add per Namespace JobManager migrate trivially changeable Jobs to Namespace.jobManager", "committedDate": "2020-07-01T14:10:05Z", "type": "commit"}, {"oid": "c4732b10459a13abe19c0671fcf313208632495d", "url": "https://github.com/bakdata/conquery/commit/c4732b10459a13abe19c0671fcf313208632495d", "message": "fix registering gauge instead using MetricRegistry::gauge", "committedDate": "2020-07-01T14:12:28Z", "type": "commit"}, {"oid": "735b3e01d899a7242072ee44213cadb7b789a1ca", "url": "https://github.com/bakdata/conquery/commit/735b3e01d899a7242072ee44213cadb7b789a1ca", "message": "remove ThreadPoolDefinition from Autodoc", "committedDate": "2020-07-01T14:17:37Z", "type": "commit"}, {"oid": "0782750bcc4e5d13be93f226cc48ce9f3b0cd3b2", "url": "https://github.com/bakdata/conquery/commit/0782750bcc4e5d13be93f226cc48ce9f3b0cd3b2", "message": "Merge 735b3e01d899a7242072ee44213cadb7b789a1ca into c8c40d9e2a1e15ebc5c2432a49c88cae9db09c00", "committedDate": "2020-07-01T14:17:45Z", "type": "commit"}, {"oid": "4dfc5de14a92cf04665c948f1763b4af2cf02642", "url": "https://github.com/bakdata/conquery/commit/4dfc5de14a92cf04665c948f1763b4af2cf02642", "message": "automatic update to docs", "committedDate": "2020-07-01T14:19:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQwMjg5OA==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r448402898", "bodyText": "Suggested change", "author": "thoniTUB", "createdAt": "2020-07-01T14:28:28Z", "path": "backend/src/main/java/com/bakdata/conquery/models/config/ClusterConfig.java", "diffHunk": "@@ -21,5 +21,6 @@\n \tprivate MinaConfig mina = new MinaConfig();\n \t@Min(1)\n \tprivate int entityBucketSize = 1000;\n-\t\n+\n+", "originalCommit": "4dfc5de14a92cf04665c948f1763b4af2cf02642", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQwMzQ4Mw==", "url": "https://github.com/bakdata/conquery/pull/1216#discussion_r448403483", "bodyText": ":D das war 0", "author": "thoniTUB", "createdAt": "2020-07-01T14:29:13Z", "path": "backend/src/main/java/com/bakdata/conquery/models/config/StorageConfig.java", "diffHunk": "@@ -25,6 +24,6 @@\n \t@NotNull\n \tprivate Duration weakCacheDuration = Duration.hours(48);\n \n-\t@Min(0)\n-\tprivate int threads = Runtime.getRuntime().availableProcessors();\n+\t@Min(1)", "originalCommit": "4dfc5de14a92cf04665c948f1763b4af2cf02642", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8f35f32cfbd8bf5d5981287be86210321c77aa4e", "url": "https://github.com/bakdata/conquery/commit/8f35f32cfbd8bf5d5981287be86210321c77aa4e", "message": "Update backend/src/main/java/com/bakdata/conquery/models/config/ClusterConfig.java\n\nCo-authored-by: MT <12283268+thoniTUB@users.noreply.github.com>", "committedDate": "2020-07-01T19:16:50Z", "type": "commit"}, {"oid": "b517b458ee3b35d2ced3b113b3a9522e5e552cb0", "url": "https://github.com/bakdata/conquery/commit/b517b458ee3b35d2ced3b113b3a9522e5e552cb0", "message": "fix missing JsonCreator", "committedDate": "2020-07-02T07:44:17Z", "type": "commit"}, {"oid": "b5818606a1824453a7a32cc4d9ef6e180231d969", "url": "https://github.com/bakdata/conquery/commit/b5818606a1824453a7a32cc4d9ef6e180231d969", "message": "Don't use SynchronizedBlockingQueue", "committedDate": "2020-07-02T08:43:26Z", "type": "commit"}, {"oid": "f4adf5cf7a27dbcfc432ddc457fc14640d4035b9", "url": "https://github.com/bakdata/conquery/commit/f4adf5cf7a27dbcfc432ddc457fc14640d4035b9", "message": "order descending", "committedDate": "2020-07-02T09:00:17Z", "type": "commit"}, {"oid": "5e8b64e5ef0b6a9f0d9d8acfa1a60167bc110bdc", "url": "https://github.com/bakdata/conquery/commit/5e8b64e5ef0b6a9f0d9d8acfa1a60167bc110bdc", "message": "shutdown namespace jobmanagers", "committedDate": "2020-07-02T11:36:46Z", "type": "commit"}, {"oid": "332e6679ca063db3866ff0ee081b9dbc4cb1d5e6", "url": "https://github.com/bakdata/conquery/commit/332e6679ca063db3866ff0ee081b9dbc4cb1d5e6", "message": "Don't use assertThat isEmpty as that uses the iterator", "committedDate": "2020-07-02T11:58:58Z", "type": "commit"}, {"oid": "077b33b290d1d26a2333d726314072dca8aac2d6", "url": "https://github.com/bakdata/conquery/commit/077b33b290d1d26a2333d726314072dca8aac2d6", "message": "Merge branch 'develop' into feature/parallel-startup", "committedDate": "2020-07-02T12:09:40Z", "type": "commit"}]}