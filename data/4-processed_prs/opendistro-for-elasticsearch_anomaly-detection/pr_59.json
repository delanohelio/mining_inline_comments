{"pr_number": 59, "pr_title": "record error and execution start/end time in AD result; handle except\u2026", "pr_createdAt": "2020-03-10T16:19:08Z", "pr_url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59", "timeline": [{"oid": "638af5d68495deb9d12f896cabdef1d12f70e51b", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/638af5d68495deb9d12f896cabdef1d12f70e51b", "message": "record error and execution start/end time in AD result; handle exception from AD result action", "committedDate": "2020-03-10T16:12:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM3NjcyNA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391376724", "bodyText": "executionStartTime and endTime are almost the same, we can just keep one.", "author": "kaituo", "createdAt": "2020-03-12T02:57:15Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -81,6 +130,11 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n             );\n         }\n \n+        Instant executionStartTime = Instant.now();\n+        IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n+        Instant endTime = Instant.now();", "originalCommit": "638af5d68495deb9d12f896cabdef1d12f70e51b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTcxNjU5Nw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391716597", "bodyText": "Will remove endTime", "author": "ylwu-amzn", "createdAt": "2020-03-12T15:51:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM3NjcyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM3OTE4MQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391379181", "bodyText": "put releaseLock in a finally clause so you don't have to remember to write it in every branch?", "author": "kaituo", "createdAt": "2020-03-12T03:07:39Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +169,301 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultExceptionSilently(\n+                jobParameter,\n+                startTime,\n+                endTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n                 endTime.toEpochMilli()\n             );\n-            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n+            client\n+                .execute(\n+                    AnomalyResultAction.INSTANCE,\n+                    request,\n+                    ActionListener\n+                        .wrap(\n+                            response -> {\n+                                indexAnomalyResultSilently(\n+                                    jobParameter,\n+                                    lockService,\n+                                    lock,\n+                                    startTime,\n+                                    endTime,\n+                                    executionStartTime,\n+                                    response\n+                                );\n+                            },\n+                            exception -> {\n+                                handleAdException(\n+                                    jobParameter,\n+                                    lockService,\n+                                    lock,\n+                                    startTime,\n+                                    endTime,\n+                                    executionStartTime,\n+                                    backoff,\n+                                    exception\n+                                );\n+                            }\n+                        )\n+                );\n+        } catch (Exception e) {\n+            indexAnomalyResultExceptionSilently(jobParameter, startTime, endTime, executionStartTime, e);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+            releaseLock(jobParameter, lockService, lock);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        Exception exception\n+    ) {\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + jobParameter.getName(), exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJobSilently(jobParameter.getName());\n+                indexAnomalyResultExceptionSilently(\n+                    jobParameter,\n+                    startTime,\n+                    endTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage()\n+                );\n                 releaseLock(jobParameter, lockService, lock);", "originalCommit": "638af5d68495deb9d12f896cabdef1d12f70e51b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM4NTE1MQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391385151", "bodyText": "Are line 252~260 same with stopAdJobForEndRunException?", "author": "kaituo", "createdAt": "2020-03-12T03:36:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM3OTE4MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTcxNjc0MQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391716741", "bodyText": "Will refactor", "author": "ylwu-amzn", "createdAt": "2020-03-12T15:51:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM3OTE4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM4MjEzMA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391382130", "bodyText": "For retryable EndRunException, I didn't mean to retry right away.  I meant to let AD job trigger the retry in the new few runs.  After that, if things do not improve, stop AD job.\nThe backoff setting for EndRunException retry here is too fast.  The formula of backoff delay is:\nstart + 10 * ((int) Math.exp(0.8d * (currentlyConsumed)) - 1)\nIn your current setting,\nstart = 1 sec\ncurrentlyConsumed is between [0, 2] since we are gonna retry 3 times.\nThen we are gonna retry in 1 sec, 11 sec, 31 sec.\nSee the definition of ExponentialBackoffIterator in Elasticsearch for further details.\nSome issue like training data not available cannot be fixed right away.  We need to wait a few more retries * AD job interval.\nAlso, would AD job run and the backoff retry happen at the same time?  If yes, would there be any problem?", "author": "kaituo", "createdAt": "2020-03-12T03:22:04Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +169,301 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultExceptionSilently(\n+                jobParameter,\n+                startTime,\n+                endTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n                 endTime.toEpochMilli()\n             );\n-            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n+            client\n+                .execute(\n+                    AnomalyResultAction.INSTANCE,\n+                    request,\n+                    ActionListener\n+                        .wrap(\n+                            response -> {\n+                                indexAnomalyResultSilently(\n+                                    jobParameter,\n+                                    lockService,\n+                                    lock,\n+                                    startTime,\n+                                    endTime,\n+                                    executionStartTime,\n+                                    response\n+                                );\n+                            },\n+                            exception -> {\n+                                handleAdException(\n+                                    jobParameter,\n+                                    lockService,\n+                                    lock,\n+                                    startTime,\n+                                    endTime,\n+                                    executionStartTime,\n+                                    backoff,\n+                                    exception\n+                                );\n+                            }\n+                        )\n+                );\n+        } catch (Exception e) {\n+            indexAnomalyResultExceptionSilently(jobParameter, startTime, endTime, executionStartTime, e);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+            releaseLock(jobParameter, lockService, lock);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        Exception exception\n+    ) {\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + jobParameter.getName(), exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJobSilently(jobParameter.getName());\n+                indexAnomalyResultExceptionSilently(\n+                    jobParameter,\n+                    startTime,\n+                    endTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage()\n+                );\n                 releaseLock(jobParameter, lockService, lock);\n-            }));\n+            } else {\n+                // retry AD job, if all retries failed or have no enough time to retry, will stop AD job.\n+                Schedule schedule = jobParameter.getSchedule();\n+                long nextExecutionTime = jobParameter.getSchedule().getNextExecutionTime(executionStartTime).toEpochMilli();\n+                long now = Instant.now().toEpochMilli();\n+                long leftTime = nextExecutionTime - now - JOB_RUN_BUFFER_IN_MILLISECONDS;\n+                long usedTime = now - executionStartTime.toEpochMilli();\n+\n+                if (!backoff.hasNext()) {\n+                    stopAdJobForEndRunException(\n+                        jobParameter,\n+                        lockService,\n+                        lock,\n+                        startTime,\n+                        endTime,\n+                        executionStartTime,\n+                        (EndRunException) exception\n+                    );\n+                } else {\n+                    if (backoff.hasNext()) {", "originalCommit": "638af5d68495deb9d12f896cabdef1d12f70e51b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTcyODIzOA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391728238", "bodyText": "I think we need to retry several times to avoid skipping anomaly result by some transient exception. I have worked on change to stop job if several job runs fail consecutively. Will publish revision soon.\nIf training data not available, why throw EndRunException rather than ResourceNotFoundException? User may ingest data soon\n\nAlso, would AD job run and the backoff retry happen at the same time? If yes, would there be any problem?\n\nWill not retry if left time is less than half - buffer. Any job run is possible to happen when last run still on going, hanguang's cancel request change will handle this.", "author": "ylwu-amzn", "createdAt": "2020-03-12T16:09:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM4MjEzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM4NTczNQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391385735", "bodyText": "How about rename to stopAdJob?  I know you want to differentiate stopADJob only and stopAdJob + index + release lock.  Silently gives me a fear that this is a serial killer without leaving any trace.  But you do have a lot of logs and exception handling.\nAlso, we don't usually use adverb as method names.  We usually use verbs or verb phrases.  See https://google.github.io/styleguide/javaguide.html\nThis applies to your other *Silently methods as well.", "author": "kaituo", "createdAt": "2020-03-12T03:38:47Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +169,301 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultExceptionSilently(\n+                jobParameter,\n+                startTime,\n+                endTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n                 endTime.toEpochMilli()\n             );\n-            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n+            client\n+                .execute(\n+                    AnomalyResultAction.INSTANCE,\n+                    request,\n+                    ActionListener\n+                        .wrap(\n+                            response -> {\n+                                indexAnomalyResultSilently(\n+                                    jobParameter,\n+                                    lockService,\n+                                    lock,\n+                                    startTime,\n+                                    endTime,\n+                                    executionStartTime,\n+                                    response\n+                                );\n+                            },\n+                            exception -> {\n+                                handleAdException(\n+                                    jobParameter,\n+                                    lockService,\n+                                    lock,\n+                                    startTime,\n+                                    endTime,\n+                                    executionStartTime,\n+                                    backoff,\n+                                    exception\n+                                );\n+                            }\n+                        )\n+                );\n+        } catch (Exception e) {\n+            indexAnomalyResultExceptionSilently(jobParameter, startTime, endTime, executionStartTime, e);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+            releaseLock(jobParameter, lockService, lock);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        Exception exception\n+    ) {\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + jobParameter.getName(), exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJobSilently(jobParameter.getName());\n+                indexAnomalyResultExceptionSilently(\n+                    jobParameter,\n+                    startTime,\n+                    endTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage()\n+                );\n                 releaseLock(jobParameter, lockService, lock);\n-            }));\n+            } else {\n+                // retry AD job, if all retries failed or have no enough time to retry, will stop AD job.\n+                Schedule schedule = jobParameter.getSchedule();\n+                long nextExecutionTime = jobParameter.getSchedule().getNextExecutionTime(executionStartTime).toEpochMilli();\n+                long now = Instant.now().toEpochMilli();\n+                long leftTime = nextExecutionTime - now - JOB_RUN_BUFFER_IN_MILLISECONDS;\n+                long usedTime = now - executionStartTime.toEpochMilli();\n+\n+                if (!backoff.hasNext()) {\n+                    stopAdJobForEndRunException(\n+                        jobParameter,\n+                        lockService,\n+                        lock,\n+                        startTime,\n+                        endTime,\n+                        executionStartTime,\n+                        (EndRunException) exception\n+                    );\n+                } else {\n+                    if (backoff.hasNext()) {\n+                        TimeValue nextRunDelay = backoff.next();\n+                        if (leftTime > (usedTime + nextRunDelay.getMillis())) {\n+                            threadPool\n+                                .schedule(\n+                                    () -> runAdJob(jobParameter, lockService, lock, startTime, endTime, executionStartTime, backoff),\n+                                    nextRunDelay,\n+                                    ThreadPool.Names.SAME\n+                                );\n+                        } else {\n+                            stopAdJobForEndRunException(\n+                                jobParameter,\n+                                lockService,\n+                                lock,\n+                                startTime,\n+                                endTime,\n+                                executionStartTime,\n+                                (EndRunException) exception\n+                            );\n+                        }\n+                    }\n+                }\n+            }\n+        } else {\n+            if (exception instanceof InternalFailure) {\n+                // AnomalyResultTransportAction already prints exception stack trace\n+                log.error(\"InternalFailure happened when executed anomaly result action for \" + jobParameter.getName());\n+            } else {\n+                log.error(\"Failed to execute anomaly result action for \" + jobParameter.getName(), exception);\n+            }\n+            indexAnomalyResultExceptionSilently(jobParameter, startTime, endTime, executionStartTime, exception);\n+            releaseLock(jobParameter, lockService, lock);\n+        }\n+    }\n+\n+    private void stopAdJobForEndRunException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        EndRunException exception\n+    ) {\n+        stopAdJobSilently(jobParameter.getName());\n+        indexAnomalyResultExceptionSilently(\n+            jobParameter,\n+            startTime,\n+            endTime,\n+            executionStartTime,\n+            \"Stopped detector: \" + exception.getMessage()\n+        );\n+        releaseLock(jobParameter, lockService, lock);\n+    }\n+\n+    private void stopAdJobSilently(String detectorId) {", "originalCommit": "638af5d68495deb9d12f896cabdef1d12f70e51b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTczMTcxNw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391731717", "bodyText": "Google's guide shows :\n\nMethod names are typically verbs or verb phrases. For example, sendMessage or stop.\n\nTypically means it allows exceptions. Actually, we can see a lot of methods with adverb in Google guava code like readFully, skipSafely, closeQuietly\nNo special taste about the naming. Will change method name.", "author": "ylwu-amzn", "createdAt": "2020-03-12T16:14:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM4NTczNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM4OTgwOQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391389809", "bodyText": "typo: responses", "author": "kaituo", "createdAt": "2020-03-12T03:58:37Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/rest/handler/AnomalyDetectorFunction.java", "diffHunk": "@@ -21,7 +21,7 @@\n     /**\n      * Performs this operation.\n      *\n-     * Notes: don't forget to send back response via channel if you process response with this method.\n+     * Notes: don't forget to send back responds via channel if you process response with this method.", "originalCommit": "638af5d68495deb9d12f896cabdef1d12f70e51b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTk0MDA0NA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391940044", "bodyText": "will change", "author": "ylwu-amzn", "createdAt": "2020-03-12T22:30:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM4OTgwOQ=="}], "type": "inlineReview"}, {"oid": "fcb22229ed6c0e18919d3b9c6ad24299b2bb8ed8", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/fcb22229ed6c0e18919d3b9c6ad24299b2bb8ed8", "message": "fail AD job if fail consecutively more than limit times", "committedDate": "2020-03-12T16:06:34Z", "type": "commit"}, {"oid": "f15696cf35e0c7497679bd41332962b18917f519", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/f15696cf35e0c7497679bd41332962b18917f519", "message": "fix typo", "committedDate": "2020-03-12T16:32:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAxNDY4MQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392014681", "bodyText": "Since detectorEndRunExceptionCount does not depend on anything else to be initialized, you can put the initialization to your constructor and remove this method. I cannot think of a use case where we need to call this method after AnomalyDetectorRunner is initialized.  Also, it is easy for other people unfamiliar with the code to forget to call this method when initializing AnomalyDetectorRunner.", "author": "kaituo", "createdAt": "2020-03-13T03:32:54Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -108,13 +109,18 @@ public void setAnomalyResultHandler(AnomalyResultHandler anomalyResultHandler) {\n         this.anomalyResultHandler = anomalyResultHandler;\n     }\n \n+    public void setDetectorEndRunExceptionCount(ConcurrentHashMap<String, Integer> detectorEndRunExceptionCount) {", "originalCommit": "f15696cf35e0c7497679bd41332962b18917f519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQwNjAzNA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392406034", "bodyText": "Good point, will change it.", "author": "ylwu-amzn", "createdAt": "2020-03-13T18:39:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAxNDY4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAxNTYyOQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392015629", "bodyText": "We also need to remove a detector id from detectorEndRunExceptionCount if we get non-EndRunException.", "author": "kaituo", "createdAt": "2020-03-13T03:37:02Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -194,43 +198,19 @@ protected void runAdJob(\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n-            client\n-                .execute(\n-                    AnomalyResultAction.INSTANCE,\n-                    request,\n-                    ActionListener\n-                        .wrap(\n-                            response -> {\n-                                indexAnomalyResultSilently(\n-                                    jobParameter,\n-                                    lockService,\n-                                    lock,\n-                                    startTime,\n-                                    endTime,\n-                                    executionStartTime,\n-                                    response\n-                                );\n-                            },\n-                            exception -> {\n-                                handleAdException(\n-                                    jobParameter,\n-                                    lockService,\n-                                    lock,\n-                                    startTime,\n-                                    endTime,\n-                                    executionStartTime,\n-                                    backoff,\n-                                    exception\n-                                );\n-                            }\n-                        )\n-                );\n+            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());\n+            },\n+                exception -> {\n+                    handleAdException(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes, exception);", "originalCommit": "f15696cf35e0c7497679bd41332962b18917f519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM4ODI0MQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392388241", "bodyText": "Good catch. Will change", "author": "ylwu-amzn", "createdAt": "2020-03-13T18:02:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAxNTYyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAxNTY4OA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392015688", "bodyText": "the key is detector id.", "author": "kaituo", "createdAt": "2020-03-13T03:37:27Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -194,43 +198,19 @@ protected void runAdJob(\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n-            client\n-                .execute(\n-                    AnomalyResultAction.INSTANCE,\n-                    request,\n-                    ActionListener\n-                        .wrap(\n-                            response -> {\n-                                indexAnomalyResultSilently(\n-                                    jobParameter,\n-                                    lockService,\n-                                    lock,\n-                                    startTime,\n-                                    endTime,\n-                                    executionStartTime,\n-                                    response\n-                                );\n-                            },\n-                            exception -> {\n-                                handleAdException(\n-                                    jobParameter,\n-                                    lockService,\n-                                    lock,\n-                                    startTime,\n-                                    endTime,\n-                                    executionStartTime,\n-                                    backoff,\n-                                    exception\n-                                );\n-                            }\n-                        )\n-                );\n+            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());", "originalCommit": "f15696cf35e0c7497679bd41332962b18917f519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM4OTcwNQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392389705", "bodyText": "jobParameter.getName equals to detector id. will change it.", "author": "ylwu-amzn", "createdAt": "2020-03-13T18:06:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAxNTY4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAxNTcyMQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392015721", "bodyText": "the key is detector id.", "author": "kaituo", "createdAt": "2020-03-13T03:37:37Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -317,22 +307,23 @@ private void stopAdJobForEndRunException(\n         LockService lockService,\n         LockModel lock,\n         Instant startTime,\n-        Instant endTime,\n         Instant executionStartTime,\n         EndRunException exception\n     ) {\n-        stopAdJobSilently(jobParameter.getName());\n-        indexAnomalyResultExceptionSilently(\n+        detectorEndRunExceptionCount.remove(jobParameter.getName());", "originalCommit": "f15696cf35e0c7497679bd41332962b18917f519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjM5MDMwNw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392390307", "bodyText": "jobParameter.getName equals to detector id. will change it.", "author": "ylwu-amzn", "createdAt": "2020-03-13T18:07:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAxNTcyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAyNjAyOA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392026028", "bodyText": "After much thought, I am still inclined to remove the backoff retry because we don't have a clear use case a quick retry is needed and there are complications for the backoff retry.  This is the 3 cases where EndRunException is thrown with endNow being false:\n\ntraining data for cold start not available\ncold start cannot succeed\nunknown prediction error\n\nTwo of the causes are related to cold start. Let's discuss it one by one:\n\ntraining data for cold start not available: the situation won't improve within seconds.\ncold start cannot succeed and unknown prediction error: this indicates some bugs of our side and  system heavy load.  Quick retry does not help.\n\nSome complications of retry quickly:\n\nCold start is expensive as it runs 24 queries, initializing models, and saving checkpoints. Retry cold start quickly can impose performance pressure.\n10 seconds buffer might not be enough to prevent multiple cold starts (started by backoff retry and AD job) at the same time as cold start cannot finish within a few seconds.  Lai once said it takes about 20~30 seconds.  The process can take longer if customers' feature queries are  complex and we have more features.  Hanguang's cancel would only apply if there are prediction queries for current window running.  Cancel won't happen when current window queries finish, but we are running 24 queries for cold start, initializing models and saving checkpoints.\nWe are using our own threadpool and it is limited by 1/4 cores.  Retry uses threadpool and may slow down other jobs' running.", "author": "kaituo", "createdAt": "2020-03-13T04:33:01Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +174,303 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                startTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n             client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());\n+            },\n+                exception -> {\n+                    handleAdException(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes, exception);\n+                }\n+            ));\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, startTime, executionStartTime, e, true);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes,\n+        Exception exception\n+    ) {\n+        String detectorId = jobParameter.getName();\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + detectorId, exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                detectorEndRunExceptionCount.remove(detectorId);\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJob(detectorId);\n+                indexAnomalyResultException(\n+                    jobParameter,\n+                    lockService,\n+                    lock,\n+                    startTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage(),\n+                    true\n+                );\n+            } else {\n+                detectorEndRunExceptionCount.compute(detectorId, (k, v) -> {\n+                    if (v == null) {\n+                        return 1;\n+                    } else if (retryTimes == 0) {\n+                        return v + 1;\n+                    } else {\n+                        return v;\n+                    }\n+                });\n+                // if AD job failed consecutively due to EndRunException and failed times exceeds upper limit, will stop AD job\n+                if (detectorEndRunExceptionCount.get(detectorId) > maxRetryForEndRunException) {", "originalCommit": "f15696cf35e0c7497679bd41332962b18917f519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQwMzIxNg==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392403216", "bodyText": "Thanks for your analysis. Here the backoff retry is to resolve the transient exception.\nCode start training data is not transient exception. We need to build finer granularity exception later to distinguish non-retryable and retryable exception. If we can't know which exception is transient and retryable in AnomalyResultTransportAction, I'm ok to remove the backoff retry now to avoid performance issue. But that's a tradeoff, as without retrying, some transient exception will cause current job run fail and if there is anomaly, user will miss it and will not get alerting notification. Sometimes missing anomaly&notification is not acceptable. For example, current detection interval is 1hour, and there should be anomaly in current interval, some transient exception may fail current AD job, so no anomaly found and user never know it. Then we start next AD job, maybe there is no anomaly in next 1hour, user will never know something wrong happened. In one word, this is some tradeoff between protecting our performance, user experience and what we can do currently.\nSo, can you help confirm if we can know which exception is retryable in AnomalyResultTransportAction? If we can't, will remove this backoff retry.", "author": "ylwu-amzn", "createdAt": "2020-03-13T18:33:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAyNjAyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU1Mzc5Mw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392553793", "bodyText": "As we discussed offline, we can define some exceptions like fail to get RCF/threshold model result as retryable exception. Such exceptions are transient and maybe resolved by some backoff retry. Will add todo now and we can change it later.", "author": "ylwu-amzn", "createdAt": "2020-03-14T03:51:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAyNjAyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAyODIwNQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392028205", "bodyText": "I was confused at the beginning when looking at this line.  Wondering when retryTimes is 0.  Then I realized every time a new AD job run would set retryTimes to 0.  retryTimes is more of a signal to increment the count by 1 instead of the real retry times of the detector.  Is my understanding correct?\nI suggest the following to simplify:\nFirst, detectorEndRunExceptionCount for a detector id is removed from the map whenever we have a successful run or an exception that is not EndRunException.\nSecond, every time an EndRunException exception is caught, add count.  Insert the mapping if the detector id is not present. Then check if the count has reached the threshold, and stop if it is.", "author": "kaituo", "createdAt": "2020-03-13T04:45:26Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +174,303 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                startTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n             client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());\n+            },\n+                exception -> {\n+                    handleAdException(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes, exception);\n+                }\n+            ));\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, startTime, executionStartTime, e, true);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes,\n+        Exception exception\n+    ) {\n+        String detectorId = jobParameter.getName();\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + detectorId, exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                detectorEndRunExceptionCount.remove(detectorId);\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJob(detectorId);\n+                indexAnomalyResultException(\n+                    jobParameter,\n+                    lockService,\n+                    lock,\n+                    startTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage(),\n+                    true\n+                );\n+            } else {\n+                detectorEndRunExceptionCount.compute(detectorId, (k, v) -> {\n+                    if (v == null) {\n+                        return 1;\n+                    } else if (retryTimes == 0) {", "originalCommit": "f15696cf35e0c7497679bd41332962b18917f519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQ1NjMxNA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392456314", "bodyText": "First, detectorEndRunExceptionCount for a detector id is removed from the map whenever we have a successful run or an exception that is not EndRunException.\n\nHave removed from map for successful run. Will remove for not EndRunException case, this comment seems duplicate with another one.\n\nSecond, every time an EndRunException exception is caught, add count. Insert the mapping if the detector id is not present. Then check if the count has reached the threshold, and stop if it is.\n\nWe can't do this as we have backoff retry now. If we do this, for the same AD job run, if we backoff retry multiple times, the detectorEndRunExceptionCount will increase count and may terminate current job immediately when the count reach limit.", "author": "ylwu-amzn", "createdAt": "2020-03-13T20:32:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAyODIwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAzMDcxMA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392030710", "bodyText": "rename to currentJobStartTime and lastJobStartTime as it is not clear what is the difference between startTime and executionStartTime?  If you agree, please change related code.", "author": "kaituo", "createdAt": "2020-03-13T04:58:38Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -132,8 +138,7 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n \n         Instant executionStartTime = Instant.now();", "originalCommit": "f15696cf35e0c7497679bd41332962b18917f519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQ2MTMxMA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392461310", "bodyText": "I prefer to change to startTime as detectionStartTime and keep executionStartTime.\nThere are some different dates in this code change, explain more:\n1.detectionStartTime, detectionEndTime: used as input dates for each AnomalyResultTransportAction run.\n2.dataStartTime, dataEndTime in AnomalyResultTransportAction means the actual date range we used to query feature data, which considering windowDelay.\ndateStartTime=detectionStartTime-windowDelay, dataEndTime=detectionEndTime-windowDelay\n3.executionStartTime, executionEndTime in AD job and AD result means when the job starts to run and completes. executionStartTime==detectionEndTime.\nIf AnomalyResultTransportAction accept dataStartTime, dataEndTime as input, we can get rid of detectionStartTime, detectionEndTime, but that means we needs to hand windowDelay from everywhere which calling AnomalyResultTransportAction. So I prefer to keep AnomalyResultTransportAction as is.", "author": "ylwu-amzn", "createdAt": "2020-03-13T20:40:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAzMDcxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAzNDY1NQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392034655", "bodyText": "would we have double lock release since your code in the try block can release the lock?  How about adding a isLockReleasedOrExpired before release?", "author": "kaituo", "createdAt": "2020-03-13T05:18:32Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +174,303 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                startTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n             client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());\n+            },\n+                exception -> {\n+                    handleAdException(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes, exception);\n+                }\n+            ));\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, startTime, executionStartTime, e, true);", "originalCommit": "f15696cf35e0c7497679bd41332962b18917f519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQ5NDAyNg==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392494026", "bodyText": "Recheck and find no double lock release. LockService already handles exception.  Lock expire time is equals to detection interval, lock will not expire during job run.", "author": "ylwu-amzn", "createdAt": "2020-03-13T21:35:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAzNDY1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAzODM0Mw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392038343", "bodyText": "Are line 232~243 the same thing as stopAdJobForEndRunException ?", "author": "kaituo", "createdAt": "2020-03-13T05:37:15Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +174,303 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                startTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n             client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());\n+            },\n+                exception -> {\n+                    handleAdException(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes, exception);\n+                }\n+            ));\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, startTime, executionStartTime, e, true);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes,\n+        Exception exception\n+    ) {\n+        String detectorId = jobParameter.getName();\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + detectorId, exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                detectorEndRunExceptionCount.remove(detectorId);\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJob(detectorId);\n+                indexAnomalyResultException(\n+                    jobParameter,\n+                    lockService,\n+                    lock,\n+                    startTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage(),\n+                    true", "originalCommit": "f15696cf35e0c7497679bd41332962b18917f519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQ5NjI1NQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392496255", "bodyText": "Yes, will change to stopAdJobForEndRunException", "author": "ylwu-amzn", "createdAt": "2020-03-13T21:39:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAzODM0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAzODQzMw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392038433", "bodyText": "the key is detector id.", "author": "kaituo", "createdAt": "2020-03-13T05:37:42Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +174,303 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                startTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n             client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());\n+            },\n+                exception -> {\n+                    handleAdException(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes, exception);\n+                }\n+            ));\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, startTime, executionStartTime, e, true);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes,\n+        Exception exception\n+    ) {\n+        String detectorId = jobParameter.getName();\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + detectorId, exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                detectorEndRunExceptionCount.remove(detectorId);\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJob(detectorId);\n+                indexAnomalyResultException(\n+                    jobParameter,\n+                    lockService,\n+                    lock,\n+                    startTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage(),\n+                    true\n+                );\n+            } else {\n+                detectorEndRunExceptionCount.compute(detectorId, (k, v) -> {\n+                    if (v == null) {\n+                        return 1;\n+                    } else if (retryTimes == 0) {\n+                        return v + 1;\n+                    } else {\n+                        return v;\n+                    }\n+                });\n+                // if AD job failed consecutively due to EndRunException and failed times exceeds upper limit, will stop AD job\n+                if (detectorEndRunExceptionCount.get(detectorId) > maxRetryForEndRunException) {\n+                    stopAdJobForEndRunException(\n+                        jobParameter,\n+                        lockService,\n+                        lock,\n+                        startTime,\n+                        executionStartTime,\n+                        (EndRunException) exception\n+                    );\n+                    return;\n+                }\n+                // retry AD job, if all retries failed or have no enough time to retry, will record exception in AD result.\n+                Schedule schedule = jobParameter.getSchedule();\n+                long nextExecutionTime = jobParameter.getSchedule().getNextExecutionTime(executionStartTime).toEpochMilli();\n+                long now = Instant.now().toEpochMilli();\n+                long leftTime = nextExecutionTime - now - JOB_RUN_BUFFER_IN_MILLISECONDS;\n+                long usedTime = now - executionStartTime.toEpochMilli();\n+\n+                TimeValue nextRunDelay = backoff.hasNext() ? backoff.next() : null;\n+\n+                if (nextRunDelay != null && leftTime > (usedTime + nextRunDelay.getMillis())) {\n+                    threadPool\n+                        .schedule(\n+                            () -> runAdJob(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes + 1),\n+                            nextRunDelay,\n+                            ThreadPool.Names.SAME\n+                        );\n+                } else {\n+                    indexAnomalyResultException(\n+                        jobParameter,\n+                        lockService,\n+                        lock,\n+                        startTime,\n+                        executionStartTime,\n+                        exception.getMessage(),\n+                        true\n+                    );\n+                }\n+            }\n+        } else {\n+            if (exception instanceof InternalFailure) {\n+                // AnomalyResultTransportAction already prints exception stack trace\n+                log.error(\"InternalFailure happened when executed anomaly result action for \" + jobParameter.getName());\n+            } else {\n+                log.error(\"Failed to execute anomaly result action for \" + jobParameter.getName(), exception);\n+            }\n+            indexAnomalyResultException(jobParameter, lockService, lock, startTime, executionStartTime, exception, true);\n+        }\n+    }\n+\n+    private void stopAdJobForEndRunException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        EndRunException exception\n+    ) {\n+        detectorEndRunExceptionCount.remove(jobParameter.getName());\n+        stopAdJob(jobParameter.getName());", "originalCommit": "f15696cf35e0c7497679bd41332962b18917f519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQ0OTg1Mg==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392449852", "bodyText": "jobParameter.getName() is detectorId", "author": "ylwu-amzn", "createdAt": "2020-03-13T20:22:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAzODQzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjA0MTk2Ng==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392041966", "bodyText": "So as long as we have 10 secs (JOB_RUN_BUFFER_IN_MILLISECONDS), and backoff has available retries, we would retry?", "author": "kaituo", "createdAt": "2020-03-13T05:53:34Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +174,303 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                startTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n             client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());\n+            },\n+                exception -> {\n+                    handleAdException(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes, exception);\n+                }\n+            ));\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, startTime, executionStartTime, e, true);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes,\n+        Exception exception\n+    ) {\n+        String detectorId = jobParameter.getName();\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + detectorId, exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                detectorEndRunExceptionCount.remove(detectorId);\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJob(detectorId);\n+                indexAnomalyResultException(\n+                    jobParameter,\n+                    lockService,\n+                    lock,\n+                    startTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage(),\n+                    true\n+                );\n+            } else {\n+                detectorEndRunExceptionCount.compute(detectorId, (k, v) -> {\n+                    if (v == null) {\n+                        return 1;\n+                    } else if (retryTimes == 0) {\n+                        return v + 1;\n+                    } else {\n+                        return v;\n+                    }\n+                });\n+                // if AD job failed consecutively due to EndRunException and failed times exceeds upper limit, will stop AD job\n+                if (detectorEndRunExceptionCount.get(detectorId) > maxRetryForEndRunException) {\n+                    stopAdJobForEndRunException(\n+                        jobParameter,\n+                        lockService,\n+                        lock,\n+                        startTime,\n+                        executionStartTime,\n+                        (EndRunException) exception\n+                    );\n+                    return;\n+                }\n+                // retry AD job, if all retries failed or have no enough time to retry, will record exception in AD result.\n+                Schedule schedule = jobParameter.getSchedule();\n+                long nextExecutionTime = jobParameter.getSchedule().getNextExecutionTime(executionStartTime).toEpochMilli();\n+                long now = Instant.now().toEpochMilli();\n+                long leftTime = nextExecutionTime - now - JOB_RUN_BUFFER_IN_MILLISECONDS;", "originalCommit": "f15696cf35e0c7497679bd41332962b18917f519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjQ0OTQwNg==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392449406", "bodyText": "No, suppose interval is 60 seconds, we used 20 seconds and find EndRunException, so  leftTime=30secs(60-20-10),  suppose next run backoff delay is 10secs, we will not retry even backoff has available retries as not meet condition leftTime > (usedTime + nextRunDelay.getMillis() which will be 30>(20 + 10).  That means we may retry less for small detection interval.", "author": "ylwu-amzn", "createdAt": "2020-03-13T20:22:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjA0MTk2Ng=="}], "type": "inlineReview"}, {"oid": "84ea1c1960c2fd7690872ea3372d73050faa48a1", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/84ea1c1960c2fd7690872ea3372d73050faa48a1", "message": "tune variable name", "committedDate": "2020-03-13T22:35:41Z", "type": "commit"}, {"oid": "3ab3c170d40fd58f11e517fdd25e6256df2cef53", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/3ab3c170d40fd58f11e517fdd25e6256df2cef53", "message": "remove backoff retry", "committedDate": "2020-03-14T03:11:47Z", "type": "commit"}, {"oid": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c", "message": "Merge branch 'development' into development", "committedDate": "2020-03-16T17:13:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIyMjMyNw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393222327", "bodyText": "Do we have issue for such TODO? Just don't want to lose track of such improvement idea in the future.", "author": "yizheliu-amazon", "createdAt": "2020-03-16T18:13:50Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -90,60 +133,368 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n                         jobParameter,\n                         context,\n                         ActionListener\n-                            .wrap(\n-                                lock -> runAdJob(jobParameter, lockService, lock),\n-                                exception -> {\n-                                    throw new IllegalStateException(\"Failed to acquire lock for AD job: \" + jobParameter.getName());\n-                                }\n-                            )\n+                            .wrap(lock -> runAdJob(jobParameter, lockService, lock, detectionStartTime, executionStartTime), exception -> {\n+                                indexAnomalyResultException(\n+                                    jobParameter,\n+                                    lockService,\n+                                    null,\n+                                    detectionStartTime,\n+                                    executionStartTime,\n+                                    exception,\n+                                    false\n+                                );\n+                                throw new IllegalStateException(\"Failed to acquire lock for AD job: \" + detectorId);\n+                            })\n                     );\n             } else {\n-                log.warn(\"Can't get lock for AD job: \" + jobParameter.getName());\n+                log.warn(\"Can't get lock for AD job: \" + detectorId);\n             }\n         };\n \n         ExecutorService executor = threadPool.executor(AD_THREAD_POOL_NAME);\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    /**\n+     * Get anomaly result, index result or handle exception if failed.\n+     *\n+     * @param jobParameter scheduled job parameter\n+     * @param lockService lock service\n+     * @param lock lock to run job\n+     * @param detectionStartTime detection start time\n+     * @param executionStartTime detection end time\n+     */\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant detectionStartTime,\n+        Instant executionStartTime\n+    ) {\n+        String detectorId = jobParameter.getName();\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                lockService,\n+                lock,\n+                detectionStartTime,\n+                executionStartTime,\n+                \"Can't run AD job due to null lock\",\n+                false\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n-                jobParameter.getName(),\n-                startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                detectorId,\n+                detectionStartTime.toEpochMilli(),\n+                executionStartTime.toEpochMilli()\n             );\n-            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+            client\n+                .execute(\n+                    AnomalyResultAction.INSTANCE,\n+                    request,\n+                    ActionListener\n+                        .wrap(\n+                            response -> {\n+                                indexAnomalyResult(jobParameter, lockService, lock, detectionStartTime, executionStartTime, response);\n+                            },\n+                            exception -> {\n+                                handleAdException(jobParameter, lockService, lock, detectionStartTime, executionStartTime, exception);\n+                            }\n+                        )\n+                );\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, detectionStartTime, executionStartTime, e, true);\n+            log.error(\"Failed to execute AD job \" + detectorId, e);\n+        }\n+    }\n+\n+    /**\n+     * Handle exception from anomaly result action.\n+     *\n+     * 1. If exception is {@link EndRunException}\n+     *   a). if isEndNow == true, stop AD job and store exception in anomaly result\n+     *   b). if isEndNow == false, record count of {@link EndRunException} for this\n+     *       detector. If count of {@link EndRunException} exceeds upper limit, will\n+     *       stop AD job and store exception in anomaly result; otherwise, just\n+     *       store exception in anomaly result, not stop AD job for the detector.\n+     *\n+     * 2. If exception is not {@link EndRunException}, decrease count of\n+     *    {@link EndRunException} for the detector and index eception in Anomaly\n+     *    result. If exception is {@link InternalFailure}, will not log exception\n+     *    stack trace as already logged in {@link AnomalyResultTransportAction}.\n+     *\n+     * TODO: Handle finer granularity exception such as some exception may be", "originalCommit": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4MDE0OQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393380149", "bodyText": "Thanks, created one issue: #66", "author": "ylwu-amzn", "createdAt": "2020-03-17T00:20:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIyMjMyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIyMjUwMw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393222503", "bodyText": "nit: typo: heavy", "author": "yizheliu-amazon", "createdAt": "2020-03-16T18:14:08Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -90,60 +133,368 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n                         jobParameter,\n                         context,\n                         ActionListener\n-                            .wrap(\n-                                lock -> runAdJob(jobParameter, lockService, lock),\n-                                exception -> {\n-                                    throw new IllegalStateException(\"Failed to acquire lock for AD job: \" + jobParameter.getName());\n-                                }\n-                            )\n+                            .wrap(lock -> runAdJob(jobParameter, lockService, lock, detectionStartTime, executionStartTime), exception -> {\n+                                indexAnomalyResultException(\n+                                    jobParameter,\n+                                    lockService,\n+                                    null,\n+                                    detectionStartTime,\n+                                    executionStartTime,\n+                                    exception,\n+                                    false\n+                                );\n+                                throw new IllegalStateException(\"Failed to acquire lock for AD job: \" + detectorId);\n+                            })\n                     );\n             } else {\n-                log.warn(\"Can't get lock for AD job: \" + jobParameter.getName());\n+                log.warn(\"Can't get lock for AD job: \" + detectorId);\n             }\n         };\n \n         ExecutorService executor = threadPool.executor(AD_THREAD_POOL_NAME);\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    /**\n+     * Get anomaly result, index result or handle exception if failed.\n+     *\n+     * @param jobParameter scheduled job parameter\n+     * @param lockService lock service\n+     * @param lock lock to run job\n+     * @param detectionStartTime detection start time\n+     * @param executionStartTime detection end time\n+     */\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant detectionStartTime,\n+        Instant executionStartTime\n+    ) {\n+        String detectorId = jobParameter.getName();\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                lockService,\n+                lock,\n+                detectionStartTime,\n+                executionStartTime,\n+                \"Can't run AD job due to null lock\",\n+                false\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n-                jobParameter.getName(),\n-                startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                detectorId,\n+                detectionStartTime.toEpochMilli(),\n+                executionStartTime.toEpochMilli()\n             );\n-            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+            client\n+                .execute(\n+                    AnomalyResultAction.INSTANCE,\n+                    request,\n+                    ActionListener\n+                        .wrap(\n+                            response -> {\n+                                indexAnomalyResult(jobParameter, lockService, lock, detectionStartTime, executionStartTime, response);\n+                            },\n+                            exception -> {\n+                                handleAdException(jobParameter, lockService, lock, detectionStartTime, executionStartTime, exception);\n+                            }\n+                        )\n+                );\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, detectionStartTime, executionStartTime, e, true);\n+            log.error(\"Failed to execute AD job \" + detectorId, e);\n+        }\n+    }\n+\n+    /**\n+     * Handle exception from anomaly result action.\n+     *\n+     * 1. If exception is {@link EndRunException}\n+     *   a). if isEndNow == true, stop AD job and store exception in anomaly result\n+     *   b). if isEndNow == false, record count of {@link EndRunException} for this\n+     *       detector. If count of {@link EndRunException} exceeds upper limit, will\n+     *       stop AD job and store exception in anomaly result; otherwise, just\n+     *       store exception in anomaly result, not stop AD job for the detector.\n+     *\n+     * 2. If exception is not {@link EndRunException}, decrease count of\n+     *    {@link EndRunException} for the detector and index eception in Anomaly\n+     *    result. If exception is {@link InternalFailure}, will not log exception\n+     *    stack trace as already logged in {@link AnomalyResultTransportAction}.\n+     *\n+     * TODO: Handle finer granularity exception such as some exception may be\n+     *       transient and retry in current job may succeed. Currently, we don't\n+     *       know which exception is transient and retryable in\n+     *       {@link AnomalyResultTransportAction}. So we don't add backoff retry\n+     *       now to avoid bring extra load to cluster, expecially the code start\n+     *       process is relatively heavey by sending out 24 queries, initializing", "originalCommit": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4MDIyNA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393380224", "bodyText": "will change it", "author": "ylwu-amzn", "createdAt": "2020-03-17T00:20:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIyMjUwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNTIzMw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393335233", "bodyText": "Can you log the exception here so that it might be easier for us to troubleshoot in case of any issue?", "author": "yizheliu-amazon", "createdAt": "2020-03-16T22:04:33Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/transport/handler/AnomalyResultHandler.java", "diffHunk": "@@ -0,0 +1,205 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.transport.handler;\n+\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.AnomalyDetectionException;\n+import com.amazon.opendistroforelasticsearch.ad.indices.AnomalyDetectionIndices;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyResult;\n+import com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings;\n+import com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ExceptionsHelper;\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.action.bulk.BackoffPolicy;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Iterator;\n+import java.util.Locale;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class AnomalyResultHandler {\n+    private static final Logger LOG = LogManager.getLogger(AnomalyResultHandler.class);\n+\n+    static final String CANNOT_SAVE_ERR_MSG = \"Cannot save anomaly result due to write block.\";\n+    static final String FAIL_TO_SAVE_ERR_MSG = \"Fail to save anomaly index: \";\n+    static final String RETRY_SAVING_ERR_MSG = \"Retry in saving anomaly index: \";\n+    static final String SUCCESS_SAVING_MSG = \"SSUCCESS_SAVING_MSGuccess in saving anomaly index: \";\n+\n+    private final Client client;\n+    private final ClusterService clusterService;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final AnomalyDetectionIndices anomalyDetectionIndices;\n+    private final ThreadPool threadPool;\n+    private final BackoffPolicy resultSavingBackoffPolicy;\n+\n+    public AnomalyResultHandler(\n+        Client client,\n+        Settings settings,\n+        ClusterService clusterService,\n+        IndexNameExpressionResolver indexNameExpressionResolver,\n+        AnomalyDetectionIndices anomalyDetectionIndices,\n+        ThreadPool threadPool\n+    ) {\n+        this.client = client;\n+        this.clusterService = clusterService;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.anomalyDetectionIndices = anomalyDetectionIndices;\n+        this.threadPool = threadPool;\n+        this.resultSavingBackoffPolicy = BackoffPolicy\n+            .exponentialBackoff(\n+                AnomalyDetectorSettings.BACKOFF_INITIAL_DELAY.get(settings),\n+                AnomalyDetectorSettings.MAX_RETRY_FOR_BACKOFF.get(settings)\n+            );\n+    }\n+\n+    public void indexAnomalyResult(AnomalyResult anomalyResult) {\n+        try {\n+            if (checkIndicesBlocked(clusterService.state(), ClusterBlockLevel.WRITE, AnomalyResult.ANOMALY_RESULT_INDEX)) {\n+                LOG.warn(CANNOT_SAVE_ERR_MSG);\n+                return;\n+            }\n+            if (!anomalyDetectionIndices.doesAnomalyResultIndexExist()) {\n+                anomalyDetectionIndices\n+                    .initAnomalyResultIndexDirectly(\n+                        ActionListener.wrap(initResponse -> onCreateAnomalyResultIndexResponse(initResponse, anomalyResult), exception -> {\n+                            if (ExceptionsHelper.unwrapCause(exception) instanceof ResourceAlreadyExistsException) {\n+                                // It is possible the index has been created while we sending the create request\n+                                saveDetectorResult(anomalyResult);\n+                            } else {\n+                                throw new AnomalyDetectionException(\n+                                    anomalyResult.getDetectorId(),\n+                                    \"Unexpected error creating anomaly result index\",\n+                                    exception\n+                                );\n+                            }\n+                        })\n+                    );\n+            } else {\n+                saveDetectorResult(anomalyResult);\n+            }\n+        } catch (Exception e) {\n+            throw new AnomalyDetectionException(\n+                anomalyResult.getDetectorId(),\n+                String\n+                    .format(\n+                        Locale.ROOT,\n+                        \"Error in saving anomaly index for ID %s from %s to %s\",\n+                        anomalyResult.getDetectorId(),\n+                        anomalyResult.getDataStartTime(),\n+                        anomalyResult.getDataEndTime()\n+                    )\n+            );\n+        }\n+    }\n+\n+    /**\n+     * Similar to checkGlobalBlock, we check block on the indices level.\n+     *\n+     * @param state   Cluster state\n+     * @param level   block level\n+     * @param indices the indices on which to check block\n+     * @return whether any of the index has block on the level.\n+     */\n+    private boolean checkIndicesBlocked(ClusterState state, ClusterBlockLevel level, String... indices) {\n+        // the original index might be an index expression with wildcards like \"log*\",\n+        // so we need to expand the expression to concrete index name\n+        String[] concreteIndices = indexNameExpressionResolver.concreteIndexNames(state, IndicesOptions.lenientExpandOpen(), indices);\n+\n+        return state.blocks().indicesBlockedException(level, concreteIndices) != null;\n+    }\n+\n+    private void onCreateAnomalyResultIndexResponse(CreateIndexResponse response, AnomalyResult anomalyResult) {\n+        if (response.isAcknowledged()) {\n+            saveDetectorResult(anomalyResult);\n+        } else {\n+            throw new AnomalyDetectionException(\n+                anomalyResult.getDetectorId(),\n+                \"Creating anomaly result index with mappings call not acknowledged.\"\n+            );\n+        }\n+    }\n+\n+    private void saveDetectorResult(AnomalyResult anomalyResult) {\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            IndexRequest indexRequest = new IndexRequest(AnomalyResult.ANOMALY_RESULT_INDEX)\n+                .source(anomalyResult.toXContent(builder, RestHandlerUtils.XCONTENT_WITH_TYPE));\n+            saveDetectorResult(\n+                indexRequest,\n+                String\n+                    .format(\n+                        Locale.ROOT,\n+                        \"ID %s from %s to %s\",\n+                        anomalyResult.getDetectorId(),\n+                        anomalyResult.getDataStartTime(),\n+                        anomalyResult.getDataEndTime()\n+                    ),\n+                resultSavingBackoffPolicy.iterator()\n+            );\n+        } catch (Exception e) {\n+            e.printStackTrace();\n+            throw new AnomalyDetectionException(anomalyResult.getDetectorId(), \"Cannot save result\");\n+        }\n+    }\n+\n+    void saveDetectorResult(IndexRequest indexRequest, String context, Iterator<TimeValue> backoff) {\n+        client\n+            .index(\n+                indexRequest,\n+                ActionListener\n+                    .<IndexResponse>wrap(\n+                        response -> LOG.debug(SUCCESS_SAVING_MSG + context),\n+                        exception -> {\n+                            // Elasticsearch has a thread pool and a queue for write per node. A thread\n+                            // pool will have N number of workers ready to handle the requests. When a\n+                            // request comes and if a worker is free , this is handled by the worker. Now by\n+                            // default the number of workers is equal to the number of cores on that CPU.\n+                            // When the workers are full and there are more write requests, the request\n+                            // will go to queue. The size of queue is also limited. If by default size is,\n+                            // say, 200 and if there happens more parallel requests than this, then those\n+                            // requests would be rejected as you can see EsRejectedExecutionException.\n+                            // So EsRejectedExecutionException is the way that Elasticsearch tells us that\n+                            // it cannot keep up with the current indexing rate.\n+                            // When it happens, we should pause indexing a bit before trying again, ideally\n+                            // with randomized exponential backoff.", "originalCommit": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4NjgxMw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393386813", "bodyText": "Sure, will add", "author": "ylwu-amzn", "createdAt": "2020-03-17T00:47:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNTIzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNTU0OQ==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393335549", "bodyText": "why use printStackTrace instead of log.error?", "author": "yizheliu-amazon", "createdAt": "2020-03-16T22:05:29Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/transport/handler/AnomalyResultHandler.java", "diffHunk": "@@ -0,0 +1,205 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.transport.handler;\n+\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.AnomalyDetectionException;\n+import com.amazon.opendistroforelasticsearch.ad.indices.AnomalyDetectionIndices;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyResult;\n+import com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings;\n+import com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ExceptionsHelper;\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.action.bulk.BackoffPolicy;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Iterator;\n+import java.util.Locale;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class AnomalyResultHandler {\n+    private static final Logger LOG = LogManager.getLogger(AnomalyResultHandler.class);\n+\n+    static final String CANNOT_SAVE_ERR_MSG = \"Cannot save anomaly result due to write block.\";\n+    static final String FAIL_TO_SAVE_ERR_MSG = \"Fail to save anomaly index: \";\n+    static final String RETRY_SAVING_ERR_MSG = \"Retry in saving anomaly index: \";\n+    static final String SUCCESS_SAVING_MSG = \"SSUCCESS_SAVING_MSGuccess in saving anomaly index: \";\n+\n+    private final Client client;\n+    private final ClusterService clusterService;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final AnomalyDetectionIndices anomalyDetectionIndices;\n+    private final ThreadPool threadPool;\n+    private final BackoffPolicy resultSavingBackoffPolicy;\n+\n+    public AnomalyResultHandler(\n+        Client client,\n+        Settings settings,\n+        ClusterService clusterService,\n+        IndexNameExpressionResolver indexNameExpressionResolver,\n+        AnomalyDetectionIndices anomalyDetectionIndices,\n+        ThreadPool threadPool\n+    ) {\n+        this.client = client;\n+        this.clusterService = clusterService;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.anomalyDetectionIndices = anomalyDetectionIndices;\n+        this.threadPool = threadPool;\n+        this.resultSavingBackoffPolicy = BackoffPolicy\n+            .exponentialBackoff(\n+                AnomalyDetectorSettings.BACKOFF_INITIAL_DELAY.get(settings),\n+                AnomalyDetectorSettings.MAX_RETRY_FOR_BACKOFF.get(settings)\n+            );\n+    }\n+\n+    public void indexAnomalyResult(AnomalyResult anomalyResult) {\n+        try {\n+            if (checkIndicesBlocked(clusterService.state(), ClusterBlockLevel.WRITE, AnomalyResult.ANOMALY_RESULT_INDEX)) {\n+                LOG.warn(CANNOT_SAVE_ERR_MSG);\n+                return;\n+            }\n+            if (!anomalyDetectionIndices.doesAnomalyResultIndexExist()) {\n+                anomalyDetectionIndices\n+                    .initAnomalyResultIndexDirectly(\n+                        ActionListener.wrap(initResponse -> onCreateAnomalyResultIndexResponse(initResponse, anomalyResult), exception -> {\n+                            if (ExceptionsHelper.unwrapCause(exception) instanceof ResourceAlreadyExistsException) {\n+                                // It is possible the index has been created while we sending the create request\n+                                saveDetectorResult(anomalyResult);\n+                            } else {\n+                                throw new AnomalyDetectionException(\n+                                    anomalyResult.getDetectorId(),\n+                                    \"Unexpected error creating anomaly result index\",\n+                                    exception\n+                                );\n+                            }\n+                        })\n+                    );\n+            } else {\n+                saveDetectorResult(anomalyResult);\n+            }\n+        } catch (Exception e) {\n+            throw new AnomalyDetectionException(\n+                anomalyResult.getDetectorId(),\n+                String\n+                    .format(\n+                        Locale.ROOT,\n+                        \"Error in saving anomaly index for ID %s from %s to %s\",\n+                        anomalyResult.getDetectorId(),\n+                        anomalyResult.getDataStartTime(),\n+                        anomalyResult.getDataEndTime()\n+                    )\n+            );\n+        }\n+    }\n+\n+    /**\n+     * Similar to checkGlobalBlock, we check block on the indices level.\n+     *\n+     * @param state   Cluster state\n+     * @param level   block level\n+     * @param indices the indices on which to check block\n+     * @return whether any of the index has block on the level.\n+     */\n+    private boolean checkIndicesBlocked(ClusterState state, ClusterBlockLevel level, String... indices) {\n+        // the original index might be an index expression with wildcards like \"log*\",\n+        // so we need to expand the expression to concrete index name\n+        String[] concreteIndices = indexNameExpressionResolver.concreteIndexNames(state, IndicesOptions.lenientExpandOpen(), indices);\n+\n+        return state.blocks().indicesBlockedException(level, concreteIndices) != null;\n+    }\n+\n+    private void onCreateAnomalyResultIndexResponse(CreateIndexResponse response, AnomalyResult anomalyResult) {\n+        if (response.isAcknowledged()) {\n+            saveDetectorResult(anomalyResult);\n+        } else {\n+            throw new AnomalyDetectionException(\n+                anomalyResult.getDetectorId(),\n+                \"Creating anomaly result index with mappings call not acknowledged.\"\n+            );\n+        }\n+    }\n+\n+    private void saveDetectorResult(AnomalyResult anomalyResult) {\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            IndexRequest indexRequest = new IndexRequest(AnomalyResult.ANOMALY_RESULT_INDEX)\n+                .source(anomalyResult.toXContent(builder, RestHandlerUtils.XCONTENT_WITH_TYPE));\n+            saveDetectorResult(\n+                indexRequest,\n+                String\n+                    .format(\n+                        Locale.ROOT,\n+                        \"ID %s from %s to %s\",\n+                        anomalyResult.getDetectorId(),\n+                        anomalyResult.getDataStartTime(),\n+                        anomalyResult.getDataEndTime()\n+                    ),\n+                resultSavingBackoffPolicy.iterator()\n+            );\n+        } catch (Exception e) {\n+            e.printStackTrace();", "originalCommit": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4NzM5Nw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393387397", "bodyText": "Will remove it. Some debug code", "author": "ylwu-amzn", "createdAt": "2020-03-17T00:50:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNTU0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNjQwNA==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393336404", "bodyText": "Can you either log the Exception or use it to initialize AnomalyDetectionException, so that we don't loose track of the original exception info?", "author": "yizheliu-amazon", "createdAt": "2020-03-16T22:07:57Z", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/transport/handler/AnomalyResultHandler.java", "diffHunk": "@@ -0,0 +1,205 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.transport.handler;\n+\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.AnomalyDetectionException;\n+import com.amazon.opendistroforelasticsearch.ad.indices.AnomalyDetectionIndices;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyResult;\n+import com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings;\n+import com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ExceptionsHelper;\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.action.bulk.BackoffPolicy;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Iterator;\n+import java.util.Locale;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class AnomalyResultHandler {\n+    private static final Logger LOG = LogManager.getLogger(AnomalyResultHandler.class);\n+\n+    static final String CANNOT_SAVE_ERR_MSG = \"Cannot save anomaly result due to write block.\";\n+    static final String FAIL_TO_SAVE_ERR_MSG = \"Fail to save anomaly index: \";\n+    static final String RETRY_SAVING_ERR_MSG = \"Retry in saving anomaly index: \";\n+    static final String SUCCESS_SAVING_MSG = \"SSUCCESS_SAVING_MSGuccess in saving anomaly index: \";\n+\n+    private final Client client;\n+    private final ClusterService clusterService;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final AnomalyDetectionIndices anomalyDetectionIndices;\n+    private final ThreadPool threadPool;\n+    private final BackoffPolicy resultSavingBackoffPolicy;\n+\n+    public AnomalyResultHandler(\n+        Client client,\n+        Settings settings,\n+        ClusterService clusterService,\n+        IndexNameExpressionResolver indexNameExpressionResolver,\n+        AnomalyDetectionIndices anomalyDetectionIndices,\n+        ThreadPool threadPool\n+    ) {\n+        this.client = client;\n+        this.clusterService = clusterService;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.anomalyDetectionIndices = anomalyDetectionIndices;\n+        this.threadPool = threadPool;\n+        this.resultSavingBackoffPolicy = BackoffPolicy\n+            .exponentialBackoff(\n+                AnomalyDetectorSettings.BACKOFF_INITIAL_DELAY.get(settings),\n+                AnomalyDetectorSettings.MAX_RETRY_FOR_BACKOFF.get(settings)\n+            );\n+    }\n+\n+    public void indexAnomalyResult(AnomalyResult anomalyResult) {\n+        try {\n+            if (checkIndicesBlocked(clusterService.state(), ClusterBlockLevel.WRITE, AnomalyResult.ANOMALY_RESULT_INDEX)) {\n+                LOG.warn(CANNOT_SAVE_ERR_MSG);\n+                return;\n+            }\n+            if (!anomalyDetectionIndices.doesAnomalyResultIndexExist()) {\n+                anomalyDetectionIndices\n+                    .initAnomalyResultIndexDirectly(\n+                        ActionListener.wrap(initResponse -> onCreateAnomalyResultIndexResponse(initResponse, anomalyResult), exception -> {\n+                            if (ExceptionsHelper.unwrapCause(exception) instanceof ResourceAlreadyExistsException) {\n+                                // It is possible the index has been created while we sending the create request\n+                                saveDetectorResult(anomalyResult);\n+                            } else {\n+                                throw new AnomalyDetectionException(\n+                                    anomalyResult.getDetectorId(),\n+                                    \"Unexpected error creating anomaly result index\",\n+                                    exception\n+                                );\n+                            }\n+                        })\n+                    );\n+            } else {\n+                saveDetectorResult(anomalyResult);\n+            }\n+        } catch (Exception e) {\n+            throw new AnomalyDetectionException(\n+                anomalyResult.getDetectorId(),\n+                String\n+                    .format(\n+                        Locale.ROOT,\n+                        \"Error in saving anomaly index for ID %s from %s to %s\",\n+                        anomalyResult.getDetectorId(),\n+                        anomalyResult.getDataStartTime(),\n+                        anomalyResult.getDataEndTime()\n+                    )\n+            );", "originalCommit": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4ODUxMw==", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393388513", "bodyText": "Sure, code split from AnomalyResultTransportAction, will refactor it to add original exception", "author": "ylwu-amzn", "createdAt": "2020-03-17T00:54:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNjQwNA=="}], "type": "inlineReview"}, {"oid": "f96571721f8952f17cecea2f44d71ea7d7f8e657", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/f96571721f8952f17cecea2f44d71ea7d7f8e657", "message": "fix typo;add more log", "committedDate": "2020-03-17T02:13:30Z", "type": "commit"}]}