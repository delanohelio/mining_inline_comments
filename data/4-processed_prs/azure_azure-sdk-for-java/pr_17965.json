{"pr_number": 17965, "pr_title": "Query plan caching", "pr_createdAt": "2020-12-03T18:44:32Z", "pr_url": "https://github.com/Azure/azure-sdk-for-java/pull/17965", "timeline": [{"oid": "3e9b09d1353aa18935e707472840563c9aed338e", "url": "https://github.com/Azure/azure-sdk-for-java/commit/3e9b09d1353aa18935e707472840563c9aed338e", "message": "This PR adds some optimizations to query execution time by caching query plan where possible.", "committedDate": "2020-12-03T18:27:46Z", "type": "commit"}, {"oid": "3a6ef72f231b3a7eda6217de0d03b2a195bceb96", "url": "https://github.com/Azure/azure-sdk-for-java/commit/3a6ef72f231b3a7eda6217de0d03b2a195bceb96", "message": "Cleanup and more tests", "committedDate": "2020-12-04T03:39:44Z", "type": "commit"}, {"oid": "29c05d46ff0ce8fcb1a73736d74988169279d9ac", "url": "https://github.com/Azure/azure-sdk-for-java/commit/29c05d46ff0ce8fcb1a73736d74988169279d9ac", "message": "spot bug fixes", "committedDate": "2020-12-05T05:07:15Z", "type": "commit"}, {"oid": "8b4a8581b77d92c48d409689fe12a3f236960c91", "url": "https://github.com/Azure/azure-sdk-for-java/commit/8b4a8581b77d92c48d409689fe12a3f236960c91", "message": "Fixing test", "committedDate": "2020-12-09T04:53:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAyOTI2MA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r539029260", "bodyText": "doesn't guava library that is shaded into our code have a LRUCache we can re-use?", "author": "moderakh", "createdAt": "2020-12-09T05:52:54Z", "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/LRUCache.java", "diffHunk": "@@ -0,0 +1,23 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+package com.azure.cosmos.implementation;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentLinkedDeque;\n+\n+public class LRUCache<K, V> extends LinkedHashMap<K, V> {", "originalCommit": "8b4a8581b77d92c48d409689fe12a3f236960c91", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAzMTUyNA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r539031524", "bodyText": "guava has a CompactLinkedHashMap which they say is more efficient than LinkedHashMap, and that could be used as LRUCache, but that class is not public", "author": "mbhaskar", "createdAt": "2020-12-09T05:59:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAyOTI2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAyOTQyMw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r539029423", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        this.queryPlanCache = new LRUCache<>(30);\n          \n          \n            \n                        this.queryPlanCache = new LRUCache<>(CACHE_SIZE);", "author": "moderakh", "createdAt": "2020-12-09T05:53:29Z", "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/RxDocumentClientImpl.java", "diffHunk": "@@ -341,6 +352,7 @@ private RxDocumentClientImpl(URI serviceEndpoint,\n             this.retryPolicy = new RetryPolicy(this, this.globalEndpointManager, this.connectionPolicy);\n             this.resetSessionTokenRetryPolicy = retryPolicy;\n             CpuMemoryMonitor.register(this);\n+            this.queryPlanCache = new LRUCache<>(30);", "originalCommit": "8b4a8581b77d92c48d409689fe12a3f236960c91", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUyNzYyNA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r539527624", "bodyText": "Done", "author": "mbhaskar", "createdAt": "2020-12-09T18:01:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAyOTQyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAyOTczNA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r539029734", "bodyText": "does anything throw this? ConcurrentModificationException", "author": "moderakh", "createdAt": "2020-12-09T05:54:24Z", "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/query/DocumentQueryExecutionContextFactory.java", "diffHunk": "@@ -21,11 +22,14 @@\n import com.azure.cosmos.implementation.routing.Range;\n import com.azure.cosmos.models.ModelBridgeInternal;\n import com.azure.cosmos.implementation.apachecommons.lang.StringUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n import reactor.core.publisher.Flux;\n import reactor.core.publisher.Mono;\n \n import java.time.Instant;\n import java.util.Collections;\n+import java.util.ConcurrentModificationException;", "originalCommit": "8b4a8581b77d92c48d409689fe12a3f236960c91", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUyODA2Mw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r539528063", "bodyText": "LinkedHashMap could throw this", "author": "mbhaskar", "createdAt": "2020-12-09T18:02:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAyOTczNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEyNDQxMg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r546124412", "bodyText": "why do we still need this?", "author": "moderakh", "createdAt": "2020-12-18T22:40:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAyOTczNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAzMDIyMQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r539030221", "bodyText": "is this thread safe?", "author": "moderakh", "createdAt": "2020-12-09T05:55:44Z", "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/LRUCache.java", "diffHunk": "@@ -0,0 +1,23 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+package com.azure.cosmos.implementation;\n+\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentLinkedDeque;\n+\n+public class LRUCache<K, V> extends LinkedHashMap<K, V> {", "originalCommit": "8b4a8581b77d92c48d409689fe12a3f236960c91", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAzMjM0Mw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r539032343", "bodyText": "This is not thread safe! and can throw ConcurrentModificationException. I tried adding thread safety but any additional synchronization added is slowing down the cache and resulting in much less perf. So in the current implementation I am just catching this exception and doing nothing, as we are good if one of the attempts to write succeeds at some point.", "author": "mbhaskar", "createdAt": "2020-12-09T06:01:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAzMDIyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0NDEzNQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r540544135", "bodyText": "Maybe I am too pragmatic - but do we really need an LRUCache? At least if my assumption above is correct that the size could be in the order of hundreds or thousands we could have simpler implementation like replacing the map with a new one if it ever exceeds the max. size or similar and use a thread-safe map implementation instead?", "author": "FabianMeiswinkel", "createdAt": "2020-12-10T22:29:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAzMDIyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0NDY4MQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r541144681", "bodyText": "I don't think we should be using a non-thread safe construct in a multi-threading fashion. I think relying on ConcurrentModificationException is not the correct pattern.", "author": "moderakh", "createdAt": "2020-12-11T18:29:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAzMDIyMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0NjY0OQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r541146649", "bodyText": "As we are bounding the cache size at this point, we need a mechanism to make sure we have policy on when we replace the query in the cache and LRU works well in this case by caching repeatedly used queries. We may not be much interested in one off queries as caching/not caching would not make much of a difference for a query run very rarely", "author": "mbhaskar", "createdAt": "2020-12-11T18:33:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAzMDIyMQ=="}], "type": "inlineReview"}, {"oid": "77e44c7800f83dc031f121f516cb13c5783a45b1", "url": "https://github.com/Azure/azure-sdk-for-java/commit/77e44c7800f83dc031f121f516cb13c5783a45b1", "message": "Implementing PR comments", "committedDate": "2020-12-09T18:01:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDUzNzExMA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r540537110", "bodyText": "I don't think we should add public surface area for this - why would you ever want to not cache query plan?\nHaving a system property override to disable it in case we cause some regression etc. is ok - but I would not allow this to be configurable in public API - especially where the best-practice is opt-in", "author": "FabianMeiswinkel", "createdAt": "2020-12-10T22:15:58Z", "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/CosmosClientBuilder.java", "diffHunk": "@@ -619,6 +621,23 @@ public CosmosClientBuilder readRequestsFallbackEnabled(boolean readRequestsFallb\n         return this;\n     }\n \n+    /**\n+     * Sets whether to allow the query plan to be cached when possible, during query execution. Caching query plan\n+     * improves the latency/throughput of the query execution when same queries are executed again. It is recommended\n+     * to use parameterized queries when trying to cache query plan.\n+     * <p>\n+     * DEFAULT value is false\n+     * </p>\n+     *\n+     * @param queryPlanCachingEnabled flag to enable query plan cache", "originalCommit": "77e44c7800f83dc031f121f516cb13c5783a45b1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEyMTE1NQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r546121155", "bodyText": "This is being enabled as an experimental feature. Based on the feedback we can make it the default behaviour", "author": "mbhaskar", "createdAt": "2020-12-18T22:29:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDUzNzExMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0MDAxOQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r540540019", "bodyText": "Should we really make this configurable? And 30 is the number of query plans to be cached? I would argue that this value should be artificially high - so that we basically nearly always are able to cache query plans. Like at least in the order of thousands. Even if query plans are relatively large - like in the order of KBs if a customer is running a workload with hundreds of different queries a couple of MBs for this case memory will be the least of their problems :-) - Disabling/reducing config as System properties - fine - but not public surface area would be my recommendation.", "author": "FabianMeiswinkel", "createdAt": "2020-12-10T22:21:24Z", "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/RxDocumentClientImpl.java", "diffHunk": "@@ -136,6 +136,9 @@\n     private RxPartitionKeyRangeCache partitionKeyRangeCache;\n     private Map<String, List<PartitionKeyAndResourceTokenPair>> resourceTokensMap;\n     private final boolean contentResponseOnWriteEnabled;\n+    private boolean queryPlanCachingEnabled;\n+    private static final int CACHE_SIZE = 30; // This value will be made configurable in future", "originalCommit": "77e44c7800f83dc031f121f516cb13c5783a45b1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0NTgxNg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r541145816", "bodyText": "With the initial data I have from some observations, I see that not many different varieties of queries are being used by the users and if parameterized, they should be good with a small size. Also, we want to start with a small size, get some feedback on the results and then either make it unbounded/very large or limit it to a particular size", "author": "mbhaskar", "createdAt": "2020-12-11T18:31:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0MDAxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEyMTA2MA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r546121060", "bodyText": "Increased it to 1000. As this is experimental feature at this point, based on the feedback and observations we make, we can set a better value", "author": "mbhaskar", "createdAt": "2020-12-18T22:29:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0MDAxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0NzQ1MQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r540547451", "bodyText": "getQueryText will return the query as specified by the user - so if user isn't using query parameters we would see a very high number of different queries even for the same shape, correct? I though the Sql parsing done with ANTLR would allow us to create the normalized query shape - like take parameter/filter values out of the equation etc.?\nI might be missing some context - so more a question that an ask to change anything...", "author": "FabianMeiswinkel", "createdAt": "2020-12-10T22:35:50Z", "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/query/DocumentQueryExecutionContextFactory.java", "diffHunk": "@@ -78,49 +84,105 @@\n         }\n \n         Instant startTime = Instant.now();\n-        Mono<PartitionedQueryExecutionInfo> queryExecutionInfoMono =\n-            QueryPlanRetriever\n-                .getQueryPlanThroughGatewayAsync(diagnosticsClientContext, client, query, resourceLink);\n+        Mono<PartitionedQueryExecutionInfo> queryExecutionInfoMono;\n+        if (queryPlanCachingEnabled &&\n+                isScopedToSinglePartition(cosmosQueryRequestOptions) &&\n+                queryPlanCache.containsKey(query.getQueryText())) {", "originalCommit": "77e44c7800f83dc031f121f516cb13c5783a45b1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0MzYzMw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r541143633", "bodyText": "Yes thats true, it would result in high number, thats why we want to cap the size of the cache. Even if we parse the query using ANTLR, we wouldn't build any context on the query info at this point and just classify the query as locally executable or not", "author": "mbhaskar", "createdAt": "2020-12-11T18:27:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0NzQ1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0OTE5NQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r540549195", "bodyText": "Why would Top/Limit not work for single partition queries? Not even for relatively common model of Top 1?", "author": "FabianMeiswinkel", "createdAt": "2020-12-10T22:38:28Z", "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/query/DocumentQueryExecutionContextFactory.java", "diffHunk": "@@ -78,49 +84,105 @@\n         }\n \n         Instant startTime = Instant.now();\n-        Mono<PartitionedQueryExecutionInfo> queryExecutionInfoMono =\n-            QueryPlanRetriever\n-                .getQueryPlanThroughGatewayAsync(diagnosticsClientContext, client, query, resourceLink);\n+        Mono<PartitionedQueryExecutionInfo> queryExecutionInfoMono;\n+        if (queryPlanCachingEnabled &&\n+                isScopedToSinglePartition(cosmosQueryRequestOptions) &&\n+                queryPlanCache.containsKey(query.getQueryText())) {\n+            Instant endTime = Instant.now(); // endTime for query plan diagnostics\n+            PartitionedQueryExecutionInfo partitionedQueryExecutionInfo = queryPlanCache.get(query.getQueryText());\n+            return getTargetRangesFromQueryPlan(cosmosQueryRequestOptions, collection, queryExecutionContext,\n+                                                partitionedQueryExecutionInfo, startTime, endTime);\n+        } else {\n+            queryExecutionInfoMono = QueryPlanRetriever\n+                                         .getQueryPlanThroughGatewayAsync(diagnosticsClientContext, client, query,\n+                                                                          resourceLink);\n+        }\n \n         return queryExecutionInfoMono.flatMap(\n             partitionedQueryExecutionInfo -> {\n \n                 Instant endTime = Instant.now();\n-                QueryInfo queryInfo =\n-                    partitionedQueryExecutionInfo.getQueryInfo();\n-                queryInfo.setQueryPlanDiagnosticsContext(new QueryInfo.QueryPlanDiagnosticsContext(startTime, endTime));\n-\n-                List<Range<String>> queryRanges =\n-                    partitionedQueryExecutionInfo.getQueryRanges();\n-\n-                if (cosmosQueryRequestOptions != null\n-                    && cosmosQueryRequestOptions.getPartitionKey() != null\n-                    && cosmosQueryRequestOptions.getPartitionKey() != PartitionKey.NONE) {\n-                    PartitionKeyInternal internalPartitionKey =\n-                        BridgeInternal.getPartitionKeyInternal(cosmosQueryRequestOptions.getPartitionKey());\n-                    Range<String> range = Range\n-                        .getPointRange(internalPartitionKey\n-                            .getEffectivePartitionKeyString(internalPartitionKey, collection.getPartitionKey()));\n-                    queryRanges = Collections.singletonList(range);\n+\n+                if (queryPlanCachingEnabled) {\n+                    tryCacheQueryPlan(query, partitionedQueryExecutionInfo, queryPlanCache);\n                 }\n-                return\n-                    queryExecutionContext.getTargetPartitionKeyRanges(collection.getResourceId(), queryRanges)\n-                    .map(pkRanges -> Pair.of(\n-                        pkRanges,\n-                        partitionedQueryExecutionInfo.getQueryInfo()));\n+\n+                return getTargetRangesFromQueryPlan(cosmosQueryRequestOptions, collection, queryExecutionContext,\n+                                                    partitionedQueryExecutionInfo, startTime, endTime);\n             });\n     }\n \n+    private static <T extends Resource> Mono<Pair<List<PartitionKeyRange>, QueryInfo>> getTargetRangesFromQueryPlan(\n+        CosmosQueryRequestOptions cosmosQueryRequestOptions, DocumentCollection collection,\n+        DefaultDocumentQueryExecutionContext<T> queryExecutionContext,\n+        PartitionedQueryExecutionInfo partitionedQueryExecutionInfo, Instant planFetchStartTime,\n+        Instant planFetchEndTime) {\n+        QueryInfo queryInfo =\n+            partitionedQueryExecutionInfo.getQueryInfo();\n+        queryInfo.setQueryPlanDiagnosticsContext(new QueryInfo.QueryPlanDiagnosticsContext(planFetchStartTime,\n+                                                                                           planFetchEndTime));\n+        List<Range<String>> queryRanges =\n+            partitionedQueryExecutionInfo.getQueryRanges();\n+\n+        if (isScopedToSinglePartition(cosmosQueryRequestOptions)) {\n+            PartitionKeyInternal internalPartitionKey =\n+                BridgeInternal.getPartitionKeyInternal(cosmosQueryRequestOptions.getPartitionKey());\n+            Range<String> range = Range\n+                                      .getPointRange(internalPartitionKey\n+                                                         .getEffectivePartitionKeyString(internalPartitionKey,\n+                                                                                         collection\n+                                                                                             .getPartitionKey()));\n+            queryRanges = Collections.singletonList(range);\n+        }\n+        return\n+            queryExecutionContext.getTargetPartitionKeyRanges(collection.getResourceId(), queryRanges)\n+                .map(pkRanges -> Pair.of(\n+                    pkRanges,\n+                    partitionedQueryExecutionInfo.getQueryInfo()));\n+    }\n+\n+    private static void tryCacheQueryPlan(\n+        SqlQuerySpec query,\n+        PartitionedQueryExecutionInfo partitionedQueryExecutionInfo,\n+        LRUCache<String, PartitionedQueryExecutionInfo> queryPlanCache) {\n+        QueryInfo queryInfo = partitionedQueryExecutionInfo.getQueryInfo();\n+        if (canCacheQuery(queryInfo) && !queryPlanCache.containsKey(query.getQueryText())) {\n+            try {\n+                queryPlanCache.put(query.getQueryText(), partitionedQueryExecutionInfo);\n+            } catch (ConcurrentModificationException exception) {\n+                logger.error(\"Error caching query plan: \", exception);\n+            }\n+        }\n+    }\n+\n+    private static boolean canCacheQuery(QueryInfo queryInfo) {\n+        // Query plan will not be cached for the types below\n+        return !queryInfo.hasAggregates()\n+                   && !queryInfo.hasDistinct()\n+                   && !queryInfo.hasGroupBy()\n+                   && !queryInfo.hasLimit()\n+                   && !queryInfo.hasTop()", "originalCommit": "77e44c7800f83dc031f121f516cb13c5783a45b1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0MjUzNg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r541142536", "bodyText": "The query plan for these queries includes the hardcoded values for the top/limit/offset specified even if the query is parameterized, which makes the query plan tied to a single query", "author": "mbhaskar", "createdAt": "2020-12-11T18:26:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0OTE5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0NDA1OA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r541144058", "bodyText": "I don't think this is the current pattern. We shouldn't be using a cache which is not thread-safe.", "author": "moderakh", "createdAt": "2020-12-11T18:28:34Z", "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/query/DocumentQueryExecutionContextFactory.java", "diffHunk": "@@ -78,49 +84,105 @@\n         }\n \n         Instant startTime = Instant.now();\n-        Mono<PartitionedQueryExecutionInfo> queryExecutionInfoMono =\n-            QueryPlanRetriever\n-                .getQueryPlanThroughGatewayAsync(diagnosticsClientContext, client, query, resourceLink);\n+        Mono<PartitionedQueryExecutionInfo> queryExecutionInfoMono;\n+        if (queryPlanCachingEnabled &&\n+                isScopedToSinglePartition(cosmosQueryRequestOptions) &&\n+                queryPlanCache.containsKey(query.getQueryText())) {\n+            Instant endTime = Instant.now(); // endTime for query plan diagnostics\n+            PartitionedQueryExecutionInfo partitionedQueryExecutionInfo = queryPlanCache.get(query.getQueryText());\n+            return getTargetRangesFromQueryPlan(cosmosQueryRequestOptions, collection, queryExecutionContext,\n+                                                partitionedQueryExecutionInfo, startTime, endTime);\n+        } else {\n+            queryExecutionInfoMono = QueryPlanRetriever\n+                                         .getQueryPlanThroughGatewayAsync(diagnosticsClientContext, client, query,\n+                                                                          resourceLink);\n+        }\n \n         return queryExecutionInfoMono.flatMap(\n             partitionedQueryExecutionInfo -> {\n \n                 Instant endTime = Instant.now();\n-                QueryInfo queryInfo =\n-                    partitionedQueryExecutionInfo.getQueryInfo();\n-                queryInfo.setQueryPlanDiagnosticsContext(new QueryInfo.QueryPlanDiagnosticsContext(startTime, endTime));\n-\n-                List<Range<String>> queryRanges =\n-                    partitionedQueryExecutionInfo.getQueryRanges();\n-\n-                if (cosmosQueryRequestOptions != null\n-                    && cosmosQueryRequestOptions.getPartitionKey() != null\n-                    && cosmosQueryRequestOptions.getPartitionKey() != PartitionKey.NONE) {\n-                    PartitionKeyInternal internalPartitionKey =\n-                        BridgeInternal.getPartitionKeyInternal(cosmosQueryRequestOptions.getPartitionKey());\n-                    Range<String> range = Range\n-                        .getPointRange(internalPartitionKey\n-                            .getEffectivePartitionKeyString(internalPartitionKey, collection.getPartitionKey()));\n-                    queryRanges = Collections.singletonList(range);\n+\n+                if (queryPlanCachingEnabled) {\n+                    tryCacheQueryPlan(query, partitionedQueryExecutionInfo, queryPlanCache);\n                 }\n-                return\n-                    queryExecutionContext.getTargetPartitionKeyRanges(collection.getResourceId(), queryRanges)\n-                    .map(pkRanges -> Pair.of(\n-                        pkRanges,\n-                        partitionedQueryExecutionInfo.getQueryInfo()));\n+\n+                return getTargetRangesFromQueryPlan(cosmosQueryRequestOptions, collection, queryExecutionContext,\n+                                                    partitionedQueryExecutionInfo, startTime, endTime);\n             });\n     }\n \n+    private static <T extends Resource> Mono<Pair<List<PartitionKeyRange>, QueryInfo>> getTargetRangesFromQueryPlan(\n+        CosmosQueryRequestOptions cosmosQueryRequestOptions, DocumentCollection collection,\n+        DefaultDocumentQueryExecutionContext<T> queryExecutionContext,\n+        PartitionedQueryExecutionInfo partitionedQueryExecutionInfo, Instant planFetchStartTime,\n+        Instant planFetchEndTime) {\n+        QueryInfo queryInfo =\n+            partitionedQueryExecutionInfo.getQueryInfo();\n+        queryInfo.setQueryPlanDiagnosticsContext(new QueryInfo.QueryPlanDiagnosticsContext(planFetchStartTime,\n+                                                                                           planFetchEndTime));\n+        List<Range<String>> queryRanges =\n+            partitionedQueryExecutionInfo.getQueryRanges();\n+\n+        if (isScopedToSinglePartition(cosmosQueryRequestOptions)) {\n+            PartitionKeyInternal internalPartitionKey =\n+                BridgeInternal.getPartitionKeyInternal(cosmosQueryRequestOptions.getPartitionKey());\n+            Range<String> range = Range\n+                                      .getPointRange(internalPartitionKey\n+                                                         .getEffectivePartitionKeyString(internalPartitionKey,\n+                                                                                         collection\n+                                                                                             .getPartitionKey()));\n+            queryRanges = Collections.singletonList(range);\n+        }\n+        return\n+            queryExecutionContext.getTargetPartitionKeyRanges(collection.getResourceId(), queryRanges)\n+                .map(pkRanges -> Pair.of(\n+                    pkRanges,\n+                    partitionedQueryExecutionInfo.getQueryInfo()));\n+    }\n+\n+    private static void tryCacheQueryPlan(\n+        SqlQuerySpec query,\n+        PartitionedQueryExecutionInfo partitionedQueryExecutionInfo,\n+        LRUCache<String, PartitionedQueryExecutionInfo> queryPlanCache) {\n+        QueryInfo queryInfo = partitionedQueryExecutionInfo.getQueryInfo();\n+        if (canCacheQuery(queryInfo) && !queryPlanCache.containsKey(query.getQueryText())) {\n+            try {\n+                queryPlanCache.put(query.getQueryText(), partitionedQueryExecutionInfo);\n+            } catch (ConcurrentModificationException exception) {\n+                logger.error(\"Error caching query plan: \", exception);", "originalCommit": "77e44c7800f83dc031f121f516cb13c5783a45b1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0ODA4OA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r541148088", "bodyText": "Agree. But this, at this point, is a experimental feature and adding strong thread safety is significantly reducing the perf of the cache. As the feature matures, we can even go with a unbounded ConcurrentMap", "author": "mbhaskar", "createdAt": "2020-12-11T18:35:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0NDA1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEyMDczNg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r546120736", "bodyText": "Moved to a thread safe map for now without LRU.", "author": "mbhaskar", "createdAt": "2020-12-18T22:28:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0NDA1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEzNDAzOQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r546134039", "bodyText": "could you please remove this then?", "author": "moderakh", "createdAt": "2020-12-18T23:01:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTE0NDA1OA=="}], "type": "inlineReview"}, {"oid": "f92f176c50f90b946718634bca3ca12abd2829ce", "url": "https://github.com/Azure/azure-sdk-for-java/commit/f92f176c50f90b946718634bca3ca12abd2829ce", "message": "Removing LRUCache and switching to ConcurrentMap.", "committedDate": "2020-12-18T22:26:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjEzNTQzNg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17965#discussion_r546135436", "bodyText": "We should track this TODO for future. as for now we are not using a LRU cache.", "author": "moderakh", "createdAt": "2020-12-18T23:03:49Z", "path": "sdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/query/DocumentQueryExecutionContextFactory.java", "diffHunk": "@@ -78,49 +85,112 @@\n         }\n \n         Instant startTime = Instant.now();\n-        Mono<PartitionedQueryExecutionInfo> queryExecutionInfoMono =\n-            QueryPlanRetriever\n-                .getQueryPlanThroughGatewayAsync(diagnosticsClientContext, client, query, resourceLink);\n+        Mono<PartitionedQueryExecutionInfo> queryExecutionInfoMono;\n+        if (queryPlanCachingEnabled &&\n+                isScopedToSinglePartition(cosmosQueryRequestOptions) &&\n+                queryPlanCache.containsKey(query.getQueryText())) {\n+            Instant endTime = Instant.now(); // endTime for query plan diagnostics\n+            PartitionedQueryExecutionInfo partitionedQueryExecutionInfo = queryPlanCache.get(query.getQueryText());\n+            if (partitionedQueryExecutionInfo != null) {\n+                return getTargetRangesFromQueryPlan(cosmosQueryRequestOptions, collection, queryExecutionContext,\n+                                                    partitionedQueryExecutionInfo, startTime, endTime);\n+            }\n+        }\n+\n+        queryExecutionInfoMono = QueryPlanRetriever\n+                                     .getQueryPlanThroughGatewayAsync(diagnosticsClientContext, client, query,\n+                                                                      resourceLink);\n \n         return queryExecutionInfoMono.flatMap(\n             partitionedQueryExecutionInfo -> {\n \n                 Instant endTime = Instant.now();\n-                QueryInfo queryInfo =\n-                    partitionedQueryExecutionInfo.getQueryInfo();\n-                queryInfo.setQueryPlanDiagnosticsContext(new QueryInfo.QueryPlanDiagnosticsContext(startTime, endTime));\n-\n-                List<Range<String>> queryRanges =\n-                    partitionedQueryExecutionInfo.getQueryRanges();\n-\n-                if (cosmosQueryRequestOptions != null\n-                    && cosmosQueryRequestOptions.getPartitionKey() != null\n-                    && cosmosQueryRequestOptions.getPartitionKey() != PartitionKey.NONE) {\n-                    PartitionKeyInternal internalPartitionKey =\n-                        BridgeInternal.getPartitionKeyInternal(cosmosQueryRequestOptions.getPartitionKey());\n-                    Range<String> range = Range\n-                        .getPointRange(internalPartitionKey\n-                            .getEffectivePartitionKeyString(internalPartitionKey, collection.getPartitionKey()));\n-                    queryRanges = Collections.singletonList(range);\n+\n+                if (queryPlanCachingEnabled) {\n+                    tryCacheQueryPlan(query, partitionedQueryExecutionInfo, queryPlanCache);\n                 }\n-                return\n-                    queryExecutionContext.getTargetPartitionKeyRanges(collection.getResourceId(), queryRanges)\n-                    .map(pkRanges -> Pair.of(\n-                        pkRanges,\n-                        partitionedQueryExecutionInfo.getQueryInfo()));\n+\n+                return getTargetRangesFromQueryPlan(cosmosQueryRequestOptions, collection, queryExecutionContext,\n+                                                    partitionedQueryExecutionInfo, startTime, endTime);\n             });\n     }\n \n+    private static <T extends Resource> Mono<Pair<List<PartitionKeyRange>, QueryInfo>> getTargetRangesFromQueryPlan(\n+        CosmosQueryRequestOptions cosmosQueryRequestOptions, DocumentCollection collection,\n+        DefaultDocumentQueryExecutionContext<T> queryExecutionContext,\n+        PartitionedQueryExecutionInfo partitionedQueryExecutionInfo, Instant planFetchStartTime,\n+        Instant planFetchEndTime) {\n+        QueryInfo queryInfo =\n+            partitionedQueryExecutionInfo.getQueryInfo();\n+        queryInfo.setQueryPlanDiagnosticsContext(new QueryInfo.QueryPlanDiagnosticsContext(planFetchStartTime,\n+                                                                                           planFetchEndTime));\n+        List<Range<String>> queryRanges =\n+            partitionedQueryExecutionInfo.getQueryRanges();\n+\n+        if (isScopedToSinglePartition(cosmosQueryRequestOptions)) {\n+            PartitionKeyInternal internalPartitionKey =\n+                BridgeInternal.getPartitionKeyInternal(cosmosQueryRequestOptions.getPartitionKey());\n+            Range<String> range = Range\n+                                      .getPointRange(internalPartitionKey\n+                                                         .getEffectivePartitionKeyString(internalPartitionKey,\n+                                                                                         collection\n+                                                                                             .getPartitionKey()));\n+            queryRanges = Collections.singletonList(range);\n+        }\n+        return\n+            queryExecutionContext.getTargetPartitionKeyRanges(collection.getResourceId(), queryRanges)\n+                .map(pkRanges -> Pair.of(\n+                    pkRanges,\n+                    partitionedQueryExecutionInfo.getQueryInfo()));\n+    }\n+\n+    private static void tryCacheQueryPlan(\n+        SqlQuerySpec query,\n+        PartitionedQueryExecutionInfo partitionedQueryExecutionInfo,\n+        ConcurrentMap<String, PartitionedQueryExecutionInfo> queryPlanCache) {\n+        QueryInfo queryInfo = partitionedQueryExecutionInfo.getQueryInfo();\n+        if (canCacheQuery(queryInfo) && !queryPlanCache.containsKey(query.getQueryText())) {\n+            if (queryPlanCache.size() > MAX_CACHE_SIZE) {\n+                // Clearing query plan cache if size is above max size. This can be optimized in future by using\n+                // a threadsafe LRU cache\n+                queryPlanCache.clear();", "originalCommit": "f92f176c50f90b946718634bca3ca12abd2829ce", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "923f5541a2f82915f2920277eb76a42bc160cdd1", "url": "https://github.com/Azure/azure-sdk-for-java/commit/923f5541a2f82915f2920277eb76a42bc160cdd1", "message": "Removed the public API to enable cache\nQueryplan caching can now be enabled using a environment paramater", "committedDate": "2021-01-08T18:01:25Z", "type": "commit"}, {"oid": "38bf6178f3cf72d38251899dea4cd401db00a136", "url": "https://github.com/Azure/azure-sdk-for-java/commit/38bf6178f3cf72d38251899dea4cd401db00a136", "message": "Fix", "committedDate": "2021-01-08T18:57:18Z", "type": "commit"}, {"oid": "afdb42e00add177808dfa9377be04c2d2494ace3", "url": "https://github.com/Azure/azure-sdk-for-java/commit/afdb42e00add177808dfa9377be04c2d2494ace3", "message": "Removing public API related code", "committedDate": "2021-01-12T07:25:21Z", "type": "commit"}, {"oid": "62274b3cca41b6b8fb6ff68b131cc5732da5744a", "url": "https://github.com/Azure/azure-sdk-for-java/commit/62274b3cca41b6b8fb6ff68b131cc5732da5744a", "message": "Merge remote-tracking branch 'upstream/master' into query-optimization", "committedDate": "2021-01-12T07:33:37Z", "type": "commit"}, {"oid": "c3bf546c21ece64198ca9a80336792160ae75144", "url": "https://github.com/Azure/azure-sdk-for-java/commit/c3bf546c21ece64198ca9a80336792160ae75144", "message": "Merge remote-tracking branch 'upstream/master' into query-optimization\n\n# Conflicts:\n#\tsdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/BridgeInternal.java\n#\tsdk/cosmos/azure-cosmos/src/main/java/com/azure/cosmos/implementation/RxDocumentClientImpl.java", "committedDate": "2021-01-12T07:39:03Z", "type": "commit"}, {"oid": "93c816c7075bc2c6028286be97b77d2a31563354", "url": "https://github.com/Azure/azure-sdk-for-java/commit/93c816c7075bc2c6028286be97b77d2a31563354", "message": "clean up", "committedDate": "2021-01-12T07:50:57Z", "type": "commit"}, {"oid": "5ef7a7d46ac47f6693d0024063100455238c50d4", "url": "https://github.com/Azure/azure-sdk-for-java/commit/5ef7a7d46ac47f6693d0024063100455238c50d4", "message": "clean up", "committedDate": "2021-01-12T08:52:01Z", "type": "commit"}, {"oid": "5248c601143d17b8ecbf921bee01c6c7fe353485", "url": "https://github.com/Azure/azure-sdk-for-java/commit/5248c601143d17b8ecbf921bee01c6c7fe353485", "message": "cleanup", "committedDate": "2021-01-16T08:44:34Z", "type": "commit"}]}