{"pr_number": 17267, "pr_title": "[TA] Add analyze tasks feature support", "pr_createdAt": "2020-11-06T07:57:41Z", "pr_url": "https://github.com/Azure/azure-sdk-for-java/pull/17267", "timeline": [{"oid": "7b0e24c4d32390dd9c2eac900eab51fcf104559a", "url": "https://github.com/Azure/azure-sdk-for-java/commit/7b0e24c4d32390dd9c2eac900eab51fcf104559a", "message": "TA-Healthcare", "committedDate": "2020-11-05T19:04:00Z", "type": "commit"}, {"oid": "446bb428456b154a9cdabf289e717f70b8ff3abe", "url": "https://github.com/Azure/azure-sdk-for-java/commit/446bb428456b154a9cdabf289e717f70b8ff3abe", "message": "remove checkstyle supppresion", "committedDate": "2020-11-05T19:13:15Z", "type": "commit"}, {"oid": "5ac3e30ec450d074ab4ef8a9a23e31f9a50b1703", "url": "https://github.com/Azure/azure-sdk-for-java/commit/5ac3e30ec450d074ab4ef8a9a23e31f9a50b1703", "message": "regenerate swagger ater a new change merged in", "committedDate": "2020-11-05T19:42:24Z", "type": "commit"}, {"oid": "c03aa751db4ebf08f2f64251cc0832fc569ce4ba", "url": "https://github.com/Azure/azure-sdk-for-java/commit/c03aa751db4ebf08f2f64251cc0832fc569ce4ba", "message": "transfer to laptop", "committedDate": "2020-11-05T22:49:24Z", "type": "commit"}, {"oid": "968acb98bda24788fd1bcbbe172665d1743a1268", "url": "https://github.com/Azure/azure-sdk-for-java/commit/968acb98bda24788fd1bcbbe172665d1743a1268", "message": "cancellation is working now", "committedDate": "2020-11-06T00:20:45Z", "type": "commit"}, {"oid": "1b5dbc8f48620263b1afbee87ad4de4adb22245b", "url": "https://github.com/Azure/azure-sdk-for-java/commit/1b5dbc8f48620263b1afbee87ad4de4adb22245b", "message": "address mari's most feedbacks", "committedDate": "2020-11-06T03:37:11Z", "type": "commit"}, {"oid": "53e0d0e853a6233f613ad880281f3d5ff5732530", "url": "https://github.com/Azure/azure-sdk-for-java/commit/53e0d0e853a6233f613ad880281f3d5ff5732530", "message": "replace a wrong json file for async pagination test", "committedDate": "2020-11-06T03:57:19Z", "type": "commit"}, {"oid": "53654d67c99d34aa8ea0e4f0f7214691799bb4aa", "url": "https://github.com/Azure/azure-sdk-for-java/commit/53654d67c99d34aa8ea0e4f0f7214691799bb4aa", "message": "init analyze tasks", "committedDate": "2020-11-06T07:56:07Z", "type": "commit"}, {"oid": "8d7935025b25fc9199f11aeff615d0dd30480ea3", "url": "https://github.com/Azure/azure-sdk-for-java/commit/8d7935025b25fc9199f11aeff615d0dd30480ea3", "message": "removed xxxTaskState class and TaskStete", "committedDate": "2020-11-06T13:55:52Z", "type": "commit"}, {"oid": "5c7f4ce29ca0fbdf6478bcf350e53737ae7da51b", "url": "https://github.com/Azure/azure-sdk-for-java/commit/5c7f4ce29ca0fbdf6478bcf350e53737ae7da51b", "message": "add changelog", "committedDate": "2020-11-06T14:05:23Z", "type": "commit"}, {"oid": "8c57c6ce4f82a2c1778944ff8c871d9ba3eb68c0", "url": "https://github.com/Azure/azure-sdk-for-java/commit/8c57c6ce4f82a2c1778944ff8c871d9ba3eb68c0", "message": "resolve conflict and updates changes", "committedDate": "2020-11-06T17:57:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODk4NDEwNQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r518984105", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            - Added support for healthcare analysis feature, it is a long-running operation, and the cancellation supported. \n          \n          \n            \n            - Added support for analyze tasks feature, It analyzes multiple tasks, such as, entity recognition, PII entity recognition \n          \n          \n            \n            and key phrases extraction simultaneously in a list of document.\n          \n          \n            \n            - Added support for healthcare analysis feature. Tt is represented as a long-running operation. Cancellation supported. \n          \n          \n            \n            - Added support for analyze multiple tasks (such as, entity recognition, PII entity recognition \n          \n          \n            \n            and key phrases extraction) simultaneously in a list of document.\n          \n      \n    \n    \n  \n\nmaybe?", "author": "maririos", "createdAt": "2020-11-06T20:16:53Z", "path": "sdk/textanalytics/azure-ai-textanalytics/CHANGELOG.md", "diffHunk": "@@ -1,7 +1,9 @@\n # Release History\n ## 5.1.0-beta.3 (Unreleased)\n **New features**\n-- Added support for Healthcare analysis, it is a long-running operation, and the cancellation supported. \n+- Added support for healthcare analysis feature, it is a long-running operation, and the cancellation supported. \n+- Added support for analyze tasks feature, It analyzes multiple tasks, such as, entity recognition, PII entity recognition \n+and key phrases extraction simultaneously in a list of document.", "originalCommit": "8c57c6ce4f82a2c1778944ff8c871d9ba3eb68c0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "37c3bf13bac035908e1da6f876575cec7ce9f622", "url": "https://github.com/Azure/azure-sdk-for-java/commit/37c3bf13bac035908e1da6f876575cec7ce9f622", "message": "resolved conflict and add more tests", "committedDate": "2020-11-11T08:16:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTUzOTAyOQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r521539029", "bodyText": "Seeing the same jobID here too - #17234 (comment)", "author": "samvaity", "createdAt": "2020-11-11T17:56:46Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeHealthcareAsyncClient.java", "diffHunk": "@@ -132,21 +137,22 @@\n                 (activationResponse, pollingContext) ->\n                     monoError(logger, new RuntimeException(\"Use the `beginCancelHealthcareJob` to cancel the job\")),\n                 fetchingOperationIterable(resultId -> Mono.just(new PagedIterable<>(getHealthcareFluxPage(resultId,\n-                    finalIncludeStatistics == null ? false : finalIncludeStatistics, context))))\n+                    finalTop, finalSkip, finalIncludeStatistics, context))))\n             );\n         } catch (RuntimeException ex) {\n             return PollerFlux.error(ex);\n         }\n     }\n \n-    PagedFlux<HealthcareTaskResult> getHealthcareFluxPage(UUID jobID, boolean showStats, Context context) {\n+    PagedFlux<HealthcareTaskResult> getHealthcareFluxPage(UUID jobID, Integer top, Integer skip, Boolean showStats,\n+        Context context) {\n         return new PagedFlux<>(\n-            () -> getPage(null, jobID, showStats, context),\n-            continuationToken -> getPage(continuationToken, jobID, showStats, context));\n+            () -> getPage(null, jobID, top, skip, showStats, context),", "originalCommit": "37c3bf13bac035908e1da6f876575cec7ce9f622", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjY1NjkzMA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r522656930", "bodyText": "Leave the comment over there.", "author": "mssfang", "createdAt": "2020-11-13T05:16:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTUzOTAyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTUzOTM4Mg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r521539382", "bodyText": "Why was this changed to non-primitive?", "author": "samvaity", "createdAt": "2020-11-11T17:57:14Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeHealthcareAsyncClient.java", "diffHunk": "@@ -132,21 +137,22 @@\n                 (activationResponse, pollingContext) ->\n                     monoError(logger, new RuntimeException(\"Use the `beginCancelHealthcareJob` to cancel the job\")),\n                 fetchingOperationIterable(resultId -> Mono.just(new PagedIterable<>(getHealthcareFluxPage(resultId,\n-                    finalIncludeStatistics == null ? false : finalIncludeStatistics, context))))\n+                    finalTop, finalSkip, finalIncludeStatistics, context))))\n             );\n         } catch (RuntimeException ex) {\n             return PollerFlux.error(ex);\n         }\n     }\n \n-    PagedFlux<HealthcareTaskResult> getHealthcareFluxPage(UUID jobID, boolean showStats, Context context) {\n+    PagedFlux<HealthcareTaskResult> getHealthcareFluxPage(UUID jobID, Integer top, Integer skip, Boolean showStats,\n+        Context context) {\n         return new PagedFlux<>(\n-            () -> getPage(null, jobID, showStats, context),\n-            continuationToken -> getPage(continuationToken, jobID, showStats, context));\n+            () -> getPage(null, jobID, top, skip, showStats, context),\n+            continuationToken -> getPage(continuationToken, jobID, top, skip, showStats, context));\n     }\n \n-    Mono<PagedResponse<HealthcareTaskResult>> getPage(String continuationToken, UUID jobID,\n-        boolean showStats, Context context) {\n+    Mono<PagedResponse<HealthcareTaskResult>> getPage(String continuationToken, UUID jobID, Integer top, Integer skip,\n+        Boolean showStats, Context context) {", "originalCommit": "37c3bf13bac035908e1da6f876575cec7ce9f622", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjY1NjY2Mg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r522656662", "bodyText": "It should be Object Boolean instead of primitive boolean, leave the default value to serivce.  service endpoint takes Boolean.", "author": "mssfang", "createdAt": "2020-11-13T05:16:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTUzOTM4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwNjE1OQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525606159", "bodyText": "I don't think from an API design it would make sense to have a potential null positional argument. If this argument could be null/ignored why not have it in the options then?\nI think I have seen Java API's wanting to expose primitives whenever possible.\n@JonathanGiles Do you know if we have a strong opinion on  this?", "author": "samvaity", "createdAt": "2020-11-18T00:02:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTUzOTM4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTc5NzQwNQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525797405", "bodyText": "The explored parameter is primitive boolean. If user has option as null, we are using the null for the default value.\nhttps://github.com/Azure/azure-sdk-for-java/pull/17267/files#diff-5ec2c21f81551de87633be791778c4b0897048d1148892267fa4bf442c44db38R123", "author": "mssfang", "createdAt": "2020-11-18T04:37:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTUzOTM4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU0MDMxNA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r521540314", "bodyText": "Is this still a service bug?", "author": "samvaity", "createdAt": "2020-11-11T17:58:51Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/test/java/com/azure/ai/textanalytics/TestUtils.java", "diffHunk": "@@ -667,82 +685,165 @@ static RecognizeHealthcareEntitiesResult getRecognizeHealthcareEntitiesResult2()\n         return healthcareEntitiesResult;\n     }\n \n-    static AnalyzeTasksResult getExpectedAnalyzeTasksResult() {\n+    /**\n+     * RecognizeEntitiesResultCollection result for\n+     * \"I had a wonderful trip to Seattle last week.\"\n+     * \"Microsoft employee with ssn 859-98-0987 is using our awesome API's.\"\n+     */\n+    static RecognizeEntitiesResultCollection getRecognizeEntitiesResultCollection() {\n         // Categorized Entities\n-        IterableStream<CategorizedEntity> categorizedEntityList1 = new IterableStream<>(getCategorizedEntitiesList1());\n+        // TODO: [Service-bugs] after service fixes the null statistics, then use the values and turn on includeStatics.\n         //TextDocumentStatistics textDocumentStatistics1 = new TextDocumentStatistics(44, 1);\n-        RecognizeEntitiesResult recognizeEntitiesResult1 = new RecognizeEntitiesResult(\"0\", null,\n-            null, new CategorizedEntityCollection(categorizedEntityList1, null));\n-        IterableStream<CategorizedEntity> categorizedEntityList2 = new IterableStream<>(\n-            asList(\n-                new CategorizedEntity(\"Microsoft\", EntityCategory.ORGANIZATION, null, 0.0, 0),\n-                new CategorizedEntity(\"employee\", EntityCategory.PERSON_TYPE, null, 0.0, 10),\n-                new CategorizedEntity(\"859\", EntityCategory.QUANTITY, \"Number\", 0.0, 28),\n-                new CategorizedEntity(\"98\", EntityCategory.QUANTITY, \"Number\", 0.0, 32),\n-                new CategorizedEntity(\"0987\", EntityCategory.QUANTITY, \"Number\", 0.0, 35),\n-                new CategorizedEntity(\"API\", EntityCategory.SKILL, null, 0.0, 61)\n-            )\n-        );\n         //TextDocumentStatistics textDocumentStatistics2 = new TextDocumentStatistics(44, 1);\n-        RecognizeEntitiesResult recognizeEntitiesResult2 = new RecognizeEntitiesResult(\"1\", null,\n-            null, new CategorizedEntityCollection(categorizedEntityList2, null));\n-\n-        RecognizeEntitiesResultCollection recognizeEntitiesResults = new RecognizeEntitiesResultCollection(\n-            asList(recognizeEntitiesResult1, recognizeEntitiesResult2),\n-            \"2020-04-01\", null\n+        return new RecognizeEntitiesResultCollection(\n+            asList(new RecognizeEntitiesResult(\"0\", null, null,\n+                    new CategorizedEntityCollection(new IterableStream<>(getCategorizedEntitiesList1()), null)),\n+                new RecognizeEntitiesResult(\"1\", null, null,\n+                    new CategorizedEntityCollection(new IterableStream<>(getCategorizedEntitiesForPiiInput()), null))\n+            ), \"2020-04-01\", null);\n             //new TextDocumentBatchStatistics(2, 2, 0, 2)\n-        );\n+    }\n \n+    /**\n+     * RecognizePiiEntitiesResultCollection result for\n+     * \"I had a wonderful trip to Seattle last week.\"\n+     * \"Microsoft employee with ssn 859-98-0987 is using our awesome API's.\"\n+     */\n+    static RecognizePiiEntitiesResultCollection getRecognizePiiEntitiesResultCollection() {\n         // PII\n-        PiiEntityCollection piiEntityCollection1 = new PiiEntityCollection(new IterableStream<>(new ArrayList<>()),\n-            \"I had a wonderful trip to Seattle last week.\", null);\n-        PiiEntityCollection piiEntityCollection2 = new PiiEntityCollection(new IterableStream<>(getPiiEntitiesList1()),\n-            \"********* employee with ssn *********** is using our awesome API's.\", null);\n+        // TODO: [Service-bugs] after service fixes the null statistics, then use the values and turn on includeStatics.", "originalCommit": "37c3bf13bac035908e1da6f876575cec7ce9f622", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU0MDc1MQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r521540751", "bodyText": "Consider adding service bugs to issues for better follow up.", "author": "samvaity", "createdAt": "2020-11-11T17:59:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU0MDMxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjY0OTY3MQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r522649671", "bodyText": "Yes, it is still a bugs. #17564", "author": "mssfang", "createdAt": "2020-11-13T05:07:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU0MDMxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU0NTM0Nw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r521545347", "bodyText": "Is this still true?", "author": "samvaity", "createdAt": "2020-11-11T18:07:41Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/test/java/com/azure/ai/textanalytics/TextAnalyticsClientTestBase.java", "diffHunk": "@@ -741,7 +778,8 @@ static void validatePiiEntitiesResultCollection(boolean showStatistics,\n         validateTextAnalyticsResult(showStatistics, expected, actual, (expectedItem, actualItem) -> {\n             final PiiEntityCollection expectedPiiEntityCollection = expectedItem.getEntities();\n             final PiiEntityCollection actualPiiEntityCollection = actualItem.getEntities();\n-            assertEquals(expectedPiiEntityCollection.getRedactedText(), actualPiiEntityCollection.getRedactedText());\n+            //TODO: redacted text is empty, which is wrong", "originalCommit": "37c3bf13bac035908e1da6f876575cec7ce9f622", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjcwNTk4NA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r522705984", "bodyText": "Noop. They already corrected now", "author": "mssfang", "createdAt": "2020-11-13T07:04:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU0NTM0Nw=="}], "type": "inlineReview"}, {"oid": "febe0be40b3f9e6888855474c84ed4ea82caa470", "url": "https://github.com/Azure/azure-sdk-for-java/commit/febe0be40b3f9e6888855474c84ed4ea82caa470", "message": "regenerate code base on swagger 5ef5a597b3f2342bfd254ed79b97b2fe160e50a1", "committedDate": "2020-11-13T04:12:25Z", "type": "commit"}, {"oid": "9a250604670607a86842206b1b3b410a0d3053c8", "url": "https://github.com/Azure/azure-sdk-for-java/commit/9a250604670607a86842206b1b3b410a0d3053c8", "message": "address feedbacks", "committedDate": "2020-11-13T07:50:11Z", "type": "commit"}, {"oid": "ee4ae09a5400778314324eb2edcfa613e394fd3e", "url": "https://github.com/Azure/azure-sdk-for-java/commit/ee4ae09a5400778314324eb2edcfa613e394fd3e", "message": "improve PLAYBACK test speed", "committedDate": "2020-11-13T17:35:42Z", "type": "commit"}, {"oid": "cd58ae8ce2c449318bc4cb66638fe9cdf4cfb713", "url": "https://github.com/Azure/azure-sdk-for-java/commit/cd58ae8ce2c449318bc4cb66638fe9cdf4cfb713", "message": "checekstyle issue", "committedDate": "2020-11-13T22:40:17Z", "type": "commit"}, {"oid": "d1c02b5396f091de61c641478522ad2fe28c96c2", "url": "https://github.com/Azure/azure-sdk-for-java/commit/d1c02b5396f091de61c641478522ad2fe28c96c2", "message": "update Analyze API endpoint", "committedDate": "2020-11-17T23:13:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU4OTUxMA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525589510", "bodyText": "by default, options.getPollInterval() ==> DEFAULT_POLL_INTERVAL, so if options is null, we use the defaultValue, if options is not null we use custom polling interval if user has set it, otherwise, use the DEFAULT_POLL_INTERVAL.", "author": "mssfang", "createdAt": "2020-11-17T23:18:13Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeHealthcareAsyncClient.java", "diffHunk": "@@ -74,12 +75,17 @@\n         try {\n             inputDocumentsValidation(documents);\n             String modelVersion = null;\n+            Duration pollInterval = DEFAULT_POLL_INTERVAL;\n             if (options != null) {\n                 modelVersion = options.getModelVersion();\n+                pollInterval = options.getPollInterval();", "originalCommit": "d1c02b5396f091de61c641478522ad2fe28c96c2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMjgyMg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525602822", "bodyText": "This could be better done at the central place at options level  like here - https://github.com/Azure/azure-sdk-for-java/blob/master/sdk/formrecognizer/azure-ai-formrecognizer/src/main/java/com/azure/ai/formrecognizer/models/RecognizeContentOptions.java#L60", "author": "samvaity", "createdAt": "2020-11-17T23:53:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU4OTUxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY5NjI3NQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525696275", "bodyText": "It is already there: https://github.com/Azure/azure-sdk-for-java/pull/17267/files#diff-659663d93baf5cac89b0841764fb0a0999f5461346bce5cc25fa1f8e4e0a2137R136\nThis check has a different purpose.  If 'options' is null, we are using DEFAULT_POLL_INTERVAL,  otherwise, we use what user defined custom poll interval. If user does not set any value, the pollInterval is still  DEFAULT_POLL_INTERVAL", "author": "mssfang", "createdAt": "2020-11-18T03:03:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU4OTUxMA=="}], "type": "inlineReview"}, {"oid": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "url": "https://github.com/Azure/azure-sdk-for-java/commit/c94420c6346fcdb35a10f7bc1c0358cb58b72228", "message": "add issue link to TODO lists", "committedDate": "2020-11-17T23:37:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMjE3NA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525602174", "bodyText": "We should keep this consistent https://github.com/Azure/azure-sdk-for-java/pull/17267/files#diff-7fbca8ee7335dc54eff4896d71e776956633f83aa352534da69dca097fefe74fR9", "author": "samvaity", "createdAt": "2020-11-17T23:51:57Z", "path": "sdk/textanalytics/azure-ai-textanalytics/CHANGELOG.md", "diffHunk": "@@ -1,7 +1,9 @@\n # Release History\n ## 5.1.0-beta.3 (Unreleased)\n **New features**", "originalCommit": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMzAzNw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525603037", "bodyText": "nit: Do you need this comment?", "author": "samvaity", "createdAt": "2020-11-17T23:54:14Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeHealthcareAsyncClient.java", "diffHunk": "@@ -74,12 +75,17 @@\n         try {\n             inputDocumentsValidation(documents);\n             String modelVersion = null;\n+            Duration pollInterval = DEFAULT_POLL_INTERVAL;\n             if (options != null) {\n                 modelVersion = options.getModelVersion();\n+                pollInterval = options.getPollInterval();\n             }\n+            // the variable used in the lambda function has to be 'final' or 'effective final'.", "originalCommit": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY3NzU2MA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525677560", "bodyText": "It can be removed.", "author": "mssfang", "createdAt": "2020-11-18T02:43:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMzAzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwNzIwOA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525607208", "bodyText": "nit: Consider putting into a function instead of the redundant checks?", "author": "samvaity", "createdAt": "2020-11-18T00:05:49Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeHealthcareAsyncClient.java", "diffHunk": "@@ -109,12 +115,16 @@\n         try {\n             inputDocumentsValidation(documents);\n             String modelVersion = null;\n+            Duration pollInterval = DEFAULT_POLL_INTERVAL;\n             if (options != null) {\n                 modelVersion = options.getModelVersion();\n+                pollInterval = options.getPollInterval();\n             }\n             final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n             return new PollerFlux<>(\n-                DEFAULT_POLL_DURATION,\n+                pollInterval,", "originalCommit": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwNzg4Mw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525607883", "bodyText": "Is there a way to catch the potential exception that could be caused by the creation of UUID from string?", "author": "samvaity", "createdAt": "2020-11-18T00:07:50Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeHealthcareAsyncClient.java", "diffHunk": "@@ -196,12 +208,13 @@\n             null);\n     }\n \n-    PollerFlux<TextAnalyticsOperationResult, Void> beginCancelAnalyzeHealthcare(UUID jobId, Context context) {\n+    PollerFlux<TextAnalyticsOperationResult, Void> beginCancelAnalyzeHealthcare(String healthTaskId,\n+        RecognizeHealthcareEntityOptions options, Context context) {\n         try {\n-            Objects.requireNonNull(jobId, \"'jobId' is required and cannot be null.\");\n+            Objects.requireNonNull(healthTaskId, \"'healthTaskId' is required and cannot be null.\");\n             return new PollerFlux<>(\n-                DEFAULT_POLL_DURATION,\n-                activationOperation(service.cancelHealthJobWithResponseAsync(jobId,\n+                options == null ? DEFAULT_POLL_INTERVAL : options.getPollInterval(),\n+                activationOperation(service.cancelHealthJobWithResponseAsync(UUID.fromString(healthTaskId),", "originalCommit": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTc5ODcwMw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525798703", "bodyText": "we have try-catch statement around the code section.", "author": "mssfang", "createdAt": "2020-11-18T04:38:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwNzg4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwODI1OA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525608258", "bodyText": "Similar comments as health care async client.", "author": "samvaity", "createdAt": "2020-11-18T00:09:07Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeTasksAsyncClient.java", "diffHunk": "@@ -0,0 +1,390 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics;\n+\n+import com.azure.ai.textanalytics.implementation.AnalyzeTasksResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsClientImpl;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsErrorInformationPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsExceptionPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsOperationResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.Utility;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeJobState;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTask;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.JobManifestTasks;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTask;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.MultiLanguageBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.PiiTask;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParametersDomain;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasks;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionPiiTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksKeyPhraseExtractionTasksItem;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksOptions;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksResult;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorCode;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorInformation;\n+import com.azure.ai.textanalytics.models.TextAnalyticsException;\n+import com.azure.ai.textanalytics.models.TextAnalyticsOperationResult;\n+import com.azure.ai.textanalytics.models.TextDocumentInput;\n+import com.azure.ai.textanalytics.util.ExtractKeyPhrasesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizeEntitiesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizePiiEntitiesResultCollection;\n+import com.azure.core.http.rest.PagedFlux;\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.core.http.rest.PagedResponse;\n+import com.azure.core.http.rest.PagedResponseBase;\n+import com.azure.core.http.rest.Response;\n+import com.azure.core.util.Context;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.core.util.logging.ClientLogger;\n+import com.azure.core.util.polling.LongRunningOperationStatus;\n+import com.azure.core.util.polling.PollResponse;\n+import com.azure.core.util.polling.PollerFlux;\n+import com.azure.core.util.polling.PollingContext;\n+import reactor.core.publisher.Mono;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static com.azure.ai.textanalytics.TextAnalyticsAsyncClient.COGNITIVE_TRACING_NAMESPACE_VALUE;\n+import static com.azure.ai.textanalytics.implementation.Utility.DEFAULT_POLL_INTERVAL;\n+import static com.azure.ai.textanalytics.implementation.Utility.inputDocumentsValidation;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseModelId;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseNextLink;\n+import static com.azure.ai.textanalytics.implementation.Utility.toBatchStatistics;\n+import static com.azure.ai.textanalytics.implementation.Utility.toExtractKeyPhrasesResultCollection;\n+import static com.azure.ai.textanalytics.implementation.Utility.toJobState;\n+import static com.azure.ai.textanalytics.implementation.Utility.toMultiLanguageInput;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizeEntitiesResultCollectionResponse;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizePiiEntitiesResultCollection;\n+import static com.azure.core.util.FluxUtil.monoError;\n+import static com.azure.core.util.tracing.Tracer.AZ_TRACING_NAMESPACE_KEY;\n+\n+class AnalyzeTasksAsyncClient {\n+    private final ClientLogger logger = new ClientLogger(AnalyzeTasksAsyncClient.class);\n+    private final TextAnalyticsClientImpl service;\n+\n+    AnalyzeTasksAsyncClient(TextAnalyticsClientImpl service) {\n+        this.service = service;\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedFlux<AnalyzeTasksResult>> beginAnalyze(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)))\n+                .setTasks(getJobManifestTasks(options));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(", "originalCommit": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwODczMA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525608730", "bodyText": "Can this check happen before the function call, one less code jump?", "author": "samvaity", "createdAt": "2020-11-18T00:10:16Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeTasksAsyncClient.java", "diffHunk": "@@ -0,0 +1,390 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics;\n+\n+import com.azure.ai.textanalytics.implementation.AnalyzeTasksResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsClientImpl;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsErrorInformationPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsExceptionPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsOperationResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.Utility;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeJobState;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTask;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.JobManifestTasks;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTask;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.MultiLanguageBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.PiiTask;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParametersDomain;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasks;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionPiiTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksKeyPhraseExtractionTasksItem;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksOptions;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksResult;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorCode;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorInformation;\n+import com.azure.ai.textanalytics.models.TextAnalyticsException;\n+import com.azure.ai.textanalytics.models.TextAnalyticsOperationResult;\n+import com.azure.ai.textanalytics.models.TextDocumentInput;\n+import com.azure.ai.textanalytics.util.ExtractKeyPhrasesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizeEntitiesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizePiiEntitiesResultCollection;\n+import com.azure.core.http.rest.PagedFlux;\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.core.http.rest.PagedResponse;\n+import com.azure.core.http.rest.PagedResponseBase;\n+import com.azure.core.http.rest.Response;\n+import com.azure.core.util.Context;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.core.util.logging.ClientLogger;\n+import com.azure.core.util.polling.LongRunningOperationStatus;\n+import com.azure.core.util.polling.PollResponse;\n+import com.azure.core.util.polling.PollerFlux;\n+import com.azure.core.util.polling.PollingContext;\n+import reactor.core.publisher.Mono;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static com.azure.ai.textanalytics.TextAnalyticsAsyncClient.COGNITIVE_TRACING_NAMESPACE_VALUE;\n+import static com.azure.ai.textanalytics.implementation.Utility.DEFAULT_POLL_INTERVAL;\n+import static com.azure.ai.textanalytics.implementation.Utility.inputDocumentsValidation;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseModelId;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseNextLink;\n+import static com.azure.ai.textanalytics.implementation.Utility.toBatchStatistics;\n+import static com.azure.ai.textanalytics.implementation.Utility.toExtractKeyPhrasesResultCollection;\n+import static com.azure.ai.textanalytics.implementation.Utility.toJobState;\n+import static com.azure.ai.textanalytics.implementation.Utility.toMultiLanguageInput;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizeEntitiesResultCollectionResponse;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizePiiEntitiesResultCollection;\n+import static com.azure.core.util.FluxUtil.monoError;\n+import static com.azure.core.util.tracing.Tracer.AZ_TRACING_NAMESPACE_KEY;\n+\n+class AnalyzeTasksAsyncClient {\n+    private final ClientLogger logger = new ClientLogger(AnalyzeTasksAsyncClient.class);\n+    private final TextAnalyticsClientImpl service;\n+\n+    AnalyzeTasksAsyncClient(TextAnalyticsClientImpl service) {\n+        this.service = service;\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedFlux<AnalyzeTasksResult>> beginAnalyze(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)))\n+                .setTasks(getJobManifestTasks(options));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(\n+                pollingInterval,\n+                activationOperation(\n+                    service.analyzeWithResponseAsync(analyzeBatchInput,\n+                        context.addData(AZ_TRACING_NAMESPACE_KEY, COGNITIVE_TRACING_NAMESPACE_VALUE))\n+                        .map(analyzeResponse -> {\n+                            final TextAnalyticsOperationResult textAnalyticsOperationResult =\n+                                new TextAnalyticsOperationResult();\n+                            TextAnalyticsOperationResultPropertiesHelper.setResultId(textAnalyticsOperationResult,\n+                                parseModelId(analyzeResponse.getDeserializedHeaders().getOperationLocation()));\n+                            return textAnalyticsOperationResult;\n+                        })),\n+                pollingOperation(resultID -> service.analyzeStatusWithResponseAsync(resultID,\n+                    finalIncludeStatistics, finalTop, finalSkip, context)),\n+                (activationResponse, pollingContext) -> null,\n+                fetchingOperation(resultId -> Mono.just(getAnalyzeOperationFluxPage(\n+                    resultId, finalTop, finalSkip, finalIncludeStatistics, context)))\n+            );\n+        } catch (RuntimeException ex) {\n+            return PollerFlux.error(ex);\n+        }\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedIterable<AnalyzeTasksResult>> beginAnalyzeIterable(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)))\n+                .setTasks(getJobManifestTasks(options));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(\n+                pollingInterval,\n+                activationOperation(\n+                    service.analyzeWithResponseAsync(analyzeBatchInput,\n+                        context.addData(AZ_TRACING_NAMESPACE_KEY, COGNITIVE_TRACING_NAMESPACE_VALUE))\n+                        .map(analyzeResponse -> {\n+                            final TextAnalyticsOperationResult textAnalyticsOperationResult =\n+                                new TextAnalyticsOperationResult();\n+                            TextAnalyticsOperationResultPropertiesHelper.setResultId(textAnalyticsOperationResult,\n+                                parseModelId(analyzeResponse.getDeserializedHeaders().getOperationLocation()));\n+                            return textAnalyticsOperationResult;\n+                        })),\n+                pollingOperation(resultID -> service.analyzeStatusWithResponseAsync(resultID,\n+                    options == null ? null : options.isIncludeStatistics(), null, null, context)),\n+                (activationResponse, pollingContext) -> null,\n+                fetchingOperationIterable(resultId -> Mono.just(new PagedIterable<>(getAnalyzeOperationFluxPage(\n+                    resultId, finalTop, finalSkip, finalIncludeStatistics, context))))\n+            );\n+        } catch (RuntimeException ex) {\n+            return PollerFlux.error(ex);\n+        }\n+    }\n+\n+    private JobManifestTasks getJobManifestTasks(AnalyzeTasksOptions options) {\n+        if (options == null) {\n+            return null;\n+        }", "originalCommit": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwOTE1NA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525609154", "bodyText": "Do we need a TODO here?", "author": "samvaity", "createdAt": "2020-11-18T00:11:23Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeTasksAsyncClient.java", "diffHunk": "@@ -0,0 +1,390 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics;\n+\n+import com.azure.ai.textanalytics.implementation.AnalyzeTasksResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsClientImpl;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsErrorInformationPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsExceptionPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsOperationResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.Utility;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeJobState;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTask;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.JobManifestTasks;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTask;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.MultiLanguageBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.PiiTask;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParametersDomain;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasks;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionPiiTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksKeyPhraseExtractionTasksItem;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksOptions;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksResult;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorCode;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorInformation;\n+import com.azure.ai.textanalytics.models.TextAnalyticsException;\n+import com.azure.ai.textanalytics.models.TextAnalyticsOperationResult;\n+import com.azure.ai.textanalytics.models.TextDocumentInput;\n+import com.azure.ai.textanalytics.util.ExtractKeyPhrasesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizeEntitiesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizePiiEntitiesResultCollection;\n+import com.azure.core.http.rest.PagedFlux;\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.core.http.rest.PagedResponse;\n+import com.azure.core.http.rest.PagedResponseBase;\n+import com.azure.core.http.rest.Response;\n+import com.azure.core.util.Context;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.core.util.logging.ClientLogger;\n+import com.azure.core.util.polling.LongRunningOperationStatus;\n+import com.azure.core.util.polling.PollResponse;\n+import com.azure.core.util.polling.PollerFlux;\n+import com.azure.core.util.polling.PollingContext;\n+import reactor.core.publisher.Mono;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static com.azure.ai.textanalytics.TextAnalyticsAsyncClient.COGNITIVE_TRACING_NAMESPACE_VALUE;\n+import static com.azure.ai.textanalytics.implementation.Utility.DEFAULT_POLL_INTERVAL;\n+import static com.azure.ai.textanalytics.implementation.Utility.inputDocumentsValidation;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseModelId;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseNextLink;\n+import static com.azure.ai.textanalytics.implementation.Utility.toBatchStatistics;\n+import static com.azure.ai.textanalytics.implementation.Utility.toExtractKeyPhrasesResultCollection;\n+import static com.azure.ai.textanalytics.implementation.Utility.toJobState;\n+import static com.azure.ai.textanalytics.implementation.Utility.toMultiLanguageInput;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizeEntitiesResultCollectionResponse;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizePiiEntitiesResultCollection;\n+import static com.azure.core.util.FluxUtil.monoError;\n+import static com.azure.core.util.tracing.Tracer.AZ_TRACING_NAMESPACE_KEY;\n+\n+class AnalyzeTasksAsyncClient {\n+    private final ClientLogger logger = new ClientLogger(AnalyzeTasksAsyncClient.class);\n+    private final TextAnalyticsClientImpl service;\n+\n+    AnalyzeTasksAsyncClient(TextAnalyticsClientImpl service) {\n+        this.service = service;\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedFlux<AnalyzeTasksResult>> beginAnalyze(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)))\n+                .setTasks(getJobManifestTasks(options));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(\n+                pollingInterval,\n+                activationOperation(\n+                    service.analyzeWithResponseAsync(analyzeBatchInput,\n+                        context.addData(AZ_TRACING_NAMESPACE_KEY, COGNITIVE_TRACING_NAMESPACE_VALUE))\n+                        .map(analyzeResponse -> {\n+                            final TextAnalyticsOperationResult textAnalyticsOperationResult =\n+                                new TextAnalyticsOperationResult();\n+                            TextAnalyticsOperationResultPropertiesHelper.setResultId(textAnalyticsOperationResult,\n+                                parseModelId(analyzeResponse.getDeserializedHeaders().getOperationLocation()));\n+                            return textAnalyticsOperationResult;\n+                        })),\n+                pollingOperation(resultID -> service.analyzeStatusWithResponseAsync(resultID,\n+                    finalIncludeStatistics, finalTop, finalSkip, context)),\n+                (activationResponse, pollingContext) -> null,\n+                fetchingOperation(resultId -> Mono.just(getAnalyzeOperationFluxPage(\n+                    resultId, finalTop, finalSkip, finalIncludeStatistics, context)))\n+            );\n+        } catch (RuntimeException ex) {\n+            return PollerFlux.error(ex);\n+        }\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedIterable<AnalyzeTasksResult>> beginAnalyzeIterable(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)))\n+                .setTasks(getJobManifestTasks(options));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(\n+                pollingInterval,\n+                activationOperation(\n+                    service.analyzeWithResponseAsync(analyzeBatchInput,\n+                        context.addData(AZ_TRACING_NAMESPACE_KEY, COGNITIVE_TRACING_NAMESPACE_VALUE))\n+                        .map(analyzeResponse -> {\n+                            final TextAnalyticsOperationResult textAnalyticsOperationResult =\n+                                new TextAnalyticsOperationResult();\n+                            TextAnalyticsOperationResultPropertiesHelper.setResultId(textAnalyticsOperationResult,\n+                                parseModelId(analyzeResponse.getDeserializedHeaders().getOperationLocation()));\n+                            return textAnalyticsOperationResult;\n+                        })),\n+                pollingOperation(resultID -> service.analyzeStatusWithResponseAsync(resultID,\n+                    options == null ? null : options.isIncludeStatistics(), null, null, context)),\n+                (activationResponse, pollingContext) -> null,\n+                fetchingOperationIterable(resultId -> Mono.just(new PagedIterable<>(getAnalyzeOperationFluxPage(\n+                    resultId, finalTop, finalSkip, finalIncludeStatistics, context))))\n+            );\n+        } catch (RuntimeException ex) {\n+            return PollerFlux.error(ex);\n+        }\n+    }\n+\n+    private JobManifestTasks getJobManifestTasks(AnalyzeTasksOptions options) {\n+        if (options == null) {\n+            return null;\n+        }\n+        return new JobManifestTasks()\n+            .setEntityRecognitionTasks(options.getEntitiesRecognitionTasks() == null ? null\n+                : options.getEntitiesRecognitionTasks().stream().map(\n+                    entitiesTask -> {\n+                        if (entitiesTask == null) {\n+                            return null;\n+                        }\n+                        final EntitiesTask entitiesTaskImpl = new EntitiesTask();\n+                        final com.azure.ai.textanalytics.models.EntitiesTaskParameters entitiesTaskParameters =\n+                            entitiesTask.getParameters();\n+                        if (entitiesTaskParameters == null) {\n+                            return entitiesTaskImpl;\n+                        }\n+                        entitiesTaskImpl.setParameters(\n+                            new EntitiesTaskParameters().setModelVersion(entitiesTaskParameters.getModelVersion()));\n+                        return entitiesTaskImpl;\n+                    }).collect(Collectors.toList()))\n+            .setEntityRecognitionPiiTasks(options.getPiiEntitiesRecognitionTasks() == null ? null\n+                : options.getPiiEntitiesRecognitionTasks().stream().map(\n+                    piiEntitiesTask -> {\n+                        if (piiEntitiesTask == null) {\n+                            return null;\n+                        }\n+                        final PiiTask piiTaskImpl = new PiiTask();\n+                        final com.azure.ai.textanalytics.models.PiiTaskParameters piiTaskParameters =\n+                            piiEntitiesTask.getParameters();\n+                        if (piiTaskParameters == null) {\n+                            return piiTaskImpl;\n+                        }\n+                        piiTaskImpl.setParameters(\n+                            new PiiTaskParameters()\n+                                .setModelVersion(piiTaskParameters.getModelVersion())\n+                                .setDomain(PiiTaskParametersDomain.fromString(\n+                                    piiTaskParameters.getDomain() == null ? null\n+                                        : piiTaskParameters.getDomain().toString())));\n+                        return piiTaskImpl;\n+                    }).collect(Collectors.toList()))\n+            .setKeyPhraseExtractionTasks(options.getKeyPhrasesExtractionTasks() == null ? null\n+                : options.getKeyPhrasesExtractionTasks().stream().map(\n+                    keyPhrasesTask -> {\n+                        if (keyPhrasesTask == null) {\n+                            return null;\n+                        }\n+                        final com.azure.ai.textanalytics.models.KeyPhrasesTaskParameters keyPhrasesTaskParameters\n+                            = keyPhrasesTask.getParameters();\n+                        final KeyPhrasesTask keyPhrasesTaskImpl = new KeyPhrasesTask();\n+                        if (keyPhrasesTaskParameters == null) {\n+                            return keyPhrasesTaskImpl;\n+                        }\n+                        keyPhrasesTaskImpl.setParameters(\n+                            new KeyPhrasesTaskParameters().setModelVersion(keyPhrasesTaskParameters.getModelVersion()));\n+                        return keyPhrasesTaskImpl;\n+                    }).collect(Collectors.toList()));\n+    }\n+\n+    private Function<PollingContext<TextAnalyticsOperationResult>, Mono<TextAnalyticsOperationResult>>\n+        activationOperation(Mono<TextAnalyticsOperationResult> operationResult) {\n+        return pollingContext -> {\n+            try {\n+                return operationResult.onErrorMap(Utility::mapToHttpResponseExceptionIfExist);\n+            } catch (RuntimeException ex) {\n+                return monoError(logger, ex);\n+            }\n+        };\n+    }\n+\n+    private Function<PollingContext<TextAnalyticsOperationResult>, Mono<PollResponse<TextAnalyticsOperationResult>>>\n+        pollingOperation(Function<String, Mono<Response<AnalyzeJobState>>> pollingFunction) {\n+        return pollingContext -> {\n+            try {\n+                final PollResponse<TextAnalyticsOperationResult> operationResultPollResponse =\n+                    pollingContext.getLatestResponse();\n+//                final UUID resultUUID = UUID.fromString(operationResultPollResponse.getValue().getResultId());", "originalCommit": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTgwNDk4Nw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525804987", "bodyText": "I can add it", "author": "mssfang", "createdAt": "2020-11-18T04:45:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwOTE1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwOTU5Mg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525609592", "bodyText": "Just confirming, cancelling == in progress?", "author": "samvaity", "createdAt": "2020-11-18T00:12:44Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeTasksAsyncClient.java", "diffHunk": "@@ -0,0 +1,390 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics;\n+\n+import com.azure.ai.textanalytics.implementation.AnalyzeTasksResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsClientImpl;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsErrorInformationPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsExceptionPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsOperationResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.Utility;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeJobState;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTask;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.JobManifestTasks;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTask;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.MultiLanguageBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.PiiTask;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParametersDomain;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasks;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionPiiTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksKeyPhraseExtractionTasksItem;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksOptions;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksResult;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorCode;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorInformation;\n+import com.azure.ai.textanalytics.models.TextAnalyticsException;\n+import com.azure.ai.textanalytics.models.TextAnalyticsOperationResult;\n+import com.azure.ai.textanalytics.models.TextDocumentInput;\n+import com.azure.ai.textanalytics.util.ExtractKeyPhrasesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizeEntitiesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizePiiEntitiesResultCollection;\n+import com.azure.core.http.rest.PagedFlux;\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.core.http.rest.PagedResponse;\n+import com.azure.core.http.rest.PagedResponseBase;\n+import com.azure.core.http.rest.Response;\n+import com.azure.core.util.Context;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.core.util.logging.ClientLogger;\n+import com.azure.core.util.polling.LongRunningOperationStatus;\n+import com.azure.core.util.polling.PollResponse;\n+import com.azure.core.util.polling.PollerFlux;\n+import com.azure.core.util.polling.PollingContext;\n+import reactor.core.publisher.Mono;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static com.azure.ai.textanalytics.TextAnalyticsAsyncClient.COGNITIVE_TRACING_NAMESPACE_VALUE;\n+import static com.azure.ai.textanalytics.implementation.Utility.DEFAULT_POLL_INTERVAL;\n+import static com.azure.ai.textanalytics.implementation.Utility.inputDocumentsValidation;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseModelId;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseNextLink;\n+import static com.azure.ai.textanalytics.implementation.Utility.toBatchStatistics;\n+import static com.azure.ai.textanalytics.implementation.Utility.toExtractKeyPhrasesResultCollection;\n+import static com.azure.ai.textanalytics.implementation.Utility.toJobState;\n+import static com.azure.ai.textanalytics.implementation.Utility.toMultiLanguageInput;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizeEntitiesResultCollectionResponse;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizePiiEntitiesResultCollection;\n+import static com.azure.core.util.FluxUtil.monoError;\n+import static com.azure.core.util.tracing.Tracer.AZ_TRACING_NAMESPACE_KEY;\n+\n+class AnalyzeTasksAsyncClient {\n+    private final ClientLogger logger = new ClientLogger(AnalyzeTasksAsyncClient.class);\n+    private final TextAnalyticsClientImpl service;\n+\n+    AnalyzeTasksAsyncClient(TextAnalyticsClientImpl service) {\n+        this.service = service;\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedFlux<AnalyzeTasksResult>> beginAnalyze(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)))\n+                .setTasks(getJobManifestTasks(options));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(\n+                pollingInterval,\n+                activationOperation(\n+                    service.analyzeWithResponseAsync(analyzeBatchInput,\n+                        context.addData(AZ_TRACING_NAMESPACE_KEY, COGNITIVE_TRACING_NAMESPACE_VALUE))\n+                        .map(analyzeResponse -> {\n+                            final TextAnalyticsOperationResult textAnalyticsOperationResult =\n+                                new TextAnalyticsOperationResult();\n+                            TextAnalyticsOperationResultPropertiesHelper.setResultId(textAnalyticsOperationResult,\n+                                parseModelId(analyzeResponse.getDeserializedHeaders().getOperationLocation()));\n+                            return textAnalyticsOperationResult;\n+                        })),\n+                pollingOperation(resultID -> service.analyzeStatusWithResponseAsync(resultID,\n+                    finalIncludeStatistics, finalTop, finalSkip, context)),\n+                (activationResponse, pollingContext) -> null,\n+                fetchingOperation(resultId -> Mono.just(getAnalyzeOperationFluxPage(\n+                    resultId, finalTop, finalSkip, finalIncludeStatistics, context)))\n+            );\n+        } catch (RuntimeException ex) {\n+            return PollerFlux.error(ex);\n+        }\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedIterable<AnalyzeTasksResult>> beginAnalyzeIterable(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)))\n+                .setTasks(getJobManifestTasks(options));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(\n+                pollingInterval,\n+                activationOperation(\n+                    service.analyzeWithResponseAsync(analyzeBatchInput,\n+                        context.addData(AZ_TRACING_NAMESPACE_KEY, COGNITIVE_TRACING_NAMESPACE_VALUE))\n+                        .map(analyzeResponse -> {\n+                            final TextAnalyticsOperationResult textAnalyticsOperationResult =\n+                                new TextAnalyticsOperationResult();\n+                            TextAnalyticsOperationResultPropertiesHelper.setResultId(textAnalyticsOperationResult,\n+                                parseModelId(analyzeResponse.getDeserializedHeaders().getOperationLocation()));\n+                            return textAnalyticsOperationResult;\n+                        })),\n+                pollingOperation(resultID -> service.analyzeStatusWithResponseAsync(resultID,\n+                    options == null ? null : options.isIncludeStatistics(), null, null, context)),\n+                (activationResponse, pollingContext) -> null,\n+                fetchingOperationIterable(resultId -> Mono.just(new PagedIterable<>(getAnalyzeOperationFluxPage(\n+                    resultId, finalTop, finalSkip, finalIncludeStatistics, context))))\n+            );\n+        } catch (RuntimeException ex) {\n+            return PollerFlux.error(ex);\n+        }\n+    }\n+\n+    private JobManifestTasks getJobManifestTasks(AnalyzeTasksOptions options) {\n+        if (options == null) {\n+            return null;\n+        }\n+        return new JobManifestTasks()\n+            .setEntityRecognitionTasks(options.getEntitiesRecognitionTasks() == null ? null\n+                : options.getEntitiesRecognitionTasks().stream().map(\n+                    entitiesTask -> {\n+                        if (entitiesTask == null) {\n+                            return null;\n+                        }\n+                        final EntitiesTask entitiesTaskImpl = new EntitiesTask();\n+                        final com.azure.ai.textanalytics.models.EntitiesTaskParameters entitiesTaskParameters =\n+                            entitiesTask.getParameters();\n+                        if (entitiesTaskParameters == null) {\n+                            return entitiesTaskImpl;\n+                        }\n+                        entitiesTaskImpl.setParameters(\n+                            new EntitiesTaskParameters().setModelVersion(entitiesTaskParameters.getModelVersion()));\n+                        return entitiesTaskImpl;\n+                    }).collect(Collectors.toList()))\n+            .setEntityRecognitionPiiTasks(options.getPiiEntitiesRecognitionTasks() == null ? null\n+                : options.getPiiEntitiesRecognitionTasks().stream().map(\n+                    piiEntitiesTask -> {\n+                        if (piiEntitiesTask == null) {\n+                            return null;\n+                        }\n+                        final PiiTask piiTaskImpl = new PiiTask();\n+                        final com.azure.ai.textanalytics.models.PiiTaskParameters piiTaskParameters =\n+                            piiEntitiesTask.getParameters();\n+                        if (piiTaskParameters == null) {\n+                            return piiTaskImpl;\n+                        }\n+                        piiTaskImpl.setParameters(\n+                            new PiiTaskParameters()\n+                                .setModelVersion(piiTaskParameters.getModelVersion())\n+                                .setDomain(PiiTaskParametersDomain.fromString(\n+                                    piiTaskParameters.getDomain() == null ? null\n+                                        : piiTaskParameters.getDomain().toString())));\n+                        return piiTaskImpl;\n+                    }).collect(Collectors.toList()))\n+            .setKeyPhraseExtractionTasks(options.getKeyPhrasesExtractionTasks() == null ? null\n+                : options.getKeyPhrasesExtractionTasks().stream().map(\n+                    keyPhrasesTask -> {\n+                        if (keyPhrasesTask == null) {\n+                            return null;\n+                        }\n+                        final com.azure.ai.textanalytics.models.KeyPhrasesTaskParameters keyPhrasesTaskParameters\n+                            = keyPhrasesTask.getParameters();\n+                        final KeyPhrasesTask keyPhrasesTaskImpl = new KeyPhrasesTask();\n+                        if (keyPhrasesTaskParameters == null) {\n+                            return keyPhrasesTaskImpl;\n+                        }\n+                        keyPhrasesTaskImpl.setParameters(\n+                            new KeyPhrasesTaskParameters().setModelVersion(keyPhrasesTaskParameters.getModelVersion()));\n+                        return keyPhrasesTaskImpl;\n+                    }).collect(Collectors.toList()));\n+    }\n+\n+    private Function<PollingContext<TextAnalyticsOperationResult>, Mono<TextAnalyticsOperationResult>>\n+        activationOperation(Mono<TextAnalyticsOperationResult> operationResult) {\n+        return pollingContext -> {\n+            try {\n+                return operationResult.onErrorMap(Utility::mapToHttpResponseExceptionIfExist);\n+            } catch (RuntimeException ex) {\n+                return monoError(logger, ex);\n+            }\n+        };\n+    }\n+\n+    private Function<PollingContext<TextAnalyticsOperationResult>, Mono<PollResponse<TextAnalyticsOperationResult>>>\n+        pollingOperation(Function<String, Mono<Response<AnalyzeJobState>>> pollingFunction) {\n+        return pollingContext -> {\n+            try {\n+                final PollResponse<TextAnalyticsOperationResult> operationResultPollResponse =\n+                    pollingContext.getLatestResponse();\n+//                final UUID resultUUID = UUID.fromString(operationResultPollResponse.getValue().getResultId());\n+                final String resultID = operationResultPollResponse.getValue().getResultId();\n+                return pollingFunction.apply(resultID)\n+                    .flatMap(modelResponse -> processAnalyzedModelResponse(modelResponse, operationResultPollResponse))\n+                    .onErrorMap(Utility::mapToHttpResponseExceptionIfExist);\n+            } catch (RuntimeException ex) {\n+                return monoError(logger, ex);\n+            }\n+        };\n+    }\n+\n+    private Function<PollingContext<TextAnalyticsOperationResult>, Mono<PagedFlux<AnalyzeTasksResult>>>\n+        fetchingOperation(Function<String, Mono<PagedFlux<AnalyzeTasksResult>>> fetchingFunction) {\n+        return pollingContext -> {\n+            try {\n+//                final UUID resultUUID = UUID.fromString(pollingContext.getLatestResponse().getValue().getResultId());\n+                final String resultUUID = pollingContext.getLatestResponse().getValue().getResultId();\n+                return fetchingFunction.apply(resultUUID);\n+            } catch (RuntimeException ex) {\n+                return monoError(logger, ex);\n+            }\n+        };\n+    }\n+\n+    private Function<PollingContext<TextAnalyticsOperationResult>, Mono<PagedIterable<AnalyzeTasksResult>>>\n+        fetchingOperationIterable(Function<String, Mono<PagedIterable<AnalyzeTasksResult>>> fetchingFunction) {\n+        return pollingContext -> {\n+            try {\n+//                final UUID resultUUID = UUID.fromString(pollingContext.getLatestResponse().getValue().getResultId());\n+                final String resultUUID = pollingContext.getLatestResponse().getValue().getResultId();\n+                return fetchingFunction.apply(resultUUID);\n+            } catch (RuntimeException ex) {\n+                return monoError(logger, ex);\n+            }\n+        };\n+    }\n+\n+    PagedFlux<AnalyzeTasksResult> getAnalyzeOperationFluxPage(String analyzeTasksId, Integer top, Integer skip,\n+        Boolean showStats, Context context) {\n+        return new PagedFlux<>(\n+            () -> getPage(null, analyzeTasksId, top, skip, showStats, context),\n+            continuationToken -> getPage(continuationToken, analyzeTasksId, top, skip, showStats, context));\n+    }\n+\n+    Mono<PagedResponse<AnalyzeTasksResult>> getPage(String continuationToken, String analyzeTasksId, Integer top,\n+        Integer skip, Boolean showStats, Context context) {\n+        if (continuationToken != null) {\n+            final Map<String, Integer> continuationTokenMap = parseNextLink(continuationToken);\n+            final Integer topValue = continuationTokenMap.getOrDefault(\"$top\", null);\n+            final Integer skipValue = continuationTokenMap.getOrDefault(\"$skip\", null);\n+            return service.analyzeStatusWithResponseAsync(analyzeTasksId, showStats, topValue, skipValue, context)\n+                .map(this::toAnalyzeTasksPagedResponse)\n+                .onErrorMap(Utility::mapToHttpResponseExceptionIfExist);\n+        } else {\n+            return service.analyzeStatusWithResponseAsync(analyzeTasksId, showStats, top, skip, context)\n+                .map(this::toAnalyzeTasksPagedResponse)\n+                .onErrorMap(Utility::mapToHttpResponseExceptionIfExist);\n+        }\n+    }\n+\n+    private PagedResponse<AnalyzeTasksResult> toAnalyzeTasksPagedResponse(Response<AnalyzeJobState> response) {\n+        final AnalyzeJobState analyzeJobState = response.getValue();\n+        return new PagedResponseBase<Void, AnalyzeTasksResult>(\n+            response.getRequest(),\n+            response.getStatusCode(),\n+            response.getHeaders(),\n+            Arrays.asList(toAnalyzeTasks(analyzeJobState)),\n+            analyzeJobState.getNextLink(),\n+            null);\n+    }\n+\n+    private AnalyzeTasksResult toAnalyzeTasks(AnalyzeJobState analyzeJobState) {\n+        TasksStateTasks tasksStateTasks = analyzeJobState.getTasks();\n+        final List<TasksStateTasksEntityRecognitionPiiTasksItem> piiTasksItems =\n+            tasksStateTasks.getEntityRecognitionPiiTasks();\n+        final List<TasksStateTasksEntityRecognitionTasksItem> entityRecognitionTasksItems =\n+            tasksStateTasks.getEntityRecognitionTasks();\n+        final List<TasksStateTasksKeyPhraseExtractionTasksItem> keyPhraseExtractionTasks =\n+            tasksStateTasks.getKeyPhraseExtractionTasks();\n+        List<RecognizeEntitiesResultCollection> entitiesResultCollections = null;\n+        List<RecognizePiiEntitiesResultCollection> piiEntitiesResultCollections = null;\n+        List<ExtractKeyPhrasesResultCollection> keyPhrasesResultCollections = null;\n+        if (!CoreUtils.isNullOrEmpty(entityRecognitionTasksItems)) {\n+            entitiesResultCollections = entityRecognitionTasksItems.stream()\n+                .map(taskItem -> toRecognizeEntitiesResultCollectionResponse(taskItem.getResults()))\n+                .collect(Collectors.toList());\n+        }\n+        if (!CoreUtils.isNullOrEmpty(piiTasksItems)) {\n+            piiEntitiesResultCollections = piiTasksItems.stream()\n+                .map(taskItem -> toRecognizePiiEntitiesResultCollection(taskItem.getResults()))\n+                .collect(Collectors.toList());\n+        }\n+        if (!CoreUtils.isNullOrEmpty(keyPhraseExtractionTasks)) {\n+            keyPhrasesResultCollections = keyPhraseExtractionTasks.stream()\n+                .map(taskItem -> toExtractKeyPhrasesResultCollection(taskItem.getResults()))\n+                .collect(Collectors.toList());\n+        }\n+        final AnalyzeTasksResult analyzeTasksResult = new AnalyzeTasksResult(\n+            analyzeJobState.getJobId(),\n+            analyzeJobState.getCreatedDateTime(),\n+            analyzeJobState.getLastUpdateDateTime(),\n+            toJobState(analyzeJobState.getStatus()),\n+            analyzeJobState.getDisplayName(),\n+            analyzeJobState.getExpirationDateTime());\n+        AnalyzeTasksResultPropertiesHelper.setErrors(analyzeTasksResult,\n+            analyzeJobState.getErrors().stream().map(Utility::toTextAnalyticsError).collect(Collectors.toList()));\n+        AnalyzeTasksResultPropertiesHelper.setStatistics(analyzeTasksResult,\n+            analyzeJobState.getStatistics() == null ? null : toBatchStatistics(analyzeJobState.getStatistics()));\n+        AnalyzeTasksResultPropertiesHelper.setCompleted(analyzeTasksResult, tasksStateTasks.getCompleted());\n+        AnalyzeTasksResultPropertiesHelper.setFailed(analyzeTasksResult, tasksStateTasks.getFailed());\n+        AnalyzeTasksResultPropertiesHelper.setInProgress(analyzeTasksResult, tasksStateTasks.getInProgress());\n+        AnalyzeTasksResultPropertiesHelper.setTotal(analyzeTasksResult, tasksStateTasks.getTotal());\n+        AnalyzeTasksResultPropertiesHelper.setEntityRecognitionTasks(analyzeTasksResult, entitiesResultCollections);\n+        AnalyzeTasksResultPropertiesHelper.setEntityRecognitionPiiTasks(analyzeTasksResult,\n+            piiEntitiesResultCollections);\n+        AnalyzeTasksResultPropertiesHelper.setKeyPhraseExtractionTasks(analyzeTasksResult, keyPhrasesResultCollections);\n+        return analyzeTasksResult;\n+    }\n+\n+    private Mono<PollResponse<TextAnalyticsOperationResult>> processAnalyzedModelResponse(\n+        Response<AnalyzeJobState> analyzeJobStateResponse,\n+        PollResponse<TextAnalyticsOperationResult> operationResultPollResponse) {\n+\n+        LongRunningOperationStatus status;\n+        switch (analyzeJobStateResponse.getValue().getStatus()) {\n+            case NOT_STARTED:\n+            case CANCELLING:", "originalCommit": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTgwOTEyNQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525809125", "bodyText": "Cancelling can be consider as in-action operation. There is only in progress that I can use and it works fine.", "author": "mssfang", "createdAt": "2020-11-18T04:49:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwOTU5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwOTk5OQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525609999", "bodyText": "remove", "author": "samvaity", "createdAt": "2020-11-18T00:14:04Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/TextAnalyticsAsyncClient.java", "diffHunk": "@@ -1043,21 +1046,51 @@ public String getDefaultLanguage() {\n     }\n \n     /**\n-     * Cancel a long-running operation healthcare task by given job ID.\n+     * Cancel a long-running operation healthcare task by given a healthcare task identification number.\n      *\n      * <p><strong>Code Sample</strong></p>\n-     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginCancelAnalyzeHealthcare#UUID}\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginCancelAnalyzeHealthcare#String-RecognizeHealthcareEntityOptions}\n      *\n-     * @param jobId A job identification number.\n+     * @param healthcareTaskId The healthcare task identification number.\n+     * @param options The additional configurable {@link RecognizeHealthcareEntityOptions options} that may be passed\n+     * when cancelling healthcare task.\n      *\n      * @return A {@link PollerFlux} that polls the analyze healthcare operation until it has completed, has failed,\n      * or has been cancelled.\n      *\n      * @throws TextAnalyticsException If analyze operation fails.\n+     * @throws NullPointerException If {@code healthcareTaskId} is null.\n+     */\n+    @ServiceMethod(returns = ReturnType.COLLECTION)\n+    public PollerFlux<TextAnalyticsOperationResult, Void> beginCancelAnalyzeHealthcare(String healthcareTaskId,\n+        RecognizeHealthcareEntityOptions options) {\n+        return analyzeHealthcareAsyncClient.beginCancelAnalyzeHealthcare(healthcareTaskId, options, Context.NONE);\n+    }\n+\n+    // Analyze LRO", "originalCommit": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYxMDIzOA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525610238", "bodyText": "This naming is too generic, should we consider renaming?", "author": "samvaity", "createdAt": "2020-11-18T00:14:43Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/TextAnalyticsAsyncClient.java", "diffHunk": "@@ -1043,21 +1046,51 @@ public String getDefaultLanguage() {\n     }\n \n     /**\n-     * Cancel a long-running operation healthcare task by given job ID.\n+     * Cancel a long-running operation healthcare task by given a healthcare task identification number.\n      *\n      * <p><strong>Code Sample</strong></p>\n-     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginCancelAnalyzeHealthcare#UUID}\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginCancelAnalyzeHealthcare#String-RecognizeHealthcareEntityOptions}\n      *\n-     * @param jobId A job identification number.\n+     * @param healthcareTaskId The healthcare task identification number.\n+     * @param options The additional configurable {@link RecognizeHealthcareEntityOptions options} that may be passed\n+     * when cancelling healthcare task.\n      *\n      * @return A {@link PollerFlux} that polls the analyze healthcare operation until it has completed, has failed,\n      * or has been cancelled.\n      *\n      * @throws TextAnalyticsException If analyze operation fails.\n+     * @throws NullPointerException If {@code healthcareTaskId} is null.\n+     */\n+    @ServiceMethod(returns = ReturnType.COLLECTION)\n+    public PollerFlux<TextAnalyticsOperationResult, Void> beginCancelAnalyzeHealthcare(String healthcareTaskId,\n+        RecognizeHealthcareEntityOptions options) {\n+        return analyzeHealthcareAsyncClient.beginCancelAnalyzeHealthcare(healthcareTaskId, options, Context.NONE);\n+    }\n+\n+    // Analyze LRO\n+    /**\n+     * Analyze tasks, such as, entity recognition, PII entity recognition and key phrases extraction in a list of\n+     * {@link TextDocumentInput document} with provided request options.\n+     *\n+     * See <a href=\"https://aka.ms/talangs\">this</a> supported languages in Text Analytics API.\n+     *\n+     * <p><strong>Code Sample</strong></p>\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginAnalyze#Iterable-AnalyzeTasksOptions}\n+     *\n+     * @param documents A list of {@link TextDocumentInput documents} to be analyzed.\n+     * @param options The additional configurable {@link AnalyzeTasksOptions options} that may be passed when\n+     * analyzing a collection of tasks.\n+     *\n+     * @return A {@link PollerFlux} that polls the analyze a collection of tasks operation until it has completed,\n+     * has failed, or has been cancelled. The completed operation returns a {@link PagedFlux} of\n+     * {@link AnalyzeTasksResult}.\n+     *\n+     * @throws TextAnalyticsException If analyze operation fails.\n      * @throws NullPointerException If {@code jobId} is null.\n      */\n     @ServiceMethod(returns = ReturnType.COLLECTION)\n-    public PollerFlux<TextAnalyticsOperationResult, Void> beginCancelAnalyzeHealthcare(UUID jobId) {\n-        return analyzeHealthcareAsyncClient.beginCancelAnalyzeHealthcare(jobId, Context.NONE);\n+    public PollerFlux<TextAnalyticsOperationResult, PagedFlux<AnalyzeTasksResult>> beginAnalyze(", "originalCommit": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYzMDU4Ng==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525630586", "bodyText": "Yes. I can change it to beginAnalyzeTasks().", "author": "mssfang", "createdAt": "2020-11-18T01:13:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYxMDIzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQzMTQ3Mg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526431472", "bodyText": "beginAnalyzeTasks is still very vague. Is this meant to change and not something that got discussed for this preview?\ncc: @maririos @iscai-msft", "author": "samvaity", "createdAt": "2020-11-18T21:26:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYxMDIzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQzNDMwNw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526434307", "bodyText": "For this release we are going with the autogenerated code so there is no focus on naming.\nI do agree that for future releases, this name needs rework", "author": "maririos", "createdAt": "2020-11-18T21:31:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYxMDIzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYxMDU0Nw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525610547", "bodyText": "There s no Job Id required in the parameters?", "author": "samvaity", "createdAt": "2020-11-18T00:15:34Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/TextAnalyticsClient.java", "diffHunk": "@@ -907,22 +908,55 @@ public AnalyzeSentimentResultCollection analyzeSentimentBatch(Iterable<String> d\n     }\n \n     /**\n-     * Cancel a long-running operation healthcare task by given job ID.\n+     * Cancel a long-running operation healthcare task by given a healthcare task identification number.\n      *\n      * <p><strong>Code Sample</strong></p>\n-     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsClient.beginCancelAnalyzeHealthcare#UUID-Context}\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsClient.beginCancelAnalyzeHealthcare#String-RecognizeHealthcareEntityOptions-Context}\n      *\n-     * @param jobId A job identification number.\n+     * @param healthcareTaskId The healthcare task identification number.\n+     * @param options The additional configurable {@link RecognizeHealthcareEntityOptions options} that may be passed\n+     * when cancelling healthcare task.\n      * @param context Additional context that is passed through the Http pipeline during the service call.\n      *\n      * @return A {@link SyncPoller} that polls the analyze healthcare operation until it has completed, has failed,\n      * or has been cancelled.\n      *\n      * @throws TextAnalyticsException If analyze operation fails.\n+     * @throws NullPointerException If {@code healthcareTaskId} is null.\n+     */\n+    @ServiceMethod(returns = ReturnType.COLLECTION)\n+    public SyncPoller<TextAnalyticsOperationResult, Void> beginCancelAnalyzeHealthcare(String healthcareTaskId,\n+        RecognizeHealthcareEntityOptions options, Context context) {\n+        return client.analyzeHealthcareAsyncClient.beginCancelAnalyzeHealthcare(healthcareTaskId, options, context)\n+                   .getSyncPoller();\n+    }\n+\n+    // Analyze\n+\n+    /**\n+     * Analyze tasks, such as, entity recognition, PII entity recognition and key phrases extraction in a list of\n+     * {@link TextDocumentInput document} with provided request options.\n+     *\n+     * See <a href=\"https://aka.ms/talangs\">this</a> supported languages in Text Analytics API.\n+     *\n+     * <p><strong>Code Sample</strong></p>\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsClient.beginAnalyze#Iterable-AnalyzeTasksOptions-Context}\n+     *\n+     * @param documents A list of {@link TextDocumentInput documents} to be analyzed.\n+     * @param options The additional configurable {@link AnalyzeTasksOptions options} that may be passed when\n+     * analyzing a collection of tasks.\n+     * @param context Additional context that is passed through the Http pipeline during the service call.\n+     *\n+     * @return A {@link SyncPoller} that polls the analyze a collection of tasks operation until it has completed,\n+     * has failed, or has been cancelled. The completed operation returns a {@link PagedIterable} of\n+     * {@link AnalyzeTasksResult}.\n+     *\n+     * @throws TextAnalyticsException If analyze operation fails.\n      * @throws NullPointerException If {@code jobId} is null.", "originalCommit": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTgxMTcwMA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525811700", "bodyText": "No Job ID is required.  will remove this null pointer exception", "author": "mssfang", "createdAt": "2020-11-18T04:52:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYxMDU0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYxMDcyMw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525610723", "bodyText": "Needs update/", "author": "samvaity", "createdAt": "2020-11-18T00:16:03Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/TextAnalyticsAsyncClient.java", "diffHunk": "@@ -1043,21 +1046,51 @@ public String getDefaultLanguage() {\n     }\n \n     /**\n-     * Cancel a long-running operation healthcare task by given job ID.\n+     * Cancel a long-running operation healthcare task by given a healthcare task identification number.\n      *\n      * <p><strong>Code Sample</strong></p>\n-     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginCancelAnalyzeHealthcare#UUID}\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginCancelAnalyzeHealthcare#String-RecognizeHealthcareEntityOptions}\n      *\n-     * @param jobId A job identification number.\n+     * @param healthcareTaskId The healthcare task identification number.\n+     * @param options The additional configurable {@link RecognizeHealthcareEntityOptions options} that may be passed\n+     * when cancelling healthcare task.\n      *\n      * @return A {@link PollerFlux} that polls the analyze healthcare operation until it has completed, has failed,\n      * or has been cancelled.\n      *\n      * @throws TextAnalyticsException If analyze operation fails.\n+     * @throws NullPointerException If {@code healthcareTaskId} is null.\n+     */\n+    @ServiceMethod(returns = ReturnType.COLLECTION)\n+    public PollerFlux<TextAnalyticsOperationResult, Void> beginCancelAnalyzeHealthcare(String healthcareTaskId,\n+        RecognizeHealthcareEntityOptions options) {\n+        return analyzeHealthcareAsyncClient.beginCancelAnalyzeHealthcare(healthcareTaskId, options, Context.NONE);\n+    }\n+\n+    // Analyze LRO\n+    /**\n+     * Analyze tasks, such as, entity recognition, PII entity recognition and key phrases extraction in a list of\n+     * {@link TextDocumentInput document} with provided request options.\n+     *\n+     * See <a href=\"https://aka.ms/talangs\">this</a> supported languages in Text Analytics API.\n+     *\n+     * <p><strong>Code Sample</strong></p>\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsAsyncClient.beginAnalyze#Iterable-AnalyzeTasksOptions}\n+     *\n+     * @param documents A list of {@link TextDocumentInput documents} to be analyzed.\n+     * @param options The additional configurable {@link AnalyzeTasksOptions options} that may be passed when\n+     * analyzing a collection of tasks.\n+     *\n+     * @return A {@link PollerFlux} that polls the analyze a collection of tasks operation until it has completed,\n+     * has failed, or has been cancelled. The completed operation returns a {@link PagedFlux} of\n+     * {@link AnalyzeTasksResult}.\n+     *\n+     * @throws TextAnalyticsException If analyze operation fails.\n      * @throws NullPointerException If {@code jobId} is null.", "originalCommit": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYxMzMyOA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525613328", "bodyText": "Do we have this mentioned in the docs anywhere?", "author": "samvaity", "createdAt": "2020-11-18T00:23:36Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/test/java/com/azure/ai/textanalytics/TextAnalyticsClientTestBase.java", "diffHunk": "@@ -620,26 +665,52 @@ void healthcareLroRunner(BiConsumer<List<TextDocumentInput>, RecognizeHealthcare\n             asList(\n                 new TextDocumentInput(\"0\", HEALTHCARE_INPUTS.get(0)),\n                 new TextDocumentInput(\"1\", HEALTHCARE_INPUTS.get(1))),\n-            new RecognizeHealthcareEntityOptions().setIncludeStatistics(true));\n+            new RecognizeHealthcareEntityOptions().setIncludeStatistics(true).setPollInterval(durationTestMode));\n     }\n \n     void healthcareLroPaginationRunner(\n-        BiConsumer<List<TextDocumentInput>, RecognizeHealthcareEntityOptions> testRunner) {\n+        BiConsumer<List<TextDocumentInput>, RecognizeHealthcareEntityOptions> testRunner, int totalDocuments) {\n         List<TextDocumentInput> documents = new ArrayList<>();\n-        // Service has 20 as the default size per page. So there will be 2 remaining page in the next page link\n-        for (int i = 0; i < 22; i++) {\n+        // Service has 10 as the default size per page. So there will be 2 remaining page in the next page link", "originalCommit": "c94420c6346fcdb35a10f7bc1c0358cb58b72228", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyODMwNg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r525628306", "bodyText": "Unfortunately. This is the first - preview of Healthcare and Analyze Tasks. There is no written document right now. Service  will increase the max document size in the next release", "author": "mssfang", "createdAt": "2020-11-18T01:07:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYxMzMyOA=="}], "type": "inlineReview"}, {"oid": "8802740487adbe907e5e94b4599c71e90b5b413c", "url": "https://github.com/Azure/azure-sdk-for-java/commit/8802740487adbe907e5e94b4599c71e90b5b413c", "message": "renaming some APIs and address feedbacks", "committedDate": "2020-11-18T05:11:01Z", "type": "commit"}, {"oid": "ae88549e02ddb4022762f65d83ff23e7ff497823", "url": "https://github.com/Azure/azure-sdk-for-java/commit/ae88549e02ddb4022762f65d83ff23e7ff497823", "message": "make final class if possible", "committedDate": "2020-11-18T05:17:39Z", "type": "commit"}, {"oid": "047f2b51481a51d91de56770bd5e33e272840640", "url": "https://github.com/Azure/azure-sdk-for-java/commit/047f2b51481a51d91de56770bd5e33e272840640", "message": "make HealthcareEntityCollection final class", "committedDate": "2020-11-18T05:32:08Z", "type": "commit"}, {"oid": "201e02596788d346212d0bf129459a7c388d6791", "url": "https://github.com/Azure/azure-sdk-for-java/commit/201e02596788d346212d0bf129459a7c388d6791", "message": "service already fixed the nextLink to @nextLink", "committedDate": "2020-11-18T22:59:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5NjE3Mg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526496172", "bodyText": "Can this be put into a function to avoid repeated code?", "author": "samvaity", "createdAt": "2020-11-18T23:42:44Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/AnalyzeTasksAsyncClient.java", "diffHunk": "@@ -0,0 +1,393 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics;\n+\n+import com.azure.ai.textanalytics.implementation.AnalyzeTasksResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsClientImpl;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsErrorInformationPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsExceptionPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.TextAnalyticsOperationResultPropertiesHelper;\n+import com.azure.ai.textanalytics.implementation.Utility;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.AnalyzeJobState;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTask;\n+import com.azure.ai.textanalytics.implementation.models.EntitiesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.JobManifestTasks;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTask;\n+import com.azure.ai.textanalytics.implementation.models.KeyPhrasesTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.MultiLanguageBatchInput;\n+import com.azure.ai.textanalytics.implementation.models.PiiTask;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParameters;\n+import com.azure.ai.textanalytics.implementation.models.PiiTaskParametersDomain;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasks;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionPiiTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksEntityRecognitionTasksItem;\n+import com.azure.ai.textanalytics.implementation.models.TasksStateTasksKeyPhraseExtractionTasksItem;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksOptions;\n+import com.azure.ai.textanalytics.models.AnalyzeTasksResult;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorCode;\n+import com.azure.ai.textanalytics.models.TextAnalyticsErrorInformation;\n+import com.azure.ai.textanalytics.models.TextAnalyticsException;\n+import com.azure.ai.textanalytics.models.TextAnalyticsOperationResult;\n+import com.azure.ai.textanalytics.models.TextDocumentInput;\n+import com.azure.ai.textanalytics.util.ExtractKeyPhrasesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizeEntitiesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizePiiEntitiesResultCollection;\n+import com.azure.core.http.rest.PagedFlux;\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.core.http.rest.PagedResponse;\n+import com.azure.core.http.rest.PagedResponseBase;\n+import com.azure.core.http.rest.Response;\n+import com.azure.core.util.Context;\n+import com.azure.core.util.CoreUtils;\n+import com.azure.core.util.logging.ClientLogger;\n+import com.azure.core.util.polling.LongRunningOperationStatus;\n+import com.azure.core.util.polling.PollResponse;\n+import com.azure.core.util.polling.PollerFlux;\n+import com.azure.core.util.polling.PollingContext;\n+import reactor.core.publisher.Mono;\n+\n+import java.time.Duration;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+\n+import static com.azure.ai.textanalytics.TextAnalyticsAsyncClient.COGNITIVE_TRACING_NAMESPACE_VALUE;\n+import static com.azure.ai.textanalytics.implementation.Utility.DEFAULT_POLL_INTERVAL;\n+import static com.azure.ai.textanalytics.implementation.Utility.inputDocumentsValidation;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseModelId;\n+import static com.azure.ai.textanalytics.implementation.Utility.parseNextLink;\n+import static com.azure.ai.textanalytics.implementation.Utility.toBatchStatistics;\n+import static com.azure.ai.textanalytics.implementation.Utility.toExtractKeyPhrasesResultCollection;\n+import static com.azure.ai.textanalytics.implementation.Utility.toJobState;\n+import static com.azure.ai.textanalytics.implementation.Utility.toMultiLanguageInput;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizeEntitiesResultCollectionResponse;\n+import static com.azure.ai.textanalytics.implementation.Utility.toRecognizePiiEntitiesResultCollection;\n+import static com.azure.core.util.FluxUtil.monoError;\n+import static com.azure.core.util.tracing.Tracer.AZ_TRACING_NAMESPACE_KEY;\n+\n+class AnalyzeTasksAsyncClient {\n+    private final ClientLogger logger = new ClientLogger(AnalyzeTasksAsyncClient.class);\n+    private final TextAnalyticsClientImpl service;\n+\n+    AnalyzeTasksAsyncClient(TextAnalyticsClientImpl service) {\n+        this.service = service;\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedFlux<AnalyzeTasksResult>> beginAnalyzeTasks(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setTasks(getJobManifestTasks(options)).setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();\n+            return new PollerFlux<>(\n+                pollingInterval,\n+                activationOperation(\n+                    service.analyzeWithResponseAsync(analyzeBatchInput,\n+                        context.addData(AZ_TRACING_NAMESPACE_KEY, COGNITIVE_TRACING_NAMESPACE_VALUE))\n+                        .map(analyzeResponse -> {\n+                            final TextAnalyticsOperationResult textAnalyticsOperationResult =\n+                                new TextAnalyticsOperationResult();\n+                            TextAnalyticsOperationResultPropertiesHelper.setResultId(textAnalyticsOperationResult,\n+                                parseModelId(analyzeResponse.getDeserializedHeaders().getOperationLocation()));\n+                            return textAnalyticsOperationResult;\n+                        })),\n+                pollingOperation(resultID -> service.analyzeStatusWithResponseAsync(resultID,\n+                    finalIncludeStatistics, finalTop, finalSkip, context)),\n+                (activationResponse, pollingContext) ->\n+                    Mono.error(new RuntimeException(\"Cancellation is not supported.\")),\n+                fetchingOperation(resultId -> Mono.just(getAnalyzeOperationFluxPage(\n+                    resultId, finalTop, finalSkip, finalIncludeStatistics, context)))\n+            );\n+        } catch (RuntimeException ex) {\n+            return PollerFlux.error(ex);\n+        }\n+    }\n+\n+    PollerFlux<TextAnalyticsOperationResult, PagedIterable<AnalyzeTasksResult>> beginAnalyzeTasksIterable(\n+        Iterable<TextDocumentInput> documents, AnalyzeTasksOptions options, Context context) {\n+        try {\n+            inputDocumentsValidation(documents);\n+            AnalyzeBatchInput analyzeBatchInput = new AnalyzeBatchInput()\n+                .setAnalysisInput(new MultiLanguageBatchInput().setDocuments(toMultiLanguageInput(documents)));\n+            Duration pollingInterval = DEFAULT_POLL_INTERVAL;\n+            if (options != null) {\n+                analyzeBatchInput.setTasks(getJobManifestTasks(options)).setDisplayName(options.getDisplayName());\n+                pollingInterval = options.getPollInterval();\n+            }\n+            final Boolean finalIncludeStatistics = options == null ? null : options.isIncludeStatistics();\n+            final Integer finalTop = options == null ? null : options.getTop();\n+            final Integer finalSkip = options == null ? null : options.getSkip();", "originalCommit": "201e02596788d346212d0bf129459a7c388d6791", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU1MzA0MQ==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526553041", "bodyText": "refactored", "author": "mssfang", "createdAt": "2020-11-19T02:32:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5NjE3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5OTU0Mg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526499542", "bodyText": "Dos needs to be updated for potential NPE.", "author": "samvaity", "createdAt": "2020-11-18T23:51:45Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/TextAnalyticsClient.java", "diffHunk": "@@ -907,22 +905,52 @@ public AnalyzeSentimentResultCollection analyzeSentimentBatch(Iterable<String> d\n     }\n \n     /**\n-     * Cancel a long-running operation healthcare task by given job ID.\n+     * Cancel a long-running operation healthcare task by given a healthcare task identification number.\n      *\n      * <p><strong>Code Sample</strong></p>\n-     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsClient.beginCancelAnalyzeHealthcare#UUID-Context}\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsClient.beginCancelHealthcareTask#String-RecognizeHealthcareEntityOptions-Context}\n      *\n-     * @param jobId A job identification number.\n+     * @param healthcareTaskId The healthcare task identification number.\n+     * @param options The additional configurable {@link RecognizeHealthcareEntityOptions options} that may be passed\n+     * when cancelling healthcare task.\n      * @param context Additional context that is passed through the Http pipeline during the service call.\n      *\n      * @return A {@link SyncPoller} that polls the analyze healthcare operation until it has completed, has failed,\n      * or has been cancelled.\n      *\n      * @throws TextAnalyticsException If analyze operation fails.\n-     * @throws NullPointerException If {@code jobId} is null.\n+     * @throws NullPointerException If {@code healthcareTaskId} is null.\n+     */\n+    @ServiceMethod(returns = ReturnType.COLLECTION)\n+    public SyncPoller<TextAnalyticsOperationResult, Void> beginCancelHealthcareTask(String healthcareTaskId,\n+        RecognizeHealthcareEntityOptions options, Context context) {\n+        return client.analyzeHealthcareAsyncClient.beginCancelAnalyzeHealthcare(healthcareTaskId, options, context)\n+                   .getSyncPoller();\n+    }\n+\n+    /**\n+     * Analyze tasks, such as, entity recognition, PII entity recognition and key phrases extraction in a list of\n+     * {@link TextDocumentInput document} with provided request options.\n+     *\n+     * See <a href=\"https://aka.ms/talangs\">this</a> supported languages in Text Analytics API.\n+     *\n+     * <p><strong>Code Sample</strong></p>\n+     * {@codesnippet com.azure.ai.textanalytics.TextAnalyticsClient.beginAnalyzeTasks#Iterable-AnalyzeTasksOptions-Context}\n+     *\n+     * @param documents A list of {@link TextDocumentInput documents} to be analyzed.\n+     * @param options The additional configurable {@link AnalyzeTasksOptions options} that may be passed when\n+     * analyzing a collection of tasks.\n+     * @param context Additional context that is passed through the Http pipeline during the service call.\n+     *\n+     * @return A {@link SyncPoller} that polls the analyze a collection of tasks operation until it has completed,\n+     * has failed, or has been cancelled. The completed operation returns a {@link PagedIterable} of\n+     * {@link AnalyzeTasksResult}.\n+     *\n+     * @throws TextAnalyticsException If analyze operation fails.", "originalCommit": "201e02596788d346212d0bf129459a7c388d6791", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUwMTE3Mg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526501172", "bodyText": "Just confirming, we are keeping some of the methods/mnamings as is since for this preview we just want to expose the generated methods/code as is. Correct?", "author": "samvaity", "createdAt": "2020-11-18T23:56:01Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/models/AnalyzeTasksResult.java", "diffHunk": "@@ -0,0 +1,251 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics.models;\n+\n+import com.azure.ai.textanalytics.implementation.AnalyzeTasksResultPropertiesHelper;\n+import com.azure.ai.textanalytics.util.ExtractKeyPhrasesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizeEntitiesResultCollection;\n+import com.azure.ai.textanalytics.util.RecognizePiiEntitiesResultCollection;\n+\n+import java.time.OffsetDateTime;\n+import java.util.List;\n+\n+/**\n+ * The AnalyzeTasksResult model.\n+ */\n+public final class AnalyzeTasksResult extends JobMetadata {\n+\n+    /*\n+     * The errors property.\n+     */\n+    private List<TextAnalyticsError> errors;\n+\n+    /*\n+     * if showStats=true was specified in the request this field will contain\n+     * information about the request payload.\n+     */\n+    private TextDocumentBatchStatistics statistics;\n+\n+    /*\n+     * The completed property.\n+     */\n+    private int completed;\n+\n+    /*\n+     * The failed property.\n+     */\n+    private int failed;\n+\n+    /*\n+     * The inProgress property.\n+     */\n+    private int inProgress;\n+\n+    /*\n+     * The total property.\n+     */\n+    private int total;\n+\n+    /*\n+     * The entityRecognitionTasks property.\n+     */\n+    private List<RecognizeEntitiesResultCollection> entityRecognitionTasks;\n+\n+    /*\n+     * The entityRecognitionPiiTasks property.\n+     */\n+    private List<RecognizePiiEntitiesResultCollection> entityRecognitionPiiTasks;\n+\n+    /*\n+     * The keyPhraseExtractionTasks property.\n+     */\n+    private List<ExtractKeyPhrasesResultCollection> keyPhraseExtractionTasks;\n+\n+    static {\n+        AnalyzeTasksResultPropertiesHelper.setAccessor(\n+            new AnalyzeTasksResultPropertiesHelper.AnalyzeTasksResultAccessor() {\n+                @Override\n+                public void setErrors(AnalyzeTasksResult analyzeTasksResult, List<TextAnalyticsError> errors) {\n+                    analyzeTasksResult.setErrors(errors);\n+                }\n+\n+                @Override\n+                public void setStatistics(AnalyzeTasksResult analyzeTasksResult,\n+                    TextDocumentBatchStatistics statistics) {\n+                    analyzeTasksResult.setStatistics(statistics);\n+                }\n+\n+                @Override\n+                public void setCompleted(AnalyzeTasksResult analyzeTasksResult, int completed) {\n+                    analyzeTasksResult.setCompleted(completed);\n+                }\n+\n+                @Override\n+                public void setFailed(AnalyzeTasksResult analyzeTasksResult, int failed) {\n+                    analyzeTasksResult.setFailed(failed);\n+                }\n+\n+                @Override\n+                public void setInProgress(AnalyzeTasksResult analyzeTasksResult, int inProgress) {\n+                    analyzeTasksResult.setInProgress(inProgress);\n+                }\n+\n+                @Override\n+                public void setTotal(AnalyzeTasksResult analyzeTasksResult, int total) {\n+                    analyzeTasksResult.setTotal(total);\n+                }\n+\n+                @Override\n+                public void setEntityRecognitionTasks(AnalyzeTasksResult analyzeTasksResult,\n+                    List<RecognizeEntitiesResultCollection> entityRecognitionTasks) {\n+                    analyzeTasksResult.setEntityRecognitionTasks(entityRecognitionTasks);\n+                }\n+\n+                @Override\n+                public void setEntityRecognitionPiiTasks(AnalyzeTasksResult analyzeTasksResult,\n+                    List<RecognizePiiEntitiesResultCollection> entityRecognitionPiiTasks) {\n+                    analyzeTasksResult.setEntityRecognitionPiiTasks(entityRecognitionPiiTasks);\n+                }\n+\n+                @Override\n+                public void setKeyPhraseExtractionTasks(AnalyzeTasksResult analyzeTasksResult,\n+                    List<ExtractKeyPhrasesResultCollection> keyPhraseExtractionTasks) {\n+                    analyzeTasksResult.setKeyPhraseExtractionTasks(keyPhraseExtractionTasks);\n+                }\n+            });\n+    }\n+\n+    /**\n+     * Creates a {@link AnalyzeTasksResult} model that describes analyzed tasks result.\n+     *\n+     * @param analyzeTasksId the analyze tasks identification.\n+     * @param createdDateTime the created time of the job.\n+     * @param lastUpdateDateTime the last updated time of the job.\n+     * @param status the job status.\n+     * @param displayName the display name.\n+     * @param expirationDateTime the expiration time of the job.\n+     */\n+    public AnalyzeTasksResult(String analyzeTasksId, OffsetDateTime createdDateTime, OffsetDateTime lastUpdateDateTime,\n+        JobState status, String displayName, OffsetDateTime expirationDateTime) {\n+        super(analyzeTasksId, createdDateTime, lastUpdateDateTime, status, displayName, expirationDateTime);\n+    }\n+\n+    /**\n+     * Get the errors property: The errors property.\n+     *\n+     * @return the errors value.\n+     */\n+    public List<TextAnalyticsError> getErrors() {\n+        return this.errors;\n+    }\n+\n+    /**\n+     * Get the statistics property: if showStats=true was specified in the request this field will contain information\n+     * about the request payload.\n+     *\n+     * @return the statistics value.\n+     */\n+    public TextDocumentBatchStatistics getStatistics() {\n+        return this.statistics;\n+    }\n+\n+    /**\n+     * Get the completed property: The completed property.\n+     *\n+     * @return the completed value.\n+     */\n+    public int getCompleted() {\n+        return this.completed;\n+    }\n+\n+    /**\n+     * Get the failed property: The failed property.\n+     *\n+     * @return the failed value.\n+     */\n+    public int getFailed() {\n+        return this.failed;\n+    }\n+\n+    /**\n+     * Get the inProgress property: The inProgress property.\n+     *\n+     * @return the inProgress value.\n+     */\n+    public int getInProgress() {", "originalCommit": "201e02596788d346212d0bf129459a7c388d6791", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUwNjAwMA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526506000", "bodyText": "Yes. That is correct. This preview is focus on make the generated method working.", "author": "mssfang", "createdAt": "2020-11-19T00:09:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUwMTE3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUwMjE5Mw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526502193", "bodyText": "Should PiiTaskParameters model name be plural, ignore if genrated code exposed.", "author": "samvaity", "createdAt": "2020-11-18T23:58:52Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/main/java/com/azure/ai/textanalytics/models/PiiTask.java", "diffHunk": "@@ -0,0 +1,35 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics.models;\n+\n+import com.azure.core.annotation.Fluent;\n+\n+/** The PiiTask model. */\n+@Fluent\n+public final class PiiTask {\n+    /*\n+     * The parameters property.\n+     */\n+    private PiiTaskParameters parameters = new PiiTaskParameters();\n+\n+    /**\n+     * Get the parameters property: The parameters property.\n+     *\n+     * @return the parameters value.\n+     */\n+    public PiiTaskParameters getParameters() {\n+        return this.parameters;\n+    }\n+\n+    /**\n+     * Set the parameters property: The parameters property.\n+     *\n+     * @param parameters the parameters value to set.\n+     * @return the PiiTask object itself.\n+     */\n+    public PiiTask setParameters(PiiTaskParameters parameters) {", "originalCommit": "201e02596788d346212d0bf129459a7c388d6791", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUwNzI5NA==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526507294", "bodyText": "PiiTaskParameters is like a wrap class that contains all parameters that PiiTask will take.", "author": "mssfang", "createdAt": "2020-11-19T00:13:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUwMjE5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUwMzEzMg==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526503132", "bodyText": "why a special foldrer for lro?", "author": "samvaity", "createdAt": "2020-11-19T00:01:28Z", "path": "sdk/textanalytics/azure-ai-textanalytics/src/samples/java/com/azure/ai/textanalytics/lro/AnalyzeTasks.java", "diffHunk": "@@ -0,0 +1,151 @@\n+// Copyright (c) Microsoft Corporation. All rights reserved.\n+// Licensed under the MIT License.\n+\n+package com.azure.ai.textanalytics.lro;", "originalCommit": "201e02596788d346212d0bf129459a7c388d6791", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUwNjc2Mw==", "url": "https://github.com/Azure/azure-sdk-for-java/pull/17267#discussion_r526506763", "bodyText": "only healthcare and multiple tasks analysis are long-running operation, it is easier to find and better categorized.", "author": "mssfang", "createdAt": "2020-11-19T00:11:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUwMzEzMg=="}], "type": "inlineReview"}, {"oid": "d52decd09201e5c05dd1de225ad86139a24f2113", "url": "https://github.com/Azure/azure-sdk-for-java/commit/d52decd09201e5c05dd1de225ad86139a24f2113", "message": "add NPE and add live test setup", "committedDate": "2020-11-19T01:01:20Z", "type": "commit"}, {"oid": "668650b09ef6dc97c2643259252dc6bde0261ae5", "url": "https://github.com/Azure/azure-sdk-for-java/commit/668650b09ef6dc97c2643259252dc6bde0261ae5", "message": "address last feedbacks", "committedDate": "2020-11-19T02:31:12Z", "type": "commit"}, {"oid": "b819e4f037f912a39dbacc33778ddb1606c661c3", "url": "https://github.com/Azure/azure-sdk-for-java/commit/b819e4f037f912a39dbacc33778ddb1606c661c3", "message": "update readme content and links", "committedDate": "2020-11-19T16:08:51Z", "type": "commit"}]}