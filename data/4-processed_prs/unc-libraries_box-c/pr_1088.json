{"pr_number": 1088, "pr_title": "BXC-2795 - Prevent deposit job blocking caused by TDB lock", "pr_createdAt": "2020-09-01T20:36:06Z", "pr_url": "https://github.com/UNC-Libraries/box-c/pull/1088", "timeline": [{"oid": "e65aca08a4186998108022dc721c85a8e38c4eb5", "url": "https://github.com/UNC-Libraries/box-c/commit/e65aca08a4186998108022dc721c85a8e38c4eb5", "message": "Refactor DepositModelManager to place jena-tdb in the directory for individual deposits, and to support separate dataset per deposit. Move it to persistence.", "committedDate": "2020-08-28T20:57:14Z", "type": "commit"}, {"oid": "b90294ededa71b6a336b7301b8fa71904478d9f8", "url": "https://github.com/UNC-Libraries/box-c/commit/b90294ededa71b6a336b7301b8fa71904478d9f8", "message": "Use deposit model manager for deposit jobs", "committedDate": "2020-08-28T22:44:22Z", "type": "commit"}, {"oid": "264ba2f9da8bf5029675070f638aee929f29d2f5", "url": "https://github.com/UNC-Libraries/box-c/commit/264ba2f9da8bf5029675070f638aee929f29d2f5", "message": "Retain reference to dataset along with model via a decorator pattern, so that dataset won't be lost while the model is in use and in case the dataset is needed locally. Update tests to use model manager instead of dataset directly. Close the datasets when the deposit stops for any reason", "committedDate": "2020-09-01T20:18:34Z", "type": "commit"}, {"oid": "59fede3aed27d4310e48f96fe52a0c5cd2588a27", "url": "https://github.com/UNC-Libraries/box-c/commit/59fede3aed27d4310e48f96fe52a0c5cd2588a27", "message": "Remove dataset cache, as jena is doing so internally. Work directly against returneddatasets in deposit jobs instead of relying on cache.", "committedDate": "2020-09-02T18:35:48Z", "type": "commit"}, {"oid": "c9fe6fcd9d3d56c9836e79184aad8acaf890693e", "url": "https://github.com/UNC-Libraries/box-c/commit/c9fe6fcd9d3d56c9836e79184aad8acaf890693e", "message": "Store individual tdb directories per deposit inside a tdb directory instead of in the deposit directories so that they don't prevent the deposits from being cleaned up in systems that hold file handles to the tdb files. Add method to cleanup empty tdb directories during startup", "committedDate": "2020-09-02T21:49:48Z", "type": "commit"}, {"oid": "6cd12e5d4e6c895fb46758ac81e3a5bef8a6a1ae", "url": "https://github.com/UNC-Libraries/box-c/commit/6cd12e5d4e6c895fb46758ac81e3a5bef8a6a1ae", "message": "Fix logging", "committedDate": "2020-09-03T14:08:39Z", "type": "commit"}, {"oid": "6cd12e5d4e6c895fb46758ac81e3a5bef8a6a1ae", "url": "https://github.com/UNC-Libraries/box-c/commit/6cd12e5d4e6c895fb46758ac81e3a5bef8a6a1ae", "message": "Fix logging", "committedDate": "2020-09-03T14:08:39Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIyMjc4Mw==", "url": "https://github.com/UNC-Libraries/box-c/pull/1088#discussion_r483222783", "bodyText": "Should this variant of the method not worry about checking if the dataset is null and just assume it is? Then there's no need to pass it in \"null\".", "author": "lfarrell", "createdAt": "2020-09-03T20:02:37Z", "path": "persistence/src/main/java/edu/unc/lib/dl/persist/services/deposit/DepositModelManager.java", "diffHunk": "@@ -0,0 +1,479 @@\n+/**\n+ * Copyright 2008 The University of North Carolina at Chapel Hill\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *         http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package edu.unc.lib.dl.persist.services.deposit;\n+\n+import static org.apache.jena.rdf.model.ModelFactory.createDefaultModel;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.io.PrintWriter;\n+import java.io.Writer;\n+import java.nio.file.DirectoryNotEmptyException;\n+import java.nio.file.DirectoryStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.List;\n+import java.util.concurrent.locks.Lock;\n+\n+import org.apache.commons.csv.CSVFormat;\n+import org.apache.commons.csv.CSVPrinter;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.jena.query.Dataset;\n+import org.apache.jena.query.Query;\n+import org.apache.jena.query.QueryExecution;\n+import org.apache.jena.query.QueryExecutionFactory;\n+import org.apache.jena.query.QueryFactory;\n+import org.apache.jena.query.QuerySolution;\n+import org.apache.jena.query.ReadWrite;\n+import org.apache.jena.query.ResultSet;\n+import org.apache.jena.rdf.model.Bag;\n+import org.apache.jena.rdf.model.Model;\n+import org.apache.jena.rdf.model.Resource;\n+import org.apache.jena.tdb.TDBFactory;\n+import org.apache.jena.tdb.transaction.TDBTransactionException;\n+import org.apache.jena.update.UpdateAction;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.util.concurrent.Striped;\n+\n+import edu.unc.lib.dl.exceptions.InterruptedRuntimeException;\n+import edu.unc.lib.dl.exceptions.RepositoryException;\n+import edu.unc.lib.dl.fedora.PID;\n+\n+/**\n+ * Manager which provides synchronized access to a common deposit model, allowing\n+ * multiple transformation jobs to write to it at the same time.\n+ *\n+ * @author bbpennel\n+ */\n+public class DepositModelManager {\n+\n+    private static final Logger log = LoggerFactory.getLogger(DepositModelManager.class);\n+    private static final int DEPOSIT_LOCK_STRIPES = 5;\n+\n+    private Path tdbBasePath;\n+    // Locks to prevent simultaneous attempts to get the same dataset\n+    private Striped<Lock> depositLocker;\n+\n+    /**\n+     * Construct a deposit model manager\n+     * @param tdbBaseDir path to the tdb directory\n+     */\n+    public DepositModelManager(String tdbBaseDir) {\n+        this(Paths.get(tdbBaseDir));\n+    }\n+\n+    /**\n+     * Construct and initialize a deposit model manager\n+     * @param depositsPtdbBasePathath\n+     */\n+    public DepositModelManager(Path tdbBasePath) {\n+        this();\n+        this.tdbBasePath = tdbBasePath;\n+    }\n+\n+    /**\n+     * Cleanup leftover empty dataset directories in the tdb directory\n+     */\n+    public void cleanupEmptyDatasets() {\n+        try (DirectoryStream<Path> dirStream = Files.newDirectoryStream(tdbBasePath)) {\n+            for (Path childPath : dirStream) {\n+                // delete the child if it is both a directory and is empty\n+                if (Files.isDirectory(childPath)) {\n+                    try (DirectoryStream<Path> childDirStream = Files.newDirectoryStream(childPath)) {\n+                        if (!childDirStream.iterator().hasNext()) {\n+                            Files.delete(childPath);\n+                        }\n+                    } catch (DirectoryNotEmptyException e) {\n+                        // Ignore attempts to delete directories that contain files\n+                    }\n+                }\n+            }\n+        } catch (IOException e) {\n+            log.error(\"Failed to cleanup empty directories in {}\", tdbBasePath, e);\n+        }\n+    }\n+\n+    /**\n+     * Construct a deposit model manager\n+     */\n+    public DepositModelManager() {\n+        depositLocker = Striped.lazyWeakLock(DEPOSIT_LOCK_STRIPES);\n+    }\n+\n+    private Dataset loadDataset(PID depositPid) {\n+        long start = System.currentTimeMillis();\n+        Path datasetTdbPath = getDatasetPath(depositPid);\n+        if (Files.notExists(datasetTdbPath)) {\n+            try {\n+                Files.createDirectories(datasetTdbPath);\n+            } catch (IOException e) {\n+                throw new RepositoryException(\"Failed to create dataset directory for deposit\", e);\n+            }\n+        }\n+        Dataset dataset = TDBFactory.createDataset(datasetTdbPath.toString());\n+        log.debug(\"Loaded dataset for {} at {} in {}ms\",\n+                depositPid.getId(), datasetTdbPath, (System.currentTimeMillis() - start));\n+        return dataset;\n+    }\n+\n+    private Path getDatasetPath(PID depositPid) {\n+        return tdbBasePath.resolve(depositPid.getId());\n+    }\n+\n+    /**\n+     * Close the model and dataset for a deposit\n+     * @param depositPid\n+     */\n+    public void close(PID depositPid) {\n+        Path datasetTdbPath = getDatasetPath(depositPid);\n+        // Skip further closing if the dataset does not exist\n+        if (Files.notExists(datasetTdbPath)) {\n+            return;\n+        }\n+        Dataset dataset = loadDataset(depositPid);\n+        dataset.close();\n+    }\n+\n+    /**\n+     * Close the provided model\n+     * @param model must be a DatasetModelDecorator\n+     */\n+    public void close(Model model) {\n+        if (!(model instanceof DatasetModelDecorator)) {\n+            throw new IllegalArgumentException(\"Must provide a DatasetModelDecorator\");\n+        }\n+        ((DatasetModelDecorator) model).getDataset().close();\n+    }\n+\n+    /**\n+     * Start a write transaction for the deposit model/dataset\n+     *\n+     * @param depositPid pid of the deposit\n+     * @return\n+     */\n+    public Model getWriteModel(PID depositPid) {\n+        String depositUri = depositPid.getURI();\n+\n+        Lock lock = depositLocker.get(depositUri);\n+        try {\n+            lock.lockInterruptibly();\n+\n+            Dataset dataset = loadDataset(depositPid);\n+            return getWriteModel(depositUri, dataset);\n+        } catch (InterruptedException e) {\n+            throw new InterruptedRuntimeException(e);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    private Model getWriteModel(String depositUri, Dataset dataset) {\n+        long start = System.currentTimeMillis();\n+        try {\n+            dataset.begin(ReadWrite.WRITE);\n+            if (!dataset.containsNamedModel(depositUri)) {\n+                dataset.addNamedModel(depositUri, createDefaultModel());\n+            }\n+            return new DatasetModelDecorator(dataset.getNamedModel(depositUri), dataset);\n+        } catch (TDBTransactionException e) {\n+            if (e.getCause() instanceof InterruptedException) {\n+                throw new InterruptedRuntimeException(\"Interrupted while waiting for TDB write lock for deposit \"\n+                        + depositUri, e);\n+            }\n+            throw e;\n+        } finally {\n+            log.debug(\"Created write model for {} in {}ms\", depositUri, (System.currentTimeMillis() - start));\n+        }\n+    }\n+\n+    /**\n+     * Get a read only model for a deposit\n+     *\n+     * @param depositPid pid of the deposit\n+     * @return the model\n+     */\n+    public Model getReadModel(PID depositPid) {\n+        long start = System.currentTimeMillis();\n+        String depositUri = depositPid.getURI();\n+\n+        Lock lock = depositLocker.get(depositUri);\n+        try {\n+            lock.lockInterruptibly();\n+\n+            Dataset dataset = loadDataset(depositPid);\n+            dataset.begin(ReadWrite.READ);\n+            return new DatasetModelDecorator(dataset.getNamedModel(depositUri), dataset);\n+        } catch (InterruptedException e) {\n+            throw new InterruptedRuntimeException(e);\n+        } catch (TDBTransactionException e) {\n+            if (e.getCause() instanceof InterruptedException) {\n+                throw new InterruptedRuntimeException(\"Interrupted while waiting for TDB read lock for deposit \"\n+                        + depositUri, e);\n+            }\n+            throw e;\n+        } finally {\n+            lock.unlock();\n+            log.debug(\"Created write model for {} in {}ms\", depositUri, (System.currentTimeMillis() - start));\n+        }\n+    }\n+\n+    /**\n+     * Removes and closes the model for a deposit from the manager\n+     *\n+     * @param depositPid\n+     */\n+    public synchronized void removeModel(PID depositPid) {\n+        Dataset dataset = loadDataset(depositPid);\n+        removeModel(depositPid, dataset);\n+    }\n+\n+    /**\n+     * Removes and closes the model for the given dataset\n+     * @param depositPid\n+     * @param dataset\n+     */\n+    public void removeModel(PID depositPid, Dataset dataset) {\n+        String uri = depositPid.getURI();\n+        if (!dataset.isInTransaction()) {\n+            dataset.begin(ReadWrite.WRITE);\n+        }\n+        dataset.removeNamedModel(uri);\n+        dataset.commit();\n+        dataset.end();\n+        dataset.close();\n+\n+        Path datasetPath = getDatasetPath(depositPid);\n+        try {\n+            FileUtils.deleteDirectory(datasetPath.toFile());\n+        } catch (IOException e) {\n+            log.debug(\"Unable to delete TDB directory {}\", datasetPath);\n+        }\n+    }\n+\n+    /**\n+     * Add triples from the provided model to the deposit model\n+     *\n+     * @param depositPid pid of the deposit\n+     * @param model\n+     */\n+    public void addTriples(PID depositPid, Model model) {\n+        addTriples(depositPid, model, null, null);\n+    }\n+\n+    /**\n+     * Add triples from the provided model to the deposit model, inserting the\n+     * new resource as the child of the provided parent\n+     *\n+     * @param depositPid pid of the deposit\n+     * @param model\n+     * @param newPid\n+     * @param parentPid\n+     */\n+    public void addTriples(PID depositPid, Model model, PID newPid, PID parentPid) {\n+        String depositUri = depositPid.getURI();\n+\n+        Lock lock = depositLocker.get(depositUri);\n+        try {\n+            lock.lockInterruptibly();\n+\n+            Dataset dataset = loadDataset(depositPid);\n+\n+            Model depositModel = getWriteModel(depositUri, dataset);\n+            try {\n+                // Insert reference from parent to new resource\n+                if (newPid != null && parentPid != null) {\n+                    Resource newResc = model.getResource(newPid.getRepositoryPath());\n+                    Bag parentBag = depositModel.getBag(parentPid.getRepositoryPath());\n+\n+                    parentBag.add(newResc);\n+                }\n+\n+                log.debug(\"Adding triples to deposit model: {}\", model);\n+                depositModel.add(model);\n+                dataset.commit();\n+            } finally {\n+                dataset.end();\n+            }\n+        } catch (InterruptedException e) {\n+            throw new InterruptedRuntimeException(e);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    /**\n+     * Perform a sparql update against the deposit model\n+     *\n+     * @param depositPid pid of the deposit\n+     * @param query sparql update query\n+     */\n+    public void performUpdate(PID depositPid, String query) {\n+        String depositUri = depositPid.getURI();\n+\n+        Lock lock = depositLocker.get(depositUri);\n+        try {\n+            lock.lockInterruptibly();\n+\n+            Dataset dataset = loadDataset(depositPid);\n+            Model depositModel = getWriteModel(depositUri, dataset);\n+            try {\n+                UpdateAction.parseExecute(query, depositModel);\n+                dataset.commit();\n+            } finally {\n+                dataset.end();\n+            }\n+        } catch (InterruptedException e) {\n+            throw new InterruptedRuntimeException(e);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    /**\n+     * Perform a sparql query against the deposit model\n+     *\n+     * @param depositPid pid of the deposit\n+     * @param queryString sparql query\n+     * @return results of the query, serialized as csv in an output stream\n+     * @throws IOException\n+     */\n+    public String performQuery(PID depositPid, String queryString) throws IOException {\n+        Model depositModel = getReadModel(depositPid);\n+\n+        Query query = QueryFactory.create(queryString);\n+\n+        ByteArrayOutputStream outStream = new ByteArrayOutputStream();\n+\n+        try (\n+                QueryExecution qexec = QueryExecutionFactory.create(query, depositModel);\n+                Writer writer = new PrintWriter(outStream);\n+                CSVPrinter printer = new CSVPrinter(writer, CSVFormat.DEFAULT);\n+                ) {\n+            ResultSet results = qexec.execSelect();\n+            List<String> varNames = results.getResultVars();\n+\n+            while (results.hasNext()) {\n+                QuerySolution soln = results.nextSolution();\n+\n+                for (String varName : varNames) {\n+                    printer.print(soln.get(varName));\n+                }\n+                printer.println();\n+            }\n+        }\n+\n+        return outStream.toString(\"UTF-8\");\n+    }\n+\n+    /**\n+     * Commit changes to the dataset\n+     * @param depositPid pid of the deposit\n+     * @param dataset dataset to commit, or null, in which case the dataset will be retrieved\n+     * @param endTx end the transaction if true\n+     */\n+    public void commit(PID depositPid, Dataset dataset, boolean endTx) {\n+        if (dataset == null) {\n+            commit(depositPid, endTx);\n+        } else {\n+            commit(dataset, endTx);\n+        }\n+    }\n+\n+    /**\n+     * Commit changes to the dataset for the specified deposit\n+     * @param depositPid pid of the deposit\n+     * @param endTx end the transaction if true\n+     */\n+    public void commit(PID depositPid, boolean endTx) {\n+        String depositUri = depositPid.getURI();\n+\n+        Lock lock = depositLocker.get(depositUri);\n+        try {\n+            lock.lockInterruptibly();\n+\n+            Dataset dataset = loadDataset(depositPid);\n+            commit(dataset, endTx);\n+        } catch (InterruptedException e) {\n+            throw new InterruptedRuntimeException(e);\n+        } finally {\n+            lock.unlock();\n+        }\n+    }\n+\n+    private void commit(Dataset dataset, boolean endTx) {\n+        if (dataset.isInTransaction()) {\n+            dataset.commit();\n+            if (endTx) {\n+                dataset.end();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Commit or abort changes in the dataset\n+     * @param depositPid pid of the deposit\n+     * @param dataset dataset to commit, or null, in which case the dataset will be retrieved\n+     * @param abort if true, the commit will be aborted\n+     */\n+    public void commitOrAbort(PID depositPid, Dataset dataset, boolean abort) {", "originalCommit": "6cd12e5d4e6c895fb46758ac81e3a5bef8a6a1ae", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIyNjc4Mw==", "url": "https://github.com/UNC-Libraries/box-c/pull/1088#discussion_r483226783", "bodyText": "JavaDoc and method signature don't match", "author": "lfarrell", "createdAt": "2020-09-03T20:11:00Z", "path": "persistence/src/main/java/edu/unc/lib/dl/persist/services/deposit/DepositModelManager.java", "diffHunk": "@@ -0,0 +1,479 @@\n+/**\n+ * Copyright 2008 The University of North Carolina at Chapel Hill\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *         http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package edu.unc.lib.dl.persist.services.deposit;\n+\n+import static org.apache.jena.rdf.model.ModelFactory.createDefaultModel;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.io.PrintWriter;\n+import java.io.Writer;\n+import java.nio.file.DirectoryNotEmptyException;\n+import java.nio.file.DirectoryStream;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.List;\n+import java.util.concurrent.locks.Lock;\n+\n+import org.apache.commons.csv.CSVFormat;\n+import org.apache.commons.csv.CSVPrinter;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.jena.query.Dataset;\n+import org.apache.jena.query.Query;\n+import org.apache.jena.query.QueryExecution;\n+import org.apache.jena.query.QueryExecutionFactory;\n+import org.apache.jena.query.QueryFactory;\n+import org.apache.jena.query.QuerySolution;\n+import org.apache.jena.query.ReadWrite;\n+import org.apache.jena.query.ResultSet;\n+import org.apache.jena.rdf.model.Bag;\n+import org.apache.jena.rdf.model.Model;\n+import org.apache.jena.rdf.model.Resource;\n+import org.apache.jena.tdb.TDBFactory;\n+import org.apache.jena.tdb.transaction.TDBTransactionException;\n+import org.apache.jena.update.UpdateAction;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.util.concurrent.Striped;\n+\n+import edu.unc.lib.dl.exceptions.InterruptedRuntimeException;\n+import edu.unc.lib.dl.exceptions.RepositoryException;\n+import edu.unc.lib.dl.fedora.PID;\n+\n+/**\n+ * Manager which provides synchronized access to a common deposit model, allowing\n+ * multiple transformation jobs to write to it at the same time.\n+ *\n+ * @author bbpennel\n+ */\n+public class DepositModelManager {\n+\n+    private static final Logger log = LoggerFactory.getLogger(DepositModelManager.class);\n+    private static final int DEPOSIT_LOCK_STRIPES = 5;\n+\n+    private Path tdbBasePath;\n+    // Locks to prevent simultaneous attempts to get the same dataset\n+    private Striped<Lock> depositLocker;\n+\n+    /**\n+     * Construct a deposit model manager\n+     * @param tdbBaseDir path to the tdb directory\n+     */\n+    public DepositModelManager(String tdbBaseDir) {\n+        this(Paths.get(tdbBaseDir));\n+    }\n+\n+    /**\n+     * Construct and initialize a deposit model manager\n+     * @param depositsPtdbBasePathath\n+     */\n+    public DepositModelManager(Path tdbBasePath) {", "originalCommit": "6cd12e5d4e6c895fb46758ac81e3a5bef8a6a1ae", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIzNjY0OA==", "url": "https://github.com/UNC-Libraries/box-c/pull/1088#discussion_r483236648", "bodyText": "Javadoc is butchered. Let me fix that", "author": "bbpennel", "createdAt": "2020-09-03T20:28:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzIyNjc4Mw=="}], "type": "inlineReview"}, {"oid": "8482900544d58b666f2de2b0f10c0d3d0ac5e219", "url": "https://github.com/UNC-Libraries/box-c/commit/8482900544d58b666f2de2b0f10c0d3d0ac5e219", "message": "Switch from write to read transaction", "committedDate": "2020-09-04T15:16:14Z", "type": "commit"}, {"oid": "545c21baeb54408ac6db41711901f2f753f74a8c", "url": "https://github.com/UNC-Libraries/box-c/commit/545c21baeb54408ac6db41711901f2f753f74a8c", "message": "Add method for performing a set of actions within a write transaction, then immediately committing. Perform each update in TransferBinaries job within an individual write transaction", "committedDate": "2020-09-04T16:24:21Z", "type": "commit"}, {"oid": "3d22c472830204f933ab6f9b1e3ffcc4e434a2cd", "url": "https://github.com/UNC-Libraries/box-c/commit/3d22c472830204f933ab6f9b1e3ffcc4e434a2cd", "message": "Initial deposit normalization jobs now build the model in memory and then open a write tx to commit it all at once. Deposit jobs which modify the model now keep read only models and then perform their updates in short lived transactions. Added a helper method for serializing models to ttl", "committedDate": "2020-09-04T18:18:18Z", "type": "commit"}, {"oid": "52df5ba4c621454439f434db6e24a535a02b6c7a", "url": "https://github.com/UNC-Libraries/box-c/commit/52df5ba4c621454439f434db6e24a535a02b6c7a", "message": "Switch back to using a single centralized deposit dataset. Add an in-memory version of the dataset manager, use it for tests to speed them up", "committedDate": "2020-09-04T23:19:21Z", "type": "commit"}, {"oid": "d77f1296a51c8cc7998d0f7e4e774ba4aab0303c", "url": "https://github.com/UNC-Libraries/box-c/commit/d77f1296a51c8cc7998d0f7e4e774ba4aab0303c", "message": "Cleanup and reverting migration commands to using tdb dir", "committedDate": "2020-09-08T13:23:58Z", "type": "commit"}, {"oid": "c5afa10c9abff436ae8ff3411abad5382ca239f3", "url": "https://github.com/UNC-Libraries/box-c/commit/c5afa10c9abff436ae8ff3411abad5382ca239f3", "message": "Fix directory used", "committedDate": "2020-09-08T15:17:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTYzNjQ0Mw==", "url": "https://github.com/UNC-Libraries/box-c/pull/1088#discussion_r485636443", "bodyText": "Should this be below the gov imports?", "author": "lfarrell", "createdAt": "2020-09-09T14:02:11Z", "path": "deposit/src/main/java/edu/unc/lib/deposit/normalize/BagIt2N3BagJob.java", "diffHunk": "@@ -32,11 +32,13 @@\n import java.util.Set;\n \n import org.apache.jena.rdf.model.Model;\n+import org.apache.jena.rdf.model.ModelFactory;\n import org.apache.jena.rdf.model.Property;\n import org.apache.jena.rdf.model.Resource;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import edu.unc.lib.dl.util.RedisWorkerConstants.DepositField;", "originalCommit": "c5afa10c9abff436ae8ff3411abad5382ca239f3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTY0NDUzNA==", "url": "https://github.com/UNC-Libraries/box-c/pull/1088#discussion_r485644534", "bodyText": "Answered my own question", "author": "lfarrell", "createdAt": "2020-09-09T14:12:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTYzNjQ0Mw=="}], "type": "inlineReview"}, {"oid": "575b40f87dff77b5b2d9744f6ab207aa2790917b", "url": "https://github.com/UNC-Libraries/box-c/commit/575b40f87dff77b5b2d9744f6ab207aa2790917b", "message": "Fix JavaDoc", "committedDate": "2020-09-09T14:16:58Z", "type": "commit"}]}