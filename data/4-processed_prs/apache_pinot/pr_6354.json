{"pr_number": 6354, "pr_title": "Ingestion resource with APIs for ingestion via file/URI", "pr_createdAt": "2020-12-15T03:39:52Z", "pr_url": "https://github.com/apache/pinot/pull/6354", "timeline": [{"oid": "e0161765a76210556294fd93430c60fcdbe2cbb1", "url": "https://github.com/apache/pinot/commit/e0161765a76210556294fd93430c60fcdbe2cbb1", "message": "Ingestion resource with APIs for ingestion via file/URI", "committedDate": "2020-12-15T03:18:24Z", "type": "commit"}, {"oid": "ec99e833c9c0b4de988c7a3b287442322ba26370", "url": "https://github.com/apache/pinot/commit/ec99e833c9c0b4de988c7a3b287442322ba26370", "message": "remove extra spaces", "committedDate": "2020-12-15T03:39:28Z", "type": "commit"}, {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "url": "https://github.com/apache/pinot/commit/3f446dc039c65db41efd9f07f93692dc1d1b0e93", "message": "Test with csv reader configs", "committedDate": "2020-12-16T03:19:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MDc4Nw==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545560787", "bodyText": "Add sample calls here. will be great if it can show up as part of swagger", "author": "kishoreg", "createdAt": "2020-12-18T04:08:19Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotIngestionRestletResource.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.api.resources;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.base.Preconditions;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import java.net.URI;\n+import java.util.Map;\n+import javax.inject.Inject;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.container.AsyncResponse;\n+import javax.ws.rs.container.Suspended;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.controller.util.FileIngestionHelper;\n+import org.apache.pinot.controller.util.FileIngestionHelper.DataPayload;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.builder.TableNameBuilder;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.glassfish.jersey.server.ManagedAsync;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * APIs related to ingestion", "originalCommit": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MTAwNA==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545561004", "bodyText": "missing async response doc", "author": "kishoreg", "createdAt": "2020-12-18T04:09:09Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotIngestionRestletResource.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.api.resources;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.base.Preconditions;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import java.net.URI;\n+import java.util.Map;\n+import javax.inject.Inject;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.container.AsyncResponse;\n+import javax.ws.rs.container.Suspended;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.controller.util.FileIngestionHelper;\n+import org.apache.pinot.controller.util.FileIngestionHelper.DataPayload;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.builder.TableNameBuilder;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.glassfish.jersey.server.ManagedAsync;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * APIs related to ingestion\n+ */\n+@Api(tags = Constants.TABLE_TAG)\n+@Path(\"/\")\n+public class PinotIngestionRestletResource {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PinotIngestionRestletResource.class);\n+\n+  @Inject\n+  PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  @Inject\n+  ControllerConf _controllerConf;\n+\n+  /**\n+   * API to upload a file and ingest it into a Pinot table\n+   * @param tableName Name of the table to upload to\n+   * @param batchConfigMapStr Batch config Map as a string. Provide the\n+   *                          input format (inputFormat)\n+   *                          record reader configs (recordReader.prop.<property>),\n+   *                          fs class name (input.fs.className)\n+   *                          fs configs (input.fs.prop.<property>)\n+   * @param fileUpload file to upload as a multipart", "originalCommit": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MjAwNg==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545562006", "bodyText": "add some documentation on what the caller should expect. Will this call return something immediately or wait until the operation is done", "author": "kishoreg", "createdAt": "2020-12-18T04:13:25Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotIngestionRestletResource.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.api.resources;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.base.Preconditions;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import java.net.URI;\n+import java.util.Map;\n+import javax.inject.Inject;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.container.AsyncResponse;\n+import javax.ws.rs.container.Suspended;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.controller.util.FileIngestionHelper;\n+import org.apache.pinot.controller.util.FileIngestionHelper.DataPayload;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.builder.TableNameBuilder;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.glassfish.jersey.server.ManagedAsync;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * APIs related to ingestion\n+ */\n+@Api(tags = Constants.TABLE_TAG)\n+@Path(\"/\")\n+public class PinotIngestionRestletResource {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PinotIngestionRestletResource.class);\n+\n+  @Inject\n+  PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  @Inject\n+  ControllerConf _controllerConf;\n+\n+  /**\n+   * API to upload a file and ingest it into a Pinot table", "originalCommit": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MjIwNA==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545562204", "bodyText": "this should be tableNameWithType right", "author": "kishoreg", "createdAt": "2020-12-18T04:14:12Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotIngestionRestletResource.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.api.resources;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.base.Preconditions;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import java.net.URI;\n+import java.util.Map;\n+import javax.inject.Inject;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.container.AsyncResponse;\n+import javax.ws.rs.container.Suspended;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.controller.util.FileIngestionHelper;\n+import org.apache.pinot.controller.util.FileIngestionHelper.DataPayload;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.builder.TableNameBuilder;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.glassfish.jersey.server.ManagedAsync;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * APIs related to ingestion\n+ */\n+@Api(tags = Constants.TABLE_TAG)\n+@Path(\"/\")\n+public class PinotIngestionRestletResource {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PinotIngestionRestletResource.class);\n+\n+  @Inject\n+  PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  @Inject\n+  ControllerConf _controllerConf;\n+\n+  /**\n+   * API to upload a file and ingest it into a Pinot table\n+   * @param tableName Name of the table to upload to", "originalCommit": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjgxNDQyMg==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r546814422", "bodyText": "i was not enforcing type. As discussed offline as well, was planning to allow table name with or without type, and assume OFFLINE if no suffix provided.\nBut changing this to enforce type, because this might come to bite us when we support realtime table uploads", "author": "npawar", "createdAt": "2020-12-21T16:49:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MjIwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MjI3OA==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545562278", "bodyText": "tableName ->tableNameWithType", "author": "kishoreg", "createdAt": "2020-12-18T04:14:36Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotIngestionRestletResource.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.api.resources;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.base.Preconditions;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import java.net.URI;\n+import java.util.Map;\n+import javax.inject.Inject;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.container.AsyncResponse;\n+import javax.ws.rs.container.Suspended;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.controller.util.FileIngestionHelper;\n+import org.apache.pinot.controller.util.FileIngestionHelper.DataPayload;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.builder.TableNameBuilder;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.glassfish.jersey.server.ManagedAsync;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * APIs related to ingestion\n+ */\n+@Api(tags = Constants.TABLE_TAG)\n+@Path(\"/\")\n+public class PinotIngestionRestletResource {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PinotIngestionRestletResource.class);\n+\n+  @Inject\n+  PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  @Inject\n+  ControllerConf _controllerConf;\n+\n+  /**\n+   * API to upload a file and ingest it into a Pinot table\n+   * @param tableName Name of the table to upload to\n+   * @param batchConfigMapStr Batch config Map as a string. Provide the\n+   *                          input format (inputFormat)\n+   *                          record reader configs (recordReader.prop.<property>),\n+   *                          fs class name (input.fs.className)\n+   *                          fs configs (input.fs.prop.<property>)\n+   * @param fileUpload file to upload as a multipart\n+   */\n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.MULTIPART_FORM_DATA)\n+  @Path(\"/ingestFromFile\")\n+  @ApiOperation(value = \"Ingest a file\", notes = \"Creates a segment using given file and pushes it to Pinot\")\n+  public void ingestFromFile(\n+      @ApiParam(value = \"Name of the table to upload the file to\", required = true) @QueryParam(\"tableName\") String tableName,\n+      @ApiParam(value = \"Batch config map as string\", required = true) @QueryParam(\"batchConfigMapStr\") String batchConfigMapStr,\n+      FormDataMultiPart fileUpload,\n+      @Suspended final AsyncResponse asyncResponse) {\n+    try {\n+      asyncResponse.resume(ingestData(tableName, batchConfigMapStr, new DataPayload(fileUpload)));\n+    } catch (Exception e) {\n+      asyncResponse.resume(new ControllerApplicationException(LOGGER,\n+          String.format(\"Caught exception when ingesting file into table: %s. %s\", tableName, e.getMessage()),\n+          Response.Status.INTERNAL_SERVER_ERROR, e));\n+    }\n+  }\n+\n+  /**\n+   * API to ingest a file into Pinot from a URI\n+   * @param tableName Name of the table to upload to\n+   * @param batchConfigMapStr Batch config Map as a string. Provide the\n+   *                          input format (inputFormat)\n+   *                          record reader configs (recordReader.prop.<property>),\n+   *                          fs class name (input.fs.className)\n+   *                          fs configs (input.fs.prop.<property>)\n+   * @param sourceURIStr URI for input file to ingest\n+   */\n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.MULTIPART_FORM_DATA)\n+  @Path(\"/ingestFromURI\")\n+  @ApiOperation(value = \"Ingest from the given URI\", notes = \"Creates a segment using file at the given URI and pushes it to Pinot\")\n+  public void ingestFromURI(\n+      @ApiParam(value = \"Name of the table to upload the file to\", required = true) @QueryParam(\"tableName\") String tableName,\n+      @ApiParam(value = \"Batch config map as string\", required = true) @QueryParam(\"batchConfigMapStr\") String batchConfigMapStr,\n+      @ApiParam(value = \"URI\", required = true) @QueryParam(\"sourceURIStr\") String sourceURIStr,\n+      @Suspended final AsyncResponse asyncResponse) {\n+    try {\n+      asyncResponse.resume(ingestData(tableName, batchConfigMapStr, new DataPayload(new URI(sourceURIStr))));\n+    } catch (Exception e) {\n+      asyncResponse.resume(new ControllerApplicationException(LOGGER,\n+          String.format(\"Caught exception when ingesting file into table: %s. %s\", tableName, e.getMessage()),\n+          Response.Status.INTERNAL_SERVER_ERROR, e));\n+    }\n+  }\n+\n+  private SuccessResponse ingestData(String tableName, String batchConfigMapStr, DataPayload payload)", "originalCommit": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MjUzMg==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545562532", "bodyText": "I thought the input is already tableName with Type?", "author": "kishoreg", "createdAt": "2020-12-18T04:15:37Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotIngestionRestletResource.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.api.resources;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.base.Preconditions;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import java.net.URI;\n+import java.util.Map;\n+import javax.inject.Inject;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.container.AsyncResponse;\n+import javax.ws.rs.container.Suspended;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.controller.util.FileIngestionHelper;\n+import org.apache.pinot.controller.util.FileIngestionHelper.DataPayload;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.builder.TableNameBuilder;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.glassfish.jersey.server.ManagedAsync;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * APIs related to ingestion\n+ */\n+@Api(tags = Constants.TABLE_TAG)\n+@Path(\"/\")\n+public class PinotIngestionRestletResource {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PinotIngestionRestletResource.class);\n+\n+  @Inject\n+  PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  @Inject\n+  ControllerConf _controllerConf;\n+\n+  /**\n+   * API to upload a file and ingest it into a Pinot table\n+   * @param tableName Name of the table to upload to\n+   * @param batchConfigMapStr Batch config Map as a string. Provide the\n+   *                          input format (inputFormat)\n+   *                          record reader configs (recordReader.prop.<property>),\n+   *                          fs class name (input.fs.className)\n+   *                          fs configs (input.fs.prop.<property>)\n+   * @param fileUpload file to upload as a multipart\n+   */\n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.MULTIPART_FORM_DATA)\n+  @Path(\"/ingestFromFile\")\n+  @ApiOperation(value = \"Ingest a file\", notes = \"Creates a segment using given file and pushes it to Pinot\")\n+  public void ingestFromFile(\n+      @ApiParam(value = \"Name of the table to upload the file to\", required = true) @QueryParam(\"tableName\") String tableName,\n+      @ApiParam(value = \"Batch config map as string\", required = true) @QueryParam(\"batchConfigMapStr\") String batchConfigMapStr,\n+      FormDataMultiPart fileUpload,\n+      @Suspended final AsyncResponse asyncResponse) {\n+    try {\n+      asyncResponse.resume(ingestData(tableName, batchConfigMapStr, new DataPayload(fileUpload)));\n+    } catch (Exception e) {\n+      asyncResponse.resume(new ControllerApplicationException(LOGGER,\n+          String.format(\"Caught exception when ingesting file into table: %s. %s\", tableName, e.getMessage()),\n+          Response.Status.INTERNAL_SERVER_ERROR, e));\n+    }\n+  }\n+\n+  /**\n+   * API to ingest a file into Pinot from a URI\n+   * @param tableName Name of the table to upload to\n+   * @param batchConfigMapStr Batch config Map as a string. Provide the\n+   *                          input format (inputFormat)\n+   *                          record reader configs (recordReader.prop.<property>),\n+   *                          fs class name (input.fs.className)\n+   *                          fs configs (input.fs.prop.<property>)\n+   * @param sourceURIStr URI for input file to ingest\n+   */\n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.MULTIPART_FORM_DATA)\n+  @Path(\"/ingestFromURI\")\n+  @ApiOperation(value = \"Ingest from the given URI\", notes = \"Creates a segment using file at the given URI and pushes it to Pinot\")\n+  public void ingestFromURI(\n+      @ApiParam(value = \"Name of the table to upload the file to\", required = true) @QueryParam(\"tableName\") String tableName,\n+      @ApiParam(value = \"Batch config map as string\", required = true) @QueryParam(\"batchConfigMapStr\") String batchConfigMapStr,\n+      @ApiParam(value = \"URI\", required = true) @QueryParam(\"sourceURIStr\") String sourceURIStr,\n+      @Suspended final AsyncResponse asyncResponse) {\n+    try {\n+      asyncResponse.resume(ingestData(tableName, batchConfigMapStr, new DataPayload(new URI(sourceURIStr))));\n+    } catch (Exception e) {\n+      asyncResponse.resume(new ControllerApplicationException(LOGGER,\n+          String.format(\"Caught exception when ingesting file into table: %s. %s\", tableName, e.getMessage()),\n+          Response.Status.INTERNAL_SERVER_ERROR, e));\n+    }\n+  }\n+\n+  private SuccessResponse ingestData(String tableName, String batchConfigMapStr, DataPayload payload)\n+      throws Exception {\n+    TableType tableType = TableNameBuilder.getTableTypeFromTableName(tableName);\n+    Preconditions\n+        .checkState(TableType.REALTIME != tableType, \"Cannot ingest file into REALTIME table: %s\", tableName);\n+    String tableNameWithType = TableNameBuilder.forType(TableType.OFFLINE).tableNameWithType(tableName);", "originalCommit": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MzEzMQ==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545563131", "bodyText": "this is a good class, can we take only the info needed from ControllerConf. This can be used in other places", "author": "kishoreg", "createdAt": "2020-12-18T04:17:47Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/FileIngestionHelper.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.net.URI;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.common.utils.TarGzCompressionUtils;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.api.resources.SuccessResponse;\n+import org.apache.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A driver for the ingestion process of the provided file.\n+ * Responsible for copying the file locally, building a segment and uploading it to the controller.\n+ */\n+public class FileIngestionHelper {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(FileIngestionHelper.class);\n+\n+  private static final String WORKING_DIR_PREFIX = \"working_dir\";\n+  private static final String INPUT_DATA_DIR = \"input_data_dir\";\n+  private static final String OUTPUT_SEGMENT_DIR = \"output_segment_dir\";\n+  private static final String SEGMENT_TAR_DIR = \"segment_tar_dir\";\n+  private static final String DATA_FILE_PREFIX = \"data\";\n+\n+  private final TableConfig _tableConfig;\n+  private final Schema _schema;\n+  private final BatchConfig _batchConfig;\n+  private final ControllerConf _controllerConf;\n+\n+  public FileIngestionHelper(TableConfig tableConfig, Schema schema,", "originalCommit": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MzM2Ng==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545563366", "bodyText": "better to log this somewhere for debugging purpose", "author": "kishoreg", "createdAt": "2020-12-18T04:18:45Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/FileIngestionHelper.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.net.URI;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.common.utils.TarGzCompressionUtils;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.api.resources.SuccessResponse;\n+import org.apache.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A driver for the ingestion process of the provided file.\n+ * Responsible for copying the file locally, building a segment and uploading it to the controller.\n+ */\n+public class FileIngestionHelper {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(FileIngestionHelper.class);\n+\n+  private static final String WORKING_DIR_PREFIX = \"working_dir\";\n+  private static final String INPUT_DATA_DIR = \"input_data_dir\";\n+  private static final String OUTPUT_SEGMENT_DIR = \"output_segment_dir\";\n+  private static final String SEGMENT_TAR_DIR = \"segment_tar_dir\";\n+  private static final String DATA_FILE_PREFIX = \"data\";\n+\n+  private final TableConfig _tableConfig;\n+  private final Schema _schema;\n+  private final BatchConfig _batchConfig;\n+  private final ControllerConf _controllerConf;\n+\n+  public FileIngestionHelper(TableConfig tableConfig, Schema schema,\n+      BatchConfig batchConfig, ControllerConf controllerConf) {\n+    _tableConfig = tableConfig;\n+    _schema = schema;\n+    _batchConfig = batchConfig;\n+    _controllerConf = controllerConf;\n+  }\n+\n+  /**\n+   * Creates a segment using the provided data file/URI and uploads to Pinot\n+   */\n+  public SuccessResponse buildSegmentAndPush(DataPayload payload)\n+      throws Exception {\n+    String tableNameWithType = _tableConfig.getTableName();\n+\n+    // Setup working dir\n+    File workingDir = new File(FileUtils.getTempDirectory(),\n+        String.format(\"%s_%s_%d\", WORKING_DIR_PREFIX, tableNameWithType, System.currentTimeMillis()));\n+    File inputDir = new File(workingDir, INPUT_DATA_DIR);\n+    File outputDir = new File(workingDir, OUTPUT_SEGMENT_DIR);\n+    File segmentTarDir = new File(workingDir, SEGMENT_TAR_DIR);\n+    try {\n+      Preconditions\n+          .checkState(inputDir.mkdirs(), \"Could not create directory for downloading input file locally: %s\", inputDir);\n+      Preconditions.checkState(segmentTarDir.mkdirs(), \"Could not create directory for segment tar file: %s\", inputDir);\n+\n+      // Copy file to local working dir\n+      File inputFile =\n+          new File(inputDir, String.format(\"%s.%s\", DATA_FILE_PREFIX, _batchConfig.getInputFormat().toString().toLowerCase()));\n+      if (payload._dataSource.equals(DataSource.URI)) {\n+        FileIngestionUtils.copyURIToLocal(_batchConfig, payload._uri, inputFile);\n+      } else {\n+        FileIngestionUtils.copyMultipartToLocal(payload._multiPart, inputFile);\n+      }\n+\n+      // Build segment\n+      SegmentGeneratorConfig segmentGeneratorConfig =", "originalCommit": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MzYxOQ==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545563619", "bodyText": "what happens if the segment already exists? can we say replace if it already exists?", "author": "kishoreg", "createdAt": "2020-12-18T04:19:47Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/FileIngestionHelper.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.net.URI;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.common.utils.TarGzCompressionUtils;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.api.resources.SuccessResponse;\n+import org.apache.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A driver for the ingestion process of the provided file.\n+ * Responsible for copying the file locally, building a segment and uploading it to the controller.\n+ */\n+public class FileIngestionHelper {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(FileIngestionHelper.class);\n+\n+  private static final String WORKING_DIR_PREFIX = \"working_dir\";\n+  private static final String INPUT_DATA_DIR = \"input_data_dir\";\n+  private static final String OUTPUT_SEGMENT_DIR = \"output_segment_dir\";\n+  private static final String SEGMENT_TAR_DIR = \"segment_tar_dir\";\n+  private static final String DATA_FILE_PREFIX = \"data\";\n+\n+  private final TableConfig _tableConfig;\n+  private final Schema _schema;\n+  private final BatchConfig _batchConfig;\n+  private final ControllerConf _controllerConf;\n+\n+  public FileIngestionHelper(TableConfig tableConfig, Schema schema,\n+      BatchConfig batchConfig, ControllerConf controllerConf) {\n+    _tableConfig = tableConfig;\n+    _schema = schema;\n+    _batchConfig = batchConfig;\n+    _controllerConf = controllerConf;\n+  }\n+\n+  /**\n+   * Creates a segment using the provided data file/URI and uploads to Pinot\n+   */\n+  public SuccessResponse buildSegmentAndPush(DataPayload payload)\n+      throws Exception {\n+    String tableNameWithType = _tableConfig.getTableName();\n+\n+    // Setup working dir\n+    File workingDir = new File(FileUtils.getTempDirectory(),\n+        String.format(\"%s_%s_%d\", WORKING_DIR_PREFIX, tableNameWithType, System.currentTimeMillis()));\n+    File inputDir = new File(workingDir, INPUT_DATA_DIR);\n+    File outputDir = new File(workingDir, OUTPUT_SEGMENT_DIR);\n+    File segmentTarDir = new File(workingDir, SEGMENT_TAR_DIR);\n+    try {\n+      Preconditions\n+          .checkState(inputDir.mkdirs(), \"Could not create directory for downloading input file locally: %s\", inputDir);\n+      Preconditions.checkState(segmentTarDir.mkdirs(), \"Could not create directory for segment tar file: %s\", inputDir);\n+\n+      // Copy file to local working dir\n+      File inputFile =\n+          new File(inputDir, String.format(\"%s.%s\", DATA_FILE_PREFIX, _batchConfig.getInputFormat().toString().toLowerCase()));\n+      if (payload._dataSource.equals(DataSource.URI)) {\n+        FileIngestionUtils.copyURIToLocal(_batchConfig, payload._uri, inputFile);\n+      } else {\n+        FileIngestionUtils.copyMultipartToLocal(payload._multiPart, inputFile);\n+      }\n+\n+      // Build segment\n+      SegmentGeneratorConfig segmentGeneratorConfig =\n+          FileIngestionUtils.generateSegmentGeneratorConfig(_tableConfig, _batchConfig, _schema, inputFile, outputDir);\n+      String segmentName = FileIngestionUtils.buildSegment(segmentGeneratorConfig);\n+\n+      // Tar and push segment\n+      File segmentTarFile =\n+          new File(segmentTarDir, segmentName + org.apache.pinot.spi.ingestion.batch.spec.Constants.TAR_GZ_FILE_EXT);\n+      TarGzCompressionUtils.createTarGzFile(new File(outputDir, segmentName), segmentTarFile);\n+      FileIngestionUtils", "originalCommit": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg5NzkyMg==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r546897922", "bodyText": "Anything that gets uploaded, will receive a unique segment name (tableName_mintime_maxtime_timestamp).\nIf a segment for a time range exists and user wishes to replace, they need to delete segment and upload again. Since this is meant as a quick test, it will be more common that users are uploading several files one by one, and they all have same time ranges. In this API we don't want the users to worry about providing a segment name generator etc, or doing some time column hacks to get unique names.", "author": "npawar", "createdAt": "2020-12-21T19:47:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MzYxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2NDM2Mg==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545564362", "bodyText": "will be good to provide the ability to configure the file.upload.dir as input this class. Useful for testing and also the controller can initialize this with a directory under the data.dir.", "author": "kishoreg", "createdAt": "2020-12-18T04:23:12Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/FileIngestionHelper.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.net.URI;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.common.utils.TarGzCompressionUtils;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.api.resources.SuccessResponse;\n+import org.apache.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A driver for the ingestion process of the provided file.\n+ * Responsible for copying the file locally, building a segment and uploading it to the controller.\n+ */\n+public class FileIngestionHelper {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(FileIngestionHelper.class);\n+\n+  private static final String WORKING_DIR_PREFIX = \"working_dir\";\n+  private static final String INPUT_DATA_DIR = \"input_data_dir\";\n+  private static final String OUTPUT_SEGMENT_DIR = \"output_segment_dir\";\n+  private static final String SEGMENT_TAR_DIR = \"segment_tar_dir\";\n+  private static final String DATA_FILE_PREFIX = \"data\";\n+\n+  private final TableConfig _tableConfig;\n+  private final Schema _schema;\n+  private final BatchConfig _batchConfig;\n+  private final ControllerConf _controllerConf;\n+\n+  public FileIngestionHelper(TableConfig tableConfig, Schema schema,\n+      BatchConfig batchConfig, ControllerConf controllerConf) {\n+    _tableConfig = tableConfig;\n+    _schema = schema;\n+    _batchConfig = batchConfig;\n+    _controllerConf = controllerConf;\n+  }\n+\n+  /**\n+   * Creates a segment using the provided data file/URI and uploads to Pinot\n+   */\n+  public SuccessResponse buildSegmentAndPush(DataPayload payload)\n+      throws Exception {\n+    String tableNameWithType = _tableConfig.getTableName();\n+\n+    // Setup working dir\n+    File workingDir = new File(FileUtils.getTempDirectory(),", "originalCommit": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2NjM3NQ==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545566375", "bodyText": "why is this called DataSource and why do we need this?", "author": "kishoreg", "createdAt": "2020-12-18T04:30:59Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/FileIngestionHelper.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.net.URI;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.common.utils.TarGzCompressionUtils;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.api.resources.SuccessResponse;\n+import org.apache.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A driver for the ingestion process of the provided file.\n+ * Responsible for copying the file locally, building a segment and uploading it to the controller.\n+ */\n+public class FileIngestionHelper {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(FileIngestionHelper.class);\n+\n+  private static final String WORKING_DIR_PREFIX = \"working_dir\";\n+  private static final String INPUT_DATA_DIR = \"input_data_dir\";\n+  private static final String OUTPUT_SEGMENT_DIR = \"output_segment_dir\";\n+  private static final String SEGMENT_TAR_DIR = \"segment_tar_dir\";\n+  private static final String DATA_FILE_PREFIX = \"data\";\n+\n+  private final TableConfig _tableConfig;\n+  private final Schema _schema;\n+  private final BatchConfig _batchConfig;\n+  private final ControllerConf _controllerConf;\n+\n+  public FileIngestionHelper(TableConfig tableConfig, Schema schema,\n+      BatchConfig batchConfig, ControllerConf controllerConf) {\n+    _tableConfig = tableConfig;\n+    _schema = schema;\n+    _batchConfig = batchConfig;\n+    _controllerConf = controllerConf;\n+  }\n+\n+  /**\n+   * Creates a segment using the provided data file/URI and uploads to Pinot\n+   */\n+  public SuccessResponse buildSegmentAndPush(DataPayload payload)\n+      throws Exception {\n+    String tableNameWithType = _tableConfig.getTableName();\n+\n+    // Setup working dir\n+    File workingDir = new File(FileUtils.getTempDirectory(),\n+        String.format(\"%s_%s_%d\", WORKING_DIR_PREFIX, tableNameWithType, System.currentTimeMillis()));\n+    File inputDir = new File(workingDir, INPUT_DATA_DIR);\n+    File outputDir = new File(workingDir, OUTPUT_SEGMENT_DIR);\n+    File segmentTarDir = new File(workingDir, SEGMENT_TAR_DIR);\n+    try {\n+      Preconditions\n+          .checkState(inputDir.mkdirs(), \"Could not create directory for downloading input file locally: %s\", inputDir);\n+      Preconditions.checkState(segmentTarDir.mkdirs(), \"Could not create directory for segment tar file: %s\", inputDir);\n+\n+      // Copy file to local working dir\n+      File inputFile =\n+          new File(inputDir, String.format(\"%s.%s\", DATA_FILE_PREFIX, _batchConfig.getInputFormat().toString().toLowerCase()));\n+      if (payload._dataSource.equals(DataSource.URI)) {\n+        FileIngestionUtils.copyURIToLocal(_batchConfig, payload._uri, inputFile);\n+      } else {\n+        FileIngestionUtils.copyMultipartToLocal(payload._multiPart, inputFile);\n+      }\n+\n+      // Build segment\n+      SegmentGeneratorConfig segmentGeneratorConfig =\n+          FileIngestionUtils.generateSegmentGeneratorConfig(_tableConfig, _batchConfig, _schema, inputFile, outputDir);\n+      String segmentName = FileIngestionUtils.buildSegment(segmentGeneratorConfig);\n+\n+      // Tar and push segment\n+      File segmentTarFile =\n+          new File(segmentTarDir, segmentName + org.apache.pinot.spi.ingestion.batch.spec.Constants.TAR_GZ_FILE_EXT);\n+      TarGzCompressionUtils.createTarGzFile(new File(outputDir, segmentName), segmentTarFile);\n+      FileIngestionUtils\n+          .uploadSegment(tableNameWithType, Lists.newArrayList(segmentTarFile), _controllerConf.getControllerHost(),\n+              Integer.parseInt(_controllerConf.getControllerPort()));\n+\n+      return new SuccessResponse(\n+          \"Successfully ingested file into table: \" + tableNameWithType + \" as segment: \" + segmentName);\n+    } catch (Exception e) {\n+      LOGGER.error(\"Caught exception when ingesting file to table: {}\", tableNameWithType, e);\n+      throw e;\n+    } finally {\n+      FileUtils.deleteQuietly(workingDir);\n+    }\n+  }\n+\n+  /**\n+   * Enum to identify the source of ingestion file\n+   */\n+  private enum DataSource {", "originalCommit": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkwNDYxNA==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r546904614", "bodyText": "Renamed to PayloadType. Payload can be either file or uri. PayloadType and DataPayload were introduced as static inner classes to wrap the payload, and avoid some code duplication until payload is downloaded.", "author": "npawar", "createdAt": "2020-12-21T20:03:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2NjM3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2ODE2Ng==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545568166", "bodyText": "it's probably better to copy the data locally for both URI based and multipart right", "author": "kishoreg", "createdAt": "2020-12-18T04:38:12Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotIngestionRestletResource.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.api.resources;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.base.Preconditions;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import java.net.URI;\n+import java.util.Map;\n+import javax.inject.Inject;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.container.AsyncResponse;\n+import javax.ws.rs.container.Suspended;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.controller.util.FileIngestionHelper;\n+import org.apache.pinot.controller.util.FileIngestionHelper.DataPayload;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.builder.TableNameBuilder;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.glassfish.jersey.server.ManagedAsync;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * APIs related to ingestion\n+ */\n+@Api(tags = Constants.TABLE_TAG)\n+@Path(\"/\")\n+public class PinotIngestionRestletResource {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PinotIngestionRestletResource.class);\n+\n+  @Inject\n+  PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  @Inject\n+  ControllerConf _controllerConf;\n+\n+  /**\n+   * API to upload a file and ingest it into a Pinot table\n+   * @param tableName Name of the table to upload to\n+   * @param batchConfigMapStr Batch config Map as a string. Provide the\n+   *                          input format (inputFormat)\n+   *                          record reader configs (recordReader.prop.<property>),\n+   *                          fs class name (input.fs.className)\n+   *                          fs configs (input.fs.prop.<property>)\n+   * @param fileUpload file to upload as a multipart\n+   */\n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.MULTIPART_FORM_DATA)\n+  @Path(\"/ingestFromFile\")\n+  @ApiOperation(value = \"Ingest a file\", notes = \"Creates a segment using given file and pushes it to Pinot\")\n+  public void ingestFromFile(\n+      @ApiParam(value = \"Name of the table to upload the file to\", required = true) @QueryParam(\"tableName\") String tableName,\n+      @ApiParam(value = \"Batch config map as string\", required = true) @QueryParam(\"batchConfigMapStr\") String batchConfigMapStr,\n+      FormDataMultiPart fileUpload,\n+      @Suspended final AsyncResponse asyncResponse) {\n+    try {\n+      asyncResponse.resume(ingestData(tableName, batchConfigMapStr, new DataPayload(fileUpload)));", "originalCommit": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkwMzgxOQ==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r546903819", "bodyText": "It does get copied for both. Look at FileIngestionHelper#88.", "author": "npawar", "createdAt": "2020-12-21T20:01:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2ODE2Ng=="}], "type": "inlineReview"}, {"oid": "d535d9d64f4c1619acc213619d6ca5b3c75cb1d0", "url": "https://github.com/apache/pinot/commit/d535d9d64f4c1619acc213619d6ca5b3c75cb1d0", "message": "Review changes", "committedDate": "2020-12-21T19:41:17Z", "type": "commit"}, {"oid": "35c8fd2a1cd1d2c7d983ace5ab69161742afa931", "url": "https://github.com/apache/pinot/commit/35c8fd2a1cd1d2c7d983ace5ab69161742afa931", "message": "Upload dir as param for FileIngestionHelper constructor", "committedDate": "2020-12-21T20:00:36Z", "type": "commit"}, {"oid": "a8eeb6b378798971899ed0b38788a4b954fbcac2", "url": "https://github.com/apache/pinot/commit/a8eeb6b378798971899ed0b38788a4b954fbcac2", "message": "Add message", "committedDate": "2020-12-21T20:12:02Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjMyODY4OA==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r546328688", "bodyText": "Shall we also add an API of\npublic String forIngestFromFile(String tableNameWithType, Map<String, String> batchConfig)\nand\npublic String forIngestFromURI(String tableNameWithType, Map<String, String> batchConfig, String sourceURIStr)", "author": "xiangfu0", "createdAt": "2020-12-20T06:20:30Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/helix/ControllerRequestURLBuilder.java", "diffHunk": "@@ -289,4 +292,18 @@ public String forInstanceReplace(String tableName, @Nullable InstancePartitionsT\n     }\n     return url;\n   }\n+\n+  public String forIngestFromFile(String tableNameWithType, String batchConfigMapStr)", "originalCommit": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjMzMDY0NQ==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r546330645", "bodyText": "Shall we extract this to a common class into RecordReaderFactory.getRecordReaderConfig(...)?", "author": "xiangfu0", "createdAt": "2020-12-20T06:42:44Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/FileIngestionUtils.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.base.Preconditions;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.net.URI;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.pinot.common.exception.HttpErrorStatusException;\n+import org.apache.pinot.common.utils.FileUploadDownloadClient;\n+import org.apache.pinot.common.utils.SimpleHttpResponse;\n+import org.apache.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import org.apache.pinot.core.segment.creator.impl.SegmentIndexCreationDriverImpl;\n+import org.apache.pinot.core.segment.name.SimpleSegmentNameGenerator;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.data.readers.FileFormat;\n+import org.apache.pinot.spi.data.readers.RecordReaderConfig;\n+import org.apache.pinot.spi.data.readers.RecordReaderFactory;\n+import org.apache.pinot.spi.filesystem.PinotFSFactory;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.plugin.PluginManager;\n+import org.apache.pinot.spi.utils.IngestionConfigUtils;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.retry.AttemptsExceededException;\n+import org.apache.pinot.spi.utils.retry.RetriableOperationException;\n+import org.apache.pinot.spi.utils.retry.RetryPolicies;\n+import org.glassfish.jersey.media.multipart.FormDataBodyPart;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Helper methods for ingestion from file\n+ */\n+public final class FileIngestionUtils {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(FileIngestionUtils.class);\n+  private static final long DEFAULT_RETRY_WAIT_MS = 1000L;\n+  private static final int DEFAULT_ATTEMPTS = 3;\n+  private static final FileUploadDownloadClient FILE_UPLOAD_DOWNLOAD_CLIENT = new FileUploadDownloadClient();\n+\n+  private FileIngestionUtils() {\n+  }\n+\n+  /**\n+   * Copy the file from given URI to local file\n+   */\n+  public static void copyURIToLocal(BatchConfig batchConfig, URI sourceFileURI, File destFile)\n+      throws Exception {\n+    String sourceFileURIScheme = sourceFileURI.getScheme();\n+    if (!PinotFSFactory.isSchemeSupported(sourceFileURIScheme)) {\n+      PinotFSFactory.register(sourceFileURIScheme, batchConfig.getInputFsClassName(),\n+          IngestionConfigUtils.getFsProps(batchConfig.getInputFsProps()));\n+    }\n+    PinotFSFactory.create(sourceFileURIScheme).copyToLocalFile(sourceFileURI, destFile);\n+  }\n+\n+  /**\n+   * Copy the file from the uploaded multipart to a local file\n+   */\n+  public static void copyMultipartToLocal(FormDataMultiPart multiPart, File destFile)\n+      throws IOException {\n+    FormDataBodyPart formDataBodyPart = multiPart.getFields().values().iterator().next().get(0);\n+    try (InputStream inputStream = formDataBodyPart.getValueAs(InputStream.class);\n+        OutputStream outputStream = new FileOutputStream(destFile)) {\n+      IOUtils.copyLarge(inputStream, outputStream);\n+    } finally {\n+      multiPart.cleanup();\n+    }\n+  }\n+\n+  /**\n+   * Creates a {@link SegmentGeneratorConfig}\n+   * @param tableConfig Table config\n+   * @param batchConfig Batch config override provided by the user during upload\n+   * @param schema Table schema\n+   * @param inputFile The input file\n+   * @param outputSegmentDir The output dir\n+   */\n+  public static SegmentGeneratorConfig generateSegmentGeneratorConfig(TableConfig tableConfig, BatchConfig batchConfig,\n+      Schema schema, File inputFile, File outputSegmentDir)\n+      throws ClassNotFoundException, IOException {\n+    SegmentGeneratorConfig segmentGeneratorConfig = new SegmentGeneratorConfig(tableConfig, schema);\n+    segmentGeneratorConfig.setTableName(tableConfig.getTableName());\n+    segmentGeneratorConfig.setOutDir(outputSegmentDir.getAbsolutePath());\n+    segmentGeneratorConfig.setInputFilePath(inputFile.getAbsolutePath());\n+\n+    FileFormat fileFormat = batchConfig.getInputFormat();\n+    segmentGeneratorConfig.setFormat(fileFormat);\n+    segmentGeneratorConfig.setRecordReaderPath(RecordReaderFactory.getRecordReaderClassName(fileFormat.toString()));\n+    String readerConfigClassName = RecordReaderFactory.getRecordReaderConfigClassName(fileFormat.toString());\n+    if (readerConfigClassName != null) {", "originalCommit": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk5MDM0MQ==", "url": "https://github.com/apache/pinot/pull/6354#discussion_r546990341", "bodyText": "done", "author": "npawar", "createdAt": "2020-12-21T23:54:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjMzMDY0NQ=="}], "type": "inlineReview"}, {"oid": "e4615e6f849af9aa4c8c840bdf1cb497cc8dc49d", "url": "https://github.com/apache/pinot/commit/e4615e6f849af9aa4c8c840bdf1cb497cc8dc49d", "message": "Message about encoding", "committedDate": "2020-12-21T22:39:37Z", "type": "commit"}, {"oid": "56d5e128974a767ea610991e139922f7ab8d6930", "url": "https://github.com/apache/pinot/commit/56d5e128974a767ea610991e139922f7ab8d6930", "message": "Review comments", "committedDate": "2020-12-21T23:54:00Z", "type": "commit"}]}