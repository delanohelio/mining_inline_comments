{"pr_number": 5769, "pr_title": "[TE] add anomaly detection as a service - Phase 1", "pr_createdAt": "2020-07-29T21:08:17Z", "pr_url": "https://github.com/apache/pinot/pull/5769", "timeline": [{"oid": "6d91338441effdb3e94eface7664035757ae2e4d", "url": "https://github.com/apache/pinot/commit/6d91338441effdb3e94eface7664035757ae2e4d", "message": "[TE] add anomaly detection as a service - Phase 1", "committedDate": "2020-07-29T22:40:52Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMwODk2MQ==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r463308961", "bodyText": "Why hard code that one user can only send one request at a time? Would it make more sense to give it more flexibility here? for example, control the overall API QPS, or have a backoff mechanism, or a per-user quota?", "author": "jihaozh", "createdAt": "2020-07-30T22:33:47Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time", "originalCommit": "6d91338441effdb3e94eface7664035757ae2e4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY3MTk0MQ==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r466671941", "bodyText": "Now an extra suffix of UUID is appended and this allows one user sends multiple requests at a time", "author": "jasonyanwenl", "createdAt": "2020-08-06T20:36:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMwODk2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxMjQzOQ==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r463312439", "bodyText": "I'm worried about creating a temporary detection config and later cleans it up. These detection configs can get leaked into the UI where users can see and change them while the task is running.\nSince we're already persisting in the task DTO, the information needed to create a detection config can actually just be persisted within the task info. Then an OnlineDetectionTaskRunner can pick it up and create the detectionConfigDTO in run time. No need to persist the DetectionConfig.", "author": "jihaozh", "createdAt": "2020-07-30T22:44:42Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time\n+    String nameSuffix = \"_\" + principal.getName();\n+\n+    try {\n+      if (payload.getBytes().length > MAX_ONLINE_PAYLOAD_SIZE) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Payload too large\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      JsonNode payloadNode = objectMapper.readTree(payload);\n+\n+      if (!validateOnlineRequestPayload(payloadNode)) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Invalid request payload\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Preprocess: remove existing entities generated by the previous interrupted request\n+      cleanExistingOnlineTask(nameSuffix);\n+\n+      // Create & save dataset\n+      datasetConfigDTO = generateDatasetConfig(payloadNode, nameSuffix);\n+\n+      // Create & save metric along with online data\n+      metricConfigDTO = generateMetricConfig(payloadNode, nameSuffix);\n+\n+      // Create & save detection\n+      detectionConfigDTO =\n+          generateDetectionConfig(payloadNode, nameSuffix, datasetConfigDTO, metricConfigDTO, start,\n+              end);", "originalCommit": "6d91338441effdb3e94eface7664035757ae2e4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwNDgxNg==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r467204816", "bodyText": "Thanks for the suggestion! Now the online detection config is saved into task info instead of DB. Please check this commit.", "author": "jasonyanwenl", "createdAt": "2020-08-07T18:32:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxMjQzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNDcyNg==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r463314726", "bodyText": "Any reason for creating the dataset and metric DTOs be created and later cleaned up?\nIMO a better approach will be to create separate CRUD endpoints for these online datasets/metrics. Doing that will allow the user to create a dataset one time and then run detection multiple times. They can also visualize them in ThirdEye UI if they want. If it's no longer needed, it can be removed. Compared to this way, users need post the data to Thirdeye every time when they run a detection.", "author": "jihaozh", "createdAt": "2020-07-30T22:51:48Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time\n+    String nameSuffix = \"_\" + principal.getName();\n+\n+    try {\n+      if (payload.getBytes().length > MAX_ONLINE_PAYLOAD_SIZE) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Payload too large\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      JsonNode payloadNode = objectMapper.readTree(payload);\n+\n+      if (!validateOnlineRequestPayload(payloadNode)) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Invalid request payload\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Preprocess: remove existing entities generated by the previous interrupted request\n+      cleanExistingOnlineTask(nameSuffix);\n+\n+      // Create & save dataset\n+      datasetConfigDTO = generateDatasetConfig(payloadNode, nameSuffix);\n+\n+      // Create & save metric along with online data\n+      metricConfigDTO = generateMetricConfig(payloadNode, nameSuffix);", "originalCommit": "6d91338441effdb3e94eface7664035757ae2e4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxOTg1OA==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r466019858", "bodyText": "I agree with Jihao. Having separate CRUD is much easier for users to use the ad-hoc detection. We can set up some cleanup mechanism that clean up any online dataset/metric that is not used for certain period, 14 days for instance.", "author": "vincentchenjl", "createdAt": "2020-08-05T21:39:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNDcyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwMDQyOA==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r467200428", "bodyText": "I think both ways have some pros and cons. I personally think that using a single endpoint is easier for users?\n\nThe main purpose of online AD endpoint is to provide a convenient way to run AD tasks so the endpoint should be as simple as possible. Using a single endpoint is more user-friendly. Using a separate CRUD endpoint does allow more flexibility but it will ask users to firstly register their data before using this service.\nSecondly, online service will not allow much too large size of data so in my sense, sending data in the request every time is not a bottleneck?\n\nI think we could provide both ways. This is phase 1 for this feature. In phase 2, we probably could support another two endpoints to support what you suggested.\nRegarding the cleanup, I think currently in phase 1, it is just a one-call request so I mentioned this as stateless because users will not have a separate endpoint to retrieve anomalies afterwards and hence we could clean up them. In phase 2, another two endpoints will be provided and for those endpoints, we do not need to do the cleanup.\nThanks for your suggestions!", "author": "jasonyanwenl", "createdAt": "2020-08-07T18:23:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNDcyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNTM1NA==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r463315354", "bodyText": "I'll still put a timeout mechanism here so that if anything external goes wrong, the thread can still timeout.", "author": "jihaozh", "createdAt": "2020-07-30T22:53:51Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time\n+    String nameSuffix = \"_\" + principal.getName();\n+\n+    try {\n+      if (payload.getBytes().length > MAX_ONLINE_PAYLOAD_SIZE) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Payload too large\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      JsonNode payloadNode = objectMapper.readTree(payload);\n+\n+      if (!validateOnlineRequestPayload(payloadNode)) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Invalid request payload\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Preprocess: remove existing entities generated by the previous interrupted request\n+      cleanExistingOnlineTask(nameSuffix);\n+\n+      // Create & save dataset\n+      datasetConfigDTO = generateDatasetConfig(payloadNode, nameSuffix);\n+\n+      // Create & save metric along with online data\n+      metricConfigDTO = generateMetricConfig(payloadNode, nameSuffix);\n+\n+      // Create & save detection\n+      detectionConfigDTO =\n+          generateDetectionConfig(payloadNode, nameSuffix, datasetConfigDTO, metricConfigDTO, start,\n+              end);\n+\n+      // Create & save task\n+      taskDTO = generateTaskConfig(detectionConfigDTO.getId(), start, end);\n+\n+      // Polling task status\n+      TaskDTO polledTaskDTO = pollingTask(taskDTO.getId());\n+\n+      // Task failure\n+      if (polledTaskDTO.getStatus() != TaskConstants.TaskStatus.COMPLETED) {\n+        LOG.warn(\"Task is not completed after polling: \" + polledTaskDTO);\n+\n+        responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+\n+        switch (polledTaskDTO.getStatus()) {\n+        case FAILED:\n+          responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+          responseMessage.put(\"message\", \"Failed to execute anomaly detection task.\");\n+          break;\n+        case TIMEOUT:\n+          responseStatus = Response.Status.REQUEST_TIMEOUT;\n+          responseMessage.put(\"message\", \"Anomaly detection task timeout.\");\n+        default:\n+          LOG.error(\"Error task status after polling: \" + polledTaskDTO.getStatus());\n+          responseMessage.put(\"message\", \"unknown task status.\");\n+          break;\n+        }\n+\n+        responseMessage.put(\"more-info\", \"Error = \" + polledTaskDTO.getMessage());\n+\n+        // Send response\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Task success\n+      // Retrieve task result\n+      anomalies = getAnomalies(start, end, metricConfigDTO.getName(), datasetConfigDTO.getName());\n+\n+      // Build success response\n+      JsonNode anomalyNode = objectMapper.convertValue(anomalies, JsonNode.class);\n+      JsonNode detectionConfigNode =\n+          objectMapper.convertValue(detectionConfigDTO.getYaml(), JsonNode.class);\n+      ObjectNode responseNode = objectMapper.createObjectNode();\n+      responseNode.set(ANOMALIES_FIELD, anomalyNode);\n+      responseNode.set(DETECTION_FIELD, detectionConfigNode);\n+\n+      responseStatus = Response.Status.OK;\n+      return Response.status(responseStatus).entity(objectMapper.writeValueAsString(responseNode))\n+          .build();\n+    } catch (JsonProcessingException e) {\n+      LOG.error(\"Error: {}\", e.getMessage());\n+      responseStatus = Response.Status.BAD_REQUEST;\n+      responseMessage.put(\"message\", \"Invalid request payload\");\n+      processException(e, responseMessage);\n+      return Response.status(responseStatus).entity(responseMessage).build();\n+    } catch (Exception e) {\n+      LOG.error(\"Error: {}\", e.getMessage());\n+      responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+      responseMessage.put(\"message\", \"Failed executing anomaly detection service.\");\n+      processException(e, responseMessage);\n+      return Response.status(responseStatus).entity(responseMessage).build();\n+    } finally {\n+      // Online service is stateless\n+      cleanStates(anomalies, taskDTO, metricConfigDTO, datasetConfigDTO, detectionConfigDTO);\n+    }\n+  }\n+\n+  void cleanExistingOnlineTask(String nameSuffix) {\n+    String metricName = DEFAULT_METRIC_NAME + nameSuffix;\n+    List<MetricConfigDTO> metricConfigDTOS = metricConfigDAO.findByMetricName(metricName);\n+    for (MetricConfigDTO metricConfigDTO : metricConfigDTOS) {\n+      metricConfigDAO.deleteById(metricConfigDTO.getId());\n+      LOG.info(\"Deleted existing metric: {}\", metricConfigDTO);\n+    }\n+\n+    String datasetName = DEFAULT_DATASET_NAME + nameSuffix;\n+    DatasetConfigDTO datasetConfigDTO = datasetConfigDAO.findByDataset(datasetName);\n+    if (datasetConfigDTO != null) {\n+      datasetConfigDAO.delete(datasetConfigDTO);\n+      LOG.info(\"Deleted existing dataset: {}\", datasetConfigDTO);\n+    }\n+\n+    String detectionName = DEFAULT_DETECTION_NAME + nameSuffix;\n+    List<DetectionConfigDTO> detectionConfigDTOS = detectionConfigDAO\n+        .findByPredicate(Predicate.EQ(DETECTION_MYSQL_NAME_COLUMN, detectionName));\n+    for (DetectionConfigDTO detectionConfigDTO : detectionConfigDTOS) {\n+      detectionConfigDAO.delete(detectionConfigDTO);\n+      taskDAO.deleteByPredicate(Predicate.EQ(TASK_MYSQL_NAME_COLUMN,\n+          TaskConstants.TaskType.DETECTION.name() + \"_\" + detectionConfigDTO.getId()));\n+      LOG.info(\"Deleted existing task with detection: {}\", detectionConfigDTO);\n+    }\n+  }\n+\n+  boolean validateOnlineRequestPayload(JsonNode payloadNode) {\n+    if (!payloadNode.has(DATA_FIELD))\n+      return false;\n+\n+    JsonNode dataNode = payloadNode.get(DATA_FIELD);\n+    if (!dataNode.has(COLUMNS_FIELD) || !dataNode.has(ROWS_FIELD))\n+      return false;\n+\n+    JsonNode columnsNode = dataNode.get(COLUMNS_FIELD);\n+    if (!columnsNode.isArray())\n+      return false;\n+\n+    boolean hasTimeColumn = false, hasMetricColumn = false;\n+    for (JsonNode columnNode : columnsNode) {\n+      if (columnNode.textValue().equals(DEFAULT_TIME_COLUMN))\n+        hasTimeColumn = true;\n+      if (columnNode.textValue().equals(DEFAULT_METRIC_COLUMN))\n+        hasMetricColumn = true;\n+      if (hasTimeColumn && hasMetricColumn)\n+        break;\n+    }\n+    return hasTimeColumn && hasMetricColumn;\n+  }\n+\n+  DatasetConfigDTO generateDatasetConfig(JsonNode payloadNode, String suffix) {\n+    DatasetConfigDTO datasetConfigDTO = new DatasetConfigDTO();\n+\n+    // Default configuration\n+    datasetConfigDTO.setDataset(DEFAULT_DATASET_NAME + suffix);\n+    datasetConfigDTO.setDimensions(DEFAULT_DIMENSIONS);\n+    datasetConfigDTO.setTimeColumn(DEFAULT_TIME_COLUMN);\n+    datasetConfigDTO.setTimeDuration(DEFAULT_TIME_DURATION);\n+    datasetConfigDTO.setTimeUnit(DEFAULT_TIME_UNIT);\n+    datasetConfigDTO.setTimeFormat(DEFAULT_TIME_FORMAT);\n+    datasetConfigDTO.setTimezone(DEFAULT_TIME_ZONE);\n+    datasetConfigDTO.setDataSource(ONLINE_DATASOURCE);\n+\n+    // Customized configuration\n+    if (payloadNode.has(DATASET_FIELD)) {\n+\n+      Map<String, Object> datasetYaml =\n+          ConfigUtils.getMap(yaml.load(payloadNode.get(DATASET_FIELD).textValue()));\n+\n+      if (datasetYaml.containsKey(TIME_COLUMN_YAML_FIELD)) {\n+        datasetConfigDTO.setTimeColumn((String) datasetYaml.get(TIME_COLUMN_YAML_FIELD));\n+      }\n+      if (datasetYaml.containsKey(TIME_UNIT_YAML_FIELD)) {\n+        datasetConfigDTO\n+            .setTimeUnit(TimeUnit.valueOf((String) datasetYaml.get(TIME_UNIT_YAML_FIELD)));\n+      }\n+      if (datasetYaml.containsKey(TIME_DURATION_YAML_FIELD)) {\n+        datasetConfigDTO.setTimeDuration((Integer) datasetYaml.get(TIME_DURATION_YAML_FIELD));\n+      }\n+      if (datasetYaml.containsKey(TIME_FORMAT_YAML_FIELD)) {\n+        datasetConfigDTO.setTimeFormat((String) datasetYaml.get(TIME_FORMAT_YAML_FIELD));\n+      }\n+      if (datasetYaml.containsKey(TIME_ZONE_YAML_FIELD)) {\n+        datasetConfigDTO.setTimezone((String) datasetYaml.get(TIME_ZONE_YAML_FIELD));\n+      }\n+    }\n+\n+    this.datasetConfigValidator.validateConfig(datasetConfigDTO);\n+\n+    datasetConfigDAO.save(datasetConfigDTO);\n+    LOG.info(\"Created dataset with config {}\", datasetConfigDTO);\n+\n+    return datasetConfigDTO;\n+  }\n+\n+  MetricConfigDTO generateMetricConfig(JsonNode payloadNode, String suffix)\n+      throws JsonProcessingException {\n+    MetricConfigDTO metricConfigDTO = new MetricConfigDTO();\n+    JsonNode dataNode = payloadNode.get(DATA_FIELD);\n+\n+    // Default configuration\n+    metricConfigDTO.setName(DEFAULT_METRIC_NAME + suffix);\n+    metricConfigDTO.setDataset(DEFAULT_DATASET_NAME + suffix);\n+    metricConfigDTO.setAlias(ThirdEyeUtils\n+        .constructMetricAlias(DEFAULT_DATASET_NAME + suffix,\n+            DEFAULT_METRIC_NAME + suffix));\n+    metricConfigDTO.setDatatype(DEFAULT_DATA_TYPE);\n+    metricConfigDTO.setDefaultAggFunction(MetricAggFunction.SUM);\n+    metricConfigDTO.setActive(true);\n+\n+    // Customized configuration\n+    if (payloadNode.has(METRIC_FIELD)) {\n+      Map<String, Object> metricYaml =\n+          ConfigUtils.getMap(yaml.load(payloadNode.get(METRIC_FIELD).textValue()));\n+\n+      if (metricYaml.containsKey(DATATYPE_YAML_FIELD)) {\n+        metricConfigDTO\n+            .setDatatype(MetricType.valueOf((String) metricYaml.get(DATATYPE_YAML_FIELD)));\n+      }\n+    }\n+\n+    // Reformat Metric column name to keep consistency with metric config\n+    ArrayNode columnsNode = dataNode.withArray(COLUMNS_FIELD);\n+    if (columnsNode.isArray()) {\n+      int colIdx = 0;\n+      for (; colIdx < columnsNode.size(); colIdx++) {\n+        if (columnsNode.get(colIdx).textValue().equals(DEFAULT_METRIC_COLUMN)) {\n+          break;\n+        }\n+      }\n+      columnsNode.set(colIdx, new TextNode(DEFAULT_METRIC_NAME + suffix));\n+    }\n+    // TODO: should store online data into a new table\n+    metricConfigDTO.setOnlineData(this.objectMapper.writeValueAsString(dataNode));\n+\n+    this.metricConfigValidator.validateConfig(metricConfigDTO);\n+\n+    metricConfigDAO.save(metricConfigDTO);\n+    LOG.info(\"Created metric with config {}\", metricConfigDTO);\n+\n+    return metricConfigDTO;\n+  }\n+\n+  DetectionConfigDTO generateDetectionConfig(JsonNode payloadNode, String suffix,\n+      DatasetConfigDTO datasetConfigDTO, MetricConfigDTO metricConfigDTO, long start, long end) {\n+    DetectionConfigDTO detectionConfigDTO;\n+    Map<String, Object> detectionYaml;\n+    ClassLoader classLoader = Thread.currentThread().getContextClassLoader();\n+\n+    if (payloadNode.has(DETECTION_FIELD)) {\n+      // Customized configuration: retrieve config from user request\n+      detectionYaml = ConfigUtils.getMap(yaml.load(payloadNode.get(DETECTION_FIELD).textValue()));\n+    } else {\n+      // Default configuration: retrieve the template from disk\n+      detectionYaml =\n+          ConfigUtils.getMap(yaml.load(classLoader.getResourceAsStream(TEMPLATE_DETECTION_PATH)));\n+    }\n+\n+    // Do not support customized detection name as it is not a common use case\n+    detectionYaml.put(DETECTION_YAML_FIELD, DEFAULT_DETECTION_NAME + suffix);\n+    detectionYaml.put(DATASET_YAML_FIELD, datasetConfigDTO.getName());\n+    detectionYaml.put(METRIC_YAML_FIELD, metricConfigDTO.getName());\n+\n+    detectionConfigDTO =\n+        new DetectionConfigTranslator(this.yaml.dump(detectionYaml), this.provider).translate();\n+    detectionConfigDTO.setCron(\"0 0 0 1 1 ? 2200\"); // Never scheduled\n+\n+    // Tune the detection config - Passes the raw yaml params & injects tuned params\n+    DetectionConfigTuner detectionTuner = new DetectionConfigTuner(detectionConfigDTO, provider);\n+    detectionConfigDTO = detectionTuner.tune(start, end);\n+\n+    // Validate the detection config\n+    detectionValidator.validateConfig(detectionConfigDTO);\n+\n+    detectionConfigDAO.save(detectionConfigDTO);\n+    LOG.info(\"Created detection with config {}\", detectionConfigDTO);\n+\n+    return detectionConfigDTO;\n+  }\n+\n+  TaskDTO generateTaskConfig(long detectionConfigId, long start, long end)\n+      throws JsonProcessingException {\n+    TaskDTO taskDTO = new TaskDTO();\n+    taskDTO.setJobName(TaskConstants.TaskType.DETECTION.toString() + \"_\" + detectionConfigId);\n+    taskDTO.setStatus(TaskConstants.TaskStatus.WAITING);\n+    taskDTO.setTaskType(TaskConstants.TaskType.DETECTION_ONLINE);\n+    DetectionPipelineTaskInfo taskInfo =\n+        new DetectionPipelineTaskInfo(detectionConfigId, start, end);\n+    String taskInfoJson = objectMapper.writeValueAsString(taskInfo);\n+    taskDTO.setTaskInfo(taskInfoJson);\n+\n+    taskDAO.save(taskDTO);\n+    LOG.info(\"Created task: {}\", taskDTO);\n+\n+    return taskDTO;\n+  }\n+\n+  private TaskDTO pollingTask(long taskId) {\n+    long startTime = System.currentTimeMillis();\n+    TaskDTO taskDTO;\n+\n+    // Timeout mechanism will be handled by worker thread in the controller", "originalCommit": "6d91338441effdb3e94eface7664035757ae2e4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNTYxNg==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r463315616", "bodyText": "no need to delete the taskDTO. it will be cleaned up periodically by the monitor task.", "author": "jihaozh", "createdAt": "2020-07-30T22:54:40Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time\n+    String nameSuffix = \"_\" + principal.getName();\n+\n+    try {\n+      if (payload.getBytes().length > MAX_ONLINE_PAYLOAD_SIZE) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Payload too large\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      JsonNode payloadNode = objectMapper.readTree(payload);\n+\n+      if (!validateOnlineRequestPayload(payloadNode)) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Invalid request payload\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Preprocess: remove existing entities generated by the previous interrupted request\n+      cleanExistingOnlineTask(nameSuffix);\n+\n+      // Create & save dataset\n+      datasetConfigDTO = generateDatasetConfig(payloadNode, nameSuffix);\n+\n+      // Create & save metric along with online data\n+      metricConfigDTO = generateMetricConfig(payloadNode, nameSuffix);\n+\n+      // Create & save detection\n+      detectionConfigDTO =\n+          generateDetectionConfig(payloadNode, nameSuffix, datasetConfigDTO, metricConfigDTO, start,\n+              end);\n+\n+      // Create & save task\n+      taskDTO = generateTaskConfig(detectionConfigDTO.getId(), start, end);\n+\n+      // Polling task status\n+      TaskDTO polledTaskDTO = pollingTask(taskDTO.getId());\n+\n+      // Task failure\n+      if (polledTaskDTO.getStatus() != TaskConstants.TaskStatus.COMPLETED) {\n+        LOG.warn(\"Task is not completed after polling: \" + polledTaskDTO);\n+\n+        responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+\n+        switch (polledTaskDTO.getStatus()) {\n+        case FAILED:\n+          responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+          responseMessage.put(\"message\", \"Failed to execute anomaly detection task.\");\n+          break;\n+        case TIMEOUT:\n+          responseStatus = Response.Status.REQUEST_TIMEOUT;\n+          responseMessage.put(\"message\", \"Anomaly detection task timeout.\");\n+        default:\n+          LOG.error(\"Error task status after polling: \" + polledTaskDTO.getStatus());\n+          responseMessage.put(\"message\", \"unknown task status.\");\n+          break;\n+        }\n+\n+        responseMessage.put(\"more-info\", \"Error = \" + polledTaskDTO.getMessage());\n+\n+        // Send response\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Task success\n+      // Retrieve task result\n+      anomalies = getAnomalies(start, end, metricConfigDTO.getName(), datasetConfigDTO.getName());\n+\n+      // Build success response\n+      JsonNode anomalyNode = objectMapper.convertValue(anomalies, JsonNode.class);\n+      JsonNode detectionConfigNode =\n+          objectMapper.convertValue(detectionConfigDTO.getYaml(), JsonNode.class);\n+      ObjectNode responseNode = objectMapper.createObjectNode();\n+      responseNode.set(ANOMALIES_FIELD, anomalyNode);\n+      responseNode.set(DETECTION_FIELD, detectionConfigNode);\n+\n+      responseStatus = Response.Status.OK;\n+      return Response.status(responseStatus).entity(objectMapper.writeValueAsString(responseNode))\n+          .build();\n+    } catch (JsonProcessingException e) {\n+      LOG.error(\"Error: {}\", e.getMessage());\n+      responseStatus = Response.Status.BAD_REQUEST;\n+      responseMessage.put(\"message\", \"Invalid request payload\");\n+      processException(e, responseMessage);\n+      return Response.status(responseStatus).entity(responseMessage).build();\n+    } catch (Exception e) {\n+      LOG.error(\"Error: {}\", e.getMessage());\n+      responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+      responseMessage.put(\"message\", \"Failed executing anomaly detection service.\");\n+      processException(e, responseMessage);\n+      return Response.status(responseStatus).entity(responseMessage).build();\n+    } finally {\n+      // Online service is stateless\n+      cleanStates(anomalies, taskDTO, metricConfigDTO, datasetConfigDTO, detectionConfigDTO);\n+    }\n+  }\n+\n+  void cleanExistingOnlineTask(String nameSuffix) {\n+    String metricName = DEFAULT_METRIC_NAME + nameSuffix;\n+    List<MetricConfigDTO> metricConfigDTOS = metricConfigDAO.findByMetricName(metricName);\n+    for (MetricConfigDTO metricConfigDTO : metricConfigDTOS) {\n+      metricConfigDAO.deleteById(metricConfigDTO.getId());\n+      LOG.info(\"Deleted existing metric: {}\", metricConfigDTO);\n+    }\n+\n+    String datasetName = DEFAULT_DATASET_NAME + nameSuffix;\n+    DatasetConfigDTO datasetConfigDTO = datasetConfigDAO.findByDataset(datasetName);\n+    if (datasetConfigDTO != null) {\n+      datasetConfigDAO.delete(datasetConfigDTO);\n+      LOG.info(\"Deleted existing dataset: {}\", datasetConfigDTO);\n+    }\n+\n+    String detectionName = DEFAULT_DETECTION_NAME + nameSuffix;\n+    List<DetectionConfigDTO> detectionConfigDTOS = detectionConfigDAO\n+        .findByPredicate(Predicate.EQ(DETECTION_MYSQL_NAME_COLUMN, detectionName));\n+    for (DetectionConfigDTO detectionConfigDTO : detectionConfigDTOS) {\n+      detectionConfigDAO.delete(detectionConfigDTO);\n+      taskDAO.deleteByPredicate(Predicate.EQ(TASK_MYSQL_NAME_COLUMN,\n+          TaskConstants.TaskType.DETECTION.name() + \"_\" + detectionConfigDTO.getId()));\n+      LOG.info(\"Deleted existing task with detection: {}\", detectionConfigDTO);\n+    }\n+  }\n+\n+  boolean validateOnlineRequestPayload(JsonNode payloadNode) {\n+    if (!payloadNode.has(DATA_FIELD))\n+      return false;\n+\n+    JsonNode dataNode = payloadNode.get(DATA_FIELD);\n+    if (!dataNode.has(COLUMNS_FIELD) || !dataNode.has(ROWS_FIELD))\n+      return false;\n+\n+    JsonNode columnsNode = dataNode.get(COLUMNS_FIELD);\n+    if (!columnsNode.isArray())\n+      return false;\n+\n+    boolean hasTimeColumn = false, hasMetricColumn = false;\n+    for (JsonNode columnNode : columnsNode) {\n+      if (columnNode.textValue().equals(DEFAULT_TIME_COLUMN))\n+        hasTimeColumn = true;\n+      if (columnNode.textValue().equals(DEFAULT_METRIC_COLUMN))\n+        hasMetricColumn = true;\n+      if (hasTimeColumn && hasMetricColumn)\n+        break;\n+    }\n+    return hasTimeColumn && hasMetricColumn;\n+  }\n+\n+  DatasetConfigDTO generateDatasetConfig(JsonNode payloadNode, String suffix) {\n+    DatasetConfigDTO datasetConfigDTO = new DatasetConfigDTO();\n+\n+    // Default configuration\n+    datasetConfigDTO.setDataset(DEFAULT_DATASET_NAME + suffix);\n+    datasetConfigDTO.setDimensions(DEFAULT_DIMENSIONS);\n+    datasetConfigDTO.setTimeColumn(DEFAULT_TIME_COLUMN);\n+    datasetConfigDTO.setTimeDuration(DEFAULT_TIME_DURATION);\n+    datasetConfigDTO.setTimeUnit(DEFAULT_TIME_UNIT);\n+    datasetConfigDTO.setTimeFormat(DEFAULT_TIME_FORMAT);\n+    datasetConfigDTO.setTimezone(DEFAULT_TIME_ZONE);\n+    datasetConfigDTO.setDataSource(ONLINE_DATASOURCE);\n+\n+    // Customized configuration\n+    if (payloadNode.has(DATASET_FIELD)) {\n+\n+      Map<String, Object> datasetYaml =\n+          ConfigUtils.getMap(yaml.load(payloadNode.get(DATASET_FIELD).textValue()));\n+\n+      if (datasetYaml.containsKey(TIME_COLUMN_YAML_FIELD)) {\n+        datasetConfigDTO.setTimeColumn((String) datasetYaml.get(TIME_COLUMN_YAML_FIELD));\n+      }\n+      if (datasetYaml.containsKey(TIME_UNIT_YAML_FIELD)) {\n+        datasetConfigDTO\n+            .setTimeUnit(TimeUnit.valueOf((String) datasetYaml.get(TIME_UNIT_YAML_FIELD)));\n+      }\n+      if (datasetYaml.containsKey(TIME_DURATION_YAML_FIELD)) {\n+        datasetConfigDTO.setTimeDuration((Integer) datasetYaml.get(TIME_DURATION_YAML_FIELD));\n+      }\n+      if (datasetYaml.containsKey(TIME_FORMAT_YAML_FIELD)) {\n+        datasetConfigDTO.setTimeFormat((String) datasetYaml.get(TIME_FORMAT_YAML_FIELD));\n+      }\n+      if (datasetYaml.containsKey(TIME_ZONE_YAML_FIELD)) {\n+        datasetConfigDTO.setTimezone((String) datasetYaml.get(TIME_ZONE_YAML_FIELD));\n+      }\n+    }\n+\n+    this.datasetConfigValidator.validateConfig(datasetConfigDTO);\n+\n+    datasetConfigDAO.save(datasetConfigDTO);\n+    LOG.info(\"Created dataset with config {}\", datasetConfigDTO);\n+\n+    return datasetConfigDTO;\n+  }\n+\n+  MetricConfigDTO generateMetricConfig(JsonNode payloadNode, String suffix)\n+      throws JsonProcessingException {\n+    MetricConfigDTO metricConfigDTO = new MetricConfigDTO();\n+    JsonNode dataNode = payloadNode.get(DATA_FIELD);\n+\n+    // Default configuration\n+    metricConfigDTO.setName(DEFAULT_METRIC_NAME + suffix);\n+    metricConfigDTO.setDataset(DEFAULT_DATASET_NAME + suffix);\n+    metricConfigDTO.setAlias(ThirdEyeUtils\n+        .constructMetricAlias(DEFAULT_DATASET_NAME + suffix,\n+            DEFAULT_METRIC_NAME + suffix));\n+    metricConfigDTO.setDatatype(DEFAULT_DATA_TYPE);\n+    metricConfigDTO.setDefaultAggFunction(MetricAggFunction.SUM);\n+    metricConfigDTO.setActive(true);\n+\n+    // Customized configuration\n+    if (payloadNode.has(METRIC_FIELD)) {\n+      Map<String, Object> metricYaml =\n+          ConfigUtils.getMap(yaml.load(payloadNode.get(METRIC_FIELD).textValue()));\n+\n+      if (metricYaml.containsKey(DATATYPE_YAML_FIELD)) {\n+        metricConfigDTO\n+            .setDatatype(MetricType.valueOf((String) metricYaml.get(DATATYPE_YAML_FIELD)));\n+      }\n+    }\n+\n+    // Reformat Metric column name to keep consistency with metric config\n+    ArrayNode columnsNode = dataNode.withArray(COLUMNS_FIELD);\n+    if (columnsNode.isArray()) {\n+      int colIdx = 0;\n+      for (; colIdx < columnsNode.size(); colIdx++) {\n+        if (columnsNode.get(colIdx).textValue().equals(DEFAULT_METRIC_COLUMN)) {\n+          break;\n+        }\n+      }\n+      columnsNode.set(colIdx, new TextNode(DEFAULT_METRIC_NAME + suffix));\n+    }\n+    // TODO: should store online data into a new table\n+    metricConfigDTO.setOnlineData(this.objectMapper.writeValueAsString(dataNode));\n+\n+    this.metricConfigValidator.validateConfig(metricConfigDTO);\n+\n+    metricConfigDAO.save(metricConfigDTO);\n+    LOG.info(\"Created metric with config {}\", metricConfigDTO);\n+\n+    return metricConfigDTO;\n+  }\n+\n+  DetectionConfigDTO generateDetectionConfig(JsonNode payloadNode, String suffix,\n+      DatasetConfigDTO datasetConfigDTO, MetricConfigDTO metricConfigDTO, long start, long end) {\n+    DetectionConfigDTO detectionConfigDTO;\n+    Map<String, Object> detectionYaml;\n+    ClassLoader classLoader = Thread.currentThread().getContextClassLoader();\n+\n+    if (payloadNode.has(DETECTION_FIELD)) {\n+      // Customized configuration: retrieve config from user request\n+      detectionYaml = ConfigUtils.getMap(yaml.load(payloadNode.get(DETECTION_FIELD).textValue()));\n+    } else {\n+      // Default configuration: retrieve the template from disk\n+      detectionYaml =\n+          ConfigUtils.getMap(yaml.load(classLoader.getResourceAsStream(TEMPLATE_DETECTION_PATH)));\n+    }\n+\n+    // Do not support customized detection name as it is not a common use case\n+    detectionYaml.put(DETECTION_YAML_FIELD, DEFAULT_DETECTION_NAME + suffix);\n+    detectionYaml.put(DATASET_YAML_FIELD, datasetConfigDTO.getName());\n+    detectionYaml.put(METRIC_YAML_FIELD, metricConfigDTO.getName());\n+\n+    detectionConfigDTO =\n+        new DetectionConfigTranslator(this.yaml.dump(detectionYaml), this.provider).translate();\n+    detectionConfigDTO.setCron(\"0 0 0 1 1 ? 2200\"); // Never scheduled\n+\n+    // Tune the detection config - Passes the raw yaml params & injects tuned params\n+    DetectionConfigTuner detectionTuner = new DetectionConfigTuner(detectionConfigDTO, provider);\n+    detectionConfigDTO = detectionTuner.tune(start, end);\n+\n+    // Validate the detection config\n+    detectionValidator.validateConfig(detectionConfigDTO);\n+\n+    detectionConfigDAO.save(detectionConfigDTO);\n+    LOG.info(\"Created detection with config {}\", detectionConfigDTO);\n+\n+    return detectionConfigDTO;\n+  }\n+\n+  TaskDTO generateTaskConfig(long detectionConfigId, long start, long end)\n+      throws JsonProcessingException {\n+    TaskDTO taskDTO = new TaskDTO();\n+    taskDTO.setJobName(TaskConstants.TaskType.DETECTION.toString() + \"_\" + detectionConfigId);\n+    taskDTO.setStatus(TaskConstants.TaskStatus.WAITING);\n+    taskDTO.setTaskType(TaskConstants.TaskType.DETECTION_ONLINE);\n+    DetectionPipelineTaskInfo taskInfo =\n+        new DetectionPipelineTaskInfo(detectionConfigId, start, end);\n+    String taskInfoJson = objectMapper.writeValueAsString(taskInfo);\n+    taskDTO.setTaskInfo(taskInfoJson);\n+\n+    taskDAO.save(taskDTO);\n+    LOG.info(\"Created task: {}\", taskDTO);\n+\n+    return taskDTO;\n+  }\n+\n+  private TaskDTO pollingTask(long taskId) {\n+    long startTime = System.currentTimeMillis();\n+    TaskDTO taskDTO;\n+\n+    // Timeout mechanism will be handled by worker thread in the controller\n+    while (true) {\n+      taskDTO = taskDAO.findById(taskId);\n+\n+      LOG.info(\"Polling task : \" + taskDTO);\n+\n+      TaskConstants.TaskStatus taskStatus = taskDTO.getStatus();\n+      if (!taskStatus.equals(TaskConstants.TaskStatus.WAITING) && !taskStatus\n+          .equals(TaskConstants.TaskStatus.RUNNING)) {\n+        LOG.info(\"Polling finished ({}ms). Task status: {}\", System.currentTimeMillis() - startTime,\n+            taskStatus);\n+        break;\n+      }\n+\n+      try {\n+        TimeUnit.SECONDS.sleep(POLLING_SLEEP_TIME);\n+      } catch (InterruptedException e) {\n+        Log.warn(\"Interrupted during polling sleep\");\n+        break;\n+      }\n+    }\n+\n+    return taskDTO;\n+  }\n+\n+  private List<AnomalySummary> getAnomalies(long start, long end, String metric, String dataset) {\n+    List<AnomalySummary> anomalies =\n+        this.userDashboardResource.queryAnomalies(start, end, null, null, metric,\n+            dataset, null, false, null);\n+\n+    LOG.info(\"Successfully returned \" + anomalies.size() + \" anomalies.\");\n+    return anomalies;\n+  }\n+\n+  private void cleanStates(List<AnomalySummary> anomalies, TaskDTO taskDTO,\n+      MetricConfigDTO metricConfigDTO, DatasetConfigDTO datasetConfigDTO,\n+      DetectionConfigDTO detectionConfigDTO) {\n+    if (anomalies != null) {\n+      for (AnomalySummary anomaly : anomalies) {\n+        anomalyDAO.deleteById(anomaly.getId());\n+        LOG.info(\"Deleted anomaly with id: {}\", anomaly.getId());\n+      }\n+    }\n+\n+    if (datasetConfigDTO != null) {\n+      datasetConfigDAO.delete(datasetConfigDTO);\n+      LOG.info(\"Deleted dataset: {}\", datasetConfigDTO);\n+    }\n+\n+    if (metricConfigDTO != null) {\n+      metricConfigDAO.delete(metricConfigDTO);\n+      LOG.info(\"Deleted metric: {}\", metricConfigDTO);\n+    }\n+\n+    if (detectionConfigDTO != null) {\n+      detectionConfigDAO.delete(detectionConfigDTO);\n+      LOG.info(\"Deleted detection: {}\", detectionConfigDTO);\n+    }\n+\n+    if (taskDTO != null) {\n+      taskDAO.delete(taskDTO);", "originalCommit": "6d91338441effdb3e94eface7664035757ae2e4d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI4NjE0Nw==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r465286147", "bodyText": "Could we use the constants in DetectionConfigValidator? It is even nicer if you can refactor these constants into a separate class.", "author": "vincentchenjl", "createdAt": "2020-08-04T19:38:48Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";", "originalCommit": "6d91338441effdb3e94eface7664035757ae2e4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwNDE1MA==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r467204150", "bodyText": "I have removed many of those constants and only keep important ones. I think currently it is not necessary to provide a separate constant class since there are much fewer constants? If it is still necessary, please let me know. I will do that! Thanks!", "author": "jasonyanwenl", "createdAt": "2020-08-07T18:31:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI4NjE0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI4ODA4NA==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r465288084", "bodyText": "If this constant is only used once, you probably don't need to define it on the class level.", "author": "vincentchenjl", "createdAt": "2020-08-04T19:42:41Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";", "originalCommit": "6d91338441effdb3e94eface7664035757ae2e4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwMzUxNQ==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r467203515", "bodyText": "Yes, I have refactored part of them. Please check this commit.", "author": "jasonyanwenl", "createdAt": "2020-08-07T18:29:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI4ODA4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQxMjI3NA==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r465412274", "bodyText": "I think that we can put the failure stacktrace into the error message from taskDTO.", "author": "vincentchenjl", "createdAt": "2020-08-05T01:03:07Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time\n+    String nameSuffix = \"_\" + principal.getName();\n+\n+    try {\n+      if (payload.getBytes().length > MAX_ONLINE_PAYLOAD_SIZE) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Payload too large\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      JsonNode payloadNode = objectMapper.readTree(payload);\n+\n+      if (!validateOnlineRequestPayload(payloadNode)) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Invalid request payload\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Preprocess: remove existing entities generated by the previous interrupted request\n+      cleanExistingOnlineTask(nameSuffix);\n+\n+      // Create & save dataset\n+      datasetConfigDTO = generateDatasetConfig(payloadNode, nameSuffix);\n+\n+      // Create & save metric along with online data\n+      metricConfigDTO = generateMetricConfig(payloadNode, nameSuffix);\n+\n+      // Create & save detection\n+      detectionConfigDTO =\n+          generateDetectionConfig(payloadNode, nameSuffix, datasetConfigDTO, metricConfigDTO, start,\n+              end);\n+\n+      // Create & save task\n+      taskDTO = generateTaskConfig(detectionConfigDTO.getId(), start, end);\n+\n+      // Polling task status\n+      TaskDTO polledTaskDTO = pollingTask(taskDTO.getId());\n+\n+      // Task failure\n+      if (polledTaskDTO.getStatus() != TaskConstants.TaskStatus.COMPLETED) {\n+        LOG.warn(\"Task is not completed after polling: \" + polledTaskDTO);\n+\n+        responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+\n+        switch (polledTaskDTO.getStatus()) {\n+        case FAILED:\n+          responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+          responseMessage.put(\"message\", \"Failed to execute anomaly detection task.\");", "originalCommit": "6d91338441effdb3e94eface7664035757ae2e4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzNjQ1OA==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r467136458", "bodyText": "Yes. I already put that after this switch statement. Thanks!", "author": "jasonyanwenl", "createdAt": "2020-08-07T16:13:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQxMjI3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxMDkwMQ==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r466010901", "bodyText": "Can we have more specific name for this class, something like OnlineMetricConfigValidator? Also, can we do more validation, such as checking the metric column specified actually exists in the dataset?", "author": "vincentchenjl", "createdAt": "2020-08-05T21:20:27Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/validators/MetricConfigValidator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.validators;\n+\n+import java.util.Map;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+\n+public class MetricConfigValidator implements ConfigValidator<MetricConfigDTO> {\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+\n+  @Override\n+  public void validateConfig(MetricConfigDTO config) throws IllegalArgumentException {\n+    Preconditions.checkArgument(config.getName().startsWith(DEFAULT_METRIC_NAME));", "originalCommit": "6d91338441effdb3e94eface7664035757ae2e4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwMjk5Nw==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r467202997", "bodyText": "This is removed now. Please see this response.\nIn addition, currently, I didn't support customized time/metric column names. But thanks for your suggestion, you just reminded me to do so. Now my new commit has added this functionality. Please check this.", "author": "jasonyanwenl", "createdAt": "2020-08-07T18:28:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxMDkwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxMTM1NA==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r466011354", "bodyText": "Can we have more specific name for this class, something like OnlineDatasetConfigValidator?", "author": "vincentchenjl", "createdAt": "2020-08-05T21:21:26Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/validators/DatasetConfigValidator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.validators;\n+\n+import java.util.Map;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+\n+public class DatasetConfigValidator implements ConfigValidator<DatasetConfigDTO> {", "originalCommit": "6d91338441effdb3e94eface7664035757ae2e4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwMTcyMg==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r467201722", "bodyText": "This is removed now. Please see this response.", "author": "jasonyanwenl", "createdAt": "2020-08-07T18:26:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxMTM1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxMjgzNQ==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r466012835", "bodyText": "Why do we want to check this prefix? It looks like that this prefix is added by our code and it is guaranteed to happen, right? If we just need to validate the prefix, we should remove this class.", "author": "vincentchenjl", "createdAt": "2020-08-05T21:24:37Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/validators/DatasetConfigValidator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.validators;\n+\n+import java.util.Map;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+\n+public class DatasetConfigValidator implements ConfigValidator<DatasetConfigDTO> {\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+\n+  @Override\n+  public void validateConfig(DatasetConfigDTO config) throws IllegalArgumentException {\n+    Preconditions.checkArgument(config.getName().startsWith(DEFAULT_DATASET_NAME));", "originalCommit": "6d91338441effdb3e94eface7664035757ae2e4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwMTE1Mg==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r467201152", "bodyText": "Yes, you are right! I've removed both this class and metricConfigValidator. The initial purpose of those two classes is to provide a separate class to validate the format of the user input YAML files. Currently, since this endpoint does not support rich customized options, there is not too much to validate so I left them as blank. I deleted those two validators and we could add them back if it's needed in the future.", "author": "jasonyanwenl", "createdAt": "2020-08-07T18:24:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxMjgzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAyNTU5MQ==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r466025591", "bodyText": "What about attaching the failure stacktrace here rather than just a generic error message, since the error might help users to debug their configurations.", "author": "vincentchenjl", "createdAt": "2020-08-05T21:53:07Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time\n+    String nameSuffix = \"_\" + principal.getName();\n+\n+    try {\n+      if (payload.getBytes().length > MAX_ONLINE_PAYLOAD_SIZE) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Payload too large\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      JsonNode payloadNode = objectMapper.readTree(payload);\n+\n+      if (!validateOnlineRequestPayload(payloadNode)) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Invalid request payload\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Preprocess: remove existing entities generated by the previous interrupted request\n+      cleanExistingOnlineTask(nameSuffix);\n+\n+      // Create & save dataset\n+      datasetConfigDTO = generateDatasetConfig(payloadNode, nameSuffix);\n+\n+      // Create & save metric along with online data\n+      metricConfigDTO = generateMetricConfig(payloadNode, nameSuffix);\n+\n+      // Create & save detection\n+      detectionConfigDTO =\n+          generateDetectionConfig(payloadNode, nameSuffix, datasetConfigDTO, metricConfigDTO, start,\n+              end);\n+\n+      // Create & save task\n+      taskDTO = generateTaskConfig(detectionConfigDTO.getId(), start, end);\n+\n+      // Polling task status\n+      TaskDTO polledTaskDTO = pollingTask(taskDTO.getId());\n+\n+      // Task failure\n+      if (polledTaskDTO.getStatus() != TaskConstants.TaskStatus.COMPLETED) {\n+        LOG.warn(\"Task is not completed after polling: \" + polledTaskDTO);\n+\n+        responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+\n+        switch (polledTaskDTO.getStatus()) {\n+        case FAILED:\n+          responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+          responseMessage.put(\"message\", \"Failed to execute anomaly detection task.\");", "originalCommit": "6d91338441effdb3e94eface7664035757ae2e4d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzEzNjYzNQ==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r467136635", "bodyText": "Yes. Same as above, I already put that after this switch statement. Thanks!", "author": "jasonyanwenl", "createdAt": "2020-08-07T16:13:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAyNTU5MQ=="}], "type": "inlineReview"}, {"oid": "8b0382938e4edcbe9daa6c881a4e5e3a91a1d262", "url": "https://github.com/apache/pinot/commit/8b0382938e4edcbe9daa6c881a4e5e3a91a1d262", "message": "[TE] add anomaly detection as a service - Phase 1", "committedDate": "2020-08-06T20:32:41Z", "type": "commit"}, {"oid": "0f6fc6aa84f4c12efb2532fa8e1024556800da40", "url": "https://github.com/apache/pinot/commit/0f6fc6aa84f4c12efb2532fa8e1024556800da40", "message": "do not delete taskDTO as it will be cleaned periodically", "committedDate": "2020-08-06T20:32:41Z", "type": "commit"}, {"oid": "1460ea1194a72145262e7c7c1411a783ac944ab1", "url": "https://github.com/apache/pinot/commit/1460ea1194a72145262e7c7c1411a783ac944ab1", "message": "add timeout for polling task status", "committedDate": "2020-08-06T20:32:41Z", "type": "commit"}, {"oid": "1cda1caedde33c4e9ed4df57a97d8f36b46efce3", "url": "https://github.com/apache/pinot/commit/1cda1caedde33c4e9ed4df57a97d8f36b46efce3", "message": "Guice injection for anomaly detection resource", "committedDate": "2020-08-06T20:32:41Z", "type": "commit"}, {"oid": "3c5f97d2326d5d77b3c13203c1816e6c49da23fa", "url": "https://github.com/apache/pinot/commit/3c5f97d2326d5d77b3c13203c1816e6c49da23fa", "message": "save detection config in task info instead of DB", "committedDate": "2020-08-06T20:32:41Z", "type": "commit"}, {"oid": "9a9a2129e08c996f72a4ff91374d21002c5d15ce", "url": "https://github.com/apache/pinot/commit/9a9a2129e08c996f72a4ff91374d21002c5d15ce", "message": "rename online task name to DETECTION_ONLINE_<>", "committedDate": "2020-08-06T20:32:41Z", "type": "commit"}, {"oid": "bb66eab7f7013b72b28dce4bc8a35038700aca8d", "url": "https://github.com/apache/pinot/commit/bb66eab7f7013b72b28dce4bc8a35038700aca8d", "message": "delete existing metric/dataset by predicate", "committedDate": "2020-08-06T20:32:41Z", "type": "commit"}, {"oid": "0d2eb05d29b3925fc797e90fdbf12ab34ec16dd2", "url": "https://github.com/apache/pinot/commit/0d2eb05d29b3925fc797e90fdbf12ab34ec16dd2", "message": "add DETECTION_ONLINE task type in exception message", "committedDate": "2020-08-06T20:32:41Z", "type": "commit"}, {"oid": "7e717eda793b22794f58377414ee46d8845cb4d0", "url": "https://github.com/apache/pinot/commit/7e717eda793b22794f58377414ee46d8845cb4d0", "message": "delete existing anomalies", "committedDate": "2020-08-06T20:32:41Z", "type": "commit"}, {"oid": "d1e951e687aac8a2529e5b7cbe64d1fa6dce8134", "url": "https://github.com/apache/pinot/commit/d1e951e687aac8a2529e5b7cbe64d1fa6dce8134", "message": "batch delete generated anomalies by metric/dataset name", "committedDate": "2020-08-06T20:32:41Z", "type": "commit"}, {"oid": "d94eb714b20153c53955a2cd05c5f5edb7bc461b", "url": "https://github.com/apache/pinot/commit/d94eb714b20153c53955a2cd05c5f5edb7bc461b", "message": "add uuid in config name suffix", "committedDate": "2020-08-06T20:32:41Z", "type": "commit"}, {"oid": "d94eb714b20153c53955a2cd05c5f5edb7bc461b", "url": "https://github.com/apache/pinot/commit/d94eb714b20153c53955a2cd05c5f5edb7bc461b", "message": "add uuid in config name suffix", "committedDate": "2020-08-06T20:32:41Z", "type": "forcePushed"}, {"oid": "1591f7c71306870ac868d4ad48de83fce8d28311", "url": "https://github.com/apache/pinot/commit/1591f7c71306870ac868d4ad48de83fce8d28311", "message": "reduce class-level constant strings", "committedDate": "2020-08-06T23:55:27Z", "type": "commit"}, {"oid": "4d37ce053af3ada1921cea53fdfe6bb1c32c850d", "url": "https://github.com/apache/pinot/commit/4d37ce053af3ada1921cea53fdfe6bb1c32c850d", "message": "support customized metric/time column names; add column name consistency validation; remove dataset/metric validator;", "committedDate": "2020-08-07T16:50:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTYwMTIzNg==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r469601236", "bodyText": "@jasonyanwenl Sorry we missed this one earlier. Will this making it only picking up the Detection task here? This could be a serious issue because it won't be picking up other tasks, for example, sending out the notification, run detection onboarding, etc. Could you double-check?\n@vincentchenjl @akshayrai FYI, we may need to hold on deployment to prod.\n@suvodeep-pyne thanks for reporting this", "author": "jihaozh", "createdAt": "2020-08-12T23:24:38Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskDriver.java", "diffHunk": "@@ -183,8 +192,11 @@ private TaskDTO acquireTask() {\n       try {\n         // randomize fetching head and tail to reduce synchronized patterns across threads (and hosts)\n         boolean orderAscending = System.currentTimeMillis() % 2 == 0;\n+\n+        // find by task type to separate online task from a normal task\n+        TaskType type = this.isOnline ? TaskType.DETECTION_ONLINE : TaskType.DETECTION;\n         anomalyTasks = taskDAO\n-            .findByStatusOrderByCreateTime(TaskStatus.WAITING, driverConfiguration.getTaskFetchSizeCap(),\n+            .findByStatusAndTypeOrderByCreateTime(TaskStatus.WAITING, type, driverConfiguration.getTaskFetchSizeCap(),", "originalCommit": "4d37ce053af3ada1921cea53fdfe6bb1c32c850d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTYwNjYwNA==", "url": "https://github.com/apache/pinot/pull/5769#discussion_r469606604", "bodyText": "Thank you so much. Really sorry about this. This is an issue. I will send a PR soon today.", "author": "jasonyanwenl", "createdAt": "2020-08-12T23:41:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTYwMTIzNg=="}], "type": "inlineReview"}]}