{"pr_number": 5778, "pr_title": "[TE] The endpoint for searching anomalies and pagination", "pr_createdAt": "2020-07-30T20:35:04Z", "pr_url": "https://github.com/apache/pinot/pull/5778", "timeline": [{"oid": "ee879b17116fe46cb33b5cdb548ea602313692e0", "url": "https://github.com/apache/pinot/commit/ee879b17116fe46cb33b5cdb548ea602313692e0", "message": "- new anomalies endpoint and unit tests", "committedDate": "2020-07-30T20:53:30Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNDM5OA==", "url": "https://github.com/apache/pinot/pull/5778#discussion_r463314398", "bodyText": "add header", "author": "bxji", "createdAt": "2020-07-30T22:50:43Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearchFilter.java", "diffHunk": "@@ -0,0 +1,132 @@\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import java.util.Collections;\n+import java.util.List;\n+\n+", "originalCommit": "ee879b17116fe46cb33b5cdb548ea602313692e0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNDQ1NA==", "url": "https://github.com/apache/pinot/pull/5778#discussion_r463314454", "bodyText": "add header", "author": "bxji", "createdAt": "2020-07-30T22:50:55Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearchResource.java", "diffHunk": "@@ -0,0 +1,61 @@\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import java.util.List;\n+import javax.ws.rs.DefaultValue;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;", "originalCommit": "ee879b17116fe46cb33b5cdb548ea602313692e0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNDUzNg==", "url": "https://github.com/apache/pinot/pull/5778#discussion_r463314536", "bodyText": "add header", "author": "bxji", "createdAt": "2020-07-30T22:51:13Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearcher.java", "diffHunk": "@@ -0,0 +1,142 @@\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import com.google.common.collect.ImmutableMap;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;", "originalCommit": "ee879b17116fe46cb33b5cdb548ea602313692e0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNDY1Ng==", "url": "https://github.com/apache/pinot/pull/5778#discussion_r463314656", "bodyText": "header", "author": "bxji", "createdAt": "2020-07-30T22:51:34Z", "path": "thirdeye/thirdeye-pinot/src/test/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearcherTest.java", "diffHunk": "@@ -0,0 +1,68 @@\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;", "originalCommit": "ee879b17116fe46cb33b5cdb548ea602313692e0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNzA1Nw==", "url": "https://github.com/apache/pinot/pull/5778#discussion_r463317057", "bodyText": "Just want to check my understanding; I see that we are starting with offset of 0. So my understanding is that if we have limit 25, the anomalies returned should be 0-24?\nIf so, since we are starting with offset of 0, do we need >= as the equality check here?", "author": "bxji", "createdAt": "2020-07-30T22:59:13Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearcher.java", "diffHunk": "@@ -0,0 +1,142 @@\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import com.google.common.collect.ImmutableMap;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.pinot.thirdeye.constant.AnomalyFeedbackType;\n+import org.apache.pinot.thirdeye.datalayer.bao.DetectionAlertConfigManager;\n+import org.apache.pinot.thirdeye.datalayer.bao.DetectionConfigManager;\n+import org.apache.pinot.thirdeye.datalayer.bao.MergedAnomalyResultManager;\n+import org.apache.pinot.thirdeye.datalayer.dto.AbstractDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MergedAnomalyResultDTO;\n+import org.apache.pinot.thirdeye.datalayer.pojo.DetectionConfigBean;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+\n+import static org.apache.pinot.thirdeye.constant.AnomalyFeedbackType.*;\n+\n+\n+/**\n+ * The type Anomaly searcher.\n+ */\n+public class AnomalySearcher {\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DetectionAlertConfigManager detectionAlertConfigDAO;\n+\n+  /**\n+   * Instantiates a new Anomaly searcher.\n+   */\n+  public AnomalySearcher() {\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.detectionAlertConfigDAO = DAORegistry.getInstance().getDetectionAlertConfigManager();\n+  }\n+\n+  /**\n+   * Search and retrieve all the anomalies matching to the search filter and limits.\n+   *\n+   * @param searchFilter the search filter\n+   * @param limit the limit\n+   * @param offset the offset\n+   * @return the result\n+   */\n+  public Map<String, Object> search(AnomalySearchFilter searchFilter, int limit, int offset) {\n+    Predicate predicate = Predicate.EQ(\"child\", false);\n+    if (searchFilter.getStartTime() != null) {\n+      predicate = Predicate.AND(predicate, Predicate.LT(\"startTime\", searchFilter.getEndTime()));\n+    }\n+    if (searchFilter.getEndTime() != null) {\n+      predicate = Predicate.AND(predicate, Predicate.GT(\"endTime\", searchFilter.getStartTime()));\n+    }\n+    // search by detections or subscription groups\n+    Set<Long> detectionConfigIds = new HashSet<>();\n+    Set<Long> subscribedDetectionConfigIds = new HashSet<>();\n+    if (!searchFilter.getDetectionNames().isEmpty()) {\n+      detectionConfigIds =\n+          this.detectionConfigDAO.findByPredicate(Predicate.IN(\"name\", searchFilter.getDetectionNames().toArray()))\n+              .stream()\n+              .map(DetectionConfigBean::getId)\n+              .collect(Collectors.toSet());\n+    }\n+    if (!searchFilter.getSubscriptionGroups().isEmpty()) {\n+      subscribedDetectionConfigIds = this.detectionAlertConfigDAO.findByPredicate(\n+          Predicate.IN(\"name\", searchFilter.getSubscriptionGroups().toArray()))\n+          .stream()\n+          .map(detectionAlertConfigDTO -> detectionAlertConfigDTO.getVectorClocks().keySet())\n+          .flatMap(Collection::stream)\n+          .collect(Collectors.toSet());\n+    }\n+    if (!searchFilter.getDetectionNames().isEmpty() && !searchFilter.getSubscriptionGroups().isEmpty()) {\n+      // intersect the detection config ids if searching by both\n+      detectionConfigIds.retainAll(subscribedDetectionConfigIds);\n+    } else {\n+      detectionConfigIds.addAll(subscribedDetectionConfigIds);\n+    }\n+    if (!searchFilter.getDetectionNames().isEmpty() || !searchFilter.getSubscriptionGroups().isEmpty()) {\n+      // add the predicate using detection config id\n+      if (detectionConfigIds.isEmpty()) {\n+        // if detection not found, return empty result\n+        return ImmutableMap.of(\"count\", 0, \"limit\", limit, \"offset\", offset, \"elements\", Collections.emptyList());\n+      }\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"detectionConfigId\", detectionConfigIds.toArray()));\n+    }\n+\n+    // search by datasets\n+    if (!searchFilter.getDatasets().isEmpty()) {\n+      List<Predicate> datasetPredicates = new ArrayList<>();\n+      for (String dataset : searchFilter.getDatasets()) {\n+        datasetPredicates.add(Predicate.LIKE(\"collection\", \"%\" + dataset + \"%\"));\n+      }\n+      predicate = Predicate.AND(predicate, Predicate.OR(datasetPredicates.toArray(new Predicate[0])));\n+    }\n+    // search by metrics\n+    if (!searchFilter.getMetrics().isEmpty()) {\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"metric\", searchFilter.getMetrics().toArray()));\n+    }\n+    // search by ids\n+    if (!searchFilter.getAnomalyIds().isEmpty()) {\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"baseId\", searchFilter.getAnomalyIds().toArray()));\n+    }\n+\n+    long count;\n+    List<MergedAnomalyResultDTO> results;\n+    if (searchFilter.getFeedbacks().isEmpty()) {\n+      List<Long> anomalyIds = this.anomalyDAO.findIdsByPredicate(predicate)\n+          .stream()\n+          .sorted(Comparator.reverseOrder())\n+          .collect(Collectors.toList());\n+      count = anomalyIds.size();\n+      results = anomalyIds.isEmpty() ? Collections.emptyList()\n+          : this.anomalyDAO.findByIds(paginateResults(anomalyIds, offset, limit));\n+    } else {\n+      // filter by feedback types if requested\n+      List<MergedAnomalyResultDTO> anomalies = this.anomalyDAO.findByPredicate(predicate);\n+      Set<AnomalyFeedbackType> feedbackFilters =\n+          searchFilter.getFeedbacks().stream().map(AnomalyFeedbackType::valueOf).collect(Collectors.toSet());\n+      results = anomalies.stream()\n+          .filter(anomaly -> (anomaly.getFeedback() == null && feedbackFilters.contains(NO_FEEDBACK)) || (\n+              anomaly.getFeedback() != null && feedbackFilters.contains(anomaly.getFeedback().getFeedbackType())))\n+          .sorted(Comparator.comparingLong(AbstractDTO::getId).reversed())\n+          .collect(Collectors.toList());\n+      count = results.size();\n+      results = paginateResults(results, offset, limit);\n+    }\n+    return ImmutableMap.of(\"count\", count, \"limit\", limit, \"offset\", offset, \"elements\", results);\n+  }\n+\n+  private <T> List<T> paginateResults(List<T> list, int offset, int limit) {", "originalCommit": "ee879b17116fe46cb33b5cdb548ea602313692e0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIzOTY4Nw==", "url": "https://github.com/apache/pinot/pull/5778#discussion_r465239687", "bodyText": "+1, good to see you Bryan!", "author": "akshayrai", "createdAt": "2020-08-04T18:16:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNzA1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIwNDE4Mg==", "url": "https://github.com/apache/pinot/pull/5778#discussion_r465204182", "bodyText": "You might want to describe these fields better or if they are intuitive enough I would usually not make an entry at all.", "author": "akshayrai", "createdAt": "2020-08-04T17:13:36Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearchResource.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ */\n+\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import java.util.List;\n+import javax.ws.rs.DefaultValue;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.thirdeye.api.Constants;\n+\n+\n+/**\n+ * The type Anomaly search resource.\n+ */\n+@Path(value = \"/anomaly-search\")\n+@Produces(MediaType.APPLICATION_JSON)\n+@Api(tags = {Constants.DETECTION_TAG})\n+public class AnomalySearchResource {\n+\n+  private final AnomalySearcher anomalySearcher;\n+\n+  /**\n+   * Instantiates a new Anomaly search resource.\n+   */\n+  public AnomalySearchResource() {\n+    this.anomalySearcher = new AnomalySearcher();\n+  }\n+\n+  /**\n+   * Search and paginate the anomalies according to the parameters.\n+   *\n+   * @param limit the limit\n+   * @param offset the offset\n+   * @param startTime the start time\n+   * @param endTime the end time\n+   * @param feedbacks the feedback types, e.g. ANOMALY, NOT_ANOMALY\n+   * @param subscriptionGroups the subscription groups\n+   * @param detectionNames the detection names\n+   * @param metrics the metrics\n+   * @param datasets the datasets\n+   * @param anomalyIds the anomaly ids\n+   * @return the response", "originalCommit": "9586523bc5505524dfc7d985321f96f9130bae10", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIxMDE5Mg==", "url": "https://github.com/apache/pinot/pull/5778#discussion_r465210192", "bodyText": "How about merging and enriching the existing query anomalies endpoint in UserDashboardResource?", "author": "akshayrai", "createdAt": "2020-08-04T17:24:00Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearchResource.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ */\n+\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import java.util.List;\n+import javax.ws.rs.DefaultValue;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.thirdeye.api.Constants;\n+\n+\n+/**\n+ * The type Anomaly search resource.\n+ */\n+@Path(value = \"/anomaly-search\")", "originalCommit": "9586523bc5505524dfc7d985321f96f9130bae10", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI2MTIwMg==", "url": "https://github.com/apache/pinot/pull/5778#discussion_r465261202", "bodyText": "I'd prefer to keep them separate and eventually we will want to deprecate the old file.\nReasons:\n\nthe input for the endpoints is quite different, the new one needs to support filter by multiple datasets, metrics, while the old one can only handle a single filter in each field.\nthe response formatting for this one is quite different. In the new one, it needs to add the pagination information, the anomaly result is on another level in the blob.\n\nTherefore just updating the old one is not going to be backward compatible.\nAlso, in the old one, in the case of multiple filters, the filters are applied in memory instead of pushing to the database, so it's not efficient when handling a large number of anomalies.", "author": "jihaozh", "createdAt": "2020-08-04T18:55:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIxMDE5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIxMzMyNw==", "url": "https://github.com/apache/pinot/pull/5778#discussion_r465213327", "bodyText": "This is generic enough to move out into a utility?", "author": "akshayrai", "createdAt": "2020-08-04T17:29:17Z", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearcher.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ */\n+\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import com.google.common.collect.ImmutableMap;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.pinot.thirdeye.constant.AnomalyFeedbackType;\n+import org.apache.pinot.thirdeye.datalayer.bao.DetectionAlertConfigManager;\n+import org.apache.pinot.thirdeye.datalayer.bao.DetectionConfigManager;\n+import org.apache.pinot.thirdeye.datalayer.bao.MergedAnomalyResultManager;\n+import org.apache.pinot.thirdeye.datalayer.dto.AbstractDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MergedAnomalyResultDTO;\n+import org.apache.pinot.thirdeye.datalayer.pojo.DetectionConfigBean;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+\n+import static org.apache.pinot.thirdeye.constant.AnomalyFeedbackType.*;\n+\n+\n+/**\n+ * The type Anomaly searcher.\n+ */\n+public class AnomalySearcher {\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DetectionAlertConfigManager detectionAlertConfigDAO;\n+\n+  /**\n+   * Instantiates a new Anomaly searcher.\n+   */\n+  public AnomalySearcher() {\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.detectionAlertConfigDAO = DAORegistry.getInstance().getDetectionAlertConfigManager();\n+  }\n+\n+  /**\n+   * Search and retrieve all the anomalies matching to the search filter and limits.\n+   *\n+   * @param searchFilter the search filter\n+   * @param limit the limit\n+   * @param offset the offset\n+   * @return the result\n+   */\n+  public Map<String, Object> search(AnomalySearchFilter searchFilter, int limit, int offset) {\n+    Predicate predicate = Predicate.EQ(\"child\", false);\n+    if (searchFilter.getStartTime() != null) {\n+      predicate = Predicate.AND(predicate, Predicate.LT(\"startTime\", searchFilter.getEndTime()));\n+    }\n+    if (searchFilter.getEndTime() != null) {\n+      predicate = Predicate.AND(predicate, Predicate.GT(\"endTime\", searchFilter.getStartTime()));\n+    }\n+    // search by detections or subscription groups\n+    Set<Long> detectionConfigIds = new HashSet<>();\n+    Set<Long> subscribedDetectionConfigIds = new HashSet<>();\n+    if (!searchFilter.getDetectionNames().isEmpty()) {\n+      detectionConfigIds =\n+          this.detectionConfigDAO.findByPredicate(Predicate.IN(\"name\", searchFilter.getDetectionNames().toArray()))\n+              .stream()\n+              .map(DetectionConfigBean::getId)\n+              .collect(Collectors.toSet());\n+    }\n+    if (!searchFilter.getSubscriptionGroups().isEmpty()) {\n+      subscribedDetectionConfigIds = this.detectionAlertConfigDAO.findByPredicate(\n+          Predicate.IN(\"name\", searchFilter.getSubscriptionGroups().toArray()))\n+          .stream()\n+          .map(detectionAlertConfigDTO -> detectionAlertConfigDTO.getVectorClocks().keySet())\n+          .flatMap(Collection::stream)\n+          .collect(Collectors.toSet());\n+    }\n+    if (!searchFilter.getDetectionNames().isEmpty() && !searchFilter.getSubscriptionGroups().isEmpty()) {\n+      // intersect the detection config ids if searching by both\n+      detectionConfigIds.retainAll(subscribedDetectionConfigIds);\n+    } else {\n+      detectionConfigIds.addAll(subscribedDetectionConfigIds);\n+    }\n+    if (!searchFilter.getDetectionNames().isEmpty() || !searchFilter.getSubscriptionGroups().isEmpty()) {\n+      // add the predicate using detection config id\n+      if (detectionConfigIds.isEmpty()) {\n+        // if detection not found, return empty result\n+        return ImmutableMap.of(\"count\", 0, \"limit\", limit, \"offset\", offset, \"elements\", Collections.emptyList());\n+      }\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"detectionConfigId\", detectionConfigIds.toArray()));\n+    }\n+\n+    // search by datasets\n+    if (!searchFilter.getDatasets().isEmpty()) {\n+      List<Predicate> datasetPredicates = new ArrayList<>();\n+      for (String dataset : searchFilter.getDatasets()) {\n+        datasetPredicates.add(Predicate.LIKE(\"collection\", \"%\" + dataset + \"%\"));\n+      }\n+      predicate = Predicate.AND(predicate, Predicate.OR(datasetPredicates.toArray(new Predicate[0])));\n+    }\n+    // search by metrics\n+    if (!searchFilter.getMetrics().isEmpty()) {\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"metric\", searchFilter.getMetrics().toArray()));\n+    }\n+    // search by ids\n+    if (!searchFilter.getAnomalyIds().isEmpty()) {\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"baseId\", searchFilter.getAnomalyIds().toArray()));\n+    }\n+\n+    long count;\n+    List<MergedAnomalyResultDTO> results;\n+    if (searchFilter.getFeedbacks().isEmpty()) {\n+      List<Long> anomalyIds = this.anomalyDAO.findIdsByPredicate(predicate)\n+          .stream()\n+          .sorted(Comparator.reverseOrder())\n+          .collect(Collectors.toList());\n+      count = anomalyIds.size();\n+      results = anomalyIds.isEmpty() ? Collections.emptyList()\n+          : this.anomalyDAO.findByIds(paginateResults(anomalyIds, offset, limit));\n+    } else {\n+      // filter by feedback types if requested\n+      List<MergedAnomalyResultDTO> anomalies = this.anomalyDAO.findByPredicate(predicate);\n+      Set<AnomalyFeedbackType> feedbackFilters =\n+          searchFilter.getFeedbacks().stream().map(AnomalyFeedbackType::valueOf).collect(Collectors.toSet());\n+      results = anomalies.stream()\n+          .filter(anomaly -> (anomaly.getFeedback() == null && feedbackFilters.contains(NO_FEEDBACK)) || (\n+              anomaly.getFeedback() != null && feedbackFilters.contains(anomaly.getFeedback().getFeedbackType())))\n+          .sorted(Comparator.comparingLong(AbstractDTO::getId).reversed())\n+          .collect(Collectors.toList());\n+      count = results.size();\n+      results = paginateResults(results, offset, limit);\n+    }\n+    return ImmutableMap.of(\"count\", count, \"limit\", limit, \"offset\", offset, \"elements\", results);\n+  }\n+\n+  private <T> List<T> paginateResults(List<T> list, int offset, int limit) {", "originalCommit": "9586523bc5505524dfc7d985321f96f9130bae10", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI1NTkzNA==", "url": "https://github.com/apache/pinot/pull/5778#discussion_r465255934", "bodyText": "make sense", "author": "jihaozh", "createdAt": "2020-08-04T18:45:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIxMzMyNw=="}], "type": "inlineReview"}, {"oid": "bc2a834ad4443a7f7de77b454993e8de25d90d0b", "url": "https://github.com/apache/pinot/commit/bc2a834ad4443a7f7de77b454993e8de25d90d0b", "message": "- new anomalies endpoint and unit tests", "committedDate": "2020-08-04T18:40:52Z", "type": "commit"}, {"oid": "d411dcdd2902a4fb42c2f88e39f8c4aba4b5bd03", "url": "https://github.com/apache/pinot/commit/d411dcdd2902a4fb42c2f88e39f8c4aba4b5bd03", "message": "address comments", "committedDate": "2020-08-04T18:44:37Z", "type": "commit"}, {"oid": "d411dcdd2902a4fb42c2f88e39f8c4aba4b5bd03", "url": "https://github.com/apache/pinot/commit/d411dcdd2902a4fb42c2f88e39f8c4aba4b5bd03", "message": "address comments", "committedDate": "2020-08-04T18:44:37Z", "type": "forcePushed"}]}