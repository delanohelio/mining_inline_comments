{"pr_number": 5967, "pr_title": "Adding push job type of segment metadata only mode", "pr_createdAt": "2020-09-03T07:37:16Z", "pr_url": "https://github.com/apache/pinot/pull/5967", "timeline": [{"oid": "e3095b279bc19f938e4bb97470a3053159e48685", "url": "https://github.com/apache/pinot/commit/e3095b279bc19f938e4bb97470a3053159e48685", "message": "Adding push job type of segment metadata only mode", "committedDate": "2020-09-03T07:37:54Z", "type": "forcePushed"}, {"oid": "cb159a356f7ec13ae930f41b95fee0f2e0b00cc9", "url": "https://github.com/apache/pinot/commit/cb159a356f7ec13ae930f41b95fee0f2e0b00cc9", "message": "Adding push job type of segment metadata only mode", "committedDate": "2020-09-03T23:29:05Z", "type": "forcePushed"}, {"oid": "bb4e5dab25d62ac7a3cc276d4dc89dd61afcc76d", "url": "https://github.com/apache/pinot/commit/bb4e5dab25d62ac7a3cc276d4dc89dd61afcc76d", "message": "Adding push job type of segment metadata only mode", "committedDate": "2020-09-23T20:41:49Z", "type": "forcePushed"}, {"oid": "7d72d386c5c13b1b7d53dbe92fe95807d024e45e", "url": "https://github.com/apache/pinot/commit/7d72d386c5c13b1b7d53dbe92fe95807d024e45e", "message": "Adding push job type of segment metadata only mode", "committedDate": "2020-09-24T01:30:36Z", "type": "forcePushed"}, {"oid": "a0aa8e698913711de1250e2069a95641aa1bd5ac", "url": "https://github.com/apache/pinot/commit/a0aa8e698913711de1250e2069a95641aa1bd5ac", "message": "Adding push job type of segment metadata only mode", "committedDate": "2020-09-24T01:38:02Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM3NjQ3OA==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496376478", "bodyText": "Should we add a new FileUploadType: METADATA instead of using this extra boolean flag?", "author": "Jackie-Jiang", "createdAt": "2020-09-29T04:23:37Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotSegmentUploadDownloadRestletResource.java", "diffHunk": "@@ -182,7 +182,8 @@ public Response downloadSegment(\n   }\n \n   private SuccessResponse uploadSegment(@Nullable String tableName, FormDataMultiPart multiPart,\n-      boolean enableParallelPushProtection, HttpHeaders headers, Request request, boolean moveSegmentToFinalLocation) {\n+      boolean enableParallelPushProtection, HttpHeaders headers, Request request, boolean moveSegmentToFinalLocation,", "originalCommit": "662b7b581942379896e01cbcd972bc815710d64b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjkwNjgyMA==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496906820", "bodyText": "added.", "author": "xiangfu0", "createdAt": "2020-09-29T17:15:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM3NjQ3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM3ODU3Mg==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496378572", "bodyText": "Suggest reusing the existing APIs and use headers to differentiate segment/metadata upload.\nUsing POST /segmentmetadata to upload segments seems counter-intuitive to me.", "author": "Jackie-Jiang", "createdAt": "2020-09-29T04:26:33Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotSegmentUploadDownloadRestletResource.java", "diffHunk": "@@ -454,7 +465,41 @@ public void uploadSegmentAsMultiPartV2(FormDataMultiPart multiPart,\n       @ApiParam(value = \"Whether to enable parallel push protection\") @DefaultValue(\"false\") @QueryParam(FileUploadDownloadClient.QueryParameters.ENABLE_PARALLEL_PUSH_PROTECTION) boolean enableParallelPushProtection,\n       @Context HttpHeaders headers, @Context Request request, @Suspended final AsyncResponse asyncResponse) {\n     try {\n-      asyncResponse.resume(uploadSegment(tableName, multiPart, enableParallelPushProtection, headers, request, true));\n+      asyncResponse.resume(uploadSegment(tableName, multiPart, enableParallelPushProtection, headers, request, true, false));\n+    } catch (Throwable t) {\n+      asyncResponse.resume(t);\n+    }\n+  }\n+\n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @Path(\"/segmentmetadata\")", "originalCommit": "662b7b581942379896e01cbcd972bc815710d64b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM3OTQ2Nw==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496379467", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                LOGGER.info(\"Start pushing segments: {}... to locations: {} for table {}\",\n          \n          \n            \n                LOGGER.info(\"Start pushing segment metadata: {} to locations: {} for table {}\",", "author": "Jackie-Jiang", "createdAt": "2020-09-29T04:27:45Z", "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +187,125 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriToTarPathMap(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)\n+      throws Exception {\n+    String tableName = spec.getTableSpec().getTableName();\n+    LOGGER.info(\"Start pushing segments: {}... to locations: {} for table {}\",", "originalCommit": "662b7b581942379896e01cbcd972bc815710d64b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM4MDc3NA==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496380774", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    Arrays.toString(segmentUriToTarPathMap.entrySet().toArray()),\n          \n          \n            \n                    segmentUriToTarPathMap,", "author": "Jackie-Jiang", "createdAt": "2020-09-29T04:29:42Z", "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +187,125 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriToTarPathMap(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)\n+      throws Exception {\n+    String tableName = spec.getTableSpec().getTableName();\n+    LOGGER.info(\"Start pushing segments: {}... to locations: {} for table {}\",\n+        Arrays.toString(segmentUriToTarPathMap.entrySet().toArray()),", "originalCommit": "662b7b581942379896e01cbcd972bc815710d64b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM4MTUwNw==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496381507", "bodyText": "Suggest using UUID", "author": "Jackie-Jiang", "createdAt": "2020-09-29T04:30:50Z", "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +187,125 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriToTarPathMap(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)\n+      throws Exception {\n+    String tableName = spec.getTableSpec().getTableName();\n+    LOGGER.info(\"Start pushing segments: {}... to locations: {} for table {}\",\n+        Arrays.toString(segmentUriToTarPathMap.entrySet().toArray()),\n+        Arrays.toString(spec.getPinotClusterSpecs()), tableName);\n+    for (String segmentUriPath : segmentUriToTarPathMap.keySet()) {\n+      String tarFilePath = segmentUriToTarPathMap.get(segmentUriPath);\n+      String fileName = new File(tarFilePath).getName();\n+      Preconditions.checkArgument(fileName.endsWith(Constants.TAR_GZ_FILE_EXT));\n+      String segmentName = fileName.substring(0, fileName.length() - Constants.TAR_GZ_FILE_EXT.length());\n+      File segmentMetadataFile = new File(FileUtils.getTempDirectory(), \"segmentMetadataFile-\" + System.nanoTime() + TarGzCompressionUtils.TAR_GZ_FILE_EXTENSION);\n+      generateSegmentMetadataFile(fileSystem, URI.create(tarFilePath), segmentMetadataFile);\n+      try {\n+        for (PinotClusterSpec pinotClusterSpec : spec.getPinotClusterSpecs()) {\n+          URI controllerURI;\n+          try {\n+            controllerURI = new URI(pinotClusterSpec.getControllerURI());\n+          } catch (URISyntaxException e) {\n+            throw new RuntimeException(\"Got invalid controller uri - '\" + pinotClusterSpec.getControllerURI() + \"'\");\n+          }\n+          LOGGER.info(\"Pushing segment: {} to location: {} for table {}\", segmentName, controllerURI, tableName);\n+          int attempts = 1;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushAttempts() > 0) {\n+            attempts = spec.getPushJobSpec().getPushAttempts();\n+          }\n+          long retryWaitMs = 1000L;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushRetryIntervalMillis() > 0) {\n+            retryWaitMs = spec.getPushJobSpec().getPushRetryIntervalMillis();\n+          }\n+          RetryPolicies.exponentialBackoffRetryPolicy(attempts, retryWaitMs, 5).attempt(() -> {\n+            try {\n+              List<Header> headers = ImmutableList.of(new BasicHeader(FileUploadDownloadClient.CustomHeaders.DOWNLOAD_URI, segmentUriPath));\n+              // Add table name as a request parameter\n+              NameValuePair tableNameValuePair =\n+                  new BasicNameValuePair(FileUploadDownloadClient.QueryParameters.TABLE_NAME, tableName);\n+              List<NameValuePair> parameters = Arrays.asList(tableNameValuePair);\n+              SimpleHttpResponse response = FILE_UPLOAD_DOWNLOAD_CLIENT.uploadSegmentMetadata(FileUploadDownloadClient.getUploadSegmentMetadataURI(controllerURI),\n+                  segmentName, segmentMetadataFile, headers, parameters, FILE_UPLOAD_DOWNLOAD_CLIENT.DEFAULT_SOCKET_TIMEOUT_MS);\n+              LOGGER.info(\"Response for pushing table {} segment {} to location {} - {}: {}\", tableName, segmentName,\n+                  controllerURI, response.getStatusCode(), response.getResponse());\n+              return true;\n+            } catch (HttpErrorStatusException e) {\n+              int statusCode = e.getStatusCode();\n+              if (statusCode >= 500) {\n+                // Temporary exception\n+                LOGGER\n+                    .warn(\"Caught temporary exception while pushing table: {} segment: {} to {}, will retry\", tableName,\n+                        segmentName, controllerURI, e);\n+                return false;\n+              } else {\n+                // Permanent exception\n+                LOGGER.error(\"Caught permanent exception while pushing table: {} segment: {} to {}, won't retry\",\n+                    tableName, segmentName, controllerURI, e);\n+                throw e;\n+              }\n+            }\n+          });\n+        }\n+      } finally {\n+        FileUtils.deleteQuietly(segmentMetadataFile);\n+      }\n+    }\n+  }\n+\n+  public static Map<String, String> getSegmentUriToTarPathMap(URI outputDirURI, String uriPrefix, String uriSuffix, String[] files) {\n+    Map<String, String> segmentUriToTarPathMap = new HashMap<>();\n+    for (String file : files) {\n+      URI uri = URI.create(file);\n+      if (uri.getPath().endsWith(Constants.TAR_GZ_FILE_EXT)) {\n+        URI updatedURI = SegmentPushUtils.generateSegmentTarURI(outputDirURI, uri, uriPrefix,uriSuffix);\n+        segmentUriToTarPathMap.put(updatedURI.toString(), file);\n+      }\n+    }\n+    return segmentUriToTarPathMap;\n+  }\n+\n+  /**\n+   * Generate a segment metadata only tar file, which contains only metadata.properties and creation.meta file.\n+   * The purpose of this is to create a lean tar to push to Pinot controller for adding segments without downloading\n+   * the complete segment and untar the segment tarball.\n+   *\n+   * 1. Download segment tar file to temp dir;\n+   * 2. Extract only metadata.properties and creation.meta files from the segment tar file;\n+   * 3. Tar both files into a segment metadata file.\n+   *\n+   */\n+  private static boolean generateSegmentMetadataFile(PinotFS fileSystem, URI tarFileURI, File segmentMetadataTarFile)\n+      throws Exception {\n+    long currentTime = System.nanoTime();", "originalCommit": "662b7b581942379896e01cbcd972bc815710d64b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM4MjE4Ng==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496382186", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                File tarFile = new File(FileUtils.getTempDirectory(), \"segmentTar-\" + currentTime + TarGzCompressionUtils.TAR_GZ_FILE_EXTENSION).getAbsoluteFile();\n          \n          \n            \n                File segmentMetadataDir = new File(FileUtils.getTempDirectory(), \"segmentMetadataDir-\" + currentTime).getAbsoluteFile();\n          \n          \n            \n                File tarFile = new File(FileUtils.getTempDirectory(), \"segmentTar-\" + currentTime + TarGzCompressionUtils.TAR_GZ_FILE_EXTENSION);\n          \n          \n            \n                File segmentMetadataDir = new File(FileUtils.getTempDirectory(), \"segmentMetadataDir-\" + currentTime);", "author": "Jackie-Jiang", "createdAt": "2020-09-29T04:31:53Z", "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +187,125 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriToTarPathMap(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)\n+      throws Exception {\n+    String tableName = spec.getTableSpec().getTableName();\n+    LOGGER.info(\"Start pushing segments: {}... to locations: {} for table {}\",\n+        Arrays.toString(segmentUriToTarPathMap.entrySet().toArray()),\n+        Arrays.toString(spec.getPinotClusterSpecs()), tableName);\n+    for (String segmentUriPath : segmentUriToTarPathMap.keySet()) {\n+      String tarFilePath = segmentUriToTarPathMap.get(segmentUriPath);\n+      String fileName = new File(tarFilePath).getName();\n+      Preconditions.checkArgument(fileName.endsWith(Constants.TAR_GZ_FILE_EXT));\n+      String segmentName = fileName.substring(0, fileName.length() - Constants.TAR_GZ_FILE_EXT.length());\n+      File segmentMetadataFile = new File(FileUtils.getTempDirectory(), \"segmentMetadataFile-\" + System.nanoTime() + TarGzCompressionUtils.TAR_GZ_FILE_EXTENSION);\n+      generateSegmentMetadataFile(fileSystem, URI.create(tarFilePath), segmentMetadataFile);\n+      try {\n+        for (PinotClusterSpec pinotClusterSpec : spec.getPinotClusterSpecs()) {\n+          URI controllerURI;\n+          try {\n+            controllerURI = new URI(pinotClusterSpec.getControllerURI());\n+          } catch (URISyntaxException e) {\n+            throw new RuntimeException(\"Got invalid controller uri - '\" + pinotClusterSpec.getControllerURI() + \"'\");\n+          }\n+          LOGGER.info(\"Pushing segment: {} to location: {} for table {}\", segmentName, controllerURI, tableName);\n+          int attempts = 1;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushAttempts() > 0) {\n+            attempts = spec.getPushJobSpec().getPushAttempts();\n+          }\n+          long retryWaitMs = 1000L;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushRetryIntervalMillis() > 0) {\n+            retryWaitMs = spec.getPushJobSpec().getPushRetryIntervalMillis();\n+          }\n+          RetryPolicies.exponentialBackoffRetryPolicy(attempts, retryWaitMs, 5).attempt(() -> {\n+            try {\n+              List<Header> headers = ImmutableList.of(new BasicHeader(FileUploadDownloadClient.CustomHeaders.DOWNLOAD_URI, segmentUriPath));\n+              // Add table name as a request parameter\n+              NameValuePair tableNameValuePair =\n+                  new BasicNameValuePair(FileUploadDownloadClient.QueryParameters.TABLE_NAME, tableName);\n+              List<NameValuePair> parameters = Arrays.asList(tableNameValuePair);\n+              SimpleHttpResponse response = FILE_UPLOAD_DOWNLOAD_CLIENT.uploadSegmentMetadata(FileUploadDownloadClient.getUploadSegmentMetadataURI(controllerURI),\n+                  segmentName, segmentMetadataFile, headers, parameters, FILE_UPLOAD_DOWNLOAD_CLIENT.DEFAULT_SOCKET_TIMEOUT_MS);\n+              LOGGER.info(\"Response for pushing table {} segment {} to location {} - {}: {}\", tableName, segmentName,\n+                  controllerURI, response.getStatusCode(), response.getResponse());\n+              return true;\n+            } catch (HttpErrorStatusException e) {\n+              int statusCode = e.getStatusCode();\n+              if (statusCode >= 500) {\n+                // Temporary exception\n+                LOGGER\n+                    .warn(\"Caught temporary exception while pushing table: {} segment: {} to {}, will retry\", tableName,\n+                        segmentName, controllerURI, e);\n+                return false;\n+              } else {\n+                // Permanent exception\n+                LOGGER.error(\"Caught permanent exception while pushing table: {} segment: {} to {}, won't retry\",\n+                    tableName, segmentName, controllerURI, e);\n+                throw e;\n+              }\n+            }\n+          });\n+        }\n+      } finally {\n+        FileUtils.deleteQuietly(segmentMetadataFile);\n+      }\n+    }\n+  }\n+\n+  public static Map<String, String> getSegmentUriToTarPathMap(URI outputDirURI, String uriPrefix, String uriSuffix, String[] files) {\n+    Map<String, String> segmentUriToTarPathMap = new HashMap<>();\n+    for (String file : files) {\n+      URI uri = URI.create(file);\n+      if (uri.getPath().endsWith(Constants.TAR_GZ_FILE_EXT)) {\n+        URI updatedURI = SegmentPushUtils.generateSegmentTarURI(outputDirURI, uri, uriPrefix,uriSuffix);\n+        segmentUriToTarPathMap.put(updatedURI.toString(), file);\n+      }\n+    }\n+    return segmentUriToTarPathMap;\n+  }\n+\n+  /**\n+   * Generate a segment metadata only tar file, which contains only metadata.properties and creation.meta file.\n+   * The purpose of this is to create a lean tar to push to Pinot controller for adding segments without downloading\n+   * the complete segment and untar the segment tarball.\n+   *\n+   * 1. Download segment tar file to temp dir;\n+   * 2. Extract only metadata.properties and creation.meta files from the segment tar file;\n+   * 3. Tar both files into a segment metadata file.\n+   *\n+   */\n+  private static boolean generateSegmentMetadataFile(PinotFS fileSystem, URI tarFileURI, File segmentMetadataTarFile)\n+      throws Exception {\n+    long currentTime = System.nanoTime();\n+    File tarFile = new File(FileUtils.getTempDirectory(), \"segmentTar-\" + currentTime + TarGzCompressionUtils.TAR_GZ_FILE_EXTENSION).getAbsoluteFile();\n+    File segmentMetadataDir = new File(FileUtils.getTempDirectory(), \"segmentMetadataDir-\" + currentTime).getAbsoluteFile();", "originalCommit": "662b7b581942379896e01cbcd972bc815710d64b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM4NTEyMA==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496385120", "bodyText": "Returns the generated file path instead of passing in the file path?", "author": "Jackie-Jiang", "createdAt": "2020-09-29T04:35:58Z", "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +187,125 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriToTarPathMap(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)\n+      throws Exception {\n+    String tableName = spec.getTableSpec().getTableName();\n+    LOGGER.info(\"Start pushing segments: {}... to locations: {} for table {}\",\n+        Arrays.toString(segmentUriToTarPathMap.entrySet().toArray()),\n+        Arrays.toString(spec.getPinotClusterSpecs()), tableName);\n+    for (String segmentUriPath : segmentUriToTarPathMap.keySet()) {\n+      String tarFilePath = segmentUriToTarPathMap.get(segmentUriPath);\n+      String fileName = new File(tarFilePath).getName();\n+      Preconditions.checkArgument(fileName.endsWith(Constants.TAR_GZ_FILE_EXT));\n+      String segmentName = fileName.substring(0, fileName.length() - Constants.TAR_GZ_FILE_EXT.length());\n+      File segmentMetadataFile = new File(FileUtils.getTempDirectory(), \"segmentMetadataFile-\" + System.nanoTime() + TarGzCompressionUtils.TAR_GZ_FILE_EXTENSION);\n+      generateSegmentMetadataFile(fileSystem, URI.create(tarFilePath), segmentMetadataFile);\n+      try {\n+        for (PinotClusterSpec pinotClusterSpec : spec.getPinotClusterSpecs()) {\n+          URI controllerURI;\n+          try {\n+            controllerURI = new URI(pinotClusterSpec.getControllerURI());\n+          } catch (URISyntaxException e) {\n+            throw new RuntimeException(\"Got invalid controller uri - '\" + pinotClusterSpec.getControllerURI() + \"'\");\n+          }\n+          LOGGER.info(\"Pushing segment: {} to location: {} for table {}\", segmentName, controllerURI, tableName);\n+          int attempts = 1;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushAttempts() > 0) {\n+            attempts = spec.getPushJobSpec().getPushAttempts();\n+          }\n+          long retryWaitMs = 1000L;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushRetryIntervalMillis() > 0) {\n+            retryWaitMs = spec.getPushJobSpec().getPushRetryIntervalMillis();\n+          }\n+          RetryPolicies.exponentialBackoffRetryPolicy(attempts, retryWaitMs, 5).attempt(() -> {\n+            try {\n+              List<Header> headers = ImmutableList.of(new BasicHeader(FileUploadDownloadClient.CustomHeaders.DOWNLOAD_URI, segmentUriPath));\n+              // Add table name as a request parameter\n+              NameValuePair tableNameValuePair =\n+                  new BasicNameValuePair(FileUploadDownloadClient.QueryParameters.TABLE_NAME, tableName);\n+              List<NameValuePair> parameters = Arrays.asList(tableNameValuePair);\n+              SimpleHttpResponse response = FILE_UPLOAD_DOWNLOAD_CLIENT.uploadSegmentMetadata(FileUploadDownloadClient.getUploadSegmentMetadataURI(controllerURI),\n+                  segmentName, segmentMetadataFile, headers, parameters, FILE_UPLOAD_DOWNLOAD_CLIENT.DEFAULT_SOCKET_TIMEOUT_MS);\n+              LOGGER.info(\"Response for pushing table {} segment {} to location {} - {}: {}\", tableName, segmentName,\n+                  controllerURI, response.getStatusCode(), response.getResponse());\n+              return true;\n+            } catch (HttpErrorStatusException e) {\n+              int statusCode = e.getStatusCode();\n+              if (statusCode >= 500) {\n+                // Temporary exception\n+                LOGGER\n+                    .warn(\"Caught temporary exception while pushing table: {} segment: {} to {}, will retry\", tableName,\n+                        segmentName, controllerURI, e);\n+                return false;\n+              } else {\n+                // Permanent exception\n+                LOGGER.error(\"Caught permanent exception while pushing table: {} segment: {} to {}, won't retry\",\n+                    tableName, segmentName, controllerURI, e);\n+                throw e;\n+              }\n+            }\n+          });\n+        }\n+      } finally {\n+        FileUtils.deleteQuietly(segmentMetadataFile);\n+      }\n+    }\n+  }\n+\n+  public static Map<String, String> getSegmentUriToTarPathMap(URI outputDirURI, String uriPrefix, String uriSuffix, String[] files) {\n+    Map<String, String> segmentUriToTarPathMap = new HashMap<>();\n+    for (String file : files) {\n+      URI uri = URI.create(file);\n+      if (uri.getPath().endsWith(Constants.TAR_GZ_FILE_EXT)) {\n+        URI updatedURI = SegmentPushUtils.generateSegmentTarURI(outputDirURI, uri, uriPrefix,uriSuffix);\n+        segmentUriToTarPathMap.put(updatedURI.toString(), file);\n+      }\n+    }\n+    return segmentUriToTarPathMap;\n+  }\n+\n+  /**\n+   * Generate a segment metadata only tar file, which contains only metadata.properties and creation.meta file.\n+   * The purpose of this is to create a lean tar to push to Pinot controller for adding segments without downloading\n+   * the complete segment and untar the segment tarball.\n+   *\n+   * 1. Download segment tar file to temp dir;\n+   * 2. Extract only metadata.properties and creation.meta files from the segment tar file;\n+   * 3. Tar both files into a segment metadata file.\n+   *\n+   */\n+  private static boolean generateSegmentMetadataFile(PinotFS fileSystem, URI tarFileURI, File segmentMetadataTarFile)", "originalCommit": "662b7b581942379896e01cbcd972bc815710d64b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM4NjUwMw==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496386503", "bodyText": "Rename this to reflect it is sending the segment metadata instead of the segments?", "author": "Jackie-Jiang", "createdAt": "2020-09-29T04:37:52Z", "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +187,125 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriToTarPathMap(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)", "originalCommit": "662b7b581942379896e01cbcd972bc815710d64b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk2NjE0OQ==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496966149", "bodyText": "I don't think we need to add these 2 new APIs, we can still use the existing segment upload API but with metadata upload in the header. I feel it is better to use the same path for segment upload.", "author": "Jackie-Jiang", "createdAt": "2020-09-29T18:55:32Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotSegmentUploadDownloadRestletResource.java", "diffHunk": "@@ -460,6 +465,40 @@ public void uploadSegmentAsMultiPartV2(FormDataMultiPart multiPart,\n     }\n   }\n \n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @Path(\"/segments/metadata\")\n+  @ApiOperation(value = \"Upload a segment with metadata\", notes = \"Upload a segment using segment metadata\")\n+  public void uploadSegmentMetadataAsJson(String segmentJsonStr,\n+      @ApiParam(value = \"Name of the table\") @QueryParam(FileUploadDownloadClient.QueryParameters.TABLE_NAME) String tableName,\n+      @ApiParam(value = \"Whether to enable parallel push protection\") @DefaultValue(\"false\") @QueryParam(FileUploadDownloadClient.QueryParameters.ENABLE_PARALLEL_PUSH_PROTECTION) boolean enableParallelPushProtection,\n+      @Context HttpHeaders headers, @Context Request request, @Suspended final AsyncResponse asyncResponse) {\n+    try {\n+      asyncResponse.resume(uploadSegment(tableName, null, enableParallelPushProtection, headers, request, false));\n+    } catch (Throwable t) {\n+      asyncResponse.resume(t);\n+    }\n+  }\n+\n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.MULTIPART_FORM_DATA)\n+  @Path(\"/segments/metadata\")\n+  @ApiOperation(value = \"Upload a segment with metadata\", notes = \"Upload a segment using segment metadata\")\n+  public void uploadSegmentMetadataAsMultiPart(FormDataMultiPart multiPart,\n+      @ApiParam(value = \"Name of the table\") @QueryParam(FileUploadDownloadClient.QueryParameters.TABLE_NAME) String tableName,\n+      @ApiParam(value = \"Whether to enable parallel push protection\") @DefaultValue(\"false\") @QueryParam(FileUploadDownloadClient.QueryParameters.ENABLE_PARALLEL_PUSH_PROTECTION) boolean enableParallelPushProtection,\n+      @Context HttpHeaders headers, @Context Request request, @Suspended final AsyncResponse asyncResponse) {\n+    try {\n+      asyncResponse.resume(uploadSegment(tableName, multiPart, enableParallelPushProtection, headers, request, false));\n+    } catch (Throwable t) {\n+      asyncResponse.resume(t);\n+    }\n+  }\n+", "originalCommit": "02ad0df5401cb8ab24570d907a7a0acd8dce73db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk3NDczNQ==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496974735", "bodyText": "make sense.", "author": "xiangfu0", "createdAt": "2020-09-29T19:11:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk2NjE0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk2NjQ0Nw==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496966447", "bodyText": "Add some javadoc?", "author": "Jackie-Jiang", "createdAt": "2020-09-29T18:56:05Z", "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +188,127 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriAndMetadata(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)", "originalCommit": "02ad0df5401cb8ab24570d907a7a0acd8dce73db", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk2NzIyMg==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496967222", "bodyText": "(nit) Why having the ... here? We are not omitting any segment here", "author": "Jackie-Jiang", "createdAt": "2020-09-29T18:57:28Z", "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +188,127 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriAndMetadata(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)\n+      throws Exception {\n+    String tableName = spec.getTableSpec().getTableName();\n+    LOGGER.info(\"Start pushing segment metadata: {}... to locations: {} for table {}\",", "originalCommit": "02ad0df5401cb8ab24570d907a7a0acd8dce73db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk3MzA4OQ==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496973089", "bodyText": "Ah, I think the purpose of this log is to only put at most say 5 segments to avoid flushing the log.\nBut I feel it should be ok to list all the segments.", "author": "xiangfu0", "createdAt": "2020-09-29T19:07:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk2NzIyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk2ODg5NA==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496968894", "bodyText": "(Critical) Shouldn't this be METADATA?", "author": "Jackie-Jiang", "createdAt": "2020-09-29T19:00:21Z", "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +188,127 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriAndMetadata(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)\n+      throws Exception {\n+    String tableName = spec.getTableSpec().getTableName();\n+    LOGGER.info(\"Start pushing segment metadata: {}... to locations: {} for table {}\",\n+        segmentUriToTarPathMap,\n+        Arrays.toString(spec.getPinotClusterSpecs()), tableName);\n+    for (String segmentUriPath : segmentUriToTarPathMap.keySet()) {\n+      String tarFilePath = segmentUriToTarPathMap.get(segmentUriPath);\n+      String fileName = new File(tarFilePath).getName();\n+      Preconditions.checkArgument(fileName.endsWith(Constants.TAR_GZ_FILE_EXT));\n+      String segmentName = fileName.substring(0, fileName.length() - Constants.TAR_GZ_FILE_EXT.length());\n+      File segmentMetadataFile = generateSegmentMetadataFile(fileSystem, URI.create(tarFilePath));\n+      try {\n+        for (PinotClusterSpec pinotClusterSpec : spec.getPinotClusterSpecs()) {\n+          URI controllerURI;\n+          try {\n+            controllerURI = new URI(pinotClusterSpec.getControllerURI());\n+          } catch (URISyntaxException e) {\n+            throw new RuntimeException(\"Got invalid controller uri - '\" + pinotClusterSpec.getControllerURI() + \"'\");\n+          }\n+          LOGGER.info(\"Pushing segment: {} to location: {} for table {}\", segmentName, controllerURI, tableName);\n+          int attempts = 1;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushAttempts() > 0) {\n+            attempts = spec.getPushJobSpec().getPushAttempts();\n+          }\n+          long retryWaitMs = 1000L;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushRetryIntervalMillis() > 0) {\n+            retryWaitMs = spec.getPushJobSpec().getPushRetryIntervalMillis();\n+          }\n+          RetryPolicies.exponentialBackoffRetryPolicy(attempts, retryWaitMs, 5).attempt(() -> {\n+            try {\n+              List<Header> headers = ImmutableList.of(\n+                  new BasicHeader(FileUploadDownloadClient.CustomHeaders.DOWNLOAD_URI, segmentUriPath),\n+                  new BasicHeader(FileUploadDownloadClient.CustomHeaders.UPLOAD_TYPE, FileUploadDownloadClient.FileUploadType.URI.toString()));", "originalCommit": "02ad0df5401cb8ab24570d907a7a0acd8dce73db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk3NDk3NA==", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496974974", "bodyText": "good catch", "author": "xiangfu0", "createdAt": "2020-09-29T19:11:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk2ODg5NA=="}], "type": "inlineReview"}, {"oid": "4d315f48cfec3910e080a67d2c4f90e593ac7cf1", "url": "https://github.com/apache/pinot/commit/4d315f48cfec3910e080a67d2c4f90e593ac7cf1", "message": "Address comments", "committedDate": "2020-09-29T19:10:50Z", "type": "forcePushed"}, {"oid": "2d32aafe5dc23b9f5a0b03045ab6a69448c87558", "url": "https://github.com/apache/pinot/commit/2d32aafe5dc23b9f5a0b03045ab6a69448c87558", "message": "Address comments", "committedDate": "2020-09-29T19:19:25Z", "type": "forcePushed"}, {"oid": "dc894949951c273566b92e90f134035d0eacabf2", "url": "https://github.com/apache/pinot/commit/dc894949951c273566b92e90f134035d0eacabf2", "message": "Adding integration tests", "committedDate": "2020-09-29T21:32:36Z", "type": "forcePushed"}, {"oid": "2dc06c7d54d03c7581cf2f61f9b0e5857bbde0d7", "url": "https://github.com/apache/pinot/commit/2dc06c7d54d03c7581cf2f61f9b0e5857bbde0d7", "message": "Adding push job type of segment metadata only mode", "committedDate": "2020-09-29T21:33:09Z", "type": "commit"}, {"oid": "85f6b43e65ba9d0e40b12c73cede7bedeae4e2b7", "url": "https://github.com/apache/pinot/commit/85f6b43e65ba9d0e40b12c73cede7bedeae4e2b7", "message": "Adding clean up for temp files", "committedDate": "2020-09-29T21:33:09Z", "type": "commit"}, {"oid": "2635036ddec271d4881c08e46db77a615c6e8879", "url": "https://github.com/apache/pinot/commit/2635036ddec271d4881c08e46db77a615c6e8879", "message": "Address comments", "committedDate": "2020-09-29T21:33:09Z", "type": "commit"}, {"oid": "41ce8628eae2ebf57029c02b57897faddc2ea898", "url": "https://github.com/apache/pinot/commit/41ce8628eae2ebf57029c02b57897faddc2ea898", "message": "Adding integration tests", "committedDate": "2020-09-29T21:33:09Z", "type": "forcePushed"}, {"oid": "d7ca99f5860dd6062d05a4119cf6b39ffd858752", "url": "https://github.com/apache/pinot/commit/d7ca99f5860dd6062d05a4119cf6b39ffd858752", "message": "Adding integration tests", "committedDate": "2020-09-29T21:53:04Z", "type": "commit"}, {"oid": "d7ca99f5860dd6062d05a4119cf6b39ffd858752", "url": "https://github.com/apache/pinot/commit/d7ca99f5860dd6062d05a4119cf6b39ffd858752", "message": "Adding integration tests", "committedDate": "2020-09-29T21:53:04Z", "type": "forcePushed"}]}