{"pr_number": 4983, "pr_title": "Make PQL case insensitive", "pr_createdAt": "2020-01-14T21:32:50Z", "pr_url": "https://github.com/apache/pinot/pull/4983", "timeline": [{"oid": "52b14bffdc86361d203b9bdb3c2e7564750cd185", "url": "https://github.com/apache/pinot/commit/52b14bffdc86361d203b9bdb3c2e7564750cd185", "message": "Make PQL case insensitive", "committedDate": "2020-01-14T21:28:42Z", "type": "commit"}, {"oid": "99992a2b52f1cfd01b74ddc7f4dfde623def62d0", "url": "https://github.com/apache/pinot/commit/99992a2b52f1cfd01b74ddc7f4dfde623def62d0", "message": "Handling expression in filter clause", "committedDate": "2020-01-14T23:28:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDg1MQ==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366670851", "bodyText": "I don't understand this if check. FilterQueryMap is flattened and contained all the FilterQuery. We just need to iterate on all these FilterQuery which are stored in \"values\" and that will take care of fixing the column name for the entire tree", "author": "siddharthteotia", "createdAt": "2020-01-15T02:32:49Z", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/requesthandler/BaseBrokerRequestHandler.java", "diffHunk": "@@ -335,6 +349,74 @@ public BrokerResponse handleRequest(JsonNode request, @Nullable RequesterIdentit\n     return brokerResponse;\n   }\n \n+  private void handleCaseSensitivity(BrokerRequest brokerRequest) {\n+    String inputTableName = brokerRequest.getQuerySource().getTableName();\n+    String actualTableName = _tableCache.getActualTableName(inputTableName);\n+    brokerRequest.getQuerySource().setTableName(actualTableName);\n+    //fix columns\n+    if (brokerRequest.getFilterSubQueryMap() != null) {\n+      Collection<FilterQuery> values = brokerRequest.getFilterSubQueryMap().getFilterQueryMap().values();\n+      for (FilterQuery filterQuery : values) {\n+        if (filterQuery.getNestedFilterQueryIdsSize() == 0) {", "originalCommit": "99992a2b52f1cfd01b74ddc7f4dfde623def62d0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzEzNDgzMA==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r367134830", "bodyText": "we just need to check the leaf nodes in the filtertree. this check ensures that we dont process intermediate nodes like (AND/OR)", "author": "kishoreg", "createdAt": "2020-01-15T22:12:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDg1MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzEzNTM3OQ==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r367135379", "bodyText": "Got it.", "author": "siddharthteotia", "createdAt": "2020-01-15T22:14:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDg1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDg4Mg==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366670882", "bodyText": "We should recurse for FUNCTION expression to identify the inner column names (IDENTIFIERS) at the leaf level and fix case for them", "author": "siddharthteotia", "createdAt": "2020-01-15T02:33:00Z", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/requesthandler/BaseBrokerRequestHandler.java", "diffHunk": "@@ -335,6 +349,74 @@ public BrokerResponse handleRequest(JsonNode request, @Nullable RequesterIdentit\n     return brokerResponse;\n   }\n \n+  private void handleCaseSensitivity(BrokerRequest brokerRequest) {\n+    String inputTableName = brokerRequest.getQuerySource().getTableName();\n+    String actualTableName = _tableCache.getActualTableName(inputTableName);\n+    brokerRequest.getQuerySource().setTableName(actualTableName);\n+    //fix columns\n+    if (brokerRequest.getFilterSubQueryMap() != null) {\n+      Collection<FilterQuery> values = brokerRequest.getFilterSubQueryMap().getFilterQueryMap().values();\n+      for (FilterQuery filterQuery : values) {\n+        if (filterQuery.getNestedFilterQueryIdsSize() == 0) {\n+          String expression = filterQuery.getColumn();\n+          filterQuery.setColumn(fixColumnNameCase(actualTableName, expression));\n+        }\n+      }\n+    }\n+    if (brokerRequest.isSetAggregationsInfo()) {\n+      for (AggregationInfo info : brokerRequest.getAggregationsInfo()) {\n+        if (info.getAggregationParams() != null && !info.getAggregationType()\n+            .equalsIgnoreCase(AggregationFunctionType.COUNT.getName())) {\n+          String column = info.getAggregationParams().get(FunctionCallAstNode.COLUMN_KEY_IN_AGGREGATION_INFO);\n+          String[] expressions = column.split(FunctionCallAstNode.DISTINCT_MULTI_COLUMN_SEPARATOR);\n+          String[] newExpressions = new String[expressions.length];\n+          for (int i = 0; i < expressions.length; i++) {\n+            String expression = expressions[i];\n+            newExpressions[i] = fixColumnNameCase(actualTableName, expression);\n+          }\n+          String newColumns = StringUtil.join(FunctionCallAstNode.DISTINCT_MULTI_COLUMN_SEPARATOR, newExpressions);\n+          info.getAggregationParams().put(FunctionCallAstNode.COLUMN_KEY_IN_AGGREGATION_INFO, newColumns);\n+        }\n+      }\n+      if (brokerRequest.isSetGroupBy()) {\n+        List<String> expressions = brokerRequest.getGroupBy().getExpressions();\n+        for (int i = 0; i < expressions.size(); i++) {\n+          expressions.set(i, fixColumnNameCase(actualTableName, expressions.get(i)));\n+        }\n+      }\n+    } else {\n+      Selection selection = brokerRequest.getSelections();\n+      List<String> selectionColumns = selection.getSelectionColumns();\n+      for (int i = 0; i < selectionColumns.size(); i++) {\n+        String expression = selectionColumns.get(i);\n+        if (!expression.trim().equalsIgnoreCase(\"*\")) {\n+          selectionColumns.set(i, fixColumnNameCase(actualTableName, expression));\n+        }\n+      }\n+    }\n+  }\n+\n+  private String fixColumnNameCase(String actualTableName, String expression) {\n+    TransformExpressionTree rootExpression = TransformExpressionTree.compileToExpressionTree(expression);\n+    LinkedList<TransformExpressionTree> q = new LinkedList<>();\n+    q.add(rootExpression);\n+    while (!q.isEmpty()) {\n+      TransformExpressionTree expressionTree = q.pop();\n+      switch (expressionTree.getExpressionType()) {\n+        case FUNCTION:", "originalCommit": "99992a2b52f1cfd01b74ddc7f4dfde623def62d0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcyNDI5MQ==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r367724291", "bodyText": "If we are not planning to handle column names for cases like SUM(ADD(col_a, col_b)) in this PR, we should note in the PR and add a TODO.", "author": "siddharthteotia", "createdAt": "2020-01-17T00:57:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDg4Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcyNTM0MQ==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r367725341", "bodyText": "I do handle that. am I missing something?", "author": "kishoreg", "createdAt": "2020-01-17T01:01:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDg4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDkwMw==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366670903", "bodyText": "Good javadoc describing purpose and usage would be helpful for future readers\nJust to confirm --  There is one instance of TableCache per broker (via BaseBrokerRequestHandler created during broker start) and one instance per controller (created during controller start). Right?", "author": "siddharthteotia", "createdAt": "2020-01-15T02:33:06Z", "path": "pinot-common/src/main/java/org/apache/pinot/common/utils/helix/TableCache.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.common.utils.helix;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.I0Itec.zkclient.IZkChildListener;\n+import org.I0Itec.zkclient.IZkDataListener;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.store.HelixPropertyListener;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.common.config.TableConfig;\n+import org.apache.pinot.common.config.TableNameBuilder;\n+import org.apache.pinot.common.utils.SchemaUtils;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+\n+", "originalCommit": "99992a2b52f1cfd01b74ddc7f4dfde623def62d0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzEzMzg2Mg==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r367133862", "bodyText": "yes. will add javadocs", "author": "kishoreg", "createdAt": "2020-01-15T22:10:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDkwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDk2OQ==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366670969", "bodyText": "Since we can get the schema name here itself, looks like we don't need the other map in SchemaChangeListener as noted further below in the comment", "author": "siddharthteotia", "createdAt": "2020-01-15T02:33:22Z", "path": "pinot-common/src/main/java/org/apache/pinot/common/utils/helix/TableCache.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.common.utils.helix;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.I0Itec.zkclient.IZkChildListener;\n+import org.I0Itec.zkclient.IZkDataListener;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.store.HelixPropertyListener;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.common.config.TableConfig;\n+import org.apache.pinot.common.config.TableNameBuilder;\n+import org.apache.pinot.common.utils.SchemaUtils;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+\n+\n+public class TableCache {\n+  private static final String PROPERTYSTORE_SCHEMAS_PREFIX = \"/SCHEMAS\";\n+  private static final String PROPERTYSTORE_TABLE_CONFIGS_PREFIX = \"/CONFIGS/TABLE\";\n+\n+  private ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  TableConfigChangeListener _tableConfigChangeListener;\n+  SchemaChangeListener _schemaChangeListener;\n+\n+  public TableCache(ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _propertyStore = propertyStore;\n+    _schemaChangeListener = new SchemaChangeListener();\n+    _schemaChangeListener.refresh();\n+    _tableConfigChangeListener = new TableConfigChangeListener();\n+    _tableConfigChangeListener.refresh();\n+  }\n+\n+  public String getActualTableName(String tableName) {\n+    return _tableConfigChangeListener._tableNameMap.getOrDefault(tableName.toLowerCase(), tableName);\n+  }\n+\n+  public String getActualColumnName(String tableName, String columnName) {\n+    String schemaName = _tableConfigChangeListener._table2SchemaConfigMap.get(tableName.toLowerCase());", "originalCommit": "99992a2b52f1cfd01b74ddc7f4dfde623def62d0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4ODg4Mw==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366688883", "bodyText": "let me check, which map are you referring to", "author": "kishoreg", "createdAt": "2020-01-15T04:11:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDk2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzEzNjAyOQ==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r367136029", "bodyText": "To _schemaMap as mentioned in this comment #4983 (comment)", "author": "siddharthteotia", "createdAt": "2020-01-15T22:15:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDk2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDk4MA==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366670980", "bodyText": "Why do we need tableConfigMap? I don't see it being used", "author": "siddharthteotia", "createdAt": "2020-01-15T02:33:25Z", "path": "pinot-common/src/main/java/org/apache/pinot/common/utils/helix/TableCache.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.common.utils.helix;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.I0Itec.zkclient.IZkChildListener;\n+import org.I0Itec.zkclient.IZkDataListener;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.store.HelixPropertyListener;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.common.config.TableConfig;\n+import org.apache.pinot.common.config.TableNameBuilder;\n+import org.apache.pinot.common.utils.SchemaUtils;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+\n+\n+public class TableCache {\n+  private static final String PROPERTYSTORE_SCHEMAS_PREFIX = \"/SCHEMAS\";\n+  private static final String PROPERTYSTORE_TABLE_CONFIGS_PREFIX = \"/CONFIGS/TABLE\";\n+\n+  private ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  TableConfigChangeListener _tableConfigChangeListener;\n+  SchemaChangeListener _schemaChangeListener;\n+\n+  public TableCache(ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _propertyStore = propertyStore;\n+    _schemaChangeListener = new SchemaChangeListener();\n+    _schemaChangeListener.refresh();\n+    _tableConfigChangeListener = new TableConfigChangeListener();\n+    _tableConfigChangeListener.refresh();\n+  }\n+\n+  public String getActualTableName(String tableName) {\n+    return _tableConfigChangeListener._tableNameMap.getOrDefault(tableName.toLowerCase(), tableName);\n+  }\n+\n+  public String getActualColumnName(String tableName, String columnName) {\n+    String schemaName = _tableConfigChangeListener._table2SchemaConfigMap.get(tableName.toLowerCase());\n+    if (schemaName != null) {\n+      return _schemaChangeListener.getColumnName(schemaName, columnName);\n+    }\n+    return columnName;\n+  }\n+\n+  class TableConfigChangeListener implements IZkChildListener, IZkDataListener {\n+\n+    Map<String, TableConfig> _tableConfigMap = new ConcurrentHashMap<>();", "originalCommit": "99992a2b52f1cfd01b74ddc7f4dfde623def62d0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4ODYxMQ==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366688611", "bodyText": "I was hoping this can replace the TableConfigCache we have in Realtime code.", "author": "kishoreg", "createdAt": "2020-01-15T04:09:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDk4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDk5Nw==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366670997", "bodyText": "I don't think this is needed. _schemaColumnMap should be enough.", "author": "siddharthteotia", "createdAt": "2020-01-15T02:33:29Z", "path": "pinot-common/src/main/java/org/apache/pinot/common/utils/helix/TableCache.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.common.utils.helix;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.I0Itec.zkclient.IZkChildListener;\n+import org.I0Itec.zkclient.IZkDataListener;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.store.HelixPropertyListener;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.common.config.TableConfig;\n+import org.apache.pinot.common.config.TableNameBuilder;\n+import org.apache.pinot.common.utils.SchemaUtils;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+\n+\n+public class TableCache {\n+  private static final String PROPERTYSTORE_SCHEMAS_PREFIX = \"/SCHEMAS\";\n+  private static final String PROPERTYSTORE_TABLE_CONFIGS_PREFIX = \"/CONFIGS/TABLE\";\n+\n+  private ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  TableConfigChangeListener _tableConfigChangeListener;\n+  SchemaChangeListener _schemaChangeListener;\n+\n+  public TableCache(ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _propertyStore = propertyStore;\n+    _schemaChangeListener = new SchemaChangeListener();\n+    _schemaChangeListener.refresh();\n+    _tableConfigChangeListener = new TableConfigChangeListener();\n+    _tableConfigChangeListener.refresh();\n+  }\n+\n+  public String getActualTableName(String tableName) {\n+    return _tableConfigChangeListener._tableNameMap.getOrDefault(tableName.toLowerCase(), tableName);\n+  }\n+\n+  public String getActualColumnName(String tableName, String columnName) {\n+    String schemaName = _tableConfigChangeListener._table2SchemaConfigMap.get(tableName.toLowerCase());\n+    if (schemaName != null) {\n+      return _schemaChangeListener.getColumnName(schemaName, columnName);\n+    }\n+    return columnName;\n+  }\n+\n+  class TableConfigChangeListener implements IZkChildListener, IZkDataListener {\n+\n+    Map<String, TableConfig> _tableConfigMap = new ConcurrentHashMap<>();\n+    Map<String, String> _tableNameMap = new ConcurrentHashMap<>();\n+    Map<String, String> _table2SchemaConfigMap = new ConcurrentHashMap<>();\n+\n+    public synchronized void refresh() {\n+      try {\n+        //always subscribe first before reading, so that we dont miss any changes\n+        _propertyStore.subscribeChildChanges(PROPERTYSTORE_TABLE_CONFIGS_PREFIX, _tableConfigChangeListener);\n+        _propertyStore.subscribeDataChanges(PROPERTYSTORE_TABLE_CONFIGS_PREFIX, _tableConfigChangeListener);\n+        List<ZNRecord> children =\n+            _propertyStore.getChildren(PROPERTYSTORE_TABLE_CONFIGS_PREFIX, null, AccessOption.PERSISTENT);\n+        if (children != null) {\n+          for (ZNRecord znRecord : children) {\n+            try {\n+              TableConfig tableConfig = TableConfig.fromZnRecord(znRecord);\n+              String tableNameWithType = tableConfig.getTableName();\n+              _tableConfigMap.put(tableNameWithType, tableConfig);\n+              String rawTableName = TableNameBuilder.extractRawTableName(tableNameWithType);\n+              //create case insensitive mapping\n+              _tableNameMap.put(tableNameWithType.toLowerCase(), tableNameWithType);\n+              _tableNameMap.put(rawTableName.toLowerCase(), rawTableName);\n+              //create case insensitive mapping between table name and schemaName\n+              _table2SchemaConfigMap.put(tableNameWithType.toLowerCase(), rawTableName);\n+              _table2SchemaConfigMap.put(rawTableName.toLowerCase(), rawTableName);\n+            } catch (IOException e) {\n+              e.printStackTrace();\n+              //ignore\n+            }\n+          }\n+        }\n+      } catch (Exception e) {\n+        e.printStackTrace();\n+        //ignore\n+      }\n+    }\n+\n+    @Override\n+    public void handleChildChange(String s, List<String> list)\n+        throws Exception {\n+      refresh();\n+    }\n+\n+    @Override\n+    public void handleDataChange(String s, Object o)\n+        throws Exception {\n+      refresh();\n+    }\n+\n+    @Override\n+    public void handleDataDeleted(String s)\n+        throws Exception {\n+      refresh();\n+    }\n+  }\n+\n+  class SchemaChangeListener implements IZkChildListener, IZkDataListener {\n+    Map<String, Schema> _schemaMap = new ConcurrentHashMap<>();", "originalCommit": "99992a2b52f1cfd01b74ddc7f4dfde623def62d0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4ODQzNQ==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366688435", "bodyText": "I did not follow", "author": "kishoreg", "createdAt": "2020-01-15T04:08:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDk5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4ODQ4NA==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366688484", "bodyText": "ah got it. will remove it", "author": "kishoreg", "createdAt": "2020-01-15T04:08:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDk5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcyMzUzNQ==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r367723535", "bodyText": "Do you want to remove this map? getColumnName() function of TableCache will first use the TableConfigChangeListener._table2SchemaConfigMap to get the schema name for a table name. It will then use the SchemaChangeListener.getColumnName(schema name, column name) to get the internal column name.\nSo _schemaMap remains unused.", "author": "siddharthteotia", "createdAt": "2020-01-17T00:54:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDk5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcyODU3OQ==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r367728579", "bodyText": "done", "author": "kishoreg", "createdAt": "2020-01-17T01:15:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MDk5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MTAxMg==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366671012", "bodyText": "So if the listener is invoked for a change to a particular table, we are going to go over schema of all the tables to update the map? If so, I think we should handle the callback at a table level.", "author": "siddharthteotia", "createdAt": "2020-01-15T02:33:33Z", "path": "pinot-common/src/main/java/org/apache/pinot/common/utils/helix/TableCache.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.common.utils.helix;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.I0Itec.zkclient.IZkChildListener;\n+import org.I0Itec.zkclient.IZkDataListener;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.store.HelixPropertyListener;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.common.config.TableConfig;\n+import org.apache.pinot.common.config.TableNameBuilder;\n+import org.apache.pinot.common.utils.SchemaUtils;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+\n+\n+public class TableCache {\n+  private static final String PROPERTYSTORE_SCHEMAS_PREFIX = \"/SCHEMAS\";\n+  private static final String PROPERTYSTORE_TABLE_CONFIGS_PREFIX = \"/CONFIGS/TABLE\";\n+\n+  private ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  TableConfigChangeListener _tableConfigChangeListener;\n+  SchemaChangeListener _schemaChangeListener;\n+\n+  public TableCache(ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _propertyStore = propertyStore;\n+    _schemaChangeListener = new SchemaChangeListener();\n+    _schemaChangeListener.refresh();\n+    _tableConfigChangeListener = new TableConfigChangeListener();\n+    _tableConfigChangeListener.refresh();\n+  }\n+\n+  public String getActualTableName(String tableName) {\n+    return _tableConfigChangeListener._tableNameMap.getOrDefault(tableName.toLowerCase(), tableName);\n+  }\n+\n+  public String getActualColumnName(String tableName, String columnName) {\n+    String schemaName = _tableConfigChangeListener._table2SchemaConfigMap.get(tableName.toLowerCase());\n+    if (schemaName != null) {\n+      return _schemaChangeListener.getColumnName(schemaName, columnName);\n+    }\n+    return columnName;\n+  }\n+\n+  class TableConfigChangeListener implements IZkChildListener, IZkDataListener {\n+\n+    Map<String, TableConfig> _tableConfigMap = new ConcurrentHashMap<>();\n+    Map<String, String> _tableNameMap = new ConcurrentHashMap<>();\n+    Map<String, String> _table2SchemaConfigMap = new ConcurrentHashMap<>();\n+\n+    public synchronized void refresh() {\n+      try {\n+        //always subscribe first before reading, so that we dont miss any changes\n+        _propertyStore.subscribeChildChanges(PROPERTYSTORE_TABLE_CONFIGS_PREFIX, _tableConfigChangeListener);\n+        _propertyStore.subscribeDataChanges(PROPERTYSTORE_TABLE_CONFIGS_PREFIX, _tableConfigChangeListener);\n+        List<ZNRecord> children =\n+            _propertyStore.getChildren(PROPERTYSTORE_TABLE_CONFIGS_PREFIX, null, AccessOption.PERSISTENT);\n+        if (children != null) {\n+          for (ZNRecord znRecord : children) {\n+            try {\n+              TableConfig tableConfig = TableConfig.fromZnRecord(znRecord);\n+              String tableNameWithType = tableConfig.getTableName();\n+              _tableConfigMap.put(tableNameWithType, tableConfig);\n+              String rawTableName = TableNameBuilder.extractRawTableName(tableNameWithType);\n+              //create case insensitive mapping\n+              _tableNameMap.put(tableNameWithType.toLowerCase(), tableNameWithType);\n+              _tableNameMap.put(rawTableName.toLowerCase(), rawTableName);\n+              //create case insensitive mapping between table name and schemaName\n+              _table2SchemaConfigMap.put(tableNameWithType.toLowerCase(), rawTableName);\n+              _table2SchemaConfigMap.put(rawTableName.toLowerCase(), rawTableName);\n+            } catch (IOException e) {\n+              e.printStackTrace();\n+              //ignore\n+            }\n+          }\n+        }\n+      } catch (Exception e) {\n+        e.printStackTrace();\n+        //ignore\n+      }\n+    }\n+\n+    @Override\n+    public void handleChildChange(String s, List<String> list)\n+        throws Exception {\n+      refresh();\n+    }\n+\n+    @Override\n+    public void handleDataChange(String s, Object o)\n+        throws Exception {\n+      refresh();\n+    }\n+\n+    @Override\n+    public void handleDataDeleted(String s)\n+        throws Exception {\n+      refresh();\n+    }\n+  }\n+\n+  class SchemaChangeListener implements IZkChildListener, IZkDataListener {\n+    Map<String, Schema> _schemaMap = new ConcurrentHashMap<>();\n+    Map<String, Map<String, String>> _schemaColumnMap = new ConcurrentHashMap<>();\n+\n+    public synchronized void refresh() {\n+      try {", "originalCommit": "99992a2b52f1cfd01b74ddc7f4dfde623def62d0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4ODM2OA==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366688368", "bodyText": "It makes the logic more complicated and there is batching where we can get only one callback and multiple tables changed in the same callback. We can instead optimize reading the contents by reading the stats. But given that schema and table configs rarely change. I dint bother optimizing it.", "author": "kishoreg", "createdAt": "2020-01-15T04:08:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MTAxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MTAyNg==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366671026", "bodyText": "Since the other listener's map is sufficient to first get the schema name, this method and _schemaMap is probably not needed.", "author": "siddharthteotia", "createdAt": "2020-01-15T02:33:37Z", "path": "pinot-common/src/main/java/org/apache/pinot/common/utils/helix/TableCache.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.common.utils.helix;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.I0Itec.zkclient.IZkChildListener;\n+import org.I0Itec.zkclient.IZkDataListener;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.store.HelixPropertyListener;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.common.config.TableConfig;\n+import org.apache.pinot.common.config.TableNameBuilder;\n+import org.apache.pinot.common.utils.SchemaUtils;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+\n+\n+public class TableCache {\n+  private static final String PROPERTYSTORE_SCHEMAS_PREFIX = \"/SCHEMAS\";\n+  private static final String PROPERTYSTORE_TABLE_CONFIGS_PREFIX = \"/CONFIGS/TABLE\";\n+\n+  private ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  TableConfigChangeListener _tableConfigChangeListener;\n+  SchemaChangeListener _schemaChangeListener;\n+\n+  public TableCache(ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _propertyStore = propertyStore;\n+    _schemaChangeListener = new SchemaChangeListener();\n+    _schemaChangeListener.refresh();\n+    _tableConfigChangeListener = new TableConfigChangeListener();\n+    _tableConfigChangeListener.refresh();\n+  }\n+\n+  public String getActualTableName(String tableName) {\n+    return _tableConfigChangeListener._tableNameMap.getOrDefault(tableName.toLowerCase(), tableName);\n+  }\n+\n+  public String getActualColumnName(String tableName, String columnName) {\n+    String schemaName = _tableConfigChangeListener._table2SchemaConfigMap.get(tableName.toLowerCase());\n+    if (schemaName != null) {\n+      return _schemaChangeListener.getColumnName(schemaName, columnName);\n+    }\n+    return columnName;\n+  }\n+\n+  class TableConfigChangeListener implements IZkChildListener, IZkDataListener {\n+\n+    Map<String, TableConfig> _tableConfigMap = new ConcurrentHashMap<>();\n+    Map<String, String> _tableNameMap = new ConcurrentHashMap<>();\n+    Map<String, String> _table2SchemaConfigMap = new ConcurrentHashMap<>();\n+\n+    public synchronized void refresh() {\n+      try {\n+        //always subscribe first before reading, so that we dont miss any changes\n+        _propertyStore.subscribeChildChanges(PROPERTYSTORE_TABLE_CONFIGS_PREFIX, _tableConfigChangeListener);\n+        _propertyStore.subscribeDataChanges(PROPERTYSTORE_TABLE_CONFIGS_PREFIX, _tableConfigChangeListener);\n+        List<ZNRecord> children =\n+            _propertyStore.getChildren(PROPERTYSTORE_TABLE_CONFIGS_PREFIX, null, AccessOption.PERSISTENT);\n+        if (children != null) {\n+          for (ZNRecord znRecord : children) {\n+            try {\n+              TableConfig tableConfig = TableConfig.fromZnRecord(znRecord);\n+              String tableNameWithType = tableConfig.getTableName();\n+              _tableConfigMap.put(tableNameWithType, tableConfig);\n+              String rawTableName = TableNameBuilder.extractRawTableName(tableNameWithType);\n+              //create case insensitive mapping\n+              _tableNameMap.put(tableNameWithType.toLowerCase(), tableNameWithType);\n+              _tableNameMap.put(rawTableName.toLowerCase(), rawTableName);\n+              //create case insensitive mapping between table name and schemaName\n+              _table2SchemaConfigMap.put(tableNameWithType.toLowerCase(), rawTableName);\n+              _table2SchemaConfigMap.put(rawTableName.toLowerCase(), rawTableName);\n+            } catch (IOException e) {\n+              e.printStackTrace();\n+              //ignore\n+            }\n+          }\n+        }\n+      } catch (Exception e) {\n+        e.printStackTrace();\n+        //ignore\n+      }\n+    }\n+\n+    @Override\n+    public void handleChildChange(String s, List<String> list)\n+        throws Exception {\n+      refresh();\n+    }\n+\n+    @Override\n+    public void handleDataChange(String s, Object o)\n+        throws Exception {\n+      refresh();\n+    }\n+\n+    @Override\n+    public void handleDataDeleted(String s)\n+        throws Exception {\n+      refresh();\n+    }\n+  }\n+\n+  class SchemaChangeListener implements IZkChildListener, IZkDataListener {\n+    Map<String, Schema> _schemaMap = new ConcurrentHashMap<>();\n+    Map<String, Map<String, String>> _schemaColumnMap = new ConcurrentHashMap<>();\n+\n+    public synchronized void refresh() {\n+      try {\n+        //always subscribe first before reading, so that we dont miss any changes\n+        _propertyStore.subscribeChildChanges(PROPERTYSTORE_SCHEMAS_PREFIX, _schemaChangeListener);\n+        _propertyStore.subscribeDataChanges(PROPERTYSTORE_SCHEMAS_PREFIX, _schemaChangeListener);\n+        List<ZNRecord> children =\n+            _propertyStore.getChildren(PROPERTYSTORE_SCHEMAS_PREFIX, null, AccessOption.PERSISTENT);\n+        if (children != null) {\n+          for (ZNRecord znRecord : children) {\n+            try {\n+              Schema schema = SchemaUtils.fromZNRecord(znRecord);\n+              String schemaNameLowerCase = schema.getSchemaName().toLowerCase();\n+              _schemaMap.put(schemaNameLowerCase, schema);\n+              Collection<FieldSpec> allFieldSpecs = schema.getAllFieldSpecs();\n+              ConcurrentHashMap<String, String> columnNameMap = new ConcurrentHashMap<>();\n+              _schemaColumnMap.put(schemaNameLowerCase, columnNameMap);\n+              for (FieldSpec fieldSpec : allFieldSpecs) {\n+                columnNameMap.put(fieldSpec.getName().toLowerCase(), fieldSpec.getName());\n+              }\n+            } catch (IOException e) {\n+              //ignore\n+            }\n+          }\n+        }\n+      } catch (Exception e) {\n+        e.printStackTrace();\n+        //ignore\n+      }\n+    }\n+\n+    Schema getSchema(String schemaName) {\n+      return _schemaMap.get(schemaName.toLowerCase());", "originalCommit": "99992a2b52f1cfd01b74ddc7f4dfde623def62d0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4Nzk1Nw==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366687957", "bodyText": "yes, just had it in case we need to get schema in the future but can remove it and add it back when we need it.", "author": "kishoreg", "createdAt": "2020-01-15T04:05:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MTAyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MTA0Mw==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366671043", "bodyText": "Unrelated to this PR but may be at some point we need to fix this?\nJust to extract the table name, a query received on the controller via rest API will be compiled to BrokerRequest twice -- once at the controller and then at the broker.", "author": "siddharthteotia", "createdAt": "2020-01-15T02:33:43Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PqlQueryResource.java", "diffHunk": "@@ -108,6 +108,8 @@ public String getQueryResponse(String pqlQuery, String traceEnabled, String quer\n     BrokerRequest brokerRequest;\n     try {\n       brokerRequest = REQUEST_COMPILER.compileToBrokerRequest(pqlQuery);\n+      String inputTableName = brokerRequest.getQuerySource().getTableName();", "originalCommit": "99992a2b52f1cfd01b74ddc7f4dfde623def62d0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY4Nzc4OA==", "url": "https://github.com/apache/pinot/pull/4983#discussion_r366687788", "bodyText": "yes, I realized that as well. Query console is generally used for debugging and not worth optimizing it.", "author": "kishoreg", "createdAt": "2020-01-15T04:04:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NjY3MTA0Mw=="}], "type": "inlineReview"}, {"oid": "2e09e1f0db11fcdf1ec812b9b06e0b5c0043426f", "url": "https://github.com/apache/pinot/commit/2e09e1f0db11fcdf1ec812b9b06e0b5c0043426f", "message": "Adding test case and making it configurable", "committedDate": "2020-01-16T08:12:57Z", "type": "commit"}, {"oid": "c8ef989ae656dd095ed516457ee8f22b4d03fe9d", "url": "https://github.com/apache/pinot/commit/c8ef989ae656dd095ed516457ee8f22b4d03fe9d", "message": "Addressing review comments", "committedDate": "2020-01-17T01:17:28Z", "type": "commit"}, {"oid": "256efe6e014d322ab3795cd8d9aca65fe2435402", "url": "https://github.com/apache/pinot/commit/256efe6e014d322ab3795cd8d9aca65fe2435402", "message": "Fixing the bug of get actual column name", "committedDate": "2020-01-18T09:37:35Z", "type": "commit"}, {"oid": "256efe6e014d322ab3795cd8d9aca65fe2435402", "url": "https://github.com/apache/pinot/commit/256efe6e014d322ab3795cd8d9aca65fe2435402", "message": "Fixing the bug of get actual column name", "committedDate": "2020-01-18T09:37:35Z", "type": "forcePushed"}]}