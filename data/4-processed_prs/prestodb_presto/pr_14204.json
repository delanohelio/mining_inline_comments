{"pr_number": 14204, "pr_title": "Compare type by (name,type) pair rather than (index,type) pair during Parquet's schema mismatch checking", "pr_createdAt": "2020-03-04T02:45:58Z", "pr_url": "https://github.com/prestodb/presto/pull/14204", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ3NjEzNw==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r387476137", "bodyText": "use checkArgument", "author": "zhenxiao", "createdAt": "2020-03-04T06:49:14Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -322,8 +325,19 @@ private static boolean checkSchemaMatch(org.apache.parquet.schema.Type parquetTy\n             switch (prestoType) {\n                 case ROW:\n                     if (groupType.getFields().size() == type.getTypeParameters().size()) {\n+                        checkState(type instanceof RowType, \"It must be a RowType here.\");", "originalCommit": "2e2526cd3ed7fb860e8852c7f599df2b6dffc810", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODM0NzA0Nw==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r398347047", "bodyText": "done", "author": "beinan", "createdAt": "2020-03-26T06:44:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ3NjEzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ3NjE5OA==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r387476198", "bodyText": "s/f/field/g", "author": "zhenxiao", "createdAt": "2020-03-04T06:49:28Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -322,8 +325,19 @@ private static boolean checkSchemaMatch(org.apache.parquet.schema.Type parquetTy\n             switch (prestoType) {\n                 case ROW:\n                     if (groupType.getFields().size() == type.getTypeParameters().size()) {\n+                        checkState(type instanceof RowType, \"It must be a RowType here.\");\n+                        RowType rowType = (RowType) type;\n+                        Map<String, Type> prestoFieldMap = rowType.getFields().stream().collect(\n+                                Collectors.toMap(\n+                                        f -> f.getName().get(),", "originalCommit": "2e2526cd3ed7fb860e8852c7f599df2b6dffc810", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODM0NzA4NA==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r398347084", "bodyText": "done", "author": "beinan", "createdAt": "2020-03-26T06:44:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ3NjE5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ3NjM1OQ==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r387476359", "bodyText": "why use parquetFieldType.getName() + \"_\"?\nif prestoFieldType == null, we should return false?", "author": "zhenxiao", "createdAt": "2020-03-04T06:50:03Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -322,8 +325,19 @@ private static boolean checkSchemaMatch(org.apache.parquet.schema.Type parquetTy\n             switch (prestoType) {\n                 case ROW:\n                     if (groupType.getFields().size() == type.getTypeParameters().size()) {\n+                        checkState(type instanceof RowType, \"It must be a RowType here.\");\n+                        RowType rowType = (RowType) type;\n+                        Map<String, Type> prestoFieldMap = rowType.getFields().stream().collect(\n+                                Collectors.toMap(\n+                                        f -> f.getName().get(),\n+                                        f -> f.getType()));\n                         for (int i = 0; i < groupType.getFields().size(); i++) {\n-                            if (!checkSchemaMatch(groupType.getFields().get(i), type.getTypeParameters().get(i))) {\n+                            org.apache.parquet.schema.Type parquetFieldType = groupType.getFields().get(i);\n+                            Type prestoFieldType = prestoFieldMap.get(parquetFieldType.getName());\n+                            if (prestoFieldType == null) {\n+                                prestoFieldType = prestoFieldMap.get(parquetFieldType.getName() + \"_\");", "originalCommit": "2e2526cd3ed7fb860e8852c7f599df2b6dffc810", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODM0NzQ3OQ==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r398347479", "bodyText": "Good call, this feature is twitter specific, which shouldn't in this pr", "author": "beinan", "createdAt": "2020-03-26T06:46:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQ3NjM1OQ=="}], "type": "inlineReview"}, {"oid": "e94443fccefa8e3c2a78a54bb6875e8d9dbebba3", "url": "https://github.com/prestodb/presto/commit/e94443fccefa8e3c2a78a54bb6875e8d9dbebba3", "message": "add unit test for parquet schema mismatch checker\n\nfix code review issues", "committedDate": "2020-03-26T06:40:23Z", "type": "forcePushed"}, {"oid": "dbb3cb744bb0cbaf064c2ac43003c0cdeec85b43", "url": "https://github.com/prestodb/presto/commit/dbb3cb744bb0cbaf064c2ac43003c0cdeec85b43", "message": "add unit test for parquet schema mismatch checker\n\nfix code review issues", "committedDate": "2020-03-26T19:30:44Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0OTcyNQ==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r398949725", "bodyText": "do we need to check type here? prestoType is from type, which is ROW. I think we do not need this line", "author": "zhenxiao", "createdAt": "2020-03-26T23:23:13Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -322,8 +325,17 @@ private static boolean checkSchemaMatch(org.apache.parquet.schema.Type parquetTy\n             switch (prestoType) {\n                 case ROW:\n                     if (groupType.getFields().size() == type.getTypeParameters().size()) {\n+                        checkArgument(type instanceof RowType, \"It must be a RowType here.\");", "originalCommit": "dbb3cb744bb0cbaf064c2ac43003c0cdeec85b43", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwMjgwMw==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r408602803", "bodyText": "good call, removed", "author": "beinan", "createdAt": "2020-04-15T06:12:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk0OTcyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1MDgwNw==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r398950807", "bodyText": "test out of order fields in nested Row type", "author": "zhenxiao", "createdAt": "2020-03-26T23:26:20Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/TestHiveFileFormats.java", "diffHunk": "@@ -722,6 +723,90 @@ public void testSchemaMismatch()\n                 .isFailingForPageSource(new ParquetPageSourceFactory(TYPE_MANAGER, HDFS_ENVIRONMENT, STATS, new HadoopFileOpener()), expectedErrorCode, expectedMessageRowLongNest);\n     }\n \n+    @Test\n+    public void testSchemaMismatchOnNestedStruct()\n+            throws Exception\n+    {\n+        //testing fields order does NOT matter", "originalCommit": "dbb3cb744bb0cbaf064c2ac43003c0cdeec85b43", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwMjg3MA==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r408602870", "bodyText": "done", "author": "beinan", "createdAt": "2020-04-15T06:13:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1MDgwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1MTkyMA==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r398951920", "bodyText": "test field name case sensitivity in nested Row type", "author": "zhenxiao", "createdAt": "2020-03-26T23:29:39Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/TestHiveFileFormats.java", "diffHunk": "@@ -722,6 +723,90 @@ public void testSchemaMismatch()\n                 .isFailingForPageSource(new ParquetPageSourceFactory(TYPE_MANAGER, HDFS_ENVIRONMENT, STATS, new HadoopFileOpener()), expectedErrorCode, expectedMessageRowLongNest);\n     }\n \n+    @Test\n+    public void testSchemaMismatchOnNestedStruct()\n+            throws Exception\n+    {\n+        //testing fields order does NOT matter\n+        TestColumn writeColumn = new TestColumn(\"column_name\",\n+                getStandardMapObjectInspector(\n+                        javaStringObjectInspector,\n+                        getStandardListObjectInspector(\n+                                getStandardStructObjectInspector(\n+                                        ImmutableList.of(\"s_int\", \"s_double\"),\n+                                        ImmutableList.of(javaIntObjectInspector, javaDoubleObjectInspector)))),\n+                ImmutableMap.of(\"test\", ImmutableList.<Object>of(Arrays.asList(1, 5.0))),\n+                mapBlockOf(createUnboundedVarcharType(), new ArrayType(RowType.anonymous(ImmutableList.of(INTEGER, DOUBLE))),\n+                        \"test\", arrayBlockOf(RowType.anonymous(ImmutableList.of(INTEGER, DOUBLE)), rowBlockOf(ImmutableList.of(INTEGER, DOUBLE), 1L, 5.0))));\n+        TestColumn readColumn = new TestColumn(\"column_name\",\n+                getStandardMapObjectInspector(\n+                        javaStringObjectInspector,\n+                        getStandardListObjectInspector(\n+                                getStandardStructObjectInspector(\n+                                        ImmutableList.of(\"s_double\", \"s_int\"),  //out of order\n+                                        ImmutableList.of(javaDoubleObjectInspector, javaIntObjectInspector)))),\n+                ImmutableMap.of(\"test\", ImmutableList.<Object>of(Arrays.asList(5.0, 1))),\n+                mapBlockOf(createUnboundedVarcharType(), new ArrayType(RowType.anonymous(ImmutableList.of(DOUBLE, INTEGER))),\n+                        \"test\", arrayBlockOf(RowType.anonymous(ImmutableList.of(DOUBLE, INTEGER)), rowBlockOf(ImmutableList.of(DOUBLE, INTEGER), 5.0, 1L))));\n+        assertThatFileFormat(PARQUET)\n+                .withWriteColumns(ImmutableList.of(writeColumn))\n+                .withReadColumns(ImmutableList.of(readColumn))\n+                .withRowsCount(1)\n+                .withSession(parquetPageSourceSession)\n+                .isReadableByPageSource(new ParquetPageSourceFactory(TYPE_MANAGER, HDFS_ENVIRONMENT, STATS, new HadoopFileOpener()));\n+\n+        //testing field name case insensitive.", "originalCommit": "dbb3cb744bb0cbaf064c2ac43003c0cdeec85b43", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwMjg5NA==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r408602894", "bodyText": "done", "author": "beinan", "createdAt": "2020-04-15T06:13:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1MTkyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1MjE4Nw==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r398952187", "bodyText": "test field name mismatch in nested Row type", "author": "zhenxiao", "createdAt": "2020-03-26T23:30:28Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/TestHiveFileFormats.java", "diffHunk": "@@ -722,6 +723,90 @@ public void testSchemaMismatch()\n                 .isFailingForPageSource(new ParquetPageSourceFactory(TYPE_MANAGER, HDFS_ENVIRONMENT, STATS, new HadoopFileOpener()), expectedErrorCode, expectedMessageRowLongNest);\n     }\n \n+    @Test\n+    public void testSchemaMismatchOnNestedStruct()\n+            throws Exception\n+    {\n+        //testing fields order does NOT matter\n+        TestColumn writeColumn = new TestColumn(\"column_name\",\n+                getStandardMapObjectInspector(\n+                        javaStringObjectInspector,\n+                        getStandardListObjectInspector(\n+                                getStandardStructObjectInspector(\n+                                        ImmutableList.of(\"s_int\", \"s_double\"),\n+                                        ImmutableList.of(javaIntObjectInspector, javaDoubleObjectInspector)))),\n+                ImmutableMap.of(\"test\", ImmutableList.<Object>of(Arrays.asList(1, 5.0))),\n+                mapBlockOf(createUnboundedVarcharType(), new ArrayType(RowType.anonymous(ImmutableList.of(INTEGER, DOUBLE))),\n+                        \"test\", arrayBlockOf(RowType.anonymous(ImmutableList.of(INTEGER, DOUBLE)), rowBlockOf(ImmutableList.of(INTEGER, DOUBLE), 1L, 5.0))));\n+        TestColumn readColumn = new TestColumn(\"column_name\",\n+                getStandardMapObjectInspector(\n+                        javaStringObjectInspector,\n+                        getStandardListObjectInspector(\n+                                getStandardStructObjectInspector(\n+                                        ImmutableList.of(\"s_double\", \"s_int\"),  //out of order\n+                                        ImmutableList.of(javaDoubleObjectInspector, javaIntObjectInspector)))),\n+                ImmutableMap.of(\"test\", ImmutableList.<Object>of(Arrays.asList(5.0, 1))),\n+                mapBlockOf(createUnboundedVarcharType(), new ArrayType(RowType.anonymous(ImmutableList.of(DOUBLE, INTEGER))),\n+                        \"test\", arrayBlockOf(RowType.anonymous(ImmutableList.of(DOUBLE, INTEGER)), rowBlockOf(ImmutableList.of(DOUBLE, INTEGER), 5.0, 1L))));\n+        assertThatFileFormat(PARQUET)\n+                .withWriteColumns(ImmutableList.of(writeColumn))\n+                .withReadColumns(ImmutableList.of(readColumn))\n+                .withRowsCount(1)\n+                .withSession(parquetPageSourceSession)\n+                .isReadableByPageSource(new ParquetPageSourceFactory(TYPE_MANAGER, HDFS_ENVIRONMENT, STATS, new HadoopFileOpener()));\n+\n+        //testing field name case insensitive.\n+        readColumn = new TestColumn(\"column_name\",\n+                getStandardMapObjectInspector(\n+                        javaStringObjectInspector,\n+                        getStandardListObjectInspector(\n+                                getStandardStructObjectInspector(\n+                                        ImmutableList.of(\"s_DOUBLE\", \"s_INT\"),  //out of order\n+                                        ImmutableList.of(javaDoubleObjectInspector, javaIntObjectInspector)))),\n+                ImmutableMap.of(\"test\", ImmutableList.<Object>of(Arrays.asList(5.0, 1))),\n+                mapBlockOf(createUnboundedVarcharType(), new ArrayType(RowType.anonymous(ImmutableList.of(DOUBLE, INTEGER))),\n+                        \"test\", arrayBlockOf(RowType.anonymous(ImmutableList.of(DOUBLE, INTEGER)), rowBlockOf(ImmutableList.of(DOUBLE, INTEGER), 5.0, 1L))));\n+        assertThatFileFormat(PARQUET)\n+                .withWriteColumns(ImmutableList.of(writeColumn))\n+                .withReadColumns(ImmutableList.of(readColumn))\n+                .withRowsCount(1)\n+                .withSession(parquetPageSourceSession)\n+                .isReadableByPageSource(new ParquetPageSourceFactory(TYPE_MANAGER, HDFS_ENVIRONMENT, STATS, new HadoopFileOpener()));\n+\n+        //testing rename a sub-field would cause a failure.", "originalCommit": "dbb3cb744bb0cbaf064c2ac43003c0cdeec85b43", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwMjkyMg==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r408602922", "bodyText": "done", "author": "beinan", "createdAt": "2020-04-15T06:13:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1MjE4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1Mjc1OA==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r398952758", "bodyText": "do we need to error out when prestoFieldType == null? If parquet file has a field not exist in Presto metastore, it is OK we just leave it there. What do you think?", "author": "zhenxiao", "createdAt": "2020-03-26T23:32:11Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/parquet/ParquetPageSourceFactory.java", "diffHunk": "@@ -322,8 +325,17 @@ private static boolean checkSchemaMatch(org.apache.parquet.schema.Type parquetTy\n             switch (prestoType) {\n                 case ROW:\n                     if (groupType.getFields().size() == type.getTypeParameters().size()) {\n+                        checkArgument(type instanceof RowType, \"It must be a RowType here.\");\n+                        RowType rowType = (RowType) type;\n+                        Map<String, Type> prestoFieldMap = rowType.getFields().stream().collect(\n+                                Collectors.toMap(\n+                                        field -> field.getName().get().toLowerCase(Locale.ENGLISH),\n+                                        field -> field.getType()));\n                         for (int i = 0; i < groupType.getFields().size(); i++) {\n-                            if (!checkSchemaMatch(groupType.getFields().get(i), type.getTypeParameters().get(i))) {\n+                            org.apache.parquet.schema.Type parquetFieldType = groupType.getFields().get(i);\n+                            String fieldName = parquetFieldType.getName().toLowerCase(Locale.ENGLISH);\n+                            Type prestoFieldType = prestoFieldMap.get(fieldName);\n+                            if (prestoFieldType == null || !checkSchemaMatch(parquetFieldType, prestoFieldType)) {", "originalCommit": "dbb3cb744bb0cbaf064c2ac43003c0cdeec85b43", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwMzM2MQ==", "url": "https://github.com/prestodb/presto/pull/14204#discussion_r408603361", "bodyText": "change the condition to prestoFieldType != null && !checkSchemaMatch(parquetFieldType, prestoFieldType)", "author": "beinan", "createdAt": "2020-04-15T06:14:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk1Mjc1OA=="}], "type": "inlineReview"}, {"oid": "6d450fab37c8cf38b740c286d9fda2268fe37444", "url": "https://github.com/prestodb/presto/commit/6d450fab37c8cf38b740c286d9fda2268fe37444", "message": "add unit test for parquet schema mismatch checker\n\nfix code review issues", "committedDate": "2020-04-15T06:10:16Z", "type": "forcePushed"}, {"oid": "d27f94784f0b982a7d4ee18dc375911c42ce5487", "url": "https://github.com/prestodb/presto/commit/d27f94784f0b982a7d4ee18dc375911c42ce5487", "message": "add unit test for parquet schema mismatch checker and fix code review issues", "committedDate": "2020-04-15T06:18:57Z", "type": "forcePushed"}, {"oid": "924069731feb29ecf843668b19c277351cccc183", "url": "https://github.com/prestodb/presto/commit/924069731feb29ecf843668b19c277351cccc183", "message": "add unit test for parquet schema mismatch checker and fix code review issues", "committedDate": "2020-04-15T18:08:42Z", "type": "forcePushed"}, {"oid": "4a30dee9d3206014685f89b039ba3df61d298b0d", "url": "https://github.com/prestodb/presto/commit/4a30dee9d3206014685f89b039ba3df61d298b0d", "message": "Make parquet's schema checking more tolerant for adding/removing sub-field in struct", "committedDate": "2020-04-21T08:03:17Z", "type": "forcePushed"}, {"oid": "8ed33b474a3cd7127e52b3d2f3698338a4c5b411", "url": "https://github.com/prestodb/presto/commit/8ed33b474a3cd7127e52b3d2f3698338a4c5b411", "message": "Use field name for Parquet schema mismatch checking", "committedDate": "2020-04-21T16:55:13Z", "type": "commit"}, {"oid": "f3d71609a8064ec73fa6734a7043cc9436400a5e", "url": "https://github.com/prestodb/presto/commit/f3d71609a8064ec73fa6734a7043cc9436400a5e", "message": "add unit test for parquet schema mismatch checker and fix code review issues", "committedDate": "2020-04-21T16:55:13Z", "type": "commit"}, {"oid": "62963c921cb74eb3f7e4482e5250afa7a85b5459", "url": "https://github.com/prestodb/presto/commit/62963c921cb74eb3f7e4482e5250afa7a85b5459", "message": "Make parquet's schema checking more tolerant for adding/removing sub-field in struct", "committedDate": "2020-04-21T16:55:14Z", "type": "forcePushed"}, {"oid": "1bba388c67fd250f395af107cdb999690b06e8e3", "url": "https://github.com/prestodb/presto/commit/1bba388c67fd250f395af107cdb999690b06e8e3", "message": "Make parquet's schema checking more tolerant for adding and removing sub-field in struct", "committedDate": "2020-04-21T18:18:03Z", "type": "forcePushed"}, {"oid": "57b0eb8b8542523c27c17d8722e144b48b553e0e", "url": "https://github.com/prestodb/presto/commit/57b0eb8b8542523c27c17d8722e144b48b553e0e", "message": "Make parquet's schema check more tolerant for adding and removing sub-field in struct", "committedDate": "2020-04-21T21:07:10Z", "type": "commit"}, {"oid": "57b0eb8b8542523c27c17d8722e144b48b553e0e", "url": "https://github.com/prestodb/presto/commit/57b0eb8b8542523c27c17d8722e144b48b553e0e", "message": "Make parquet's schema check more tolerant for adding and removing sub-field in struct", "committedDate": "2020-04-21T21:07:10Z", "type": "forcePushed"}]}