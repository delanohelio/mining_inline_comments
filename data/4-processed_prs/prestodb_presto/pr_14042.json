{"pr_number": 14042, "pr_title": "Presto Druid Connector", "pr_createdAt": "2020-02-01T18:43:17Z", "pr_url": "https://github.com/prestodb/presto/pull/14042", "timeline": [{"oid": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "url": "https://github.com/prestodb/presto/commit/0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "message": "Presto Druid Connector\n\nCo-authored-by: Zhenxiao Luo <zluo@twitter.com>", "committedDate": "2020-02-01T18:41:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NDQ2Nw==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373884467", "bodyText": "Add a comment to indicate the start of test deps.", "author": "highker", "createdAt": "2020-02-02T23:24:05Z", "path": "presto-druid/pom.xml", "diffHunk": "@@ -0,0 +1,161 @@\n+<?xml version=\"1.0\"?>\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <parent>\n+        <groupId>com.facebook.presto</groupId>\n+        <artifactId>presto-root</artifactId>\n+        <version>0.232-SNAPSHOT</version>\n+    </parent>\n+\n+    <artifactId>presto-druid</artifactId>\n+    <description>Presto - Druid Connector</description>\n+    <packaging>presto-plugin</packaging>\n+\n+    <properties>\n+        <air.main.basedir>${project.parent.basedir}</air.main.basedir>\n+    </properties>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>org.apache.druid</groupId>\n+            <artifactId>druid-processing</artifactId>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>*</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.apache.druid</groupId>\n+            <artifactId>druid-core</artifactId>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>*</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.facebook.airlift</groupId>\n+            <artifactId>bootstrap</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.facebook.airlift</groupId>\n+            <artifactId>configuration</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.facebook.airlift</groupId>\n+            <artifactId>log</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.facebook.airlift</groupId>\n+            <artifactId>json</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.facebook.airlift</groupId>\n+            <artifactId>http-client</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.guava</groupId>\n+            <artifactId>guava</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.inject</groupId>\n+            <artifactId>guice</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.google.code.findbugs</groupId>\n+            <artifactId>jsr305</artifactId>\n+            <optional>true</optional>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>javax.inject</groupId>\n+            <artifactId>javax.inject</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>javax.validation</groupId>\n+            <artifactId>validation-api</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>joda-time</groupId>\n+            <artifactId>joda-time</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.facebook.presto.hadoop</groupId>\n+            <artifactId>hadoop-apache2</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-databind</artifactId>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-core</artifactId>\n+        </dependency>\n+\n+        <!-- Presto SPI -->\n+        <dependency>\n+            <groupId>com.facebook.presto</groupId>\n+            <artifactId>presto-spi</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>slice</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>io.airlift</groupId>\n+            <artifactId>units</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>com.fasterxml.jackson.core</groupId>\n+            <artifactId>jackson-annotations</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+\n+        <dependency>\n+            <groupId>org.openjdk.jol</groupId>\n+            <artifactId>jol-core</artifactId>\n+            <scope>provided</scope>\n+        </dependency>\n+", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NTMyNg==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373885326", "bodyText": "not needed; same for other readers", "author": "highker", "createdAt": "2020-02-02T23:37:47Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/column/DoubleColumnReader.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.column;\n+\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.BlockBuilder;\n+import com.facebook.presto.spi.type.Type;\n+import org.apache.druid.segment.ColumnValueSelector;\n+\n+import java.io.IOException;\n+\n+import static com.facebook.presto.spi.type.DoubleType.DOUBLE;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DoubleColumnReader\n+        implements ColumnReader\n+{\n+    private final ColumnValueSelector<Double> valueSelector;\n+\n+    public DoubleColumnReader(ColumnValueSelector valueSelector)\n+    {\n+        this.valueSelector = requireNonNull(valueSelector, \"value selector is null\");\n+    }\n+\n+    @Override\n+    public Block readBlock(Type type, int batchSize)\n+            throws IOException", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NTM0MA==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373885340", "bodyText": "i++; same for other loops", "author": "highker", "createdAt": "2020-02-02T23:37:55Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/column/DoubleColumnReader.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.column;\n+\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.BlockBuilder;\n+import com.facebook.presto.spi.type.Type;\n+import org.apache.druid.segment.ColumnValueSelector;\n+\n+import java.io.IOException;\n+\n+import static com.facebook.presto.spi.type.DoubleType.DOUBLE;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DoubleColumnReader\n+        implements ColumnReader\n+{\n+    private final ColumnValueSelector<Double> valueSelector;\n+\n+    public DoubleColumnReader(ColumnValueSelector valueSelector)\n+    {\n+        this.valueSelector = requireNonNull(valueSelector, \"value selector is null\");\n+    }\n+\n+    @Override\n+    public Block readBlock(Type type, int batchSize)\n+            throws IOException\n+    {\n+        checkArgument(type == DOUBLE);\n+        BlockBuilder builder = type.createBlockBuilder(null, batchSize);\n+        for (int i = 0; i < batchSize; ++i) {", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NTM4Mw==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373885383", "bodyText": "not necessary.", "author": "highker", "createdAt": "2020-02-02T23:38:57Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/column/ColumnReader.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.column;\n+\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.type.Type;\n+import org.apache.druid.segment.ColumnValueSelector;\n+\n+import java.io.IOException;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_UNSUPPORTED_TYPE_ERROR;\n+import static com.facebook.presto.spi.type.BigintType.BIGINT;\n+import static com.facebook.presto.spi.type.DoubleType.DOUBLE;\n+import static com.facebook.presto.spi.type.RealType.REAL;\n+import static com.facebook.presto.spi.type.TimestampType.TIMESTAMP;\n+import static com.facebook.presto.spi.type.VarcharType.VARCHAR;\n+import static java.lang.String.format;\n+\n+// TODO: refactor duplicate code in column readers\n+public interface ColumnReader\n+{\n+    Block readBlock(Type type, int batchSize)\n+            throws IOException;", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NTc3OA==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373885778", "bodyText": "it's weird to increment row inside getOffset. How about having this class inheriting Offset rather than ReadableOffset?", "author": "highker", "createdAt": "2020-02-02T23:45:30Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/column/SimpleReadableOffset.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.column;\n+\n+import org.apache.druid.query.monomorphicprocessing.RuntimeShapeInspector;\n+import org.apache.druid.segment.data.ReadableOffset;\n+\n+public class SimpleReadableOffset\n+        implements ReadableOffset\n+{\n+    private int row;\n+\n+    @Override\n+    public int getOffset()\n+    {\n+        int offset = row;\n+        ++row;", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAzMTkwMg==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375031902", "bodyText": "bad, could not inherit Offset, BaseColumn is requiring ReadableOffset in makeColumnValuesSelector:\nmakeColumnValueSelector(ReadableOffset offset);\nlet me add comment there", "author": "zhenxiao", "createdAt": "2020-02-05T02:34:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NTc3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NTg1Mg==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373885852", "bodyText": "camel and lower case them", "author": "highker", "createdAt": "2020-02-02T23:46:37Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/metadata/DruidColumnInfo.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.metadata;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DruidColumnInfo\n+{\n+    private final String columnName;\n+    private final String dataType;\n+\n+    @JsonCreator\n+    public DruidColumnInfo(\n+            @JsonProperty(\"COLUMN_NAME\") String columnName,", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY0Mjc5Ng==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375642796", "bodyText": "have to be COLUMN_NAME, it is Druid json fixed format", "author": "zhenxiao", "createdAt": "2020-02-06T05:09:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NTg1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NTg3Mg==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373885872", "bodyText": "camel case", "author": "highker", "createdAt": "2020-02-02T23:46:54Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/metadata/DruidSegmentIdWrapper.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.metadata;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DruidSegmentIdWrapper\n+{\n+    private final String segmentId;\n+\n+    @JsonCreator\n+    public DruidSegmentIdWrapper(@JsonProperty(\"segment_id\") String segmentId)", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY0Mjg4MQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375642881", "bodyText": "have to be segment_id, druid json metadata fixed format", "author": "zhenxiao", "createdAt": "2020-02-06T05:09:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NTg3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NTg5Nw==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373885897", "bodyText": "spell out Spec; same for the other one.", "author": "highker", "createdAt": "2020-02-02T23:47:22Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/metadata/DruidSegmentInfo.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.metadata;\n+\n+import com.facebook.presto.spi.PrestoException;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import org.joda.time.Interval;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_METADATA_ERROR;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DruidSegmentInfo\n+{\n+    private static final String DEEP_STORAGE_TYPE_KEY = \"type\";\n+    private static final String SEGMENT_PATH_KEY = \"path\";\n+\n+    private final String dataSource;\n+    private final Interval interval;\n+    private final String version;\n+    private final Optional<Map<String, String>> loadSpec;", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NTk0Mg==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373885942", "bodyText": "size can't be null", "author": "highker", "createdAt": "2020-02-02T23:48:04Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/metadata/DruidSegmentInfo.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.metadata;\n+\n+import com.facebook.presto.spi.PrestoException;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import org.joda.time.Interval;\n+\n+import javax.annotation.Nullable;\n+\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_METADATA_ERROR;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DruidSegmentInfo\n+{\n+    private static final String DEEP_STORAGE_TYPE_KEY = \"type\";\n+    private static final String SEGMENT_PATH_KEY = \"path\";\n+\n+    private final String dataSource;\n+    private final Interval interval;\n+    private final String version;\n+    private final Optional<Map<String, String>> loadSpec;\n+    private final Optional<Map<String, String>> shardSpec;\n+    private final Integer binaryVersion;\n+    private final long size;\n+\n+    public enum DeepStorageType\n+    {\n+        HDFS(\"hdfs\");\n+\n+        private final String type;\n+\n+        DeepStorageType(String type)\n+        {\n+            this.type = type;\n+        }\n+    }\n+\n+    @JsonCreator\n+    public DruidSegmentInfo(\n+            @JsonProperty(\"dataSource\") String dataSource,\n+            @JsonProperty(\"interval\") Interval interval,\n+            @JsonProperty(\"version\") String version,\n+            @JsonProperty(\"loadSpec\") Optional<Map<String, String>> loadSpec,\n+            @JsonProperty(\"shardSpec\") @Nullable Optional<Map<String, String>> shardSpec,\n+            @JsonProperty(\"binaryVersion\") Integer binaryVersion,\n+            @JsonProperty(\"size\") long size)\n+    {\n+        this.dataSource = requireNonNull(dataSource, \"dataSource is null\");\n+        this.interval = requireNonNull(interval, \"interval is null\");\n+        this.version = requireNonNull(version, \"version is null\");\n+        this.loadSpec = requireNonNull(loadSpec, \"loadSpec is null\");\n+        this.shardSpec = requireNonNull(shardSpec, \"shardSpec is null\");\n+        this.binaryVersion = requireNonNull(binaryVersion, \"binaryVersion is null\");\n+        this.size = requireNonNull(size, \"size is null\");", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NTk3OQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373885979", "bodyText": "camel and lower case", "author": "highker", "createdAt": "2020-02-02T23:48:41Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/metadata/DruidTableInfo.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.metadata;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DruidTableInfo\n+{\n+    private final String tableName;\n+\n+    @JsonCreator\n+    public DruidTableInfo(@JsonProperty(\"TABLE_NAME\") String tableName)", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTY0Mjk4Mg==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375642982", "bodyText": "same, have to be TABLE_NAME, druid json fixed format", "author": "zhenxiao", "createdAt": "2020-02-06T05:10:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NTk3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NjAwMQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373886001", "bodyText": "convert to local var", "author": "highker", "createdAt": "2020-02-02T23:48:57Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/DruidSegmentReader.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.druid.DruidColumnHandle;\n+import com.facebook.presto.druid.column.ColumnReader;\n+import com.facebook.presto.druid.column.SimpleReadableOffset;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.type.Type;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.QueryableIndex;\n+import org.apache.druid.segment.column.BaseColumn;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static com.facebook.presto.druid.column.ColumnReader.createColumnReader;\n+import static java.lang.Math.min;\n+import static java.lang.Math.toIntExact;\n+\n+public class DruidSegmentReader\n+        implements SegmentReader\n+{\n+    private static final int BATCH_SIZE = 1024;\n+\n+    private final QueryableIndex queryableIndex;", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NjA0Mg==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373886042", "bodyText": "Shall we build this with ImmutableMap inside constructor?", "author": "highker", "createdAt": "2020-02-02T23:49:42Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/DruidSegmentReader.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.druid.DruidColumnHandle;\n+import com.facebook.presto.druid.column.ColumnReader;\n+import com.facebook.presto.druid.column.SimpleReadableOffset;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.type.Type;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.QueryableIndex;\n+import org.apache.druid.segment.column.BaseColumn;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static com.facebook.presto.druid.column.ColumnReader.createColumnReader;\n+import static java.lang.Math.min;\n+import static java.lang.Math.toIntExact;\n+\n+public class DruidSegmentReader\n+        implements SegmentReader\n+{\n+    private static final int BATCH_SIZE = 1024;\n+\n+    private final QueryableIndex queryableIndex;\n+    private final Map<String, ColumnReader> columnValueSelectors = new HashMap<>();", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NjA2Mg==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373886062", "bodyText": "not useful", "author": "highker", "createdAt": "2020-02-02T23:50:02Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/SegmentReader.java", "diffHunk": "@@ -0,0 +1,28 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.type.Type;\n+\n+import java.io.IOException;\n+\n+public interface SegmentReader\n+{\n+    int nextBatch()\n+            throws IOException;", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NjA3NQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373886075", "bodyText": "same", "author": "highker", "createdAt": "2020-02-02T23:50:17Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/SegmentReader.java", "diffHunk": "@@ -0,0 +1,28 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.type.Type;\n+\n+import java.io.IOException;\n+\n+public interface SegmentReader\n+{\n+    int nextBatch()\n+            throws IOException;\n+\n+    Block readBlock(Type type, String columnName)\n+            throws IOException;", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NjEwMQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373886101", "bodyText": "never null", "author": "highker", "createdAt": "2020-02-02T23:50:35Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/HdfsDataInputSource.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.druid.DataInputSource;\n+import com.facebook.presto.druid.DataInputSourceId;\n+import com.facebook.presto.spi.PrestoException;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+\n+import java.io.IOException;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_DEEP_STORAGE_ERROR;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HdfsDataInputSource\n+        implements DataInputSource\n+{\n+    private final DataInputSourceId id;\n+    private final FSDataInputStream inputStream;\n+    private final long size;\n+    private long readTimeNanos;\n+    private long readBytes;\n+\n+    public HdfsDataInputSource(\n+            DataInputSourceId id,\n+            FSDataInputStream inputStream,\n+            long size)\n+    {\n+        this.id = requireNonNull(id, \"id is null\");\n+        this.inputStream = requireNonNull(inputStream, \"inputStream is null\");\n+        this.size = requireNonNull(size, \"size is null\");", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NjE1Mw==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373886153", "bodyText": "not used", "author": "highker", "createdAt": "2020-02-02T23:51:13Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/SmooshedColumnSource.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.spi.PrestoException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.druid.common.utils.SerializerUtils;\n+import org.apache.druid.jackson.DefaultObjectMapper;\n+\n+import java.io.BufferedReader;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.TreeMap;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class SmooshedColumnSource\n+        implements SegmentColumnSource\n+{\n+    private static final String FILE_EXTENSION = \"smoosh\";\n+    private static final String SMOOSH_METADATA_FILE_NAME = makeMetaFileName();\n+    private static final String VERSION_FILE_NAME = \"version.bin\";\n+    private static final String INDEX_METADATA_FILE_NAME = \"index.drd\";\n+    private static final String SEGMENT_METADATA_FILE_NAME = \"metadata.drd\";", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg4NjE3Ng==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r373886176", "bodyText": "not used", "author": "highker", "createdAt": "2020-02-02T23:51:33Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/SmooshedColumnSource.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.spi.PrestoException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.druid.common.utils.SerializerUtils;\n+import org.apache.druid.jackson.DefaultObjectMapper;\n+\n+import java.io.BufferedReader;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.TreeMap;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class SmooshedColumnSource\n+        implements SegmentColumnSource\n+{\n+    private static final String FILE_EXTENSION = \"smoosh\";\n+    private static final String SMOOSH_METADATA_FILE_NAME = makeMetaFileName();\n+    private static final String VERSION_FILE_NAME = \"version.bin\";\n+    private static final String INDEX_METADATA_FILE_NAME = \"index.drd\";\n+    private static final String SEGMENT_METADATA_FILE_NAME = \"metadata.drd\";\n+\n+    private static final ObjectMapper JSON_MAPPER = new DefaultObjectMapper();\n+    private static final SerializerUtils SERIALIZER_UTILS = new SerializerUtils();\n+\n+    private final IndexFileSource indexFileSource;\n+    private final Map<String, SmooshFileMetadata> columnSmoosh = new TreeMap<>();\n+\n+    private int numFiles;", "originalCommit": "0d54c2dfa76c5c2ccfc8eef5c38001a5aa1fec71", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "77d65600491271fee6eff1d23d334c979915d246", "url": "https://github.com/prestodb/presto/commit/77d65600491271fee6eff1d23d334c979915d246", "message": "Fix coding style for Druid connector", "committedDate": "2020-02-05T02:59:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTUwMzI1OQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375503259", "bodyText": "Hey, since the latest version of druid is 0.17, any plans on upgrading this ?", "author": "ChethanUK", "createdAt": "2020-02-05T20:56:52Z", "path": "pom.xml", "diffHunk": "@@ -64,6 +64,7 @@\n         <dep.gcs.version>1.9.17</dep.gcs.version>\n         <dep.alluxio.version>2.1.1</dep.alluxio.version>\n         <dep.kafka.version>2.3.1</dep.kafka.version>\n+        <dep.druid.version>0.15.0-incubating</dep.druid.version>", "originalCommit": "77d65600491271fee6eff1d23d334c979915d246", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "68028485595f3beb7247b9c928bbd5a4c54a1905", "url": "https://github.com/prestodb/presto/commit/68028485595f3beb7247b9c928bbd5a4c54a1905", "message": "Upgrade to druid 0.17.0", "committedDate": "2020-02-06T00:20:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU4OTY3NQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375589675", "bodyText": "wow? So you cannot have predicate like true or false in Druid??", "author": "wenleix", "createdAt": "2020-02-06T00:51:37Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/DruidClient.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid;\n+\n+import com.facebook.airlift.http.client.HttpClient;\n+import com.facebook.airlift.http.client.HttpUriBuilder;\n+import com.facebook.airlift.http.client.Request;\n+import com.facebook.airlift.json.JsonCodec;\n+import com.facebook.presto.druid.metadata.DruidColumnInfo;\n+import com.facebook.presto.druid.metadata.DruidSegmentIdWrapper;\n+import com.facebook.presto.druid.metadata.DruidSegmentInfo;\n+import com.facebook.presto.druid.metadata.DruidTableInfo;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.Range;\n+import com.google.common.base.Joiner;\n+import org.joda.time.Instant;\n+\n+import javax.inject.Inject;\n+\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static com.facebook.airlift.http.client.HttpUriBuilder.uriBuilderFrom;\n+import static com.facebook.airlift.http.client.JsonResponseHandler.createJsonResponseHandler;\n+import static com.facebook.airlift.http.client.Request.Builder.prepareGet;\n+import static com.facebook.airlift.http.client.Request.Builder.preparePost;\n+import static com.facebook.airlift.http.client.StaticBodyGenerator.createStaticBodyGenerator;\n+import static com.facebook.airlift.json.JsonCodec.jsonCodec;\n+import static com.facebook.airlift.json.JsonCodec.listJsonCodec;\n+import static com.facebook.presto.spi.type.TimestampType.TIMESTAMP;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.net.HttpHeaders.ACCEPT;\n+import static com.google.common.net.HttpHeaders.CONTENT_TYPE;\n+import static com.google.common.net.MediaType.JSON_UTF_8;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DruidClient\n+{\n+    private static final String ALWAYS_TRUE = \"1=1\";", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMjY0MQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375602641", "bodyText": "yep, druid does not have boolean type", "author": "zhenxiao", "createdAt": "2020-02-06T01:42:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU4OTY3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU5MDI1MQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375590251", "bodyText": "What does this comment mean?", "author": "wenleix", "createdAt": "2020-02-06T00:53:40Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/DruidSplitManager.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid;\n+\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorSplitSource;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.FixedSplitSource;\n+import com.facebook.presto.spi.HostAddress;\n+import com.facebook.presto.spi.connector.ConnectorSplitManager;\n+import com.facebook.presto.spi.connector.ConnectorTransactionHandle;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+\n+import javax.inject.Inject;\n+\n+import java.util.List;\n+\n+import static com.facebook.presto.spi.type.TimestampType.TIMESTAMP;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DruidSplitManager\n+        implements ConnectorSplitManager\n+{\n+    private final DruidClient druidClient;\n+\n+    @Inject\n+    public DruidSplitManager(DruidClient druidClient)\n+    {\n+        this.druidClient = requireNonNull(druidClient, \"druid client is null\");\n+    }\n+\n+    @Override\n+    public ConnectorSplitSource getSplits(\n+            ConnectorTransactionHandle transaction,\n+            ConnectorSession session,\n+            ConnectorTableLayoutHandle layout,\n+            SplitSchedulingContext splitSchedulingContext)\n+    {\n+        DruidTableLayoutHandle layoutHandle = (DruidTableLayoutHandle) layout;\n+        DruidTableHandle table = layoutHandle.getTable();\n+        List<String> segmentIds = getSegmentId(table);\n+\n+        // TODO: add scheduling", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU5MTY5Nw==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375591697", "bodyText": "nit:\n        while (position - offset < length && bytesRead != -1) {", "author": "wenleix", "createdAt": "2020-02-06T00:59:05Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/ZipIndexFileSource.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.druid.DataInputSource;\n+import com.facebook.presto.druid.zip.CentralDirectoryFileHeader;\n+import com.facebook.presto.druid.zip.EndOfCentralDirectoryRecord;\n+import com.facebook.presto.druid.zip.LocalFileHeader;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectory;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectoryLocator;\n+import com.facebook.presto.druid.zip.ZipFileData;\n+import com.facebook.presto.druid.zip.ZipFileEntry;\n+import com.facebook.presto.druid.zip.ZipUtil;\n+import com.facebook.presto.spi.PrestoException;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Collection;\n+import java.util.zip.Inflater;\n+import java.util.zip.InflaterInputStream;\n+import java.util.zip.ZipException;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.lang.String.format;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ZipIndexFileSource\n+        implements IndexFileSource, Closeable, AutoCloseable\n+{\n+    private final DataInputSource dataInputSource;\n+    private final ZipFileData zipData;\n+\n+    public ZipIndexFileSource(DataInputSource dataInputSource)\n+    {\n+        this.dataInputSource = requireNonNull(dataInputSource, \"dataInputSource is null\");\n+        this.zipData = readCentralDirectory();\n+    }\n+\n+    /**\n+     * Reads file inside a zip archive\n+     */\n+    @Override\n+    public byte[] readFile(String fileName)\n+            throws IOException\n+    {\n+        ZipFileEntry entry = zipData.getEntry(fileName);\n+        if (entry == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip doesn't contain file: %s\", fileName));\n+        }\n+        byte[] fileData = new byte[(int) entry.getSize()];\n+        readFully(entry, 0, fileData, 0, fileData.length);\n+        return fileData;\n+    }\n+\n+    @Override\n+    public final void readFile(String fileName, long position, byte[] buffer)\n+            throws IOException\n+    {\n+        ZipFileEntry entry = zipData.getEntry(fileName);\n+        if (entry == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip doesn't contain file: %s\", fileName));\n+        }\n+        readFully(entry, position, buffer, 0, buffer.length);\n+    }\n+\n+    private void readFully(ZipFileEntry entry, long position, byte[] buffer, int bufferOffset, int bufferLength)\n+            throws IOException\n+    {\n+        long offset = entry.getLocalHeaderOffset();\n+        byte[] fileHeader = new byte[LocalFileHeader.FIXED_DATA_SIZE];\n+        dataInputSource.readFully(offset, fileHeader);\n+        offset += fileHeader.length;\n+\n+        if (!ZipUtil.arrayStartsWith(fileHeader, ZipUtil.intToLittleEndian(LocalFileHeader.SIGNATURE))) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR,\n+                    format(\"The file '%s' is not a correctly formatted zip file: Expected a File Header at file offset %d, but was not present.\", entry.getName()));\n+        }\n+\n+        // skip name and extra field\n+        int nameLength = ZipUtil.getUnsignedShort(fileHeader, LocalFileHeader.FILENAME_LENGTH_OFFSET);\n+        int extraFieldLength = ZipUtil.getUnsignedShort(fileHeader, LocalFileHeader.EXTRA_FIELD_LENGTH_OFFSET);\n+        offset += (nameLength + extraFieldLength);\n+\n+        // deflate\n+        int compressedSize = (int) entry.getCompressedSize();\n+        byte[] compressedData = new byte[compressedSize];\n+        dataInputSource.readFully(offset, compressedData);\n+        InflaterInputStream inflaterInputStream = new InflaterInputStream(new ByteArrayInputStream(compressedData), new Inflater(true));\n+\n+        try {\n+            inflaterInputStream.skip(position);\n+            int size = chunkedRead(inflaterInputStream, buffer, bufferOffset, bufferLength);\n+            checkState(size == bufferLength);\n+        }\n+        catch (IOException e) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Malformed zip file: %s\", entry.getName()));\n+        }\n+    }\n+\n+    // read inflater stream chunk by chunk\n+    private static int chunkedRead(InflaterInputStream inflaterInputStream, byte[] buffer, int offset, int length)\n+            throws IOException\n+    {\n+        int position = offset;\n+        int bytesRead = 0;\n+\n+        while (((position - offset) < length) && bytesRead != -1) {", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU5Mjg4Nw==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375592887", "bodyText": "I personally just prefer to have something like\nwhile (true) {\n      line = in.readLine();\n      if (line == null) {\n          break;\n      }\n......\n}\nBut it's just personal preference and not strong opinion here :)", "author": "wenleix", "createdAt": "2020-02-06T01:03:31Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/SmooshedColumnSource.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.spi.PrestoException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.druid.common.utils.SerializerUtils;\n+import org.apache.druid.jackson.DefaultObjectMapper;\n+\n+import java.io.BufferedReader;\n+import java.io.ByteArrayInputStream;\n+import java.io.IOException;\n+import java.io.InputStreamReader;\n+import java.nio.ByteBuffer;\n+import java.util.Map;\n+import java.util.TreeMap;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class SmooshedColumnSource\n+        implements SegmentColumnSource\n+{\n+    private static final String FILE_EXTENSION = \"smoosh\";\n+    private static final String SMOOSH_METADATA_FILE_NAME = makeMetaFileName();\n+    private static final String VERSION_FILE_NAME = \"version.bin\";\n+    private static final String INDEX_METADATA_FILE_NAME = \"index.drd\";\n+\n+    private static final ObjectMapper JSON_MAPPER = new DefaultObjectMapper();\n+    private static final SerializerUtils SERIALIZER_UTILS = new SerializerUtils();\n+\n+    private final IndexFileSource indexFileSource;\n+    private final Map<String, SmooshFileMetadata> columnSmoosh = new TreeMap<>();\n+\n+    private int numFiles;\n+\n+    public SmooshedColumnSource(IndexFileSource indexFileSource)\n+    {\n+        this.indexFileSource = requireNonNull(indexFileSource, \"indexFileSource is null\");\n+        loadSmooshFileMetadata();\n+    }\n+\n+    @Override\n+    public int getVersion()\n+    {\n+        try {\n+            return ByteBuffer.wrap(indexFileSource.readFile(VERSION_FILE_NAME)).getInt();\n+        }\n+        catch (IOException e) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, e);\n+        }\n+    }\n+\n+    @Override\n+    public byte[] getColumnData(String name)\n+    {\n+        SmooshFileMetadata metadata = columnSmoosh.get(name);\n+        if (metadata == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Internal file %s doesn't exist\", name));\n+        }\n+        String fileName = makeChunkFileName(metadata.getFileNum());\n+        int fileStart = metadata.getStartOffset();\n+        int fileSize = metadata.getEndOffset() - fileStart;\n+\n+        byte[] buffer = new byte[fileSize];\n+        try {\n+            indexFileSource.readFile(fileName, fileStart, buffer);\n+        }\n+        catch (IOException e) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, e);\n+        }\n+        return buffer;\n+    }\n+\n+    private void loadSmooshFileMetadata()\n+    {\n+        try {\n+            byte[] metadata = indexFileSource.readFile(SMOOSH_METADATA_FILE_NAME);\n+            BufferedReader in = new BufferedReader(new InputStreamReader(new ByteArrayInputStream(metadata)));\n+            String line = in.readLine();\n+            if (line == null) {\n+                throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Malformed metadata file: first line should be version,maxChunkSize,numChunks, got null.\"));\n+            }\n+\n+            String[] splits = line.split(\",\");\n+            if (!\"v1\".equals(splits[0])) {\n+                throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Malformed metadata file: unknown version[%s], v1 is all I know.\", splits[0]));\n+            }\n+            if (splits.length != 3) {\n+                throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Malformed metadata file: wrong number of splits[%d] in line[%s]\", splits.length,\n+                        line));\n+            }\n+            numFiles = Integer.valueOf(splits[2]);\n+\n+            while ((line = in.readLine()) != null) {", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU5ODU3Nw==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375598577", "bodyText": "Maybe just make it a DruidQueryRunner like what other connectors do.", "author": "highker", "createdAt": "2020-02-06T01:25:26Z", "path": "presto-druid/src/test/java/com/facebook/presto/druid/DruidQueryRunnerBuilder.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid;\n+\n+import com.facebook.airlift.log.Logger;\n+import com.facebook.presto.Session;\n+import com.facebook.presto.tests.DistributedQueryRunner;\n+import com.google.common.collect.ImmutableMap;\n+\n+import java.util.Map;\n+\n+import static com.facebook.presto.testing.TestingSession.testSessionBuilder;\n+import static java.lang.String.format;\n+\n+public class DruidQueryRunnerBuilder", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU5OTA3NQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375599075", "bodyText": "this can be a local variable", "author": "highker", "createdAt": "2020-02-06T01:27:29Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/DruidSegmentReader.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.druid.DruidColumnHandle;\n+import com.facebook.presto.druid.column.ColumnReader;\n+import com.facebook.presto.druid.column.SimpleReadableOffset;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.type.Type;\n+import com.google.common.collect.ImmutableMap;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.QueryableIndex;\n+import org.apache.druid.segment.column.BaseColumn;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static com.facebook.presto.druid.column.ColumnReader.createColumnReader;\n+import static java.lang.Math.min;\n+import static java.lang.Math.toIntExact;\n+\n+public class DruidSegmentReader\n+        implements SegmentReader\n+{\n+    private static final int BATCH_SIZE = 1024;\n+\n+    private final Map<String, ColumnReader> columnValueSelectors;\n+    private final long totalRowCount;\n+\n+    private QueryableIndex queryableIndex;", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU5OTMzOA==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375599338", "bodyText": "remove final and actually this variable is not used.", "author": "highker", "createdAt": "2020-02-06T01:28:43Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/V9SegmentIndexSource.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.airlift.log.Logger;\n+import com.facebook.presto.druid.DruidColumnHandle;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.PrestoException;\n+import com.fasterxml.jackson.core.JsonParseException;\n+import com.fasterxml.jackson.databind.JsonMappingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.base.Supplier;\n+import com.google.common.collect.Streams;\n+import org.apache.druid.common.utils.SerializerUtils;\n+import org.apache.druid.jackson.DefaultObjectMapper;\n+import org.apache.druid.java.util.common.Intervals;\n+import org.apache.druid.segment.Metadata;\n+import org.apache.druid.segment.QueryableIndex;\n+import org.apache.druid.segment.SimpleQueryableIndex;\n+import org.apache.druid.segment.column.ColumnDescriptor;\n+import org.apache.druid.segment.column.ColumnHolder;\n+import org.apache.druid.segment.data.BitmapSerde;\n+import org.apache.druid.segment.data.BitmapSerdeFactory;\n+import org.apache.druid.segment.data.GenericIndexed;\n+import org.joda.time.Interval;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.druid.segment.column.ColumnHolder.TIME_COLUMN_NAME;\n+import static org.apache.druid.segment.data.GenericIndexed.STRING_STRATEGY;\n+\n+// V9 index with version 1 index.drd\n+public class V9SegmentIndexSource\n+        implements SegmentIndexSource\n+{\n+    private static final Logger log = Logger.get(V9SegmentIndexSource.class);\n+\n+    private static final String INDEX_METADATA_FILE_NAME = \"index.drd\";\n+    private static final String SEGMENT_METADATA_FILE_NAME = \"metadata.drd\";\n+\n+    private static final ObjectMapper JSON_MAPPER = new DefaultObjectMapper();\n+    private static final SerializerUtils SERIALIZER_UTILS = new SerializerUtils();\n+\n+    private final SegmentColumnSource segmentColumnSource;\n+\n+    public V9SegmentIndexSource(SegmentColumnSource segmentColumnSource)\n+    {\n+        this.segmentColumnSource = requireNonNull(segmentColumnSource, \"segmentColumnSource is null\");\n+    }\n+\n+    @Override\n+    public QueryableIndex loadIndex(List<ColumnHandle> columnHandles)\n+            throws IOException\n+    {\n+        ByteBuffer indexBuffer = ByteBuffer.wrap(segmentColumnSource.getColumnData(INDEX_METADATA_FILE_NAME));\n+        final GenericIndexed<String> allColumns = GenericIndexed.read(", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU5OTY2Mg==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375599662", "bodyText": "nit columns::containsKey", "author": "highker", "createdAt": "2020-02-06T01:30:12Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/V9SegmentIndexSource.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.airlift.log.Logger;\n+import com.facebook.presto.druid.DruidColumnHandle;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.PrestoException;\n+import com.fasterxml.jackson.core.JsonParseException;\n+import com.fasterxml.jackson.databind.JsonMappingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.base.Supplier;\n+import com.google.common.collect.Streams;\n+import org.apache.druid.common.utils.SerializerUtils;\n+import org.apache.druid.jackson.DefaultObjectMapper;\n+import org.apache.druid.java.util.common.Intervals;\n+import org.apache.druid.segment.Metadata;\n+import org.apache.druid.segment.QueryableIndex;\n+import org.apache.druid.segment.SimpleQueryableIndex;\n+import org.apache.druid.segment.column.ColumnDescriptor;\n+import org.apache.druid.segment.column.ColumnHolder;\n+import org.apache.druid.segment.data.BitmapSerde;\n+import org.apache.druid.segment.data.BitmapSerdeFactory;\n+import org.apache.druid.segment.data.GenericIndexed;\n+import org.joda.time.Interval;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.druid.segment.column.ColumnHolder.TIME_COLUMN_NAME;\n+import static org.apache.druid.segment.data.GenericIndexed.STRING_STRATEGY;\n+\n+// V9 index with version 1 index.drd\n+public class V9SegmentIndexSource\n+        implements SegmentIndexSource\n+{\n+    private static final Logger log = Logger.get(V9SegmentIndexSource.class);\n+\n+    private static final String INDEX_METADATA_FILE_NAME = \"index.drd\";\n+    private static final String SEGMENT_METADATA_FILE_NAME = \"metadata.drd\";\n+\n+    private static final ObjectMapper JSON_MAPPER = new DefaultObjectMapper();\n+    private static final SerializerUtils SERIALIZER_UTILS = new SerializerUtils();\n+\n+    private final SegmentColumnSource segmentColumnSource;\n+\n+    public V9SegmentIndexSource(SegmentColumnSource segmentColumnSource)\n+    {\n+        this.segmentColumnSource = requireNonNull(segmentColumnSource, \"segmentColumnSource is null\");\n+    }\n+\n+    @Override\n+    public QueryableIndex loadIndex(List<ColumnHandle> columnHandles)\n+            throws IOException\n+    {\n+        ByteBuffer indexBuffer = ByteBuffer.wrap(segmentColumnSource.getColumnData(INDEX_METADATA_FILE_NAME));\n+        final GenericIndexed<String> allColumns = GenericIndexed.read(\n+                indexBuffer,\n+                STRING_STRATEGY);\n+        GenericIndexed<String> allDimensions = GenericIndexed.read(\n+                indexBuffer,\n+                STRING_STRATEGY);\n+\n+        Interval dataInterval = Intervals.utc(indexBuffer.getLong(), indexBuffer.getLong());\n+\n+        BitmapSerdeFactory segmentBitmapSerdeFactory;\n+\n+        if (indexBuffer.hasRemaining()) {\n+            segmentBitmapSerdeFactory = JSON_MAPPER.readValue(SERIALIZER_UTILS.readString(indexBuffer), BitmapSerdeFactory.class);\n+        }\n+        else {\n+            segmentBitmapSerdeFactory = new BitmapSerde.LegacyBitmapSerdeFactory();\n+        }\n+\n+        Metadata metadata = null;\n+        ByteBuffer metadataBB = ByteBuffer.wrap(segmentColumnSource.getColumnData(SEGMENT_METADATA_FILE_NAME));\n+        try {\n+            metadata = JSON_MAPPER.readValue(SERIALIZER_UTILS.readBytes(metadataBB, metadataBB.remaining()), Metadata.class);\n+        }\n+        catch (JsonParseException | JsonMappingException e) {\n+            // Any jackson deserialization errors are ignored e.g. if metadata contains some aggregator which\n+            // is no longer supported then it is OK to not use the metadata instead of failing segment loading\n+            log.warn(e, \"Failed to load metadata for segment \");\n+        }\n+\n+        Map<String, Supplier<ColumnHolder>> columns = new HashMap<>();\n+        for (ColumnHandle columnHandle : columnHandles) {\n+            String columnName = ((DruidColumnHandle) columnHandle).getColumnName();\n+            columns.put(columnName, () -> createColumnHolder(columnName));\n+        }\n+\n+        List<String> availableDimensions = Streams.stream(allDimensions.iterator())\n+                .filter(dimension -> columns.containsKey(dimension))", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU5OTc2NQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375599765", "bodyText": "spell out metadataBB", "author": "highker", "createdAt": "2020-02-06T01:30:43Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/V9SegmentIndexSource.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.airlift.log.Logger;\n+import com.facebook.presto.druid.DruidColumnHandle;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.PrestoException;\n+import com.fasterxml.jackson.core.JsonParseException;\n+import com.fasterxml.jackson.databind.JsonMappingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.base.Supplier;\n+import com.google.common.collect.Streams;\n+import org.apache.druid.common.utils.SerializerUtils;\n+import org.apache.druid.jackson.DefaultObjectMapper;\n+import org.apache.druid.java.util.common.Intervals;\n+import org.apache.druid.segment.Metadata;\n+import org.apache.druid.segment.QueryableIndex;\n+import org.apache.druid.segment.SimpleQueryableIndex;\n+import org.apache.druid.segment.column.ColumnDescriptor;\n+import org.apache.druid.segment.column.ColumnHolder;\n+import org.apache.druid.segment.data.BitmapSerde;\n+import org.apache.druid.segment.data.BitmapSerdeFactory;\n+import org.apache.druid.segment.data.GenericIndexed;\n+import org.joda.time.Interval;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.util.Objects.requireNonNull;\n+import static org.apache.druid.segment.column.ColumnHolder.TIME_COLUMN_NAME;\n+import static org.apache.druid.segment.data.GenericIndexed.STRING_STRATEGY;\n+\n+// V9 index with version 1 index.drd\n+public class V9SegmentIndexSource\n+        implements SegmentIndexSource\n+{\n+    private static final Logger log = Logger.get(V9SegmentIndexSource.class);\n+\n+    private static final String INDEX_METADATA_FILE_NAME = \"index.drd\";\n+    private static final String SEGMENT_METADATA_FILE_NAME = \"metadata.drd\";\n+\n+    private static final ObjectMapper JSON_MAPPER = new DefaultObjectMapper();\n+    private static final SerializerUtils SERIALIZER_UTILS = new SerializerUtils();\n+\n+    private final SegmentColumnSource segmentColumnSource;\n+\n+    public V9SegmentIndexSource(SegmentColumnSource segmentColumnSource)\n+    {\n+        this.segmentColumnSource = requireNonNull(segmentColumnSource, \"segmentColumnSource is null\");\n+    }\n+\n+    @Override\n+    public QueryableIndex loadIndex(List<ColumnHandle> columnHandles)\n+            throws IOException\n+    {\n+        ByteBuffer indexBuffer = ByteBuffer.wrap(segmentColumnSource.getColumnData(INDEX_METADATA_FILE_NAME));\n+        final GenericIndexed<String> allColumns = GenericIndexed.read(\n+                indexBuffer,\n+                STRING_STRATEGY);\n+        GenericIndexed<String> allDimensions = GenericIndexed.read(\n+                indexBuffer,\n+                STRING_STRATEGY);\n+\n+        Interval dataInterval = Intervals.utc(indexBuffer.getLong(), indexBuffer.getLong());\n+\n+        BitmapSerdeFactory segmentBitmapSerdeFactory;\n+\n+        if (indexBuffer.hasRemaining()) {\n+            segmentBitmapSerdeFactory = JSON_MAPPER.readValue(SERIALIZER_UTILS.readString(indexBuffer), BitmapSerdeFactory.class);\n+        }\n+        else {\n+            segmentBitmapSerdeFactory = new BitmapSerde.LegacyBitmapSerdeFactory();\n+        }\n+\n+        Metadata metadata = null;\n+        ByteBuffer metadataBB = ByteBuffer.wrap(segmentColumnSource.getColumnData(SEGMENT_METADATA_FILE_NAME));", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU5OTkyMw==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375599923", "bodyText": "put this on stack", "author": "highker", "createdAt": "2020-02-06T01:31:21Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/ZipIndexFileSource.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.druid.DataInputSource;\n+import com.facebook.presto.druid.zip.CentralDirectoryFileHeader;\n+import com.facebook.presto.druid.zip.EndOfCentralDirectoryRecord;\n+import com.facebook.presto.druid.zip.LocalFileHeader;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectory;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectoryLocator;\n+import com.facebook.presto.druid.zip.ZipFileData;\n+import com.facebook.presto.druid.zip.ZipFileEntry;\n+import com.facebook.presto.druid.zip.ZipUtil;\n+import com.facebook.presto.spi.PrestoException;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Collection;\n+import java.util.zip.Inflater;\n+import java.util.zip.InflaterInputStream;\n+import java.util.zip.ZipException;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.lang.String.format;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ZipIndexFileSource\n+        implements IndexFileSource, Closeable, AutoCloseable\n+{\n+    private final DataInputSource dataInputSource;\n+    private final ZipFileData zipData;\n+\n+    public ZipIndexFileSource(DataInputSource dataInputSource)\n+    {\n+        this.dataInputSource = requireNonNull(dataInputSource, \"dataInputSource is null\");\n+        this.zipData = readCentralDirectory();", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMDAzNg==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375600036", "bodyText": "format argument does not match.", "author": "highker", "createdAt": "2020-02-06T01:31:48Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/ZipIndexFileSource.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.druid.DataInputSource;\n+import com.facebook.presto.druid.zip.CentralDirectoryFileHeader;\n+import com.facebook.presto.druid.zip.EndOfCentralDirectoryRecord;\n+import com.facebook.presto.druid.zip.LocalFileHeader;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectory;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectoryLocator;\n+import com.facebook.presto.druid.zip.ZipFileData;\n+import com.facebook.presto.druid.zip.ZipFileEntry;\n+import com.facebook.presto.druid.zip.ZipUtil;\n+import com.facebook.presto.spi.PrestoException;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Collection;\n+import java.util.zip.Inflater;\n+import java.util.zip.InflaterInputStream;\n+import java.util.zip.ZipException;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.lang.String.format;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ZipIndexFileSource\n+        implements IndexFileSource, Closeable, AutoCloseable\n+{\n+    private final DataInputSource dataInputSource;\n+    private final ZipFileData zipData;\n+\n+    public ZipIndexFileSource(DataInputSource dataInputSource)\n+    {\n+        this.dataInputSource = requireNonNull(dataInputSource, \"dataInputSource is null\");\n+        this.zipData = readCentralDirectory();\n+    }\n+\n+    /**\n+     * Reads file inside a zip archive\n+     */\n+    @Override\n+    public byte[] readFile(String fileName)\n+            throws IOException\n+    {\n+        ZipFileEntry entry = zipData.getEntry(fileName);\n+        if (entry == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip doesn't contain file: %s\", fileName));\n+        }\n+        byte[] fileData = new byte[(int) entry.getSize()];\n+        readFully(entry, 0, fileData, 0, fileData.length);\n+        return fileData;\n+    }\n+\n+    @Override\n+    public final void readFile(String fileName, long position, byte[] buffer)\n+            throws IOException\n+    {\n+        ZipFileEntry entry = zipData.getEntry(fileName);\n+        if (entry == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip doesn't contain file: %s\", fileName));\n+        }\n+        readFully(entry, position, buffer, 0, buffer.length);\n+    }\n+\n+    private void readFully(ZipFileEntry entry, long position, byte[] buffer, int bufferOffset, int bufferLength)\n+            throws IOException\n+    {\n+        long offset = entry.getLocalHeaderOffset();\n+        byte[] fileHeader = new byte[LocalFileHeader.FIXED_DATA_SIZE];\n+        dataInputSource.readFully(offset, fileHeader);\n+        offset += fileHeader.length;\n+\n+        if (!ZipUtil.arrayStartsWith(fileHeader, ZipUtil.intToLittleEndian(LocalFileHeader.SIGNATURE))) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR,\n+                    format(\"The file '%s' is not a correctly formatted zip file: Expected a File Header at file offset %d, but was not present.\", entry.getName()));", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMDA4NQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375600085", "bodyText": "move  DRUID_SEGMENT_LOAD_ERROR to its own line", "author": "highker", "createdAt": "2020-02-06T01:32:04Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/ZipIndexFileSource.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.druid.DataInputSource;\n+import com.facebook.presto.druid.zip.CentralDirectoryFileHeader;\n+import com.facebook.presto.druid.zip.EndOfCentralDirectoryRecord;\n+import com.facebook.presto.druid.zip.LocalFileHeader;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectory;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectoryLocator;\n+import com.facebook.presto.druid.zip.ZipFileData;\n+import com.facebook.presto.druid.zip.ZipFileEntry;\n+import com.facebook.presto.druid.zip.ZipUtil;\n+import com.facebook.presto.spi.PrestoException;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Collection;\n+import java.util.zip.Inflater;\n+import java.util.zip.InflaterInputStream;\n+import java.util.zip.ZipException;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.lang.String.format;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ZipIndexFileSource\n+        implements IndexFileSource, Closeable, AutoCloseable\n+{\n+    private final DataInputSource dataInputSource;\n+    private final ZipFileData zipData;\n+\n+    public ZipIndexFileSource(DataInputSource dataInputSource)\n+    {\n+        this.dataInputSource = requireNonNull(dataInputSource, \"dataInputSource is null\");\n+        this.zipData = readCentralDirectory();\n+    }\n+\n+    /**\n+     * Reads file inside a zip archive\n+     */\n+    @Override\n+    public byte[] readFile(String fileName)\n+            throws IOException\n+    {\n+        ZipFileEntry entry = zipData.getEntry(fileName);\n+        if (entry == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip doesn't contain file: %s\", fileName));\n+        }\n+        byte[] fileData = new byte[(int) entry.getSize()];\n+        readFully(entry, 0, fileData, 0, fileData.length);\n+        return fileData;\n+    }\n+\n+    @Override\n+    public final void readFile(String fileName, long position, byte[] buffer)\n+            throws IOException\n+    {\n+        ZipFileEntry entry = zipData.getEntry(fileName);\n+        if (entry == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip doesn't contain file: %s\", fileName));\n+        }\n+        readFully(entry, position, buffer, 0, buffer.length);\n+    }\n+\n+    private void readFully(ZipFileEntry entry, long position, byte[] buffer, int bufferOffset, int bufferLength)\n+            throws IOException\n+    {\n+        long offset = entry.getLocalHeaderOffset();\n+        byte[] fileHeader = new byte[LocalFileHeader.FIXED_DATA_SIZE];\n+        dataInputSource.readFully(offset, fileHeader);\n+        offset += fileHeader.length;\n+\n+        if (!ZipUtil.arrayStartsWith(fileHeader, ZipUtil.intToLittleEndian(LocalFileHeader.SIGNATURE))) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR,", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMDIxOA==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375600218", "bodyText": "not used", "author": "highker", "createdAt": "2020-02-06T01:32:35Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/ZipIndexFileSource.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.druid.DataInputSource;\n+import com.facebook.presto.druid.zip.CentralDirectoryFileHeader;\n+import com.facebook.presto.druid.zip.EndOfCentralDirectoryRecord;\n+import com.facebook.presto.druid.zip.LocalFileHeader;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectory;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectoryLocator;\n+import com.facebook.presto.druid.zip.ZipFileData;\n+import com.facebook.presto.druid.zip.ZipFileEntry;\n+import com.facebook.presto.druid.zip.ZipUtil;\n+import com.facebook.presto.spi.PrestoException;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Collection;\n+import java.util.zip.Inflater;\n+import java.util.zip.InflaterInputStream;\n+import java.util.zip.ZipException;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.lang.String.format;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ZipIndexFileSource\n+        implements IndexFileSource, Closeable, AutoCloseable\n+{\n+    private final DataInputSource dataInputSource;\n+    private final ZipFileData zipData;\n+\n+    public ZipIndexFileSource(DataInputSource dataInputSource)\n+    {\n+        this.dataInputSource = requireNonNull(dataInputSource, \"dataInputSource is null\");\n+        this.zipData = readCentralDirectory();\n+    }\n+\n+    /**\n+     * Reads file inside a zip archive\n+     */\n+    @Override\n+    public byte[] readFile(String fileName)\n+            throws IOException\n+    {\n+        ZipFileEntry entry = zipData.getEntry(fileName);\n+        if (entry == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip doesn't contain file: %s\", fileName));\n+        }\n+        byte[] fileData = new byte[(int) entry.getSize()];\n+        readFully(entry, 0, fileData, 0, fileData.length);\n+        return fileData;\n+    }\n+\n+    @Override\n+    public final void readFile(String fileName, long position, byte[] buffer)\n+            throws IOException\n+    {\n+        ZipFileEntry entry = zipData.getEntry(fileName);\n+        if (entry == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip doesn't contain file: %s\", fileName));\n+        }\n+        readFully(entry, position, buffer, 0, buffer.length);\n+    }\n+\n+    private void readFully(ZipFileEntry entry, long position, byte[] buffer, int bufferOffset, int bufferLength)\n+            throws IOException\n+    {\n+        long offset = entry.getLocalHeaderOffset();\n+        byte[] fileHeader = new byte[LocalFileHeader.FIXED_DATA_SIZE];\n+        dataInputSource.readFully(offset, fileHeader);\n+        offset += fileHeader.length;\n+\n+        if (!ZipUtil.arrayStartsWith(fileHeader, ZipUtil.intToLittleEndian(LocalFileHeader.SIGNATURE))) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR,\n+                    format(\"The file '%s' is not a correctly formatted zip file: Expected a File Header at file offset %d, but was not present.\", entry.getName()));\n+        }\n+\n+        // skip name and extra field\n+        int nameLength = ZipUtil.getUnsignedShort(fileHeader, LocalFileHeader.FILENAME_LENGTH_OFFSET);\n+        int extraFieldLength = ZipUtil.getUnsignedShort(fileHeader, LocalFileHeader.EXTRA_FIELD_LENGTH_OFFSET);\n+        offset += (nameLength + extraFieldLength);\n+\n+        // deflate\n+        int compressedSize = (int) entry.getCompressedSize();\n+        byte[] compressedData = new byte[compressedSize];\n+        dataInputSource.readFully(offset, compressedData);\n+        InflaterInputStream inflaterInputStream = new InflaterInputStream(new ByteArrayInputStream(compressedData), new Inflater(true));\n+\n+        try {\n+            inflaterInputStream.skip(position);\n+            int size = chunkedRead(inflaterInputStream, buffer, bufferOffset, bufferLength);\n+            checkState(size == bufferLength);\n+        }\n+        catch (IOException e) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Malformed zip file: %s\", entry.getName()));\n+        }\n+    }\n+\n+    // read inflater stream chunk by chunk\n+    private static int chunkedRead(InflaterInputStream inflaterInputStream, byte[] buffer, int offset, int length)\n+            throws IOException\n+    {\n+        int position = offset;\n+        int bytesRead = 0;\n+\n+        while (((position - offset) < length) && bytesRead != -1) {\n+            bytesRead = inflaterInputStream.read(buffer, position, offset + length - position);\n+            if (bytesRead > 0) {\n+                position += bytesRead;\n+            }\n+        }\n+\n+        return position - offset;\n+    }\n+\n+    public final ZipFileEntry getFileEntry(String fileName)", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMDIzOQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375600239", "bodyText": "not used", "author": "highker", "createdAt": "2020-02-06T01:32:40Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/ZipIndexFileSource.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.druid.DataInputSource;\n+import com.facebook.presto.druid.zip.CentralDirectoryFileHeader;\n+import com.facebook.presto.druid.zip.EndOfCentralDirectoryRecord;\n+import com.facebook.presto.druid.zip.LocalFileHeader;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectory;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectoryLocator;\n+import com.facebook.presto.druid.zip.ZipFileData;\n+import com.facebook.presto.druid.zip.ZipFileEntry;\n+import com.facebook.presto.druid.zip.ZipUtil;\n+import com.facebook.presto.spi.PrestoException;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Collection;\n+import java.util.zip.Inflater;\n+import java.util.zip.InflaterInputStream;\n+import java.util.zip.ZipException;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.lang.String.format;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ZipIndexFileSource\n+        implements IndexFileSource, Closeable, AutoCloseable\n+{\n+    private final DataInputSource dataInputSource;\n+    private final ZipFileData zipData;\n+\n+    public ZipIndexFileSource(DataInputSource dataInputSource)\n+    {\n+        this.dataInputSource = requireNonNull(dataInputSource, \"dataInputSource is null\");\n+        this.zipData = readCentralDirectory();\n+    }\n+\n+    /**\n+     * Reads file inside a zip archive\n+     */\n+    @Override\n+    public byte[] readFile(String fileName)\n+            throws IOException\n+    {\n+        ZipFileEntry entry = zipData.getEntry(fileName);\n+        if (entry == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip doesn't contain file: %s\", fileName));\n+        }\n+        byte[] fileData = new byte[(int) entry.getSize()];\n+        readFully(entry, 0, fileData, 0, fileData.length);\n+        return fileData;\n+    }\n+\n+    @Override\n+    public final void readFile(String fileName, long position, byte[] buffer)\n+            throws IOException\n+    {\n+        ZipFileEntry entry = zipData.getEntry(fileName);\n+        if (entry == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip doesn't contain file: %s\", fileName));\n+        }\n+        readFully(entry, position, buffer, 0, buffer.length);\n+    }\n+\n+    private void readFully(ZipFileEntry entry, long position, byte[] buffer, int bufferOffset, int bufferLength)\n+            throws IOException\n+    {\n+        long offset = entry.getLocalHeaderOffset();\n+        byte[] fileHeader = new byte[LocalFileHeader.FIXED_DATA_SIZE];\n+        dataInputSource.readFully(offset, fileHeader);\n+        offset += fileHeader.length;\n+\n+        if (!ZipUtil.arrayStartsWith(fileHeader, ZipUtil.intToLittleEndian(LocalFileHeader.SIGNATURE))) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR,\n+                    format(\"The file '%s' is not a correctly formatted zip file: Expected a File Header at file offset %d, but was not present.\", entry.getName()));\n+        }\n+\n+        // skip name and extra field\n+        int nameLength = ZipUtil.getUnsignedShort(fileHeader, LocalFileHeader.FILENAME_LENGTH_OFFSET);\n+        int extraFieldLength = ZipUtil.getUnsignedShort(fileHeader, LocalFileHeader.EXTRA_FIELD_LENGTH_OFFSET);\n+        offset += (nameLength + extraFieldLength);\n+\n+        // deflate\n+        int compressedSize = (int) entry.getCompressedSize();\n+        byte[] compressedData = new byte[compressedSize];\n+        dataInputSource.readFully(offset, compressedData);\n+        InflaterInputStream inflaterInputStream = new InflaterInputStream(new ByteArrayInputStream(compressedData), new Inflater(true));\n+\n+        try {\n+            inflaterInputStream.skip(position);\n+            int size = chunkedRead(inflaterInputStream, buffer, bufferOffset, bufferLength);\n+            checkState(size == bufferLength);\n+        }\n+        catch (IOException e) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Malformed zip file: %s\", entry.getName()));\n+        }\n+    }\n+\n+    // read inflater stream chunk by chunk\n+    private static int chunkedRead(InflaterInputStream inflaterInputStream, byte[] buffer, int offset, int length)\n+            throws IOException\n+    {\n+        int position = offset;\n+        int bytesRead = 0;\n+\n+        while (((position - offset) < length) && bytesRead != -1) {\n+            bytesRead = inflaterInputStream.read(buffer, position, offset + length - position);\n+            if (bytesRead > 0) {\n+                position += bytesRead;\n+            }\n+        }\n+\n+        return position - offset;\n+    }\n+\n+    public final ZipFileEntry getFileEntry(String fileName)\n+    {\n+        return zipData.getEntry(fileName);\n+    }\n+\n+    public Collection<ZipFileEntry> getFileEntry()", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMDM0Ng==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375600346", "bodyText": "spell out eocd", "author": "highker", "createdAt": "2020-02-06T01:33:07Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/ZipIndexFileSource.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.druid.DataInputSource;\n+import com.facebook.presto.druid.zip.CentralDirectoryFileHeader;\n+import com.facebook.presto.druid.zip.EndOfCentralDirectoryRecord;\n+import com.facebook.presto.druid.zip.LocalFileHeader;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectory;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectoryLocator;\n+import com.facebook.presto.druid.zip.ZipFileData;\n+import com.facebook.presto.druid.zip.ZipFileEntry;\n+import com.facebook.presto.druid.zip.ZipUtil;\n+import com.facebook.presto.spi.PrestoException;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Collection;\n+import java.util.zip.Inflater;\n+import java.util.zip.InflaterInputStream;\n+import java.util.zip.ZipException;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.lang.String.format;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ZipIndexFileSource\n+        implements IndexFileSource, Closeable, AutoCloseable\n+{\n+    private final DataInputSource dataInputSource;\n+    private final ZipFileData zipData;\n+\n+    public ZipIndexFileSource(DataInputSource dataInputSource)\n+    {\n+        this.dataInputSource = requireNonNull(dataInputSource, \"dataInputSource is null\");\n+        this.zipData = readCentralDirectory();\n+    }\n+\n+    /**\n+     * Reads file inside a zip archive\n+     */\n+    @Override\n+    public byte[] readFile(String fileName)\n+            throws IOException\n+    {\n+        ZipFileEntry entry = zipData.getEntry(fileName);\n+        if (entry == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip doesn't contain file: %s\", fileName));\n+        }\n+        byte[] fileData = new byte[(int) entry.getSize()];\n+        readFully(entry, 0, fileData, 0, fileData.length);\n+        return fileData;\n+    }\n+\n+    @Override\n+    public final void readFile(String fileName, long position, byte[] buffer)\n+            throws IOException\n+    {\n+        ZipFileEntry entry = zipData.getEntry(fileName);\n+        if (entry == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip doesn't contain file: %s\", fileName));\n+        }\n+        readFully(entry, position, buffer, 0, buffer.length);\n+    }\n+\n+    private void readFully(ZipFileEntry entry, long position, byte[] buffer, int bufferOffset, int bufferLength)\n+            throws IOException\n+    {\n+        long offset = entry.getLocalHeaderOffset();\n+        byte[] fileHeader = new byte[LocalFileHeader.FIXED_DATA_SIZE];\n+        dataInputSource.readFully(offset, fileHeader);\n+        offset += fileHeader.length;\n+\n+        if (!ZipUtil.arrayStartsWith(fileHeader, ZipUtil.intToLittleEndian(LocalFileHeader.SIGNATURE))) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR,\n+                    format(\"The file '%s' is not a correctly formatted zip file: Expected a File Header at file offset %d, but was not present.\", entry.getName()));\n+        }\n+\n+        // skip name and extra field\n+        int nameLength = ZipUtil.getUnsignedShort(fileHeader, LocalFileHeader.FILENAME_LENGTH_OFFSET);\n+        int extraFieldLength = ZipUtil.getUnsignedShort(fileHeader, LocalFileHeader.EXTRA_FIELD_LENGTH_OFFSET);\n+        offset += (nameLength + extraFieldLength);\n+\n+        // deflate\n+        int compressedSize = (int) entry.getCompressedSize();\n+        byte[] compressedData = new byte[compressedSize];\n+        dataInputSource.readFully(offset, compressedData);\n+        InflaterInputStream inflaterInputStream = new InflaterInputStream(new ByteArrayInputStream(compressedData), new Inflater(true));\n+\n+        try {\n+            inflaterInputStream.skip(position);\n+            int size = chunkedRead(inflaterInputStream, buffer, bufferOffset, bufferLength);\n+            checkState(size == bufferLength);\n+        }\n+        catch (IOException e) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Malformed zip file: %s\", entry.getName()));\n+        }\n+    }\n+\n+    // read inflater stream chunk by chunk\n+    private static int chunkedRead(InflaterInputStream inflaterInputStream, byte[] buffer, int offset, int length)\n+            throws IOException\n+    {\n+        int position = offset;\n+        int bytesRead = 0;\n+\n+        while (((position - offset) < length) && bytesRead != -1) {\n+            bytesRead = inflaterInputStream.read(buffer, position, offset + length - position);\n+            if (bytesRead > 0) {\n+                position += bytesRead;\n+            }\n+        }\n+\n+        return position - offset;\n+    }\n+\n+    public final ZipFileEntry getFileEntry(String fileName)\n+    {\n+        return zipData.getEntry(fileName);\n+    }\n+\n+    public Collection<ZipFileEntry> getFileEntry()\n+    {\n+        return zipData.getEntries();\n+    }\n+\n+    /**\n+     * Finds, reads and parses ZIP file entries from the central directory.\n+     */\n+    private ZipFileData readCentralDirectory()\n+    {\n+        try {\n+            long eocdLocation = findEndOfCentralDirectoryRecord();", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMDcyMQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375600721", "bodyText": "nit\n                    int commentLength = ZipUtil.getUnsignedShort(\n                            buffer,\n                            signatureLocation + EndOfCentralDirectoryRecord.COMMENT_LENGTH_OFFSET);", "author": "highker", "createdAt": "2020-02-06T01:34:37Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/zip/ZipFileData.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+// Copyright 2015 The Bazel Authors. All rights reserved.\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+package com.facebook.presto.druid.zip;\n+\n+import com.facebook.presto.druid.DataInputSource;\n+import com.facebook.presto.spi.PrestoException;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Collection;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.zip.ZipException;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static java.lang.String.format;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+\n+/**\n+ * A representation of a ZIP file. Contains the file comment, encoding, and entries. Also contains\n+ * internal information about the structure and location of ZIP file parts.\n+ */\n+public class ZipFileData\n+{\n+    private final Charset charset;\n+    private String comment;\n+\n+    private long centralDirectorySize;\n+    private long centralDirectoryOffset;\n+    private long expectedEntries;\n+    private long numEntries;\n+    private final Map<String, ZipFileEntry> entries;\n+\n+    private boolean maybeZip64;\n+    private boolean isZip64;\n+    private long zip64EndOfCentralDirectoryOffset;\n+\n+    public ZipFileData(Charset charset)\n+    {\n+        if (charset == null) {\n+            throw new NullPointerException();\n+        }\n+        this.charset = charset;\n+        comment = \"\";\n+        entries = new LinkedHashMap<>();\n+    }\n+\n+    public Charset getCharset()\n+    {\n+        return charset;\n+    }\n+\n+    public String getComment()\n+    {\n+        return comment;\n+    }\n+\n+    public void setComment(byte[] comment)\n+    {\n+        if (comment == null) {\n+            throw new NullPointerException();\n+        }\n+        if (comment.length > 0xffff) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"File comment too long. Is %d; max %d.\", comment.length, 0xffff));\n+        }\n+        this.comment = fromBytes(comment);\n+    }\n+\n+    public void setComment(String comment)\n+    {\n+        setComment(getBytes(comment));\n+    }\n+\n+    public long getCentralDirectorySize()\n+    {\n+        return centralDirectorySize;\n+    }\n+\n+    public void setCentralDirectorySize(long centralDirectorySize)\n+    {\n+        this.centralDirectorySize = centralDirectorySize;\n+        if (centralDirectorySize > 0xffffffffL) {\n+            setZip64(true);\n+        }\n+    }\n+\n+    public long getCentralDirectoryOffset()\n+    {\n+        return centralDirectoryOffset;\n+    }\n+\n+    public void setCentralDirectoryOffset(long offset)\n+    {\n+        this.centralDirectoryOffset = offset;\n+        if (centralDirectoryOffset > 0xffffffffL) {\n+            setZip64(true);\n+        }\n+    }\n+\n+    public long getExpectedEntries()\n+    {\n+        return expectedEntries;\n+    }\n+\n+    public void setExpectedEntries(long count)\n+    {\n+        this.expectedEntries = count;\n+        if (expectedEntries > 0xffff) {\n+            setZip64(true);\n+        }\n+    }\n+\n+    public long getNumEntries()\n+    {\n+        return numEntries;\n+    }\n+\n+    private void setNumEntries(long numEntries)\n+    {\n+        this.numEntries = numEntries;\n+        if (numEntries > 0xffff) {\n+            setZip64(true);\n+        }\n+    }\n+\n+    public Collection<ZipFileEntry> getEntries()\n+    {\n+        return entries.values();\n+    }\n+\n+    public ZipFileEntry getEntry(@Nullable String name)\n+    {\n+        return entries.get(name);\n+    }\n+\n+    public void addEntry(ZipFileEntry entry)\n+    {\n+        entries.put(entry.getName(), entry);\n+        setNumEntries(numEntries + 1);\n+        if (entry.getFeatureSet().contains(ZipFileEntry.Feature.ZIP64_SIZE)\n+                || entry.getFeatureSet().contains(ZipFileEntry.Feature.ZIP64_CSIZE)\n+                || entry.getFeatureSet().contains(ZipFileEntry.Feature.ZIP64_OFFSET)) {\n+            setZip64(true);\n+        }\n+    }\n+\n+    public boolean isMaybeZip64()\n+    {\n+        return maybeZip64;\n+    }\n+\n+    public void setMaybeZip64(boolean maybeZip64)\n+    {\n+        this.maybeZip64 = maybeZip64;\n+    }\n+\n+    public boolean isZip64()\n+    {\n+        return isZip64;\n+    }\n+\n+    public void setZip64(boolean isZip64)\n+    {\n+        this.isZip64 = isZip64;\n+        setMaybeZip64(true);\n+    }\n+\n+    public long getZip64EndOfCentralDirectoryOffset()\n+    {\n+        return zip64EndOfCentralDirectoryOffset;\n+    }\n+\n+    public void setZip64EndOfCentralDirectoryOffset(long offset)\n+    {\n+        this.zip64EndOfCentralDirectoryOffset = offset;\n+        setZip64(true);\n+    }\n+\n+    public byte[] getBytes(String string)\n+    {\n+        return string.getBytes(charset);\n+    }\n+\n+    public String fromBytes(byte[] bytes)\n+    {\n+        return new String(bytes, charset);\n+    }\n+\n+    /**\n+     * Finds, reads and parses ZIP file entries from the central directory.\n+     */\n+    public ZipFileData createZipFileData(DataInputSource dataInputSource)\n+            throws IOException\n+    {\n+        long eocdLocation = findEndOfCentralDirectoryRecord(dataInputSource);\n+        ZipFileData fileData = new ZipFileData(UTF_8);\n+        EndOfCentralDirectoryRecord.read(fileData, dataInputSource, eocdLocation);\n+\n+        if (fileData.isMaybeZip64()) {\n+            try {\n+                Zip64EndOfCentralDirectoryLocator.read(fileData, dataInputSource, eocdLocation - Zip64EndOfCentralDirectoryLocator.FIXED_DATA_SIZE);\n+                Zip64EndOfCentralDirectory.read(fileData, dataInputSource, fileData.getZip64EndOfCentralDirectoryOffset());\n+            }\n+            catch (ZipException e) {\n+                // expected if not in Zip64 format\n+            }\n+        }\n+\n+        if (fileData.isZip64()) {\n+            // If in Zip64 format or using strict entry numbers, use the parsed information as is to read\n+            // the central directory file headers.\n+            readCentralDirectoryFileHeaders(fileData, dataInputSource, fileData.getCentralDirectoryOffset(), fileData.getCharset(), fileData.getExpectedEntries());\n+        }\n+        else {\n+            // If not in Zip64 format, compute central directory offset by end of central directory record\n+            // offset and central directory size to allow reading large non-compliant Zip32 directories.\n+            long centralDirectoryOffset = eocdLocation - fileData.getCentralDirectorySize();\n+            // If the lower 4 bytes match, the above calculation is correct; otherwise fallback to\n+            // reported offset.\n+            if ((int) centralDirectoryOffset == (int) fileData.getCentralDirectoryOffset()) {\n+                readCentralDirectoryFileHeaders(fileData, dataInputSource, centralDirectoryOffset, fileData.getCharset());\n+            }\n+            else {\n+                readCentralDirectoryFileHeaders(fileData, dataInputSource, fileData.getCentralDirectoryOffset(), fileData.getCharset(), fileData.getExpectedEntries());\n+            }\n+        }\n+        return fileData;\n+    }\n+\n+    /**\n+     * Finds the file offset of the end of central directory record.\n+     */\n+    private long findEndOfCentralDirectoryRecord(DataInputSource dataInputSource)\n+            throws IOException\n+    {\n+        long fileSize = dataInputSource.getSize();\n+        byte[] signature = ZipUtil.intToLittleEndian(EndOfCentralDirectoryRecord.SIGNATURE);\n+        byte[] buffer = new byte[(int) Math.min(64, fileSize)];\n+        int readLength = buffer.length;\n+        if (readLength < EndOfCentralDirectoryRecord.FIXED_DATA_SIZE) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip file '%s' is malformed. It does not contain an end of central directory record.\", dataInputSource.getId()));\n+        }\n+\n+        long offset = fileSize - buffer.length;\n+        while (offset >= 0) {\n+            dataInputSource.readFully(offset, buffer, 0, readLength);\n+            int signatureLocation = scanBackwards(signature, buffer, buffer.length);\n+            while (signatureLocation != -1) {\n+                long eocdSize = fileSize - offset - signatureLocation;\n+                if (eocdSize >= EndOfCentralDirectoryRecord.FIXED_DATA_SIZE) {\n+                    int commentLength = ZipUtil.getUnsignedShort(buffer, signatureLocation", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMDc4MA==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375600780", "bodyText": "i++", "author": "highker", "createdAt": "2020-02-06T01:34:53Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/zip/ZipFileData.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+// Copyright 2015 The Bazel Authors. All rights reserved.\n+//\n+// Licensed under the Apache License, Version 2.0 (the \"License\");\n+// you may not use this file except in compliance with the License.\n+// You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+package com.facebook.presto.druid.zip;\n+\n+import com.facebook.presto.druid.DataInputSource;\n+import com.facebook.presto.spi.PrestoException;\n+\n+import javax.annotation.Nullable;\n+\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Collection;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.zip.ZipException;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static java.lang.String.format;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+\n+/**\n+ * A representation of a ZIP file. Contains the file comment, encoding, and entries. Also contains\n+ * internal information about the structure and location of ZIP file parts.\n+ */\n+public class ZipFileData\n+{\n+    private final Charset charset;\n+    private String comment;\n+\n+    private long centralDirectorySize;\n+    private long centralDirectoryOffset;\n+    private long expectedEntries;\n+    private long numEntries;\n+    private final Map<String, ZipFileEntry> entries;\n+\n+    private boolean maybeZip64;\n+    private boolean isZip64;\n+    private long zip64EndOfCentralDirectoryOffset;\n+\n+    public ZipFileData(Charset charset)\n+    {\n+        if (charset == null) {\n+            throw new NullPointerException();\n+        }\n+        this.charset = charset;\n+        comment = \"\";\n+        entries = new LinkedHashMap<>();\n+    }\n+\n+    public Charset getCharset()\n+    {\n+        return charset;\n+    }\n+\n+    public String getComment()\n+    {\n+        return comment;\n+    }\n+\n+    public void setComment(byte[] comment)\n+    {\n+        if (comment == null) {\n+            throw new NullPointerException();\n+        }\n+        if (comment.length > 0xffff) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"File comment too long. Is %d; max %d.\", comment.length, 0xffff));\n+        }\n+        this.comment = fromBytes(comment);\n+    }\n+\n+    public void setComment(String comment)\n+    {\n+        setComment(getBytes(comment));\n+    }\n+\n+    public long getCentralDirectorySize()\n+    {\n+        return centralDirectorySize;\n+    }\n+\n+    public void setCentralDirectorySize(long centralDirectorySize)\n+    {\n+        this.centralDirectorySize = centralDirectorySize;\n+        if (centralDirectorySize > 0xffffffffL) {\n+            setZip64(true);\n+        }\n+    }\n+\n+    public long getCentralDirectoryOffset()\n+    {\n+        return centralDirectoryOffset;\n+    }\n+\n+    public void setCentralDirectoryOffset(long offset)\n+    {\n+        this.centralDirectoryOffset = offset;\n+        if (centralDirectoryOffset > 0xffffffffL) {\n+            setZip64(true);\n+        }\n+    }\n+\n+    public long getExpectedEntries()\n+    {\n+        return expectedEntries;\n+    }\n+\n+    public void setExpectedEntries(long count)\n+    {\n+        this.expectedEntries = count;\n+        if (expectedEntries > 0xffff) {\n+            setZip64(true);\n+        }\n+    }\n+\n+    public long getNumEntries()\n+    {\n+        return numEntries;\n+    }\n+\n+    private void setNumEntries(long numEntries)\n+    {\n+        this.numEntries = numEntries;\n+        if (numEntries > 0xffff) {\n+            setZip64(true);\n+        }\n+    }\n+\n+    public Collection<ZipFileEntry> getEntries()\n+    {\n+        return entries.values();\n+    }\n+\n+    public ZipFileEntry getEntry(@Nullable String name)\n+    {\n+        return entries.get(name);\n+    }\n+\n+    public void addEntry(ZipFileEntry entry)\n+    {\n+        entries.put(entry.getName(), entry);\n+        setNumEntries(numEntries + 1);\n+        if (entry.getFeatureSet().contains(ZipFileEntry.Feature.ZIP64_SIZE)\n+                || entry.getFeatureSet().contains(ZipFileEntry.Feature.ZIP64_CSIZE)\n+                || entry.getFeatureSet().contains(ZipFileEntry.Feature.ZIP64_OFFSET)) {\n+            setZip64(true);\n+        }\n+    }\n+\n+    public boolean isMaybeZip64()\n+    {\n+        return maybeZip64;\n+    }\n+\n+    public void setMaybeZip64(boolean maybeZip64)\n+    {\n+        this.maybeZip64 = maybeZip64;\n+    }\n+\n+    public boolean isZip64()\n+    {\n+        return isZip64;\n+    }\n+\n+    public void setZip64(boolean isZip64)\n+    {\n+        this.isZip64 = isZip64;\n+        setMaybeZip64(true);\n+    }\n+\n+    public long getZip64EndOfCentralDirectoryOffset()\n+    {\n+        return zip64EndOfCentralDirectoryOffset;\n+    }\n+\n+    public void setZip64EndOfCentralDirectoryOffset(long offset)\n+    {\n+        this.zip64EndOfCentralDirectoryOffset = offset;\n+        setZip64(true);\n+    }\n+\n+    public byte[] getBytes(String string)\n+    {\n+        return string.getBytes(charset);\n+    }\n+\n+    public String fromBytes(byte[] bytes)\n+    {\n+        return new String(bytes, charset);\n+    }\n+\n+    /**\n+     * Finds, reads and parses ZIP file entries from the central directory.\n+     */\n+    public ZipFileData createZipFileData(DataInputSource dataInputSource)\n+            throws IOException\n+    {\n+        long eocdLocation = findEndOfCentralDirectoryRecord(dataInputSource);\n+        ZipFileData fileData = new ZipFileData(UTF_8);\n+        EndOfCentralDirectoryRecord.read(fileData, dataInputSource, eocdLocation);\n+\n+        if (fileData.isMaybeZip64()) {\n+            try {\n+                Zip64EndOfCentralDirectoryLocator.read(fileData, dataInputSource, eocdLocation - Zip64EndOfCentralDirectoryLocator.FIXED_DATA_SIZE);\n+                Zip64EndOfCentralDirectory.read(fileData, dataInputSource, fileData.getZip64EndOfCentralDirectoryOffset());\n+            }\n+            catch (ZipException e) {\n+                // expected if not in Zip64 format\n+            }\n+        }\n+\n+        if (fileData.isZip64()) {\n+            // If in Zip64 format or using strict entry numbers, use the parsed information as is to read\n+            // the central directory file headers.\n+            readCentralDirectoryFileHeaders(fileData, dataInputSource, fileData.getCentralDirectoryOffset(), fileData.getCharset(), fileData.getExpectedEntries());\n+        }\n+        else {\n+            // If not in Zip64 format, compute central directory offset by end of central directory record\n+            // offset and central directory size to allow reading large non-compliant Zip32 directories.\n+            long centralDirectoryOffset = eocdLocation - fileData.getCentralDirectorySize();\n+            // If the lower 4 bytes match, the above calculation is correct; otherwise fallback to\n+            // reported offset.\n+            if ((int) centralDirectoryOffset == (int) fileData.getCentralDirectoryOffset()) {\n+                readCentralDirectoryFileHeaders(fileData, dataInputSource, centralDirectoryOffset, fileData.getCharset());\n+            }\n+            else {\n+                readCentralDirectoryFileHeaders(fileData, dataInputSource, fileData.getCentralDirectoryOffset(), fileData.getCharset(), fileData.getExpectedEntries());\n+            }\n+        }\n+        return fileData;\n+    }\n+\n+    /**\n+     * Finds the file offset of the end of central directory record.\n+     */\n+    private long findEndOfCentralDirectoryRecord(DataInputSource dataInputSource)\n+            throws IOException\n+    {\n+        long fileSize = dataInputSource.getSize();\n+        byte[] signature = ZipUtil.intToLittleEndian(EndOfCentralDirectoryRecord.SIGNATURE);\n+        byte[] buffer = new byte[(int) Math.min(64, fileSize)];\n+        int readLength = buffer.length;\n+        if (readLength < EndOfCentralDirectoryRecord.FIXED_DATA_SIZE) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip file '%s' is malformed. It does not contain an end of central directory record.\", dataInputSource.getId()));\n+        }\n+\n+        long offset = fileSize - buffer.length;\n+        while (offset >= 0) {\n+            dataInputSource.readFully(offset, buffer, 0, readLength);\n+            int signatureLocation = scanBackwards(signature, buffer, buffer.length);\n+            while (signatureLocation != -1) {\n+                long eocdSize = fileSize - offset - signatureLocation;\n+                if (eocdSize >= EndOfCentralDirectoryRecord.FIXED_DATA_SIZE) {\n+                    int commentLength = ZipUtil.getUnsignedShort(buffer, signatureLocation\n+                            + EndOfCentralDirectoryRecord.COMMENT_LENGTH_OFFSET);\n+                    long readCommentLength = eocdSize - EndOfCentralDirectoryRecord.FIXED_DATA_SIZE;\n+                    if (commentLength == readCommentLength) {\n+                        return offset + signatureLocation;\n+                    }\n+                }\n+                signatureLocation = scanBackwards(signature, buffer, signatureLocation - 1);\n+            }\n+            readLength = buffer.length - 3;\n+            buffer[buffer.length - 3] = buffer[0];\n+            buffer[buffer.length - 2] = buffer[1];\n+            buffer[buffer.length - 1] = buffer[2];\n+            offset -= readLength;\n+        }\n+        throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip file '%s' is malformed. It does not contain an end of central directory record.\", dataInputSource.getId()));\n+    }\n+\n+    /**\n+     * Reads and parses ZIP file entries from the central directory.\n+     */\n+    private void readCentralDirectoryFileHeaders(ZipFileData fileData, DataInputSource dataInputSource, long fileOffset, Charset charset, long count)\n+            throws IOException\n+    {\n+        try {\n+            long position = fileOffset;\n+            for (long i = 0; i < count; ++i) {", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMDgxMA==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375600810", "bodyText": "same", "author": "highker", "createdAt": "2020-02-06T01:35:01Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/DruidSegmentPageSource.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid;\n+\n+import com.facebook.presto.druid.metadata.DruidSegmentInfo;\n+import com.facebook.presto.druid.segment.DruidSegmentReader;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPageSource;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.LazyBlock;\n+import com.facebook.presto.spi.block.LazyBlockLoader;\n+import com.facebook.presto.spi.type.Type;\n+\n+import java.util.List;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DruidSegmentPageSource\n+        implements ConnectorPageSource\n+{\n+    private final DruidSegmentInfo segmentInfo;\n+    private final List<ColumnHandle> columns;\n+    private final DruidSegmentReader segmentReader;\n+\n+    private int batchId;\n+    private boolean closed;\n+    private long completedBytes;\n+    private long completedPositions;\n+\n+    public DruidSegmentPageSource(\n+            DruidSegmentInfo segmentInfo,\n+            List<ColumnHandle> columns,\n+            DruidSegmentReader segmentReader)\n+    {\n+        this.segmentInfo = requireNonNull(segmentInfo, \"segment info is null\");\n+        this.columns = requireNonNull(columns, \"columns is null\");\n+        this.segmentReader = requireNonNull(segmentReader, \"segmentReader is null\");\n+    }\n+\n+    @Override\n+    public long getCompletedBytes()\n+    {\n+        return completedBytes;\n+    }\n+\n+    @Override\n+    public long getCompletedPositions()\n+    {\n+        return completedPositions;\n+    }\n+\n+    @Override\n+    public long getReadTimeNanos()\n+    {\n+        return 0;\n+    }\n+\n+    @Override\n+    public boolean isFinished()\n+    {\n+        return closed;\n+    }\n+\n+    @Override\n+    public Page getNextPage()\n+    {\n+        batchId++;\n+        int batchSize = segmentReader.nextBatch();\n+        if (batchSize <= 0) {\n+            close();\n+            return null;\n+        }\n+        Block[] blocks = new Block[columns.size()];\n+        for (int i = 0; i < blocks.length; ++i) {", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMDg2Nw==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375600867", "bodyText": "same", "author": "highker", "createdAt": "2020-02-06T01:35:14Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/ZipIndexFileSource.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.druid.DataInputSource;\n+import com.facebook.presto.druid.zip.CentralDirectoryFileHeader;\n+import com.facebook.presto.druid.zip.EndOfCentralDirectoryRecord;\n+import com.facebook.presto.druid.zip.LocalFileHeader;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectory;\n+import com.facebook.presto.druid.zip.Zip64EndOfCentralDirectoryLocator;\n+import com.facebook.presto.druid.zip.ZipFileData;\n+import com.facebook.presto.druid.zip.ZipFileEntry;\n+import com.facebook.presto.druid.zip.ZipUtil;\n+import com.facebook.presto.spi.PrestoException;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.nio.charset.Charset;\n+import java.util.Collection;\n+import java.util.zip.Inflater;\n+import java.util.zip.InflaterInputStream;\n+import java.util.zip.ZipException;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.lang.String.format;\n+import static java.nio.charset.StandardCharsets.UTF_8;\n+import static java.util.Objects.requireNonNull;\n+\n+public class ZipIndexFileSource\n+        implements IndexFileSource, Closeable, AutoCloseable\n+{\n+    private final DataInputSource dataInputSource;\n+    private final ZipFileData zipData;\n+\n+    public ZipIndexFileSource(DataInputSource dataInputSource)\n+    {\n+        this.dataInputSource = requireNonNull(dataInputSource, \"dataInputSource is null\");\n+        this.zipData = readCentralDirectory();\n+    }\n+\n+    /**\n+     * Reads file inside a zip archive\n+     */\n+    @Override\n+    public byte[] readFile(String fileName)\n+            throws IOException\n+    {\n+        ZipFileEntry entry = zipData.getEntry(fileName);\n+        if (entry == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip doesn't contain file: %s\", fileName));\n+        }\n+        byte[] fileData = new byte[(int) entry.getSize()];\n+        readFully(entry, 0, fileData, 0, fileData.length);\n+        return fileData;\n+    }\n+\n+    @Override\n+    public final void readFile(String fileName, long position, byte[] buffer)\n+            throws IOException\n+    {\n+        ZipFileEntry entry = zipData.getEntry(fileName);\n+        if (entry == null) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip doesn't contain file: %s\", fileName));\n+        }\n+        readFully(entry, position, buffer, 0, buffer.length);\n+    }\n+\n+    private void readFully(ZipFileEntry entry, long position, byte[] buffer, int bufferOffset, int bufferLength)\n+            throws IOException\n+    {\n+        long offset = entry.getLocalHeaderOffset();\n+        byte[] fileHeader = new byte[LocalFileHeader.FIXED_DATA_SIZE];\n+        dataInputSource.readFully(offset, fileHeader);\n+        offset += fileHeader.length;\n+\n+        if (!ZipUtil.arrayStartsWith(fileHeader, ZipUtil.intToLittleEndian(LocalFileHeader.SIGNATURE))) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR,\n+                    format(\"The file '%s' is not a correctly formatted zip file: Expected a File Header at file offset %d, but was not present.\", entry.getName()));\n+        }\n+\n+        // skip name and extra field\n+        int nameLength = ZipUtil.getUnsignedShort(fileHeader, LocalFileHeader.FILENAME_LENGTH_OFFSET);\n+        int extraFieldLength = ZipUtil.getUnsignedShort(fileHeader, LocalFileHeader.EXTRA_FIELD_LENGTH_OFFSET);\n+        offset += (nameLength + extraFieldLength);\n+\n+        // deflate\n+        int compressedSize = (int) entry.getCompressedSize();\n+        byte[] compressedData = new byte[compressedSize];\n+        dataInputSource.readFully(offset, compressedData);\n+        InflaterInputStream inflaterInputStream = new InflaterInputStream(new ByteArrayInputStream(compressedData), new Inflater(true));\n+\n+        try {\n+            inflaterInputStream.skip(position);\n+            int size = chunkedRead(inflaterInputStream, buffer, bufferOffset, bufferLength);\n+            checkState(size == bufferLength);\n+        }\n+        catch (IOException e) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Malformed zip file: %s\", entry.getName()));\n+        }\n+    }\n+\n+    // read inflater stream chunk by chunk\n+    private static int chunkedRead(InflaterInputStream inflaterInputStream, byte[] buffer, int offset, int length)\n+            throws IOException\n+    {\n+        int position = offset;\n+        int bytesRead = 0;\n+\n+        while (((position - offset) < length) && bytesRead != -1) {\n+            bytesRead = inflaterInputStream.read(buffer, position, offset + length - position);\n+            if (bytesRead > 0) {\n+                position += bytesRead;\n+            }\n+        }\n+\n+        return position - offset;\n+    }\n+\n+    public final ZipFileEntry getFileEntry(String fileName)\n+    {\n+        return zipData.getEntry(fileName);\n+    }\n+\n+    public Collection<ZipFileEntry> getFileEntry()\n+    {\n+        return zipData.getEntries();\n+    }\n+\n+    /**\n+     * Finds, reads and parses ZIP file entries from the central directory.\n+     */\n+    private ZipFileData readCentralDirectory()\n+    {\n+        try {\n+            long eocdLocation = findEndOfCentralDirectoryRecord();\n+            ZipFileData fileData = new ZipFileData(UTF_8);\n+            EndOfCentralDirectoryRecord.read(fileData, dataInputSource, eocdLocation);\n+\n+            if (fileData.isMaybeZip64()) {\n+                try {\n+                    Zip64EndOfCentralDirectoryLocator.read(fileData, dataInputSource, eocdLocation - Zip64EndOfCentralDirectoryLocator.FIXED_DATA_SIZE);\n+                    Zip64EndOfCentralDirectory.read(fileData, dataInputSource, fileData.getZip64EndOfCentralDirectoryOffset());\n+                }\n+                catch (ZipException e) {\n+                    // expected if not in Zip64 format\n+                }\n+            }\n+\n+            if (fileData.isZip64()) {\n+                // If in Zip64 format or using strict entry numbers, use the parsed information as is to read\n+                // the central directory file headers.\n+                readCentralDirectoryFileHeaders(fileData, dataInputSource, fileData.getCentralDirectoryOffset(), fileData.getCharset(), fileData.getExpectedEntries());\n+            }\n+            else {\n+                // If not in Zip64 format, compute central directory offset by end of central directory record\n+                // offset and central directory size to allow reading large non-compliant Zip32 directories.\n+                long centralDirectoryOffset = eocdLocation - fileData.getCentralDirectorySize();\n+                // If the lower 4 bytes match, the above calculation is correct; otherwise fallback to\n+                // reported offset.\n+                if ((int) centralDirectoryOffset == (int) fileData.getCentralDirectoryOffset()) {\n+                    readCentralDirectoryFileHeaders(fileData, dataInputSource, centralDirectoryOffset, fileData.getCharset());\n+                }\n+                else {\n+                    readCentralDirectoryFileHeaders(fileData, dataInputSource, fileData.getCentralDirectoryOffset(), fileData.getCharset(), fileData.getExpectedEntries());\n+                }\n+            }\n+            return fileData;\n+        }\n+        catch (IOException e) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, e);\n+        }\n+    }\n+\n+    /**\n+     * Finds the file offset of the end of central directory record.\n+     */\n+    private long findEndOfCentralDirectoryRecord()\n+            throws IOException\n+    {\n+        long fileSize = dataInputSource.getSize();\n+        byte[] signature = ZipUtil.intToLittleEndian(EndOfCentralDirectoryRecord.SIGNATURE);\n+        byte[] buffer = new byte[(int) Math.min(64, fileSize)];\n+        int readLength = buffer.length;\n+        if (readLength < EndOfCentralDirectoryRecord.FIXED_DATA_SIZE) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip file '%s' is malformed. It does not contain an end of central directory record.\", dataInputSource.getId()));\n+        }\n+\n+        long offset = fileSize - buffer.length;\n+        while (offset >= 0) {\n+            dataInputSource.readFully(offset, buffer, 0, readLength);\n+            int signatureLocation = scanBackwards(signature, buffer, buffer.length);\n+            while (signatureLocation != -1) {\n+                long eocdSize = fileSize - offset - signatureLocation;\n+                if (eocdSize >= EndOfCentralDirectoryRecord.FIXED_DATA_SIZE) {\n+                    int commentLength = ZipUtil.getUnsignedShort(buffer, signatureLocation\n+                            + EndOfCentralDirectoryRecord.COMMENT_LENGTH_OFFSET);\n+                    long readCommentLength = eocdSize - EndOfCentralDirectoryRecord.FIXED_DATA_SIZE;\n+                    if (commentLength == readCommentLength) {\n+                        return offset + signatureLocation;\n+                    }\n+                }\n+                signatureLocation = scanBackwards(signature, buffer, signatureLocation - 1);\n+            }\n+            readLength = buffer.length - 3;\n+            buffer[buffer.length - 3] = buffer[0];\n+            buffer[buffer.length - 2] = buffer[1];\n+            buffer[buffer.length - 1] = buffer[2];\n+            offset -= readLength;\n+        }\n+        throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Zip file '%s' is malformed. It does not contain an end of central directory record.\", dataInputSource.getId()));\n+    }\n+\n+    /**\n+     * Reads and parses ZIP file entries from the central directory.\n+     */\n+    private void readCentralDirectoryFileHeaders(ZipFileData fileData, DataInputSource dataInputSource, long fileOffset, Charset charset, long count)\n+            throws IOException\n+    {\n+        try {\n+            long position = fileOffset;\n+            for (long i = 0; i < count; ++i) {", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMTA1Mg==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375601052", "bodyText": "not used", "author": "highker", "createdAt": "2020-02-06T01:36:01Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/zip/EndOfCentralDirectoryRecord.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.zip;\n+\n+import com.facebook.presto.druid.DataInputSource;\n+import com.facebook.presto.spi.PrestoException;\n+\n+import java.io.IOException;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static java.lang.String.format;\n+\n+public class EndOfCentralDirectoryRecord\n+{\n+    public static final int SIGNATURE = 0x06054b50;\n+    public static final int FIXED_DATA_SIZE = 22;\n+    public static final int SIGNATURE_OFFSET = 0;", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMTE4OQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375601189", "bodyText": "why we need this static function throwing an error?", "author": "highker", "createdAt": "2020-02-06T01:36:33Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/zip/EndOfCentralDirectoryRecord.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.zip;\n+\n+import com.facebook.presto.druid.DataInputSource;\n+import com.facebook.presto.spi.PrestoException;\n+\n+import java.io.IOException;\n+\n+import static com.facebook.presto.druid.DruidErrorCode.DRUID_SEGMENT_LOAD_ERROR;\n+import static java.lang.String.format;\n+\n+public class EndOfCentralDirectoryRecord\n+{\n+    public static final int SIGNATURE = 0x06054b50;\n+    public static final int FIXED_DATA_SIZE = 22;\n+    public static final int SIGNATURE_OFFSET = 0;\n+    public static final int DISK_NUMBER_OFFSET = 4;\n+    public static final int CD_DISK_OFFSET = 6;\n+    public static final int DISK_ENTRIES_OFFSET = 8;\n+    public static final int TOTAL_ENTRIES_OFFSET = 10;\n+    public static final int CD_SIZE_OFFSET = 12;\n+    public static final int CD_OFFSET_OFFSET = 16;\n+    public static final int COMMENT_LENGTH_OFFSET = 20;\n+\n+    private EndOfCentralDirectoryRecord()\n+    {\n+    }\n+\n+    /**\n+     * Read the end of central directory record from the input stream and parse {@link ZipFileData}\n+     * from it.\n+     */\n+    public static void read(ZipFileData zipFileData, DataInputSource dataInputSource, long offset)\n+            throws IOException\n+    {\n+        long position = offset;\n+        byte[] fixedSizeData = new byte[FIXED_DATA_SIZE];\n+\n+        dataInputSource.readFully(position, fixedSizeData, 0, FIXED_DATA_SIZE);\n+        position += FIXED_DATA_SIZE;\n+        if (!ZipUtil.arrayStartsWith(fixedSizeData, ZipUtil.intToLittleEndian(SIGNATURE))) {\n+            throw new PrestoException(DRUID_SEGMENT_LOAD_ERROR, format(\"Malformed End of Central Directory Record; does not start with %08x\", SIGNATURE));\n+        }\n+\n+        byte[] comment = new byte[ZipUtil.getUnsignedShort(fixedSizeData, COMMENT_LENGTH_OFFSET)];\n+        if (comment.length > 0) {\n+            dataInputSource.readFully(position, comment, 0, comment.length);\n+        }\n+        short diskNumber = ZipUtil.get16(fixedSizeData, DISK_NUMBER_OFFSET);\n+        short centralDirectoryDisk = ZipUtil.get16(fixedSizeData, CD_DISK_OFFSET);\n+        short entriesOnDisk = ZipUtil.get16(fixedSizeData, DISK_ENTRIES_OFFSET);\n+        short totalEntries = ZipUtil.get16(fixedSizeData, TOTAL_ENTRIES_OFFSET);\n+        int centralDirectorySize = ZipUtil.get32(fixedSizeData, CD_SIZE_OFFSET);\n+        int centralDirectoryOffset = ZipUtil.get32(fixedSizeData, CD_OFFSET_OFFSET);\n+        if (diskNumber == -1 || centralDirectoryDisk == -1 || entriesOnDisk == -1\n+                || totalEntries == -1 || centralDirectorySize == -1 || centralDirectoryOffset == -1) {\n+            zipFileData.setMaybeZip64(true);\n+        }\n+        zipFileData.setComment(comment);\n+        zipFileData.setCentralDirectorySize(ZipUtil.getUnsignedInt(fixedSizeData, CD_SIZE_OFFSET));\n+        zipFileData.setCentralDirectoryOffset(ZipUtil.getUnsignedInt(fixedSizeData, CD_OFFSET_OFFSET));\n+        zipFileData.setExpectedEntries(ZipUtil.getUnsignedShort(fixedSizeData, TOTAL_ENTRIES_OFFSET));\n+    }\n+\n+    static byte[] create(ZipFileData file, boolean allowZip64)", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMTM0Mg==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375601342", "bodyText": "not used", "author": "highker", "createdAt": "2020-02-06T01:37:11Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/zip/ExtraData.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.zip;\n+\n+import java.util.Arrays;\n+\n+/**\n+ * A holder class for extra data in a ZIP entry.\n+ */\n+final class ExtraData\n+{\n+    static final int ID_OFFSET = 0;\n+    static final int LENGTH_OFFSET = 2;\n+    static final int FIXED_DATA_SIZE = 4;\n+\n+    private final int index;\n+    private final byte[] buffer;\n+\n+    public ExtraData(short id, byte[] data)", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMTQwMA==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375601400", "bodyText": "most of these are not used", "author": "highker", "createdAt": "2020-02-06T01:37:27Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/zip/ExtraDataList.java", "diffHunk": "@@ -0,0 +1,181 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.zip;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+\n+class ExtraDataList\n+{\n+    public static final short ZIP64 = 0x0001;", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMTQ1OQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375601459", "bodyText": "Can we use Map?", "author": "highker", "createdAt": "2020-02-06T01:37:43Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/zip/ExtraDataList.java", "diffHunk": "@@ -0,0 +1,181 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.zip;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Iterator;\n+import java.util.LinkedHashMap;\n+\n+class ExtraDataList\n+{\n+    public static final short ZIP64 = 0x0001;\n+    public static final short EXTENDED_TIMESTAMP = 0x5455;\n+    // Some documentation says that this is actually 0x7855, but zip files do not seem to corroborate\n+    // this\n+    public static final short INFOZIP_UNIX_NEW = 0x7875;\n+    private final LinkedHashMap<Short, ExtraData> entries;", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMTU3OQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375601579", "bodyText": "most consts are not used; same for many other files", "author": "highker", "createdAt": "2020-02-06T01:38:10Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/zip/LocalFileHeader.java", "diffHunk": "@@ -0,0 +1,35 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.zip;\n+\n+public class LocalFileHeader\n+{\n+    public static final int SIGNATURE = 0x04034b50;\n+    public static final int FIXED_DATA_SIZE = 30;\n+    public static final int SIGNATURE_OFFSET = 0;", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMjAzMg==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375602032", "bodyText": "These should be used by DruidSegmentPageSource", "author": "highker", "createdAt": "2020-02-06T01:40:08Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/DataInputSource.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+\n+public interface DataInputSource\n+        extends Closeable\n+{\n+    DataInputSourceId getId();\n+\n+    long getReadBytes();\n+\n+    long getReadTimeNanos();", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMjEwNA==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375602104", "bodyText": "not used", "author": "highker", "createdAt": "2020-02-06T01:40:29Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/DruidSegmentPageSource.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid;\n+\n+import com.facebook.presto.druid.metadata.DruidSegmentInfo;\n+import com.facebook.presto.druid.segment.DruidSegmentReader;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPageSource;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.LazyBlock;\n+import com.facebook.presto.spi.block.LazyBlockLoader;\n+import com.facebook.presto.spi.type.Type;\n+\n+import java.util.List;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DruidSegmentPageSource\n+        implements ConnectorPageSource\n+{\n+    private final DruidSegmentInfo segmentInfo;", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTYwMjI2NQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r375602265", "bodyText": "Do we wanna return ImmutableList.of(address) or this is intensionally?", "author": "highker", "createdAt": "2020-02-06T01:41:05Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/DruidSplit.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid;\n+\n+import com.facebook.presto.druid.metadata.DruidSegmentInfo;\n+import com.facebook.presto.spi.ConnectorSplit;\n+import com.facebook.presto.spi.HostAddress;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.collect.ImmutableList;\n+\n+import java.util.List;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class DruidSplit\n+        implements ConnectorSplit\n+{\n+    private final DruidSegmentInfo segmentInfo;\n+    private final HostAddress address;\n+\n+    @JsonCreator\n+    public DruidSplit(\n+            @JsonProperty(\"segmentInfo\") DruidSegmentInfo segmentInfo,\n+            @JsonProperty(\"address\") HostAddress address)\n+    {\n+        this.segmentInfo = requireNonNull(segmentInfo, \"segment info is null\");\n+        this.address = requireNonNull(address, \"address info is null\");\n+    }\n+\n+    @JsonProperty\n+    public DruidSegmentInfo getSegmentInfo()\n+    {\n+        return segmentInfo;\n+    }\n+\n+    @JsonProperty\n+    public HostAddress getAddress()\n+    {\n+        return address;\n+    }\n+\n+    @Override\n+    public boolean isRemotelyAccessible()\n+    {\n+        return true;\n+    }\n+\n+    @Override\n+    public List<HostAddress> getAddresses()\n+    {\n+        return ImmutableList.of();", "originalCommit": "68028485595f3beb7247b9c928bbd5a4c54a1905", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "946e9272eceba50584b19c3fd55ef486eb3cef6d", "url": "https://github.com/prestodb/presto/commit/946e9272eceba50584b19c3fd55ef486eb3cef6d", "message": "Remove unused variable and methods from druid connector", "committedDate": "2020-02-06T03:38:02Z", "type": "commit"}, {"oid": "07a09a9e05103e5b770377fb1215e02c88735f6b", "url": "https://github.com/prestodb/presto/commit/07a09a9e05103e5b770377fb1215e02c88735f6b", "message": "Add DruidQueryRunner", "committedDate": "2020-02-06T03:53:18Z", "type": "commit"}, {"oid": "263808764b7b764105da8f8e781f7a203c4a13a7", "url": "https://github.com/prestodb/presto/commit/263808764b7b764105da8f8e781f7a203c4a13a7", "message": "Fix Druid metadata Json format", "committedDate": "2020-02-06T04:23:37Z", "type": "commit"}, {"oid": "45156d77da67b3844248f66283c593229932cbac", "url": "https://github.com/prestodb/presto/commit/45156d77da67b3844248f66283c593229932cbac", "message": "Fix Druid 0.17.0 index generation", "committedDate": "2020-02-06T04:53:20Z", "type": "commit"}, {"oid": "ab1680d7ce48406dddf825c5c514935495b0e23b", "url": "https://github.com/prestodb/presto/commit/ab1680d7ce48406dddf825c5c514935495b0e23b", "message": "Fix getReadTimeNanos for DruidSegmentPageSource", "committedDate": "2020-02-06T07:24:31Z", "type": "commit"}, {"oid": "ab1680d7ce48406dddf825c5c514935495b0e23b", "url": "https://github.com/prestodb/presto/commit/ab1680d7ce48406dddf825c5c514935495b0e23b", "message": "Fix getReadTimeNanos for DruidSegmentPageSource", "committedDate": "2020-02-06T07:24:31Z", "type": "forcePushed"}, {"oid": "9a7a15d7495b6dc1b2f439906e662f592e7d03bc", "url": "https://github.com/prestodb/presto/commit/9a7a15d7495b6dc1b2f439906e662f592e7d03bc", "message": "Add Druid connector documentation", "committedDate": "2020-02-07T00:07:17Z", "type": "commit"}, {"oid": "005b40a86afd47609b4435fbd2de4ebdd197139d", "url": "https://github.com/prestodb/presto/commit/005b40a86afd47609b4435fbd2de4ebdd197139d", "message": "Druid connector schema configurable", "committedDate": "2020-02-07T00:49:49Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE3NjYwMA==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r376176600", "bodyText": "Do you want to use the Pushdown framework to push the filters down instead of Tuple Domains ?", "author": "agrawaldevesh", "createdAt": "2020-02-07T01:44:25Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/DruidClient.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid;\n+\n+import com.facebook.airlift.http.client.HttpClient;\n+import com.facebook.airlift.http.client.HttpUriBuilder;\n+import com.facebook.airlift.http.client.Request;\n+import com.facebook.airlift.json.JsonCodec;\n+import com.facebook.presto.druid.metadata.DruidColumnInfo;\n+import com.facebook.presto.druid.metadata.DruidSegmentIdWrapper;\n+import com.facebook.presto.druid.metadata.DruidSegmentInfo;\n+import com.facebook.presto.druid.metadata.DruidTableInfo;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.Range;\n+import com.google.common.base.Joiner;\n+import org.joda.time.Instant;\n+\n+import javax.inject.Inject;\n+\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import static com.facebook.airlift.http.client.HttpUriBuilder.uriBuilderFrom;\n+import static com.facebook.airlift.http.client.JsonResponseHandler.createJsonResponseHandler;\n+import static com.facebook.airlift.http.client.Request.Builder.prepareGet;\n+import static com.facebook.airlift.http.client.Request.Builder.preparePost;\n+import static com.facebook.airlift.http.client.StaticBodyGenerator.createStaticBodyGenerator;\n+import static com.facebook.airlift.json.JsonCodec.jsonCodec;\n+import static com.facebook.airlift.json.JsonCodec.listJsonCodec;\n+import static com.facebook.presto.spi.type.TimestampType.TIMESTAMP;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.net.HttpHeaders.ACCEPT;\n+import static com.google.common.net.HttpHeaders.CONTENT_TYPE;\n+import static com.google.common.net.MediaType.JSON_UTF_8;\n+import static java.lang.String.format;\n+import static java.util.Objects.requireNonNull;\n+\n+public class DruidClient\n+{\n+    private static final String ALWAYS_TRUE = \"1=1\";\n+    private static final String ALWAYS_FALSE = \"1=0\";\n+\n+    // Druid coordinator API endpoints\n+    private static final String METADATA_PATH = \"/druid/coordinator/v1/metadata\";\n+    // Druid broker API endpoints\n+    private static final String SQL_ENDPOINT = \"/druid/v2/sql\";\n+\n+    private static final String LIST_TABLE_QUERY = \"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'druid'\";\n+    private static final String GET_COLUMN_TEMPLATE = \"SELECT COLUMN_NAME, DATA_TYPE FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = 'druid' AND TABLE_NAME = '%s'\";\n+    private static final String GET_SEGMENTS_ID_TEMPLATE = \"SELECT segment_id FROM sys.segments WHERE datasource = '%s' AND is_published = 1 AND %s\";\n+\n+    // codec\n+    private static final JsonCodec<List<DruidSegmentIdWrapper>> LIST_SEGMENT_ID_CODEC = listJsonCodec(DruidSegmentIdWrapper.class);\n+    private static final JsonCodec<List<DruidColumnInfo>> LIST_COLUMN_INFO_CODEC = listJsonCodec(DruidColumnInfo.class);\n+    private static final JsonCodec<List<DruidTableInfo>> LIST_TABLE_NAME_CODEC = listJsonCodec(DruidTableInfo.class);\n+    private static final JsonCodec<DruidSegmentInfo> SEGMENT_INFO_CODEC = jsonCodec(DruidSegmentInfo.class);\n+\n+    private final HttpClient httpClient;\n+    private final URI druidCoordinator;\n+    private final URI druidBroker;\n+\n+    @Inject\n+    public DruidClient(DruidConfig config, @ForDruidClient HttpClient httpClient)\n+    {\n+        requireNonNull(config, \"config is null\");\n+        this.httpClient = requireNonNull(httpClient, \"httpClient is null\");\n+        this.druidCoordinator = URI.create(config.getDruidCoordinatorUrl());\n+        this.druidBroker = URI.create(config.getDruidBrokerUrl());\n+    }\n+\n+    public URI getDruidBroker()\n+    {\n+        return druidBroker;\n+    }\n+\n+    public List<String> getTables()\n+    {\n+        return httpClient.execute(prepareQuery(LIST_TABLE_QUERY), createJsonResponseHandler(LIST_TABLE_NAME_CODEC)).stream()\n+                .map(DruidTableInfo::getTableName)\n+                .collect(toImmutableList());\n+    }\n+\n+    public List<DruidColumnInfo> getColumnDataType(String tableName)\n+    {\n+        return httpClient.execute(prepareQuery(format(GET_COLUMN_TEMPLATE, tableName)), createJsonResponseHandler(LIST_COLUMN_INFO_CODEC));\n+    }\n+\n+    public List<String> getAllDataSegmentId(String tableName)\n+    {\n+        return getDataSegmentIdInDomain(tableName, Domain.all(TIMESTAMP));\n+    }\n+\n+    public List<String> getDataSegmentIdInDomain(String tableName, Domain domain)\n+    {\n+        return httpClient.execute(prepareQuery(format(GET_SEGMENTS_ID_TEMPLATE, tableName, toPredicate(domain))), createJsonResponseHandler(LIST_SEGMENT_ID_CODEC)).stream()\n+                .map(wrapper -> wrapper.getSegmentId())\n+                .collect(toImmutableList());\n+    }\n+\n+    public DruidSegmentInfo getSingleSegmentInfo(String dataSource, String segmentId)\n+    {\n+        URI uri = uriBuilderFrom(druidCoordinator)\n+                .replacePath(METADATA_PATH)\n+                .appendPath(format(\"datasources/%s/segments/%s\", dataSource, segmentId))\n+                .build();\n+        Request request = setContentTypeHeaders(prepareGet())\n+                .setUri(uri)\n+                .build();\n+\n+        return httpClient.execute(request, createJsonResponseHandler(SEGMENT_INFO_CODEC));\n+    }\n+\n+    private static Request.Builder setContentTypeHeaders(Request.Builder requestBuilder)\n+    {\n+        return requestBuilder\n+                .setHeader(CONTENT_TYPE, JSON_UTF_8.toString())\n+                .setHeader(ACCEPT, JSON_UTF_8.toString());\n+    }\n+\n+    private static byte[] createRequestBody(String query)\n+    {\n+        return format(\"{\\\"query\\\":\\\"%s\\\"}\\n\", query).getBytes();\n+    }\n+\n+    private Request prepareQuery(String query)\n+    {\n+        HttpUriBuilder uriBuilder = uriBuilderFrom(druidBroker).replacePath(SQL_ENDPOINT);\n+\n+        return setContentTypeHeaders(preparePost())\n+                .setUri(uriBuilder.build())\n+                .setBodyGenerator(createStaticBodyGenerator(createRequestBody(query)))\n+                .build();\n+    }\n+\n+    private String toPredicate(Domain domain)", "originalCommit": "ab1680d7ce48406dddf825c5c514935495b0e23b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE4MTAzNw==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r376181037", "bodyText": "yep, that's a following step", "author": "zhenxiao", "createdAt": "2020-02-07T02:03:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE3NjYwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE3NzE1NQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r376177155", "bodyText": "Can some of this Druid specific stuff be pushed into its own repo like we did for pinot: https://github.com/prestodb/presto-pinot-driver. For example, this repo abstracts all of the pinot specific intricacies like talking to ZK, merging the server results and what not. I feel that there is some of that going in Druid land as well: you stitch results from hdfs and druid proper.", "author": "agrawaldevesh", "createdAt": "2020-02-07T01:46:52Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/segment/SmooshedColumnSource.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid.segment;\n+\n+import com.facebook.presto.spi.PrestoException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.apache.druid.common.utils.SerializerUtils;\n+import org.apache.druid.jackson.DefaultObjectMapper;", "originalCommit": "ab1680d7ce48406dddf825c5c514935495b0e23b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE4MjAzNA==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r376182034", "bodyText": "good idea. We did not separate them out yet. Currently, Druid connector only use Druid for metadata. it is scanning Druid segments files directly from HDFS.", "author": "zhenxiao", "createdAt": "2020-02-07T02:07:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE3NzE1NQ=="}], "type": "inlineReview"}, {"oid": "e0c92a528c61833473b11aeb1cabd2b57b4adfb3", "url": "https://github.com/prestodb/presto/commit/e0c92a528c61833473b11aeb1cabd2b57b4adfb3", "message": "Remove unused files and comments from druid connector", "committedDate": "2020-02-07T02:01:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYwMzQ0OQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r376603449", "bodyText": "not used", "author": "highker", "createdAt": "2020-02-07T20:56:26Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/DataInputSource.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+\n+public interface DataInputSource\n+        extends Closeable\n+{\n+    DataInputSourceId getId();\n+\n+    long getReadBytes();", "originalCommit": "e0c92a528c61833473b11aeb1cabd2b57b4adfb3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYwNDIwOQ==", "url": "https://github.com/prestodb/presto/pull/14042#discussion_r376604209", "bodyText": "0x0100 is not the right error code. Check the one for PinotErrorCode and other connectors' error code. It should be something greater than 0x0505.", "author": "highker", "createdAt": "2020-02-07T20:58:09Z", "path": "presto-druid/src/main/java/com/facebook/presto/druid/DruidErrorCode.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.druid;\n+\n+import com.facebook.presto.spi.ErrorCode;\n+import com.facebook.presto.spi.ErrorCodeSupplier;\n+import com.facebook.presto.spi.ErrorType;\n+\n+import static com.facebook.presto.spi.ErrorType.EXTERNAL;\n+\n+public enum DruidErrorCode\n+        implements ErrorCodeSupplier\n+{\n+    DRUID_METADATA_ERROR(0, EXTERNAL),\n+    DRUID_DEEP_STORAGE_ERROR(1, EXTERNAL),\n+    DRUID_SEGMENT_LOAD_ERROR(2, EXTERNAL),\n+    DRUID_UNSUPPORTED_TYPE_ERROR(3, EXTERNAL);\n+\n+    private final ErrorCode errorCode;\n+\n+    DruidErrorCode(int code, ErrorType type)\n+    {\n+        errorCode = new ErrorCode(code + 0x0100_0000, name(), type);", "originalCommit": "e0c92a528c61833473b11aeb1cabd2b57b4adfb3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "68ca7cd541a77668945e07acf09c1d881133512f", "url": "https://github.com/prestodb/presto/commit/68ca7cd541a77668945e07acf09c1d881133512f", "message": "Fix Druid ErrorCode", "committedDate": "2020-02-07T21:29:59Z", "type": "commit"}]}