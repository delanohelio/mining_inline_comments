{"pr_number": 15262, "pr_title": "Disable broadcast join optimization for Presto on Spark", "pr_createdAt": "2020-10-02T19:30:56Z", "pr_url": "https://github.com/prestodb/presto/pull/15262", "timeline": [{"oid": "fbd4bbb37dd0d6649dfec4668d4a089d222babe9", "url": "https://github.com/prestodb/presto/commit/fbd4bbb37dd0d6649dfec4668d4a089d222babe9", "message": "Revert \"Enable nullifying iterator for broadcast join\"\n\nThis reverts commit 8ae554dc9c1434c3e22b1c6c94fc45ed478012fa.", "committedDate": "2020-10-02T14:52:22Z", "type": "commit"}, {"oid": "a8a6cdf71754f9cd73c4fcfb835b0bbc79a09193", "url": "https://github.com/prestodb/presto/commit/a8a6cdf71754f9cd73c4fcfb835b0bbc79a09193", "message": "Make sure PagesSerde is not used in a non thread safe manner", "committedDate": "2020-10-02T14:52:22Z", "type": "commit"}, {"oid": "b8fadf5aa929a0fe70b966831dc9f13036cf2d9c", "url": "https://github.com/prestodb/presto/commit/b8fadf5aa929a0fe70b966831dc9f13036cf2d9c", "message": "Compress broadcast pages in Presto on Spark to save memory", "committedDate": "2020-10-02T15:14:57Z", "type": "commit"}, {"oid": "451242d5ac49bed60f10e48e5b251e8989fc7c6b", "url": "https://github.com/prestodb/presto/commit/451242d5ac49bed60f10e48e5b251e8989fc7c6b", "message": "Enforce broadcast memory limits in Presto on Spark", "committedDate": "2020-10-02T15:14:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAzMDQ0OQ==", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499030449", "bodyText": "I really think we should have something like presto-compression to avoid code duplication =)", "author": "wenleix", "createdAt": "2020-10-02T20:15:06Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/util/PrestoSparkUtils.java", "diffHunk": "@@ -83,8 +89,75 @@ public static PagesSerde createPagesSerde(BlockEncodingManager blockEncodingMana\n     {\n         return new PagesSerde(\n                 blockEncodingManager,\n-                Optional.empty(),\n-                Optional.empty(),\n+                Optional.of(createPageCompressor()),\n+                Optional.of(createPageDecompressor()),\n                 Optional.empty());\n     }\n+\n+    private static PageCompressor createPageCompressor()\n+    {\n+        // based on ZstdJniCompressor", "originalCommit": "b8fadf5aa929a0fe70b966831dc9f13036cf2d9c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTc0MjIxNQ==", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499742215", "bodyText": "Yeah. I was thinking about that. I was trying to extract a dependency before copying. But given the amount of code, and relatively simple logic I decided to simply copy it for now.", "author": "arhimondr", "createdAt": "2020-10-05T16:58:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAzMDQ0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA3MzUwMA==", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499073500", "bodyText": "just double check: this is consistent with how Presto classic checks max broadcast size right?\nAlso I feel in theory we can do the check on driver ? (before broadcast the data)", "author": "wenleix", "createdAt": "2020-10-02T22:21:57Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -897,9 +900,29 @@ else if (executionException instanceof PrestoSparkExecutionException) {\n                 PlanFragment childFragment = child.getFragment();\n                 if (childFragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_BROADCAST_DISTRIBUTION)) {\n                     RddAndMore<PrestoSparkSerializedPage> childRdd = createRdd(child, PrestoSparkSerializedPage.class);\n+\n+                    // TODO: The driver might still OOM on a very large broadcast, think of how to prevent that from happening\n                     List<PrestoSparkSerializedPage> broadcastPages = childRdd.collectAndDestroyDependencies().stream()\n                             .map(Tuple2::_2)\n                             .collect(toList());\n+\n+                    int compressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(page -> page.getBytes().length)\n+                            .sum();\n+                    int uncompressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(PrestoSparkSerializedPage::getUncompressedSizeInBytes)\n+                            .sum();\n+                    DataSize maxBroadcastSize = getQueryMaxBroadcastMemory(session);\n+                    long maxBroadcastSizeInBytes = maxBroadcastSize.toBytes();", "originalCommit": "451242d5ac49bed60f10e48e5b251e8989fc7c6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTc0MTMzNg==", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499741336", "bodyText": "just double check: this is consistent with how Presto classic checks max broadcast size right?\n\nYeah. The only difference that Presto Classic enforces that limit on a consumer side. Here we enforce it on a driver before even starting the downstream stage that is supposed to consume the broadcasted table.", "author": "arhimondr", "createdAt": "2020-10-05T16:56:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA3MzUwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA3MzYxMg==", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499073612", "bodyText": "i assume you can do this check even before uncompressed the data?", "author": "wenleix", "createdAt": "2020-10-02T22:22:26Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -897,9 +900,29 @@ else if (executionException instanceof PrestoSparkExecutionException) {\n                 PlanFragment childFragment = child.getFragment();\n                 if (childFragment.getPartitioningScheme().getPartitioning().getHandle().equals(FIXED_BROADCAST_DISTRIBUTION)) {\n                     RddAndMore<PrestoSparkSerializedPage> childRdd = createRdd(child, PrestoSparkSerializedPage.class);\n+\n+                    // TODO: The driver might still OOM on a very large broadcast, think of how to prevent that from happening\n                     List<PrestoSparkSerializedPage> broadcastPages = childRdd.collectAndDestroyDependencies().stream()\n                             .map(Tuple2::_2)\n                             .collect(toList());\n+\n+                    int compressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(page -> page.getBytes().length)\n+                            .sum();\n+                    int uncompressedBroadcastSizeInBytes = broadcastPages.stream()\n+                            .mapToInt(PrestoSparkSerializedPage::getUncompressedSizeInBytes)\n+                            .sum();\n+                    DataSize maxBroadcastSize = getQueryMaxBroadcastMemory(session);\n+                    long maxBroadcastSizeInBytes = maxBroadcastSize.toBytes();\n+\n+                    if (compressedBroadcastSizeInBytes > maxBroadcastSizeInBytes) {", "originalCommit": "451242d5ac49bed60f10e48e5b251e8989fc7c6b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTc0MTYxMA==", "url": "https://github.com/prestodb/presto/pull/15262#discussion_r499741610", "bodyText": "Yup. Luckily we have the exact size of the uncompressed data, so we can check both before even uncompressing.", "author": "arhimondr", "createdAt": "2020-10-05T16:57:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTA3MzYxMg=="}], "type": "inlineReview"}]}