{"pr_number": 14099, "pr_title": "Implement row base exchange in Presto on Spark", "pr_createdAt": "2020-02-13T22:59:48Z", "pr_url": "https://github.com/prestodb/presto/pull/14099", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTA5OTQ0NQ==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381099445", "bodyText": "unrelated change? -- since the original RLE block is also a valid representation for all nulls block?", "author": "wenleix", "createdAt": "2020-02-19T06:32:24Z", "path": "presto-main/src/test/java/com/facebook/presto/block/BlockAssertions.java", "diffHunk": "@@ -115,7 +115,11 @@ public static void assertBlockEquals(Type type, Block actual, Block expected)\n \n     public static Block createAllNullsBlock(Type type, int positionCount)\n     {\n-        return new RunLengthEncodedBlock(type.createBlockBuilder(null, 1).appendNull().build(), positionCount);\n+        BlockBuilder blockBuilder = type.createBlockBuilder(null, 1);", "originalCommit": "435878e8d9dee686a3b53d573aef2663db3fb5b5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjExNzg2Mw==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382117863", "bodyText": "It just feels a little contrintuitive. I would expect the createAllNullsBlock to create a native block for a given type when all positions are nulls. If the intent is to create a RLE block with a null value - there should be a separate method that does that.", "author": "arhimondr", "createdAt": "2020-02-20T16:36:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTA5OTQ0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjEyNDIxNA==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382124214", "bodyText": "Let me extract it into a separate commit", "author": "arhimondr", "createdAt": "2020-02-20T16:46:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTA5OTQ0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTEwNTE2NQ==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381105165", "bodyText": "So this OutputPartitioning is only required by PartitionedOutputOperatorFactory right? (and later PrestoSparkOutputFactory)? Maybe check argument in other OutputFactory that this shouldn't present", "author": "wenleix", "createdAt": "2020-02-19T06:53:34Z", "path": "presto-main/src/main/java/com/facebook/presto/operator/OutputFactory.java", "diffHunk": "@@ -17,11 +17,19 @@\n import com.facebook.presto.spi.Page;\n import com.facebook.presto.spi.plan.PlanNodeId;\n import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n \n import java.util.List;\n+import java.util.Optional;\n import java.util.function.Function;\n \n public interface OutputFactory\n {\n-    OperatorFactory createOutputOperator(int operatorId, PlanNodeId planNodeId, List<Type> types, Function<Page, Page> pagePreprocessor, PagesSerdeFactory serdeFactory);\n+    OperatorFactory createOutputOperator(\n+            int operatorId,\n+            PlanNodeId planNodeId,\n+            List<Type> types,\n+            Function<Page, Page> pagePreprocessor,\n+            Optional<OutputPartitioning> outputPartitioning,", "originalCommit": "3dae179722b363137ef8997d4c5fe4477e9d982c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjEzMDgzNQ==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382130835", "bodyText": "Added a check in the TaskOutputFactory. Didn't add for others, as the others are only used in tests.", "author": "arhimondr", "createdAt": "2020-02-20T16:57:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTEwNTE2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU1MjMxMw==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383552313", "bodyText": "Might still be useful to explicitly add the tests (it's more for convenient for readers of the code :)  )", "author": "wenleix", "createdAt": "2020-02-24T22:27:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTEwNTE2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTYwODkzNw==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381608937", "bodyText": "When outputPartitioning is not present, in PrestoSparkOutputFactory  it means it's SINGLE_PARTITION, but it's not necessary the case for other OutputFactory right? For example, in", "author": "wenleix", "createdAt": "2020-02-19T23:34:04Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);", "originalCommit": "15dc6614cb36f515819e831cbfbfbc8fef635adf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0MzIyMA==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382143220", "bodyText": "For example, in\n\nGithub must've saved not the final version. Could you please elaborate?", "author": "arhimondr", "createdAt": "2020-02-20T17:19:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTYwODkzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU4NDAzMg==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383584032", "bodyText": "@arhimondr : For example, in TaskOutputOperatorFactory ,  the output partitioning can be any of the FIXED_BROADCAST_DISTRIBUTION, FIXED_ARBITRARY_DISTRIBUTION, SCALED_WRITER_DISTRIBUTION, SINGLE_DISTRIBUTION, COORDINATOR_DISTRIBUTION: \n  \n    \n      presto/presto-main/src/main/java/com/facebook/presto/sql/planner/LocalExecutionPlanner.java\n    \n    \n        Lines 381 to 395\n      in\n      2fb54ed\n    \n    \n    \n    \n\n        \n          \n           if (partitioningScheme.getPartitioning().getHandle().equals(FIXED_BROADCAST_DISTRIBUTION) || \n        \n\n        \n          \n                   partitioningScheme.getPartitioning().getHandle().equals(FIXED_ARBITRARY_DISTRIBUTION) || \n        \n\n        \n          \n                   partitioningScheme.getPartitioning().getHandle().equals(SCALED_WRITER_DISTRIBUTION) || \n        \n\n        \n          \n                   partitioningScheme.getPartitioning().getHandle().equals(SINGLE_DISTRIBUTION) || \n        \n\n        \n          \n                   partitioningScheme.getPartitioning().getHandle().equals(COORDINATOR_DISTRIBUTION)) { \n        \n\n        \n          \n               return plan( \n        \n\n        \n          \n                       taskContext, \n        \n\n        \n          \n                       stageExecutionDescriptor, \n        \n\n        \n          \n                       plan, \n        \n\n        \n          \n                       outputLayout, \n        \n\n        \n          \n                       partitionedSourceOrder, \n        \n\n        \n          \n                       new TaskOutputFactory(outputBuffer), \n        \n\n        \n          \n                       remoteSourceFactory, \n        \n\n        \n          \n                       tableWriteInfo); \n        \n\n        \n          \n           } \n        \n    \n  \n\n\nUpdate: with the check argument that output partitioning must be absent, it might be OK... just note the absence of output partitioning seems to have different semantic for TaskOutputOperatorFactory vs. PrestoSparkOutputFactory", "author": "wenleix", "createdAt": "2020-02-24T23:55:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTYwODkzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTYyOTQ0MQ==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381629441", "bodyText": "what does replicateNullsAndAny mean? In PartitionedOutputOperator, the variable name is replicatesAnyRow", "author": "wenleix", "createdAt": "2020-02-20T00:42:08Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitioning.getPartitionFunction(),\n+                    partitioning.getPartitionChannels(),\n+                    partitioning.getPartitionConstants().stream()\n+                            .map(constant -> constant.map(ConstantExpression::getValueBlock))\n+                            .collect(toImmutableList()),\n+                    partitioning.isReplicateNullsAndAny(),\n+                    partitioning.getNullChannel());\n+        }\n+    }\n+\n+    private static class ConstantPartitionFunction\n+            implements PartitionFunction\n+    {\n+        @Override\n+        public int getPartitionCount()\n+        {\n+            return 1;\n+        }\n+\n+        @Override\n+        public int getPartition(Page page, int position)\n+        {\n+            return 0;\n+        }\n+    }\n+\n+    public static class PrestoSparkOutputOperatorFactory\n+            implements OperatorFactory\n+    {\n+        private final int operatorId;\n+        private final PlanNodeId planNodeId;\n+        private final PrestoSparkRowBuffer rowBuffer;\n+        private final Function<Page, Page> pagePreprocessor;\n+        private final PartitionFunction partitionFunction;\n+        private final List<Integer> partitionChannels;\n+        private final List<Optional<Block>> partitionConstants;\n+        private final boolean replicateNullsAndAny;", "originalCommit": "15dc6614cb36f515819e831cbfbfbc8fef635adf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjEzOTM1OQ==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382139359", "bodyText": "what does replicateNullsAndAny mean?\n\nIt is needed for the SemiJoin. It tels the partitioner to copy null rows to every partition and also make sure that if the input is not empty - a row is replicated to every partition (so the partitions are not empty). It is needed to preserve correct null vs false semantics of the SemiJoin.\nI think the replicatesAnyRow is missleading. Whoever was extending this behaviour to the replicateNullsAndAny probably just forgot to do the rename in the PartitioningOperator.", "author": "arhimondr", "createdAt": "2020-02-20T17:12:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTYyOTQ0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2NzA4NA==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381767084", "bodyText": "So PrestoSparkRowBuffer#get is a blocked call. Is there any reason for that -- I am asking this since the general convention in Presto seems to be using ListenableFuture<PrestoSparkRow> for such cases?", "author": "wenleix", "createdAt": "2020-02-20T05:24:04Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();\n+    @GuardedBy(\"monitor\")\n+    private volatile boolean finished;\n+\n+    public PrestoSparkRowBuffer(OutputBufferMemoryManager memoryManager)\n+    {\n+        this.memoryManager = requireNonNull(memoryManager, \"memoryManager is null\");\n+    }\n+\n+    public ListenableFuture<?> isFull()\n+    {\n+        return memoryManager.getBufferBlockedFuture();\n+    }\n+\n+    public void enqueue(PrestoSparkRow row)\n+    {\n+        requireNonNull(row, \"row is null\");\n+        synchronized (monitor) {\n+            buffer.add(row);\n+            monitor.notify();\n+        }\n+        memoryManager.updateMemoryUsage(row.getRetainedSize());\n+    }\n+\n+    public void setNoMoreRows()\n+    {\n+        memoryManager.setNoBlockOnFull();\n+        synchronized (monitor) {\n+            finished = true;\n+            monitor.notifyAll();\n+        }\n+    }\n+\n+    public boolean hasRowsBuffered()\n+    {\n+        synchronized (monitor) {\n+            return !buffer.isEmpty();\n+        }\n+    }\n+\n+    public PrestoSparkRow get()\n+            throws InterruptedException\n+    {\n+        PrestoSparkRow row;\n+        synchronized (monitor) {\n+            while (!finished && buffer.isEmpty()) {\n+                monitor.wait();", "originalCommit": "15dc6614cb36f515819e831cbfbfbc8fef635adf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0MDQ3Mw==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382140473", "bodyText": "The Spark iterator is blocking anyway. It is mostly for implementation simplicity. Otherwise we would always wait on the Future#get() unconditionally in the SparkIterator.", "author": "arhimondr", "createdAt": "2020-02-20T17:14:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2NzA4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2ODM1NQ==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381768355", "bodyText": "I guess you intend to avoid create a new DynamicSliceOutput each time so you try to get the underlying byte array directly \ud83d\ude03 . I understand it cannot be done for now since you cannot reset DynamicSliceOutput\nThat being said, we might want to consider add something like reset into SliceOutput?", "author": "wenleix", "createdAt": "2020-02-20T05:26:42Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitioning.getPartitionFunction(),\n+                    partitioning.getPartitionChannels(),\n+                    partitioning.getPartitionConstants().stream()\n+                            .map(constant -> constant.map(ConstantExpression::getValueBlock))\n+                            .collect(toImmutableList()),\n+                    partitioning.isReplicateNullsAndAny(),\n+                    partitioning.getNullChannel());\n+        }\n+    }\n+\n+    private static class ConstantPartitionFunction\n+            implements PartitionFunction\n+    {\n+        @Override\n+        public int getPartitionCount()\n+        {\n+            return 1;\n+        }\n+\n+        @Override\n+        public int getPartition(Page page, int position)\n+        {\n+            return 0;\n+        }\n+    }\n+\n+    public static class PrestoSparkOutputOperatorFactory\n+            implements OperatorFactory\n+    {\n+        private final int operatorId;\n+        private final PlanNodeId planNodeId;\n+        private final PrestoSparkRowBuffer rowBuffer;\n+        private final Function<Page, Page> pagePreprocessor;\n+        private final PartitionFunction partitionFunction;\n+        private final List<Integer> partitionChannels;\n+        private final List<Optional<Block>> partitionConstants;\n+        private final boolean replicateNullsAndAny;\n+        private final OptionalInt nullChannel;\n+\n+        public PrestoSparkOutputOperatorFactory(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                PrestoSparkRowBuffer rowBuffer,\n+                Function<Page, Page> pagePreprocessor,\n+                PartitionFunction partitionFunction,\n+                List<Integer> partitionChannels,\n+                List<Optional<Block>> partitionConstants,\n+                boolean replicateNullsAndAny,\n+                OptionalInt nullChannel)\n+        {\n+            this.operatorId = operatorId;\n+            this.planNodeId = requireNonNull(planNodeId, \"planNodeId is null\");\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+            this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+            this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+            this.partitionChannels = requireNonNull(partitionChannels, \"partitionChannels is null\");\n+            this.partitionConstants = requireNonNull(partitionConstants, \"partitionConstants is null\");\n+            this.replicateNullsAndAny = replicateNullsAndAny;\n+            this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+        }\n+\n+        @Override\n+        public Operator createOperator(DriverContext driverContext)\n+        {\n+            OperatorContext operatorContext = driverContext.addOperatorContext(operatorId, planNodeId, PrestoSparkOutputOperator.class.getSimpleName());\n+            return new PrestoSparkOutputOperator(\n+                    operatorContext,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+\n+        @Override\n+        public void noMoreOperators()\n+        {\n+        }\n+\n+        @Override\n+        public OperatorFactory duplicate()\n+        {\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+    }\n+\n+    private final OperatorContext operatorContext;\n+    private final PrestoSparkRowBuffer rowBuffer;\n+    private final Function<Page, Page> pagePreprocessor;\n+    private final PartitionFunction partitionFunction;\n+    private final List<Integer> partitionChannels;\n+    private final List<Optional<Block>> partitionConstants;\n+    private final boolean replicateNullsAndAny;\n+    private final OptionalInt nullChannel;\n+\n+    private boolean finished;\n+    private boolean hasAnyRowBeenReplicated;\n+\n+    public PrestoSparkOutputOperator(\n+            OperatorContext operatorContext,\n+            PrestoSparkRowBuffer rowBuffer,\n+            Function<Page, Page> pagePreprocessor,\n+            PartitionFunction partitionFunction,\n+            List<Integer> partitionChannels,\n+            List<Optional<Block>> partitionConstants,\n+            boolean replicateNullsAndAny,\n+            OptionalInt nullChannel)\n+    {\n+        this.operatorContext = requireNonNull(operatorContext, \"operatorContext is null\");\n+        this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+        this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+        this.partitionChannels = ImmutableList.copyOf(requireNonNull(partitionChannels, \"partitionChannels is null\"));\n+        this.partitionConstants = ImmutableList.copyOf(requireNonNull(partitionConstants, \"partitionConstants is null\"));\n+        this.replicateNullsAndAny = replicateNullsAndAny;\n+        this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+    }\n+\n+    @Override\n+    public OperatorContext getOperatorContext()\n+    {\n+        return operatorContext;\n+    }\n+\n+    @Override\n+    public ListenableFuture<?> isBlocked()\n+    {\n+        return rowBuffer.isFull();\n+    }\n+\n+    @Override\n+    public boolean needsInput()\n+    {\n+        return !finished && isBlocked().isDone();\n+    }\n+\n+    @Override\n+    public void addInput(Page page)\n+    {\n+        page = pagePreprocessor.apply(page);\n+        int positionCount = page.getPositionCount();\n+        int channelCount = page.getChannelCount();\n+        int averageRowSizeInBytes = min(toIntExact(page.getLogicalSizeInBytes() / positionCount), 10);\n+        Page partitionFunctionArguments = getPartitionFunctionArguments(page);\n+        for (int position = 0; position < positionCount; position++) {\n+            SliceOutput output = new DynamicSliceOutput(averageRowSizeInBytes * 2);\n+            for (int channel = 0; channel < channelCount; channel++) {\n+                Block block = page.getBlock(channel);\n+                block.writePositionTo(position, output);\n+            }\n+\n+            boolean shouldReplicate = (replicateNullsAndAny && !hasAnyRowBeenReplicated) ||\n+                    nullChannel.isPresent() && page.getBlock(nullChannel.getAsInt()).isNull(position);\n+            if (shouldReplicate) {\n+                for (int i = 0; i < partitionFunction.getPartitionCount(); i++) {\n+                    rowBuffer.enqueue(new PrestoSparkRow(i, output.size(), output.getUnderlyingSlice().byteArray()));", "originalCommit": "15dc6614cb36f515819e831cbfbfbc8fef635adf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0MTA3Mg==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382141072", "bodyText": "This should be done as part of the buffer recycling effort. As SliceOutput has to acquire a free buffer from a pool before you can reset it.", "author": "arhimondr", "createdAt": "2020-02-20T17:16:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2ODM1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2OTU1Mg==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381769552", "bodyText": "is this enough -- do we want to make sure rowBuffer is empty?", "author": "wenleix", "createdAt": "2020-02-20T05:29:01Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkOutputOperator.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.PagesSerdeFactory;\n+import com.facebook.presto.operator.DriverContext;\n+import com.facebook.presto.operator.Operator;\n+import com.facebook.presto.operator.OperatorContext;\n+import com.facebook.presto.operator.OperatorFactory;\n+import com.facebook.presto.operator.OutputFactory;\n+import com.facebook.presto.operator.PartitionFunction;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.facebook.presto.spi.Page;\n+import com.facebook.presto.spi.block.Block;\n+import com.facebook.presto.spi.block.RunLengthEncodedBlock;\n+import com.facebook.presto.spi.plan.PlanNodeId;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.type.Type;\n+import com.facebook.presto.sql.planner.OutputPartitioning;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.util.concurrent.ListenableFuture;\n+import io.airlift.slice.DynamicSliceOutput;\n+import io.airlift.slice.SliceOutput;\n+\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.function.Function;\n+\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static java.lang.Integer.min;\n+import static java.lang.Math.toIntExact;\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkOutputOperator\n+        implements Operator\n+{\n+    public static class PrestoSparkOutputFactory\n+            implements OutputFactory\n+    {\n+        private static final OutputPartitioning SINGLE_PARTITION = new OutputPartitioning(\n+                new ConstantPartitionFunction(),\n+                ImmutableList.of(),\n+                ImmutableList.of(),\n+                false,\n+                OptionalInt.empty());\n+\n+        private final PrestoSparkRowBuffer rowBuffer;\n+\n+        public PrestoSparkOutputFactory(PrestoSparkRowBuffer rowBuffer)\n+        {\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        }\n+\n+        @Override\n+        public OperatorFactory createOutputOperator(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                List<Type> types,\n+                Function<Page, Page> pagePreprocessor,\n+                Optional<OutputPartitioning> outputPartitioning,\n+                PagesSerdeFactory serdeFactory)\n+        {\n+            OutputPartitioning partitioning = outputPartitioning.orElse(SINGLE_PARTITION);\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitioning.getPartitionFunction(),\n+                    partitioning.getPartitionChannels(),\n+                    partitioning.getPartitionConstants().stream()\n+                            .map(constant -> constant.map(ConstantExpression::getValueBlock))\n+                            .collect(toImmutableList()),\n+                    partitioning.isReplicateNullsAndAny(),\n+                    partitioning.getNullChannel());\n+        }\n+    }\n+\n+    private static class ConstantPartitionFunction\n+            implements PartitionFunction\n+    {\n+        @Override\n+        public int getPartitionCount()\n+        {\n+            return 1;\n+        }\n+\n+        @Override\n+        public int getPartition(Page page, int position)\n+        {\n+            return 0;\n+        }\n+    }\n+\n+    public static class PrestoSparkOutputOperatorFactory\n+            implements OperatorFactory\n+    {\n+        private final int operatorId;\n+        private final PlanNodeId planNodeId;\n+        private final PrestoSparkRowBuffer rowBuffer;\n+        private final Function<Page, Page> pagePreprocessor;\n+        private final PartitionFunction partitionFunction;\n+        private final List<Integer> partitionChannels;\n+        private final List<Optional<Block>> partitionConstants;\n+        private final boolean replicateNullsAndAny;\n+        private final OptionalInt nullChannel;\n+\n+        public PrestoSparkOutputOperatorFactory(\n+                int operatorId,\n+                PlanNodeId planNodeId,\n+                PrestoSparkRowBuffer rowBuffer,\n+                Function<Page, Page> pagePreprocessor,\n+                PartitionFunction partitionFunction,\n+                List<Integer> partitionChannels,\n+                List<Optional<Block>> partitionConstants,\n+                boolean replicateNullsAndAny,\n+                OptionalInt nullChannel)\n+        {\n+            this.operatorId = operatorId;\n+            this.planNodeId = requireNonNull(planNodeId, \"planNodeId is null\");\n+            this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+            this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+            this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+            this.partitionChannels = requireNonNull(partitionChannels, \"partitionChannels is null\");\n+            this.partitionConstants = requireNonNull(partitionConstants, \"partitionConstants is null\");\n+            this.replicateNullsAndAny = replicateNullsAndAny;\n+            this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+        }\n+\n+        @Override\n+        public Operator createOperator(DriverContext driverContext)\n+        {\n+            OperatorContext operatorContext = driverContext.addOperatorContext(operatorId, planNodeId, PrestoSparkOutputOperator.class.getSimpleName());\n+            return new PrestoSparkOutputOperator(\n+                    operatorContext,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+\n+        @Override\n+        public void noMoreOperators()\n+        {\n+        }\n+\n+        @Override\n+        public OperatorFactory duplicate()\n+        {\n+            return new PrestoSparkOutputOperatorFactory(\n+                    operatorId,\n+                    planNodeId,\n+                    rowBuffer,\n+                    pagePreprocessor,\n+                    partitionFunction,\n+                    partitionChannels,\n+                    partitionConstants,\n+                    replicateNullsAndAny,\n+                    nullChannel);\n+        }\n+    }\n+\n+    private final OperatorContext operatorContext;\n+    private final PrestoSparkRowBuffer rowBuffer;\n+    private final Function<Page, Page> pagePreprocessor;\n+    private final PartitionFunction partitionFunction;\n+    private final List<Integer> partitionChannels;\n+    private final List<Optional<Block>> partitionConstants;\n+    private final boolean replicateNullsAndAny;\n+    private final OptionalInt nullChannel;\n+\n+    private boolean finished;\n+    private boolean hasAnyRowBeenReplicated;\n+\n+    public PrestoSparkOutputOperator(\n+            OperatorContext operatorContext,\n+            PrestoSparkRowBuffer rowBuffer,\n+            Function<Page, Page> pagePreprocessor,\n+            PartitionFunction partitionFunction,\n+            List<Integer> partitionChannels,\n+            List<Optional<Block>> partitionConstants,\n+            boolean replicateNullsAndAny,\n+            OptionalInt nullChannel)\n+    {\n+        this.operatorContext = requireNonNull(operatorContext, \"operatorContext is null\");\n+        this.rowBuffer = requireNonNull(rowBuffer, \"rowBuffer is null\");\n+        this.pagePreprocessor = requireNonNull(pagePreprocessor, \"pagePreprocessor is null\");\n+        this.partitionFunction = requireNonNull(partitionFunction, \"partitionFunction is null\");\n+        this.partitionChannels = ImmutableList.copyOf(requireNonNull(partitionChannels, \"partitionChannels is null\"));\n+        this.partitionConstants = ImmutableList.copyOf(requireNonNull(partitionConstants, \"partitionConstants is null\"));\n+        this.replicateNullsAndAny = replicateNullsAndAny;\n+        this.nullChannel = requireNonNull(nullChannel, \"nullChannel is null\");\n+    }\n+\n+    @Override\n+    public OperatorContext getOperatorContext()\n+    {\n+        return operatorContext;\n+    }\n+\n+    @Override\n+    public ListenableFuture<?> isBlocked()\n+    {\n+        return rowBuffer.isFull();\n+    }\n+\n+    @Override\n+    public boolean needsInput()\n+    {\n+        return !finished && isBlocked().isDone();\n+    }\n+\n+    @Override\n+    public void addInput(Page page)\n+    {\n+        page = pagePreprocessor.apply(page);\n+        int positionCount = page.getPositionCount();\n+        int channelCount = page.getChannelCount();\n+        int averageRowSizeInBytes = min(toIntExact(page.getLogicalSizeInBytes() / positionCount), 10);\n+        Page partitionFunctionArguments = getPartitionFunctionArguments(page);\n+        for (int position = 0; position < positionCount; position++) {\n+            SliceOutput output = new DynamicSliceOutput(averageRowSizeInBytes * 2);\n+            for (int channel = 0; channel < channelCount; channel++) {\n+                Block block = page.getBlock(channel);\n+                block.writePositionTo(position, output);\n+            }\n+\n+            boolean shouldReplicate = (replicateNullsAndAny && !hasAnyRowBeenReplicated) ||\n+                    nullChannel.isPresent() && page.getBlock(nullChannel.getAsInt()).isNull(position);\n+            if (shouldReplicate) {\n+                for (int i = 0; i < partitionFunction.getPartitionCount(); i++) {\n+                    rowBuffer.enqueue(new PrestoSparkRow(i, output.size(), output.getUnderlyingSlice().byteArray()));\n+                }\n+                hasAnyRowBeenReplicated = true;\n+            }\n+            else {\n+                int partition = getPartition(partitionFunctionArguments, position);\n+                rowBuffer.enqueue(new PrestoSparkRow(partition, output.size(), output.getUnderlyingSlice().byteArray()));\n+            }\n+        }\n+    }\n+\n+    private int getPartition(Page partitionFunctionArgs, int position)\n+    {\n+        return partitionFunction.getPartition(partitionFunctionArgs, position);\n+    }\n+\n+    private Page getPartitionFunctionArguments(Page page)\n+    {\n+        Block[] blocks = new Block[partitionChannels.size()];\n+        for (int i = 0; i < blocks.length; i++) {\n+            Optional<Block> partitionConstant = partitionConstants.get(i);\n+            if (partitionConstant.isPresent()) {\n+                blocks[i] = new RunLengthEncodedBlock(partitionConstant.get(), page.getPositionCount());\n+            }\n+            else {\n+                blocks[i] = page.getBlock(partitionChannels.get(i));\n+            }\n+        }\n+        return new Page(page.getPositionCount(), blocks);\n+    }\n+\n+    @Override\n+    public Page getOutput()\n+    {\n+        return null;\n+    }\n+\n+    @Override\n+    public void finish()\n+    {\n+        finished = true;\n+    }\n+\n+    @Override\n+    public boolean isFinished()\n+    {\n+        return finished && isBlocked().isDone();", "originalCommit": "15dc6614cb36f515819e831cbfbfbc8fef635adf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0NDE3Ng==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382144176", "bodyText": "It looks like the TaskOutputFactory is not waiting for the buffer to be drained. I followed the same approach here.", "author": "arhimondr", "createdAt": "2020-02-20T17:21:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2OTU1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2OTkyMw==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381769923", "bodyText": "As a future work, I guess you want to use Spark's MutableRow? :) . cc @sameeragarwal", "author": "wenleix", "createdAt": "2020-02-20T05:29:49Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceOperator.java", "diffHunk": "@@ -74,18 +81,29 @@ public Page getOutput()\n             return null;\n         }\n \n-        SerializedPage serializedPage = null;\n+        PageBuilder pageBuilder = new PageBuilder(types);\n         synchronized (iterator) {\n-            if (iterator.hasNext()) {\n-                serializedPage = iterator.next();\n+            while (iterator.hasNext() && !pageBuilder.isFull()) {\n+                PrestoSparkRow row = iterator.next();", "originalCommit": "15dc6614cb36f515819e831cbfbfbc8fef635adf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0MTU3Ng==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382141576", "bodyText": "Actually I'm not sure if we want to integrate with Spark's types at this point.", "author": "arhimondr", "createdAt": "2020-02-20T17:16:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc2OTkyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MDQ1Nw==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381770457", "bodyText": "looks like this did nothing for BasicSliceInput ?", "author": "wenleix", "createdAt": "2020-02-20T05:30:57Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceOperator.java", "diffHunk": "@@ -74,18 +81,29 @@ public Page getOutput()\n             return null;\n         }\n \n-        SerializedPage serializedPage = null;\n+        PageBuilder pageBuilder = new PageBuilder(types);\n         synchronized (iterator) {\n-            if (iterator.hasNext()) {\n-                serializedPage = iterator.next();\n+            while (iterator.hasNext() && !pageBuilder.isFull()) {\n+                PrestoSparkRow row = iterator.next();\n+                SliceInput sliceInput = new BasicSliceInput(wrappedBuffer(row.getBytes(), 0, row.getLength()));\n+                pageBuilder.declarePosition();\n+                for (int channel = 0; channel < types.size(); channel++) {\n+                    BlockBuilder blockBuilder = pageBuilder.getBlockBuilder(channel);\n+                    blockBuilder.readPositionFrom(sliceInput);\n+                }\n+                sliceInput.close();", "originalCommit": "15dc6614cb36f515819e831cbfbfbc8fef635adf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0MTcwNQ==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382141705", "bodyText": "Just in case =)", "author": "arhimondr", "createdAt": "2020-02-20T17:17:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MDQ1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MDc5Nw==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381770797", "bodyText": "nit: types is null", "author": "wenleix", "createdAt": "2020-02-20T05:31:41Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRemoteSourceOperator.java", "diffHunk": "@@ -123,17 +141,17 @@ public void noMoreSplits()\n     {\n         private final int operatorId;\n         private final PlanNodeId planNodeId;\n-        private final Iterator<SerializedPage> iterator;\n-        private final PagesSerde serde;\n+        private final Iterator<PrestoSparkRow> iterator;\n+        private final List<Type> types;\n \n         private boolean closed;\n \n-        public SparkRemoteSourceOperatorFactory(int operatorId, PlanNodeId planNodeId, Iterator<SerializedPage> iterator, PagesSerde serde)\n+        public SparkRemoteSourceOperatorFactory(int operatorId, PlanNodeId planNodeId, Iterator<PrestoSparkRow> iterator, List<Type> types)\n         {\n             this.operatorId = operatorId;\n             this.planNodeId = requireNonNull(planNodeId, \"planNodeId is null\");\n             this.iterator = requireNonNull(iterator, \"iterator is null\");\n-            this.serde = requireNonNull(serde, \"serde is null\");\n+            this.types = ImmutableList.copyOf(requireNonNull(types, \"serde is null\"));", "originalCommit": "15dc6614cb36f515819e831cbfbfbc8fef635adf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MjcxMA==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381772710", "bodyText": "I am wondering if we should have a utility function to convert a list of PrestoSparkRow into a list of Blocks? -- we can leave this as TODO .", "author": "wenleix", "createdAt": "2020-02-20T05:35:43Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -270,11 +258,20 @@ private PrestoSparkQueryExecution(\n             queryCompletedEvent(Optional.empty());\n \n             ConnectorSession connectorSession = session.toConnectorSession();\n-            return resultRdd.stream()\n-                    .map(Tuple2::_2)\n-                    .map(this::deserializePage)\n-                    .flatMap(page -> getPageValues(connectorSession, page, rootFragment.getTypes()).stream())\n-                    .collect(toList());\n+            List<Type> types = rootFragment.getTypes();\n+            ImmutableList.Builder<List<Object>> result = ImmutableList.builder();\n+            for (Tuple2<Integer, PrestoSparkRow> tuple : resultRdd) {\n+                PrestoSparkRow row = tuple._2;\n+                SliceInput sliceInput = new BasicSliceInput(Slices.wrappedBuffer(row.getBytes(), 0, row.getLength()));\n+                ImmutableList.Builder<Object> columns = ImmutableList.builder();\n+                for (Type type : types) {", "originalCommit": "15dc6614cb36f515819e831cbfbfbc8fef635adf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzkwOTMyOQ==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383909329", "bodyText": "Currently this is a single place where it is done. Let's keep it here for now.", "author": "arhimondr", "createdAt": "2020-02-25T14:24:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MjcxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MzQ2MA==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381773460", "bodyText": "Why not using ClassLayout.parseClass as we did for other Presto class? -- I am asking this is just adding these bytes together doesn't necessarily sum up to the instance size ,  e.g. there are Java object padding size, etc.", "author": "wenleix", "createdAt": "2020-02-20T05:37:14Z", "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "diffHunk": "@@ -17,18 +17,44 @@\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedPrestoSparkPage\n+public class PrestoSparkRow\n         implements Serializable\n {\n+    private static final int INSTANCE_SIZE = Long.BYTES * 2 /* headers */", "originalCommit": "15dc6614cb36f515819e831cbfbfbc8fef635adf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0MjI1NQ==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382142255", "bodyText": "The Jol library is not in the Spark's classpath, and I don't want to add one to avoid potential clashes.", "author": "arhimondr", "createdAt": "2020-02-20T17:18:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MzQ2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzY2MzYxOA==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383663618", "bodyText": "@arhimondr : Sounds reasonable, just add a comment explain why this is the case.\nAlso, looks like JOL and your calculation returns different results? (You seems to over-estimate): https://gist.github.com/wenleix/faae51ac5fe3c0f688d8520c7c0d3105\nInstance Size from JOL: 24\nInstance Size from Andrii: 32", "author": "wenleix", "createdAt": "2020-02-25T05:20:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3MzQ2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3NDE1MA==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r381774150", "bodyText": "Similarly, we usually use SizeOf.sizeOf(bytes)", "author": "wenleix", "createdAt": "2020-02-20T05:38:38Z", "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "diffHunk": "@@ -17,18 +17,44 @@\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedPrestoSparkPage\n+public class PrestoSparkRow\n         implements Serializable\n {\n+    private static final int INSTANCE_SIZE = Long.BYTES * 2 /* headers */\n+            + Integer.BYTES /* partition */\n+            + Integer.BYTES /* length */\n+            + Long.BYTES /* bytes pointer */\n+            + Long.BYTES * 2 /* bytes headers */\n+            + Integer.BYTES /* bytes length */;\n+\n+    private final int partition;\n+    private final int length;\n     private final byte[] bytes;\n \n-    public SerializedPrestoSparkPage(byte[] bytes)\n+    public PrestoSparkRow(int partition, int length, byte[] bytes)\n     {\n+        this.partition = partition;\n+        this.length = length;\n         this.bytes = requireNonNull(bytes, \"bytes is null\");\n     }\n \n+    public int getPartition()\n+    {\n+        return partition;\n+    }\n+\n+    public int getLength()\n+    {\n+        return length;\n+    }\n+\n     public byte[] getBytes()\n     {\n         return bytes;\n     }\n+\n+    public long getRetainedSize()\n+    {\n+        return INSTANCE_SIZE + bytes.length;", "originalCommit": "15dc6614cb36f515819e831cbfbfbc8fef635adf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjE0MjU4Mg==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382142582", "bodyText": "SizeOf is in Slice library. I don't want to add it to avoid potential clashes.", "author": "arhimondr", "createdAt": "2020-02-20T17:18:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3NDE1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU4NTQyMg==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383585422", "bodyText": "In this case, should we just copy sizeOfByteArray implementation? i.e. something like\n    public long getRetainedSize()\n    {\n        return INSTANCE_SIZE + sizeOfByteArray(bytes.length);\n    }\n\n    // Copied from SizeOf#sizeOfByteArray in Slice library\n    private static long sizeOfByteArray(int length)\n    {\n        return ARRAY_BYTE_BASE_OFFSET + (((long) ARRAY_BYTE_INDEX_SCALE) * length);\n    }", "author": "wenleix", "createdAt": "2020-02-24T23:59:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MTc3NDE1MA=="}], "type": "inlineReview"}, {"oid": "b05ed21ead31462462bc33a85d25a267aaea8137", "url": "https://github.com/prestodb/presto/commit/b05ed21ead31462462bc33a85d25a267aaea8137", "message": "Implement row base exchange in Presto on Spark", "committedDate": "2020-02-20T19:09:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTIwOA==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382965208", "bodyText": "I don't think this needs to be volatile", "author": "tdcmeehan", "createdAt": "2020-02-23T05:17:09Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();\n+    @GuardedBy(\"monitor\")\n+    private volatile boolean finished;", "originalCommit": "b05ed21ead31462462bc33a85d25a267aaea8137", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzM0MjkwMQ==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383342901", "bodyText": "Yes. Since the variable is guarded by lock the volatile modifier is not needed, as the synchronized block guarantees the ordering. However it is generally a good practice to keep the volatile modifier as it doesn't introduce any performance regressions while allowing to use the variable directly without synchronization where compare-and-set semantics are not needed.", "author": "arhimondr", "createdAt": "2020-02-24T15:44:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTIwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU1MTA4MA==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383551080", "bodyText": "I think for boolean/byte/integer, JMM grantees it's an atomic update: https://docs.oracle.com/javase/specs/jls/se8/html/jls-17.html#jls-17.7 .\n@arhimondr : Are you more worried about the \"Happens Before\" memory model ? (See references in #8772 (comment))  . In that case adding volatile guarantees sequentially consistent  memory model :)", "author": "wenleix", "createdAt": "2020-02-24T22:24:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTIwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU1Mjg1Mg==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383552852", "bodyText": "Since this variable is never accessed outside the lock it doesn't have to be volatile as synchronization enforces the memory ordering. It can be safely removed. I added it just in case somebody accidental uses it outside the lock (e.g.: simple atomic read). However now I'm not sure how much of sense does it make. Let me simply remove it to avoid confusion.", "author": "arhimondr", "createdAt": "2020-02-24T22:28:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTIwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTY2MA==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382965660", "bodyText": "Could we use an ArrayBlockingDeque and remove the synchronization in this class?", "author": "tdcmeehan", "createdAt": "2020-02-23T05:26:38Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();", "originalCommit": "b05ed21ead31462462bc33a85d25a267aaea8137", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzM0MzQ3NA==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383343474", "bodyText": "ArrayBlockingDeque blocks based on the number of elements. We want to block based on the memory utilization instead.", "author": "arhimondr", "createdAt": "2020-02-24T15:45:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTY2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzU1MTk1Ng==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383551956", "bodyText": "Discussed offline, a linked blocking queue would work but we'd suffer pointer indirection costs.  There's high performance unbounded array blocking queues out there but not worth the additional dependency.", "author": "tdcmeehan", "createdAt": "2020-02-24T22:26:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTY2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTY5Mw==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r382965693", "bodyText": "Should we clear the buffer as well?", "author": "tdcmeehan", "createdAt": "2020-02-23T05:27:36Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/execution/PrestoSparkRowBuffer.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.spark.execution;\n+\n+import com.facebook.presto.execution.buffer.OutputBufferMemoryManager;\n+import com.facebook.presto.spark.classloader_interface.PrestoSparkRow;\n+import com.google.common.util.concurrent.ListenableFuture;\n+\n+import javax.annotation.concurrent.GuardedBy;\n+\n+import java.util.ArrayDeque;\n+import java.util.Queue;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+public class PrestoSparkRowBuffer\n+{\n+    private final OutputBufferMemoryManager memoryManager;\n+\n+    private final Object monitor = new Object();\n+    @GuardedBy(\"monitor\")\n+    private final Queue<PrestoSparkRow> buffer = new ArrayDeque<>();\n+    @GuardedBy(\"monitor\")\n+    private volatile boolean finished;\n+\n+    public PrestoSparkRowBuffer(OutputBufferMemoryManager memoryManager)\n+    {\n+        this.memoryManager = requireNonNull(memoryManager, \"memoryManager is null\");\n+    }\n+\n+    public ListenableFuture<?> isFull()\n+    {\n+        return memoryManager.getBufferBlockedFuture();\n+    }\n+\n+    public void enqueue(PrestoSparkRow row)\n+    {\n+        requireNonNull(row, \"row is null\");\n+        synchronized (monitor) {\n+            buffer.add(row);\n+            monitor.notify();\n+        }\n+        memoryManager.updateMemoryUsage(row.getRetainedSize());\n+    }\n+\n+    public void setNoMoreRows()\n+    {\n+        memoryManager.setNoBlockOnFull();\n+        synchronized (monitor) {\n+            finished = true;\n+            monitor.notifyAll();", "originalCommit": "b05ed21ead31462462bc33a85d25a267aaea8137", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzM0NDM1NA==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383344354", "bodyText": "No. Buffered rows has to be consumed by the consumer.", "author": "arhimondr", "createdAt": "2020-02-24T15:46:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mjk2NTY5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTYyNw==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383091627", "bodyText": "Have you considered adding something like an overload to getObjectValue that takes in a sliceInput, to avoid having to create the block builder per cell?", "author": "tdcmeehan", "createdAt": "2020-02-24T05:36:54Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkQueryExecutionFactory.java", "diffHunk": "@@ -270,11 +258,20 @@ private PrestoSparkQueryExecution(\n             queryCompletedEvent(Optional.empty());\n \n             ConnectorSession connectorSession = session.toConnectorSession();\n-            return resultRdd.stream()\n-                    .map(Tuple2::_2)\n-                    .map(this::deserializePage)\n-                    .flatMap(page -> getPageValues(connectorSession, page, rootFragment.getTypes()).stream())\n-                    .collect(toList());\n+            List<Type> types = rootFragment.getTypes();\n+            ImmutableList.Builder<List<Object>> result = ImmutableList.builder();\n+            for (Tuple2<Integer, PrestoSparkRow> tuple : resultRdd) {\n+                PrestoSparkRow row = tuple._2;\n+                SliceInput sliceInput = new BasicSliceInput(Slices.wrappedBuffer(row.getBytes(), 0, row.getLength()));\n+                ImmutableList.Builder<Object> columns = ImmutableList.builder();\n+                for (Type type : types) {\n+                    BlockBuilder blockBuilder = type.createBlockBuilder(null, 1);\n+                    blockBuilder.deserializePosition(sliceInput);", "originalCommit": "b05ed21ead31462462bc33a85d25a267aaea8137", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzM0NTAzMw==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383345033", "bodyText": "This is only used to produce the final output to the client, which is not expected to be large.", "author": "arhimondr", "createdAt": "2020-02-24T15:47:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5MTYyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzY2MzI4NQ==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383663285", "bodyText": "bytes headers and bytes length should probably go into sizeOfByteArray?", "author": "wenleix", "createdAt": "2020-02-25T05:18:47Z", "path": "presto-spark-classloader-interface/src/main/java/com/facebook/presto/spark/classloader_interface/PrestoSparkRow.java", "diffHunk": "@@ -17,18 +17,44 @@\n \n import static java.util.Objects.requireNonNull;\n \n-public class SerializedPrestoSparkPage\n+public class PrestoSparkRow\n         implements Serializable\n {\n+    private static final int INSTANCE_SIZE = Long.BYTES * 2 /* headers */\n+            + Integer.BYTES /* partition */\n+            + Integer.BYTES /* length */\n+            + Long.BYTES /* bytes pointer */\n+            + Long.BYTES * 2 /* bytes headers */", "originalCommit": "b05ed21ead31462462bc33a85d25a267aaea8137", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzkxMDA0OA==", "url": "https://github.com/prestodb/presto/pull/14099#discussion_r383910048", "bodyText": "sizeOfByteArray is in the Slice library. It is not available here =\\", "author": "arhimondr", "createdAt": "2020-02-25T14:25:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzY2MzI4NQ=="}], "type": "inlineReview"}, {"oid": "a0708316d18af0d3d6b510a65454c28133929d98", "url": "https://github.com/prestodb/presto/commit/a0708316d18af0d3d6b510a65454c28133929d98", "message": "Implement row base exchange in Presto on Spark", "committedDate": "2020-02-25T14:35:55Z", "type": "forcePushed"}, {"oid": "9ea95d9c20975d3a83f6d2ef6a8337c7232604fb", "url": "https://github.com/prestodb/presto/commit/9ea95d9c20975d3a83f6d2ef6a8337c7232604fb", "message": "Implement row base exchange in Presto on Spark", "committedDate": "2020-02-25T19:08:38Z", "type": "forcePushed"}, {"oid": "224ec928d5372f5abf29ba07475ee5b4d28a73e8", "url": "https://github.com/prestodb/presto/commit/224ec928d5372f5abf29ba07475ee5b4d28a73e8", "message": "Create normal block with all null positions in createAllNullsBlock\n\nIt is somehow not intuitive that the createAllNullsBlock creates an\nRLE block. If the RLE block of a null value is needed - it feels like\nthere should be an explicit method that does that.", "committedDate": "2020-02-25T19:15:54Z", "type": "commit"}, {"oid": "57ba1ad6e3069510b0f7d1bd6d754cfb5d760f59", "url": "https://github.com/prestodb/presto/commit/57ba1ad6e3069510b0f7d1bd6d754cfb5d760f59", "message": "Implement serialize/deserializePosition in Block/BlockBuilder\n\nThese methods will allow to serialize blocks row by row", "committedDate": "2020-02-25T19:15:55Z", "type": "commit"}, {"oid": "c6e991fbfd94c115bc0bdafb020c85643ca62eb2", "url": "https://github.com/prestodb/presto/commit/c6e991fbfd94c115bc0bdafb020c85643ca62eb2", "message": "Refactor LocalExecutionPlanner\n\nAdd additional \"plan\" method that takes a OutputFactory as an input.\n\nIt is different from the existing \"plan\" method (that also takes OutputFactory).\nThe existing version does not create partitioning function, as it is only intended to\nuse by the LocalQueryRunner that doesn't have to partition the data between stages.\nThe new version creates a partitioning function based on the PartitioningScheme and passes\nit as a parameter of the OutputFactory.\n\nThis allows to override OuputOperator behavior without duplicating the code that\ncreates the partitioning function.", "committedDate": "2020-02-25T19:15:56Z", "type": "commit"}, {"oid": "d82cdfbd295b9b627a45be6d4c94934a01b81de9", "url": "https://github.com/prestodb/presto/commit/d82cdfbd295b9b627a45be6d4c94934a01b81de9", "message": "Refactor RemoteSourceFactory\n\nPass list of types as a parameter", "committedDate": "2020-02-25T19:15:57Z", "type": "commit"}, {"oid": "b2d5c4037d512680b1592b7c94f232448bffe4a4", "url": "https://github.com/prestodb/presto/commit/b2d5c4037d512680b1592b7c94f232448bffe4a4", "message": "Implement row base exchange in Presto on Spark", "committedDate": "2020-02-25T19:15:58Z", "type": "commit"}, {"oid": "b2d5c4037d512680b1592b7c94f232448bffe4a4", "url": "https://github.com/prestodb/presto/commit/b2d5c4037d512680b1592b7c94f232448bffe4a4", "message": "Implement row base exchange in Presto on Spark", "committedDate": "2020-02-25T19:15:58Z", "type": "forcePushed"}]}