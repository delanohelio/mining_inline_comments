{"pr_number": 14040, "pr_title": "Move Hive filter pushdown logic out of PickTableLayout", "pr_createdAt": "2020-02-01T01:51:08Z", "pr_url": "https://github.com/prestodb/presto/pull/14040", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc1Njc1MA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r373756750", "bodyText": "this should be injected into HiveConnector. No need to open an interface.", "author": "highker", "createdAt": "2020-02-01T04:20:55Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java", "diffHunk": "@@ -2593,6 +2593,11 @@ public void revokeTablePrivileges(ConnectorSession session, SchemaTableName sche\n         return toCompletableFuture(stagingFileCommitter.commitFiles(session, handle.getSchemaName(), handle.getTableName(), getPartitionUpdates(fragments)));\n     }\n \n+    public FunctionMetadataManager getFunctionMetadataManager()", "originalCommit": "d74e26c2e63460610484c75369ad925154f7397a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDAwNTU3Nw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384005577", "bodyText": "@sachdevs +1. Is there any particular reason to introduce this method?", "author": "mbasmanova", "createdAt": "2020-02-25T17:06:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc1Njc1MA=="}], "type": "inlineReview"}, {"oid": "d3049bc52bee892f804ee2edb95d7f31cc526f8a", "url": "https://github.com/prestodb/presto/commit/d3049bc52bee892f804ee2edb95d7f31cc526f8a", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-03T18:34:33Z", "type": "forcePushed"}, {"oid": "5c5de97bcbf70f260298abb74cbe6b7f44084edc", "url": "https://github.com/prestodb/presto/commit/5c5de97bcbf70f260298abb74cbe6b7f44084edc", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-03T20:56:33Z", "type": "forcePushed"}, {"oid": "6db4a0a05338e05cf74d12276af8ea812bfd06b2", "url": "https://github.com/prestodb/presto/commit/6db4a0a05338e05cf74d12276af8ea812bfd06b2", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-04T01:30:36Z", "type": "forcePushed"}, {"oid": "a6df3ed20b4ae1f2dd23f79ba9595a23d9607da7", "url": "https://github.com/prestodb/presto/commit/a6df3ed20b4ae1f2dd23f79ba9595a23d9607da7", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-05T20:58:28Z", "type": "forcePushed"}, {"oid": "cba93ba95fcb2dd47b4b9be2c5344f549b68d8da", "url": "https://github.com/prestodb/presto/commit/cba93ba95fcb2dd47b4b9be2c5344f549b68d8da", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-05T21:43:44Z", "type": "forcePushed"}, {"oid": "155a2a17645fc737d90477f444576a1cb8b44f81", "url": "https://github.com/prestodb/presto/commit/155a2a17645fc737d90477f444576a1cb8b44f81", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-07T22:12:55Z", "type": "forcePushed"}, {"oid": "6ea7eca7b9e073c2fcb777601b191b2d0007eeb9", "url": "https://github.com/prestodb/presto/commit/6ea7eca7b9e073c2fcb777601b191b2d0007eeb9", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-07T22:23:19Z", "type": "forcePushed"}, {"oid": "7453811611d6a1364f2ec185556170654630ad8f", "url": "https://github.com/prestodb/presto/commit/7453811611d6a1364f2ec185556170654630ad8f", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-08T00:02:00Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc1OTI5NA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r376759294", "bodyText": "We should combine all these visitors into one. No need to separate them apart.", "author": "highker", "createdAt": "2020-02-09T06:38:56Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdownLogicalOptimizer.java", "diffHunk": "@@ -0,0 +1,527 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorPushdownFilterResult;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HiveFilterPushdownLogicalOptimizer\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdownLogicalOptimizer(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        PlanNode newPlan = maxSubplan.accept(new FilterVisitor(session, idAllocator, transactionManager), null);\n+        return newPlan.accept(new TableScanVisitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdownLogicalOptimizer::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    private abstract class Visitor", "originalCommit": "7453811611d6a1364f2ec185556170654630ad8f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI2MjQ0Mw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r377262443", "bodyText": "I'll check if that is doable. Using multiple visitors as the original code had multiple optimizer rules executed one after another. If both rules are executed mutually exclusively then this is possible. I'll check if it works.", "author": "sachdevs", "createdAt": "2020-02-10T19:15:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc1OTI5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc1OTMxNw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r376759317", "bodyText": "This doesn't seem right. It should be return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());. Otherwise, the visitor will stop exploring for such case.", "author": "highker", "createdAt": "2020-02-09T06:39:45Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdownLogicalOptimizer.java", "diffHunk": "@@ -0,0 +1,527 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorPushdownFilterResult;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+public class HiveFilterPushdownLogicalOptimizer\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdownLogicalOptimizer(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        PlanNode newPlan = maxSubplan.accept(new FilterVisitor(session, idAllocator, transactionManager), null);\n+        return newPlan.accept(new TableScanVisitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdownLogicalOptimizer::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    private abstract class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        protected final ConnectorSession session;\n+        protected final PlanNodeIdAllocator idAllocator;\n+        protected final HiveTransactionManager transactionManager;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator,\n+                HiveTransactionManager transactionManager)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+            this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+    }\n+\n+    private class FilterVisitor\n+            extends Visitor\n+    {\n+        FilterVisitor(ConnectorSession session, PlanNodeIdAllocator idAllocator, HiveTransactionManager transactionManager)\n+        {\n+            super(session, idAllocator, transactionManager);\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return filter;", "originalCommit": "7453811611d6a1364f2ec185556170654630ad8f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI2MjU2Nw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r377262567", "bodyText": "Nice catch :)", "author": "sachdevs", "createdAt": "2020-02-10T19:15:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Njc1OTMxNw=="}], "type": "inlineReview"}, {"oid": "78504d28d98fbf4946ae4a228364d7a5cc6daa08", "url": "https://github.com/prestodb/presto/commit/78504d28d98fbf4946ae4a228364d7a5cc6daa08", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-10T18:54:04Z", "type": "forcePushed"}, {"oid": "8a767ea02eeaff3fe7d0a4a96fd336956de78ae8", "url": "https://github.com/prestodb/presto/commit/8a767ea02eeaff3fe7d0a4a96fd336956de78ae8", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-10T23:37:40Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM4Mjg5Mw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r377382893", "bodyText": "This part of the test verification can no longer occur in this way as we cannot explicitly call metadata.pushdownFilter", "author": "sachdevs", "createdAt": "2020-02-10T23:42:21Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -2052,15 +2050,15 @@ private void doTestBucketedTableEvolution(HiveStorageFormat storageFormat, Schem\n \n             NullableValue singleBucket = NullableValue.of(INTEGER, 6L);\n             ConnectorTableLayoutHandle layoutHandle;\n-            if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n-                TupleDomain<VariableReferenceExpression> bucketDomain = TupleDomain.fromFixedValues(ImmutableMap.of(new VariableReferenceExpression(BUCKET_COLUMN_NAME, BIGINT), singleBucket));\n-\n-                RowExpression predicate = ROW_EXPRESSION_SERVICE.getDomainTranslator().toPredicate(bucketDomain);\n-                layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-            }\n-            else {\n-                layoutHandle = getOnlyElement(metadata.getTableLayouts(session, tableHandle, new Constraint<>(TupleDomain.fromFixedValues(ImmutableMap.of(bucketColumnHandle(), singleBucket))), Optional.empty())).getTableLayout().getHandle();\n-            }\n+//            if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n+//                TupleDomain<VariableReferenceExpression> bucketDomain = TupleDomain.fromFixedValues(ImmutableMap.of(new VariableReferenceExpression(BUCKET_COLUMN_NAME, BIGINT), singleBucket));\n+//\n+//                RowExpression predicate = ROW_EXPRESSION_SERVICE.getDomainTranslator().toPredicate(bucketDomain);\n+//                layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n+//            }\n+//            else {\n+            layoutHandle = getOnlyElement(metadata.getTableLayouts(session, tableHandle, new Constraint<>(TupleDomain.fromFixedValues(ImmutableMap.of(bucketColumnHandle(), singleBucket))), Optional.empty())).getTableLayout().getHandle();\n+//            }", "originalCommit": "8a767ea02eeaff3fe7d0a4a96fd336956de78ae8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM4Mjk1MA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r377382950", "bodyText": "ditto.", "author": "sachdevs", "createdAt": "2020-02-10T23:42:32Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -2373,12 +2371,12 @@ public void testPartitionSchemaNonCanonical()\n \n     private static ConnectorTableLayout getTableLayout(ConnectorSession session, ConnectorMetadata metadata, ConnectorTableHandle tableHandle, Constraint<ColumnHandle> constraint)\n     {\n-        if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n-            assertTrue(constraint.getSummary().isAll());\n-\n-            ConnectorPushdownFilterResult pushdownFilterResult = metadata.pushdownFilter(session, tableHandle, TRUE_CONSTANT, Optional.empty());\n-            return pushdownFilterResult.getLayout();\n-        }\n+//        if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n+//            assertTrue(constraint.getSummary().isAll());\n+//\n+//            ConnectorPushdownFilterResult pushdownFilterResult = metadata.pushdownFilter(session, tableHandle, TRUE_CONSTANT, Optional.empty());\n+//            return pushdownFilterResult.getLayout();\n+//        }\n ", "originalCommit": "8a767ea02eeaff3fe7d0a4a96fd336956de78ae8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "url": "https://github.com/prestodb/presto/commit/a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-11T19:48:24Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ0NDc3Mg==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378444772", "bodyText": "not used", "author": "highker", "createdAt": "2020-02-12T18:50:40Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final HiveTransactionManager transactionManager;", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ0NTI1NQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378445255", "bodyText": "nit node", "author": "highker", "createdAt": "2020-02-12T18:51:33Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final HiveTransactionManager transactionManager;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator,\n+                HiveTransactionManager transactionManager)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+            this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), replacedExpression, tableScan.getTable().getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            TableScanNode ret = new TableScanNode(", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ0OTY1OQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378449659", "bodyText": "static", "author": "highker", "createdAt": "2020-02-12T18:59:31Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final HiveTransactionManager transactionManager;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator,\n+                HiveTransactionManager transactionManager)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+            this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), replacedExpression, tableScan.getTable().getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            TableScanNode ret = new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    layout.getPredicate(),\n+                    TupleDomain.all());\n+\n+            RowExpression unenforcedFilter = pushdownFilterResult.getUnenforcedConstraint();\n+            if (!TRUE_CONSTANT.equals(unenforcedFilter)) {\n+                return new FilterNode(idAllocator.getNextId(), ret, replaceExpression(unenforcedFilter, symbolToColumnMapping.inverse()));\n+            }\n+\n+            return ret;\n+        }\n+\n+        @Override\n+        public PlanNode visitTableScan(TableScanNode tableScan, Void context)\n+        {\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return tableScan;\n+            }\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), TRUE_CONSTANT, tableScan.getTable().getLayout());\n+            if (pushdownFilterResult.getLayout().getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            return new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    pushdownFilterResult.getLayout().getPredicate(),\n+                    TupleDomain.all());\n+        }\n+    }\n+\n+    private static class ConstraintEvaluator\n+    {\n+        private final Map<String, ColumnHandle> assignments;\n+        private final RowExpressionService evaluator;\n+        private final ConnectorSession session;\n+        private final RowExpression expression;\n+        private final Set<ColumnHandle> arguments;\n+\n+        public ConstraintEvaluator(RowExpressionService evaluator, ConnectorSession session, Map<String, ColumnHandle> assignments, RowExpression expression)\n+        {\n+            this.assignments = assignments;\n+            this.evaluator = evaluator;\n+            this.session = session;\n+            this.expression = expression;\n+\n+            arguments = ImmutableSet.copyOf(extractAll(expression)).stream()\n+                    .map(VariableReferenceExpression::getName)\n+                    .map(assignments::get)\n+                    .collect(toImmutableSet());\n+        }\n+\n+        private boolean isCandidate(Map<ColumnHandle, NullableValue> bindings)\n+        {\n+            if (intersection(bindings.keySet(), arguments).isEmpty()) {\n+                return true;\n+            }\n+\n+            Function<VariableReferenceExpression, Object> variableResolver = variable -> {\n+                ColumnHandle column = assignments.get(variable.getName());\n+                checkArgument(column != null, \"Missing column assignment for %s\", variable);\n+\n+                if (!bindings.containsKey(column)) {\n+                    return variable;\n+                }\n+\n+                return bindings.get(column).getValue();\n+            };\n+\n+            // Skip pruning if evaluation fails in a recoverable way. Failing here can cause\n+            // spurious query failures for partitions that would otherwise be filtered out.\n+            Object optimized = null;\n+            try {\n+                optimized = evaluator.getExpressionOptimizer().optimize(expression, OPTIMIZED, session, variableResolver);\n+            }\n+            catch (PrestoException e) {\n+                propagateIfUnhandled(e);\n+            }\n+\n+            // If any conjuncts evaluate to FALSE or null, then the whole predicate will never be true and so the partition should be pruned\n+            return !Boolean.FALSE.equals(optimized) && optimized != null && (!(optimized instanceof ConstantExpression) || !((ConstantExpression) optimized).isNull());\n+        }\n+\n+        private static void propagateIfUnhandled(PrestoException e)\n+                throws PrestoException\n+        {\n+            int errorCode = e.getErrorCode().getCode();\n+            if (errorCode == DIVISION_BY_ZERO.toErrorCode().getCode()\n+                    || errorCode == INVALID_CAST_ARGUMENT.toErrorCode().getCode()\n+                    || errorCode == INVALID_FUNCTION_ARGUMENT.toErrorCode().getCode()\n+                    || errorCode == NUMERIC_VALUE_OUT_OF_RANGE.toErrorCode().getCode()) {\n+                return;\n+            }\n+\n+            throw e;\n+        }\n+    }\n+\n+    private HiveMetadata getMetadata(TableHandle tableHandle)\n+    {\n+        ConnectorMetadata metadata = transactionManager.get(tableHandle.getTransaction());\n+        checkState(metadata instanceof HiveMetadata, \"metadata must be HiveMetadata\");\n+        return (HiveMetadata) metadata;\n+    }\n+\n+    private String getColumnName(ConnectorSession session, HiveMetadata metadata, ConnectorTableHandle tableHandle, ColumnHandle columnHandle)\n+    {\n+        return metadata.getColumnMetadata(session, tableHandle, columnHandle).getName();\n+    }\n+\n+    private boolean isPushdownFilterSupported(ConnectorSession session, TableHandle tableHandle)\n+    {\n+        checkArgument(tableHandle.getConnectorHandle() instanceof HiveTableHandle, \"pushdownFilter is never supported on a non-hive TableHandle\");\n+        if (((HiveTableHandle) tableHandle.getConnectorHandle()).getAnalyzePartitionValues().isPresent()) {\n+            return false;\n+        }\n+\n+        boolean pushdownFilterEnabled = HiveSessionProperties.isPushdownFilterEnabled(session);\n+        if (pushdownFilterEnabled) {\n+            HiveStorageFormat hiveStorageFormat = getHiveStorageFormat(getMetadata(tableHandle).getTableMetadata(session, tableHandle.getConnectorHandle()).getProperties());\n+            if (hiveStorageFormat == HiveStorageFormat.ORC || hiveStorageFormat == HiveStorageFormat.DWRF) {\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n+    private DomainTranslator.ExtractionResult intersectExtractionResult(DomainTranslator.ExtractionResult left, DomainTranslator.ExtractionResult right)", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ0OTc4NQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378449785", "bodyText": "static, same for other helpers", "author": "highker", "createdAt": "2020-02-12T18:59:48Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator, transactionManager), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+        private final HiveTransactionManager transactionManager;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator,\n+                HiveTransactionManager transactionManager)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+            this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), replacedExpression, tableScan.getTable().getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            TableScanNode ret = new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    layout.getPredicate(),\n+                    TupleDomain.all());\n+\n+            RowExpression unenforcedFilter = pushdownFilterResult.getUnenforcedConstraint();\n+            if (!TRUE_CONSTANT.equals(unenforcedFilter)) {\n+                return new FilterNode(idAllocator.getNextId(), ret, replaceExpression(unenforcedFilter, symbolToColumnMapping.inverse()));\n+            }\n+\n+            return ret;\n+        }\n+\n+        @Override\n+        public PlanNode visitTableScan(TableScanNode tableScan, Void context)\n+        {\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return tableScan;\n+            }\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), TRUE_CONSTANT, tableScan.getTable().getLayout());\n+            if (pushdownFilterResult.getLayout().getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            return new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    pushdownFilterResult.getLayout().getPredicate(),\n+                    TupleDomain.all());\n+        }\n+    }\n+\n+    private static class ConstraintEvaluator\n+    {\n+        private final Map<String, ColumnHandle> assignments;\n+        private final RowExpressionService evaluator;\n+        private final ConnectorSession session;\n+        private final RowExpression expression;\n+        private final Set<ColumnHandle> arguments;\n+\n+        public ConstraintEvaluator(RowExpressionService evaluator, ConnectorSession session, Map<String, ColumnHandle> assignments, RowExpression expression)\n+        {\n+            this.assignments = assignments;\n+            this.evaluator = evaluator;\n+            this.session = session;\n+            this.expression = expression;\n+\n+            arguments = ImmutableSet.copyOf(extractAll(expression)).stream()\n+                    .map(VariableReferenceExpression::getName)\n+                    .map(assignments::get)\n+                    .collect(toImmutableSet());\n+        }\n+\n+        private boolean isCandidate(Map<ColumnHandle, NullableValue> bindings)\n+        {\n+            if (intersection(bindings.keySet(), arguments).isEmpty()) {\n+                return true;\n+            }\n+\n+            Function<VariableReferenceExpression, Object> variableResolver = variable -> {\n+                ColumnHandle column = assignments.get(variable.getName());\n+                checkArgument(column != null, \"Missing column assignment for %s\", variable);\n+\n+                if (!bindings.containsKey(column)) {\n+                    return variable;\n+                }\n+\n+                return bindings.get(column).getValue();\n+            };\n+\n+            // Skip pruning if evaluation fails in a recoverable way. Failing here can cause\n+            // spurious query failures for partitions that would otherwise be filtered out.\n+            Object optimized = null;\n+            try {\n+                optimized = evaluator.getExpressionOptimizer().optimize(expression, OPTIMIZED, session, variableResolver);\n+            }\n+            catch (PrestoException e) {\n+                propagateIfUnhandled(e);\n+            }\n+\n+            // If any conjuncts evaluate to FALSE or null, then the whole predicate will never be true and so the partition should be pruned\n+            return !Boolean.FALSE.equals(optimized) && optimized != null && (!(optimized instanceof ConstantExpression) || !((ConstantExpression) optimized).isNull());\n+        }\n+\n+        private static void propagateIfUnhandled(PrestoException e)\n+                throws PrestoException\n+        {\n+            int errorCode = e.getErrorCode().getCode();\n+            if (errorCode == DIVISION_BY_ZERO.toErrorCode().getCode()\n+                    || errorCode == INVALID_CAST_ARGUMENT.toErrorCode().getCode()\n+                    || errorCode == INVALID_FUNCTION_ARGUMENT.toErrorCode().getCode()\n+                    || errorCode == NUMERIC_VALUE_OUT_OF_RANGE.toErrorCode().getCode()) {\n+                return;\n+            }\n+\n+            throw e;\n+        }\n+    }\n+\n+    private HiveMetadata getMetadata(TableHandle tableHandle)\n+    {\n+        ConnectorMetadata metadata = transactionManager.get(tableHandle.getTransaction());\n+        checkState(metadata instanceof HiveMetadata, \"metadata must be HiveMetadata\");\n+        return (HiveMetadata) metadata;\n+    }\n+\n+    private String getColumnName(ConnectorSession session, HiveMetadata metadata, ConnectorTableHandle tableHandle, ColumnHandle columnHandle)\n+    {\n+        return metadata.getColumnMetadata(session, tableHandle, columnHandle).getName();\n+    }\n+\n+    private boolean isPushdownFilterSupported(ConnectorSession session, TableHandle tableHandle)\n+    {\n+        checkArgument(tableHandle.getConnectorHandle() instanceof HiveTableHandle, \"pushdownFilter is never supported on a non-hive TableHandle\");\n+        if (((HiveTableHandle) tableHandle.getConnectorHandle()).getAnalyzePartitionValues().isPresent()) {\n+            return false;\n+        }\n+\n+        boolean pushdownFilterEnabled = HiveSessionProperties.isPushdownFilterEnabled(session);\n+        if (pushdownFilterEnabled) {\n+            HiveStorageFormat hiveStorageFormat = getHiveStorageFormat(getMetadata(tableHandle).getTableMetadata(session, tableHandle.getConnectorHandle()).getProperties());\n+            if (hiveStorageFormat == HiveStorageFormat.ORC || hiveStorageFormat == HiveStorageFormat.DWRF) {\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n+    private DomainTranslator.ExtractionResult intersectExtractionResult(DomainTranslator.ExtractionResult left, DomainTranslator.ExtractionResult right)\n+    {\n+        RowExpression newRemainingExpression;\n+        if (right.getRemainingExpression().equals(TRUE_CONSTANT)) {\n+            newRemainingExpression = left.getRemainingExpression();\n+        }\n+        else if (left.getRemainingExpression().equals(TRUE_CONSTANT)) {\n+            newRemainingExpression = right.getRemainingExpression();\n+        }\n+        else {\n+            newRemainingExpression = and(left.getRemainingExpression(), right.getRemainingExpression());\n+        }\n+        return new DomainTranslator.ExtractionResult(left.getTupleDomain().intersect(right.getTupleDomain()), newRemainingExpression);\n+    }\n+\n+    private boolean isEntireColumn(Subfield subfield)", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1MTE1OA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378451158", "bodyText": "Explain more how to use ConnectorPlanOptimizer as the way to pushdown compute.", "author": "highker", "createdAt": "2020-02-12T19:02:26Z", "path": "presto-main/src/main/java/com/facebook/presto/metadata/Metadata.java", "diffHunk": "@@ -100,18 +99,11 @@\n     TableHandle getAlternativeTableHandle(Session session, TableHandle tableHandle, PartitioningHandle partitioningHandle);\n \n     /**\n-     * Experimental: if true, the engine will invoke pushdownFilter instead of getLayout.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n-     */\n-    boolean isPushdownFilterSupported(Session session, TableHandle tableHandle);\n-\n-    /**\n-     * Experimental: returns table layout that encapsulates the given filter.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n+     * Experimental: if true, the engine will invoke getLayout otherwise, getLayout will not be called.\n+     * This function remains to ensure backwards compatibility, it needs to be removed.", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU2ODgxMQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378568811", "bodyText": "Let me know if the description I added is sufficient.", "author": "sachdevs", "createdAt": "2020-02-12T23:17:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1MTE1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1MzIzOQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378453239", "bodyText": "Add a comment to explain \"new filters can be created and we need to merge them together\" something like that", "author": "highker", "createdAt": "2020-02-12T19:06:27Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java", "diffHunk": "@@ -13,24 +13,53 @@\n  */\n package com.facebook.presto.hive.rule;\n \n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.connector.ConnectorPlanOptimizerProvider;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n import com.google.common.collect.ImmutableSet;\n+import com.google.inject.Inject;\n \n import java.util.Set;\n \n+import static java.util.Objects.requireNonNull;\n+\n public class HivePlanOptimizerProvider\n         implements ConnectorPlanOptimizerProvider\n {\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    @Inject\n+    public HivePlanOptimizerProvider(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n     @Override\n     public Set<ConnectorPlanOptimizer> getLogicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        return ImmutableSet.of(new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager));\n     }\n \n     @Override\n     public Set<ConnectorPlanOptimizer> getPhysicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        return ImmutableSet.of(new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager));", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1MzgwMA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378453800", "bodyText": "Just remove. They don't hold anymore", "author": "highker", "createdAt": "2020-02-12T19:07:36Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -1373,29 +1371,29 @@ protected void doTestMismatchSchemaTable(\n             MaterializedResult result = readTable(transaction, tableHandle, columnHandles, session, TupleDomain.all(), OptionalInt.empty(), Optional.empty());\n             assertEqualsIgnoreOrder(result.getMaterializedRows(), dataAfter.getMaterializedRows());\n \n-            int filterCount = afterFilters.size();\n-            for (int i = 0; i < filterCount; i++) {\n-                RowExpression predicate = afterFilters.get(i);\n-                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-\n-                // Read all columns with a filter\n-                MaterializedResult filteredResult = readTable(transaction, tableHandle, layoutHandle, columnHandles, session, OptionalInt.empty(), Optional.empty());\n-\n-                Predicate<MaterializedRow> rowPredicate = afterResultPredicates.get(i);\n-                List<MaterializedRow> expectedRows = dataAfter.getMaterializedRows().stream().filter(rowPredicate::apply).collect(toList());\n-\n-                assertEqualsIgnoreOrder(filteredResult.getMaterializedRows(), expectedRows);\n-\n-                // Read all columns except the ones used in the filter\n-                Set<String> filterColumnNames = extractUnique(predicate).stream().map(VariableReferenceExpression::getName).collect(toImmutableSet());\n-\n-                List<ColumnHandle> nonFilterColumns = columnHandles.stream()\n-                        .filter(column -> !filterColumnNames.contains(((HiveColumnHandle) column).getName()))\n-                        .collect(toList());\n-\n-                int resultCount = readTable(transaction, tableHandle, layoutHandle, nonFilterColumns, session, OptionalInt.empty(), Optional.empty()).getRowCount();\n-                assertEquals(resultCount, expectedRows.size());\n-            }\n+//            int filterCount = afterFilters.size();\n+//            for (int i = 0; i < filterCount; i++) {\n+//                RowExpression predicate = afterFilters.get(i);\n+//                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n+//\n+//                // Read all columns with a filter\n+//                MaterializedResult filteredResult = readTable(transaction, tableHandle, layoutHandle, columnHandles, session, OptionalInt.empty(), Optional.empty());\n+//\n+//                Predicate<MaterializedRow> rowPredicate = afterResultPredicates.get(i);\n+//                List<MaterializedRow> expectedRows = dataAfter.getMaterializedRows().stream().filter(rowPredicate::apply).collect(toList());\n+//\n+//                assertEqualsIgnoreOrder(filteredResult.getMaterializedRows(), expectedRows);\n+//\n+//                // Read all columns except the ones used in the filter\n+//                Set<String> filterColumnNames = extractUnique(predicate).stream().map(VariableReferenceExpression::getName).collect(toImmutableSet());\n+//\n+//                List<ColumnHandle> nonFilterColumns = columnHandles.stream()\n+//                        .filter(column -> !filterColumnNames.contains(((HiveColumnHandle) column).getName()))\n+//                        .collect(toList());\n+//\n+//                int resultCount = readTable(transaction, tableHandle, layoutHandle, nonFilterColumns, session, OptionalInt.empty(), Optional.empty()).getRowCount();\n+//                assertEquals(resultCount, expectedRows.size());\n+//            }", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1Mzg5MA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378453890", "bodyText": "same", "author": "highker", "createdAt": "2020-02-12T19:07:46Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -2052,15 +2050,15 @@ private void doTestBucketedTableEvolution(HiveStorageFormat storageFormat, Schem\n \n             NullableValue singleBucket = NullableValue.of(INTEGER, 6L);\n             ConnectorTableLayoutHandle layoutHandle;\n-            if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n-                TupleDomain<VariableReferenceExpression> bucketDomain = TupleDomain.fromFixedValues(ImmutableMap.of(new VariableReferenceExpression(BUCKET_COLUMN_NAME, BIGINT), singleBucket));\n-\n-                RowExpression predicate = ROW_EXPRESSION_SERVICE.getDomainTranslator().toPredicate(bucketDomain);\n-                layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-            }\n-            else {\n-                layoutHandle = getOnlyElement(metadata.getTableLayouts(session, tableHandle, new Constraint<>(TupleDomain.fromFixedValues(ImmutableMap.of(bucketColumnHandle(), singleBucket))), Optional.empty())).getTableLayout().getHandle();\n-            }\n+//            if (HiveSessionProperties.isPushdownFilterEnabled(session)) {\n+//                TupleDomain<VariableReferenceExpression> bucketDomain = TupleDomain.fromFixedValues(ImmutableMap.of(new VariableReferenceExpression(BUCKET_COLUMN_NAME, BIGINT), singleBucket));\n+//\n+//                RowExpression predicate = ROW_EXPRESSION_SERVICE.getDomainTranslator().toPredicate(bucketDomain);\n+//                layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n+//            }\n+//            else {\n+            layoutHandle = getOnlyElement(metadata.getTableLayouts(session, tableHandle, new Constraint<>(TupleDomain.fromFixedValues(ImmutableMap.of(bucketColumnHandle(), singleBucket))), Optional.empty())).getTableLayout().getHandle();\n+//            }", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378462068", "bodyText": "@sachdevs Why is this code commented out?", "author": "mbasmanova", "createdAt": "2020-02-12T19:23:02Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -1373,29 +1371,29 @@ protected void doTestMismatchSchemaTable(\n             MaterializedResult result = readTable(transaction, tableHandle, columnHandles, session, TupleDomain.all(), OptionalInt.empty(), Optional.empty());\n             assertEqualsIgnoreOrder(result.getMaterializedRows(), dataAfter.getMaterializedRows());\n \n-            int filterCount = afterFilters.size();\n-            for (int i = 0; i < filterCount; i++) {\n-                RowExpression predicate = afterFilters.get(i);\n-                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n-\n-                // Read all columns with a filter\n-                MaterializedResult filteredResult = readTable(transaction, tableHandle, layoutHandle, columnHandles, session, OptionalInt.empty(), Optional.empty());\n-\n-                Predicate<MaterializedRow> rowPredicate = afterResultPredicates.get(i);\n-                List<MaterializedRow> expectedRows = dataAfter.getMaterializedRows().stream().filter(rowPredicate::apply).collect(toList());\n-\n-                assertEqualsIgnoreOrder(filteredResult.getMaterializedRows(), expectedRows);\n-\n-                // Read all columns except the ones used in the filter\n-                Set<String> filterColumnNames = extractUnique(predicate).stream().map(VariableReferenceExpression::getName).collect(toImmutableSet());\n-\n-                List<ColumnHandle> nonFilterColumns = columnHandles.stream()\n-                        .filter(column -> !filterColumnNames.contains(((HiveColumnHandle) column).getName()))\n-                        .collect(toList());\n-\n-                int resultCount = readTable(transaction, tableHandle, layoutHandle, nonFilterColumns, session, OptionalInt.empty(), Optional.empty()).getRowCount();\n-                assertEquals(resultCount, expectedRows.size());\n-            }\n+//            int filterCount = afterFilters.size();", "originalCommit": "a6e1a854ca9aff28d95436a24a962f7e0ec5de23", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU2NDI3MA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378564270", "bodyText": "We can no longer test by calling metadata.pushdownFilter in our tests. These commented out blocks (see above comments in the PR) were left in just so that it is clear that it is clear that they are obsolete (and to draw attention to it for the reviewers :) ).\nIt is no longer possible to get the connector table layout handle without invoking the entire plan optimizer and maybe doing an assertPlan(...). I am removing these now.\nI'm unsure if there's another way to rewrite this logic or the tests that inherit from AbstractTestHiveClient that depend on this logic. Let me know if you have any alternative ideas.", "author": "sachdevs", "createdAt": "2020-02-12T23:04:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODYzMzYyOA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378633628", "bodyText": "@sachdevs These tests are providing coverage for important scenarios, e.g. schema evolution. I don't believe we have that coverage anywhere else. Simply removing this coverage is undesirable. We need to figure out a replacement.\nCC: @bhhari @yingsu00 @oerling", "author": "mbasmanova", "createdAt": "2020-02-13T03:25:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODY3OTA3Nw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378679077", "bodyText": "@sachdevs @mbasmanova, a quick workaround is to keep the original pushdownFilter for HiveMetadata (i.e., moving pushdownFilter from HiveFilterPushdown to HiveMetadata). Then in the test, we downcast ConnectorMetadata to HiveMetadata to still call pushdownFilter. WDYT?", "author": "highker", "createdAt": "2020-02-13T06:53:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODY5NTY2OQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378695669", "bodyText": "It tests function pushdownFilter, isn't it?", "author": "highker", "createdAt": "2020-02-13T07:45:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODY5Nzg1Ng==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r378697856", "bodyText": "I can try that out - just need to verify that has no impact on Prism (but should be fine). @mbasmanova ?", "author": "sachdevs", "createdAt": "2020-02-13T07:52:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA1MzkyMg==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379053922", "bodyText": "It tests function pushdownFilter, isn't it?\n\nYeah, I misunderstood your comment earlier.", "author": "sachdevs", "createdAt": "2020-02-13T18:53:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ2MjA2OA=="}], "type": "inlineReview"}, {"oid": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "url": "https://github.com/prestodb/presto/commit/37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-12T23:19:07Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMDUzNg==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379310536", "bodyText": "Consider editing for brevity and clarity:\n/**\n * Runs during both logical and physical phases of connector-aided plan optimization.\n * In most cases filter pushdown will occur during logical phase. However, in cases \n * when new filter is added between logical and physical phases, e.g. a filter on a join \n * key from one side of a join is added to the other side, the new filter will get\n * merged with the one already pushed down.\n */", "author": "mbasmanova", "createdAt": "2020-02-14T08:49:50Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMTIyOQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379311229", "bodyText": "perhaps, drop Connector prefix here: PushdownFilterResult\nmake private", "author": "mbasmanova", "createdAt": "2020-02-14T08:51:25Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTY4Nzc5Ng==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379687796", "bodyText": "See the corresponding PR in prism. These functions need to be protected. Let me know if there's a cleaner way that doesnt cause confusion in open source.", "author": "sachdevs", "createdAt": "2020-02-14T23:26:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMTIyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMTQzNQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379311435", "bodyText": "make this private", "author": "mbasmanova", "createdAt": "2020-02-14T08:51:51Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTY4NzgzNQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379687835", "bodyText": "same", "author": "sachdevs", "createdAt": "2020-02-14T23:26:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMTQzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMTcwMg==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379311702", "bodyText": "nit: put arguments on a single line: Visitor(ConnectorSession session, PlanNodeIdAllocator idAllocator)", "author": "mbasmanova", "createdAt": "2020-02-14T08:52:28Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+\n+        Visitor(", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMzA5Mg==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379313092", "bodyText": "no need to create new object if source didn't change; perhaps, just call visitPlan: return visitPlan(filter, context);", "author": "mbasmanova", "createdAt": "2020-02-14T08:55:38Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTY4Nzg4Nw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379687887", "bodyText": "nice", "author": "sachdevs", "createdAt": "2020-02-14T23:27:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxMzA5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxNDQ4OQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379314489", "bodyText": "move this variable up and re-use", "author": "mbasmanova", "createdAt": "2020-02-14T08:58:52Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,530 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * HiveFilterPushdown is an optimizer that runs at both the logical and physical phases of connector-aided plan optimization.\n+ * The purpose of this is to intersect the domains of any extra filters that may be added after the logical phase of planning.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metadata.getMetastore(), tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(session, tableName, hivePartitionResult.getBucketHandle(), hivePartitionResult.getBucketFilter(), decomposedFilter.getRemainingExpression(), domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    protected static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+\n+        Visitor(\n+                ConnectorSession session,\n+                PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return new FilterNode(filter.getId(), filter.getSource().accept(this, null), filter.getPredicate());\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), replacedExpression, tableScan.getTable().getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();\n+            TableScanNode node = new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    layout.getPredicate(),\n+                    TupleDomain.all());\n+\n+            RowExpression unenforcedFilter = pushdownFilterResult.getUnenforcedConstraint();\n+            if (!TRUE_CONSTANT.equals(unenforcedFilter)) {\n+                return new FilterNode(idAllocator.getNextId(), node, replaceExpression(unenforcedFilter, symbolToColumnMapping.inverse()));\n+            }\n+\n+            return node;\n+        }\n+\n+        @Override\n+        public PlanNode visitTableScan(TableScanNode tableScan, Void context)\n+        {\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return tableScan;\n+            }\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(session, hiveMetadata, tableScan.getTable().getConnectorHandle(), TRUE_CONSTANT, tableScan.getTable().getLayout());\n+            if (pushdownFilterResult.getLayout().getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxNTU0NQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379315545", "bodyText": "any reason to make a new HiveFilterPushdown object here? Can the same object be re-used in logical and physical phases?", "author": "mbasmanova", "createdAt": "2020-02-14T09:01:14Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java", "diffHunk": "@@ -13,24 +13,54 @@\n  */\n package com.facebook.presto.hive.rule;\n \n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.connector.ConnectorPlanOptimizerProvider;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n import com.google.common.collect.ImmutableSet;\n+import com.google.inject.Inject;\n \n import java.util.Set;\n \n+import static java.util.Objects.requireNonNull;\n+\n public class HivePlanOptimizerProvider\n         implements ConnectorPlanOptimizerProvider\n {\n+    private final HiveTransactionManager transactionManager;\n+    private final RowExpressionService rowExpressionService;\n+    private final StandardFunctionResolution functionResolution;\n+    private final HivePartitionManager partitionManager;\n+    private final FunctionMetadataManager functionMetadataManager;\n+\n+    @Inject\n+    public HivePlanOptimizerProvider(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n     @Override\n     public Set<ConnectorPlanOptimizer> getLogicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        return ImmutableSet.of(new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager));\n     }\n \n     @Override\n     public Set<ConnectorPlanOptimizer> getPhysicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        // New filters may be created in between logical optimization and physical optimization. Push those newly created filters as well.\n+        return ImmutableSet.of(new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager));", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDkwMzM0MQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r380903341", "bodyText": "It can - good catch.", "author": "sachdevs", "createdAt": "2020-02-18T20:00:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxNTU0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxNzYxOA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379317618", "bodyText": "Based on the description, I'd rename this method to isLegacyGetLayoutSupported. What kind of backwards compatibility is needed here?", "author": "mbasmanova", "createdAt": "2020-02-14T09:06:09Z", "path": "presto-main/src/main/java/com/facebook/presto/metadata/Metadata.java", "diffHunk": "@@ -100,18 +99,13 @@\n     TableHandle getAlternativeTableHandle(Session session, TableHandle tableHandle, PartitioningHandle partitioningHandle);\n \n     /**\n-     * Experimental: if true, the engine will invoke pushdownFilter instead of getLayout.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n-     */\n-    boolean isPushdownFilterSupported(Session session, TableHandle tableHandle);\n-\n-    /**\n-     * Experimental: returns table layout that encapsulates the given filter.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n+     * Experimental: if true, the engine will invoke getLayout otherwise, getLayout will not be called.\n+     * This function remains to ensure backwards compatibility, it needs to be removed.\n+     * If filter pushdown is required, use a ConnectorPlanOptimizer in the respective connector in order\n+     * to push compute into it's TableScan.\n      */\n-    PushdownFilterResult pushdownFilter(Session session, TableHandle tableHandle, RowExpression filter);\n+    @Deprecated\n+    boolean isPredicatePushdownEnabled(Session session, TableHandle tableHandle);", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDkxMDk2Nw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r380910967", "bodyText": "Essentially PickTableLayout needs to know that it should not invoke getLayout for queries in which predicatePushdown is enabled. PickTableLayout logic is currently mutually exclusive with pushdownFilter logic. This is the \"backwards compatibility\" that needs to be supported.\nI do think calling this function \"isLegacyGetLayoutSupported\" is an apt name. However, when reading PickTableLayout pushPredicateIntoTableScan is only called when ! isPredicatePushdownEnabled. Hence in that context, isPredicatePushdownEnabled may make more sense.\nLet me know if you still think that the name may be misleading or if we can come up with a better a comment to represent what it actually does.", "author": "sachdevs", "createdAt": "2020-02-18T20:15:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxNzYxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxOTMxNA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r379319314", "bodyText": "perhaps, make com.facebook.presto.hive.rule.HiveFilterPushdown#pushdownFilter @VisibleForTesting and use here?", "author": "mbasmanova", "createdAt": "2020-02-14T09:10:12Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -1373,30 +1371,6 @@ protected void doTestMismatchSchemaTable(\n             MaterializedResult result = readTable(transaction, tableHandle, columnHandles, session, TupleDomain.all(), OptionalInt.empty(), Optional.empty());\n             assertEqualsIgnoreOrder(result.getMaterializedRows(), dataAfter.getMaterializedRows());\n \n-            int filterCount = afterFilters.size();\n-            for (int i = 0; i < filterCount; i++) {\n-                RowExpression predicate = afterFilters.get(i);\n-                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();", "originalCommit": "37b0924d9d8c43c9ec3531af02b074c7eb0cdd9d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk2NTMyNA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r380965324", "bodyText": "Okay I refactored a ton to make this static and testable - take a look and see if it makes sense.", "author": "sachdevs", "createdAt": "2020-02-18T22:09:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMxOTMxNA=="}], "type": "inlineReview"}, {"oid": "11344ed62d98905bf429f35f8328988606319f8b", "url": "https://github.com/prestodb/presto/commit/11344ed62d98905bf429f35f8328988606319f8b", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-02-18T22:07:04Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk2NjY2Mw==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r380966663", "bodyText": "I dont think we intended this Transaction interface to have a param for getMetastore - I dont see it being used anywhere (even in the internal codebase) am I missing something?", "author": "sachdevs", "createdAt": "2020-02-18T22:12:15Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/AbstractTestHiveClient.java", "diffHunk": "@@ -1376,7 +1379,17 @@ protected void doTestMismatchSchemaTable(\n             int filterCount = afterFilters.size();\n             for (int i = 0; i < filterCount; i++) {\n                 RowExpression predicate = afterFilters.get(i);\n-                ConnectorTableLayoutHandle layoutHandle = metadata.pushdownFilter(session, tableHandle, predicate, Optional.empty()).getLayout().getHandle();\n+                ConnectorTableLayoutHandle layoutHandle = pushdownFilter(\n+                        session,\n+                        metadata,\n+                        transaction.getMetastore(\"\"), // function does not use param in all implementations?", "originalCommit": "11344ed62d98905bf429f35f8328988606319f8b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxODY2MA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384818660", "bodyText": "@sachdevs Let's remove the parameter then. Just check prism connector first.", "author": "mbasmanova", "createdAt": "2020-02-26T22:57:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDk2NjY2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxNjY0NQ==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384816645", "bodyText": "Please, remove this method.", "author": "mbasmanova", "createdAt": "2020-02-26T22:52:37Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java", "diffHunk": "@@ -2675,6 +2460,11 @@ public void revokeTablePrivileges(ConnectorSession session, SchemaTableName sche\n         return toCompletableFuture(stagingFileCommitter.commitFiles(session, handle.getSchemaName(), handle.getTableName(), getPartitionUpdates(fragments)));\n     }\n \n+    public FunctionMetadataManager getFunctionMetadataManager()", "originalCommit": "11344ed62d98905bf429f35f8328988606319f8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxNzE0Mg==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384817142", "bodyText": "let's rename to isLegacyGetLayoutSupported; that name would match the description and the actual meaning more closely", "author": "mbasmanova", "createdAt": "2020-02-26T22:53:52Z", "path": "presto-spi/src/main/java/com/facebook/presto/spi/connector/ConnectorMetadata.java", "diffHunk": "@@ -127,25 +125,14 @@ default ConnectorTableLayoutHandle getAlternativeLayoutHandle(ConnectorSession s\n     }\n \n     /**\n-     * Experimental: if true, the engine will invoke pushdownFilter instead of getTableLayouts.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n-     */\n-    @Experimental\n-    default boolean isPushdownFilterSupported(ConnectorSession session, ConnectorTableHandle tableHandle)\n-    {\n-        return false;\n-    }\n-\n-    /**\n-     * Experimental: returns table layout that encapsulates the given filter.\n-     *\n-     * This interface can be replaced with a connector optimizer rule once the engine supports these (#12546).\n+     * Experimental: if true, the engine will invoke getLayout otherwise, getLayout will not be called.\n+     * This function remains to ensure backwards compatibility, it needs to be removed.\n      */\n+    @Deprecated\n     @Experimental\n-    default ConnectorPushdownFilterResult pushdownFilter(ConnectorSession session, ConnectorTableHandle tableHandle, RowExpression filter, Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    default boolean isPredicatePushdownEnabled(ConnectorSession session, ConnectorTableHandle tableHandle)", "originalCommit": "11344ed62d98905bf429f35f8328988606319f8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxNzgyNA==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384817824", "bodyText": "Please, move this variable up and reuse in the following places:\nHiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n...tableScan.getTable().getConnectorHandle()", "author": "mbasmanova", "createdAt": "2020-02-26T22:55:32Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HiveFilterPushdown.java", "diffHunk": "@@ -0,0 +1,578 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.facebook.presto.hive.rule;\n+\n+import com.facebook.presto.expressions.DefaultRowExpressionTraversalVisitor;\n+import com.facebook.presto.expressions.LogicalRowExpressions;\n+import com.facebook.presto.hive.HiveBucketHandle;\n+import com.facebook.presto.hive.HiveBucketing;\n+import com.facebook.presto.hive.HiveColumnHandle;\n+import com.facebook.presto.hive.HiveMetadata;\n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HivePartitionResult;\n+import com.facebook.presto.hive.HiveSessionProperties;\n+import com.facebook.presto.hive.HiveStorageFormat;\n+import com.facebook.presto.hive.HiveTableHandle;\n+import com.facebook.presto.hive.HiveTableLayoutHandle;\n+import com.facebook.presto.hive.HiveTransactionManager;\n+import com.facebook.presto.hive.SubfieldExtractor;\n+import com.facebook.presto.hive.metastore.Column;\n+import com.facebook.presto.hive.metastore.SemiTransactionalHiveMetastore;\n+import com.facebook.presto.spi.ColumnHandle;\n+import com.facebook.presto.spi.ConnectorPlanOptimizer;\n+import com.facebook.presto.spi.ConnectorSession;\n+import com.facebook.presto.spi.ConnectorTableHandle;\n+import com.facebook.presto.spi.ConnectorTableLayout;\n+import com.facebook.presto.spi.ConnectorTableLayoutHandle;\n+import com.facebook.presto.spi.Constraint;\n+import com.facebook.presto.spi.PrestoException;\n+import com.facebook.presto.spi.SchemaTableName;\n+import com.facebook.presto.spi.Subfield;\n+import com.facebook.presto.spi.TableHandle;\n+import com.facebook.presto.spi.VariableAllocator;\n+import com.facebook.presto.spi.connector.ConnectorMetadata;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.plan.FilterNode;\n+import com.facebook.presto.spi.plan.PlanNode;\n+import com.facebook.presto.spi.plan.PlanNodeIdAllocator;\n+import com.facebook.presto.spi.plan.PlanVisitor;\n+import com.facebook.presto.spi.plan.TableScanNode;\n+import com.facebook.presto.spi.plan.ValuesNode;\n+import com.facebook.presto.spi.predicate.Domain;\n+import com.facebook.presto.spi.predicate.NullableValue;\n+import com.facebook.presto.spi.predicate.TupleDomain;\n+import com.facebook.presto.spi.relation.ConstantExpression;\n+import com.facebook.presto.spi.relation.DomainTranslator;\n+import com.facebook.presto.spi.relation.RowExpression;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n+import com.facebook.presto.spi.relation.VariableReferenceExpression;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Functions;\n+import com.google.common.collect.BiMap;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.function.Function;\n+\n+import static com.facebook.presto.expressions.LogicalRowExpressions.FALSE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.TRUE_CONSTANT;\n+import static com.facebook.presto.expressions.LogicalRowExpressions.and;\n+import static com.facebook.presto.expressions.RowExpressionNodeInliner.replaceExpression;\n+import static com.facebook.presto.hive.HiveTableProperties.getHiveStorageFormat;\n+import static com.facebook.presto.spi.StandardErrorCode.DIVISION_BY_ZERO;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n+import static com.facebook.presto.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n+import static com.facebook.presto.spi.predicate.TupleDomain.withColumnDomains;\n+import static com.facebook.presto.spi.relation.ExpressionOptimizer.Level.OPTIMIZED;\n+import static com.google.common.base.MoreObjects.toStringHelper;\n+import static com.google.common.base.Preconditions.checkArgument;\n+import static com.google.common.base.Preconditions.checkState;\n+import static com.google.common.collect.ImmutableBiMap.toImmutableBiMap;\n+import static com.google.common.collect.ImmutableList.toImmutableList;\n+import static com.google.common.collect.ImmutableMap.toImmutableMap;\n+import static com.google.common.collect.ImmutableSet.toImmutableSet;\n+import static com.google.common.collect.Sets.intersection;\n+import static java.util.Collections.emptyList;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Runs during both logical and physical phases of connector-aided plan optimization.\n+ * In most cases filter pushdown will occur during logical phase. However, in cases\n+ * when new filter is added between logical and physical phases, e.g. a filter on a join\n+ * key from one side of a join is added to the other side, the new filter will get\n+ * merged with the one already pushed down.\n+ */\n+public class HiveFilterPushdown\n+        implements ConnectorPlanOptimizer\n+{\n+    private static final ConnectorTableLayout EMPTY_TABLE_LAYOUT = new ConnectorTableLayout(\n+            new ConnectorTableLayoutHandle() {},\n+            Optional.empty(),\n+            TupleDomain.none(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            Optional.empty(),\n+            emptyList());\n+\n+    private final HiveTransactionManager transactionManager;\n+    protected final RowExpressionService rowExpressionService;\n+    protected final StandardFunctionResolution functionResolution;\n+    protected final HivePartitionManager partitionManager;\n+    protected final FunctionMetadataManager functionMetadataManager;\n+\n+    public HiveFilterPushdown(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        this.transactionManager = requireNonNull(transactionManager, \"transactionManager is null\");\n+        this.rowExpressionService = requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        this.functionResolution = requireNonNull(functionResolution, \"functionResolution is null\");\n+        this.partitionManager = requireNonNull(partitionManager, \"partitionManager is null\");\n+        this.functionMetadataManager = requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+    }\n+\n+    @Override\n+    public PlanNode optimize(PlanNode maxSubplan, ConnectorSession session, VariableAllocator variableAllocator, PlanNodeIdAllocator idAllocator)\n+    {\n+        return maxSubplan.accept(new Visitor(session, idAllocator), null);\n+    }\n+\n+    protected ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            HiveMetadata metadata,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        return pushdownFilter(\n+                session,\n+                metadata,\n+                metadata.getMetastore(),\n+                rowExpressionService,\n+                functionResolution,\n+                partitionManager,\n+                functionMetadataManager,\n+                tableHandle,\n+                filter,\n+                currentLayoutHandle);\n+    }\n+\n+    @VisibleForTesting\n+    public static ConnectorPushdownFilterResult pushdownFilter(\n+            ConnectorSession session,\n+            ConnectorMetadata metadata,\n+            SemiTransactionalHiveMetastore metastore,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager,\n+            ConnectorTableHandle tableHandle,\n+            RowExpression filter,\n+            Optional<ConnectorTableLayoutHandle> currentLayoutHandle)\n+    {\n+        checkArgument(!FALSE_CONSTANT.equals(filter), \"Cannot pushdown filter that is always false\");\n+        if (TRUE_CONSTANT.equals(filter) && currentLayoutHandle.isPresent()) {\n+            return new ConnectorPushdownFilterResult(metadata.getTableLayout(session, currentLayoutHandle.get()), TRUE_CONSTANT);\n+        }\n+\n+        // Split the filter into 3 groups of conjuncts:\n+        //  - range filters that apply to entire columns,\n+        //  - range filters that apply to subfields,\n+        //  - the rest. Intersect these with possibly pre-existing filters.\n+        DomainTranslator.ExtractionResult<Subfield> decomposedFilter = rowExpressionService.getDomainTranslator()\n+                .fromPredicate(session, filter, new SubfieldExtractor(functionResolution, rowExpressionService.getExpressionOptimizer(), session).toColumnExtractor());\n+        if (currentLayoutHandle.isPresent()) {\n+            HiveTableLayoutHandle currentHiveLayout = (HiveTableLayoutHandle) currentLayoutHandle.get();\n+            decomposedFilter = intersectExtractionResult(new DomainTranslator.ExtractionResult(currentHiveLayout.getDomainPredicate(), currentHiveLayout.getRemainingPredicate()), decomposedFilter);\n+        }\n+\n+        if (decomposedFilter.getTupleDomain().isNone()) {\n+            return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+        }\n+\n+        RowExpression optimizedRemainingExpression = rowExpressionService.getExpressionOptimizer().optimize(decomposedFilter.getRemainingExpression(), OPTIMIZED, session);\n+        if (optimizedRemainingExpression instanceof ConstantExpression) {\n+            ConstantExpression constantExpression = (ConstantExpression) optimizedRemainingExpression;\n+            if (FALSE_CONSTANT.equals(constantExpression) || constantExpression.getValue() == null) {\n+                return new ConnectorPushdownFilterResult(EMPTY_TABLE_LAYOUT, FALSE_CONSTANT);\n+            }\n+        }\n+        Map<String, ColumnHandle> columnHandles = metadata.getColumnHandles(session, tableHandle);\n+        TupleDomain<ColumnHandle> entireColumnDomain = decomposedFilter.getTupleDomain()\n+                .transform(subfield -> isEntireColumn(subfield) ? subfield.getRootName() : null)\n+                .transform(columnHandles::get);\n+        if (currentLayoutHandle.isPresent()) {\n+            entireColumnDomain = entireColumnDomain.intersect(((HiveTableLayoutHandle) (currentLayoutHandle.get())).getPartitionColumnPredicate());\n+        }\n+\n+        Constraint<ColumnHandle> constraint = new Constraint<>(entireColumnDomain);\n+\n+        // Extract deterministic conjuncts that apply to partition columns and specify these as Constraint#predicate\n+        if (!TRUE_CONSTANT.equals(decomposedFilter.getRemainingExpression())) {\n+            LogicalRowExpressions logicalRowExpressions = new LogicalRowExpressions(rowExpressionService.getDeterminismEvaluator(), functionResolution, functionMetadataManager);\n+            RowExpression deterministicPredicate = logicalRowExpressions.filterDeterministicConjuncts(decomposedFilter.getRemainingExpression());\n+            if (!TRUE_CONSTANT.equals(deterministicPredicate)) {\n+                ConstraintEvaluator evaluator = new ConstraintEvaluator(rowExpressionService, session, columnHandles, deterministicPredicate);\n+                constraint = new Constraint<>(entireColumnDomain, evaluator::isCandidate);\n+            }\n+        }\n+\n+        HivePartitionResult hivePartitionResult = partitionManager.getPartitions(metastore, tableHandle, constraint, session);\n+\n+        TupleDomain<Subfield> domainPredicate = withColumnDomains(ImmutableMap.<Subfield, Domain>builder()\n+                .putAll(hivePartitionResult.getUnenforcedConstraint()\n+                        .transform(HiveFilterPushdown::toSubfield)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .putAll(decomposedFilter.getTupleDomain()\n+                        .transform(subfield -> !isEntireColumn(subfield) ? subfield : null)\n+                        .getDomains()\n+                        .orElse(ImmutableMap.of()))\n+                .build());\n+\n+        Set<String> predicateColumnNames = new HashSet<>();\n+        domainPredicate.getDomains().get().keySet().stream()\n+                .map(Subfield::getRootName)\n+                .forEach(predicateColumnNames::add);\n+        // Include only columns referenced in the optimized expression. Although the expression is sent to the worker node\n+        // unoptimized, the worker is expected to optimize the expression before executing.\n+        extractAll(optimizedRemainingExpression).stream()\n+                .map(VariableReferenceExpression::getName)\n+                .forEach(predicateColumnNames::add);\n+\n+        Map<String, HiveColumnHandle> predicateColumns = predicateColumnNames.stream()\n+                .map(columnHandles::get)\n+                .map(HiveColumnHandle.class::cast)\n+                .collect(toImmutableMap(HiveColumnHandle::getName, Functions.identity()));\n+\n+        SchemaTableName tableName = ((HiveTableHandle) tableHandle).getSchemaTableName();\n+        return new ConnectorPushdownFilterResult(\n+                metadata.getTableLayout(\n+                        session,\n+                        new HiveTableLayoutHandle(\n+                                tableName,\n+                                hivePartitionResult.getPartitionColumns(),\n+                                // remove comments to optimize serialization costs\n+                                pruneColumnComments(hivePartitionResult.getDataColumns()),\n+                                hivePartitionResult.getTableParameters(),\n+                                hivePartitionResult.getPartitions(),\n+                                domainPredicate,\n+                                decomposedFilter.getRemainingExpression(),\n+                                predicateColumns,\n+                                hivePartitionResult.getEnforcedConstraint(),\n+                                hivePartitionResult.getBucketHandle(),\n+                                hivePartitionResult.getBucketFilter(),\n+                                true,\n+                                createTableLayoutString(\n+                                        session,\n+                                        rowExpressionService,\n+                                        tableName,\n+                                        hivePartitionResult.getBucketHandle(),\n+                                        hivePartitionResult.getBucketFilter(),\n+                                        decomposedFilter.getRemainingExpression(),\n+                                        domainPredicate))),\n+                TRUE_CONSTANT);\n+    }\n+\n+    @VisibleForTesting\n+    public static class ConnectorPushdownFilterResult\n+    {\n+        private final ConnectorTableLayout layout;\n+        private final RowExpression unenforcedConstraint;\n+\n+        ConnectorPushdownFilterResult(ConnectorTableLayout layout, RowExpression unenforcedConstraint)\n+        {\n+            this.layout = requireNonNull(layout, \"layout is null\");\n+            this.unenforcedConstraint = requireNonNull(unenforcedConstraint, \"unenforcedConstraint is null\");\n+        }\n+\n+        public ConnectorTableLayout getLayout()\n+        {\n+            return layout;\n+        }\n+\n+        public RowExpression getUnenforcedConstraint()\n+        {\n+            return unenforcedConstraint;\n+        }\n+    }\n+\n+    private class Visitor\n+            extends PlanVisitor<PlanNode, Void>\n+    {\n+        private final ConnectorSession session;\n+        private final PlanNodeIdAllocator idAllocator;\n+\n+        Visitor(ConnectorSession session, PlanNodeIdAllocator idAllocator)\n+        {\n+            this.session = requireNonNull(session, \"session is null\");\n+            this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n+        }\n+\n+        @Override\n+        public PlanNode visitPlan(PlanNode node, Void context)\n+        {\n+            ImmutableList.Builder<PlanNode> children = ImmutableList.builder();\n+            boolean changed = false;\n+            for (PlanNode child : node.getSources()) {\n+                PlanNode newChild = child.accept(this, null);\n+                if (newChild != child) {\n+                    changed = true;\n+                }\n+                children.add(newChild);\n+            }\n+\n+            if (!changed) {\n+                return node;\n+            }\n+            return node.replaceChildren(children.build());\n+        }\n+\n+        @Override\n+        public PlanNode visitFilter(FilterNode filter, Void context)\n+        {\n+            if (!(filter.getSource() instanceof TableScanNode)) {\n+                return visitPlan(filter, context);\n+            }\n+\n+            TableScanNode tableScan = (TableScanNode) filter.getSource();\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return filter;\n+            }\n+\n+            RowExpression expression = filter.getPredicate();\n+            TableHandle handle = tableScan.getTable();\n+            HiveMetadata hiveMetadata = getMetadata(handle);\n+\n+            BiMap<VariableReferenceExpression, VariableReferenceExpression> symbolToColumnMapping = tableScan.getAssignments().entrySet().stream()\n+                    .collect(toImmutableBiMap(\n+                            Map.Entry::getKey,\n+                            entry -> new VariableReferenceExpression(getColumnName(session, hiveMetadata, handle.getConnectorHandle(), entry.getValue()), entry.getKey().getType())));\n+\n+            RowExpression replacedExpression = replaceExpression(expression, symbolToColumnMapping);\n+            // replaceExpression() may further optimize the expression; if the resulting expression is always false, then return empty Values node\n+            if (FALSE_CONSTANT.equals(replacedExpression)) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(\n+                    session,\n+                    hiveMetadata,\n+                    handle.getConnectorHandle(),\n+                    replacedExpression,\n+                    handle.getLayout());\n+\n+            ConnectorTableLayout layout = pushdownFilterResult.getLayout();\n+            if (layout.getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableScanNode node = new TableScanNode(\n+                    tableScan.getId(),\n+                    new TableHandle(handle.getConnectorId(), handle.getConnectorHandle(), handle.getTransaction(), Optional.of(pushdownFilterResult.getLayout().getHandle())),\n+                    tableScan.getOutputVariables(),\n+                    tableScan.getAssignments(),\n+                    layout.getPredicate(),\n+                    TupleDomain.all());\n+\n+            RowExpression unenforcedFilter = pushdownFilterResult.getUnenforcedConstraint();\n+            if (!TRUE_CONSTANT.equals(unenforcedFilter)) {\n+                return new FilterNode(idAllocator.getNextId(), node, replaceExpression(unenforcedFilter, symbolToColumnMapping.inverse()));\n+            }\n+\n+            return node;\n+        }\n+\n+        @Override\n+        public PlanNode visitTableScan(TableScanNode tableScan, Void context)\n+        {\n+            if (!isPushdownFilterSupported(session, tableScan.getTable())) {\n+                return tableScan;\n+            }\n+            HiveMetadata hiveMetadata = getMetadata(tableScan.getTable());\n+            ConnectorPushdownFilterResult pushdownFilterResult = pushdownFilter(\n+                    session,\n+                    hiveMetadata,\n+                    tableScan.getTable().getConnectorHandle(),\n+                    TRUE_CONSTANT,\n+                    tableScan.getTable().getLayout());\n+            if (pushdownFilterResult.getLayout().getPredicate().isNone()) {\n+                return new ValuesNode(idAllocator.getNextId(), tableScan.getOutputVariables(), ImmutableList.of());\n+            }\n+\n+            TableHandle handle = tableScan.getTable();", "originalCommit": "11344ed62d98905bf429f35f8328988606319f8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgxODAzMg==", "url": "https://github.com/prestodb/presto/pull/14040#discussion_r384818032", "bodyText": "no need to make new set object every time; change the variable type to Set", "author": "mbasmanova", "createdAt": "2020-02-26T22:56:01Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/rule/HivePlanOptimizerProvider.java", "diffHunk": "@@ -13,24 +13,51 @@\n  */\n package com.facebook.presto.hive.rule;\n \n+import com.facebook.presto.hive.HivePartitionManager;\n+import com.facebook.presto.hive.HiveTransactionManager;\n import com.facebook.presto.spi.ConnectorPlanOptimizer;\n import com.facebook.presto.spi.connector.ConnectorPlanOptimizerProvider;\n+import com.facebook.presto.spi.function.FunctionMetadataManager;\n+import com.facebook.presto.spi.function.StandardFunctionResolution;\n+import com.facebook.presto.spi.relation.RowExpressionService;\n import com.google.common.collect.ImmutableSet;\n+import com.google.inject.Inject;\n \n import java.util.Set;\n \n+import static java.util.Objects.requireNonNull;\n+\n public class HivePlanOptimizerProvider\n         implements ConnectorPlanOptimizerProvider\n {\n+    private final HiveFilterPushdown filterPushdownOptimizer;\n+\n+    @Inject\n+    public HivePlanOptimizerProvider(\n+            HiveTransactionManager transactionManager,\n+            RowExpressionService rowExpressionService,\n+            StandardFunctionResolution functionResolution,\n+            HivePartitionManager partitionManager,\n+            FunctionMetadataManager functionMetadataManager)\n+    {\n+        requireNonNull(transactionManager, \"transactionManager is null\");\n+        requireNonNull(rowExpressionService, \"rowExpressionService is null\");\n+        requireNonNull(functionResolution, \"functionResolution is null\");\n+        requireNonNull(partitionManager, \"partitionManager is null\");\n+        requireNonNull(functionMetadataManager, \"functionMetadataManager is null\");\n+        this.filterPushdownOptimizer = new HiveFilterPushdown(transactionManager, rowExpressionService, functionResolution, partitionManager, functionMetadataManager);\n+    }\n+\n     @Override\n     public Set<ConnectorPlanOptimizer> getLogicalPlanOptimizers()\n     {\n-        return ImmutableSet.of();\n+        return ImmutableSet.of(filterPushdownOptimizer);", "originalCommit": "11344ed62d98905bf429f35f8328988606319f8b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "url": "https://github.com/prestodb/presto/commit/889c90f8cb2cbf627256b1bf79ff91a10cf5dd6f", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-03-04T00:24:46Z", "type": "forcePushed"}, {"oid": "abf05811d635dc6c4df778ba1e872efded23a5db", "url": "https://github.com/prestodb/presto/commit/abf05811d635dc6c4df778ba1e872efded23a5db", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-03-04T20:24:55Z", "type": "commit"}, {"oid": "abf05811d635dc6c4df778ba1e872efded23a5db", "url": "https://github.com/prestodb/presto/commit/abf05811d635dc6c4df778ba1e872efded23a5db", "message": "Move Hive filter pushdown logic out of PickTableLayout", "committedDate": "2020-03-04T20:24:55Z", "type": "forcePushed"}]}