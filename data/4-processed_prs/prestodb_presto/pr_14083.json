{"pr_number": 14083, "pr_title": "Balance ArbitraryOutputbuffer distribution over clients", "pr_createdAt": "2020-02-11T16:05:48Z", "pr_url": "https://github.com/prestodb/presto/pull/14083", "timeline": [{"oid": "dd87c17860bf544f12cfb2fa3cf367be8c7d939a", "url": "https://github.com/prestodb/presto/commit/dd87c17860bf544f12cfb2fa3cf367be8c7d939a", "message": "Balance ArbitraryOutputbuffer distribution over clients\n\nPreviously, the order that client buffers were polled was always\nstarted with the first ClientBuffer, which could lead to data skew\nwhen the master buffer drained before all clients could be polled\nsince the client buffer traversal order was stable (but arbitrary).\n\nThis change stores the stop index of client buffer iteration to\nensure that subsequent polling loops don't overload the first client\nbuffer.", "committedDate": "2020-02-11T17:55:00Z", "type": "forcePushed"}, {"oid": "31b3faa17ee8c6b0270a65358b7d2bedc0028ac7", "url": "https://github.com/prestodb/presto/commit/31b3faa17ee8c6b0270a65358b7d2bedc0028ac7", "message": "Balance ArbitraryOutputbuffer distribution over clients\n\nPreviously, the order that client buffers were polled was always\nstarted with the first ClientBuffer, which could lead to data skew\nwhen the master buffer drained before all clients could be polled\nsince the client buffer traversal order was stable (but arbitrary).\n\nThis change stores the stop index of client buffer iteration to\nensure that subsequent polling loops don't overload the first client\nbuffer.", "committedDate": "2020-02-11T21:55:26Z", "type": "forcePushed"}, {"oid": "bdcd004e94fe322ac4e3db46af2da182857a3c30", "url": "https://github.com/prestodb/presto/commit/bdcd004e94fe322ac4e3db46af2da182857a3c30", "message": "Balance ArbitraryOutputbuffer distribution over clients\n\nPreviously, the order that client buffers were polled was always\nstarted with the first ClientBuffer, which could lead to data skew\nwhen the master buffer drained before all clients could be polled\nsince the client buffer traversal order was stable (but arbitrary).\n\nThis change stores the stop index of client buffer iteration to\nensure that subsequent polling loops don't overload the first client\nbuffer.", "committedDate": "2020-02-11T22:16:20Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk1OTg0NQ==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r377959845", "bodyText": "Is enqueue called from multiple threads? IOW do multiple threads enter this loop and fetch nextClientBufferIndex?", "author": "aweisberg", "createdAt": "2020-02-11T23:25:00Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/buffer/ArbitraryOutputBuffer.java", "diffHunk": "@@ -248,11 +253,20 @@ public void enqueue(Lifespan lifespan, List<SerializedPage> pages)\n         masterBuffer.addPages(serializedPageReferences);\n \n         // process any pending reads from the client buffers\n-        for (ClientBuffer clientBuffer : safeGetBuffersSnapshot()) {\n+        List<ClientBuffer> buffers = safeGetBuffersSnapshot();\n+        if (buffers.isEmpty()) {\n+            return;\n+        }\n+        // handle potential for racy update of next index and client buffers present\n+        int index = nextClientBufferIndex.get() % buffers.size();\n+        for (int i = 0; i < buffers.size(); i++) {\n+            buffers.get(index).loadPagesIfNecessary(masterBuffer);\n+            index = (index + 1) % buffers.size();\n             if (masterBuffer.isEmpty()) {\n+                // Resume from the next client buffer on the next iteration\n+                nextClientBufferIndex.set(index);", "originalCommit": "bdcd004e94fe322ac4e3db46af2da182857a3c30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk3Mjg3Nw==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r377972877", "bodyText": "I believe it\u2019s possible that yes, they could. I didn\u2019t look into it because I propose that scenario is not a \u201cproblem\u201d worth solving because if that does happen this implementation will put one thread \u201cin front\u201d of the other in performing the iteration at all times (even if the leading caller changes between iterations). The net result is that the leading caller releases any blocked clients and the trailing caller has no effect. That seems preferable to putting more synchronization around enqueue operations, because this path only matters when the producer side is slower than consumers. A faster producer still drives the output distribution through consumption rate.", "author": "pettyjamesm", "createdAt": "2020-02-12T00:05:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk1OTg0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ0NzEyMQ==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r378447121", "bodyText": "WFM", "author": "aweisberg", "createdAt": "2020-02-12T18:54:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk1OTg0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk1OTkyMg==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r377959922", "bodyText": "Given the current usage you don't need nextClientBufferIndex to be an AtomicLong. volatile would suffice.", "author": "aweisberg", "createdAt": "2020-02-11T23:25:13Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/buffer/ArbitraryOutputBuffer.java", "diffHunk": "@@ -73,6 +73,9 @@\n     @GuardedBy(\"this\")\n     private final ConcurrentMap<OutputBufferId, ClientBuffer> buffers = new ConcurrentHashMap<>();\n \n+    //  The index of the first client buffer that should be polled\n+    private final AtomicInteger nextClientBufferIndex = new AtomicInteger(0);", "originalCommit": "bdcd004e94fe322ac4e3db46af2da182857a3c30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk3OTgzNA==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r377979834", "bodyText": "I tend to prefer Aomic* over volatile for maintainability because of how easy it is for future changes to treat volatile fields as \u201cregular int\u201d and do something like use it in a loop counter. I\u2019m fine changing it to volatile if you prefer.", "author": "pettyjamesm", "createdAt": "2020-02-12T00:29:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk1OTkyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ3NzA4Mg==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r378477082", "bodyText": "I don't have a strong preference in this case. You can leave it as is.", "author": "aweisberg", "createdAt": "2020-02-12T19:51:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk1OTkyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk2MDgxNA==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r377960814", "bodyText": "This reordered checking if the masterBuffer is empty before loading the client. Depending on which case is more common this results in a bunch of extra lock acquisitions inside a client.\nI think this also means that the index is incremented even if no data is loaded into it which might be undesirable?", "author": "aweisberg", "createdAt": "2020-02-11T23:27:47Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/buffer/ArbitraryOutputBuffer.java", "diffHunk": "@@ -248,11 +253,20 @@ public void enqueue(Lifespan lifespan, List<SerializedPage> pages)\n         masterBuffer.addPages(serializedPageReferences);\n \n         // process any pending reads from the client buffers\n-        for (ClientBuffer clientBuffer : safeGetBuffersSnapshot()) {\n+        List<ClientBuffer> buffers = safeGetBuffersSnapshot();\n+        if (buffers.isEmpty()) {\n+            return;\n+        }\n+        // handle potential for racy update of next index and client buffers present\n+        int index = nextClientBufferIndex.get() % buffers.size();\n+        for (int i = 0; i < buffers.size(); i++) {\n+            buffers.get(index).loadPagesIfNecessary(masterBuffer);\n+            index = (index + 1) % buffers.size();\n             if (masterBuffer.isEmpty()) {", "originalCommit": "bdcd004e94fe322ac4e3db46af2da182857a3c30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk3Nzc3NQ==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r377977775", "bodyText": "The code was a little cleaner this way (not a ton) but the assumptions are:\n\nthis code path only matters when the producing side is slow, and the master buffer is usually emptied before all client buffers have been fed (or: most clients are waiting on data)\nsince we just added data to the buffer, at least one iteration will receive data unless a race is lost in a very narrow window. Checking for empty first does not completely remove that window\n\nIf that occurs then yes, a client may \u201cmiss a turn\u201d. I think that\u2019s probably ok since missing a turn under these conditions implies that almost all clients are starved. The goal is not to be perfectly fair, but rather to spread the trickle of data more evenly.", "author": "pettyjamesm", "createdAt": "2020-02-12T00:22:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk2MDgxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODQ1MTE0OQ==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r378451149", "bodyText": "Could this introduce a weird odd/even bias? Or maybe not odd/even depending on how many clients a given input is divided up over, but some multiple of whatever clients buffer.\n        // handle potential for racy update of indexOffset and buffer list copy\n        int index = nextClientBufferIndex.get() % buffers.size();\n        for (int i = 0; i < buffers.size(); i++) {\n            if (masterBuffer.isEmpty()) {\n                break;\n            }\n            buffers.get(index).loadPagesIfNecessary(masterBuffer);\n            index = (index + 1) % buffers.size();\n        }\n        // Resume from the next client buffer on the next iteration\n        nextClientBufferIndex.set(index);\n\nDoesn't look much worse to me and it does closer to what you would expect.", "author": "aweisberg", "createdAt": "2020-02-12T19:02:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk2MDgxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODkyNzMwNA==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r378927304", "bodyText": "Sure. I've reordered the check to the start of the loop to match your example with one change: the atomic write to nextClientBufferIndex is still only necessary when the loop exits early. If the loop completes then no atomic write is necessary because the next iteration starts from the same offset as the previous one.", "author": "pettyjamesm", "createdAt": "2020-02-13T15:20:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk2MDgxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk2MTI3Mg==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r377961272", "bodyText": "I'm not sure why this is written this way. Why materialize this list on read every time? Why not materialize it only when the set of buffers changes?\nOrthogonal to your set of changes though.", "author": "aweisberg", "createdAt": "2020-02-11T23:29:10Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/buffer/ArbitraryOutputBuffer.java", "diffHunk": "@@ -395,7 +409,7 @@ private synchronized ClientBuffer getBuffer(OutputBufferId id)\n         return buffer;\n     }\n \n-    private synchronized Collection<ClientBuffer> safeGetBuffersSnapshot()\n+    private synchronized List<ClientBuffer> safeGetBuffersSnapshot()", "originalCommit": "bdcd004e94fe322ac4e3db46af2da182857a3c30", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk3OTA1Mw==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r377979053", "bodyText": "I looked at that too, but shied away from it because of the on demand client buffer creation inside of \u201cget\u201d. Keeping the two structures in sync seemed brittle, but can definitely be done.", "author": "pettyjamesm", "createdAt": "2020-02-12T00:26:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk2MTI3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTAwNDY2MA==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r379004660", "bodyText": "Yeah. It wouldn't be difficult to make not brittle just because the set of buffers is only ever added to. A CAS loop on updating the materialized list would be enough.\nTotally out of scope for this just seems like LHF.", "author": "aweisberg", "createdAt": "2020-02-13T17:19:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk2MTI3Mg=="}], "type": "inlineReview"}, {"oid": "1b35750d80ea5c85d6cd0aa002440ee72d59ab2f", "url": "https://github.com/prestodb/presto/commit/1b35750d80ea5c85d6cd0aa002440ee72d59ab2f", "message": "Balance ArbitraryOutputbuffer distribution over clients\n\nPreviously, the order that client buffers were polled was always\nstarted with the first ClientBuffer, which could lead to data skew\nwhen the master buffer drained before all clients could be polled\nsince the client buffer traversal order was stable (but arbitrary).\n\nThis change stores the stop index of client buffer iteration to\nensure that subsequent polling loops don't overload the first client\nbuffer.", "committedDate": "2020-02-12T16:15:32Z", "type": "forcePushed"}, {"oid": "748def67479939e0a89dbbcb781958961dfcb8b3", "url": "https://github.com/prestodb/presto/commit/748def67479939e0a89dbbcb781958961dfcb8b3", "message": "Balance ArbitraryOutputbuffer distribution over clients\n\nPreviously, the order that client buffers were polled was always\nstarted with the first ClientBuffer, which could lead to data skew\nwhen the master buffer drained before all clients could be polled\nsince the client buffer traversal order was stable (but arbitrary).\n\nThis change stores the stop index of client buffer iteration to\nensure that subsequent polling loops don't overload the first client\nbuffer.", "committedDate": "2020-02-13T15:18:08Z", "type": "forcePushed"}, {"oid": "766bbf23ba75231d61710a556aa08edc43eff5a9", "url": "https://github.com/prestodb/presto/commit/766bbf23ba75231d61710a556aa08edc43eff5a9", "message": "Balance ArbitraryOutputbuffer distribution over clients\n\nPreviously, the order that client buffers were polled was always\nstarted with the first ClientBuffer, which could lead to data skew\nwhen the master buffer drained before all clients could be polled\nsince the client buffer traversal order was stable (but arbitrary).\n\nThis change stores the stop index of client buffer iteration to\nensure that subsequent polling loops don't overload the first client\nbuffer.", "committedDate": "2020-02-13T17:28:48Z", "type": "commit"}, {"oid": "766bbf23ba75231d61710a556aa08edc43eff5a9", "url": "https://github.com/prestodb/presto/commit/766bbf23ba75231d61710a556aa08edc43eff5a9", "message": "Balance ArbitraryOutputbuffer distribution over clients\n\nPreviously, the order that client buffers were polled was always\nstarted with the first ClientBuffer, which could lead to data skew\nwhen the master buffer drained before all clients could be polled\nsince the client buffer traversal order was stable (but arbitrary).\n\nThis change stores the stop index of client buffer iteration to\nensure that subsequent polling loops don't overload the first client\nbuffer.", "committedDate": "2020-02-13T17:28:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMyMjU1NA==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r379322554", "bodyText": "Why do you need to do  % buffers.size() here since you already did index = (index + 1) % buffers.size(); when setting the value of it in the loop?", "author": "yingsu00", "createdAt": "2020-02-14T09:17:14Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/buffer/ArbitraryOutputBuffer.java", "diffHunk": "@@ -248,11 +253,20 @@ public void enqueue(Lifespan lifespan, List<SerializedPage> pages)\n         masterBuffer.addPages(serializedPageReferences);\n \n         // process any pending reads from the client buffers\n-        for (ClientBuffer clientBuffer : safeGetBuffersSnapshot()) {\n+        List<ClientBuffer> buffers = safeGetBuffersSnapshot();\n+        if (buffers.isEmpty()) {\n+            return;\n+        }\n+        // handle potential for racy update of next index and client buffers present\n+        int index = nextClientBufferIndex.get() % buffers.size();", "originalCommit": "766bbf23ba75231d61710a556aa08edc43eff5a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTUxMDYwNg==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r379510606", "bodyText": "The index is used before the value is clamped for subsequent iterations of the loop.", "author": "aweisberg", "createdAt": "2020-02-14T16:01:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMyMjU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTY4ODE3NQ==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r379688175", "bodyText": "I see. The buffer.size() could be changing between two enqueue calls.", "author": "yingsu00", "createdAt": "2020-02-14T23:28:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMyMjU1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMzMDU3OA==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r379330578", "bodyText": "Since you added the isEmpty() check and a new comment below, this comment line seems to be only for the section\nList<ClientBuffer> buffers = safeGetBuffersSnapshot();\n        if (buffers.isEmpty()) {\n            return;\n        }\n\nAnd this may cause confusion. Would it be better to move it to above line 268??", "author": "yingsu00", "createdAt": "2020-02-14T09:34:44Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/buffer/ArbitraryOutputBuffer.java", "diffHunk": "@@ -248,11 +253,20 @@ public void enqueue(Lifespan lifespan, List<SerializedPage> pages)\n         masterBuffer.addPages(serializedPageReferences);\n \n         // process any pending reads from the client buffers", "originalCommit": "766bbf23ba75231d61710a556aa08edc43eff5a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTUwOTExNg==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r379509116", "bodyText": "The entire loop used to be in a separate method and it got pulled up. I hadn't noticed that happened. I think that might be why the comment makes less sense. Is there a reason that happened?", "author": "aweisberg", "createdAt": "2020-02-14T15:58:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMzMDU3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTU1OTczOA==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r379559738", "bodyText": "Yeah, I kept this PR in sync and that change was based on feedback from the cross port trinodb/trino#2788 (comment)", "author": "pettyjamesm", "createdAt": "2020-02-14T17:41:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMzMDU3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMzNDM0OQ==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r379334349", "bodyText": "Maybe it's because I'm not a native English speaker, but I don't quite understand this sentence. What does client buffers present refer to? I saw you only updated the next index, but not the client buffers. What is **for** racy update? Would handle potential racy update of next index be enough?", "author": "yingsu00", "createdAt": "2020-02-14T09:42:36Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/buffer/ArbitraryOutputBuffer.java", "diffHunk": "@@ -248,11 +253,20 @@ public void enqueue(Lifespan lifespan, List<SerializedPage> pages)\n         masterBuffer.addPages(serializedPageReferences);\n \n         // process any pending reads from the client buffers\n-        for (ClientBuffer clientBuffer : safeGetBuffersSnapshot()) {\n+        List<ClientBuffer> buffers = safeGetBuffersSnapshot();\n+        if (buffers.isEmpty()) {\n+            return;\n+        }\n+        // handle potential for racy update of next index and client buffers present", "originalCommit": "766bbf23ba75231d61710a556aa08edc43eff5a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTUwNzk1OQ==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r379507959", "bodyText": "Earlier in the method it retrieves a snapshot of the client buffers. The snapshot could be out of date as soon as it is retrieved. Another client buffer could get added to the set immediately after by another thread.\nThen another thread could update the index to point to the just added client buffer which doesn't exist in the snapshot that was copied.\nIf it's not clear to you then the comment could be more detailed. Spotting and understanding races is hard and we should try to be very particular about how we handle concurrency.", "author": "aweisberg", "createdAt": "2020-02-14T15:56:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMzNDM0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTU2MDAwOA==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r379560008", "bodyText": "Correct, thanks for the clear explanation @aweisberg", "author": "pettyjamesm", "createdAt": "2020-02-14T17:42:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTMzNDM0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDQyMDUzNg==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r380420536", "bodyText": "It looks to me the only difference with trinodb/trino#2788 is the position of these two lines (line 268 - line 269). In trinodb/trino#2788, these two lines are at the beginning of for-loop (before the if (masterBuffer.isEmpty())) statement).\nCurious what's the discussion over this? :)", "author": "wenleix", "createdAt": "2020-02-18T01:51:07Z", "path": "presto-main/src/main/java/com/facebook/presto/execution/buffer/ArbitraryOutputBuffer.java", "diffHunk": "@@ -248,11 +253,20 @@ public void enqueue(Lifespan lifespan, List<SerializedPage> pages)\n         masterBuffer.addPages(serializedPageReferences);\n \n         // process any pending reads from the client buffers\n-        for (ClientBuffer clientBuffer : safeGetBuffersSnapshot()) {\n+        List<ClientBuffer> buffers = safeGetBuffersSnapshot();\n+        if (buffers.isEmpty()) {\n+            return;\n+        }\n+        // handle potential for racy update of next index and client buffers present\n+        int index = nextClientBufferIndex.get() % buffers.size();\n+        for (int i = 0; i < buffers.size(); i++) {\n             if (masterBuffer.isEmpty()) {\n+                // Resume from the current client buffer on the next iteration\n+                nextClientBufferIndex.set(index);\n                 break;\n             }\n-            clientBuffer.loadPagesIfNecessary(masterBuffer);\n+            buffers.get(index).loadPagesIfNecessary(masterBuffer);", "originalCommit": "766bbf23ba75231d61710a556aa08edc43eff5a9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDQyMDk5Mg==", "url": "https://github.com/prestodb/presto/pull/14083#discussion_r380420992", "bodyText": "Update: I think the discussion is here: #14083 (comment)", "author": "wenleix", "createdAt": "2020-02-18T01:53:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDQyMDUzNg=="}], "type": "inlineReview"}]}