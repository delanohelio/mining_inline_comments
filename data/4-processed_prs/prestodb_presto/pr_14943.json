{"pr_number": 14943, "pr_title": "Add max Spark input partition count for auto tune", "pr_createdAt": "2020-08-03T04:19:22Z", "pr_url": "https://github.com/prestodb/presto/pull/14943", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgxMDkxMA==", "url": "https://github.com/prestodb/presto/pull/14943#discussion_r465810910", "bodyText": "When auto tune is not enabled, do we also want to set a max limit ? actual partition count = min(count_set_by_session_property,  hard_limit_set_by_this_config)", "author": "viczhang861", "createdAt": "2020-08-05T15:26:39Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkConfig.java", "diffHunk": "@@ -38,6 +39,19 @@ public PrestoSparkConfig setSparkPartitionCountAutoTuneEnabled(boolean sparkPart\n         return this;\n     }\n \n+    @Config(\"spark.max-spark-input-partition-count-for-auto-tune\")\n+    @ConfigDescription(\"Max Spark input partition count when Spark partition auto tune is enabled\")", "originalCommit": "7a763d6f36b8981eb87f65ff5e1706ac6cfaea5d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM1NDc4MQ==", "url": "https://github.com/prestodb/presto/pull/14943#discussion_r475354781", "bodyText": "@viczhang861 : this is also used as session property. I feel we should allow user to manually specify some large number when they intend to do so.\nAlthough so many config properties is not ideal anyway, we should really implement history-based auto mapper tuning.", "author": "wenleix", "createdAt": "2020-08-24T05:44:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTgxMDkxMA=="}], "type": "inlineReview"}, {"oid": "4d4b2d085ec0d730945897e2b9b1f9e02d454128", "url": "https://github.com/prestodb/presto/commit/4d4b2d085ec0d730945897e2b9b1f9e02d454128", "message": "Add max Spark input partition count for auto tune\n\nWhen scanning over very large tables (hundreds of TBs or even PBs),\nusing the default `spark.max-splits-data-size-per-partition` might\nresult in too many Spark executors (e.g. >50K) and cause jobs to be\nunstable.\n\nThe long term solution is to set\n`spark.max-splits-data-size-per-partition` to be reasonably large, and\nleverage historic based optimizer to figure out the optimal split size\nper partition. In a short term, having a max Spark input partition count\nmakes it makes it easier for job auto migration.", "committedDate": "2020-08-24T05:39:37Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM4NDYxMg==", "url": "https://github.com/prestodb/presto/pull/14943#discussion_r475384612", "bodyText": "Just curious, will this be the new default to replace 2000 in production? If not,  maybe keep it as 16 to make it easier for PrestoQueryRunner", "author": "viczhang861", "createdAt": "2020-08-24T07:09:26Z", "path": "presto-spark-base/src/main/java/com/facebook/presto/spark/PrestoSparkConfig.java", "diffHunk": "@@ -25,7 +25,8 @@\n public class PrestoSparkConfig\n {\n     private boolean sparkPartitionCountAutoTuneEnabled = true;\n-    private int initialSparkPartitionCount = 16;\n+    private int maxSparkInputPartitionCountForAutoTune = 1000;\n+    private int initialSparkPartitionCount = 100;", "originalCommit": "4d4b2d085ec0d730945897e2b9b1f9e02d454128", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "2a714869435ec54a86bcdc9dc4903d02167bad88", "url": "https://github.com/prestodb/presto/commit/2a714869435ec54a86bcdc9dc4903d02167bad88", "message": "Add max Spark input partition count for auto tune\n\nWhen scanning over very large tables (hundreds of TBs or even PBs),\nusing the default `spark.max-splits-data-size-per-partition` might\nresult in too many Spark executors (e.g. >50K) and cause jobs to be\nunstable.\n\nThe long term solution is to set\n`spark.max-splits-data-size-per-partition` to be reasonably large, and\nleverage historic based optimizer to figure out the optimal split size\nper partition. In a short term, having a max Spark input partition count\nmakes it makes it easier for job auto migration.", "committedDate": "2020-08-24T17:21:10Z", "type": "forcePushed"}, {"oid": "4b08f76250ac93a7989ca797f700e97be9889202", "url": "https://github.com/prestodb/presto/commit/4b08f76250ac93a7989ca797f700e97be9889202", "message": "Add max Spark input partition count for auto tune\n\nWhen scanning over very large tables (hundreds of TBs or even PBs),\nusing the default `spark.max-splits-data-size-per-partition` might\nresult in too many Spark executors (e.g. >50K) and cause jobs to be\nunstable.\n\nThe long term solution is to set\n`spark.max-splits-data-size-per-partition` to be reasonably large, and\nleverage historic based optimizer to figure out the optimal split size\nper partition. In a short term, having a max Spark input partition count\nmakes it makes it easier for job auto migration.", "committedDate": "2020-08-24T18:20:55Z", "type": "commit"}, {"oid": "4b08f76250ac93a7989ca797f700e97be9889202", "url": "https://github.com/prestodb/presto/commit/4b08f76250ac93a7989ca797f700e97be9889202", "message": "Add max Spark input partition count for auto tune\n\nWhen scanning over very large tables (hundreds of TBs or even PBs),\nusing the default `spark.max-splits-data-size-per-partition` might\nresult in too many Spark executors (e.g. >50K) and cause jobs to be\nunstable.\n\nThe long term solution is to set\n`spark.max-splits-data-size-per-partition` to be reasonably large, and\nleverage historic based optimizer to figure out the optimal split size\nper partition. In a short term, having a max Spark input partition count\nmakes it makes it easier for job auto migration.", "committedDate": "2020-08-24T18:20:55Z", "type": "forcePushed"}]}