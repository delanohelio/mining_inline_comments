{"pr_number": 14321, "pr_title": "Optimize metastore calls", "pr_createdAt": "2020-04-01T00:12:35Z", "pr_url": "https://github.com/prestodb/presto/pull/14321", "timeline": [{"oid": "2510a436ee6bd86c861a028561b5eabd0ce6e308", "url": "https://github.com/prestodb/presto/commit/2510a436ee6bd86c861a028561b5eabd0ce6e308", "message": "Optimize metastore communication when writing to partitioned table\n\nAvoid unnecesary metastore calls on Presto workers when writing to\na partitioned table.\n\nGenerally it is required to get the partition information on the worker\nto figure out the storage format and other partition parameters.\n\nHowever if the partitions are immutable the append is not supported, thus\nthe information about the underlying storage format of a partition is not\nneeded.\n\nHowever the getPartition call is still needed to check if the partition\nexist. As in case when overwrite is not allowed we would like to fail fast.\n\nGiven the number of extra metastore calls it results into it feels like\nit is not reasonable price to pay for fail fast for this non very common\ncase.\n\nIf the direct write into the destination partition is required (with no\nstaging directory) the old model should stay in place, as it is the only\nway to avoid adding files into the folder of an immutable partition.", "committedDate": "2020-04-01T22:54:05Z", "type": "forcePushed"}, {"oid": "2d2a9267d95e0ada0ece9861643b3d8111ced84a", "url": "https://github.com/prestodb/presto/commit/2d2a9267d95e0ada0ece9861643b3d8111ced84a", "message": "Optimize metastore communication when writing to partitioned table\n\nAvoid unnecesary metastore calls on Presto workers when writing to\na partitioned table.\n\nGenerally it is required to get the partition information on the worker\nto figure out the storage format and other partition parameters.\n\nHowever if the partitions are immutable the append is not supported, thus\nthe information about the underlying storage format of a partition is not\nneeded.\n\nHowever the getPartition call is still needed to check if the partition\nexist. As in case when overwrite is not allowed we would like to fail fast.\n\nGiven the number of extra metastore calls it results into it feels like\nit is not reasonable price to pay for fail fast for this non very common\ncase.\n\nIf the direct write into the destination partition is required (with no\nstaging directory) the old model should stay in place, as it is the only\nway to avoid adding files into the folder of an immutable partition.", "committedDate": "2020-04-02T17:39:04Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzMxMzMyNA==", "url": "https://github.com/prestodb/presto/pull/14321#discussion_r403313324", "bodyText": "The method calling this already calculating it differently? 522248f#diff-bd92d40b327dea510bb55e3f197aa911R302\nSeems like we can either generate it from the name or from the column values. Would be nice to be consistent and not do it twice?", "author": "aweisberg", "createdAt": "2020-04-03T20:33:40Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveWriterFactory.java", "diffHunk": "@@ -308,38 +309,107 @@ public HiveWriter createWriter(Page partitionColumns, int position, OptionalInt\n             partitionName = Optional.empty();\n         }\n \n+        WriterParameters writerParameters = getWriterParameters(partitionName, bucketNumber);\n+\n+        validateSchema(partitionName, writerParameters.getSchema());\n+\n+        String extension = getFileExtension(writerParameters.getOutputStorageFormat(), compressionCodec);\n+        String targetFileName;\n+        if (bucketNumber.isPresent()) {\n+            targetFileName = computeBucketedFileName(filePrefix, bucketNumber.getAsInt()) + extension;\n+        }\n+        else {\n+            targetFileName = filePrefix + \"_\" + randomUUID() + extension;\n+        }\n+\n+        String writeFileName;\n+        if (partitionCommitRequired) {\n+            writeFileName = \".tmp.presto.\" + filePrefix + \"_\" + randomUUID() + extension;\n+        }\n+        else {\n+            writeFileName = targetFileName;\n+        }\n+\n+        Path path = new Path(writerParameters.getWriteInfo().getWritePath(), writeFileName);\n+\n+        HiveFileWriter hiveFileWriter = null;\n+        for (HiveFileWriterFactory fileWriterFactory : fileWriterFactories) {\n+            Optional<HiveFileWriter> fileWriter = fileWriterFactory.createFileWriter(\n+                    path,\n+                    dataColumns.stream()\n+                            .map(DataColumn::getName)\n+                            .collect(toList()),\n+                    writerParameters.getOutputStorageFormat(),\n+                    writerParameters.getSchema(),\n+                    conf,\n+                    session);\n+            if (fileWriter.isPresent()) {\n+                hiveFileWriter = fileWriter.get();\n+                break;\n+            }\n+        }\n+\n+        if (hiveFileWriter == null) {\n+            hiveFileWriter = new RecordFileWriter(\n+                    path,\n+                    dataColumns.stream()\n+                            .map(DataColumn::getName)\n+                            .collect(toList()),\n+                    writerParameters.getOutputStorageFormat(),\n+                    writerParameters.getSchema(),\n+                    partitionStorageFormat.getEstimatedWriterSystemMemoryUsage(),\n+                    conf,\n+                    typeManager,\n+                    session);\n+        }\n+\n+        if (sortingFileWriterFactory.isPresent()) {\n+            checkState(bucketNumber.isPresent(), \"missing bucket number for sorted table write\");\n+            hiveFileWriter = sortingFileWriterFactory.get().createSortingFileWriter(\n+                    path,\n+                    hiveFileWriter,\n+                    bucketNumber.getAsInt(),\n+                    writerParameters.getWriteInfo().getTempPath());\n+        }\n+\n+        return new HiveWriter(\n+                hiveFileWriter,\n+                partitionName,\n+                writerParameters.getUpdateMode(),\n+                new FileWriteInfo(writeFileName, targetFileName),\n+                writerParameters.getWriteInfo().getWritePath().toString(),\n+                writerParameters.getWriteInfo().getTargetPath().toString(),\n+                createCommitEventListener(path, partitionName, hiveFileWriter, writerParameters),\n+                hiveWriterStats);\n+    }\n+\n+    private WriterParameters getWriterParameters(Optional<String> partitionName, OptionalInt bucketNumber)\n+    {\n         // attempt to get the existing partition (if this is an existing partitioned table)\n         Optional<Partition> partition = Optional.empty();\n-        if (!partitionValues.isEmpty() && table != null) {\n-            partition = pageSinkMetadataProvider.getPartition(partitionValues);\n+        if (partitionName.isPresent() && table != null) {\n+            partition = pageSinkMetadataProvider.getPartition(toPartitionValues(partitionName.get()));", "originalCommit": "522248f158838926751ef340aa72bf154961cd59", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM4MzA3MQ==", "url": "https://github.com/prestodb/presto/pull/14321#discussion_r404383071", "bodyText": "I just wanted to avoid passing both, Optional<PartitionName> and Optional<List<String>> partitionValues to keep the signature simple.", "author": "arhimondr", "createdAt": "2020-04-06T20:57:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzMxMzMyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzMxNDUxNQ==", "url": "https://github.com/prestodb/presto/pull/14321#discussion_r403314515", "bodyText": "Intentional line break?", "author": "aweisberg", "createdAt": "2020-04-03T20:35:19Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveWriterFactory.java", "diffHunk": "@@ -308,38 +309,107 @@ public HiveWriter createWriter(Page partitionColumns, int position, OptionalInt\n             partitionName = Optional.empty();\n         }\n \n+        WriterParameters writerParameters = getWriterParameters(partitionName, bucketNumber);\n+\n+        validateSchema(partitionName, writerParameters.getSchema());\n+\n+        String extension = getFileExtension(writerParameters.getOutputStorageFormat(), compressionCodec);\n+        String targetFileName;\n+        if (bucketNumber.isPresent()) {\n+            targetFileName = computeBucketedFileName(filePrefix, bucketNumber.getAsInt()) + extension;\n+        }\n+        else {\n+            targetFileName = filePrefix + \"_\" + randomUUID() + extension;\n+        }\n+\n+        String writeFileName;\n+        if (partitionCommitRequired) {\n+            writeFileName = \".tmp.presto.\" + filePrefix + \"_\" + randomUUID() + extension;\n+        }\n+        else {\n+            writeFileName = targetFileName;\n+        }\n+\n+        Path path = new Path(writerParameters.getWriteInfo().getWritePath(), writeFileName);\n+\n+        HiveFileWriter hiveFileWriter = null;\n+        for (HiveFileWriterFactory fileWriterFactory : fileWriterFactories) {\n+            Optional<HiveFileWriter> fileWriter = fileWriterFactory.createFileWriter(\n+                    path,\n+                    dataColumns.stream()\n+                            .map(DataColumn::getName)\n+                            .collect(toList()),\n+                    writerParameters.getOutputStorageFormat(),\n+                    writerParameters.getSchema(),\n+                    conf,\n+                    session);\n+            if (fileWriter.isPresent()) {\n+                hiveFileWriter = fileWriter.get();\n+                break;\n+            }\n+        }\n+\n+        if (hiveFileWriter == null) {\n+            hiveFileWriter = new RecordFileWriter(\n+                    path,\n+                    dataColumns.stream()\n+                            .map(DataColumn::getName)\n+                            .collect(toList()),\n+                    writerParameters.getOutputStorageFormat(),\n+                    writerParameters.getSchema(),\n+                    partitionStorageFormat.getEstimatedWriterSystemMemoryUsage(),\n+                    conf,\n+                    typeManager,\n+                    session);\n+        }\n+\n+        if (sortingFileWriterFactory.isPresent()) {\n+            checkState(bucketNumber.isPresent(), \"missing bucket number for sorted table write\");\n+            hiveFileWriter = sortingFileWriterFactory.get().createSortingFileWriter(\n+                    path,\n+                    hiveFileWriter,\n+                    bucketNumber.getAsInt(),\n+                    writerParameters.getWriteInfo().getTempPath());\n+        }\n+\n+        return new HiveWriter(\n+                hiveFileWriter,\n+                partitionName,\n+                writerParameters.getUpdateMode(),\n+                new FileWriteInfo(writeFileName, targetFileName),\n+                writerParameters.getWriteInfo().getWritePath().toString(),\n+                writerParameters.getWriteInfo().getTargetPath().toString(),\n+                createCommitEventListener(path, partitionName, hiveFileWriter, writerParameters),\n+                hiveWriterStats);\n+    }\n+\n+    private WriterParameters getWriterParameters(Optional<String> partitionName, OptionalInt bucketNumber)\n+    {\n         // attempt to get the existing partition (if this is an existing partitioned table)\n         Optional<Partition> partition = Optional.empty();\n-        if (!partitionValues.isEmpty() && table != null) {\n-            partition = pageSinkMetadataProvider.getPartition(partitionValues);\n+        if (partitionName.isPresent() && table != null) {\n+            partition = pageSinkMetadataProvider.getPartition(toPartitionValues(partitionName.get()));\n         }\n \n         UpdateMode updateMode;\n         Properties schema;\n         WriteInfo writeInfo;\n         StorageFormat outputStorageFormat;\n+", "originalCommit": "522248f158838926751ef340aa72bf154961cd59", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk1MzA3MQ==", "url": "https://github.com/prestodb/presto/pull/14321#discussion_r404953071", "bodyText": "Yeah maybe let's remove this line break.", "author": "shixuan-fan", "createdAt": "2020-04-07T16:38:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzMxNDUxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcyNTI4Ng==", "url": "https://github.com/prestodb/presto/pull/14321#discussion_r403725286", "bodyText": "If they are are enabled by default then isn't what the test needs to do the inverse? It needs test with the optimized writers disabled?", "author": "aweisberg", "createdAt": "2020-04-05T16:31:10Z", "path": "presto-hive/src/test/java/com/facebook/presto/hive/TestHiveIntegrationSmokeTest.java", "diffHunk": "@@ -4704,59 +4703,8 @@ private static ConnectorSession getConnectorSession(Session session)\n \n     private void testWithAllStorageFormats(BiConsumer<Session, HiveStorageFormat> test)\n     {\n-        for (TestingHiveStorageFormat storageFormat : getAllTestingHiveStorageFormat()) {\n-            testWithStorageFormat(storageFormat, test);\n-        }\n-    }\n-\n-    private static void testWithStorageFormat(TestingHiveStorageFormat storageFormat, BiConsumer<Session, HiveStorageFormat> test)\n-    {\n-        requireNonNull(storageFormat, \"storageFormat is null\");\n-        requireNonNull(test, \"test is null\");\n-        Session session = storageFormat.getSession();\n-        try {\n-            test.accept(session, storageFormat.getFormat());\n-        }\n-        catch (Exception | AssertionError e) {\n-            fail(format(\"Failure for format %s with properties %s\", storageFormat.getFormat(), session.getConnectorProperties()), e);\n-        }\n-    }\n-\n-    private List<TestingHiveStorageFormat> getAllTestingHiveStorageFormat()\n-    {\n-        Session session = getSession();\n-        ImmutableList.Builder<TestingHiveStorageFormat> formats = ImmutableList.builder();\n-        for (HiveStorageFormat hiveStorageFormat : HiveStorageFormat.values()) {\n-            formats.add(new TestingHiveStorageFormat(session, hiveStorageFormat));\n-        }\n-        formats.add(new TestingHiveStorageFormat(\n-                Session.builder(session).setCatalogSessionProperty(session.getCatalog().get(), \"orc_optimized_writer_enabled\", \"true\").build(),\n-                HiveStorageFormat.ORC));\n-        formats.add(new TestingHiveStorageFormat(\n-                Session.builder(session).setCatalogSessionProperty(session.getCatalog().get(), \"orc_optimized_writer_enabled\", \"true\").build(),\n-                HiveStorageFormat.DWRF));\n-        return formats.build();\n-    }\n-\n-    private static class TestingHiveStorageFormat\n-    {\n-        private final Session session;\n-        private final HiveStorageFormat format;\n-\n-        TestingHiveStorageFormat(Session session, HiveStorageFormat format)\n-        {\n-            this.session = requireNonNull(session, \"session is null\");\n-            this.format = requireNonNull(format, \"format is null\");\n-        }\n-\n-        public Session getSession()\n-        {\n-            return session;\n-        }\n-\n-        public HiveStorageFormat getFormat()\n-        {\n-            return format;\n+        for (HiveStorageFormat storageFormat : HiveStorageFormat.values()) {", "originalCommit": "7cf2809cfd33ed87a1940df0814e897255cb62e4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM4Mzc5Ng==", "url": "https://github.com/prestodb/presto/pull/14321#discussion_r404383796", "bodyText": "The old writers are provided by the Hadoop library. The old writers have been also disabled for a quite some time, and it doesn't look like we support them anymore.", "author": "arhimondr", "createdAt": "2020-04-06T20:58:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcyNTI4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcyNzY0Ng==", "url": "https://github.com/prestodb/presto/pull/14321#discussion_r403727646", "bodyText": "Why does this have to include partitions being appended to? Seems like we don't use this in the append path.\nAre there cases where we will attempt to append and also overwrite/new?", "author": "aweisberg", "createdAt": "2020-04-05T16:48:59Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveMetadata.java", "diffHunk": "@@ -1548,6 +1553,8 @@ public HiveInsertTableHandle beginInsert(ConnectorSession session, ConnectorTabl\n                 .collect(toImmutableMap(HiveColumnHandle::getName, column -> column.getHiveType().getType(typeManager)));\n         Map<List<String>, ComputedStatistics> partitionComputedStatistics = createComputedStatisticsToPartitionMap(computedStatistics, partitionedBy, columnTypes);\n \n+        Set<String> existingPartitions = getExistingPartitionNames(handle.getSchemaName(), handle.getTableName(), partitionUpdates);", "originalCommit": "2d2a9267d95e0ada0ece9861643b3d8111ced84a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM4NDUwNg==", "url": "https://github.com/prestodb/presto/pull/14321#discussion_r404384506", "bodyText": "The write mode APPEND can only be set if the partition exist. The existence of partition is checked explicitly on the writer, so i thought that checking it here again can be avoided.", "author": "arhimondr", "createdAt": "2020-04-06T20:59:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzcyNzY0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk2OTY3NQ==", "url": "https://github.com/prestodb/presto/pull/14321#discussion_r404969675", "bodyText": "The only concern I have is that this seems to change the default behavior and I'm not sure if we want to start with setting the default value to true.", "author": "shixuan-fan", "createdAt": "2020-04-07T17:02:59Z", "path": "presto-hive/src/main/java/com/facebook/presto/hive/HiveClientConfig.java", "diffHunk": "@@ -88,6 +88,7 @@\n     private boolean respectTableFormat = true;\n     private boolean immutablePartitions;\n     private boolean insertOverwriteImmutablePartitions;\n+    private boolean failFastOnInsertIntoImmutablePartitionsEnabled;", "originalCommit": "2d2a9267d95e0ada0ece9861643b3d8111ced84a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTE1NDU0MQ==", "url": "https://github.com/prestodb/presto/pull/14321#discussion_r405154541", "bodyText": "I think you are right. Changing it to true by default.", "author": "arhimondr", "createdAt": "2020-04-07T22:39:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDk2OTY3NQ=="}], "type": "inlineReview"}, {"oid": "b1ad7d4e3eb36eab86e01e7a07fc74e86d821e12", "url": "https://github.com/prestodb/presto/commit/b1ad7d4e3eb36eab86e01e7a07fc74e86d821e12", "message": "Refactor HiveWriterFactory#createWriter\n\nThe method is way too large. It is hard to make any changes to it.", "committedDate": "2020-04-07T22:41:05Z", "type": "commit"}, {"oid": "1960cc4bd6f704056a5fa6ba62aef6382e04bf22", "url": "https://github.com/prestodb/presto/commit/1960cc4bd6f704056a5fa6ba62aef6382e04bf22", "message": "Refactor HiveWriterFactory#getWriterParameters\n\nSplit this method into smaller once as it is too large and hard to\nfollow and maintain.", "committedDate": "2020-04-07T22:42:19Z", "type": "commit"}, {"oid": "c59c38d8e9e29e8847b07387df36b814d979c6c5", "url": "https://github.com/prestodb/presto/commit/c59c38d8e9e29e8847b07387df36b814d979c6c5", "message": "Refactor TestHiveIntegrationSmokeTest\n\nOptimized writers for ORC and RC file are enabled by default, thus\nthere's not need to enable them explicitly in the smoke test", "committedDate": "2020-04-07T22:42:20Z", "type": "commit"}, {"oid": "ca24181fda69e8d024160a184c4b0236c1399ed1", "url": "https://github.com/prestodb/presto/commit/ca24181fda69e8d024160a184c4b0236c1399ed1", "message": "Add smoke test for insert into immutable partition", "committedDate": "2020-04-07T22:42:20Z", "type": "commit"}, {"oid": "cb046c249f89af3d5a7bd1b8a7f0fe5ea88f43b4", "url": "https://github.com/prestodb/presto/commit/cb046c249f89af3d5a7bd1b8a7f0fe5ea88f43b4", "message": "Optimize metastore communication when writing to partitioned table\n\nAvoid unnecesary metastore calls on Presto workers when writing to\na partitioned table.\n\nGenerally it is required to get the partition information on the worker\nto figure out the storage format and other partition parameters.\n\nHowever if the partitions are immutable the append is not supported, thus\nthe information about the underlying storage format of a partition is not\nneeded.\n\nHowever the getPartition call is still needed to check if the partition\nexist. As in case when overwrite is not allowed we would like to fail fast.\n\nGiven the number of extra metastore calls it results into it feels like\nit is not reasonable price to pay for fail fast for this non very common\ncase.\n\nIf the direct write into the destination partition is required (with no\nstaging directory) the old model should stay in place, as it is the only\nway to avoid adding files into the folder of an immutable partition.", "committedDate": "2020-04-07T22:42:20Z", "type": "commit"}, {"oid": "cb046c249f89af3d5a7bd1b8a7f0fe5ea88f43b4", "url": "https://github.com/prestodb/presto/commit/cb046c249f89af3d5a7bd1b8a7f0fe5ea88f43b4", "message": "Optimize metastore communication when writing to partitioned table\n\nAvoid unnecesary metastore calls on Presto workers when writing to\na partitioned table.\n\nGenerally it is required to get the partition information on the worker\nto figure out the storage format and other partition parameters.\n\nHowever if the partitions are immutable the append is not supported, thus\nthe information about the underlying storage format of a partition is not\nneeded.\n\nHowever the getPartition call is still needed to check if the partition\nexist. As in case when overwrite is not allowed we would like to fail fast.\n\nGiven the number of extra metastore calls it results into it feels like\nit is not reasonable price to pay for fail fast for this non very common\ncase.\n\nIf the direct write into the destination partition is required (with no\nstaging directory) the old model should stay in place, as it is the only\nway to avoid adding files into the folder of an immutable partition.", "committedDate": "2020-04-07T22:42:20Z", "type": "forcePushed"}]}