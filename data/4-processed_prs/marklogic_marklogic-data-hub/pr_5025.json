{"pr_number": 5025, "pr_title": "DHFPROD-6205: Customize Optic optimization level via Spark connector", "pr_createdAt": "2020-12-17T23:53:38Z", "pr_url": "https://github.com/marklogic/marklogic-data-hub/pull/5025", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg1NzI1OA==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r545857258", "bodyText": "op.import returns a plan, so to avoid duplication here, try this:\nlet thePlan = op.import(...);\nif (optimization level is set) thePlan = thePlan.prepare(...);\nthePlan.result(...).toArray().forEach(...)", "author": "rjrudin", "createdAt": "2020-12-18T14:16:00Z", "path": "marklogic-data-hub/src/main/resources/ml-modules/root/marklogic-data-hub-spark-connector/readRows.sjs", "diffHunk": "@@ -25,19 +25,32 @@ const results = [endpointState];\n \n const partitionNumber = endpointConstants.partitionNumber;\n const partition = endpointConstants.initializationResponse.partitions[partitionNumber];\n+const optimizationlevel = endpointConstants.optimizationlevel;\n \n if (endpointState.batchNumber <= partition.batchCount) {\n   // Determine the min/max rowID of the current batch number\n   const batch = partitionLib.getPartitionBatch(partition, endpointState.batchNumber);\n \n   // Run the parameterized plan, constraining it to the min and max row ID of the current batch\n-  op.import(endpointConstants.initializationResponse.parameterizedPlan)\n-    .result(null, {\n-      \"MIN_ROW_ID\": batch.min,\n-      \"MAX_ROW_ID\": batch.max\n-    })\n-    .toArray()\n-    .forEach(row => results.push(row));\n+  if(optimizationlevel >= 0) {", "originalCommit": "32067b92fc4d486f5095ce2e54856c9992d27c5f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAzOTc0Nw==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r546039747", "bodyText": "There's still duplication here of the \"result\" call. You can avoid that by doing what I showed above - call thePlan = thePlan.prepare if there's an optimization level.", "author": "rjrudin", "createdAt": "2020-12-18T19:14:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg1NzI1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjA1NDM3Mw==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r546054373", "bodyText": "Done. Sorry about the confusion.!", "author": "anu3990", "createdAt": "2020-12-18T19:41:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg1NzI1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg1NzY2NQ==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r545857665", "bodyText": "Since this is needed for every test, put it in a BeforeEach-annotated method at the top of the test. For readability, it's helpful to see BeforeEach methods at the top.", "author": "rjrudin", "createdAt": "2020-12-18T14:16:45Z", "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/reader/ReadWithCustomOptimizationlevel.java", "diffHunk": "@@ -0,0 +1,62 @@\n+package com.marklogic.hub.spark.sql.sources.v2.reader;\n+\n+import com.marklogic.hub.spark.sql.sources.v2.Options;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.List;\n+\n+import static org.junit.jupiter.api.Assertions.*;\n+\n+public class ReadWithCustomOptimizationlevel extends AbstractSparkReadTest {\n+\n+    @Test\n+    public void testStringOptimizationlevel() {\n+        setUp();\n+        Options options = newOptions().withView(\"Customer\").withStringOptimizationlevel(\"2\");\n+        List<InternalRow> rows = readRows(new HubDataSourceReader(options.toDataSourceOptions()));\n+        assertEquals(10, rows.size(), \"All 10 rows could not be read.\");\n+    }\n+\n+    @Test\n+    public void testIntegerOptimizationlevel() {\n+        setUp();\n+        Options options = newOptions().withView(\"Customer\").withIntegerOptimizationlevel(2);\n+        List<InternalRow> rows = readRows(new HubDataSourceReader(options.toDataSourceOptions()));\n+        assertEquals(10, rows.size(), \"All 10 rows could not be read.\");\n+    }\n+\n+    @Test\n+    public void testInvalidOptimizationlevel() {\n+        setUp();\n+        Options options = newOptions().withView(\"Customer\").withIntegerOptimizationlevel(6);\n+        IllegalArgumentException ex = assertThrows(IllegalArgumentException.class,\n+            () -> readRows(new HubDataSourceReader(options.toDataSourceOptions())));\n+        assertEquals(\"optimizationlevel needs to be 0,1 or 2\",\n+            ex.getMessage());\n+\n+        Options newOptions = newOptions().withView(\"Customer\").withIntegerOptimizationlevel(-1);\n+        ex = assertThrows(IllegalArgumentException.class,\n+            () -> readRows(new HubDataSourceReader(newOptions.toDataSourceOptions())));\n+        assertEquals(\"optimizationlevel needs to be 0,1 or 2\",\n+            ex.getMessage());\n+    }\n+\n+    @Test\n+    public void testDecimalOptimizationlevel() {\n+        setUp();\n+        Options options = newOptions().withView(\"Customer\").withStringOptimizationlevel(\"1.5\");\n+        IllegalArgumentException ex = assertThrows(IllegalArgumentException.class,\n+            () -> readRows(new HubDataSourceReader(options.toDataSourceOptions())));\n+        assertEquals(\"optimizationlevel needs to be 0,1 or 2\",\n+            ex.getMessage());\n+    }\n+\n+    private void setUp() {", "originalCommit": "32067b92fc4d486f5095ce2e54856c9992d27c5f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTg1ODgzNA==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r545858834", "bodyText": "Given that we have a couple levels of nesting going on here, that's a good indicator that we could use a new private method for readability here - e.g.\naddOptimizationLevel(options, endpointConstants);\n\nThat method will then do the error handling and validation of the value that the user provides.", "author": "rjrudin", "createdAt": "2020-12-18T14:18:39Z", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubInputPartitionReader.java", "diffHunk": "@@ -88,10 +88,21 @@ public void close() {\n         logger.debug(\"Closing\");\n     }\n \n-    private ObjectNode buildEndpointConstants(JsonNode initializationResponse, int partitionNumber) {\n+    private ObjectNode buildEndpointConstants(Map<String, String> options, JsonNode initializationResponse, int partitionNumber) {\n         ObjectNode endpointConstants = objectMapper.createObjectNode();\n         endpointConstants.set(\"initializationResponse\", initializationResponse);\n         endpointConstants.put(\"partitionNumber\", partitionNumber);\n+        String optimizationlevel = options.get(\"optimizationlevel\");", "originalCommit": "32067b92fc4d486f5095ce2e54856c9992d27c5f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b3ec443468645149ab7114020cd65e2749071323", "url": "https://github.com/marklogic/marklogic-data-hub/commit/b3ec443468645149ab7114020cd65e2749071323", "message": "DHFPROD-6205: Customize Optic optimization level via Spark connector", "committedDate": "2020-12-18T18:56:23Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAzODUwNQ==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/5025#discussion_r546038505", "bodyText": "It's best to use StringUtils.hasText or StringUtils.isNotEmpty here, as that will do a trim().length(), which rules out whitespace.", "author": "rjrudin", "createdAt": "2020-12-18T19:13:19Z", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/reader/HubInputPartitionReader.java", "diffHunk": "@@ -117,4 +122,19 @@ private void readNextBatchOfRows() {\n             rowIndex = 0;\n         }\n     }\n+\n+    private ObjectNode addOptimizationLevel(Map<String, String> options, ObjectNode endpointConstants){\n+        String optimizationlevel = options.get(\"optimizationlevel\");\n+        if(optimizationlevel!=null && optimizationlevel.length()>0) {", "originalCommit": "b3ec443468645149ab7114020cd65e2749071323", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "12460562e8b9fdd48742a18b7edb94db4ab1326f", "url": "https://github.com/marklogic/marklogic-data-hub/commit/12460562e8b9fdd48742a18b7edb94db4ab1326f", "message": "DHFPROD-6205: Customize Optic optimization level via Spark connector", "committedDate": "2020-12-18T19:38:33Z", "type": "commit"}, {"oid": "12460562e8b9fdd48742a18b7edb94db4ab1326f", "url": "https://github.com/marklogic/marklogic-data-hub/commit/12460562e8b9fdd48742a18b7edb94db4ab1326f", "message": "DHFPROD-6205: Customize Optic optimization level via Spark connector", "committedDate": "2020-12-18T19:38:33Z", "type": "forcePushed"}]}