{"pr_number": 4697, "pr_title": "DHFPROD-6095: - Run connector against DHF 5.x", "pr_createdAt": "2020-10-09T21:50:49Z", "pr_url": "https://github.com/marklogic/marklogic-data-hub/pull/4697", "timeline": [{"oid": "e1e2ff00baf8dace0af03ef6c8b187718e8137f5", "url": "https://github.com/marklogic/marklogic-data-hub/commit/e1e2ff00baf8dace0af03ef6c8b187718e8137f5", "message": "DHFPROD-6095 - Run connector against DHF 5.x", "committedDate": "2020-10-09T21:48:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk4NDM1NA==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r502984354", "bodyText": "These imports should all be removed as they're not used", "author": "rjrudin", "createdAt": "2020-10-12T00:00:45Z", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/writer/HubDataWriterFactory.java", "diffHunk": "@@ -15,15 +15,18 @@\n  */\n package com.marklogic.hub.spark.sql.sources.v2.writer;\n \n+import com.fasterxml.jackson.databind.node.ObjectNode;", "originalCommit": "e1e2ff00baf8dace0af03ef6c8b187718e8137f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk4NDY3MA==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r502984670", "bodyText": "This PR should including deleting the two files from /data-hub/5/data-services/ingestion from git, as they're being moved to /marklogic-data-hub-spark-connector/", "author": "rjrudin", "createdAt": "2020-10-12T00:03:19Z", "path": "marklogic-data-hub-spark-connector/src/test/java/com/marklogic/hub/spark/sql/sources/v2/WriteDataTest.java", "diffHunk": "@@ -132,6 +132,20 @@ void invalidPermissionsString() {\n         assertTrue(ex.getCause().getMessage().contains(\"Unable to parse permissions: rest-reader,read,rest-writer\"), \"Unexpected error message: \" + ex.getCause().getMessage());\n     }\n \n+    @Test\n+    public void testEndpointsAreLoaded() throws Exception {\n+        TextDocumentManager modMgr = getHubClient().getModulesClient().newTextDocumentManager();\n+        modMgr.delete(\"/data-hub/5/data-services/ingestion/bulkIngester.api\", \"/data-hub/5/data-services/ingestion/bulkIngester.sjs\",", "originalCommit": "e1e2ff00baf8dace0af03ef6c8b187718e8137f5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDA5NTQ2MA==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r504095460", "bodyText": "Should we keep these in datahub modules too? Just in case if installer is installing these modules?", "author": "SameeraPriyathamTadikonda", "createdAt": "2020-10-13T16:32:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk4NDY3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1NTAyNw==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r504155027", "bodyText": "The modules should still be in DHF core ,but under /marklogic-data-hub-spark-connector/", "author": "rjrudin", "createdAt": "2020-10-13T18:05:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk4NDY3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk4NTQwNQ==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r502985405", "bodyText": "Pinging @SameeraPriyathamTadikonda and @ehennum  about this - I believe we should move the initialization to HubDataSourceWriter. This is based on my assumption that @SameeraPriyathamTadikonda  will be adding the initialization and finalization logic there for the job document.\nI think it makes sense though to not write this module if Ernie specifies his own ingestion path. Thus, it seems that all of the logic in this constructor should move into HubDataWriteSource. Does that seem right?", "author": "rjrudin", "createdAt": "2020-10-12T00:09:20Z", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/writer/HubDataWriter.java", "diffHunk": "@@ -142,7 +146,20 @@ protected JsonNode determineIngestionEndpointParams(Map<String, String> options)\n         }\n \n         if (doesNotHaveApiPath) {\n-            endpointParams.put(\"apiPath\", \"/data-hub/5/data-services/ingestion/bulkIngester.api\");\n+            String apiPath = \"/data-hub/5/data-services/ingestion/bulkIngester.api\";", "originalCommit": "e1e2ff00baf8dace0af03ef6c8b187718e8137f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk4NTUxNg==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r502985516", "bodyText": "We don't want to lose the original exception here - e.g:\nthrow new RuntimeException(\"Unable to write default ingestion endpoint at path: \" + path + \"; cause: \" + e.getMessage(), e);", "author": "rjrudin", "createdAt": "2020-10-12T00:10:19Z", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/writer/HubDataWriter.java", "diffHunk": "@@ -142,7 +146,20 @@ protected JsonNode determineIngestionEndpointParams(Map<String, String> options)\n         }\n \n         if (doesNotHaveApiPath) {\n-            endpointParams.put(\"apiPath\", \"/data-hub/5/data-services/ingestion/bulkIngester.api\");\n+            String apiPath = \"/data-hub/5/data-services/ingestion/bulkIngester.api\";\n+\n+            if(hubClient.getModulesClient().newJSONDocumentManager().exists(apiPath) == null) {\n+                IOUtil ioUtil = new IOUtil(this.hubClient.getModulesClient());\n+                try {\n+                    ioUtil.load(\"bulkIngester.api\");\n+                } catch (IOException e) {\n+                    throw new RuntimeException(\"Error occurred while loading default endpoints.\");", "originalCommit": "e1e2ff00baf8dace0af03ef6c8b187718e8137f5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk4NTgxNA==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r502985814", "bodyText": "We'll need to toss these files into the shadowJar, which is part of #4695 .\nOnce it's in the jar, the Spring class ClassPathResource can be used to retrieve it, no need for IOUtil:\nnew ClassPathResource(\"marklogic-data-hub-spark-connector/bulkIngester.api\").getInputStream()", "author": "rjrudin", "createdAt": "2020-10-12T00:12:51Z", "path": "marklogic-data-hub-spark-connector/src/main/java/com/marklogic/hub/spark/sql/sources/v2/writer/HubDataWriter.java", "diffHunk": "@@ -142,7 +146,20 @@ protected JsonNode determineIngestionEndpointParams(Map<String, String> options)\n         }\n \n         if (doesNotHaveApiPath) {\n-            endpointParams.put(\"apiPath\", \"/data-hub/5/data-services/ingestion/bulkIngester.api\");\n+            String apiPath = \"/data-hub/5/data-services/ingestion/bulkIngester.api\";\n+\n+            if(hubClient.getModulesClient().newJSONDocumentManager().exists(apiPath) == null) {\n+                IOUtil ioUtil = new IOUtil(this.hubClient.getModulesClient());\n+                try {\n+                    ioUtil.load(\"bulkIngester.api\");", "originalCommit": "e1e2ff00baf8dace0af03ef6c8b187718e8137f5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzcwNDc5NQ==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r503704795", "bodyText": "@rjrudin . I am guessing -\nnew ClassPathResource(\"marklogic-data-hub-spark-connector/bulkIngester.api\").getInputStream()\nis a replacement for IOUtil.testFileToString().\nThere are other operations in IOUtil as well like - adding permissions and writing to data-hub-MODULES database. Please let me know if there is a method in data-hub that handles the permissions part. Will go ahead and replace them.", "author": "anu3990", "createdAt": "2020-10-13T06:49:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk4NTgxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzg3MDk4NQ==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r503870985", "bodyText": "@anu3990 @SameeraPriyathamTadikonda I think you'll want a separate method for building a DocumentWriteOperation for each endpoint module that needs to be written (it would be unusual, but it's possible that the connector only needs to write 1 or 2 of the 3 endpoint modules). And then another method will handle adding each DWO to a DocumentWriteSet, which can then be written to the modules database. I think all of that logic should be in HubDataWriterSource for now - there's no need for a separate utility class, the Java Client makes it pretty simple. We'd just want to avoid any duplication within HDWS.", "author": "rjrudin", "createdAt": "2020-10-13T11:22:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjk4NTgxNA=="}], "type": "inlineReview"}, {"oid": "772e8eb137126e7cc01eaab1c873ae3f0261e757", "url": "https://github.com/marklogic/marklogic-data-hub/commit/772e8eb137126e7cc01eaab1c873ae3f0261e757", "message": "DHFPROD-6095 - Run connector against DHF 5.2.x.", "committedDate": "2020-10-13T06:44:04Z", "type": "forcePushed"}, {"oid": "a7e6528112d6d687cdd22a56453643d9e2404b71", "url": "https://github.com/marklogic/marklogic-data-hub/commit/a7e6528112d6d687cdd22a56453643d9e2404b71", "message": "DHFPROD-6095 - Run connector against DHF 5.2.x.", "committedDate": "2020-10-13T21:35:51Z", "type": "forcePushed"}, {"oid": "27dc710892e1cf3932e893b38aa95fb638fa6385", "url": "https://github.com/marklogic/marklogic-data-hub/commit/27dc710892e1cf3932e893b38aa95fb638fa6385", "message": "DHFPROD-6095 - Run connector against DHF 5.2.x.", "committedDate": "2020-10-13T21:41:07Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI3ODU3NQ==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r504278575", "bodyText": "This file should be inside datahub/5/modules according to the previous comment(#4697 (comment)).", "author": "SameeraPriyathamTadikonda", "createdAt": "2020-10-13T21:49:19Z", "path": "marklogic-data-hub-spark-connector/src/main/resources/marklogic-data-hub-spark-connector/bulkIngester.api", "diffHunk": "@@ -1,5 +1,5 @@\n {", "originalCommit": "27dc710892e1cf3932e893b38aa95fb638fa6385", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDMyMTI0Ng==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r504321246", "bodyText": "It should be here - we want to move these modules to this location so that they can be inserted by a data-hub-operator user.", "author": "rjrudin", "createdAt": "2020-10-13T23:49:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI3ODU3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDMyNjE5Nw==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r504326197", "bodyText": "Do we intend to maintain two copies of the same endpoint?", "author": "SameeraPriyathamTadikonda", "createdAt": "2020-10-14T00:06:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI3ODU3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDY2NTI0NA==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r504665244", "bodyText": "I'm trying out the PR locally now - I'll post something to include in the connector's build.gradle file to copy the modules from the core project into the jar when the jar is built. That way, all the modules can live in the same place still. Currently, BulkIngestTest is failing because its modules no longer exist.", "author": "rjrudin", "createdAt": "2020-10-14T13:12:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI3ODU3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDY4MzIwMw==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r504683203", "bodyText": "I added this PR to copy the modules from the core project - https://github.com/anu3990/marklogic-data-hub/pull/4/files", "author": "rjrudin", "createdAt": "2020-10-14T13:37:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI3ODU3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDg4NjI4MQ==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r504886281", "bodyText": "Included all the changes. Also rebased the code.", "author": "anu3990", "createdAt": "2020-10-14T18:28:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDI3ODU3NQ=="}], "type": "inlineReview"}, {"oid": "32e8b00e7e782027a9c851a48c035f87fe4b5077", "url": "https://github.com/marklogic/marklogic-data-hub/commit/32e8b00e7e782027a9c851a48c035f87fe4b5077", "message": "DHFPROD-6095 - Run connector against DHF 5.2.x.", "committedDate": "2020-10-14T18:20:43Z", "type": "forcePushed"}, {"oid": "d27333597f30fde6888612ff8cddec40a20a9c5f", "url": "https://github.com/marklogic/marklogic-data-hub/commit/d27333597f30fde6888612ff8cddec40a20a9c5f", "message": "DHFPROD-6095 - Run connector against DHF 5.2.x.", "committedDate": "2020-10-14T21:00:14Z", "type": "forcePushed"}, {"oid": "60ff9d21af78718355afc02d44e11d839b55b1e3", "url": "https://github.com/marklogic/marklogic-data-hub/commit/60ff9d21af78718355afc02d44e11d839b55b1e3", "message": "DHFPROD-6095 - Run connector against DHF 5.2.x.", "committedDate": "2020-10-15T20:51:58Z", "type": "forcePushed"}, {"oid": "f552ca6da03eb6b99ef0223da3477c930346c942", "url": "https://github.com/marklogic/marklogic-data-hub/commit/f552ca6da03eb6b99ef0223da3477c930346c942", "message": "DHFPROD-6095 - Run connector against DHF 5.2.x.", "committedDate": "2020-10-16T15:47:04Z", "type": "forcePushed"}, {"oid": "18b9fc6cae177a213eaa57ee5f596a8afa58c3e5", "url": "https://github.com/marklogic/marklogic-data-hub/commit/18b9fc6cae177a213eaa57ee5f596a8afa58c3e5", "message": "DHFPROD-6095 - Run connector against DHF 5.2.x.", "committedDate": "2020-10-16T15:50:20Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU3NDkxNQ==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r506574915", "bodyText": "@anu3990 I'm approving, but is this even needed anymore?", "author": "rjrudin", "createdAt": "2020-10-16T16:06:42Z", "path": "marklogic-data-hub/src/main/resources/ml-modules/root/marklogic-data-hub-spark-connector/bulkIngester.sjs", "diffHunk": "@@ -72,7 +72,9 @@ if (input instanceof Sequence) {\n }\n \n inputArray.forEach(record => {\n-  state.next = state.next + 1;\n+if(state!=null && state.next!=null){", "originalCommit": "18b9fc6cae177a213eaa57ee5f596a8afa58c3e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjY3OTc4Mw==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r506679783", "bodyText": "@rjrudin after java-client 5.3 release i removed the code wherein we were creating and sending an empty endpointState. So now, since the endpointState can be null, it was giving NullPointerException at state.next.", "author": "anu3990", "createdAt": "2020-10-16T19:27:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU3NDkxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjk1NTYwMQ==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r506955601", "bodyText": "Can't we remove this entirely though? Our connector doesn't care about anything in the endpointState. And if Ernie wants to store something there, he has to provide his own endpoint.", "author": "rjrudin", "createdAt": "2020-10-17T15:46:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU3NDkxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzgzMDAyNA==", "url": "https://github.com/marklogic/marklogic-data-hub/pull/4697#discussion_r507830024", "bodyText": "@anu3990 I checked this out locally, and all the tests pass with this block of code removed - i.e. this stuff:\nif(state!=null && state.next!=null){\n    state.next = state.next + 1;\n  }\n\nAs part of rebasing, can you remove that from the endpoint too?", "author": "rjrudin", "createdAt": "2020-10-19T15:07:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU3NDkxNQ=="}], "type": "inlineReview"}, {"oid": "a4264ba2a69f7b8451c68590698396580ab68073", "url": "https://github.com/marklogic/marklogic-data-hub/commit/a4264ba2a69f7b8451c68590698396580ab68073", "message": "DHFPROD-6095 - Run connector against DHF 5.2.x.", "committedDate": "2020-10-19T22:42:21Z", "type": "forcePushed"}, {"oid": "d0705843a43bf1bda0fe498733258f6c6a0d8419", "url": "https://github.com/marklogic/marklogic-data-hub/commit/d0705843a43bf1bda0fe498733258f6c6a0d8419", "message": "DHFPROD-6095 - Run connector against DHF 5.2.x.", "committedDate": "2020-10-20T06:30:42Z", "type": "forcePushed"}, {"oid": "edebb3b6843bedf60bd8bf0c1bfd40b61116e0e9", "url": "https://github.com/marklogic/marklogic-data-hub/commit/edebb3b6843bedf60bd8bf0c1bfd40b61116e0e9", "message": "DHFPROD-6095 - Run connector against DHF 5.2.x.", "committedDate": "2020-10-20T16:47:53Z", "type": "commit"}, {"oid": "edebb3b6843bedf60bd8bf0c1bfd40b61116e0e9", "url": "https://github.com/marklogic/marklogic-data-hub/commit/edebb3b6843bedf60bd8bf0c1bfd40b61116e0e9", "message": "DHFPROD-6095 - Run connector against DHF 5.2.x.", "committedDate": "2020-10-20T16:47:53Z", "type": "forcePushed"}]}