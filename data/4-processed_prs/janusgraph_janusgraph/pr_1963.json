{"pr_number": 1963, "pr_title": "Improve lucene tokenizer", "pr_createdAt": "2020-02-17T08:53:53Z", "pr_url": "https://github.com/JanusGraph/janusgraph/pull/1963", "timeline": [{"oid": "656edcc947fbd24c1ca7391547fb336119a9effc", "url": "https://github.com/JanusGraph/janusgraph/commit/656edcc947fbd24c1ca7391547fb336119a9effc", "message": "Improve lucene tokenizer\n\nIf tokenizer returns more than one token for one word then query builder combine that such tokens with \"should\" occurrence\n\nSigned-off-by: Vladimir Bogomolov <vladimir.bogomoloff@gmail.com>", "committedDate": "2020-02-17T09:10:41Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDM0Mzg5OQ==", "url": "https://github.com/JanusGraph/janusgraph/pull/1963#discussion_r380343899", "bodyText": "(nitpick)\nSo we are executing new ArrayList<>() even if it isn't absent. Generally it isn't a big deal because GC handles those objects easily but I am not sure if compilator is able to optimize that (I think it isn't).\nYou can either create a static function which returns a new array list (i.e. it is executed only if it is absent) or your can just return your list and create a new one if it is empty.\nSomething like:\nList<String> stemList = stemsByOffset.get(offset);\nif(stemList == null){\n  stemList = new ArrayList<>();\n  stemsByOffset.put(offset, stemList);\n}\nstemList.add(stem);", "author": "porunov", "createdAt": "2020-02-17T19:43:08Z", "path": "janusgraph-lucene/src/main/java/org/janusgraph/diskstorage/lucene/LuceneIndex.java", "diffHunk": "@@ -603,23 +605,27 @@ private static Query numericQuery(String key, Cmp relation, Number value) {\n     }\n \n     // adapted from SolrIndex\n-    private List<String> customTokenize(Analyzer analyzer, String fieldName, String value) {\n-        final List<String> terms = new ArrayList<>();\n+    private List<List<String>> customTokenize(Analyzer analyzer, String fieldName, String value) {\n+        Map<Integer, List<String>> stemsByOffset = new HashMap<>();\n         try (CachingTokenFilter stream = new CachingTokenFilter(analyzer.tokenStream(fieldName, value))) {\n+            final OffsetAttribute offsetAtt = stream.getAttribute(OffsetAttribute.class);\n             final TermToBytesRefAttribute termAtt = stream.getAttribute(TermToBytesRefAttribute.class);\n             stream.reset();\n             while (stream.incrementToken()) {\n-                terms.add(termAtt.getBytesRef().utf8ToString());\n+                int offset = offsetAtt.startOffset();\n+                String stem = termAtt.getBytesRef().utf8ToString();\n+                stemsByOffset.putIfAbsent(offset, new ArrayList<>());", "originalCommit": "656edcc947fbd24c1ca7391547fb336119a9effc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDUwNTAzNQ==", "url": "https://github.com/JanusGraph/janusgraph/pull/1963#discussion_r380505035", "bodyText": "It makes sense, thanks.\nDone.", "author": "VladimirBogomolov", "createdAt": "2020-02-18T07:52:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MDM0Mzg5OQ=="}], "type": "inlineReview"}, {"oid": "2d2c38d4e8304b69cd0a70f86603d282f04669d8", "url": "https://github.com/JanusGraph/janusgraph/commit/2d2c38d4e8304b69cd0a70f86603d282f04669d8", "message": "Delete unnecessary list creation\n\nSigned-off-by: Vladimir Bogomolov <vladimir.bogomoloff@gmail.com>", "committedDate": "2020-02-18T07:49:43Z", "type": "forcePushed"}, {"oid": "51996a5dfdc73a59ac5f262dafeb044d2518b95f", "url": "https://github.com/JanusGraph/janusgraph/commit/51996a5dfdc73a59ac5f262dafeb044d2518b95f", "message": "Improve lucene tokenizer\n\nIf tokenizer returns more than one token for one word then query builder combine that such tokens with \"should\" occurrence\n\nSigned-off-by: Vladimir Bogomolov <vladimir.bogomoloff@gmail.com>", "committedDate": "2020-02-20T13:26:26Z", "type": "commit"}, {"oid": "51996a5dfdc73a59ac5f262dafeb044d2518b95f", "url": "https://github.com/JanusGraph/janusgraph/commit/51996a5dfdc73a59ac5f262dafeb044d2518b95f", "message": "Improve lucene tokenizer\n\nIf tokenizer returns more than one token for one word then query builder combine that such tokens with \"should\" occurrence\n\nSigned-off-by: Vladimir Bogomolov <vladimir.bogomoloff@gmail.com>", "committedDate": "2020-02-20T13:26:26Z", "type": "forcePushed"}]}