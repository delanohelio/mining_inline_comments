{"pr_number": 11575, "pr_title": "Clean up files in parallel to avoid large recursive delete", "pr_createdAt": "2020-06-17T00:52:57Z", "pr_url": "https://github.com/Alluxio/alluxio/pull/11575", "timeline": [{"oid": "caad5fcef98f2a055a52029c075c8c7ed5d0573d", "url": "https://github.com/Alluxio/alluxio/commit/caad5fcef98f2a055a52029c075c8c7ed5d0573d", "message": "Clean up files in parallel", "committedDate": "2020-06-16T22:22:09Z", "type": "commit"}, {"oid": "b73c2948edd25e79879a80ab39978c1252442387", "url": "https://github.com/Alluxio/alluxio/commit/b73c2948edd25e79879a80ab39978c1252442387", "message": "Handle empty directories", "committedDate": "2020-06-16T22:57:26Z", "type": "commit"}, {"oid": "045a22ae2bed96a3aa5353d18053a8280bf910f5", "url": "https://github.com/Alluxio/alluxio/commit/045a22ae2bed96a3aa5353d18053a8280bf910f5", "message": "Don't wait too long", "committedDate": "2020-06-17T00:51:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQyODU3MA==", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442428570", "bodyText": "Is this correct for this to happen for every subdir?", "author": "bradyoo", "createdAt": "2020-06-18T18:41:32Z", "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -130,6 +135,76 @@ public void prepare() throws Exception {\n     }\n   }\n \n+  private void deletePaths(FileSystem fs, Path basePath) throws Exception {\n+    // the base dir has sub directories per task id\n+    if (!fs.exists(basePath)) {\n+      return;\n+    }\n+    FileStatus[] subDirs = fs.listStatus(basePath);\n+    if (subDirs.length == 0) {\n+      return;\n+    }\n+\n+    // determine the fixed portion size\n+    int fixedSize = fs.listStatus(new Path(subDirs[0].getPath(), \"fixed\")).length;\n+\n+    long batchSize = 50_000;\n+    int deleteThreads = 256;\n+    ExecutorService service =\n+        ExecutorServiceFactories.fixedThreadPool(\"bench-delete-thread\", deleteThreads).create();\n+\n+    for (FileStatus subDir : subDirs) {\n+      LOG.info(\"Cleaning up all files in: {}\", subDir.getPath());\n+      AtomicLong globalCounter = new AtomicLong();\n+      Path fixedBase = new Path(subDir.getPath(), \"fixed\");\n+      long runningLimit = 0;\n+\n+      // delete individual files in batches, to avoid the recursive-delete problem\n+      while (!Thread.currentThread().isInterrupted()) {\n+        AtomicLong success = new AtomicLong();\n+        runningLimit += batchSize;\n+        long limit = runningLimit;\n+\n+        List<Callable<Void>> callables = new ArrayList<>(deleteThreads);\n+        for (int i = 0; i < deleteThreads; i++) {\n+          callables.add(() -> {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              long counter = globalCounter.getAndIncrement();\n+              if (counter >= limit) {\n+                globalCounter.getAndDecrement();\n+                return null;\n+              }\n+              Path deletePath;\n+              if (counter < fixedSize) {\n+                deletePath = new Path(fixedBase, Long.toString(counter));", "originalCommit": "045a22ae2bed96a3aa5353d18053a8280bf910f5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5NTI2Mg==", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442495262", "bodyText": "Yes, each sub-dir has a fixed portion.", "author": "gpang", "createdAt": "2020-06-18T20:51:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQyODU3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzMTQ2Ng==", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442431466", "bodyText": "This design definitely misses some files because the 1 minute could end and the code could be in between globalCounter.getAndIncrement and delete. Is that okay?", "author": "bradyoo", "createdAt": "2020-06-18T18:46:59Z", "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -130,6 +135,76 @@ public void prepare() throws Exception {\n     }\n   }\n \n+  private void deletePaths(FileSystem fs, Path basePath) throws Exception {\n+    // the base dir has sub directories per task id\n+    if (!fs.exists(basePath)) {\n+      return;\n+    }\n+    FileStatus[] subDirs = fs.listStatus(basePath);\n+    if (subDirs.length == 0) {\n+      return;\n+    }\n+\n+    // determine the fixed portion size\n+    int fixedSize = fs.listStatus(new Path(subDirs[0].getPath(), \"fixed\")).length;\n+\n+    long batchSize = 50_000;\n+    int deleteThreads = 256;\n+    ExecutorService service =\n+        ExecutorServiceFactories.fixedThreadPool(\"bench-delete-thread\", deleteThreads).create();\n+\n+    for (FileStatus subDir : subDirs) {\n+      LOG.info(\"Cleaning up all files in: {}\", subDir.getPath());\n+      AtomicLong globalCounter = new AtomicLong();\n+      Path fixedBase = new Path(subDir.getPath(), \"fixed\");\n+      long runningLimit = 0;\n+\n+      // delete individual files in batches, to avoid the recursive-delete problem\n+      while (!Thread.currentThread().isInterrupted()) {\n+        AtomicLong success = new AtomicLong();\n+        runningLimit += batchSize;\n+        long limit = runningLimit;\n+\n+        List<Callable<Void>> callables = new ArrayList<>(deleteThreads);\n+        for (int i = 0; i < deleteThreads; i++) {\n+          callables.add(() -> {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              long counter = globalCounter.getAndIncrement();\n+              if (counter >= limit) {\n+                globalCounter.getAndDecrement();\n+                return null;\n+              }\n+              Path deletePath;\n+              if (counter < fixedSize) {\n+                deletePath = new Path(fixedBase, Long.toString(counter));\n+              } else {\n+                deletePath = new Path(subDir.getPath(), Long.toString(counter));\n+              }\n+              if (fs.delete(deletePath, true)) {", "originalCommit": "045a22ae2bed96a3aa5353d18053a8280bf910f5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5NjQwNw==", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442496407", "bodyText": "This is ok. The goal for the parallel delete is reduce the size of the recursive delete later.", "author": "gpang", "createdAt": "2020-06-18T20:53:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzMTQ2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzNTUxNQ==", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442435515", "bodyText": "Should this later be moved to some cleanup step? (As opposed to prepare step)", "author": "bradyoo", "createdAt": "2020-06-18T18:54:29Z", "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -98,7 +100,10 @@ public void prepare() throws Exception {\n \n       if (mParameters.mOperation == Operation.CreateFile\n           || mParameters.mOperation == Operation.CreateDir) {\n-        prepareFs.delete(basePath, true);\n+        long start = CommonUtils.getCurrentMs();\n+        deletePaths(prepareFs, basePath);", "originalCommit": "045a22ae2bed96a3aa5353d18053a8280bf910f5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5NTEyOQ==", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442495129", "bodyText": "We actually don't want to cleanup all the time, since some operations like listDir uses the results of CreateFile. That is why we don't delete when the operation is listDir.", "author": "gpang", "createdAt": "2020-06-18T20:51:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzNTUxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzNzM1MQ==", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442437351", "bodyText": "Despite what the doc seems to say, invokeAll doesn't necessarily guarantee that all the futures are done. So I think here, we should be checking if all of the futures are done. Log if some are not done and shutdown/reconfigure the service on every loop.", "author": "bradyoo", "createdAt": "2020-06-18T18:57:38Z", "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -130,6 +135,76 @@ public void prepare() throws Exception {\n     }\n   }\n \n+  private void deletePaths(FileSystem fs, Path basePath) throws Exception {\n+    // the base dir has sub directories per task id\n+    if (!fs.exists(basePath)) {\n+      return;\n+    }\n+    FileStatus[] subDirs = fs.listStatus(basePath);\n+    if (subDirs.length == 0) {\n+      return;\n+    }\n+\n+    // determine the fixed portion size\n+    int fixedSize = fs.listStatus(new Path(subDirs[0].getPath(), \"fixed\")).length;\n+\n+    long batchSize = 50_000;\n+    int deleteThreads = 256;\n+    ExecutorService service =\n+        ExecutorServiceFactories.fixedThreadPool(\"bench-delete-thread\", deleteThreads).create();\n+\n+    for (FileStatus subDir : subDirs) {\n+      LOG.info(\"Cleaning up all files in: {}\", subDir.getPath());\n+      AtomicLong globalCounter = new AtomicLong();\n+      Path fixedBase = new Path(subDir.getPath(), \"fixed\");\n+      long runningLimit = 0;\n+\n+      // delete individual files in batches, to avoid the recursive-delete problem\n+      while (!Thread.currentThread().isInterrupted()) {\n+        AtomicLong success = new AtomicLong();\n+        runningLimit += batchSize;\n+        long limit = runningLimit;\n+\n+        List<Callable<Void>> callables = new ArrayList<>(deleteThreads);\n+        for (int i = 0; i < deleteThreads; i++) {\n+          callables.add(() -> {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              long counter = globalCounter.getAndIncrement();\n+              if (counter >= limit) {\n+                globalCounter.getAndDecrement();\n+                return null;\n+              }\n+              Path deletePath;\n+              if (counter < fixedSize) {\n+                deletePath = new Path(fixedBase, Long.toString(counter));\n+              } else {\n+                deletePath = new Path(subDir.getPath(), Long.toString(counter));\n+              }\n+              if (fs.delete(deletePath, true)) {\n+                success.getAndIncrement();\n+              }\n+            }\n+            return null;\n+          });\n+        }\n+        service.invokeAll(callables, 1, TimeUnit.MINUTES);", "originalCommit": "045a22ae2bed96a3aa5353d18053a8280bf910f5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjUwMjU5OA==", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442502598", "bodyText": "This is ok. If this times out, it cancels all remaining tasks. That is fine, because the next round will just create more tasks, and any remaining tasks will be taken care of the final recursive delete.", "author": "gpang", "createdAt": "2020-06-18T21:06:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzNzM1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ0MDQ0NA==", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442440444", "bodyText": "I guess this covers the case of skips.", "author": "bradyoo", "createdAt": "2020-06-18T19:03:19Z", "path": "stress/shell/src/main/java/alluxio/stress/cli/StressMasterBench.java", "diffHunk": "@@ -130,6 +135,76 @@ public void prepare() throws Exception {\n     }\n   }\n \n+  private void deletePaths(FileSystem fs, Path basePath) throws Exception {\n+    // the base dir has sub directories per task id\n+    if (!fs.exists(basePath)) {\n+      return;\n+    }\n+    FileStatus[] subDirs = fs.listStatus(basePath);\n+    if (subDirs.length == 0) {\n+      return;\n+    }\n+\n+    // determine the fixed portion size\n+    int fixedSize = fs.listStatus(new Path(subDirs[0].getPath(), \"fixed\")).length;\n+\n+    long batchSize = 50_000;\n+    int deleteThreads = 256;\n+    ExecutorService service =\n+        ExecutorServiceFactories.fixedThreadPool(\"bench-delete-thread\", deleteThreads).create();\n+\n+    for (FileStatus subDir : subDirs) {\n+      LOG.info(\"Cleaning up all files in: {}\", subDir.getPath());\n+      AtomicLong globalCounter = new AtomicLong();\n+      Path fixedBase = new Path(subDir.getPath(), \"fixed\");\n+      long runningLimit = 0;\n+\n+      // delete individual files in batches, to avoid the recursive-delete problem\n+      while (!Thread.currentThread().isInterrupted()) {\n+        AtomicLong success = new AtomicLong();\n+        runningLimit += batchSize;\n+        long limit = runningLimit;\n+\n+        List<Callable<Void>> callables = new ArrayList<>(deleteThreads);\n+        for (int i = 0; i < deleteThreads; i++) {\n+          callables.add(() -> {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              long counter = globalCounter.getAndIncrement();\n+              if (counter >= limit) {\n+                globalCounter.getAndDecrement();\n+                return null;\n+              }\n+              Path deletePath;\n+              if (counter < fixedSize) {\n+                deletePath = new Path(fixedBase, Long.toString(counter));\n+              } else {\n+                deletePath = new Path(subDir.getPath(), Long.toString(counter));\n+              }\n+              if (fs.delete(deletePath, true)) {\n+                success.getAndIncrement();\n+              }\n+            }\n+            return null;\n+          });\n+        }\n+        service.invokeAll(callables, 1, TimeUnit.MINUTES);\n+\n+        if (success.get() == 0) {\n+          // stop deleting one-by-one if none of the batch succeeded.\n+          break;\n+        }\n+        LOG.info(\"Removed {} files\", success.get());\n+      }\n+    }\n+\n+    service.shutdownNow();\n+    service.awaitTermination(10, TimeUnit.SECONDS);\n+\n+    // Cleanup the rest recursively, which should be empty or much smaller than the full tree.\n+    LOG.info(\"Deleting base directory: {}\", basePath);\n+    fs.delete(basePath, true);", "originalCommit": "045a22ae2bed96a3aa5353d18053a8280bf910f5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ5Njc3OA==", "url": "https://github.com/Alluxio/alluxio/pull/11575#discussion_r442496778", "bodyText": "Yes, this recursive delete takes care of the the base directory itself, as well as any straggler files.", "author": "gpang", "createdAt": "2020-06-18T20:54:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ0MDQ0NA=="}], "type": "inlineReview"}, {"oid": "b34baa0d842347e6cff8c80c09f5b5c8418b6ff1", "url": "https://github.com/Alluxio/alluxio/commit/b34baa0d842347e6cff8c80c09f5b5c8418b6ff1", "message": "Update comments", "committedDate": "2020-06-18T21:09:14Z", "type": "commit"}]}