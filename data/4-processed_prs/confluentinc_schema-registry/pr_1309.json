{"pr_number": 1309, "pr_title": "Optimize internal cache indexes", "pr_createdAt": "2020-02-03T05:46:04Z", "pr_url": "https://github.com/confluentinc/schema-registry/pull/1309", "timeline": [{"oid": "e7a371ebdb4b1fc935ad5f029b8ac0dee13aa222", "url": "https://github.com/confluentinc/schema-registry/commit/e7a371ebdb4b1fc935ad5f029b8ac0dee13aa222", "message": "Optimize internal cache indexes", "committedDate": "2020-02-03T05:45:31Z", "type": "commit"}, {"oid": "d87c00c06d06559bce261b29b936b46accd985ff", "url": "https://github.com/confluentinc/schema-registry/commit/d87c00c06d06559bce261b29b936b46accd985ff", "message": "Minor renaming", "committedDate": "2020-02-03T05:48:45Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkzNTAxNg==", "url": "https://github.com/confluentinc/schema-registry/pull/1309#discussion_r373935016", "bodyText": "I've simplified the internal maps.\nBefore we had (guid -> schemakey) and (md5 -> (guid -> (subject -> version))\nI've refactored these to (guid -> (subject -> version)) and (md5 -> guid)\nThe (guid -> schemaKey) can be reconstructed by taking the first entry from (guid -> (subject -> version))\nAlso we no longer need guidToDeletedSchemaKeys because tombstoning now happens during registration as opposed to in KafkaStoreMessageHandler", "author": "rayokota", "createdAt": "2020-02-03T06:12:04Z", "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/InMemoryCache.java", "diffHunk": "@@ -38,19 +38,17 @@\n public class InMemoryCache<K, V> implements LookupCache<K, V> {\n   // visible for subclasses\n   protected final ConcurrentNavigableMap<K, V> store;\n-  private final Map<Integer, SchemaKey> guidToSchemaKey;\n-  private final Map<MD5, SchemaIdAndSubjects> schemaHashToGuid;\n-  private final Map<Integer, List<SchemaKey>> guidToDeletedSchemaKeys;\n+  private final Map<Integer, Map<String, Integer>> guidToSubjectVersions;\n+  private final Map<MD5, Integer> hashToGuid;\n ", "originalCommit": "e7a371ebdb4b1fc935ad5f029b8ac0dee13aa222", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkzNTgxOA==", "url": "https://github.com/confluentinc/schema-registry/pull/1309#discussion_r373935818", "bodyText": "These complicated methods were used to maintain (guid -> schemaKey) and are no longer needed", "author": "rayokota", "createdAt": "2020-02-03T06:15:53Z", "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/InMemoryCache.java", "diffHunk": "@@ -255,48 +258,10 @@ public void clearSubjects(Predicate<String> match) {\n     return s -> subject == null || subject.equals(s);\n   }\n \n-  // Visible for testing\n-  protected void replaceMatchingDeletedWithNonDeletedOrRemove(Predicate<String> match) {\n-    Predicate<SchemaKey> matchDeleted = matchDeleted(match);\n-\n-    // Iterate through the entries, and for each entry that matches and is soft deleted,\n-    // see if there is a replacement entry (that is not soft deleted) that has the same\n-    // schema string.  If so, replace, else remove the entry.\n-    Iterator<Map.Entry<Integer, SchemaKey>> it = guidToSchemaKey.entrySet().iterator();\n-    while (it.hasNext()) {\n-      Map.Entry<Integer, SchemaKey> entry = it.next();\n-      SchemaKey schemaKey = entry.getValue();\n-      if (matchDeleted.test(schemaKey)) {\n-        SchemaValue schemaValue = (SchemaValue) store.get(schemaKey);\n-        // The value returned from the store should not be null since we clean up caches\n-        // after tombstoning, but we still check defensively\n-        SchemaKey newSchemaKey = schemaValue != null\n-                                 ? getNonDeletedSchemaKey(schemaValue)\n-                                 : null;\n-        if (newSchemaKey != null) {\n-          entry.setValue(newSchemaKey);\n-        } else {\n-          it.remove();\n-        }\n-      }\n-    }\n-  }\n-\n-  private SchemaKey getNonDeletedSchemaKey(SchemaValue schema) {\n-    MD5 md5 = MD5.ofString(schema.getSchema(), schema.getReferences());\n-    SchemaIdAndSubjects keys = schemaHashToGuid.get(md5);\n-    return keys == null ? null : keys.findAny(key -> {\n-      SchemaValue value = (SchemaValue) store.get(key);\n-      // The value returned from the store should not be null since we clean up caches\n-      // after tombstoning, but we still check defensively\n-      return value != null && !value.isDeleted();\n-    });\n-  }\n-\n-  private Predicate<SchemaKey> matchDeleted(Predicate<String> match) {\n-    return key -> {\n-      if (match.test(key.getSubject())) {\n-        SchemaValue value = (SchemaValue) store.get(key);\n+  private BiPredicate<String, Integer> matchDeleted(Predicate<String> match) {\n+    return (subject, version) -> {\n+      if (match.test(subject)) {\n+        SchemaValue value = (SchemaValue) store.get(new SchemaKey(subject, version));\n         // The value returned from the store should not be null since we clean up caches", "originalCommit": "d87c00c06d06559bce261b29b936b46accd985ff", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkzNjEyNQ==", "url": "https://github.com/confluentinc/schema-registry/pull/1309#discussion_r373936125", "bodyText": "The tombstoning now happens here in register vs. in KafkaStoreMessageHandler.  This removes the need for guidToDeletedSchemaKeys", "author": "rayokota", "createdAt": "2020-02-03T06:17:21Z", "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/KafkaSchemaRegistry.java", "diffHunk": "@@ -458,6 +461,13 @@ public int register(String subject,\n                 + \"to generating an ID that is already in use.\");\n           }\n         }\n+        for (SchemaValue schemaValue : deletedVersions) {\n+          if (schemaValue.getId().equals(schema.getId())) {\n+            // Tombstone previous version with the same ID\n+            SchemaKey key = new SchemaKey(schemaValue.getSubject(), schemaValue.getVersion());\n+            kafkaStore.delete(key);\n+          }\n+        }", "originalCommit": "d87c00c06d06559bce261b29b936b46accd985ff", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkzNjM3MA==", "url": "https://github.com/confluentinc/schema-registry/pull/1309#discussion_r373936370", "bodyText": "This is the old method of tombstoning, which has moved to register.  This code actually had a bug where both masters and replicas would perform tombstoning, leading to redundant tombstones.  By moving the code to register, this problem is avoided.", "author": "rayokota", "createdAt": "2020-02-03T06:18:41Z", "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/KafkaStoreMessageHandler.java", "diffHunk": "@@ -122,46 +124,26 @@ private void handleClearSubject(ClearSubjectValue clearSubjectValue) {\n     }\n   }\n \n-  private void handleSchemaUpdate(SchemaKey schemaKey, SchemaValue schemaObj) {\n-    if (schemaObj != null) {\n+  private void handleSchemaUpdate(SchemaKey schemaKey,\n+                                  SchemaValue schemaValue,\n+                                  SchemaValue oldSchemaValue) {\n+    if (schemaValue != null) {\n       // If the schema is marked to be deleted, we store it in an internal datastructure\n       // that holds all deleted schema keys for an id.\n       // Whenever we encounter a new schema for a subject, we check to see if the same schema\n       // (same id) was deleted for the subject ever. If so, we tombstone those delete keys.\n       // This helps optimize the storage. The main reason we only allow soft deletes in SR is that\n       // consumers should be able to access the schemas by id. This is guaranteed when the schema is\n       // re-registered again and hence we can tombstone the record.\n-      if (schemaObj.isDeleted()) {\n-        this.lookupCache.schemaDeleted(schemaKey, schemaObj);\n+      if (schemaValue.isDeleted()) {\n+        this.lookupCache.schemaDeleted(schemaKey, schemaValue);\n       } else {\n         // Update the maximum id seen so far\n-        idGenerator.schemaRegistered(schemaKey, schemaObj);\n-        lookupCache.schemaRegistered(schemaKey, schemaObj);\n-        List<SchemaKey> schemaKeys = lookupCache.deletedSchemaKeys(schemaObj);\n-        schemaKeys.stream().filter(v ->\n-            v.getSubject().equals(schemaObj.getSubject())\n-                && v.getVersion() != schemaObj.getVersion())\n-            .forEach(this::tombstoneSchemaKey);\n+        idGenerator.schemaRegistered(schemaKey, schemaValue);\n+        lookupCache.schemaRegistered(schemaKey, schemaValue);\n       }\n     } else {\n-      lookupCache.schemaTombstoned(schemaKey);\n-    }\n-  }\n-\n-  private void tombstoneSchemaKey(SchemaKey schemaKey) {\n-    if (schemaRegistry.getKafkaStore().initialized()) {\n-      tombstoneExecutor.execute(() -> {\n-            try {\n-              schemaRegistry.getKafkaStore().waitForInit();\n-              schemaRegistry.getKafkaStore().delete(schemaKey);\n-              log.debug(\"Tombstoned {}\", schemaKey);\n-            } catch (InterruptedException e) {\n-              log.error(\"Interrupted while waiting for the tombstone thread to be initialized \", e);\n-            } catch (StoreException e) {\n-              log.error(\"Failed to tombstone {}\", schemaKey, e);\n-            }\n-          }\n-      );", "originalCommit": "d87c00c06d06559bce261b29b936b46accd985ff", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkzNjQ4OQ==", "url": "https://github.com/confluentinc/schema-registry/pull/1309#discussion_r373936489", "bodyText": "These tests were for the complicated logic to maintain (guid -> schemaKey) and so are no longer needed.", "author": "rayokota", "createdAt": "2020-02-03T06:19:16Z", "path": "core/src/test/java/io/confluent/kafka/schemaregistry/storage/KafkaStoreTest.java", "diffHunk": "@@ -463,53 +463,6 @@ public void testKafkaStoreMessageHandlerSameIdSameSchema() throws Exception {\n     assertEquals(2, size);\n   }\n \n-  @Test\n-  public void testReplaceDeletedWithNonDeleted() throws Exception {\n-    InMemoryCache<SchemaKey, SchemaValue> inMemoryStore = new InMemoryCache<>();\n-\n-    int id = 100;\n-    SchemaKey schemaKey = new SchemaKey(\"subject\", 1);\n-    SchemaValue schemaValue =\n-        new SchemaValue(\"subject\", 1, id, \"schemaString\", false);\n-\n-    SchemaKey schemaKey2 = new SchemaKey(\"subject2\", 1);\n-    SchemaValue schemaValue2 =\n-        new SchemaValue(\"subject2\", 1, id, \"schemaString\", false);\n-\n-    inMemoryStore.put(schemaKey, schemaValue);\n-    inMemoryStore.schemaRegistered(schemaKey, schemaValue);\n-\n-    inMemoryStore.put(schemaKey2, schemaValue2);\n-    inMemoryStore.schemaRegistered(schemaKey2, schemaValue2);\n-\n-    schemaValue2.setDeleted(true);\n-    inMemoryStore.schemaDeleted(schemaKey2, schemaValue2);\n-\n-    assertTrue(inMemoryStore.get(inMemoryStore.schemaKeyById(id)).isDeleted());\n-\n-    inMemoryStore.replaceMatchingDeletedWithNonDeletedOrRemove(s -> s.equals(\"subject2\"));\n-\n-    SchemaValue newValue = inMemoryStore.get(inMemoryStore.schemaKeyById(id));\n-    assertEquals(\"subject\", newValue.getSubject());\n-    assertFalse(newValue.isDeleted());\n-  }\n-\n-  @Test\n-  public void testReplaceDeletedWithNonDeletedAfterCompaction() throws Exception {\n-    InMemoryCache<SchemaKey, SchemaValue> inMemoryStore = new InMemoryCache<>();\n-\n-    int id = 100;\n-    SchemaKey schemaKey = new SchemaKey(\"subject\", 1);\n-    SchemaValue schemaValue =\n-        new SchemaValue(\"subject\", 1, id, \"schemaString\", true);\n-\n-    // After a compaction, the schema will not be registered but only deleted\n-    inMemoryStore.put(schemaKey, schemaValue);\n-    inMemoryStore.schemaDeleted(schemaKey, schemaValue);\n-\n-    inMemoryStore.replaceMatchingDeletedWithNonDeletedOrRemove(s -> s.equals(\"subject\"));\n-  }\n-", "originalCommit": "d87c00c06d06559bce261b29b936b46accd985ff", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMzNjI4Ng==", "url": "https://github.com/confluentinc/schema-registry/pull/1309#discussion_r374336286", "bodyText": "Can we break after the first match here or do we need to go through all the deleted versions ?", "author": "dragosvictor", "createdAt": "2020-02-03T20:56:23Z", "path": "core/src/main/java/io/confluent/kafka/schemaregistry/storage/KafkaSchemaRegistry.java", "diffHunk": "@@ -458,6 +461,13 @@ public int register(String subject,\n                 + \"to generating an ID that is already in use.\");\n           }\n         }\n+        for (SchemaValue schemaValue : deletedVersions) {\n+          if (schemaValue.getId().equals(schema.getId())) {\n+            // Tombstone previous version with the same ID\n+            SchemaKey key = new SchemaKey(schemaValue.getSubject(), schemaValue.getVersion());\n+            kafkaStore.delete(key);\n+          }\n+        }", "originalCommit": "d87c00c06d06559bce261b29b936b46accd985ff", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM0NDIzMQ==", "url": "https://github.com/confluentinc/schema-registry/pull/1309#discussion_r374344231", "bodyText": "Good question.  In normal cases there should only be one match, but in case of failure there could be more than one.", "author": "rayokota", "createdAt": "2020-02-03T21:14:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMzNjI4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQyMTA0Ng==", "url": "https://github.com/confluentinc/schema-registry/pull/1309#discussion_r374421046", "bodyText": "Do we need any test with the 3rd parameter here being non-null?", "author": "maverick64", "createdAt": "2020-02-04T00:42:00Z", "path": "core/src/test/java/io/confluent/kafka/schemaregistry/storage/KafkaStoreTest.java", "diffHunk": "@@ -590,7 +543,7 @@ public void testKafkaStoreMessageHandlerDeleteSubjectKeyNullValue() throws Excep\n     KafkaStoreMessageHandler storeMessageHandler = new KafkaStoreMessageHandler(schemaRegistry,\n             new InMemoryCache<>(), new IncrementalIdGenerator());\n \n-    storeMessageHandler.handleUpdate(new DeleteSubjectKey(\"test\"), null);\n+    storeMessageHandler.handleUpdate(new DeleteSubjectKey(\"test\"), null, null);", "originalCommit": "d87c00c06d06559bce261b29b936b46accd985ff", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}