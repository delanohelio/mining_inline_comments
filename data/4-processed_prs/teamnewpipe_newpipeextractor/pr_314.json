{"pr_number": 314, "pr_title": "Add Page class and remove getNextPageUrl()", "pr_createdAt": "2020-04-14T16:43:02Z", "pr_url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAzOTAzOA==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r409039038", "bodyText": "This should be a Map and not HashMap, same for the contructor", "author": "XiangRongLin", "createdAt": "2020-04-15T18:13:51Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/Page.java", "diffHunk": "@@ -0,0 +1,45 @@\n+package org.schabi.newpipe.extractor;\n+\n+import java.io.Serializable;\n+import java.util.HashMap;\n+import java.util.List;\n+\n+public class Page implements Serializable {\n+    private final String url;\n+    private final List<String> ids;\n+    private final HashMap<String, String> cookies;", "originalCommit": "6a47b8f73421ec0350268636efeea40bb1f5a7d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTA4NDkyMA==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r409084920", "bodyText": "You're right", "author": "wb9688", "createdAt": "2020-04-15T19:33:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAzOTAzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjkyMzk0Nw==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r422923947", "bodyText": "@XiangRongLin: I just fixed it.\nOff-topic: once Android Studio 4 is released, we could start using streams like you wanted.", "author": "wb9688", "createdAt": "2020-05-11T09:55:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAzOTAzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA3MTA1OQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r423071059", "bodyText": "The constructors on line 23 and 31 are still using the HashMap\nhttps://github.com/TeamNewPipe/NewPipeExtractor/pull/314/files#diff-ba49925f61d52432cc3e52fa23360e0eR23-R33", "author": "XiangRongLin", "createdAt": "2020-05-11T14:15:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAzOTAzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODg2MjUzOQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r428862539", "bodyText": "I thought you are a fan of final vars :P", "author": "TobiGr", "createdAt": "2020-05-21T19:22:12Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/peertube/extractors/PeertubeAccountExtractor.java", "diffHunk": "@@ -92,11 +93,11 @@ public String getParentChannelAvatarUrl() throws ParsingException {\n \n     @Override\n     public InfoItemsPage<StreamInfoItem> getInitialPage() throws IOException, ExtractionException {\n-        super.fetchPage();\n-        return initPage;\n+        String pageUrl = getUrl() + \"/videos?\" + START_KEY + \"=0&\" + COUNT_KEY + \"=\" + ITEMS_PER_PAGE;", "originalCommit": "f2233c4227175b233b20d96e0eab398c5e7d0167", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODg4OTc3MA==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r428889770", "bodyText": "Oof", "author": "B0pol", "createdAt": "2020-05-21T20:16:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODg2MjUzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODg2MzY3MQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r428863671", "bodyText": "Why Serializable? What did I miss in the code?", "author": "TobiGr", "createdAt": "2020-05-21T19:24:33Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/Page.java", "diffHunk": "@@ -0,0 +1,45 @@\n+package org.schabi.newpipe.extractor;\n+\n+import java.io.Serializable;\n+import java.util.List;\n+import java.util.Map;\n+\n+public class Page implements Serializable {", "originalCommit": "f2233c4227175b233b20d96e0eab398c5e7d0167", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYwNzQxOA==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439607418", "bodyText": "As suggested in the frontend pr, a static method replacing this code would be useful", "author": "Stypox", "createdAt": "2020-06-12T19:34:11Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/ListExtractor.java", "diffHunk": "@@ -105,40 +89,41 @@ public ListLinkHandler getLinkHandler() {\n         /**\n          * Url pointing to the next page relative to this one\n          *\n-         * @see ListExtractor#getPage(String)\n+         * @see ListExtractor#getPage(Page)\n+         * @see Page\n          */\n-        private final String nextPageUrl;\n+        private final Page nextPage;\n \n         /**\n          * Errors that happened during the extraction\n          */\n         private final List<Throwable> errors;\n \n-        public InfoItemsPage(InfoItemsCollector<T, ?> collector, String nextPageUrl) {\n-            this(collector.getItems(), nextPageUrl, collector.getErrors());\n+        public InfoItemsPage(InfoItemsCollector<T, ?> collector, Page nextPage) {\n+            this(collector.getItems(), nextPage, collector.getErrors());\n         }\n \n-        public InfoItemsPage(List<T> itemsList, String nextPageUrl, List<Throwable> errors) {\n+        public InfoItemsPage(List<T> itemsList, Page nextPage, List<Throwable> errors) {\n             this.itemsList = itemsList;\n-            this.nextPageUrl = nextPageUrl;\n+            this.nextPage = nextPage;\n             this.errors = errors;\n         }\n \n         public boolean hasNextPage() {\n-            return !isNullOrEmpty(nextPageUrl);\n+            return nextPage != null && (!isNullOrEmpty(nextPage.getUrl())\n+                    || !isNullOrEmpty(nextPage.getIds()));", "originalCommit": "401d7f1d2e5573b2b563281627e82019f2e8afe2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTc1Njc2NQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439756765", "bodyText": "I thought of that and then forgot to do it lol", "author": "wb9688", "createdAt": "2020-06-13T17:56:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYwNzQxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYwODU5MQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439608591", "bodyText": "This variable could be removed alltoghether", "author": "Stypox", "createdAt": "2020-06-12T19:37:18Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/peertube/PeertubeParsingHelper.java", "diffHunk": "@@ -22,17 +23,17 @@\n     private PeertubeParsingHelper() {\n     }\n \n-    public static void validate(JsonObject json) throws ContentNotAvailableException {\n-        String error = json.getString(\"error\");\n+    public static void validate(final JsonObject json) throws ContentNotAvailableException {\n+        final String error = json.getString(\"error\");", "originalCommit": "401d7f1d2e5573b2b563281627e82019f2e8afe2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTc1NjgwNg==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439756806", "bodyText": "Why/how?", "author": "wb9688", "createdAt": "2020-06-13T17:56:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYwODU5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTgwMTIxMQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439801211", "bodyText": "Oh, sorry, I was wrong ;-)", "author": "Stypox", "createdAt": "2020-06-14T07:37:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYwODU5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYwOTkxMA==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439609910", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    final Number number = JsonUtils.getNumber(json, \"followersCount\");\n          \n          \n            \n                    return number.longValue();\n          \n          \n            \n                    return JsonUtils.getNumber(json, \"followersCount\").longValue();", "author": "Stypox", "createdAt": "2020-06-12T19:40:57Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/peertube/extractors/PeertubeChannelExtractor.java", "diffHunk": "@@ -59,12 +59,12 @@ public String getFeedUrl() throws ParsingException {\n \n     @Override\n     public long getSubscriberCount() throws ParsingException {\n-        Number number = JsonUtils.getNumber(json, \"followersCount\");\n+        final Number number = JsonUtils.getNumber(json, \"followersCount\");\n         return number.longValue();", "originalCommit": "401d7f1d2e5573b2b563281627e82019f2e8afe2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYyMjYyOA==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439622628", "bodyText": "No no no.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    final Number number = JsonUtils.getNumber(json, \"followersCount\");\n          \n          \n            \n                    return number.longValue();\n          \n          \n            \n                    final Number number = JsonUtils.getNumber(json, \"followersCount\");\n          \n          \n            \n                    return number == null ? -1 /* or throw a clear exception of what's going on??? */ : number.longValue();\n          \n      \n    \n    \n  \n\nIn Invidious PR #352, I got some NullPointerException s because getNumber() returns null by default, unlike getObject() and getArray().", "author": "B0pol", "createdAt": "2020-06-12T20:14:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYwOTkxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTc1Njg5MQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439756891", "bodyText": "That's why it should be json.getLong(\"followersCount\")", "author": "wb9688", "createdAt": "2020-06-13T17:57:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYwOTkxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTc2ODQ1MA==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439768450", "bodyText": "It is null safe but return 0 instead of -1, you need to take on board this.", "author": "B0pol", "createdAt": "2020-06-13T20:53:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYwOTkxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTc2OTIzMQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439769231", "bodyText": "@B0pol: Yes. This code is basically duplicate in a lot of places. In some places, the old behavior was to fall back to the previously fetched page (that's just stupid), fall back to 0 or throw a NullPointerException. Also, in SoundCloud, 0 was often explicitly defined as fallback.", "author": "wb9688", "createdAt": "2020-06-13T21:07:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYwOTkxMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE3NTYzOA==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r444175638", "bodyText": "We should return -1, but that should be done in a separate PR.", "author": "TobiGr", "createdAt": "2020-06-23T12:13:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYwOTkxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYxMTgyOA==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439611828", "bodyText": "Isn't this function a duplicate of the one in PeertubePlaylistExtractor? Shouldn't it be put in PeertubeHelper?", "author": "Stypox", "createdAt": "2020-06-12T19:46:12Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/peertube/extractors/PeertubeSearchExtractor.java", "diffHunk": "@@ -47,44 +45,38 @@ public boolean isCorrectedSearch() {\n \n     @Override\n     public InfoItemsPage<InfoItem> getInitialPage() throws IOException, ExtractionException {\n-        super.fetchPage();\n-        return initPage;\n+        final String pageUrl = getUrl() + \"&\" + START_KEY + \"=0&\" + COUNT_KEY + \"=\" + ITEMS_PER_PAGE;\n+        return getPage(new Page(pageUrl));\n     }\n \n-    private InfoItemsCollector<InfoItem, InfoItemExtractor> collectStreamsFrom(JsonObject json) throws ParsingException {\n-        final InfoItemsSearchCollector collector = new InfoItemsSearchCollector(getServiceId());\n-\n-        JsonArray contents;\n+    private void collectStreamsFrom(final InfoItemsSearchCollector collector, final JsonObject json) throws ParsingException {", "originalCommit": "401d7f1d2e5573b2b563281627e82019f2e8afe2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTc1ODg1Nw==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439758857", "bodyText": "It's a duplicate of the ones in all of PeerTube's ListExtractors. That was already the case, however I moved it to PeertubeParsingHelper now.", "author": "wb9688", "createdAt": "2020-06-13T18:26:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYxMTgyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYxNTM5MA==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439615390", "bodyText": "There are now two functions that supposedly do the same thing: getInitialPage and onFetchPage. The first one comes from ListExtractor, the other from Extractor. Since either one or the other should remain empty, I'd suggest overriding with final the onFetchPage function in ListExtractor, to make it clear that getInitialPage should be used instead\n(also for other occourences)", "author": "Stypox", "createdAt": "2020-06-12T19:55:18Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/peertube/extractors/PeertubeTrendingExtractor.java", "diffHunk": "@@ -36,61 +39,58 @@ public String getName() throws ParsingException {\n \n     @Override\n     public InfoItemsPage<StreamInfoItem> getInitialPage() throws IOException, ExtractionException {\n-        super.fetchPage();", "originalCommit": "401d7f1d2e5573b2b563281627e82019f2e8afe2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYxNTgwOQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439615809", "bodyText": "final ;-)", "author": "Stypox", "createdAt": "2020-06-12T19:56:21Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/soundcloud/extractors/SoundcloudChartsExtractor.java", "diffHunk": "@@ -61,27 +61,11 @@ private void computeNextPageAndStreams() throws IOException, ExtractionException\n             apiUrl += \"&kind=trending\";\n         }\n \n-\n         String contentCountry = SoundCloud.getContentCountry().getCountryCode();\n         apiUrl += \"&region=soundcloud:regions:\" + contentCountry;\n \n-        nextPageUrl = SoundcloudParsingHelper.getStreamsFromApi(collector, apiUrl, true);\n-    }\n-\n-    @Override\n-    public String getNextPageUrl() throws IOException, ExtractionException {\n-        if (nextPageUrl == null) {\n-            computeNextPageAndStreams();\n-        }\n-        return nextPageUrl;\n-    }\n+        String nextPageUrl = SoundcloudParsingHelper.getStreamsFromApi(collector, apiUrl, true);", "originalCommit": "401d7f1d2e5573b2b563281627e82019f2e8afe2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYxNjI4Nw==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439616287", "bodyText": "Maybe it could also be a good idea to create static functions in the Page class for these kinds of common checks?", "author": "Stypox", "createdAt": "2020-06-12T19:57:34Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/soundcloud/extractors/SoundcloudCommentsExtractor.java", "diffHunk": "@@ -15,57 +17,62 @@\n import org.schabi.newpipe.extractor.exceptions.ParsingException;\n import org.schabi.newpipe.extractor.linkhandler.ListLinkHandler;\n \n-import javax.annotation.Nonnull;\n import java.io.IOException;\n \n-public class SoundcloudCommentsExtractor extends CommentsExtractor {\n+import javax.annotation.Nonnull;\n \n-    private JsonObject json;\n+import static org.schabi.newpipe.extractor.utils.Utils.isNullOrEmpty;\n \n-    public SoundcloudCommentsExtractor(StreamingService service, ListLinkHandler uiHandler) {\n+public class SoundcloudCommentsExtractor extends CommentsExtractor {\n+    public SoundcloudCommentsExtractor(final StreamingService service, final ListLinkHandler uiHandler) {\n         super(service, uiHandler);\n     }\n \n     @Nonnull\n     @Override\n-    public InfoItemsPage<CommentsInfoItem> getInitialPage() throws IOException, ExtractionException {\n+    public InfoItemsPage<CommentsInfoItem> getInitialPage() throws ExtractionException, IOException {\n+        final Downloader downloader = NewPipe.getDownloader();\n+        final Response response = downloader.get(getUrl());\n+\n+        final JsonObject json;\n+        try {\n+            json = JsonParser.object().from(response.responseBody());\n+        } catch (JsonParserException e) {\n+            throw new ParsingException(\"Could not parse json\", e);\n+        }\n+\n         final CommentsInfoItemsCollector collector = new CommentsInfoItemsCollector(getServiceId());\n \n         collectStreamsFrom(collector, json.getArray(\"collection\"));\n \n-        return new InfoItemsPage<>(collector, getNextPageUrl());\n+        return new InfoItemsPage<>(collector, new Page(json.getString(\"next_href\")));\n     }\n \n     @Override\n-    public String getNextPageUrl() throws IOException, ExtractionException {\n-        return json.getString(\"next_href\");\n-    }\n+    public InfoItemsPage<CommentsInfoItem> getPage(final Page page) throws ExtractionException, IOException {\n+        if (page == null || isNullOrEmpty(page.getUrl())) {\n+            throw new IllegalArgumentException(\"Page doesn't contain an URL\");", "originalCommit": "401d7f1d2e5573b2b563281627e82019f2e8afe2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTgwMTg5NA==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439801894", "bodyText": "Not sure, currently there could be:\n\nURL\nURL + cookies\nIDs\nIDs + cookies\n\nThere will probably be even more combinations in the future, as e.g. the new continuations stuff from YouTube (that they rolled back again) would introduce yet another attribute.", "author": "wb9688", "createdAt": "2020-06-14T07:46:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYxNjI4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTgwMzY1Ng==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439803656", "bodyText": "Oh ok, then no", "author": "Stypox", "createdAt": "2020-06-14T08:09:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYxNjI4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYxODQyMQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439618421", "bodyText": "Maybe we should replace the duplicate method in the frontend with a call to this one (not in this pr though, I think)\nAnother note for the future: we should add tests for these utility functions, I think", "author": "Stypox", "createdAt": "2020-06-12T20:03:08Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/utils/Utils.java", "diffHunk": "@@ -203,4 +204,16 @@ public static boolean isNullOrEmpty(final Collection<?> collection) {\n     public static boolean isNullOrEmpty(final Map map) {\n         return map == null || map.isEmpty();\n     }\n-}\n\\ No newline at end of file\n+\n+    public static String join(final CharSequence delimiter, final Iterable<? extends CharSequence> elements) {", "originalCommit": "401d7f1d2e5573b2b563281627e82019f2e8afe2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYyMzgxMw==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439623813", "bodyText": "Yes, we should tests these functions. And if there is a duplicate, it should be removed in frontend, not backend. Backend can't call frontend code, whereas the reverse is true.", "author": "B0pol", "createdAt": "2020-06-12T20:17:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYxODQyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYxOTMyMg==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r439619322", "bodyText": "Shouln't this be an empty List?", "author": "Stypox", "createdAt": "2020-06-12T20:05:39Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/peertube/extractors/PeertubeStreamExtractor.java", "diffHunk": "@@ -213,20 +221,19 @@ public String getHlsUrl() throws ParsingException {\n \n \n     @Override\n-    public List<VideoStream> getVideoOnlyStreams() throws IOException, ExtractionException {\n-        // TODO Auto-generated method stub\n+    public List<VideoStream> getVideoOnlyStreams() {\n         return null;", "originalCommit": "401d7f1d2e5573b2b563281627e82019f2e8afe2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY5MzUwNw==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r446693507", "bodyText": "No need to check for null here, it is not possible for JsonParser.object().from() to return null: it either throws an exception or returns a valid value. So change JsonObject json = null; into JsonObject json; and add an else after the previeous if throwing the below exception\nhttps://github.com/TeamNewPipe/nanojson/blob/master/src/main/java/com/grack/nanojson/JsonParser.java#L76.\nEdit: just realised this is done everywhere else, so skip this comment ;-)", "author": "Stypox", "createdAt": "2020-06-28T20:18:48Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/peertube/extractors/PeertubeAccountExtractor.java", "diffHunk": "@@ -72,93 +71,73 @@ public String getDescription() throws ParsingException {\n     }\n \n     @Override\n-    public String getParentChannelName() throws ParsingException {\n+    public String getParentChannelName() {\n         return \"\";\n     }\n \n     @Override\n-    public String getParentChannelUrl() throws ParsingException {\n+    public String getParentChannelUrl() {\n         return \"\";\n     }\n \n     @Override\n-    public String getParentChannelAvatarUrl() throws ParsingException {\n+    public String getParentChannelAvatarUrl() {\n         return \"\";\n     }\n \n     @Override\n     public InfoItemsPage<StreamInfoItem> getInitialPage() throws IOException, ExtractionException {\n-        super.fetchPage();\n-        return initPage;\n+        final String pageUrl = getUrl() + \"/videos?\" + START_KEY + \"=0&\" + COUNT_KEY + \"=\" + ITEMS_PER_PAGE;\n+        return getPage(new Page(pageUrl));\n     }\n \n-    private void collectStreamsFrom(StreamInfoItemsCollector collector, JsonObject json, String pageUrl) throws ParsingException {\n-        JsonArray contents;\n-        try {\n-            contents = (JsonArray) JsonUtils.getValue(json, \"data\");\n-        } catch (Exception e) {\n-            throw new ParsingException(\"unable to extract channel streams\", e);\n-        }\n-\n-        for (Object c : contents) {\n-            if (c instanceof JsonObject) {\n-                final JsonObject item = (JsonObject) c;\n-                PeertubeStreamInfoItemExtractor extractor = new PeertubeStreamInfoItemExtractor(item, baseUrl);\n-                collector.commit(extractor);\n-            }\n+    @Override\n+    public InfoItemsPage<StreamInfoItem> getPage(final Page page) throws IOException, ExtractionException {\n+        if (page == null || isNullOrEmpty(page.getUrl())) {\n+            throw new IllegalArgumentException(\"Page doesn't contain an URL\");\n         }\n \n-    }\n+        final Response response = getDownloader().get(page.getUrl());\n \n-    @Override\n-    public String getNextPageUrl() throws IOException, ExtractionException {\n-        super.fetchPage();\n-        return initPage.getNextPageUrl();\n-    }\n-\n-    @Override\n-    public InfoItemsPage<StreamInfoItem> getPage(String pageUrl) throws IOException, ExtractionException {\n-        Response response = getDownloader().get(pageUrl);\n         JsonObject json = null;\n         if (response != null && !Utils.isBlank(response.responseBody())) {\n             try {\n                 json = JsonParser.object().from(response.responseBody());\n             } catch (Exception e) {\n-                throw new ParsingException(\"Could not parse json data for kiosk info\", e);\n+                throw new ParsingException(\"Could not parse json data for account info\", e);\n             }\n         }\n \n-        StreamInfoItemsCollector collector = new StreamInfoItemsCollector(getServiceId());\n         if (json != null) {", "originalCommit": "4890b2906f805ccfccc83be13d954ed2cb8fc4e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY5NDI0OA==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r446694248", "bodyText": "I see this is used in many places; what about adding an overload to Utils.isNullOrEmpty() taking a Response? For another PR though", "author": "Stypox", "createdAt": "2020-06-28T20:26:01Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/peertube/extractors/PeertubeStreamExtractor.java", "diffHunk": "@@ -280,29 +273,29 @@ public StreamInfoItemsCollector getRelatedStreams() throws IOException, Extracti\n \n     @Nonnull\n     @Override\n-    public String getSupportInfo() throws ParsingException {\n+    public String getSupportInfo() {\n         try {\n             return JsonUtils.getString(json, \"support\");\n         } catch (ParsingException e) {\n             return \"\";\n         }\n     }\n \n-    private String getRelatedStreamsUrl(List<String> tags) throws UnsupportedEncodingException {\n-        String url = baseUrl + PeertubeSearchQueryHandlerFactory.SEARCH_ENDPOINT;\n-        StringBuilder params = new StringBuilder();\n+    private String getRelatedStreamsUrl(final List<String> tags) throws UnsupportedEncodingException {\n+        final String url = baseUrl + PeertubeSearchQueryHandlerFactory.SEARCH_ENDPOINT;\n+        final StringBuilder params = new StringBuilder();\n         params.append(\"start=0&count=8&sort=-createdAt\");\n-        for (String tag : tags) {\n+        for (final String tag : tags) {\n             params.append(\"&tagsOneOf=\");\n             params.append(URLEncoder.encode(tag, \"UTF-8\"));\n         }\n         return url + \"?\" + params.toString();\n     }\n \n-    private void getStreamsFromApi(StreamInfoItemsCollector collector, String apiUrl) throws ReCaptchaException, IOException, ParsingException {\n-        Response response = getDownloader().get(apiUrl);\n+    private void getStreamsFromApi(final StreamInfoItemsCollector collector, final String apiUrl) throws ReCaptchaException, IOException, ParsingException {\n+        final Response response = getDownloader().get(apiUrl);\n         JsonObject relatedVideosJson = null;\n-        if (null != response && !Utils.isBlank(response.responseBody())) {\n+        if (response != null && !Utils.isBlank(response.responseBody())) {", "originalCommit": "4890b2906f805ccfccc83be13d954ed2cb8fc4e5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY0NDk1MA==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r447644950", "bodyText": "No, create isNullOrBlank, because we don't check nullness here (well,we implicitly do it, but we do more that just that)", "author": "B0pol", "createdAt": "2020-06-30T12:31:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY5NDI0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg0NDA4MQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r447844081", "bodyText": "Oh yeah, sorry", "author": "Stypox", "createdAt": "2020-06-30T17:06:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY5NDI0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDQwMzg4Mg==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r450403882", "bodyText": "Good idea, but not in this PR due to lack of time (plus it was already the case before)", "author": "wb9688", "createdAt": "2020-07-06T18:25:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY5NDI0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY5NDM3Mg==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r446694372", "bodyText": "final", "author": "Stypox", "createdAt": "2020-06-28T20:27:14Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/soundcloud/extractors/SoundcloudChannelExtractor.java", "diffHunk": "@@ -102,44 +101,31 @@ public String getParentChannelAvatarUrl() throws ParsingException {\n     @Nonnull\n     @Override\n     public InfoItemsPage<StreamInfoItem> getInitialPage() throws ExtractionException {\n-        if (streamInfoItemsCollector == null) {\n-            computeNextPageAndGetStreams();\n-        }\n-        return new InfoItemsPage<>(streamInfoItemsCollector, getNextPageUrl());\n-    }\n-\n-    @Override\n-    public String getNextPageUrl() throws ExtractionException {\n-        if (nextPageUrl == null) {\n-            computeNextPageAndGetStreams();\n-        }\n-        return nextPageUrl;\n-    }\n-\n-    private void computeNextPageAndGetStreams() throws ExtractionException {\n         try {\n-            streamInfoItemsCollector = new StreamInfoItemsCollector(getServiceId());\n+            StreamInfoItemsCollector streamInfoItemsCollector = new StreamInfoItemsCollector(getServiceId());", "originalCommit": "4890b2906f805ccfccc83be13d954ed2cb8fc4e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY5NDM3OQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r446694379", "bodyText": "final", "author": "Stypox", "createdAt": "2020-06-28T20:27:19Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/soundcloud/extractors/SoundcloudChannelExtractor.java", "diffHunk": "@@ -102,44 +101,31 @@ public String getParentChannelAvatarUrl() throws ParsingException {\n     @Nonnull\n     @Override\n     public InfoItemsPage<StreamInfoItem> getInitialPage() throws ExtractionException {\n-        if (streamInfoItemsCollector == null) {\n-            computeNextPageAndGetStreams();\n-        }\n-        return new InfoItemsPage<>(streamInfoItemsCollector, getNextPageUrl());\n-    }\n-\n-    @Override\n-    public String getNextPageUrl() throws ExtractionException {\n-        if (nextPageUrl == null) {\n-            computeNextPageAndGetStreams();\n-        }\n-        return nextPageUrl;\n-    }\n-\n-    private void computeNextPageAndGetStreams() throws ExtractionException {\n         try {\n-            streamInfoItemsCollector = new StreamInfoItemsCollector(getServiceId());\n+            StreamInfoItemsCollector streamInfoItemsCollector = new StreamInfoItemsCollector(getServiceId());\n \n             String apiUrl = \"https://api-v2.soundcloud.com/users/\" + getId() + \"/tracks\"\n                     + \"?client_id=\" + SoundcloudParsingHelper.clientId()\n                     + \"&limit=20\"\n                     + \"&linked_partitioning=1\";\n \n-            nextPageUrl = SoundcloudParsingHelper.getStreamsFromApiMinItems(15, streamInfoItemsCollector, apiUrl);\n+            String nextPageUrl = SoundcloudParsingHelper.getStreamsFromApiMinItems(15, streamInfoItemsCollector, apiUrl);", "originalCommit": "4890b2906f805ccfccc83be13d954ed2cb8fc4e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY5NDM5Mg==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r446694392", "bodyText": "final", "author": "Stypox", "createdAt": "2020-06-28T20:27:26Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/soundcloud/extractors/SoundcloudChannelExtractor.java", "diffHunk": "@@ -102,44 +101,31 @@ public String getParentChannelAvatarUrl() throws ParsingException {\n     @Nonnull\n     @Override\n     public InfoItemsPage<StreamInfoItem> getInitialPage() throws ExtractionException {\n-        if (streamInfoItemsCollector == null) {\n-            computeNextPageAndGetStreams();\n-        }\n-        return new InfoItemsPage<>(streamInfoItemsCollector, getNextPageUrl());\n-    }\n-\n-    @Override\n-    public String getNextPageUrl() throws ExtractionException {\n-        if (nextPageUrl == null) {\n-            computeNextPageAndGetStreams();\n-        }\n-        return nextPageUrl;\n-    }\n-\n-    private void computeNextPageAndGetStreams() throws ExtractionException {\n         try {\n-            streamInfoItemsCollector = new StreamInfoItemsCollector(getServiceId());\n+            StreamInfoItemsCollector streamInfoItemsCollector = new StreamInfoItemsCollector(getServiceId());\n \n             String apiUrl = \"https://api-v2.soundcloud.com/users/\" + getId() + \"/tracks\"", "originalCommit": "4890b2906f805ccfccc83be13d954ed2cb8fc4e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY5NDQxNg==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r446694416", "bodyText": "final", "author": "Stypox", "createdAt": "2020-06-28T20:27:37Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/soundcloud/extractors/SoundcloudChannelExtractor.java", "diffHunk": "@@ -102,44 +101,31 @@ public String getParentChannelAvatarUrl() throws ParsingException {\n     @Nonnull\n     @Override\n     public InfoItemsPage<StreamInfoItem> getInitialPage() throws ExtractionException {\n-        if (streamInfoItemsCollector == null) {\n-            computeNextPageAndGetStreams();\n-        }\n-        return new InfoItemsPage<>(streamInfoItemsCollector, getNextPageUrl());\n-    }\n-\n-    @Override\n-    public String getNextPageUrl() throws ExtractionException {\n-        if (nextPageUrl == null) {\n-            computeNextPageAndGetStreams();\n-        }\n-        return nextPageUrl;\n-    }\n-\n-    private void computeNextPageAndGetStreams() throws ExtractionException {\n         try {\n-            streamInfoItemsCollector = new StreamInfoItemsCollector(getServiceId());\n+            StreamInfoItemsCollector streamInfoItemsCollector = new StreamInfoItemsCollector(getServiceId());\n \n             String apiUrl = \"https://api-v2.soundcloud.com/users/\" + getId() + \"/tracks\"\n                     + \"?client_id=\" + SoundcloudParsingHelper.clientId()\n                     + \"&limit=20\"\n                     + \"&linked_partitioning=1\";\n \n-            nextPageUrl = SoundcloudParsingHelper.getStreamsFromApiMinItems(15, streamInfoItemsCollector, apiUrl);\n+            String nextPageUrl = SoundcloudParsingHelper.getStreamsFromApiMinItems(15, streamInfoItemsCollector, apiUrl);\n+\n+            return new InfoItemsPage<>(streamInfoItemsCollector, new Page(nextPageUrl));\n         } catch (Exception e) {\n             throw new ExtractionException(\"Could not get next page\", e);\n         }\n     }\n \n     @Override\n-    public InfoItemsPage<StreamInfoItem> getPage(final String pageUrl) throws IOException, ExtractionException {\n-        if (isNullOrEmpty(pageUrl)) {\n-            throw new ExtractionException(new IllegalArgumentException(\"Page url is empty or null\"));\n+    public InfoItemsPage<StreamInfoItem> getPage(final Page page) throws IOException, ExtractionException {\n+        if (page == null || isNullOrEmpty(page.getUrl())) {\n+            throw new IllegalArgumentException(\"Page doesn't contain an URL\");\n         }\n \n         StreamInfoItemsCollector collector = new StreamInfoItemsCollector(getServiceId());\n-        String nextPageUrl = SoundcloudParsingHelper.getStreamsFromApiMinItems(15, collector, pageUrl);\n+        String nextPageUrl = SoundcloudParsingHelper.getStreamsFromApiMinItems(15, collector, page.getUrl());", "originalCommit": "4890b2906f805ccfccc83be13d954ed2cb8fc4e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjY5NDUzOQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r446694539", "bodyText": "final (while you are at it ;-) )", "author": "Stypox", "createdAt": "2020-06-28T20:29:04Z", "path": "extractor/src/main/java/org/schabi/newpipe/extractor/services/youtube/extractors/YoutubePlaylistExtractor.java", "diffHunk": "@@ -193,42 +186,45 @@ public String getSubChannelAvatarUrl() {\n                             .getObject(\"videoList\").getObject(\"playlistVideoListRenderer\").getArray(\"contents\"));\n                 }\n             }\n+\n+            return new InfoItemsPage<>(collector, null);\n         } else if (contents.getObject(0).has(\"playlistVideoListRenderer\")) {\n-            final JsonArray videos = contents.getObject(0)\n-                    .getObject(\"playlistVideoListRenderer\").getArray(\"contents\");\n-            collectStreamsFrom(collector, videos);\n+            final JsonObject videos = contents.getObject(0).getObject(\"playlistVideoListRenderer\");\n+            collectStreamsFrom(collector, videos.getArray(\"contents\"));\n+\n+            nextPage = getNextPageFrom(videos.getArray(\"continuations\"));\n         }\n \n-        return new InfoItemsPage<>(collector, getNextPageUrl());\n+        return new InfoItemsPage<>(collector, nextPage);\n     }\n \n     @Override\n-    public InfoItemsPage<StreamInfoItem> getPage(final String pageUrl) throws IOException, ExtractionException {\n-        if (isNullOrEmpty(pageUrl)) {\n-            throw new ExtractionException(new IllegalArgumentException(\"Page url is empty or null\"));\n+    public InfoItemsPage<StreamInfoItem> getPage(final Page page) throws IOException, ExtractionException {\n+        if (page == null || isNullOrEmpty(page.getUrl())) {\n+            throw new IllegalArgumentException(\"Page doesn't contain an URL\");\n         }\n \n         final StreamInfoItemsCollector collector = new StreamInfoItemsCollector(getServiceId());\n-        final JsonArray ajaxJson = getJsonResponse(pageUrl, getExtractorLocalization());\n+        final JsonArray ajaxJson = getJsonResponse(page.getUrl(), getExtractorLocalization());\n \n         final JsonObject sectionListContinuation = ajaxJson.getObject(1).getObject(\"response\")\n                 .getObject(\"continuationContents\").getObject(\"playlistVideoListContinuation\");\n \n         collectStreamsFrom(collector, sectionListContinuation.getArray(\"contents\"));\n \n-        return new InfoItemsPage<>(collector, getNextPageUrlFrom(sectionListContinuation.getArray(\"continuations\")));\n+        return new InfoItemsPage<>(collector, getNextPageFrom(sectionListContinuation.getArray(\"continuations\")));\n     }\n \n-    private String getNextPageUrlFrom(final JsonArray continuations) {\n+    private Page getNextPageFrom(final JsonArray continuations) {\n         if (isNullOrEmpty(continuations)) {\n-            return \"\";\n+            return null;\n         }\n \n         JsonObject nextContinuationData = continuations.getObject(0).getObject(\"nextContinuationData\");\n         String continuation = nextContinuationData.getString(\"continuation\");\n         String clickTrackingParams = nextContinuationData.getString(\"clickTrackingParams\");", "originalCommit": "4890b2906f805ccfccc83be13d954ed2cb8fc4e5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e3bfdba13563a2e3da77f4f4ab59bc9761b2a8ea", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/commit/e3bfdba13563a2e3da77f4f4ab59bc9761b2a8ea", "message": "Remove getNextPageUrl() function from ListExtractor", "committedDate": "2020-07-06T18:11:40Z", "type": "commit"}, {"oid": "4cc312086afc6d6772ba657ddf96c5f5b14f41bd", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/commit/4cc312086afc6d6772ba657ddf96c5f5b14f41bd", "message": "Introduce Page class", "committedDate": "2020-07-06T18:19:31Z", "type": "commit"}, {"oid": "9b6fe1dea6b740c948a8553da03e1f20390b6112", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/commit/9b6fe1dea6b740c948a8553da03e1f20390b6112", "message": "Throw IllegalArgumentException when Page is invalid", "committedDate": "2020-07-06T18:19:31Z", "type": "commit"}, {"oid": "17ba8a57fa81aacd338373c2ff810513e5a099e7", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/commit/17ba8a57fa81aacd338373c2ff810513e5a099e7", "message": "Clean up the code", "committedDate": "2020-07-06T18:19:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDk4ODQyMw==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r450988423", "bodyText": "This should be converted to a do-while loop.", "author": "TobiGr", "createdAt": "2020-07-07T16:21:50Z", "path": "extractor/src/test/java/org/schabi/newpipe/extractor/services/youtube/YoutubeCommentsExtractorTest.java", "diffHunk": "@@ -63,16 +63,18 @@ public void testGetCommentsFromCommentsInfo() throws IOException, ExtractionExce\n     }\n \n     private boolean getCommentsFromCommentsInfoHelper(String url) throws IOException, ExtractionException {\n-        boolean result = false;\n         CommentsInfo commentsInfo = CommentsInfo.getInfo(url);\n-        result = findInComments(commentsInfo.getRelatedItems(), \"s1ck m3m3\");\n \n-   /*     String nextPage = commentsInfo.getNextPageUrl();\n-        while (!Utils.isBlank(nextPage) && !result) {\n-            InfoItemsPage<CommentsInfoItem> moreItems = CommentsInfo.getMoreItems(YouTube, commentsInfo, nextPage);\n+        assertEquals(\"Comments\", commentsInfo.getName());\n+        boolean result = findInComments(commentsInfo.getRelatedItems(), \"s1ck m3m3\");\n+\n+        Page nextPage = commentsInfo.getNextPage();\n+        InfoItemsPage<CommentsInfoItem> moreItems = new InfoItemsPage<>(null, nextPage, null);\n+        while (moreItems.hasNextPage() && !result) {\n+            moreItems = CommentsInfo.getMoreItems(YouTube, commentsInfo, nextPage);\n             result = findInComments(moreItems.getItems(), \"s1ck m3m3\");\n-            nextPage = moreItems.getNextPageUrl();\n-        }*/\n+            nextPage = moreItems.getNextPage();\n+        }", "originalCommit": "c45a0a51c86372c5b5fa8942529d3e0d4aef014e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDk4ODgxOQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r450988819", "bodyText": "whitespace", "author": "TobiGr", "createdAt": "2020-07-07T16:22:28Z", "path": "extractor/src/test/java/org/schabi/newpipe/extractor/services/peertube/PeertubeCommentsExtractorTest.java", "diffHunk": "@@ -31,37 +34,38 @@ public static void setUp() throws Exception {\n         @Test\n         public void testGetComments() throws IOException, ExtractionException {\n             InfoItemsPage<CommentsInfoItem> comments = extractor.getInitialPage();\n-            assertTrue(comments.getErrors().isEmpty());\n-\n             boolean result = findInComments(comments, \"@root A great documentary on a great guy.\");\n+    \n             while (comments.hasNextPage() && !result) {\n-                comments = extractor.getPage(comments.getNextPageUrl());\n+                comments = extractor.getPage(comments.getNextPage());\n                 result = findInComments(comments, \"@root A great documentary on a great guy.\");\n             }\n-\n+    ", "originalCommit": "c45a0a51c86372c5b5fa8942529d3e0d4aef014e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDk4ODk0NA==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r450988944", "bodyText": "whitespace", "author": "TobiGr", "createdAt": "2020-07-07T16:22:41Z", "path": "extractor/src/test/java/org/schabi/newpipe/extractor/services/peertube/PeertubeCommentsExtractorTest.java", "diffHunk": "@@ -31,37 +34,38 @@ public static void setUp() throws Exception {\n         @Test\n         public void testGetComments() throws IOException, ExtractionException {\n             InfoItemsPage<CommentsInfoItem> comments = extractor.getInitialPage();\n-            assertTrue(comments.getErrors().isEmpty());\n-\n             boolean result = findInComments(comments, \"@root A great documentary on a great guy.\");\n+    \n             while (comments.hasNextPage() && !result) {\n-                comments = extractor.getPage(comments.getNextPageUrl());\n+                comments = extractor.getPage(comments.getNextPage());\n                 result = findInComments(comments, \"@root A great documentary on a great guy.\");\n             }\n-\n+    \n             assertTrue(result);\n         }\n-\n+    ", "originalCommit": "c45a0a51c86372c5b5fa8942529d3e0d4aef014e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDk4OTE0NQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r450989145", "bodyText": "whitespace", "author": "TobiGr", "createdAt": "2020-07-07T16:23:03Z", "path": "extractor/src/test/java/org/schabi/newpipe/extractor/services/peertube/PeertubeCommentsExtractorTest.java", "diffHunk": "@@ -31,37 +34,38 @@ public static void setUp() throws Exception {\n         @Test\n         public void testGetComments() throws IOException, ExtractionException {\n             InfoItemsPage<CommentsInfoItem> comments = extractor.getInitialPage();\n-            assertTrue(comments.getErrors().isEmpty());\n-\n             boolean result = findInComments(comments, \"@root A great documentary on a great guy.\");\n+    \n             while (comments.hasNextPage() && !result) {\n-                comments = extractor.getPage(comments.getNextPageUrl());\n+                comments = extractor.getPage(comments.getNextPage());\n                 result = findInComments(comments, \"@root A great documentary on a great guy.\");\n             }\n-\n+    \n             assertTrue(result);\n         }\n-\n+    \n         @Test\n         public void testGetCommentsFromCommentsInfo() throws IOException, ExtractionException {\n-            final CommentsInfo commentsInfo = CommentsInfo.getInfo(\"https://framatube.org/videos/watch/a8ea95b8-0396-49a6-8f30-e25e25fb2828\");\n-            assertTrue(commentsInfo.getErrors().isEmpty());\n+            CommentsInfo commentsInfo = CommentsInfo.getInfo(\"https://framatube.org/videos/watch/a8ea95b8-0396-49a6-8f30-e25e25fb2828\");\n             assertEquals(\"Comments\", commentsInfo.getName());\n-\n+    ", "originalCommit": "c45a0a51c86372c5b5fa8942529d3e0d4aef014e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDk4OTE5OQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r450989199", "bodyText": "whitespace", "author": "TobiGr", "createdAt": "2020-07-07T16:23:08Z", "path": "extractor/src/test/java/org/schabi/newpipe/extractor/services/peertube/PeertubeCommentsExtractorTest.java", "diffHunk": "@@ -31,37 +34,38 @@ public static void setUp() throws Exception {\n         @Test\n         public void testGetComments() throws IOException, ExtractionException {\n             InfoItemsPage<CommentsInfoItem> comments = extractor.getInitialPage();\n-            assertTrue(comments.getErrors().isEmpty());\n-\n             boolean result = findInComments(comments, \"@root A great documentary on a great guy.\");\n+    \n             while (comments.hasNextPage() && !result) {\n-                comments = extractor.getPage(comments.getNextPageUrl());\n+                comments = extractor.getPage(comments.getNextPage());\n                 result = findInComments(comments, \"@root A great documentary on a great guy.\");\n             }\n-\n+    \n             assertTrue(result);\n         }\n-\n+    \n         @Test\n         public void testGetCommentsFromCommentsInfo() throws IOException, ExtractionException {\n-            final CommentsInfo commentsInfo = CommentsInfo.getInfo(\"https://framatube.org/videos/watch/a8ea95b8-0396-49a6-8f30-e25e25fb2828\");\n-            assertTrue(commentsInfo.getErrors().isEmpty());\n+            CommentsInfo commentsInfo = CommentsInfo.getInfo(\"https://framatube.org/videos/watch/a8ea95b8-0396-49a6-8f30-e25e25fb2828\");\n             assertEquals(\"Comments\", commentsInfo.getName());\n-\n+    \n             boolean result = findInComments(commentsInfo.getRelatedItems(), \"Loved it!!!\");\n-            String nextPage = commentsInfo.getNextPageUrl();\n-            while (!Utils.isBlank(nextPage) && !result) {\n-                final InfoItemsPage<CommentsInfoItem> moreItems = CommentsInfo.getMoreItems(PeerTube, commentsInfo, nextPage);\n+    \n+            Page nextPage = commentsInfo.getNextPage();\n+            InfoItemsPage<CommentsInfoItem> moreItems = new InfoItemsPage<>(null, nextPage, null);\n+            while (moreItems.hasNextPage() && !result) {\n+                moreItems = CommentsInfo.getMoreItems(PeerTube, commentsInfo, nextPage);\n                 result = findInComments(moreItems.getItems(), \"Loved it!!!\");\n-                nextPage = moreItems.getNextPageUrl();\n+                nextPage = moreItems.getNextPage();\n             }\n+    \n             assertTrue(result);\n         }\n-\n+    ", "originalCommit": "c45a0a51c86372c5b5fa8942529d3e0d4aef014e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDk4OTI2Mw==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r450989263", "bodyText": "whitespace", "author": "TobiGr", "createdAt": "2020-07-07T16:23:15Z", "path": "extractor/src/test/java/org/schabi/newpipe/extractor/services/peertube/PeertubeCommentsExtractorTest.java", "diffHunk": "@@ -71,16 +75,16 @@ public void testGetCommentsAllData() throws IOException, ExtractionException {\n                 assertFalse(Utils.isBlank(c.getTextualUploadDate()));\n                 assertFalse(Utils.isBlank(c.getThumbnailUrl()));\n                 assertFalse(Utils.isBlank(c.getUrl()));\n-                assertEquals(-1, c.getLikeCount());\n+                assertFalse(c.getLikeCount() != -1);\n             }\n         }\n-\n-        private boolean findInComments(final InfoItemsPage<CommentsInfoItem> comments, final String comment) {\n+    ", "originalCommit": "c45a0a51c86372c5b5fa8942529d3e0d4aef014e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDk4OTI5NQ==", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/pull/314#discussion_r450989295", "bodyText": "whitespace", "author": "TobiGr", "createdAt": "2020-07-07T16:23:19Z", "path": "extractor/src/test/java/org/schabi/newpipe/extractor/services/peertube/PeertubeCommentsExtractorTest.java", "diffHunk": "@@ -71,16 +75,16 @@ public void testGetCommentsAllData() throws IOException, ExtractionException {\n                 assertFalse(Utils.isBlank(c.getTextualUploadDate()));\n                 assertFalse(Utils.isBlank(c.getThumbnailUrl()));\n                 assertFalse(Utils.isBlank(c.getUrl()));\n-                assertEquals(-1, c.getLikeCount());\n+                assertFalse(c.getLikeCount() != -1);\n             }\n         }\n-\n-        private boolean findInComments(final InfoItemsPage<CommentsInfoItem> comments, final String comment) {\n+    \n+        private boolean findInComments(InfoItemsPage<CommentsInfoItem> comments, String comment) {\n             return findInComments(comments.getItems(), comment);\n         }\n-\n-        private boolean findInComments(final List<CommentsInfoItem> comments, final String comment) {\n-            for (final CommentsInfoItem c : comments) {\n+    ", "originalCommit": "c45a0a51c86372c5b5fa8942529d3e0d4aef014e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0a5a905bc70b52f57f70bf69705f05cde1d4e329", "url": "https://github.com/TeamNewPipe/NewPipeExtractor/commit/0a5a905bc70b52f57f70bf69705f05cde1d4e329", "message": "Add final at more places", "committedDate": "2020-07-07T18:45:47Z", "type": "commit"}]}