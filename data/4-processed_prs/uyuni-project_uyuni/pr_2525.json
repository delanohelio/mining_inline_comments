{"pr_number": 2525, "pr_title": "Xliff merge tool", "pr_createdAt": "2020-08-26T11:12:14Z", "pr_url": "https://github.com/uyuni-project/uyuni/pull/2525", "timeline": [{"oid": "51d60ad30ddc761fda44cda76ca697e317defec0", "url": "https://github.com/uyuni-project/uyuni/commit/51d60ad30ddc761fda44cda76ca697e317defec0", "message": "1st draft of xliff merge tool", "committedDate": "2020-08-26T11:12:51Z", "type": "commit"}, {"oid": "51d60ad30ddc761fda44cda76ca697e317defec0", "url": "https://github.com/uyuni-project/uyuni/commit/51d60ad30ddc761fda44cda76ca697e317defec0", "message": "1st draft of xliff merge tool", "committedDate": "2020-08-26T11:12:51Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM2MTQ5Mw==", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r477361493", "bodyText": "state is an attribute for \"<target>\". Here it seems you set it on <trans-unit> .\nBut I think we do not need to set state=new as a missing <target> has the same effect", "author": "mcalmer", "createdAt": "2020-08-26T14:49:33Z", "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,95 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        item.set('state', 'new')", "originalCommit": "51d60ad30ddc761fda44cda76ca697e317defec0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM2MTk5Mg==", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r477361992", "bodyText": "state is an attribute for \"<target>\". Here it seems you set it on <trans-unit>\nhttp://docs.oasis-open.org/xliff/v1.2/os/xliff-core.html#state", "author": "mcalmer", "createdAt": "2020-08-26T14:50:10Z", "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,95 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        item.set('state', 'new')\n+        body_element.append(item)\n+\n+\n+def update_trans_units(body_element, trans_units, id_new_value_dict):\n+    to_update = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in id_new_value_dict]\n+    for trans_unit in to_update:\n+        trans_unit.set('state', 'needs-adaptation')", "originalCommit": "51d60ad30ddc761fda44cda76ca697e317defec0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM2MzU4MA==", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r477363580", "bodyText": "Can we be sure that trans_unit[0] is element \"source\"? I think we better pick the source element explicit.", "author": "mcalmer", "createdAt": "2020-08-26T14:52:17Z", "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,95 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        item.set('state', 'new')\n+        body_element.append(item)\n+\n+\n+def update_trans_units(body_element, trans_units, id_new_value_dict):\n+    to_update = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in id_new_value_dict]\n+    for trans_unit in to_update:\n+        trans_unit.set('state', 'needs-adaptation')\n+        trans_unit[0].text = id_new_value_dict[trans_unit.attrib['id']]", "originalCommit": "51d60ad30ddc761fda44cda76ca697e317defec0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM2MzkyNA==", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r477363924", "bodyText": "Can we be sure that tr_unit[0] is element \"source\"? I think we better pick the source element explicit.", "author": "mcalmer", "createdAt": "2020-08-26T14:52:47Z", "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,95 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        item.set('state', 'new')\n+        body_element.append(item)\n+\n+\n+def update_trans_units(body_element, trans_units, id_new_value_dict):\n+    to_update = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in id_new_value_dict]\n+    for trans_unit in to_update:\n+        trans_unit.set('state', 'needs-adaptation')\n+        trans_unit[0].text = id_new_value_dict[trans_unit.attrib['id']]\n+\n+\n+def process(original_file, translation_file):\n+    xml_tree_original = ET.parse(original_file)\n+    xml_tree_translation = ET.parse(translation_file)\n+    original_body_element, original_trans_units = get_trans_units(xml_tree_original)\n+    translation_body_element, translation_trans_units = get_trans_units(xml_tree_translation)\n+    logging.debug(f'{len(original_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(translation_trans_units)} trans_units in translation file {translation_file}')\n+\n+    org_trans_units_ids = [tr_unit.attrib['id'] for tr_unit in original_trans_units]\n+    trans_units_ids = [tr_unit.attrib['id'] for tr_unit in translation_trans_units]\n+    logging.debug(f'{org_trans_units_ids} trans_units IDs in original file {original_file}')\n+    logging.debug(f'{trans_units_ids} trans_units in Ids translation file {translation_file}')\n+\n+    # Delete the ones which are in translation file but not in original\n+    logging.info(\"########## DELETING ORPHAN TRANS_UNITS ##########\")\n+    to_remove = set(trans_units_ids).difference(set(org_trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_remove}, will be deleted from the {translation_file}')\n+    delete_trans_units(translation_body_element, translation_trans_units, to_remove)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Add the ones which are not in translation file but exist in original\n+    logging.info(\"########## ADDING MISSING TRANS_UNITS ##########\")\n+    to_add = set(org_trans_units_ids).difference(set(trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_add}, will be added to the {translation_file}')\n+    add_trans_units(translation_body_element, original_trans_units, to_add)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Update() those trans_units where source has been changed but id remained same. We will be updating source text and\n+    # add the 'needs-adaptation' state attribute\n+    logging.info(\"########## UPDATE THE CHANGED TRANS_UNITS ##########\")\n+    # Get again so we get the updated list after deletion/addition\n+    translation_trans_units = list(translation_body_element)\n+\n+    logging.debug(f'{len(original_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(translation_trans_units)} trans_units in original file {original_file}')\n+    if len(translation_trans_units) == len(original_trans_units):\n+        trans_units_sources = {tr_unit.attrib['id']: tr_unit[0].text for tr_unit in translation_trans_units}\n+        org_trans_units_sources = {tr_unit.attrib['id']: tr_unit[0].text for tr_unit in original_trans_units}", "originalCommit": "51d60ad30ddc761fda44cda76ca697e317defec0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM2NDY2MA==", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r477364660", "bodyText": "What about else: (if len(translation_trans_units) == len(original_trans_units):)\nI think we should at least write a message", "author": "mcalmer", "createdAt": "2020-08-26T14:53:46Z", "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,95 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        item.set('state', 'new')\n+        body_element.append(item)\n+\n+\n+def update_trans_units(body_element, trans_units, id_new_value_dict):\n+    to_update = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in id_new_value_dict]\n+    for trans_unit in to_update:\n+        trans_unit.set('state', 'needs-adaptation')\n+        trans_unit[0].text = id_new_value_dict[trans_unit.attrib['id']]\n+\n+\n+def process(original_file, translation_file):\n+    xml_tree_original = ET.parse(original_file)\n+    xml_tree_translation = ET.parse(translation_file)\n+    original_body_element, original_trans_units = get_trans_units(xml_tree_original)\n+    translation_body_element, translation_trans_units = get_trans_units(xml_tree_translation)\n+    logging.debug(f'{len(original_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(translation_trans_units)} trans_units in translation file {translation_file}')\n+\n+    org_trans_units_ids = [tr_unit.attrib['id'] for tr_unit in original_trans_units]\n+    trans_units_ids = [tr_unit.attrib['id'] for tr_unit in translation_trans_units]\n+    logging.debug(f'{org_trans_units_ids} trans_units IDs in original file {original_file}')\n+    logging.debug(f'{trans_units_ids} trans_units in Ids translation file {translation_file}')\n+\n+    # Delete the ones which are in translation file but not in original\n+    logging.info(\"########## DELETING ORPHAN TRANS_UNITS ##########\")\n+    to_remove = set(trans_units_ids).difference(set(org_trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_remove}, will be deleted from the {translation_file}')\n+    delete_trans_units(translation_body_element, translation_trans_units, to_remove)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Add the ones which are not in translation file but exist in original\n+    logging.info(\"########## ADDING MISSING TRANS_UNITS ##########\")\n+    to_add = set(org_trans_units_ids).difference(set(trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_add}, will be added to the {translation_file}')\n+    add_trans_units(translation_body_element, original_trans_units, to_add)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Update() those trans_units where source has been changed but id remained same. We will be updating source text and\n+    # add the 'needs-adaptation' state attribute\n+    logging.info(\"########## UPDATE THE CHANGED TRANS_UNITS ##########\")\n+    # Get again so we get the updated list after deletion/addition\n+    translation_trans_units = list(translation_body_element)\n+\n+    logging.debug(f'{len(original_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(translation_trans_units)} trans_units in original file {original_file}')\n+    if len(translation_trans_units) == len(original_trans_units):\n+        trans_units_sources = {tr_unit.attrib['id']: tr_unit[0].text for tr_unit in translation_trans_units}\n+        org_trans_units_sources = {tr_unit.attrib['id']: tr_unit[0].text for tr_unit in original_trans_units}\n+        to_update = {k: org_trans_units_sources[k] for k,_ in set(org_trans_units_sources.items()) - set(trans_units_sources.items())}\n+        logging.info(f' These (id,new_source_value) -> {to_update}, will be updated in the {translation_file} ')\n+        update_trans_units(translation_body_element,translation_trans_units,to_update)\n+", "originalCommit": "51d60ad30ddc761fda44cda76ca697e317defec0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM2NTMyMQ==", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r477365321", "bodyText": "Would be good if we could provide the working directory as command line parameter.", "author": "mcalmer", "createdAt": "2020-08-26T14:54:39Z", "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,95 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        item.set('state', 'new')\n+        body_element.append(item)\n+\n+\n+def update_trans_units(body_element, trans_units, id_new_value_dict):\n+    to_update = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in id_new_value_dict]\n+    for trans_unit in to_update:\n+        trans_unit.set('state', 'needs-adaptation')\n+        trans_unit[0].text = id_new_value_dict[trans_unit.attrib['id']]\n+\n+\n+def process(original_file, translation_file):\n+    xml_tree_original = ET.parse(original_file)\n+    xml_tree_translation = ET.parse(translation_file)\n+    original_body_element, original_trans_units = get_trans_units(xml_tree_original)\n+    translation_body_element, translation_trans_units = get_trans_units(xml_tree_translation)\n+    logging.debug(f'{len(original_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(translation_trans_units)} trans_units in translation file {translation_file}')\n+\n+    org_trans_units_ids = [tr_unit.attrib['id'] for tr_unit in original_trans_units]\n+    trans_units_ids = [tr_unit.attrib['id'] for tr_unit in translation_trans_units]\n+    logging.debug(f'{org_trans_units_ids} trans_units IDs in original file {original_file}')\n+    logging.debug(f'{trans_units_ids} trans_units in Ids translation file {translation_file}')\n+\n+    # Delete the ones which are in translation file but not in original\n+    logging.info(\"########## DELETING ORPHAN TRANS_UNITS ##########\")\n+    to_remove = set(trans_units_ids).difference(set(org_trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_remove}, will be deleted from the {translation_file}')\n+    delete_trans_units(translation_body_element, translation_trans_units, to_remove)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Add the ones which are not in translation file but exist in original\n+    logging.info(\"########## ADDING MISSING TRANS_UNITS ##########\")\n+    to_add = set(org_trans_units_ids).difference(set(trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_add}, will be added to the {translation_file}')\n+    add_trans_units(translation_body_element, original_trans_units, to_add)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Update() those trans_units where source has been changed but id remained same. We will be updating source text and\n+    # add the 'needs-adaptation' state attribute\n+    logging.info(\"########## UPDATE THE CHANGED TRANS_UNITS ##########\")\n+    # Get again so we get the updated list after deletion/addition\n+    translation_trans_units = list(translation_body_element)\n+\n+    logging.debug(f'{len(original_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(translation_trans_units)} trans_units in original file {original_file}')\n+    if len(translation_trans_units) == len(original_trans_units):\n+        trans_units_sources = {tr_unit.attrib['id']: tr_unit[0].text for tr_unit in translation_trans_units}\n+        org_trans_units_sources = {tr_unit.attrib['id']: tr_unit[0].text for tr_unit in original_trans_units}\n+        to_update = {k: org_trans_units_sources[k] for k,_ in set(org_trans_units_sources.items()) - set(trans_units_sources.items())}\n+        logging.info(f' These (id,new_source_value) -> {to_update}, will be updated in the {translation_file} ')\n+        update_trans_units(translation_body_element,translation_trans_units,to_update)\n+\n+\n+    #xml_tree_translation.write(translation, encoding='utf-8', xml_declaration=True)\n+    logging.info(\"########## FINISH ##########\")\n+\n+\n+def get_trans_units(xml_tree):\n+    root_node = xml_tree.getroot()\n+    # file_tag = root_node[0]\n+    body_element = root_node[0][0]\n+    return body_element, list(body_element)\n+\n+\n+ET.register_namespace('', \"urn:oasis:names:tc:xliff:document:1.1\")\n+ET.register_namespace('xyz', \"urn:appInfo:Items\")\n+ET.register_namespace('xsi', \"http://www.w3.org/2001/XMLSchema-instance\")\n+\n+files = os.listdir('.')", "originalCommit": "51d60ad30ddc761fda44cda76ca697e317defec0", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "f242c376a559fdb3984506ec72e4dafef5694987", "url": "https://github.com/uyuni-project/uyuni/commit/f242c376a559fdb3984506ec72e4dafef5694987", "message": "accept command line 'path' paramter to input directory of translation files", "committedDate": "2020-08-27T13:58:23Z", "type": "commit"}, {"oid": "0d4bbb434fae70f9dfa934072fe2b6738739575a", "url": "https://github.com/uyuni-project/uyuni/commit/0d4bbb434fae70f9dfa934072fe2b6738739575a", "message": "Use name instead of index when referenceing elements", "committedDate": "2020-08-27T14:49:45Z", "type": "commit"}, {"oid": "5eb02e5f4c624d841fb12543c25ca69f77e1131d", "url": "https://github.com/uyuni-project/uyuni/commit/5eb02e5f4c624d841fb12543c25ca69f77e1131d", "message": "Use state attribute in target element instead of trans-unit", "committedDate": "2020-08-27T14:50:41Z", "type": "commit"}, {"oid": "13ca7daad48d3bb1ce77c8547f55306da66cf94f", "url": "https://github.com/uyuni-project/uyuni/commit/13ca7daad48d3bb1ce77c8547f55306da66cf94f", "message": "tool to extract trans-units from group element and then remove the element", "committedDate": "2020-08-28T15:35:45Z", "type": "commit"}, {"oid": "13ca7daad48d3bb1ce77c8547f55306da66cf94f", "url": "https://github.com/uyuni-project/uyuni/commit/13ca7daad48d3bb1ce77c8547f55306da66cf94f", "message": "tool to extract trans-units from group element and then remove the element", "committedDate": "2020-08-28T15:35:45Z", "type": "forcePushed"}, {"oid": "ddf45b78c9b1d1b0136bfad15a3ed7202e69cb8f", "url": "https://github.com/uyuni-project/uyuni/commit/ddf45b78c9b1d1b0136bfad15a3ed7202e69cb8f", "message": "Fix the order of insertion.", "committedDate": "2020-08-31T11:51:58Z", "type": "commit"}, {"oid": "ab049c99da4a96e073cd91d8be71324841b259a4", "url": "https://github.com/uyuni-project/uyuni/commit/ab049c99da4a96e073cd91d8be71324841b259a4", "message": "Keep the comments in modified file.", "committedDate": "2020-09-03T09:09:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU3MDQ0NQ==", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r483570445", "bodyText": "This parameter is not being used. I guess it can be removed?", "author": "parlt91", "createdAt": "2020-09-04T11:58:14Z", "path": "scripts/translation/trans-units-extractor.py", "diffHunk": "@@ -0,0 +1,62 @@\n+#!/usr/bin/python3\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+import argparse\n+argparser = argparse.ArgumentParser()\n+argparser.add_argument(\"path\", help=\"Path to look into for translation files!\")\n+args = argparser.parse_args()\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+class CommentedTreeBuilder(ET.TreeBuilder):\n+    def comment(self, data):\n+        self.start(ET.Comment, {})\n+        self.data(data)\n+        self.end(ET.Comment)\n+\n+\n+def get_groups(xml_tree):\n+    root_node = xml_tree.getroot()\n+    file_tag = root_node.find('d:file', ns)\n+    body_element = file_tag.find('d:body', ns)\n+    groups = list(body_element.findall('d:group', ns))\n+    logging.info(\"'{0}' <group> elements are found\".format(len(groups)))\n+    return body_element, groups\n+\n+\n+def extract_trans_units(org_file):\n+    parser = ET.XMLParser(target=CommentedTreeBuilder())\n+    tree = ET.parse(file, parser=parser)\n+    body_element, groups = get_groups(tree)\n+    for group in groups:\n+        all_child_elements_of_body = list(body_element)\n+        context_group = group.find('d:context-group', ns)\n+        group_trans_units = group.findall('d:trans-unit', ns)\n+        index = all_child_elements_of_body.index(group)\n+        group_trans_units.reverse()\n+        for group_trans_unit in group_trans_units:\n+            if context_group is not None:\n+                group_trans_unit.append(context_group)\n+            body_element.insert(index, group_trans_unit)\n+        body_element.remove(group)\n+\n+    tree.write(org_file, encoding='utf-8', xml_declaration=True)\n+\n+\n+\n+ET.register_namespace('', \"urn:oasis:names:tc:xliff:document:1.1\")\n+ET.register_namespace('xyz', \"urn:appInfo:Items\")\n+ET.register_namespace('xsi', \"http://www.w3.org/2001/XMLSchema-instance\")\n+ns = {'d': 'urn:oasis:names:tc:xliff:document:1.1'}\n+\n+os.chdir(args.path)\n+files = os.listdir(args.path)\n+logging.debug(files)\n+\n+for file in files:\n+    if file.startswith('StringResource_') and file.endswith('.xml'):\n+        original = 'StringResource_en_US.xml'", "originalCommit": "ab049c99da4a96e073cd91d8be71324841b259a4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU3NDE4OQ==", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r483574189", "bodyText": "parser -> argparser", "author": "parlt91", "createdAt": "2020-09-04T12:07:02Z", "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,122 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+import argparse\n+argparser = argparse.ArgumentParser()\n+argparser.add_argument(\"path\", help=\"Path to look into for translation files!\")\n+args = parser.parse_args()", "originalCommit": "ab049c99da4a96e073cd91d8be71324841b259a4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU4MjE3NQ==", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r483582175", "bodyText": "Using the same instance of parser two parse both files does not seem to work for me\nINFO:root:\nprocessing StringResource_ca.xml\nTraceback (most recent call last):\n  File \"/home/pascal/git/uyuni/scripts/translation/xliffmerger.py\", line 123, in <module>\n    process(original, translation)\n  File \"/home/pascal/git/uyuni/scripts/translation/xliffmerger.py\", line 53, in process\n    xml_tree_original = ET.parse(original_file, parser=parser)\n  File \"/usr/lib64/python3.6/xml/etree/ElementTree.py\", line 1196, in parse\n    tree.parse(source, parser)\n  File \"/usr/lib64/python3.6/xml/etree/ElementTree.py\", line 603, in parse\n    parser.feed(data)\nxml.etree.ElementTree.ParseError: parsing finished: line 23921, column 8", "author": "parlt91", "createdAt": "2020-09-04T12:24:16Z", "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -40,8 +47,9 @@ def update_trans_units(body_element, trans_units, id_new_value_dict):\n \n \n def process(original_file, translation_file):\n-    xml_tree_original = ET.parse(original_file)\n-    xml_tree_translation = ET.parse(translation_file)\n+    parser = ET.XMLParser(target=CommentedTreeBuilder())", "originalCommit": "ab049c99da4a96e073cd91d8be71324841b259a4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU4MzE3OA==", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r483583178", "bodyText": "Creating two parsers seems to work\nparser1 = ET.XMLParser(target=CommentedTreeBuilder())\nparser2 = ET.XMLParser(target=CommentedTreeBuilder())\nxml_tree_original = ET.parse(original_file, parser=parser1)\nxml_tree_translation = ET.parse(translation_file, parser=parser2)\n\nI have no idea why though", "author": "parlt91", "createdAt": "2020-09-04T12:26:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU4MjE3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU4MzcyOA==", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r483583728", "bodyText": "Should be un-commented before merging", "author": "parlt91", "createdAt": "2020-09-04T12:27:34Z", "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,122 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+import argparse\n+argparser = argparse.ArgumentParser()\n+argparser.add_argument(\"path\", help=\"Path to look into for translation files!\")\n+args = parser.parse_args()\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+class CommentedTreeBuilder(ET.TreeBuilder):\n+    def comment(self, data):\n+        self.start(ET.Comment, {})\n+        self.data(data)\n+        self.end(ET.Comment)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        target_element = ET.Element('target', {'state': 'new'})\n+        target_element.tail = \"\\n  \"\n+        item.append(target_element)\n+        body_element.append(item)\n+\n+\n+def update_trans_units(body_element, trans_units, id_new_value_dict):\n+    to_update = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in id_new_value_dict]\n+    for trans_unit in to_update:\n+        source_element = trans_unit.find('d:source', ns)\n+        source_element.text = id_new_value_dict[trans_unit.attrib['id']]\n+        target_element = trans_unit.find('d:target', ns)\n+        if target_element is None:\n+            target_element = ET.Element('target', {'state': 'needs-adaptation'})\n+            target_element.tail = \"\\n      \"\n+            trans_unit.append(target_element)\n+        else:\n+            target_element.set('state', 'needs-adaptation')\n+\n+\n+def process(original_file, translation_file):\n+    parser = ET.XMLParser(target=CommentedTreeBuilder())\n+    xml_tree_original = ET.parse(original_file, parser=parser)\n+    xml_tree_translation = ET.parse(translation_file, parser=parser)\n+    original_body_element, orig_trans_units = get_trans_units(xml_tree_original)\n+    translation_body_element, trans_trans_units = get_trans_units(xml_tree_translation)\n+    logging.debug(f'{len(orig_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(trans_trans_units)} trans_units in translation file {translation_file}')\n+\n+    org_trans_units_ids = [tr_unit.attrib['id'] for tr_unit in orig_trans_units]\n+    trans_units_ids = [tr_unit.attrib['id'] for tr_unit in trans_trans_units]\n+    logging.debug(f'{org_trans_units_ids} trans_units IDs in original file {original_file}')\n+    logging.debug(f'{trans_units_ids} trans_units in Ids translation file {translation_file}')\n+\n+    # Delete the ones which are in translation file but not in original\n+    logging.info(\"########## DELETING ORPHAN TRANS_UNITS ##########\")\n+    to_remove = set(trans_units_ids).difference(set(org_trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_remove}, will be deleted from the {translation_file}')\n+    delete_trans_units(translation_body_element, trans_trans_units, to_remove)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Add the ones which are not in translation file but exist in original\n+    logging.info(\"########## ADDING MISSING TRANS_UNITS ##########\")\n+    to_add = set(org_trans_units_ids).difference(set(trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_add}, will be added to the {translation_file}')\n+    add_trans_units(translation_body_element, orig_trans_units, to_add)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Update() those trans_units where source has been changed but id remained same. We will be updating source text and\n+    # add the 'needs-adaptation' state attribute\n+    logging.info(\"########## UPDATE THE CHANGED TRANS_UNITS ##########\")\n+    # Get again so we get the updated list after deletion/addition\n+    trans_trans_units = list(translation_body_element.findall('d:trans-unit', ns))\n+\n+    logging.debug(f'{len(orig_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(trans_trans_units)} trans_units in original file {original_file}')\n+    if len(trans_trans_units) == len(orig_trans_units):\n+        trans_units_srcs = {tr_unit.attrib['id']: tr_unit.find('d:source', ns).text for tr_unit in trans_trans_units}\n+        org_trans_units_srcs = {tr_unit.attrib['id']: tr_unit.find('d:source', ns).text for tr_unit in orig_trans_units}\n+        to_update = {k: org_trans_units_srcs[k] for k, _ in\n+                     set(org_trans_units_srcs.items()) - set(trans_units_srcs.items())}\n+        logging.info(f' These (id,new_source_value) -> {to_update}, will be updated in the {translation_file} ')\n+        update_trans_units(translation_body_element, trans_trans_units, to_update)\n+    else:\n+        logging.info(\"Something went wrong, this should not have happend!\")\n+\n+\n+    #xml_tree_translation.write(translation, encoding='utf-8', xml_declaration=True)", "originalCommit": "ab049c99da4a96e073cd91d8be71324841b259a4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzU4NDA4MA==", "url": "https://github.com/uyuni-project/uyuni/pull/2525#discussion_r483584080", "bodyText": "Also make sure to remove unneeded comments", "author": "parlt91", "createdAt": "2020-09-04T12:28:18Z", "path": "scripts/translation/xliffmerger.py", "diffHunk": "@@ -0,0 +1,122 @@\n+#!/usr/bin/python\n+import xml.etree.ElementTree as ET\n+import os\n+import logging\n+import argparse\n+argparser = argparse.ArgumentParser()\n+argparser.add_argument(\"path\", help=\"Path to look into for translation files!\")\n+args = parser.parse_args()\n+\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+class CommentedTreeBuilder(ET.TreeBuilder):\n+    def comment(self, data):\n+        self.start(ET.Comment, {})\n+        self.data(data)\n+        self.end(ET.Comment)\n+\n+\n+def delete_trans_units(body_element, trans_units, units_to_remove):\n+    to_delete = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_remove]\n+    for item in to_delete:\n+        body_element.remove(item)\n+\n+\n+def add_trans_units(body_element, trans_units, units_to_add):\n+    to_add = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in units_to_add]\n+    for item in to_add:\n+        target_element = ET.Element('target', {'state': 'new'})\n+        target_element.tail = \"\\n  \"\n+        item.append(target_element)\n+        body_element.append(item)\n+\n+\n+def update_trans_units(body_element, trans_units, id_new_value_dict):\n+    to_update = [tr_unit for tr_unit in trans_units if tr_unit.attrib['id'] in id_new_value_dict]\n+    for trans_unit in to_update:\n+        source_element = trans_unit.find('d:source', ns)\n+        source_element.text = id_new_value_dict[trans_unit.attrib['id']]\n+        target_element = trans_unit.find('d:target', ns)\n+        if target_element is None:\n+            target_element = ET.Element('target', {'state': 'needs-adaptation'})\n+            target_element.tail = \"\\n      \"\n+            trans_unit.append(target_element)\n+        else:\n+            target_element.set('state', 'needs-adaptation')\n+\n+\n+def process(original_file, translation_file):\n+    parser = ET.XMLParser(target=CommentedTreeBuilder())\n+    xml_tree_original = ET.parse(original_file, parser=parser)\n+    xml_tree_translation = ET.parse(translation_file, parser=parser)\n+    original_body_element, orig_trans_units = get_trans_units(xml_tree_original)\n+    translation_body_element, trans_trans_units = get_trans_units(xml_tree_translation)\n+    logging.debug(f'{len(orig_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(trans_trans_units)} trans_units in translation file {translation_file}')\n+\n+    org_trans_units_ids = [tr_unit.attrib['id'] for tr_unit in orig_trans_units]\n+    trans_units_ids = [tr_unit.attrib['id'] for tr_unit in trans_trans_units]\n+    logging.debug(f'{org_trans_units_ids} trans_units IDs in original file {original_file}')\n+    logging.debug(f'{trans_units_ids} trans_units in Ids translation file {translation_file}')\n+\n+    # Delete the ones which are in translation file but not in original\n+    logging.info(\"########## DELETING ORPHAN TRANS_UNITS ##########\")\n+    to_remove = set(trans_units_ids).difference(set(org_trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_remove}, will be deleted from the {translation_file}')\n+    delete_trans_units(translation_body_element, trans_trans_units, to_remove)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Add the ones which are not in translation file but exist in original\n+    logging.info(\"########## ADDING MISSING TRANS_UNITS ##########\")\n+    to_add = set(org_trans_units_ids).difference(set(trans_units_ids))\n+    logging.info(f'Trans-units with these Ids : {to_add}, will be added to the {translation_file}')\n+    add_trans_units(translation_body_element, orig_trans_units, to_add)\n+    logging.info(\"-------------------------------------------------\\n\")\n+\n+    # Update() those trans_units where source has been changed but id remained same. We will be updating source text and\n+    # add the 'needs-adaptation' state attribute\n+    logging.info(\"########## UPDATE THE CHANGED TRANS_UNITS ##########\")\n+    # Get again so we get the updated list after deletion/addition\n+    trans_trans_units = list(translation_body_element.findall('d:trans-unit', ns))\n+\n+    logging.debug(f'{len(orig_trans_units)} trans_units in original file {original_file}')\n+    logging.debug(f'{len(trans_trans_units)} trans_units in original file {original_file}')\n+    if len(trans_trans_units) == len(orig_trans_units):\n+        trans_units_srcs = {tr_unit.attrib['id']: tr_unit.find('d:source', ns).text for tr_unit in trans_trans_units}\n+        org_trans_units_srcs = {tr_unit.attrib['id']: tr_unit.find('d:source', ns).text for tr_unit in orig_trans_units}\n+        to_update = {k: org_trans_units_srcs[k] for k, _ in\n+                     set(org_trans_units_srcs.items()) - set(trans_units_srcs.items())}\n+        logging.info(f' These (id,new_source_value) -> {to_update}, will be updated in the {translation_file} ')\n+        update_trans_units(translation_body_element, trans_trans_units, to_update)\n+    else:\n+        logging.info(\"Something went wrong, this should not have happend!\")\n+\n+\n+    #xml_tree_translation.write(translation, encoding='utf-8', xml_declaration=True)\n+\n+\n+def get_trans_units(xml_tree):\n+    root_node = xml_tree.getroot()\n+    # file_tag = root_node[0]\n+    file_tag = root_node.find('d:file', ns)\n+    # body_element = root_node[0][0]", "originalCommit": "ab049c99da4a96e073cd91d8be71324841b259a4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0abe1e0b12eda8bfdc5b8f79306592a433124dca", "url": "https://github.com/uyuni-project/uyuni/commit/0abe1e0b12eda8bfdc5b8f79306592a433124dca", "message": "suggested fixes", "committedDate": "2020-09-07T10:06:57Z", "type": "commit"}]}