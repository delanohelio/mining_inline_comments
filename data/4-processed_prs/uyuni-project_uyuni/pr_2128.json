{"pr_number": 2128, "pr_title": "Cluster Awareness: Introduce generic SLS files for Cluster Management and CaaSP Cluster Provider custom Salt module.", "pr_createdAt": "2020-04-16T15:29:06Z", "pr_url": "https://github.com/uyuni-project/uyuni/pull/2128", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY1NTYxMA==", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r409655610", "bodyText": "Please start all our ids with mgr_ and use also a unique name.\nIf somebody call addnode and removenode in one state.apply it will fail.\nI think it is better to use always unique ids.", "author": "mcalmer", "createdAt": "2020-04-16T15:38:36Z", "path": "susemanager-utils/susemanager-sls/salt/clusters/addnode.sls", "diffHunk": "@@ -0,0 +1,24 @@\n+{%- if pillar.get('ssh_auth_sock', False) %}\n+ssh_agent_socket:", "originalCommit": "598fcc0bd066618341892dd7b6c71f12bab495ee", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "86425eac9dad7afb7dd584f88dc84069d65e36e0", "url": "https://github.com/uyuni-project/uyuni/commit/86425eac9dad7afb7dd584f88dc84069d65e36e0", "message": "Add mgrclusters meta custom module for Salt", "committedDate": "2020-04-17T10:53:28Z", "type": "commit"}, {"oid": "53f1d770419aeac9dc5ff387d676cde20c31ffeb", "url": "https://github.com/uyuni-project/uyuni/commit/53f1d770419aeac9dc5ff387d676cde20c31ffeb", "message": "Add CaaSP Cluster Provider Management module for Salt", "committedDate": "2020-04-17T10:53:36Z", "type": "commit"}, {"oid": "04da7e85aa3fa1042c928ed32fc28c4ec350d6dd", "url": "https://github.com/uyuni-project/uyuni/commit/04da7e85aa3fa1042c928ed32fc28c4ec350d6dd", "message": "Add initial SLS states files for managing clusters", "committedDate": "2020-04-17T10:53:36Z", "type": "commit"}, {"oid": "666f4b8a4f31c3365f4d81ed3c8a89fcac3acd4e", "url": "https://github.com/uyuni-project/uyuni/commit/666f4b8a4f31c3365f4d81ed3c8a89fcac3acd4e", "message": "Change format for custom Salt 'caasp.list_nodes' output", "committedDate": "2020-04-17T10:53:36Z", "type": "commit"}, {"oid": "65cb3390bcc4d71eeeff27db394e875d8e897161", "url": "https://github.com/uyuni-project/uyuni/commit/65cb3390bcc4d71eeeff27db394e875d8e897161", "message": "Sanizite values returned by skuba CLI", "committedDate": "2020-04-17T10:53:37Z", "type": "commit"}, {"oid": "16a9f1677b4ecadc487c925ab24f6f6e3c0cc5c9", "url": "https://github.com/uyuni-project/uyuni/commit/16a9f1677b4ecadc487c925ab24f6f6e3c0cc5c9", "message": "Implement 'upgrade_cluster' method on CaaSP cluster manager", "committedDate": "2020-04-17T10:53:37Z", "type": "commit"}, {"oid": "211fc52c83781efed37a0cbb09fc6d2ef1dea242", "url": "https://github.com/uyuni-project/uyuni/commit/211fc52c83781efed37a0cbb09fc6d2ef1dea242", "message": "Set default timeout to 20 minutes for Skuba commands", "committedDate": "2020-04-17T10:53:37Z", "type": "commit"}, {"oid": "295ef14fefdb8eaff4108b9eb31357d858fabe18", "url": "https://github.com/uyuni-project/uyuni/commit/295ef14fefdb8eaff4108b9eb31357d858fabe18", "message": "Add SLS file for clusters.createcluster state", "committedDate": "2020-04-17T10:53:37Z", "type": "commit"}, {"oid": "4aba93a5152a0860880d98708d1a2fbfebcbc9fb", "url": "https://github.com/uyuni-project/uyuni/commit/4aba93a5152a0860880d98708d1a2fbfebcbc9fb", "message": "Set SSH_AUTH_SOCK env if available for clusters SLS states", "committedDate": "2020-04-17T10:53:38Z", "type": "commit"}, {"oid": "9e898f9fdedd58a08616be6e1b92b4d898e525e6", "url": "https://github.com/uyuni-project/uyuni/commit/9e898f9fdedd58a08616be6e1b92b4d898e525e6", "message": "Take care of <none> values on skuba output", "committedDate": "2020-04-17T10:53:38Z", "type": "commit"}, {"oid": "aeec39cd29ffafc831973bc5f4796e4daca6da0d", "url": "https://github.com/uyuni-project/uyuni/commit/aeec39cd29ffafc831973bc5f4796e4daca6da0d", "message": "Implement cluster creation methods for CaaSP cluster", "committedDate": "2020-04-17T10:53:39Z", "type": "commit"}, {"oid": "e2c5951c55fd1fb06bb19955aa20b726820910e2", "url": "https://github.com/uyuni-project/uyuni/commit/e2c5951c55fd1fb06bb19955aa20b726820910e2", "message": "Add gateway for mgrclusters.create_cluster module", "committedDate": "2020-04-17T10:53:40Z", "type": "commit"}, {"oid": "520343dfdf580204a9dfcb789dc1f9483fa59d27", "url": "https://github.com/uyuni-project/uyuni/commit/520343dfdf580204a9dfcb789dc1f9483fa59d27", "message": "Fix salt.utils.path.which import in 2016.11 codebase", "committedDate": "2020-04-17T10:53:40Z", "type": "commit"}, {"oid": "c8dcdba55c9457c60434d71f07bb7bc33a8ea37a", "url": "https://github.com/uyuni-project/uyuni/commit/c8dcdba55c9457c60434d71f07bb7bc33a8ea37a", "message": "Add comments and fix identation", "committedDate": "2020-04-17T10:53:40Z", "type": "commit"}, {"oid": "5e0a311acad93d91d8e372096c5348d451176769", "url": "https://github.com/uyuni-project/uyuni/commit/5e0a311acad93d91d8e372096c5348d451176769", "message": "Introduce 'upgrade_node' and optional parameters", "committedDate": "2020-04-17T10:53:40Z", "type": "commit"}, {"oid": "a3f1625f397140b0813bee4b4d08a2529166f40a", "url": "https://github.com/uyuni-project/uyuni/commit/a3f1625f397140b0813bee4b4d08a2529166f40a", "message": "Cosmetic changes at method signature", "committedDate": "2020-04-17T10:53:41Z", "type": "commit"}, {"oid": "803160f67890bde1697fc2628124979fe9dcc42c", "url": "https://github.com/uyuni-project/uyuni/commit/803160f67890bde1697fc2628124979fe9dcc42c", "message": "Fix upgrade_cluster skuba commands args", "committedDate": "2020-04-17T10:53:41Z", "type": "commit"}, {"oid": "364fe59e2db9b6109860afba822fed7daf95557f", "url": "https://github.com/uyuni-project/uyuni/commit/364fe59e2db9b6109860afba822fed7daf95557f", "message": "Add 'mgrclusters' and 'mgr_caasp_manager' Salt modules to spec file", "committedDate": "2020-04-17T10:53:41Z", "type": "commit"}, {"oid": "290f9a29bdc8007a66e21285ad6c842883a232e0", "url": "https://github.com/uyuni-project/uyuni/commit/290f9a29bdc8007a66e21285ad6c842883a232e0", "message": "Update changelog for susemanager-sls", "committedDate": "2020-04-17T10:54:03Z", "type": "commit"}, {"oid": "8e80e4aa78687a1b1aef85eafec815a37e1385e4", "url": "https://github.com/uyuni-project/uyuni/commit/8e80e4aa78687a1b1aef85eafec815a37e1385e4", "message": "Make clusters SLS files to require util.syncmodules", "committedDate": "2020-04-17T10:54:03Z", "type": "commit"}, {"oid": "5120f3176a843dfbef9d643b386d9a7f00c52345", "url": "https://github.com/uyuni-project/uyuni/commit/5120f3176a843dfbef9d643b386d9a7f00c52345", "message": "Pass 'cloud_provider' and 'strict_capability_defaults' to cluster_init", "committedDate": "2020-04-17T10:54:03Z", "type": "commit"}, {"oid": "a82810b2e078264a9bb4518412777ea4d4fe22a0", "url": "https://github.com/uyuni-project/uyuni/commit/a82810b2e078264a9bb4518412777ea4d4fe22a0", "message": "Use unique state ids between different clusters states", "committedDate": "2020-04-17T10:54:03Z", "type": "commit"}, {"oid": "14c785fa105894990f9fc9e00d70b15a3b093b7a", "url": "https://github.com/uyuni-project/uyuni/commit/14c785fa105894990f9fc9e00d70b15a3b093b7a", "message": "Add missing upgradecluster.sls file", "committedDate": "2020-04-17T10:54:04Z", "type": "commit"}, {"oid": "14c785fa105894990f9fc9e00d70b15a3b093b7a", "url": "https://github.com/uyuni-project/uyuni/commit/14c785fa105894990f9fc9e00d70b15a3b093b7a", "message": "Add missing upgradecluster.sls file", "committedDate": "2020-04-17T10:54:04Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDE0OTY3NQ==", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r410149675", "bodyText": "For consistency maybe this parameter should be called skuba_cluster_path.", "author": "mateiw", "createdAt": "2020-04-17T10:58:53Z", "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "diffHunk": "@@ -0,0 +1,347 @@\n+# -*- coding: utf-8 -*-\n+'''\n+SUSE Manager CaaSP Cluster Manager module for Salt\n+\n+'''\n+from __future__ import absolute_import\n+\n+\n+import logging\n+import os\n+import subprocess\n+\n+import salt.utils.stringutils\n+import salt.utils.timed_subprocess\n+\n+try:\n+    from salt.utils.path import which\n+except ImportError:\n+    from salt.utils import which\n+\n+from salt.utils.dictupdate import merge_list\n+from salt.exceptions import CommandExecutionError\n+\n+\n+log = logging.getLogger(__name__)\n+\n+__virtualname__ = 'caasp'\n+\n+DEFAULT_TIMEOUT = 1200\n+\n+\n+def __virtual__():\n+    '''\n+    This module is always enabled while 'skuba' CLI tools is available.\n+    '''\n+    return __virtualname__ if which('skuba') else (False, 'skuba is not available')\n+\n+\n+def _call_skuba(skuba_cluster_path,\n+                cmd_args,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    log.debug(\"Calling Skuba CLI: 'skuba {}' - Timeout: {}\".format(cmd_args, timeout))\n+    try:\n+        skuba_proc = salt.utils.timed_subprocess.TimedProc(\n+            [\"skuba\"] + cmd_args.split(),\n+            stdout=subprocess.PIPE,\n+            stderr=subprocess.PIPE,\n+            timeout=timeout,\n+            cwd=skuba_cluster_path,\n+        )\n+        skuba_proc.run()\n+        return skuba_proc\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while calling skuba: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+\n+def _sanitize_skuba_output_values(items):\n+    ret = []\n+    for i in items:\n+        if i.lower() == 'no':\n+            ret.append(False)\n+        elif i.lower() == 'yes':\n+            ret.append(True)\n+        elif i.lower() == '<none>':\n+            ret.append(None)\n+        else:\n+            ret.append(i)\n+    return ret\n+\n+\n+def list_nodes(skuba_cluster_path,\n+               timeout=DEFAULT_TIMEOUT,\n+               **kwargs):\n+    skuba_proc = _call_skuba(skuba_cluster_path, \"cluster status\")\n+    if skuba_proc.process.returncode != 0 or skuba_proc.stderr:\n+        error_msg = \"Unexpected error {} at skuba when listing nodes: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+    skuba_proc_lines = salt.utils.stringutils.to_str(skuba_proc.stdout).splitlines()\n+\n+    ret = {}\n+    try:\n+        # The first line of skuba output are the headers\n+        headers = [x.strip().lower() for x in skuba_proc_lines[0].split('  ') if x]\n+        name_idx = headers.index('name')\n+        headers.remove('name')\n+        for line in skuba_proc_lines[1:]:\n+            items = [x.strip() for x in line.split('  ') if x]\n+            node_name = items.pop(name_idx)\n+            node_zip = zip(headers, _sanitize_skuba_output_values(items))\n+            ret[node_name] = dict(node_zip)\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while parsing skuba output: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+    return ret\n+\n+\n+def remove_node(skuba_cluster_path,\n+                node_name,\n+                drain_timeout=None,\n+                verbosity=None,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    cmd_args = \"node remove {}\".format(node_name)\n+\n+    if drain_timeout:\n+        cmd_args += \" --drain-timeout {}\".format(drain_timeout)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when removing a node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def add_node(skuba_cluster_path,\n+             node_name,\n+             role,\n+             target,\n+             ignore_preflight_errors=None,\n+             port=None,\n+             sudo=None,\n+             user=None,\n+             verbosity=None,\n+             timeout=DEFAULT_TIMEOUT,\n+             **kwargs):\n+\n+    cmd_args = \"node join --role {} --target {} {}\".format(role, target, node_name)\n+\n+    if ignore_preflight_errors:\n+        cmd_args += \" --ignore-preflight-errors {}\".format(ignore_preflight_errors)\n+    if port:\n+        cmd_args += \" --port {}\".format(port)\n+    if sudo:\n+        cmd_args += \" --sudo\"\n+    if user:\n+        cmd_args += \" --user {}\".format(user)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when adding a new node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def upgrade_cluster(skuba_cluster_path,\n+                    verbosity=None,\n+                    timeout=DEFAULT_TIMEOUT,\n+                    **kwargs):\n+\n+    cmd_args = \"cluster upgrade plan\"\n+\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when upgrading the cluster: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def upgrade_node(skuba_cluster_path,\n+                 verbosity=None,\n+                 timeout=DEFAULT_TIMEOUT,\n+                 plan=False,\n+                 **kwargs):\n+\n+    cmd_args = \"node upgrade {}\".format(\"plan\" if plan else \"apply\")\n+\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when upgrading the node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def cluster_init(name,\n+                 cluster_path,\n+                 target,\n+                 cloud_provider=None,\n+                 strict_capability_defaults=False,\n+                 verbosity=None,\n+                 timeout=DEFAULT_TIMEOUT,\n+                 **kwargs):\n+\n+    cmd_args = \"cluster init --control-plane {} {}\".format(target, name)\n+\n+    if cloud_provider:\n+        cmd_args += \" --cloud-provider {}\".format(cloud_provider)\n+    if strict_capability_defaults:\n+        cmd_args += \" --strict-capability-defaults\"\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when initializing the cluster: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def master_bootstrap(node_name,\n+                     skuba_cluster_path,\n+                     target,\n+                     ignore_preflight_errors=None,\n+                     port=None,\n+                     sudo=None,\n+                     user=None,\n+                     verbosity=None,\n+                     timeout=DEFAULT_TIMEOUT,\n+                     **kwargs):\n+\n+    cmd_args = \"node bootstrap --target {} {}\".format(target, node_name)\n+\n+    if ignore_preflight_errors:\n+        cmd_args += \" --ignore-preflight-errors {}\".format(ignore_preflight_errors)\n+    if port:\n+        cmd_args += \" --port {}\".format(port)\n+    if sudo:\n+        cmd_args += \" --sudo\"\n+    if user:\n+        cmd_args += \" --user {}\".format(user)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when bootstrapping the node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def create_cluster(cluster_name,\n+                   cluster_path,", "originalCommit": "c05c42779a492d7cab84333c867efc6229a9b26c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDE1NTQ5OA==", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r410155498", "bodyText": "@mateiw actually those two parameters are not representing the same:\n\ncluster_path would be something like /srv/my-clusters/. The path where the cluster directory will be created.\nskuba_cluster_path is where your particular cluster is stored: i.a. /srv/my-clusters/my-first-cluster/\n\nSince they sound similar, maybe I should change cluster_path to something else more descriptive to avoid the confusion. I'll go maybe with base_path", "author": "meaksh", "createdAt": "2020-04-17T11:12:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDE0OTY3NQ=="}], "type": "inlineReview"}, {"oid": "711e983f49d7dab6b5451c5a9b155ae1295295cf", "url": "https://github.com/uyuni-project/uyuni/commit/711e983f49d7dab6b5451c5a9b155ae1295295cf", "message": "Rename some parameters to have better consistency", "committedDate": "2020-04-17T11:19:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMwNzc2MA==", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r410307760", "bodyText": "@ereslibre : this is the core of what we would be using to call skuba via Salt.\nWould you please review it if it makes sense from the skuba standpoint?", "author": "mbologna", "createdAt": "2020-04-17T15:43:36Z", "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "diffHunk": "@@ -0,0 +1,347 @@\n+# -*- coding: utf-8 -*-", "originalCommit": "711e983f49d7dab6b5451c5a9b155ae1295295cf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMwOTExNA==", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r410309114", "bodyText": "I assume that if a specific type of cluster does not offer the init workflow, we can skip the initialization and jump directly to other operations, correct?", "author": "mbologna", "createdAt": "2020-04-17T15:45:48Z", "path": "susemanager-utils/susemanager-sls/salt/clusters/createcluster.sls", "diffHunk": "@@ -0,0 +1,24 @@\n+{%- if pillar.get('ssh_auth_sock', False) %}\n+mgr_ssh_agent_socket_clusters_createcluster:\n+  environ.setenv:\n+    - name: SSH_AUTH_SOCK\n+    - value: {{ pillar['ssh_auth_sock'] }}\n+{%- endif %}\n+\n+mgr_cluster_create_cluster:", "originalCommit": "711e983f49d7dab6b5451c5a9b155ae1295295cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMyNTI1MA==", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r410325250", "bodyText": "That's correct. Or, even in the case of CaaSP, if the cluster has been already created, we can directly operate it with i.a. clusters.addnode.", "author": "meaksh", "createdAt": "2020-04-17T16:12:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMwOTExNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMxNjM5NA==", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r410316394", "bodyText": "I think timeout  timeout should be passed as arg to every call to _call_skuba, am I assuming correctly?", "author": "mbologna", "createdAt": "2020-04-17T15:57:17Z", "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "diffHunk": "@@ -0,0 +1,347 @@\n+# -*- coding: utf-8 -*-\n+'''\n+SUSE Manager CaaSP Cluster Manager module for Salt\n+\n+'''\n+from __future__ import absolute_import\n+\n+\n+import logging\n+import os\n+import subprocess\n+\n+import salt.utils.stringutils\n+import salt.utils.timed_subprocess\n+\n+try:\n+    from salt.utils.path import which\n+except ImportError:\n+    from salt.utils import which\n+\n+from salt.utils.dictupdate import merge_list\n+from salt.exceptions import CommandExecutionError\n+\n+\n+log = logging.getLogger(__name__)\n+\n+__virtualname__ = 'caasp'\n+\n+DEFAULT_TIMEOUT = 1200\n+\n+\n+def __virtual__():\n+    '''\n+    This module is always enabled while 'skuba' CLI tools is available.\n+    '''\n+    return __virtualname__ if which('skuba') else (False, 'skuba is not available')\n+\n+\n+def _call_skuba(skuba_cluster_path,\n+                cmd_args,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    log.debug(\"Calling Skuba CLI: 'skuba {}' - Timeout: {}\".format(cmd_args, timeout))\n+    try:\n+        skuba_proc = salt.utils.timed_subprocess.TimedProc(\n+            [\"skuba\"] + cmd_args.split(),\n+            stdout=subprocess.PIPE,\n+            stderr=subprocess.PIPE,\n+            timeout=timeout,\n+            cwd=skuba_cluster_path,\n+        )\n+        skuba_proc.run()\n+        return skuba_proc\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while calling skuba: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+\n+def _sanitize_skuba_output_values(items):\n+    ret = []\n+    for i in items:\n+        if i.lower() == 'no':\n+            ret.append(False)\n+        elif i.lower() == 'yes':\n+            ret.append(True)\n+        elif i.lower() == '<none>':\n+            ret.append(None)\n+        else:\n+            ret.append(i)\n+    return ret\n+\n+\n+def list_nodes(skuba_cluster_path,\n+               timeout=DEFAULT_TIMEOUT,\n+               **kwargs):\n+    skuba_proc = _call_skuba(skuba_cluster_path, \"cluster status\")", "originalCommit": "711e983f49d7dab6b5451c5a9b155ae1295295cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMyNTU1OA==", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r410325558", "bodyText": "You're correct. Good catch! I've missed that :)", "author": "meaksh", "createdAt": "2020-04-17T16:12:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDMxNjM5NA=="}], "type": "inlineReview"}, {"oid": "752181d41f679c1d4d85fe3e1ab7243c1e27db1f", "url": "https://github.com/uyuni-project/uyuni/commit/752181d41f679c1d4d85fe3e1ab7243c1e27db1f", "message": "Pass custom timeout value to _skuba_call method", "committedDate": "2020-04-17T16:15:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDM2ODE0Ng==", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r414368146", "bodyText": "Just a comment for the near future (non-blocking). When performing upgrades there are different stages when it comes to upgrading addons and nodes, so in general:\n\nUpgrade addons to the latest version of the current platform version (skuba addon upgrade plan/apply)\nUpgrade all nodes normally (skuba node upgrade plan/apply)\nUpgrade addons to the new version of the platform (skuba addon upgrade plan/apply)\n\n1. and 3. are not always required (depends on what changes on each release), but can always be run to ensure the most constraining scenario.", "author": "ereslibre", "createdAt": "2020-04-24T07:47:54Z", "path": "susemanager-utils/susemanager-sls/src/modules/mgr_caasp_manager.py", "diffHunk": "@@ -0,0 +1,347 @@\n+# -*- coding: utf-8 -*-\n+'''\n+SUSE Manager CaaSP Cluster Manager module for Salt\n+\n+'''\n+from __future__ import absolute_import\n+\n+\n+import logging\n+import os\n+import subprocess\n+\n+import salt.utils.stringutils\n+import salt.utils.timed_subprocess\n+\n+try:\n+    from salt.utils.path import which\n+except ImportError:\n+    from salt.utils import which\n+\n+from salt.utils.dictupdate import merge_list\n+from salt.exceptions import CommandExecutionError\n+\n+\n+log = logging.getLogger(__name__)\n+\n+__virtualname__ = 'caasp'\n+\n+DEFAULT_TIMEOUT = 1200\n+\n+\n+def __virtual__():\n+    '''\n+    This module is always enabled while 'skuba' CLI tools is available.\n+    '''\n+    return __virtualname__ if which('skuba') else (False, 'skuba is not available')\n+\n+\n+def _call_skuba(skuba_cluster_path,\n+                cmd_args,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    log.debug(\"Calling Skuba CLI: 'skuba {}' - Timeout: {}\".format(cmd_args, timeout))\n+    try:\n+        skuba_proc = salt.utils.timed_subprocess.TimedProc(\n+            [\"skuba\"] + cmd_args.split(),\n+            stdout=subprocess.PIPE,\n+            stderr=subprocess.PIPE,\n+            timeout=timeout,\n+            cwd=skuba_cluster_path,\n+        )\n+        skuba_proc.run()\n+        return skuba_proc\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while calling skuba: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+\n+def _sanitize_skuba_output_values(items):\n+    ret = []\n+    for i in items:\n+        if i.lower() == 'no':\n+            ret.append(False)\n+        elif i.lower() == 'yes':\n+            ret.append(True)\n+        elif i.lower() == '<none>':\n+            ret.append(None)\n+        else:\n+            ret.append(i)\n+    return ret\n+\n+\n+def list_nodes(skuba_cluster_path,\n+               timeout=DEFAULT_TIMEOUT,\n+               **kwargs):\n+    skuba_proc = _call_skuba(skuba_cluster_path, \"cluster status\", timeout=timeout)\n+    if skuba_proc.process.returncode != 0 or skuba_proc.stderr:\n+        error_msg = \"Unexpected error {} at skuba when listing nodes: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+    skuba_proc_lines = salt.utils.stringutils.to_str(skuba_proc.stdout).splitlines()\n+\n+    ret = {}\n+    try:\n+        # The first line of skuba output are the headers\n+        headers = [x.strip().lower() for x in skuba_proc_lines[0].split('  ') if x]\n+        name_idx = headers.index('name')\n+        headers.remove('name')\n+        for line in skuba_proc_lines[1:]:\n+            items = [x.strip() for x in line.split('  ') if x]\n+            node_name = items.pop(name_idx)\n+            node_zip = zip(headers, _sanitize_skuba_output_values(items))\n+            ret[node_name] = dict(node_zip)\n+    except Exception as exc:\n+        error_msg = \"Unexpected error while parsing skuba output: {}\".format(exc)\n+        log.error(error_msg)\n+        raise CommandExecutionError(error_msg)\n+\n+    return ret\n+\n+\n+def remove_node(skuba_cluster_path,\n+                node_name,\n+                drain_timeout=None,\n+                verbosity=None,\n+                timeout=DEFAULT_TIMEOUT,\n+                **kwargs):\n+\n+    cmd_args = \"node remove {}\".format(node_name)\n+\n+    if drain_timeout:\n+        cmd_args += \" --drain-timeout {}\".format(drain_timeout)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args, timeout=timeout)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when removing a node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def add_node(skuba_cluster_path,\n+             node_name,\n+             role,\n+             target,\n+             ignore_preflight_errors=None,\n+             port=None,\n+             sudo=None,\n+             user=None,\n+             verbosity=None,\n+             timeout=DEFAULT_TIMEOUT,\n+             **kwargs):\n+\n+    cmd_args = \"node join --role {} --target {} {}\".format(role, target, node_name)\n+\n+    if ignore_preflight_errors:\n+        cmd_args += \" --ignore-preflight-errors {}\".format(ignore_preflight_errors)\n+    if port:\n+        cmd_args += \" --port {}\".format(port)\n+    if sudo:\n+        cmd_args += \" --sudo\"\n+    if user:\n+        cmd_args += \" --user {}\".format(user)\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args, timeout=timeout)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when adding a new node: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def upgrade_cluster(skuba_cluster_path,\n+                    verbosity=None,\n+                    timeout=DEFAULT_TIMEOUT,\n+                    **kwargs):\n+\n+    cmd_args = \"cluster upgrade plan\"\n+\n+    if verbosity:\n+        cmd_args += \" --verbosity {}\".format(verbosity)\n+\n+    skuba_proc = _call_skuba(skuba_cluster_path, cmd_args, timeout=timeout)\n+    if skuba_proc.process.returncode != 0:\n+        error_msg = \"Unexpected error {} at skuba when upgrading the cluster: {}\".format(\n+                skuba_proc.process.returncode,\n+                salt.utils.stringutils.to_str(skuba_proc.stderr))\n+        log.error(error_msg)\n+\n+    ret = {\n+        'stdout': salt.utils.stringutils.to_str(skuba_proc.stdout),\n+        'stderr': salt.utils.stringutils.to_str(skuba_proc.stderr),\n+        'success': not skuba_proc.process.returncode,\n+        'retcode': skuba_proc.process.returncode,\n+    }\n+    return ret\n+\n+\n+def upgrade_node(skuba_cluster_path,\n+                 verbosity=None,\n+                 timeout=DEFAULT_TIMEOUT,\n+                 plan=False,\n+                 **kwargs):\n+\n+    cmd_args = \"node upgrade {}\".format(\"plan\" if plan else \"apply\")", "originalCommit": "752181d41f679c1d4d85fe3e1ab7243c1e27db1f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTY5MDg1MA==", "url": "https://github.com/uyuni-project/uyuni/pull/2128#discussion_r415690850", "bodyText": "@ereslibre thanks for clarifying the upgrade stages! I'll be pushing those missing methods on the next round of PR. \ud83d\udc4d", "author": "meaksh", "createdAt": "2020-04-27T10:20:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDM2ODE0Ng=="}], "type": "inlineReview"}]}