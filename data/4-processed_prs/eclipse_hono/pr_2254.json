{"pr_number": 2254, "pr_title": "[#8] Add specifications for the Kafka-based Telemetry API and Event API.", "pr_createdAt": "2020-10-16T12:24:56Z", "pr_url": "https://github.com/eclipse/hono/pull/2254", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507535398", "bodyText": "is there a particular problem with sticking to using / as the path segment delimiter?", "author": "sophokles73", "createdAt": "2020-10-19T07:41:48Z", "path": "site/documentation/content/api/event/index.md", "diffHunk": "@@ -130,3 +132,88 @@ The example below might be used by the MQTT adapter to indicate that a connectio\n   }\n }\n ~~~\n+\n+\n+## Event API for Kafka\n+\n+Hono can alternatively be configured to publish event messages to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Event API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send event messages received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Event\n+\n+The protocol adapter writes messages to the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload event messages for.", "originalCommit": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY1NDEzOA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507654138", "bodyText": "The / is not allowed in Kafka topic names. The only valid non-alphanumerical characters are ., _, and -. Underscore and period could collide in metric systems, so I decided to use the safe character.", "author": "b-abel", "createdAt": "2020-10-19T10:54:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY1NjA0NA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507656044", "bodyText": "Tenant IDs that are based on UUIDs will contain several - characters. Will this be a problem, e.g. with distinguishing topic names?", "author": "sophokles73", "createdAt": "2020-10-19T10:57:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY2NjkzOA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507666938", "bodyText": "If we strictly adhere to the schema that a topic starts with the prefix consisting of endpoint and - we can always only consider the first -. The other two characters are also not prohibited in tenant names, right?", "author": "b-abel", "createdAt": "2020-10-19T11:18:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY4NzQ0NA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507687444", "bodyText": "no, they are not. But in the default configuration the tenant ID pattern excludes / ...\nAs long as the topic names consist of two segments only, we might get away with considering the first - as the delimiter. However, with the C&C discussions going on, I am not sure if we can safely assume that it will always only be two segments ...\nIt would be safer to come up with another idea, e.g. URI escaping the - in path segments or something like that.", "author": "sophokles73", "createdAt": "2020-10-19T11:57:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDMwNjMyNQ==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r514306325", "bodyText": "Before having the problem of topic names with more than two elements, we have the even more pressing issue here that tenant IDs may contain characters that are not allowed and prevent the topic to be created in the first place.\nURI-encoding does not work because the % character is not allowed in topic names. To solve this we could invent our own encoding logic. I am hesitating to do this because backend applications would be required to do this as well, which might be error-prone.\nA second option is to restrict tenant names (I would suggest to the characters used in UUIDs). Even if we don't want to change the pattern that validates tenant IDs with a minor version of Hono, it could be documented that using Kafka requires migrating tenant IDs to this restricted character set (plus starting, to create only safe tenant IDs in our device registry code).\nA third option would be to not use the tenant ID in the topic name, but a new, safe identifier. This could be stored in the tenant configuration. The drawback is that backend applications could no longer derive it from the tenant ID but need somehow to get the topic name.", "author": "b-abel", "createdAt": "2020-10-29T14:34:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDMxODYyMg==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r514318622", "bodyText": "FMPOV option 2 should be ok as we are not restricting any existing functionality but add new functionality here ...", "author": "sophokles73", "createdAt": "2020-10-29T14:49:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDk2ODY4NQ==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r514968685", "bodyText": "I just had a look at the tenant ID pattern. This is exactly the same character set that Kafka allows for topic names: \n  \n    \n      hono/core/src/main/java/org/eclipse/hono/util/RegistryManagementConstants.java\n    \n    \n         Line 343\n      in\n      41ad9e6\n    \n    \n    \n    \n\n        \n          \n           public static final String DEFAULT_TENANT_ID_PATTERN = \"^[a-zA-Z0-9-_\\\\.]+$\"; \n        \n    \n  \n\n\nSo, we do not have the problem of invalid characters in current tenant IDs.\nWe could continue with the initial approach of static prefixes followed by the tenant ID. From my understanding, even for C&C, there should be no need for topics with more (dynamic) elements.\nAlternatively, if we do not feel safe with this approach, I would deprecate the current pattern and add a new one that does not include the dot ('.'). The dot would then be Hono's the delimiter character for topic names. I would still allow '_' because it is used in \"DEFAULT_TENANT\" which is widely used, even in external resources like blog articles (and of course '-' because of the UUIDs).\n@sophokles73 WDYT?\n@calohmn, do you expect topic names for C&C to contain multiple elements that would require to have a delimiter character?", "author": "b-abel", "createdAt": "2020-10-30T09:29:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE5NTY5MQ==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r515195691", "bodyText": "Concerning C&C, the envisioned approaches only use topics with a fixed prefix followed by the tenant ID or some other ID. So, for these, no delimiter would be needed.", "author": "calohmn", "createdAt": "2020-10-30T15:45:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIyNzAxMg==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r515227012", "bodyText": "My proposal for topic names is:\nhono.${endpoint}.${tenant_id}.\n\nNamespacing (i.e. starting with hono) is a good practice and might come in handy later on (e.g. Kafka supports subscriptions on multiple topics with regular expressions.\nIn contrast to my first proposal, I would not use - as a delimiter to make it more readable with UUIDs as tenant IDs. Since the _ is already contained in the famous \"DEFAULT_TENANT\" and in the endpoint command_response\", the .` is my first choice.\n\n@sophokles73 @calohmn WDYT?", "author": "b-abel", "createdAt": "2020-10-30T16:35:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg4OTkwNA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r515889904", "bodyText": "Based on https://stackoverflow.com/questions/37062904/what-are-apache-kafka-topic-name-limitations it seems that we should use either . or _ but not both. Given that we already have the DEFALUT_TENANT name, it looks like we are advised against using . as well then.\nHow about using __ (two underscores) as the delimiter instead?", "author": "sophokles73", "createdAt": "2020-11-02T10:52:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkwNjk3OQ==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r515906979", "bodyText": "we should use either . or _ but not both\n\nThat is right. The reason is that they could collide in metrics. Therefore the Kafka CLI always prints a warning if you create a topic that contains a  . or a _. In practice, there would be no collision with our naming schema.\n\nHow about using __ (two underscores) as the delimiter instead?\n\nI like the creative thinking here, but the drawback is that two underscores are hard to read. Depending on the font they are displayed as a single long underscore (obviously we need to explain at least here on Github what it is).", "author": "b-abel", "createdAt": "2020-11-02T11:24:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzAxNDg1Ng==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r523014856", "bodyText": "I think it would be good if we could come to a final decision regarding the structure of topic names soon. FMPOV, we can't complete the API specification or implementation before that.\nMy proposal would be the following:\n\nwe start with using topic names with a static prefix and a dynamic second element. Then we do not need a reserved delimiter.\nwe separate the two elements (and possible sub-elements within the prefix) with a defined separator, which is only for human readability and not used as a technical delimiter for parsing the name.\nwe take the '.' as the separator. Although we then have '.' and '_' in topic names, which in principle could lead to name conflicts in Kafka metrics, no conflicts will occur with our structure of the names.\nif we realize at a later time that this naming scheme is no longer sufficient for us, we can still define a technical delimiter. For the TenantIds, '.' is a good choice for the reasons mentioned above, so that we don't have to change the character again. For other dynamic elements, we can't tell which characters they contain without knowing them anyway.\nthe static prefixes are additionally namespaced with hono.\n\nThe result will look like this:\nhono.${endpoint}.${tenant_id}. Or, more concrete: hono.event.${tenant_id}, hono.telemetry.${tenant_id}, hono.command.${tenant_id}, hono.command_response.${tenant_id}.\nWDYT?", "author": "b-abel", "createdAt": "2020-11-13T15:15:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzk2ODMxNg==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r523968316", "bodyText": "Looks ok FMPOV. What is the proposed pattern for tenant identifiers then?", "author": "sophokles73", "createdAt": "2020-11-16T08:30:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDAxNzk3MA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r524017970", "bodyText": "Looks ok FMPOV. What is the proposed pattern for tenant identifiers then?\n\nI think we could leave it as it is for now. If we consider everything after the fixed prefix as identifiers for the client, it doesn't matter what it contains. But if you feel more comfortable if we now deprecate '.' in the tenant identifiers, that's fine with me too.", "author": "b-abel", "createdAt": "2020-11-16T09:25:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTM5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTg5Nw==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507535897", "bodyText": "is broker a common term for referring to Kafka?", "author": "sophokles73", "createdAt": "2020-10-19T07:42:35Z", "path": "site/documentation/content/api/event/index.md", "diffHunk": "@@ -130,3 +132,88 @@ The example below might be used by the MQTT adapter to indicate that a connectio\n   }\n }\n ~~~\n+\n+\n+## Event API for Kafka\n+\n+Hono can alternatively be configured to publish event messages to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Event API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send event messages received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Event\n+\n+The protocol adapter writes messages to the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload event messages for.\n+\n+\n+**Preconditions**\n+\n+1. Either the topic `event-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.", "originalCommit": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY1NDI2Mg==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507654262", "bodyText": "Yes, that's the common term (see e.g. https://kafka.apache.org/documentation/#brokerconfigs).", "author": "b-abel", "createdAt": "2020-10-19T10:54:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzNTg5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzOTUyNg==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507539526", "bodyText": "Maybe we can refer to the Telemetry API for a description of the mentioned params ...", "author": "sophokles73", "createdAt": "2020-10-19T07:48:31Z", "path": "site/documentation/content/api/event/index.md", "diffHunk": "@@ -130,3 +132,88 @@ The example below might be used by the MQTT adapter to indicate that a connectio\n   }\n }\n ~~~\n+\n+\n+## Event API for Kafka\n+\n+Hono can alternatively be configured to publish event messages to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Event API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send event messages received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Event\n+\n+The protocol adapter writes messages to the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload event messages for.\n+\n+\n+**Preconditions**\n+\n+1. Either the topic `event-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to write to the topic.\n+1. The device for which the adapter wants to send event messages has been registered (see [Device Registration API]({{< relref \"/api/device-registration\" >}})).\n+\n+**Message Flow**\n+\n+Hono supports *AT LEAST ONCE* delivery of *Event* messages only. A client therefore MUST set *acks* to `all`. Either MUST *enable.idempotence* be set to `true` OR *max.in.flight.requests.per.connection* MUST be set to `1`.", "originalCommit": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY1NTYxMg==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507655612", "bodyText": "You mean having each configuration property explained in one place and then referencing to this where they are mentioned? I like the idea. But it needs to focus on why and how the property is relevant to Hono, because the Kafka documentation already does a great job in explaining each configuration option: https://kafka.apache.org/documentation/#producerconfigs\nWe need to be careful here, because, in contrast to the AMQP 1.0 specification, Kafka is not a standard and it is constantly evolving.", "author": "b-abel", "createdAt": "2020-10-19T10:57:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzUzOTUyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MDE3NQ==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507540175", "bodyText": "is the exception being thrown after the client has re-tried to send the event to Kafka?", "author": "sophokles73", "createdAt": "2020-10-19T07:49:36Z", "path": "site/documentation/content/api/event/index.md", "diffHunk": "@@ -130,3 +132,88 @@ The example below might be used by the MQTT adapter to indicate that a connectio\n   }\n }\n ~~~\n+\n+\n+## Event API for Kafka\n+\n+Hono can alternatively be configured to publish event messages to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Event API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send event messages received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Event\n+\n+The protocol adapter writes messages to the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload event messages for.\n+\n+\n+**Preconditions**\n+\n+1. Either the topic `event-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to write to the topic.\n+1. The device for which the adapter wants to send event messages has been registered (see [Device Registration API]({{< relref \"/api/device-registration\" >}})).\n+\n+**Message Flow**\n+\n+Hono supports *AT LEAST ONCE* delivery of *Event* messages only. A client therefore MUST set *acks* to `all`. Either MUST *enable.idempotence* be set to `true` OR *max.in.flight.requests.per.connection* MUST be set to `1`.\n+\n+\n+The recommended Kafka producer properties for *Event* messages are: `enable.idempotence=true`, `acks=all`, `max.in.flight.requests.per.connection=5`, leaving *retries* unset (which defaults to `Integer.MAX`), and setting *delivery.timeout.ms* to a reasonable value (supported from Kafka version 1.0.0 on). \n+\n+The following sequence diagram illustrates the flow of messages involved in the *MQTT Adapter* producing an event to the Kafka cluster.\n+\n+{{< figure src=\"produce_kafka.svg\" title=\"Produce event flow\" >}}\n+\n+1. *Device* `4711` publishes an event using MQTT QoS 1.\n+   1. *MQTT Adapter* produces an event message to *Kafka Cluster*.\n+   1. *Kafka cluster* acknowledges reception of the message.\n+   1. *MQTT Adapter* acknowledges the reception of the message to the *Device*.\n+\n+When the Kafka producer receives an exception when sending an event message to Kafka, the protocol adapter MUST NOT try to re-send such rejected messages but MUST indicate the failed transfer to the device if the transport protocol provides means to do so.", "originalCommit": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY1NDUzNQ==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507654535", "bodyText": "Yes. The Kafka client distinguishes different types of errors. For those that are potentially transient, retries are made as configured (you can configure the maximum retry count and/or a timeout, and you can disable retries), for those that are final, it throws an exception immediately.", "author": "b-abel", "createdAt": "2020-10-19T10:55:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MDE3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEyMjYzMA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r515122630", "bodyText": "@b-abel how about using the word \"raises\" or \"throws\" instead of \"receives\"? When I read this, it first appears as if the producer is receiving an exception (in the form of a message) from the Kafka cluster.", "author": "Alfusainey", "createdAt": "2020-10-30T14:05:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MDE3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEyNTUyNw==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r515125527", "bodyText": "maybe also replacing \"when\" with \"while\" since the error is raised during the sending process. Also, how about replacing \"the\" with \"a\" since you are referring to any Kafka producer and not a specific one.. e.g When *a* Kafka producer *raises* an exception *while* sending an event message to Kafka...", "author": "Alfusainey", "createdAt": "2020-10-30T14:09:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MDE3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIzMjc1Mg==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r515232752", "bodyText": "@Alfusainey You are right, this is poorly formulated. I will have a look at this next week.", "author": "b-abel", "createdAt": "2020-10-30T16:44:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MDE3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkzNjM3OA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r515936378", "bodyText": "@Alfusainey Thank you for your great suggestion. I applied it.", "author": "b-abel", "createdAt": "2020-11-02T12:25:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MDE3NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkzNjUyMA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r515936520", "bodyText": "The current specification of the Telemetry API says:\n\nWhen the AMQP Messaging Network fails to settle the transfer of a telemetry message or settles the transfer with any other outcome than accepted, the protocol adapter MUST NOT try to re-send such rejected messages but SHOULD indicate the failed transfer to the device if the transport protocol provides means to do so.\n\nFor the event API it says: \"...but MUST indicate the failed transfer...\".\n@sophokles73 I am not sure about the reasoning behind this and this should be applied to the Kafka based API. Why must the protocol adapter not implement a retry? And does the difference regarding the obligation to inform the device only arise from the fact that this is not possible with QoS 0?", "author": "b-abel", "createdAt": "2020-11-02T12:25:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MDE3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MjA4Ng==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507542086", "bodyText": "is committing a message the common term for advancing the message pointer in the Kafka world?", "author": "sophokles73", "createdAt": "2020-10-19T07:52:47Z", "path": "site/documentation/content/api/event/index.md", "diffHunk": "@@ -130,3 +132,88 @@ The example below might be used by the MQTT adapter to indicate that a connectio\n   }\n }\n ~~~\n+\n+\n+## Event API for Kafka\n+\n+Hono can alternatively be configured to publish event messages to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Event API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send event messages received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Event\n+\n+The protocol adapter writes messages to the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload event messages for.\n+\n+\n+**Preconditions**\n+\n+1. Either the topic `event-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to write to the topic.\n+1. The device for which the adapter wants to send event messages has been registered (see [Device Registration API]({{< relref \"/api/device-registration\" >}})).\n+\n+**Message Flow**\n+\n+Hono supports *AT LEAST ONCE* delivery of *Event* messages only. A client therefore MUST set *acks* to `all`. Either MUST *enable.idempotence* be set to `true` OR *max.in.flight.requests.per.connection* MUST be set to `1`.\n+\n+\n+The recommended Kafka producer properties for *Event* messages are: `enable.idempotence=true`, `acks=all`, `max.in.flight.requests.per.connection=5`, leaving *retries* unset (which defaults to `Integer.MAX`), and setting *delivery.timeout.ms* to a reasonable value (supported from Kafka version 1.0.0 on). \n+\n+The following sequence diagram illustrates the flow of messages involved in the *MQTT Adapter* producing an event to the Kafka cluster.\n+\n+{{< figure src=\"produce_kafka.svg\" title=\"Produce event flow\" >}}\n+\n+1. *Device* `4711` publishes an event using MQTT QoS 1.\n+   1. *MQTT Adapter* produces an event message to *Kafka Cluster*.\n+   1. *Kafka cluster* acknowledges reception of the message.\n+   1. *MQTT Adapter* acknowledges the reception of the message to the *Device*.\n+\n+When the Kafka producer receives an exception when sending an event message to Kafka, the protocol adapter MUST NOT try to re-send such rejected messages but MUST indicate the failed transfer to the device if the transport protocol provides means to do so.\n+\n+**Message Format**\n+\n+See [Telemetry API]({{< relref \"/api/telemetry#produce-telemetry-data\" >}}) for the definition of the message format.\n+\n+### Northbound Operations\n+\n+The following operation can be used by *Business Applications* to receive event messages from Kafka.\n+\n+#### Consume Events\n+\n+Hono delivers messages containing events reported by a particular device in the same order that they have been received in (using the [Produce Event]({{< relref \"#produce-event\" >}}) operation).\n+*Business Applications* consume messages from the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` represents the ID of the tenant the client wants to retrieve event messages for.\n+\n+**Preconditions**\n+\n+1. Either the topic `event-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to read from the topic.\n+1. The client subscribes to the topic with a Kafka consumer. \n+\n+Hono supports *AT LEAST ONCE* delivery of *Event* messages only. A client therefore MUST NOT commit messages until it has successfully completed consuming them.", "originalCommit": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY1NDYxMw==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507654613", "bodyText": "Yes.", "author": "b-abel", "createdAt": "2020-10-19T10:55:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MjA4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MjY2Ng==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507542666", "bodyText": "I guess none at all. We cannot prevent people form doing what they want to do. We can only point out consequences of not following the behavior we propose in this context.", "author": "sophokles73", "createdAt": "2020-10-19T07:53:41Z", "path": "site/documentation/content/api/event/index.md", "diffHunk": "@@ -130,3 +132,88 @@ The example below might be used by the MQTT adapter to indicate that a connectio\n   }\n }\n ~~~\n+\n+\n+## Event API for Kafka\n+\n+Hono can alternatively be configured to publish event messages to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Event API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send event messages received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Event\n+\n+The protocol adapter writes messages to the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload event messages for.\n+\n+\n+**Preconditions**\n+\n+1. Either the topic `event-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to write to the topic.\n+1. The device for which the adapter wants to send event messages has been registered (see [Device Registration API]({{< relref \"/api/device-registration\" >}})).\n+\n+**Message Flow**\n+\n+Hono supports *AT LEAST ONCE* delivery of *Event* messages only. A client therefore MUST set *acks* to `all`. Either MUST *enable.idempotence* be set to `true` OR *max.in.flight.requests.per.connection* MUST be set to `1`.\n+\n+\n+The recommended Kafka producer properties for *Event* messages are: `enable.idempotence=true`, `acks=all`, `max.in.flight.requests.per.connection=5`, leaving *retries* unset (which defaults to `Integer.MAX`), and setting *delivery.timeout.ms* to a reasonable value (supported from Kafka version 1.0.0 on). \n+\n+The following sequence diagram illustrates the flow of messages involved in the *MQTT Adapter* producing an event to the Kafka cluster.\n+\n+{{< figure src=\"produce_kafka.svg\" title=\"Produce event flow\" >}}\n+\n+1. *Device* `4711` publishes an event using MQTT QoS 1.\n+   1. *MQTT Adapter* produces an event message to *Kafka Cluster*.\n+   1. *Kafka cluster* acknowledges reception of the message.\n+   1. *MQTT Adapter* acknowledges the reception of the message to the *Device*.\n+\n+When the Kafka producer receives an exception when sending an event message to Kafka, the protocol adapter MUST NOT try to re-send such rejected messages but MUST indicate the failed transfer to the device if the transport protocol provides means to do so.\n+\n+**Message Format**\n+\n+See [Telemetry API]({{< relref \"/api/telemetry#produce-telemetry-data\" >}}) for the definition of the message format.\n+\n+### Northbound Operations\n+\n+The following operation can be used by *Business Applications* to receive event messages from Kafka.\n+\n+#### Consume Events\n+\n+Hono delivers messages containing events reported by a particular device in the same order that they have been received in (using the [Produce Event]({{< relref \"#produce-event\" >}}) operation).\n+*Business Applications* consume messages from the tenant-specific topic `event-${tenant_id}` where `${tenant_id}` represents the ID of the tenant the client wants to retrieve event messages for.\n+\n+**Preconditions**\n+\n+1. Either the topic `event-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to read from the topic.\n+1. The client subscribes to the topic with a Kafka consumer. \n+\n+Hono supports *AT LEAST ONCE* delivery of *Event* messages only. A client therefore MUST NOT commit messages until it has successfully completed consuming them.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_How many assumptions about the behaviour of the consumers should hono make?_**", "originalCommit": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY1NzIyNQ==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507657225", "bodyText": "Absolutely.\nHono has no way to recognize the behavior of consumers and therefore there are no consequences possible (like with AMQP where Hono could terminate the link). I think the only thing we can do here is stating that consumers are expected to implement AT LEAST ONCE semantics. Even though a device can't be sure that the event will eventually be consumed by an application (as with publish/subscribe messaging there might be 0, 1, or more consumers).", "author": "b-abel", "createdAt": "2020-10-19T11:00:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MjY2Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY1ODM2OA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507658368", "bodyText": "Then I guess that is what you should explain here.", "author": "sophokles73", "createdAt": "2020-10-19T11:02:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0MjY2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0Mzg4MA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507543880", "bodyText": "absolutely \ud83d\udc4d", "author": "sophokles73", "createdAt": "2020-10-19T07:55:45Z", "path": "site/documentation/content/api/telemetry/index.md", "diffHunk": "@@ -118,3 +121,134 @@ The *Business Application* can only consume telemetry messages that have been up\n **Message Format**\n \n The format of the messages containing the telemetry data is the same as for the [Forward Telemetry Data operation]({{< relref \"#forward-telemetry-data\" >}}).\n+\n+\n+## Telemetry API for Kafka\n+\n+Hono can alternatively be configured to publish telemetry data to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Telemetry API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send telemetry data received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Telemetry Data\n+\n+The protocol adapter writes messages to the tenant-specific topic `telemetry-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload telemetry data for.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_Should we add a section with some basic explanations? E.g. like this:_**", "originalCommit": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY1NDgyNA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507654824", "bodyText": "I like the idea of enabling readers to easily understand the specification without the need to be Kafka experts beforehand. On the other side, we must then make clear that those short explanations of Kafka basics can not be authoritative nor exhaustive.\nI'm not sure where to put this. Maybe in a separate document and link to it from the API specifications?", "author": "b-abel", "createdAt": "2020-10-19T10:55:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0Mzg4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY1NzI2NA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507657264", "bodyText": "FMPOV this could be embedded in the API document itself. We can then also include a pointer to the official Kafka documentation.", "author": "sophokles73", "createdAt": "2020-10-19T11:00:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0Mzg4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0NTIyNA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507545224", "bodyText": "IMHO that is a good idea", "author": "sophokles73", "createdAt": "2020-10-19T07:57:55Z", "path": "site/documentation/content/api/telemetry/index.md", "diffHunk": "@@ -118,3 +121,134 @@ The *Business Application* can only consume telemetry messages that have been up\n **Message Format**\n \n The format of the messages containing the telemetry data is the same as for the [Forward Telemetry Data operation]({{< relref \"#forward-telemetry-data\" >}}).\n+\n+\n+## Telemetry API for Kafka\n+\n+Hono can alternatively be configured to publish telemetry data to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Telemetry API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send telemetry data received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Telemetry Data\n+\n+The protocol adapter writes messages to the tenant-specific topic `telemetry-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload telemetry data for.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_Should we add a section with some basic explanations? E.g. like this:_**\n+\n+**On Acknowledgements, Retries and Message Ordering**\n+\n+The adapter indicates its preferred message delivery mode by means of the Kafka producer config properties *acks*, *retries*, and *max.in.flight.requests.per.connection*.\n+Setting *acks* to `0` effectively disables retries.\n+Setting *acks* to `1` requests only the partition leader to acknowledge the message. If the leader goes down before the followers finished replication, then the message will be lost.\n+Setting *acks* to `all` (or equivalent `-1`) requests the leader to wait for the acknowledgements from all in-sync replicas before sending the acknowledgement back to the client. \n+This guarantees that the message will not be lost as long as at least one in-sync replica remains alive.\n+\n+If *retries* are enabled and *max.in.flight.requests.per.connection* is set to a value greater than `1`, the order of the messages is no longer guaranteed by Kafka. \n+The only exception is the *idempotent* producer, which can handle *max.in.flight.requests.per.connection* to be up to `5` with retries enabled while still maintaining the message order (since Kafka version 1.0.0).\n+\n+{{% /note %}}\n+\n+**Preconditions**\n+\n+1. Either the topic `telemetry-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to write to the topic.\n+1. The device for which the adapter wants to send telemetry data has been registered (see [Device Registration API]({{< relref \"/api/device-registration\" >}})).\n+\n+**Message Flow**\n+\n+It is up to the discretion of the protocol adapter whether it wants to use *AT LEAST ONCE* or *AT MOST ONCE* delivery semantics.\n+To achieve *AT LEAST ONCE* delivery semantics the protocol adapter MUST request acknowledgements from *all* in-sync-replicas in the Kafka cluster.\n+For *AT MOST ONCE* delivery semantics the protocol adapter acknowledges the message to the device without waiting for any acknowledgements from the Kafka cluster.\n+If *retries* is greater than zero, *max.in.flight.requests.per.connection* MUST be set to `1`, except if *enable.idempotence* is set to `true`.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_Should we add a table similar to the one in the AMQP Telemetry API? It could look like this:_**", "originalCommit": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY1NTgyOQ==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507655829", "bodyText": "I would rather list recommended (combinations of) configuration options than exhaustively listing all other combinations.\nThe table is very verbose while the most important information in it is a just reiteration of the three sentences above. The explanations in the last column may be better moved to the explanation of Kafka basics that we discussed above.", "author": "b-abel", "createdAt": "2020-10-19T10:57:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0NTIyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDAzNDA3OA==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r524034078", "bodyText": "No, I agree with the approach. In the end, that is the whole point of defining the fixed prefix, right?", "author": "sophokles73", "createdAt": "2020-11-16T09:39:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0NTIyNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDE0NDgzMw==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r524144833", "bodyText": "Yes.", "author": "b-abel", "createdAt": "2020-11-16T11:19:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0NTIyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0NzA1Mg==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507547052", "bodyText": "which device ID is that? The authenticated device's or the device's that the data originates from?", "author": "sophokles73", "createdAt": "2020-10-19T08:00:57Z", "path": "site/documentation/content/api/telemetry/index.md", "diffHunk": "@@ -118,3 +121,134 @@ The *Business Application* can only consume telemetry messages that have been up\n **Message Format**\n \n The format of the messages containing the telemetry data is the same as for the [Forward Telemetry Data operation]({{< relref \"#forward-telemetry-data\" >}}).\n+\n+\n+## Telemetry API for Kafka\n+\n+Hono can alternatively be configured to publish telemetry data to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Telemetry API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send telemetry data received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Telemetry Data\n+\n+The protocol adapter writes messages to the tenant-specific topic `telemetry-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload telemetry data for.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_Should we add a section with some basic explanations? E.g. like this:_**\n+\n+**On Acknowledgements, Retries and Message Ordering**\n+\n+The adapter indicates its preferred message delivery mode by means of the Kafka producer config properties *acks*, *retries*, and *max.in.flight.requests.per.connection*.\n+Setting *acks* to `0` effectively disables retries.\n+Setting *acks* to `1` requests only the partition leader to acknowledge the message. If the leader goes down before the followers finished replication, then the message will be lost.\n+Setting *acks* to `all` (or equivalent `-1`) requests the leader to wait for the acknowledgements from all in-sync replicas before sending the acknowledgement back to the client. \n+This guarantees that the message will not be lost as long as at least one in-sync replica remains alive.\n+\n+If *retries* are enabled and *max.in.flight.requests.per.connection* is set to a value greater than `1`, the order of the messages is no longer guaranteed by Kafka. \n+The only exception is the *idempotent* producer, which can handle *max.in.flight.requests.per.connection* to be up to `5` with retries enabled while still maintaining the message order (since Kafka version 1.0.0).\n+\n+{{% /note %}}\n+\n+**Preconditions**\n+\n+1. Either the topic `telemetry-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to write to the topic.\n+1. The device for which the adapter wants to send telemetry data has been registered (see [Device Registration API]({{< relref \"/api/device-registration\" >}})).\n+\n+**Message Flow**\n+\n+It is up to the discretion of the protocol adapter whether it wants to use *AT LEAST ONCE* or *AT MOST ONCE* delivery semantics.\n+To achieve *AT LEAST ONCE* delivery semantics the protocol adapter MUST request acknowledgements from *all* in-sync-replicas in the Kafka cluster.\n+For *AT MOST ONCE* delivery semantics the protocol adapter acknowledges the message to the device without waiting for any acknowledgements from the Kafka cluster.\n+If *retries* is greater than zero, *max.in.flight.requests.per.connection* MUST be set to `1`, except if *enable.idempotence* is set to `true`.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_Should we add a table similar to the one in the AMQP Telemetry API? It could look like this:_**\n+\n+| acks  | retries   |  max.in.flight.requests.per.connection    | enable.idempotence    | Delivery semantics |\n+| :---: | :-----:   | :-------------------------------------:   | :-------------------: | :----------------- |\n+| 0     | 0  | >0 | `false` | Setting *acks* to `0` allows for adapters to implement *AT MOST ONCE* delivery semantics only. This is the fastest mode of delivery but has the drawback of potential loss of messages without notice. |\n+| 1     | 0  | >0 | `false` | Setting *acks* to `1` allows for adapters to implement *AT MOST ONCE* delivery semantics only. If the leader goes down before the followers finished replication, then the message will be lost. | \n+| 1     | >0 | 1  | `false` | Setting *acks* to `1` allows for adapters to implement *AT MOST ONCE* delivery semantics only. When retries are enabled, *max.in.flight.requests.per.connection* MUST be set to `1`. | \n+| all   | 0  | >0 | `false` | Setting *acks* to `all` allows for adapters to implement both *AT LEAST ONCE* or *AT MOST ONCE* delivery semantics, depending on whether the adapter waits for and considers the acknowledgement it receives from the Kafka cluster or not. Disabling retries might cause messages to fail in case of high load or transient transmission failures. |\n+| all   | >0 | 1  | `false` | Setting *acks* to `all` allows for adapters to implement both *AT LEAST ONCE* or *AT MOST ONCE* delivery semantics, depending on whether the adapter waits for and considers the acknowledgement it receives from the Kafka cluster or not. When retries are enabled, *max.in.flight.requests.per.connection* MUST be set to `1`. |\n+| all   | >0 | <6 | `true`  | Setting *acks* to `all` allows for adapters to implement both *AT LEAST ONCE* or *AT MOST ONCE* delivery semantics, depending on whether the adapter waits for and considers the acknowledgement it receives from the Kafka cluster or not. |\n+\n+All other combinations are not supported by Hono.\n+{{% /note %}}\n+\n+The recommended Kafka producer properties for *AT LEAST ONCE* delivery are: `enable.idempotence=true`, `acks=all`, `max.in.flight.requests.per.connection=5`, leaving *retries* unset, and setting *delivery.timeout.ms* to a reasonable value (supported from Kafka version 1.0.0 on). \n+\n+The following sequence diagram illustrates the flow of messages involved in the *HTTP Adapter* producing a telemetry data message to the Kafka cluster implementing *AT MOST ONCE* delivery semantics.\n+\n+{{< figure src=\"produce_kafka_qos0.svg\" title=\"Produce telemetry data flow (AT MOST ONCE)\" >}}\n+\n+1. *Device* `4711` PUTs telemetry data to the *HTTP Adapter*\n+   1. *HTTP Adapter* produces telemetry data to *Kafka Cluster*.\n+   1. *HTTP Adapter* acknowledges the reception of the data to the *Device*.\n+\n+The following sequence diagram illustrates the flow of messages involved in the *HTTP Adapter* producing a telemetry data message to the Kafka cluster implementing *AT LEAST ONCE* delivery semantics.\n+\n+{{< figure src=\"produce_kafka_qos1.svg\" title=\"Produce telemetry data flow (AT LEAST ONCE)\" >}}\n+\n+1. *Device* `4711` PUTs telemetry data to the *HTTP Adapter*, indicating *QoS Level* 1.\n+   1. *HTTP Adapter* produces telemetry data to *Kafka Cluster*.\n+   1. *Kafka Cluster* acknowledges reception of the message.\n+   1. *HTTP Adapter* acknowledges the reception of the data to the *Device*.\n+\n+When the Kafka producer receives an exception when sending a telemetry message to Kafka, the protocol adapter MUST NOT try to re-send such rejected messages but SHOULD indicate the failed transfer to the device if the transport protocol provides means to do so.\n+\n+**Message Format**\n+\n+A Kafka message (also called record) consists of a key, a value, a timestamp, and headers.\n+The key of the message MUST be the device ID.", "originalCommit": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY1NDg2OQ==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r507654869", "bodyText": "The ID of the device that the data originates from. I'm going to add this.", "author": "b-abel", "createdAt": "2020-10-19T10:55:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzU0NzA1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEzMzgwNQ==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r515133805", "bodyText": "How about using either here? I think when you say both, then it means both AT LEAST ONCE and AT MOST ONCE.\nmaybe it is worth to distinguish how this implements AT LEAST ONCE or AT MOST ONCE delivery semantics. Do you mean that it implements AT LEAST ONCE when there is at least one alive in-sync replica that commits the message? And it implements AT MOST ONCE when no in-sync replica is alive, in which case the message will be lost?", "author": "Alfusainey", "createdAt": "2020-10-30T14:22:17Z", "path": "site/documentation/content/api/telemetry/index.md", "diffHunk": "@@ -118,3 +121,134 @@ The *Business Application* can only consume telemetry messages that have been up\n **Message Format**\n \n The format of the messages containing the telemetry data is the same as for the [Forward Telemetry Data operation]({{< relref \"#forward-telemetry-data\" >}}).\n+\n+\n+## Telemetry API for Kafka\n+\n+Hono can alternatively be configured to publish telemetry data to an Apache Kafka&reg; cluster instead of an AMQP Messaging Network. The Telemetry API for Kafka is defined by means of Kafka messages.\n+\n+### Southbound Operations\n+\n+The following operation can be used by *Protocol Adapters* to send telemetry data received from devices to downstream consumers like *Business Applications*.\n+\n+#### Produce Telemetry Data\n+\n+The protocol adapter writes messages to the tenant-specific topic `telemetry-${tenant_id}` where `${tenant_id}` is the ID of the tenant that the client wants to upload telemetry data for.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_Should we add a section with some basic explanations? E.g. like this:_**\n+\n+**On Acknowledgements, Retries and Message Ordering**\n+\n+The adapter indicates its preferred message delivery mode by means of the Kafka producer config properties *acks*, *retries*, and *max.in.flight.requests.per.connection*.\n+Setting *acks* to `0` effectively disables retries.\n+Setting *acks* to `1` requests only the partition leader to acknowledge the message. If the leader goes down before the followers finished replication, then the message will be lost.\n+Setting *acks* to `all` (or equivalent `-1`) requests the leader to wait for the acknowledgements from all in-sync replicas before sending the acknowledgement back to the client. \n+This guarantees that the message will not be lost as long as at least one in-sync replica remains alive.\n+\n+If *retries* are enabled and *max.in.flight.requests.per.connection* is set to a value greater than `1`, the order of the messages is no longer guaranteed by Kafka. \n+The only exception is the *idempotent* producer, which can handle *max.in.flight.requests.per.connection* to be up to `5` with retries enabled while still maintaining the message order (since Kafka version 1.0.0).\n+\n+{{% /note %}}\n+\n+**Preconditions**\n+\n+1. Either the topic `telemetry-${tenant_id}` exists, or the broker is configured to automatically create topics on demand.\n+1. The client is authorized to write to the topic.\n+1. The device for which the adapter wants to send telemetry data has been registered (see [Device Registration API]({{< relref \"/api/device-registration\" >}})).\n+\n+**Message Flow**\n+\n+It is up to the discretion of the protocol adapter whether it wants to use *AT LEAST ONCE* or *AT MOST ONCE* delivery semantics.\n+To achieve *AT LEAST ONCE* delivery semantics the protocol adapter MUST request acknowledgements from *all* in-sync-replicas in the Kafka cluster.\n+For *AT MOST ONCE* delivery semantics the protocol adapter acknowledges the message to the device without waiting for any acknowledgements from the Kafka cluster.\n+If *retries* is greater than zero, *max.in.flight.requests.per.connection* MUST be set to `1`, except if *enable.idempotence* is set to `true`.\n+\n+{{% note title=\"TO BE DISCUSSED\" %}}\n+**_Should we add a table similar to the one in the AMQP Telemetry API? It could look like this:_**\n+\n+| acks  | retries   |  max.in.flight.requests.per.connection    | enable.idempotence    | Delivery semantics |\n+| :---: | :-----:   | :-------------------------------------:   | :-------------------: | :----------------- |\n+| 0     | 0  | >0 | `false` | Setting *acks* to `0` allows for adapters to implement *AT MOST ONCE* delivery semantics only. This is the fastest mode of delivery but has the drawback of potential loss of messages without notice. |\n+| 1     | 0  | >0 | `false` | Setting *acks* to `1` allows for adapters to implement *AT MOST ONCE* delivery semantics only. If the leader goes down before the followers finished replication, then the message will be lost. | \n+| 1     | >0 | 1  | `false` | Setting *acks* to `1` allows for adapters to implement *AT MOST ONCE* delivery semantics only. When retries are enabled, *max.in.flight.requests.per.connection* MUST be set to `1`. | \n+| all   | 0  | >0 | `false` | Setting *acks* to `all` allows for adapters to implement both *AT LEAST ONCE* or *AT MOST ONCE* delivery semantics, depending on whether the adapter waits for and considers the acknowledgement it receives from the Kafka cluster or not. Disabling retries might cause messages to fail in case of high load or transient transmission failures. |", "originalCommit": "b4bd1948150c9a4432f3c2962bfa80fec42fb8cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTIzMDYxNg==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r515230616", "bodyText": "@Alfusainey Thank you for your feedback. Please have a look at my last change if it resolves this issue.", "author": "b-abel", "createdAt": "2020-10-30T16:41:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEzMzgwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg5MDk4OQ==", "url": "https://github.com/eclipse/hono/pull/2254#discussion_r521890989", "bodyText": "it might be helpful to also explain the reason for this requirement.", "author": "sophokles73", "createdAt": "2020-11-12T07:35:15Z", "path": "site/documentation/content/api/kafka/telemetry-kafka/index.md", "diffHunk": "@@ -141,6 +144,13 @@ The following sequence diagram illustrates the flow of messages involved in the\n \n When a Kafka producer raises an exception while sending a telemetry message to Kafka, the protocol adapter MUST NOT try to re-send such rejected messages but SHOULD indicate the failed transfer to the device if the transport protocol provides means to do so.\n \n+**Use *AT LEAST ONCE* and *AT MOST ONCE* in a Protocol Adapter**\n+\n+If a protocol adapter should support both delivery semantics, a single producer MUST be used and it MUST be configured \n+for *AT LEAST ONCE*. It may not wait for acknowledgements of *AT MOST ONCE* messages. \n+\n+A protocol adapter MUST NOT use two producers sending telemetry data for the same device.", "originalCommit": "0e102dd5b22ab4204cbc1481d526864d9963cd82", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1e67730e7d68d614f70a632ed8096705230d72d9", "url": "https://github.com/eclipse/hono/commit/1e67730e7d68d614f70a632ed8096705230d72d9", "message": "[#8] Add specifications for the Kafka-based Telemetry API and Event API.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>", "committedDate": "2021-01-04T11:16:01Z", "type": "commit"}, {"oid": "5d5a39606bd04ac3af5159bd429232fce0f9c6d1", "url": "https://github.com/eclipse/hono/commit/5d5a39606bd04ac3af5159bd429232fce0f9c6d1", "message": "[#8] Add preview notice to Kafka API documentation.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>", "committedDate": "2021-01-04T11:16:01Z", "type": "commit"}, {"oid": "cfe5a6f2ecfa02e7c95621b33d555b8cfa880507", "url": "https://github.com/eclipse/hono/commit/cfe5a6f2ecfa02e7c95621b33d555b8cfa880507", "message": "[#8] Add Kafka APIs to release notes.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>", "committedDate": "2021-01-04T11:16:01Z", "type": "commit"}, {"oid": "bb1e1753edc80e8988bf10787a4bf2d964ae91c1", "url": "https://github.com/eclipse/hono/commit/bb1e1753edc80e8988bf10787a4bf2d964ae91c1", "message": "[#8] Do not use a sub-menu for Kafka-based API specifications.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>", "committedDate": "2021-01-04T11:47:43Z", "type": "commit"}, {"oid": "bb1e1753edc80e8988bf10787a4bf2d964ae91c1", "url": "https://github.com/eclipse/hono/commit/bb1e1753edc80e8988bf10787a4bf2d964ae91c1", "message": "[#8] Do not use a sub-menu for Kafka-based API specifications.\n\nSigned-off-by: Abel Buechner-Mihaljevic <abel.buechner-mihaljevic@bosch.io>", "committedDate": "2021-01-04T11:47:43Z", "type": "forcePushed"}]}