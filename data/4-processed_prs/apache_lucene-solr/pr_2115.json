{"pr_number": 2115, "pr_title": "SOLR-14992 Wait for node down before checking for node up", "pr_createdAt": "2020-12-02T18:59:56Z", "pr_url": "https://github.com/apache/lucene-solr/pull/2115", "timeline": [{"oid": "ef1b833130bfc0412b46e2aadc73d8dc08d72dd6", "url": "https://github.com/apache/lucene-solr/commit/ef1b833130bfc0412b46e2aadc73d8dc08d72dd6", "message": "SOLR-14992 Wait for node down before checking for node up", "committedDate": "2020-12-02T18:58:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ0NTU0NQ==", "url": "https://github.com/apache/lucene-solr/pull/2115#discussion_r534445545", "bodyText": "Wouldn't it be better to actually check for the node znode ctime? Or maybe a bump in /live_nodes's cversion?", "author": "tflobbe", "createdAt": "2020-12-02T20:01:53Z", "path": "solr/core/src/test/org/apache/solr/cloud/TestPullReplicaErrorHandling.java", "diffHunk": "@@ -236,8 +237,9 @@ public void testCloseHooksDeletedOnReconnect() throws Exception {\n     JettySolrRunner jetty = getJettyForReplica(s.getReplicas(EnumSet.of(Replica.Type.PULL)).get(0));\n     SolrCore core = jetty.getCoreContainer().getCores().iterator().next();\n \n-    for (int i = 0; i < 5; i++) {\n+    for (int i = 0; i < (TEST_NIGHTLY ? 5 : 2); i++) {\n       cluster.expireZkSession(jetty);\n+      waitForState(\"Expecting node to be disconnected\", collectionName, activeReplicaCount(1, 0, 0));", "originalCommit": "ef1b833130bfc0412b46e2aadc73d8dc08d72dd6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ4Mjc2OQ==", "url": "https://github.com/apache/lucene-solr/pull/2115#discussion_r534482769", "bodyText": "There is a window where live node has gone away but state is still active because it hasn't updated yet. if we're just waiting for and watching live nodes, then we can see that go away and complete the test before the cluster has quiesced. this is also how we check in testPullReplicaDisconnectsFromZooKeeper, so for consistency this felt better.\nThere is still a different race here that the replica could go down and come back up before we start waiting for it to be down the first time (we're expecting the overseer to be slow), which I'm sure @markrmiller would be upset with me over, but we can deal with that when he finishes the rest of his speed up branch.", "author": "madrob", "createdAt": "2020-12-02T21:09:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ0NTU0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDcwMjA5Nw==", "url": "https://github.com/apache/lucene-solr/pull/2115#discussion_r534702097", "bodyText": "There is a window where live node has gone away but state is still active because it hasn't updated yet.\n\nHave you seen that happening? AFAIK, everywhere that we check if a replica is active we look at the state and the live nodes.\n\nif we're just waiting for and watching live nodes, then we can see that go away and complete the test before the cluster has quiesced.\n\nWe would still have the check in line 243, right? My point was:\n\nwait to see a change in live nodes\nwait for active (line 243 as it is now)\n\nWouldn't that be safe (assuming no other, unrelated node dies just at this point)?\n\nThere is still a different race here that the replica could go down and come back up before we start waiting for it to be down the first time\n\nRight, that's the one I was concerned about. Difficult to happen, but...", "author": "tflobbe", "createdAt": "2020-12-03T05:59:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ0NTU0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTc0NzYyNQ==", "url": "https://github.com/apache/lucene-solr/pull/2115#discussion_r535747625", "bodyText": "I think you're technically correct, but I'd rather leave that as a future improvement since we do it in several places.", "author": "madrob", "createdAt": "2020-12-04T00:31:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDQ0NTU0NQ=="}], "type": "inlineReview"}]}