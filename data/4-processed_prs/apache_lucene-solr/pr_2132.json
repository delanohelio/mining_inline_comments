{"pr_number": 2132, "pr_title": "SOLR-15036: auto- select / rollup / sort / plist over facet expression when using a collection alias with multiple collections", "pr_createdAt": "2020-12-09T00:50:02Z", "pr_url": "https://github.com/apache/lucene-solr/pull/2132", "timeline": [{"oid": "c35a205672ee4bd8fa8bdb876ad89590e4dd416a", "url": "https://github.com/apache/lucene-solr/commit/c35a205672ee4bd8fa8bdb876ad89590e4dd416a", "message": "SOLR-15036: auto- select / rollup / sort / plist over facet expression when using a collection alias with multiple collections", "committedDate": "2020-12-09T00:46:20Z", "type": "commit"}, {"oid": "0762024f03fa32ab08b9192596332b92e6dbd50c", "url": "https://github.com/apache/lucene-solr/commit/0762024f03fa32ab08b9192596332b92e6dbd50c", "message": "Fix precommit problems", "committedDate": "2020-12-09T17:42:49Z", "type": "commit"}, {"oid": "2556070a5d624c5b30e7cc0ebbfa933bba216572", "url": "https://github.com/apache/lucene-solr/commit/2556070a5d624c5b30e7cc0ebbfa933bba216572", "message": "Try to generalize the parallel metrics rollup logic", "committedDate": "2020-12-14T23:26:31Z", "type": "commit"}, {"oid": "73c2a6a6a2c1f1ac946b7d65893f9646d98c953e", "url": "https://github.com/apache/lucene-solr/commit/73c2a6a6a2c1f1ac946b7d65893f9646d98c953e", "message": "Fix format call", "committedDate": "2020-12-14T23:28:39Z", "type": "commit"}, {"oid": "b0a3261cbc0a1ae490e4de43cbb1530584374ab7", "url": "https://github.com/apache/lucene-solr/commit/b0a3261cbc0a1ae490e4de43cbb1530584374ab7", "message": "Merge remote-tracking branch 'asf/master' into SOLR-15036", "committedDate": "2020-12-14T23:31:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjk2NDc0OQ==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r542964749", "bodyText": "NULL_DEREFERENCE:  object returned by FacetStream.cloudSolrClient.getClusterStateProvider() could be null and is dereferenced at line 562.", "author": "sonatype-lift", "createdAt": "2020-12-15T01:01:42Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/FacetStream.java", "diffHunk": "@@ -545,6 +557,18 @@ public void open() throws IOException {\n       cloudSolrClient = new Builder(hosts, Optional.empty()).withSocketTimeout(30000).withConnectionTimeout(15000).build();\n     }\n \n+    if (params.getBool(\"plist\", true)) {\n+      params.remove(\"plist\");\n+      final List<String> resolved = cloudSolrClient.getClusterStateProvider().resolveAlias(collection);", "originalCommit": "b0a3261cbc0a1ae490e4de43cbb1530584374ab7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ0MzQ4Nw==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r543443487", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                for(int i=0; i<sorts.length; i++) {\n          \n          \n            \n                for (int i = 0; i < sorts.length; i++) {", "author": "jbampton", "createdAt": "2020-12-15T15:26:50Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/FacetStream.java", "diffHunk": "@@ -351,25 +361,26 @@ public String getCollection() {\n \n     FieldComparator[] comps = new FieldComparator[sorts.length];\n     for(int i=0; i<sorts.length; i++) {", "originalCommit": "b0a3261cbc0a1ae490e4de43cbb1530584374ab7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ0Mzk3NQ==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r543443975", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                if(s.endsWith(\"asc\") || s.endsWith(\"ASC\")) {\n          \n          \n            \n                if (s.endsWith(\"asc\") || s.endsWith(\"ASC\")) {", "author": "jbampton", "createdAt": "2020-12-15T15:27:20Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/FacetStream.java", "diffHunk": "@@ -351,25 +361,26 @@ public String getCollection() {\n \n     FieldComparator[] comps = new FieldComparator[sorts.length];\n     for(int i=0; i<sorts.length; i++) {\n-      String s = sorts[i];\n+      comps[i] = parseSortClause(sorts[i]);\n+    }\n \n-      String fieldName = null;\n-      String order = null;\n+    return comps;\n+  }\n \n-      if(s.endsWith(\"asc\") || s.endsWith(\"ASC\")) {\n-        order = \"asc\";\n-        fieldName = s.substring(0, s.length()-3).trim().replace(\" \", \"\");\n-      } else if(s.endsWith(\"desc\") || s.endsWith(\"DESC\")) {\n-        order = \"desc\";\n-        fieldName = s.substring(0, s.length()-4).trim().replace(\" \", \"\");\n-      } else {\n-        throw new IOException(String.format(Locale.ROOT,\"invalid expression - bad bucketSort '%s'.\",bucketSortString));\n-      }\n-            \n-      comps[i] = new FieldComparator(fieldName, order.equalsIgnoreCase(\"asc\") ? ComparatorOrder.ASCENDING : ComparatorOrder.DESCENDING);\n+  private FieldComparator parseSortClause(final String s) throws IOException {\n+    String fieldName = null;\n+    String order = null;\n+    if(s.endsWith(\"asc\") || s.endsWith(\"ASC\")) {", "originalCommit": "b0a3261cbc0a1ae490e4de43cbb1530584374ab7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ0NDM2Nw==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r543444367", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } else if(s.endsWith(\"desc\") || s.endsWith(\"DESC\")) {\n          \n          \n            \n                } else if (s.endsWith(\"desc\") || s.endsWith(\"DESC\")) {", "author": "jbampton", "createdAt": "2020-12-15T15:27:44Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/FacetStream.java", "diffHunk": "@@ -351,25 +361,26 @@ public String getCollection() {\n \n     FieldComparator[] comps = new FieldComparator[sorts.length];\n     for(int i=0; i<sorts.length; i++) {\n-      String s = sorts[i];\n+      comps[i] = parseSortClause(sorts[i]);\n+    }\n \n-      String fieldName = null;\n-      String order = null;\n+    return comps;\n+  }\n \n-      if(s.endsWith(\"asc\") || s.endsWith(\"ASC\")) {\n-        order = \"asc\";\n-        fieldName = s.substring(0, s.length()-3).trim().replace(\" \", \"\");\n-      } else if(s.endsWith(\"desc\") || s.endsWith(\"DESC\")) {\n-        order = \"desc\";\n-        fieldName = s.substring(0, s.length()-4).trim().replace(\" \", \"\");\n-      } else {\n-        throw new IOException(String.format(Locale.ROOT,\"invalid expression - bad bucketSort '%s'.\",bucketSortString));\n-      }\n-            \n-      comps[i] = new FieldComparator(fieldName, order.equalsIgnoreCase(\"asc\") ? ComparatorOrder.ASCENDING : ComparatorOrder.DESCENDING);\n+  private FieldComparator parseSortClause(final String s) throws IOException {\n+    String fieldName = null;\n+    String order = null;\n+    if(s.endsWith(\"asc\") || s.endsWith(\"ASC\")) {\n+      order = \"asc\";\n+      fieldName = s.substring(0, s.length()-3).trim().replace(\" \", \"\");\n+    } else if(s.endsWith(\"desc\") || s.endsWith(\"DESC\")) {", "originalCommit": "b0a3261cbc0a1ae490e4de43cbb1530584374ab7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ0NTE0Ng==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r543445146", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  throw new IOException(String.format(Locale.ROOT,\"invalid expression - bad sort caluse '%s'.\",s));\n          \n          \n            \n                  throw new IOException(String.format(Locale.ROOT, \"invalid expression - bad sort caluse '%s'.\", s));", "author": "jbampton", "createdAt": "2020-12-15T15:28:43Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/FacetStream.java", "diffHunk": "@@ -351,25 +361,26 @@ public String getCollection() {\n \n     FieldComparator[] comps = new FieldComparator[sorts.length];\n     for(int i=0; i<sorts.length; i++) {\n-      String s = sorts[i];\n+      comps[i] = parseSortClause(sorts[i]);\n+    }\n \n-      String fieldName = null;\n-      String order = null;\n+    return comps;\n+  }\n \n-      if(s.endsWith(\"asc\") || s.endsWith(\"ASC\")) {\n-        order = \"asc\";\n-        fieldName = s.substring(0, s.length()-3).trim().replace(\" \", \"\");\n-      } else if(s.endsWith(\"desc\") || s.endsWith(\"DESC\")) {\n-        order = \"desc\";\n-        fieldName = s.substring(0, s.length()-4).trim().replace(\" \", \"\");\n-      } else {\n-        throw new IOException(String.format(Locale.ROOT,\"invalid expression - bad bucketSort '%s'.\",bucketSortString));\n-      }\n-            \n-      comps[i] = new FieldComparator(fieldName, order.equalsIgnoreCase(\"asc\") ? ComparatorOrder.ASCENDING : ComparatorOrder.DESCENDING);\n+  private FieldComparator parseSortClause(final String s) throws IOException {\n+    String fieldName = null;\n+    String order = null;\n+    if(s.endsWith(\"asc\") || s.endsWith(\"ASC\")) {\n+      order = \"asc\";\n+      fieldName = s.substring(0, s.length()-3).trim().replace(\" \", \"\");\n+    } else if(s.endsWith(\"desc\") || s.endsWith(\"DESC\")) {\n+      order = \"desc\";\n+      fieldName = s.substring(0, s.length()-4).trim().replace(\" \", \"\");\n+    } else {\n+      throw new IOException(String.format(Locale.ROOT,\"invalid expression - bad sort caluse '%s'.\",s));", "originalCommit": "b0a3261cbc0a1ae490e4de43cbb1530584374ab7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ0NjA1NA==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r543446054", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                for (int c=0; c < parallelStreams.length; c++) {\n          \n          \n            \n                for (int c = 0; c < parallelStreams.length; c++) {", "author": "jbampton", "createdAt": "2020-12-15T15:29:45Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/FacetStream.java", "diffHunk": "@@ -842,10 +874,73 @@ public int getCost() {\n \n   @Override\n   public StreamComparator getStreamSort() {\n-    if(bucketSorts.length > 1) {\n-      return new MultipleFieldComparator(bucketSorts);\n+    return (bucketSorts.length > 1) ? new MultipleFieldComparator(bucketSorts) : bucketSorts[0];\n+  }\n+\n+  @Override\n+  public TupleStream[] parallelize(List<String> partitions) throws IOException {\n+    TupleStream[] parallelStreams = new TupleStream[partitions.size()];\n+\n+    // prefer a different node for each collection if possible as we don't want the same remote node\n+    // being the coordinator if possible, otherwise, our plist isn't distributing the load as well\n+    final Set<String> preferredNodes = new HashSet<>(Math.max((int) (parallelStreams.length/.75f) + 1, 16));\n+\n+    for (int c=0; c < parallelStreams.length; c++) {", "originalCommit": "b0a3261cbc0a1ae490e4de43cbb1530584374ab7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ0NjkwMg==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r543446902", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                for (int m=0; m < rollup.length; m++) {\n          \n          \n            \n                for (int m = 0; m < rollup.length; m++) {", "author": "jbampton", "createdAt": "2020-12-15T15:30:51Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/ParallelMetricsRollup.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.client.solrj.io.stream;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import org.apache.solr.client.solrj.io.comp.StreamComparator;\n+import org.apache.solr.client.solrj.io.stream.metrics.CountMetric;\n+import org.apache.solr.client.solrj.io.stream.metrics.MaxMetric;\n+import org.apache.solr.client.solrj.io.stream.metrics.MeanMetric;\n+import org.apache.solr.client.solrj.io.stream.metrics.Metric;\n+import org.apache.solr.client.solrj.io.stream.metrics.MinMetric;\n+import org.apache.solr.client.solrj.io.stream.metrics.SumMetric;\n+import org.apache.solr.client.solrj.io.stream.metrics.WeightedSumMetric;\n+\n+/**\n+ * Indicates the underlying stream source supports parallelizing metrics computation across collections\n+ * using a rollup of metrics from each collection.\n+ */\n+public interface ParallelMetricsRollup {\n+  TupleStream[] parallelize(List<String> partitions) throws IOException;\n+  StreamComparator getParallelListSortOrder() throws IOException;\n+  RollupStream getRollupStream(SortStream sortStream, Metric[] rollupMetrics) throws IOException;\n+  Map<String,String> getRollupSelectFields(Metric[] rollupMetrics);\n+\n+  default Optional<TupleStream> openParallelStream(StreamContext context, List<String> partitions, Metric[] metrics) throws IOException {\n+    Optional<Metric[]> maybeRollupMetrics = getRollupMetrics(metrics);\n+    if (maybeRollupMetrics.isEmpty())\n+      return Optional.empty(); // some metric is incompatible with doing a rollup over the plist results\n+\n+    TupleStream[] parallelStreams = parallelize(partitions);\n+\n+    // the tuples from each plist need to be sorted using the same order to do a rollup\n+    Metric[] rollupMetrics = maybeRollupMetrics.get();\n+    StreamComparator comparator = getParallelListSortOrder();\n+    SortStream sortStream = new SortStream(new ParallelListStream(parallelStreams), comparator);\n+    RollupStream rollup = getRollupStream(sortStream, rollupMetrics);\n+    SelectStream select = new SelectStream(rollup, getRollupSelectFields(rollupMetrics));\n+    select.setStreamContext(context);\n+    select.open();\n+\n+    return Optional.of(select);\n+  }\n+\n+  default Optional<Metric[]> getRollupMetrics(Metric[] metrics) {\n+    Metric[] rollup = new Metric[metrics.length];\n+    CountMetric count = null;\n+    for (int m=0; m < rollup.length; m++) {", "originalCommit": "b0a3261cbc0a1ae490e4de43cbb1530584374ab7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ0NzM0MA==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r543447340", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                      for (int n=m+1; n < metrics.length; n++) {\n          \n          \n            \n                      for (int n = m+1; n < metrics.length; n++) {", "author": "jbampton", "createdAt": "2020-12-15T15:31:25Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/ParallelMetricsRollup.java", "diffHunk": "@@ -0,0 +1,108 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.client.solrj.io.stream;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+\n+import org.apache.solr.client.solrj.io.comp.StreamComparator;\n+import org.apache.solr.client.solrj.io.stream.metrics.CountMetric;\n+import org.apache.solr.client.solrj.io.stream.metrics.MaxMetric;\n+import org.apache.solr.client.solrj.io.stream.metrics.MeanMetric;\n+import org.apache.solr.client.solrj.io.stream.metrics.Metric;\n+import org.apache.solr.client.solrj.io.stream.metrics.MinMetric;\n+import org.apache.solr.client.solrj.io.stream.metrics.SumMetric;\n+import org.apache.solr.client.solrj.io.stream.metrics.WeightedSumMetric;\n+\n+/**\n+ * Indicates the underlying stream source supports parallelizing metrics computation across collections\n+ * using a rollup of metrics from each collection.\n+ */\n+public interface ParallelMetricsRollup {\n+  TupleStream[] parallelize(List<String> partitions) throws IOException;\n+  StreamComparator getParallelListSortOrder() throws IOException;\n+  RollupStream getRollupStream(SortStream sortStream, Metric[] rollupMetrics) throws IOException;\n+  Map<String,String> getRollupSelectFields(Metric[] rollupMetrics);\n+\n+  default Optional<TupleStream> openParallelStream(StreamContext context, List<String> partitions, Metric[] metrics) throws IOException {\n+    Optional<Metric[]> maybeRollupMetrics = getRollupMetrics(metrics);\n+    if (maybeRollupMetrics.isEmpty())\n+      return Optional.empty(); // some metric is incompatible with doing a rollup over the plist results\n+\n+    TupleStream[] parallelStreams = parallelize(partitions);\n+\n+    // the tuples from each plist need to be sorted using the same order to do a rollup\n+    Metric[] rollupMetrics = maybeRollupMetrics.get();\n+    StreamComparator comparator = getParallelListSortOrder();\n+    SortStream sortStream = new SortStream(new ParallelListStream(parallelStreams), comparator);\n+    RollupStream rollup = getRollupStream(sortStream, rollupMetrics);\n+    SelectStream select = new SelectStream(rollup, getRollupSelectFields(rollupMetrics));\n+    select.setStreamContext(context);\n+    select.open();\n+\n+    return Optional.of(select);\n+  }\n+\n+  default Optional<Metric[]> getRollupMetrics(Metric[] metrics) {\n+    Metric[] rollup = new Metric[metrics.length];\n+    CountMetric count = null;\n+    for (int m=0; m < rollup.length; m++) {\n+      Metric nextRollup;\n+      Metric next = metrics[m];\n+      if (next instanceof SumMetric) {\n+        // sum of sums\n+        nextRollup = new SumMetric(next.getIdentifier());\n+      } else if (next instanceof MinMetric) {\n+        // min of mins\n+        nextRollup = new MinMetric(next.getIdentifier());\n+      } else if (next instanceof MaxMetric) {\n+        // max of max\n+        nextRollup = new MaxMetric(next.getIdentifier());\n+      } else if (next instanceof CountMetric) {\n+        // sum of counts\n+        nextRollup = new SumMetric(next.getIdentifier());\n+        count = (CountMetric)next;\n+      } else if (next instanceof MeanMetric) {\n+        // WeightedSumMetric must have a count to compute the weighted avg. rollup from ...\n+        // if the user is not requesting count, then we can't parallelize\n+        if (count == null) {\n+          // just look past the current position\n+          for (int n=m+1; n < metrics.length; n++) {", "originalCommit": "b0a3261cbc0a1ae490e4de43cbb1530584374ab7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ0Nzc1MA==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r543447750", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } else if(o instanceof Long) {\n          \n          \n            \n                } else if (o instanceof Long) {", "author": "jbampton", "createdAt": "2020-12-15T15:31:52Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/metrics/MaxMetric.java", "diffHunk": "@@ -86,7 +86,7 @@ public void update(Tuple tuple) {\n       if(l > longMax) {\n         longMax = l;\n       }\n-    } else {\n+    } else if(o instanceof Long) {", "originalCommit": "b0a3261cbc0a1ae490e4de43cbb1530584374ab7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDA1NjYwOQ==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r554056609", "bodyText": "the current format is consistent with the rest of the source file, best not to mix formatting even if it's wrong", "author": "thelabdude", "createdAt": "2021-01-08T16:41:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ0Nzc1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ0ODA5OA==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r543448098", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } else if(o instanceof Long) {\n          \n          \n            \n                } else if (o instanceof Long) {", "author": "jbampton", "createdAt": "2020-12-15T15:32:17Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/metrics/MinMetric.java", "diffHunk": "@@ -87,7 +87,7 @@ public void update(Tuple tuple) {\n       if(l < longMin) {\n         longMin = l;\n       }\n-    } else {\n+    } else if(o instanceof Long) {", "originalCommit": "b0a3261cbc0a1ae490e4de43cbb1530584374ab7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ0ODczNQ==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r543448735", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            }\n          \n          \n            \n            }", "author": "jbampton", "createdAt": "2020-12-15T15:33:04Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/metrics/WeightedSumMetric.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.solr.client.solrj.io.stream.metrics;\n+\n+import java.io.IOException;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Locale;\n+\n+import org.apache.solr.client.solrj.io.Tuple;\n+import org.apache.solr.client.solrj.io.stream.expr.StreamExpression;\n+import org.apache.solr.client.solrj.io.stream.expr.StreamExpressionParameter;\n+import org.apache.solr.client.solrj.io.stream.expr.StreamFactory;\n+\n+public class WeightedSumMetric extends Metric {\n+\n+  public static final String FUNC = \"wsum\";\n+\n+  private static final class Part {\n+    private final double value;\n+    private final long count;\n+\n+    Part(long count, double value) {\n+      this.count = count;\n+      this.value = value;\n+    }\n+\n+    double weighted(final long total) {\n+      return ((double) count / total) * value;\n+    }\n+  }\n+\n+  private String valueCol;\n+  private String countCol;\n+  private List<Part> parts;\n+\n+  public WeightedSumMetric(String valueCol, String countCol) {\n+    init(valueCol, countCol, false);\n+  }\n+\n+  public WeightedSumMetric(String valueCol, String countCol, boolean outputLong) {\n+    init(valueCol, countCol, outputLong);\n+  }\n+\n+  public WeightedSumMetric(StreamExpression expression, StreamFactory factory) throws IOException {\n+    // grab all parameters out\n+    String functionName = expression.getFunctionName();\n+    if (!FUNC.equals(functionName)) {\n+      throw new IOException(\"Expected '\" + FUNC + \"' function but found \" + functionName);\n+    }\n+    String valueCol = factory.getValueOperand(expression, 0);\n+    String countCol = factory.getValueOperand(expression, 1);\n+    String outputLong = factory.getValueOperand(expression, 2);\n+\n+    // validate expression contains only what we want.\n+    if (null == valueCol) {\n+      throw new IOException(String.format(Locale.ROOT, \"Invalid expression %s - expected %s(valueCol,countCol)\", expression, FUNC));\n+    }\n+\n+    boolean ol = false;\n+    if (outputLong != null) {\n+      ol = Boolean.parseBoolean(outputLong);\n+    }\n+\n+    init(valueCol, countCol, ol);\n+  }\n+\n+  private void init(String valueCol, String countCol, boolean outputLong) {\n+    this.valueCol = valueCol;\n+    this.countCol = countCol != null ? countCol : \"count(*)\";\n+    this.outputLong = outputLong;\n+    setFunctionName(FUNC);\n+    setIdentifier(FUNC, \"(\", valueCol, \", \" + countCol + \")\");\n+  }\n+\n+  public void update(Tuple tuple) {\n+    Object c = tuple.get(countCol);\n+    Object o = tuple.get(valueCol);\n+    if (c instanceof Number && o instanceof Number) {\n+      if (parts == null) {\n+        parts = new LinkedList<>();\n+      }\n+      Number count = (Number) c;\n+      Number value = (Number) o;\n+      parts.add(new Part(count.longValue(), value.doubleValue()));\n+    }\n+  }\n+\n+  public Metric newInstance() {\n+    return new WeightedSumMetric(valueCol, countCol, outputLong);\n+  }\n+\n+  public String[] getColumns() {\n+    return new String[]{valueCol, countCol};\n+  }\n+\n+  public Number getValue() {\n+    long total = sumCounts();\n+    double wavg = 0d;\n+    for (Part next : parts) {\n+      wavg += next.weighted(total);\n+    }\n+    return outputLong ? Math.round(wavg) : wavg;\n+  }\n+\n+  private long sumCounts() {\n+    long total = 0L;\n+    for (Part next : parts) {\n+      total += next.count;\n+    }\n+    return total;\n+  }\n+\n+  @Override\n+  public StreamExpressionParameter toExpression(StreamFactory factory) throws IOException {\n+    return new StreamExpression(getFunctionName()).withParameter(valueCol).withParameter(countCol).withParameter(Boolean.toString(outputLong));\n+  }\n+}", "originalCommit": "b0a3261cbc0a1ae490e4de43cbb1530584374ab7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzQ0OTI0Nw==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r543449247", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                for (int i=0; i < dists.length; i++) {\n          \n          \n            \n                for (int i = 0; i < dists.length; i++) {", "author": "jbampton", "createdAt": "2020-12-15T15:33:44Z", "path": "solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/ParallelFacetStreamOverAliasTest.java", "diffHunk": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.client.solrj.io.stream;\n+\n+import java.io.IOException;\n+import java.lang.invoke.MethodHandles;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.SortedMap;\n+import java.util.TreeMap;\n+import java.util.UUID;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import org.apache.commons.math3.distribution.NormalDistribution;\n+import org.apache.commons.math3.random.JDKRandomGenerator;\n+import org.apache.commons.math3.random.RandomGenerator;\n+import org.apache.commons.math3.util.Precision;\n+import org.apache.lucene.util.LuceneTestCase;\n+import org.apache.solr.SolrTestCaseJ4;\n+import org.apache.solr.client.solrj.SolrServerException;\n+import org.apache.solr.client.solrj.io.SolrClientCache;\n+import org.apache.solr.client.solrj.io.Tuple;\n+import org.apache.solr.client.solrj.io.stream.expr.StreamFactory;\n+import org.apache.solr.client.solrj.request.CollectionAdminRequest;\n+import org.apache.solr.client.solrj.request.UpdateRequest;\n+import org.apache.solr.cloud.SolrCloudTestCase;\n+import org.apache.solr.handler.SolrDefaultStreamFactory;\n+import org.apache.solr.util.LogLevel;\n+import org.apache.solr.util.RTimer;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * objective of this test suite is to test scalability of Streaming expressions for large deployments,\n+ * for example where there are many collections with high sharding and each collection has millions of documents\n+ */\n+@SolrTestCaseJ4.SuppressSSL\n+@LuceneTestCase.SuppressCodecs({\"Lucene3x\", \"Lucene40\", \"Lucene41\", \"Lucene42\", \"Lucene45\"})\n+@LogLevel(\"org.apache.solr.client.solrj.io.stream=INFO;org.apache.solr.common.cloud.ZkStateReader=WARN;org.apache.solr.metrics=WARN;org.apache.solr.core.SolrCore=WARN;org.apache.solr.cloud=WARN;org.apache.solr.update=WARN;org.apache.solr.rest=ERROR;org.apache.solr.servlet.HttpSolrCall=WARN;org.apache.solr=WARN;org.apache.solr.client.solrj.impl=INFO\")\n+public class ParallelFacetStreamOverAliasTest extends SolrCloudTestCase {\n+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());\n+\n+  private static final String ALIAS_NAME = \"SOME_ALIAS_WITH_MANY_COLLS\";\n+\n+  private static final String id = \"id\";\n+  private static final int NUM_COLLECTIONS = 2;\n+  private static final int NUM_DOCS_PER_COLLECTION = 40;\n+  private static final int NUM_SHARDS_PER_COLLECTION = 4;\n+  private static final int CARD = 10;\n+\n+  private static List<String> listOfCollections;\n+  private static final RandomGenerator rand = new JDKRandomGenerator(5150);\n+\n+  @BeforeClass\n+  public static void setupCluster() throws Exception {\n+    final RTimer timer = new RTimer();\n+    configureCluster(NUM_COLLECTIONS).withMetrics(false)\n+        .addConfig(\"conf\", getFile(\"solrj\").toPath().resolve(\"solr\").resolve(\"configsets\").resolve(\"streaming\").resolve(\"conf\"))\n+        .configure();\n+    cleanup();\n+    setupCollectionsAndAlias();\n+\n+    if (log.isInfoEnabled())\n+      log.info(\"Took {}ms to setup cluster with {} collections\", timer.getTime(), NUM_COLLECTIONS);\n+  }\n+\n+  /**\n+   * setup the testbed with necessary collections, documents, and alias\n+   */\n+  public static void setupCollectionsAndAlias() throws Exception {\n+\n+    final NormalDistribution[] dists = new NormalDistribution[CARD];\n+    for (int i=0; i < dists.length; i++) {", "originalCommit": "b0a3261cbc0a1ae490e4de43cbb1530584374ab7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "dfb70cb8048ea136e8f1f3835e2b5a836c956bb8", "url": "https://github.com/apache/lucene-solr/commit/dfb70cb8048ea136e8f1f3835e2b5a836c956bb8", "message": "Drill expr wip", "committedDate": "2020-12-16T22:18:46Z", "type": "commit"}, {"oid": "87c5034038a4bb51b76eb1e45afd32afa3c7e127", "url": "https://github.com/apache/lucene-solr/commit/87c5034038a4bb51b76eb1e45afd32afa3c7e127", "message": "Merge remote-tracking branch 'asf/master' into SOLR-15036", "committedDate": "2020-12-16T22:18:59Z", "type": "commit"}, {"oid": "5d5ba27571b50059856ef181c28434d9d95465be", "url": "https://github.com/apache/lucene-solr/commit/5d5ba27571b50059856ef181c28434d9d95465be", "message": "Merge remote-tracking branch 'asf/master' into SOLR-15036", "committedDate": "2020-12-16T22:42:44Z", "type": "commit"}, {"oid": "f4afe16c778844c1e2d8c71a15b3a022e283bb1a", "url": "https://github.com/apache/lucene-solr/commit/f4afe16c778844c1e2d8c71a15b3a022e283bb1a", "message": "Merge remote-tracking branch 'asf/master' into SOLR-15036", "committedDate": "2021-01-06T14:57:37Z", "type": "commit"}, {"oid": "c2f8d69ef0024f589bb65229199bcf28781c71e9", "url": "https://github.com/apache/lucene-solr/commit/c2f8d69ef0024f589bb65229199bcf28781c71e9", "message": "WIP: some code clean-up", "committedDate": "2021-01-07T18:57:08Z", "type": "commit"}, {"oid": "e7b7fd3a3448fc95cbc5564152a269b7ad6c7602", "url": "https://github.com/apache/lucene-solr/commit/e7b7fd3a3448fc95cbc5564152a269b7ad6c7602", "message": "restore original version", "committedDate": "2021-01-07T18:57:55Z", "type": "commit"}, {"oid": "e07d0abe670de9149ae74b56fb80dbcdae90c5a1", "url": "https://github.com/apache/lucene-solr/commit/e07d0abe670de9149ae74b56fb80dbcdae90c5a1", "message": "Merge remote-tracking branch 'asf/master' into SOLR-15036", "committedDate": "2021-01-07T18:58:14Z", "type": "commit"}, {"oid": "fc7dc2d681a284d4277d38c16c740a581da28ae9", "url": "https://github.com/apache/lucene-solr/commit/fc7dc2d681a284d4277d38c16c740a581da28ae9", "message": "Add Javadoc for ParallelMetricsRollup and fix-up check issues", "committedDate": "2021-01-07T19:26:56Z", "type": "commit"}, {"oid": "978787f8b0893f2fccf2bb96b0e993b4fa0b379e", "url": "https://github.com/apache/lucene-solr/commit/978787f8b0893f2fccf2bb96b0e993b4fa0b379e", "message": "No need to expose the rollup sort comparator in the ParallelMetricsRollup interface", "committedDate": "2021-01-08T00:04:42Z", "type": "commit"}, {"oid": "97d0218640cd29839ed33d46ac9e4fa0cb03edce", "url": "https://github.com/apache/lucene-solr/commit/97d0218640cd29839ed33d46ac9e4fa0cb03edce", "message": "Merge remote-tracking branch 'asf/master' into SOLR-15036", "committedDate": "2021-01-08T00:35:50Z", "type": "commit"}, {"oid": "83bae9c8cd681001fee303b34ed61bb746caba3e", "url": "https://github.com/apache/lucene-solr/commit/83bae9c8cd681001fee303b34ed61bb746caba3e", "message": "Add unit test for WeightedSumMetric", "committedDate": "2021-01-08T16:07:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDA1MjU3Mg==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r554052572", "bodyText": "This refactor makes use of the enhancement provided by SOLR-14987 to reuse HttpSolrClients per host vs. one per replica", "author": "thelabdude", "createdAt": "2021-01-08T16:34:11Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/DrillStream.java", "diffHunk": "@@ -252,29 +253,27 @@ public void setStreamContext(StreamContext streamContext) {\n   }\n \n   protected void constructStreams() throws IOException {\n-\n     try {\n-\n       Object pushStream = ((Expressible) tupleStream).toExpression(streamFactory);\n-\n-      List<String> shardUrls = getShards(this.zkHost, this.collection, this.streamContext);\n-\n-      for(int w=0; w<shardUrls.size(); w++) {\n-        ModifiableSolrParams paramsLoc = new ModifiableSolrParams();\n-        paramsLoc.set(DISTRIB,\"false\"); // We are the aggregator.\n-        paramsLoc.set(\"expr\", pushStream.toString());\n-        paramsLoc.set(\"qt\",\"/export\");\n-        paramsLoc.set(\"fl\", fl);\n-        paramsLoc.set(\"sort\", sort);\n-        paramsLoc.set(\"q\", q);\n-        String url = shardUrls.get(w);\n-        SolrStream solrStream = new SolrStream(url, paramsLoc);\n+      final ModifiableSolrParams paramsLoc = new ModifiableSolrParams();\n+      paramsLoc.set(DISTRIB,\"false\"); // We are the aggregator.\n+      paramsLoc.set(\"expr\", pushStream.toString());\n+      paramsLoc.set(\"qt\",\"/export\");\n+      paramsLoc.set(\"fl\", fl);\n+      paramsLoc.set(\"sort\", sort);\n+      paramsLoc.set(\"q\", q);\n+      getReplicas(this.zkHost, this.collection, this.streamContext, paramsLoc).forEach(r -> {", "originalCommit": "83bae9c8cd681001fee303b34ed61bb746caba3e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e3df84cb6929c89fec8d37350d256b4b30868d57", "url": "https://github.com/apache/lucene-solr/commit/e3df84cb6929c89fec8d37350d256b4b30868d57", "message": "Remove unused log", "committedDate": "2021-01-08T16:34:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDA1NDI3NA==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r554054274", "bodyText": "This source file did not adhere to the community code format so I reformatted it. It's bad practice in general, but since my PR was getting dinged for format issues, I chose to fix globally in this file vs. piecemeal.", "author": "thelabdude", "createdAt": "2021-01-08T16:37:09Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/FacetStream.java", "diffHunk": "@@ -20,15 +20,19 @@\n import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Collections;\n+import java.util.HashMap;", "originalCommit": "e3df84cb6929c89fec8d37350d256b4b30868d57", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDA1NDgxMA==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r554054810", "bodyText": "this is the main hook to see if the auto-plist approach should apply to this facet expression", "author": "thelabdude", "createdAt": "2021-01-08T16:38:09Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/FacetStream.java", "diffHunk": "@@ -537,14 +555,29 @@ public void setStreamContext(StreamContext context) {\n   }\n \n   public void open() throws IOException {\n-    if(cache != null) {\n+    if (cache != null) {\n       cloudSolrClient = cache.getCloudSolrClient(zkHost);\n     } else {\n       final List<String> hosts = new ArrayList<>();\n       hosts.add(zkHost);\n       cloudSolrClient = new Builder(hosts, Optional.empty()).withSocketTimeout(30000).withConnectionTimeout(15000).build();\n     }\n \n+    // Parallelize the facet expression across multiple collections for an alias using plist if possible\n+    if (params.getBool(\"plist\", defaultPlistEnabled)) {", "originalCommit": "e3df84cb6929c89fec8d37350d256b4b30868d57", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDA1NTM2MA==", "url": "https://github.com/apache/lucene-solr/pull/2132#discussion_r554055360", "bodyText": "Implementation of the ParallelMetricsRollup interface starts here ...", "author": "thelabdude", "createdAt": "2021-01-08T16:39:08Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/FacetStream.java", "diffHunk": "@@ -842,10 +881,99 @@ public int getCost() {\n \n   @Override\n   public StreamComparator getStreamSort() {\n-    if(bucketSorts.length > 1) {\n-      return new MultipleFieldComparator(bucketSorts);\n+    return (bucketSorts.length > 1) ? new MultipleFieldComparator(bucketSorts) : bucketSorts[0];\n+  }\n+\n+  @Override", "originalCommit": "e3df84cb6929c89fec8d37350d256b4b30868d57", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a678e4d72c1f2d50443c0f9781fdbebcde87a00d", "url": "https://github.com/apache/lucene-solr/commit/a678e4d72c1f2d50443c0f9781fdbebcde87a00d", "message": "Merge remote-tracking branch 'asf/master' into SOLR-15036", "committedDate": "2021-01-08T16:42:33Z", "type": "commit"}, {"oid": "2d463af9d4afe82e238940a9a8748109e5ee8ec8", "url": "https://github.com/apache/lucene-solr/commit/2d463af9d4afe82e238940a9a8748109e5ee8ec8", "message": "Update changes.txt and add ref guide doc for plist option", "committedDate": "2021-01-08T17:01:28Z", "type": "commit"}, {"oid": "c8057236df3866b5f9283e516f16e01df030b747", "url": "https://github.com/apache/lucene-solr/commit/c8057236df3866b5f9283e516f16e01df030b747", "message": "Switch to using tiered for opt-in/out and revert reformatting changes to FacetStream", "committedDate": "2021-01-08T21:15:03Z", "type": "commit"}, {"oid": "e5ca8770d8e38d4d42619ac17786d9b194c6d321", "url": "https://github.com/apache/lucene-solr/commit/e5ca8770d8e38d4d42619ac17786d9b194c6d321", "message": "Merge remote-tracking branch 'asf/master' into SOLR-15036", "committedDate": "2021-01-08T22:07:12Z", "type": "commit"}, {"oid": "ee22336f516e8724d33702f121d28639dfe19eaf", "url": "https://github.com/apache/lucene-solr/commit/ee22336f516e8724d33702f121d28639dfe19eaf", "message": "Add unit test for facet with multi-dimensions to verify sorting logic", "committedDate": "2021-01-09T18:31:15Z", "type": "commit"}, {"oid": "531962b587506b071df726cf189fabd51321b1dd", "url": "https://github.com/apache/lucene-solr/commit/531962b587506b071df726cf189fabd51321b1dd", "message": "Refactor test to remove duplication", "committedDate": "2021-01-09T18:52:23Z", "type": "commit"}, {"oid": "06d822b3721b67adbb0e02e25a56d0e146563287", "url": "https://github.com/apache/lucene-solr/commit/06d822b3721b67adbb0e02e25a56d0e146563287", "message": "Merge remote-tracking branch 'asf/master' into SOLR-15036", "committedDate": "2021-01-09T18:52:32Z", "type": "commit"}, {"oid": "21d6844895c621a5875f29ce04ca0f182c7d68fc", "url": "https://github.com/apache/lucene-solr/commit/21d6844895c621a5875f29ce04ca0f182c7d68fc", "message": "Merge remote-tracking branch 'asf/master' into SOLR-15036", "committedDate": "2021-01-11T15:09:22Z", "type": "commit"}, {"oid": "223fbcddd23ee2c40ebe69ec86c876a7720a1b7e", "url": "https://github.com/apache/lucene-solr/commit/223fbcddd23ee2c40ebe69ec86c876a7720a1b7e", "message": "use bucket sort order for rollup if it includes all bucket fields and skip the final re-sort", "committedDate": "2021-01-11T15:43:19Z", "type": "commit"}, {"oid": "53a51553f9ba5c875e045979e832bd4d03b09d7f", "url": "https://github.com/apache/lucene-solr/commit/53a51553f9ba5c875e045979e832bd4d03b09d7f", "message": "check resort needed before using the stream sort for the rollup sort", "committedDate": "2021-01-11T16:12:55Z", "type": "commit"}, {"oid": "0d7f0d3c9414b76547c82769c4ecb7acb50e23fe", "url": "https://github.com/apache/lucene-solr/commit/0d7f0d3c9414b76547c82769c4ecb7acb50e23fe", "message": "Switch to using a HashRollupStream vs. Rollup with sort", "committedDate": "2021-01-11T16:56:22Z", "type": "commit"}]}