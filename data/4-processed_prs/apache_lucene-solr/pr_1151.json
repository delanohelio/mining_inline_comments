{"pr_number": 1151, "pr_title": "SOLR-13890: Add \"top-level\" DVTQ implementation", "pr_createdAt": "2020-01-07T12:27:29Z", "pr_url": "https://github.com/apache/lucene-solr/pull/1151", "timeline": [{"oid": "aaa6765fdd337973f07f8d35791a2a3408f2b3d7", "url": "https://github.com/apache/lucene-solr/commit/aaa6765fdd337973f07f8d35791a2a3408f2b3d7", "message": "SOLR-13890: Add \"top-level\" DVTQ implementation", "committedDate": "2020-01-06T20:25:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc0MDEwMg==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r363740102", "bodyText": "Is this just a minor improvement or is it necessary?  If just some minor improvement, I recommend you don't touch Lucene in a Solr PR.", "author": "dsmiley", "createdAt": "2020-01-07T13:11:16Z", "path": "lucene/core/src/java/org/apache/lucene/search/TwoPhaseIterator.java", "diffHunk": "@@ -64,7 +64,7 @@ public static TwoPhaseIterator unwrap(DocIdSetIterator iterator) {\n \n     TwoPhaseIteratorAsDocIdSetIterator(TwoPhaseIterator twoPhaseIterator) {\n       this.twoPhaseIterator = twoPhaseIterator;\n-      this.approximation = twoPhaseIterator.approximation;\n+      this.approximation = twoPhaseIterator.approximation();", "originalCommit": "aaa6765fdd337973f07f8d35791a2a3408f2b3d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDE5MjQ5MQ==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r364192491", "bodyText": "It was necessary with the TopLevelTwoPhaseIterator approach in previous versions of this patch, but is not necessary now.  Removing.", "author": "gerlowskija", "createdAt": "2020-01-08T11:46:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc0MDEwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc0MDI2Nw==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r363740267", "bodyText": "\"withvery\" -- add space.", "author": "dsmiley", "createdAt": "2020-01-07T13:11:44Z", "path": "solr/CHANGES.txt", "diffHunk": "@@ -187,6 +187,11 @@ Improvements\n   hl.fragsizeIsMinimum, with defaults that aim to better center matches in fragments than previously. See the ref guide.\n   Regardless of the settings, the passages may be sized differently than before. (N\u00e1ndor M\u00e1trav\u00f6lgyi, David Smiley)\n \n+* SOLR-13890: Add \"top-level\" DV implementation for {!terms} queries.  This approach tends to be more efficient for\n+  queries withvery large numbers of terms.  The new implementation is used by default for method=docValuesTermsFilter", "originalCommit": "aaa6765fdd337973f07f8d35791a2a3408f2b3d7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc0NDcwMg==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r363744702", "bodyText": "Instead of yet another local-param, maybe \"method\" could be docValuesTermsFilterTopLevel and docValuesTermsFilterTopLevel.  The existing docValuesTermsFilter could dispatch to either of those.", "author": "dsmiley", "createdAt": "2020-01-07T13:23:22Z", "path": "solr/core/src/java/org/apache/solr/search/TermsQParserPlugin.java", "diffHunk": "@@ -79,20 +88,34 @@ Query makeFilter(String fname, BytesRef[] byteRefs) {\n     },\n     automaton {\n       @Override\n-      Query makeFilter(String fname, BytesRef[] byteRefs) {\n+      Query makeFilter(String fname, BytesRef[] byteRefs, SolrParams localParams) {\n         ArrayUtil.timSort(byteRefs); // same sort algo as TermInSetQuery's choice\n         Automaton union = Automata.makeStringUnion(Arrays.asList(byteRefs)); // input must be sorted\n         return new AutomatonQuery(new Term(fname), union);//constant scores\n       }\n     },\n     docValuesTermsFilter {//on 4x this is FieldCacheTermsFilter but we use the 5x name any way\n       @Override\n-      Query makeFilter(String fname, BytesRef[] byteRefs) {\n-        return new DocValuesTermsQuery(fname, byteRefs);//constant scores\n+      Query makeFilter(String fname, BytesRef[] byteRefs, SolrParams localParams) {\n+        final String type = localParams.get(SUBMETHOD);", "originalCommit": "aaa6765fdd337973f07f8d35791a2a3408f2b3d7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc0NTAzNA==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r363745034", "bodyText": "Instead the line above \"NoEx\" could be removed and then we get an exception", "author": "dsmiley", "createdAt": "2020-01-07T13:24:08Z", "path": "solr/core/src/java/org/apache/solr/search/TermsQParserPlugin.java", "diffHunk": "@@ -102,6 +125,9 @@ public QParser createParser(String qstr, SolrParams localParams, SolrParams para\n       public Query parse() throws SyntaxError {\n         String fname = localParams.get(QueryParsing.F);\n         FieldType ft = req.getSchema().getFieldTypeNoEx(fname);\n+        if (ft == null) {\n+          throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"Field name [\" + fname + \"] does not exist\");", "originalCommit": "aaa6765fdd337973f07f8d35791a2a3408f2b3d7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc0NTQ1MA==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r363745450", "bodyText": "I don't think you need this class; it seems more confusing than it is useful", "author": "dsmiley", "createdAt": "2020-01-07T13:25:19Z", "path": "solr/core/src/java/org/apache/solr/search/TermsQParserPlugin.java", "diffHunk": "@@ -138,8 +164,128 @@ public Query parse() throws SyntaxError {\n           bytesRefs[i] = term.toBytesRef();\n         }\n \n-        return method.makeFilter(fname, bytesRefs);\n+        return method.makeFilter(fname, bytesRefs, localParams);\n       }\n     };\n   }\n+\n+  private static abstract class TopLevelTwoPhaseIterator extends TwoPhaseIterator {", "originalCommit": "aaa6765fdd337973f07f8d35791a2a3408f2b3d7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc1MDA3Nw==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r363750077", "bodyText": "I wouldn't bother implementing ExtendedQuery.  If we want to tweak defaults, we should probably do so to affect all docValuesTermsQuery (both sub-methods) and that can be done by replacing QParser.localParams wrapped with one setting defaults we choose in our QParser.", "author": "dsmiley", "createdAt": "2020-01-07T13:37:33Z", "path": "solr/core/src/java/org/apache/solr/search/TermsQParserPlugin.java", "diffHunk": "@@ -138,8 +164,128 @@ public Query parse() throws SyntaxError {\n           bytesRefs[i] = term.toBytesRef();\n         }\n \n-        return method.makeFilter(fname, bytesRefs);\n+        return method.makeFilter(fname, bytesRefs, localParams);\n       }\n     };\n   }\n+\n+  private static abstract class TopLevelTwoPhaseIterator extends TwoPhaseIterator {\n+    private final int docBase;\n+    private final int nextDocBase;\n+    public TopLevelTwoPhaseIterator(DocIdSetIterator approximation, int docBase, int nextDocBase) {\n+      super(new PerSegmentViewDocIdSetIterator(approximation, docBase, nextDocBase));\n+\n+      this.docBase = docBase;\n+      this.nextDocBase = nextDocBase;\n+    }\n+  }\n+\n+  private static class TopLevelDocValuesTermsQuery extends DocValuesTermsQuery implements ExtendedQuery{", "originalCommit": "aaa6765fdd337973f07f8d35791a2a3408f2b3d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDIxNTI5NA==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r364215294", "bodyText": "Will that work?  My understanding was that SolrIndexSearcher uses cost/cache iff it notices its working with an ExtendedQuery that has getCost/getCache methods it can use. (i.e. it uses those specific methods, it doesn't root around in SolrParams objects looking for cost/cache param values.)", "author": "gerlowskija", "createdAt": "2020-01-08T12:52:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc1MDA3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDI5MzE2NA==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r364293164", "bodyText": "It will because QParser.getQuery will wrap the query produced by parse() if it's not already an ExtendedQuery.", "author": "dsmiley", "createdAt": "2020-01-08T15:35:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc1MDA3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc1MzE5NA==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r363753194", "bodyText": "Can you make this an inner class of topLevelDocValuesTermsQuery or anonymous?  If there is a future need to share it then I think we should pull it out.  I doubt it's as generally useful to be a standalone public class.\nAfter further review, I don't think we need the functionality here at all... see my future feedback", "author": "dsmiley", "createdAt": "2020-01-07T13:45:02Z", "path": "solr/core/src/java/org/apache/solr/search/PerSegmentViewDocIdSetIterator.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.solr.search;\n+\n+import java.io.IOException;\n+\n+import org.apache.lucene.search.DocIdSetIterator;\n+\n+/**\n+ * A {@link org.apache.lucene.search.DocIdSetIterator} which allows single-segment access to a wrapped top-level (multi-segment) DISI.\n+ *\n+ * Useful as a shim between a top-level data structure, and logic that attempts to operate on it using segment-level docIds.\n+ * The same wrapped DISI can be used serially by multiple PerSegmentViewDocIdSetIterators\n+ */\n+public class PerSegmentViewDocIdSetIterator extends DocIdSetIterator {", "originalCommit": "aaa6765fdd337973f07f8d35791a2a3408f2b3d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDE5MzQwMQ==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r364193401", "bodyText": "Removed entirely per your future feedback", "author": "gerlowskija", "createdAt": "2020-01-08T11:49:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc1MzE5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc1ODgyNw==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r363758827", "bodyText": "I see that you are using the top level sortedSetDocValues as a DocIdSetIterator approximation.  I can see this works but I think we needn't get that complex, and we miss out on other optimizations by doing so.  I'll post PR comment on how to replace it in a way that also removes TopLevelTwoPhaseIterator.", "author": "dsmiley", "createdAt": "2020-01-07T13:58:08Z", "path": "solr/core/src/java/org/apache/solr/search/TermsQParserPlugin.java", "diffHunk": "@@ -138,8 +164,128 @@ public Query parse() throws SyntaxError {\n           bytesRefs[i] = term.toBytesRef();\n         }\n \n-        return method.makeFilter(fname, bytesRefs);\n+        return method.makeFilter(fname, bytesRefs, localParams);\n       }\n     };\n   }\n+\n+  private static abstract class TopLevelTwoPhaseIterator extends TwoPhaseIterator {\n+    private final int docBase;\n+    private final int nextDocBase;\n+    public TopLevelTwoPhaseIterator(DocIdSetIterator approximation, int docBase, int nextDocBase) {\n+      super(new PerSegmentViewDocIdSetIterator(approximation, docBase, nextDocBase));\n+\n+      this.docBase = docBase;\n+      this.nextDocBase = nextDocBase;\n+    }\n+  }\n+\n+  private static class TopLevelDocValuesTermsQuery extends DocValuesTermsQuery implements ExtendedQuery{\n+    private final String fieldName;\n+    private SortedSetDocValues values;\n+    private LongBitSet queryTermOrdinals;\n+    private boolean matchesAtLeastOneTerm = false;\n+    private boolean cache = true;\n+    private boolean cacheSeparately = false;\n+    private int cost;\n+\n+\n+    public TopLevelDocValuesTermsQuery(String field, BytesRef... terms) {\n+      super(field, terms);\n+      this.fieldName = field;\n+    }\n+\n+    public Weight createWeight(IndexSearcher searcher, final ScoreMode scoreMode, float boost) throws IOException {\n+      values = DocValues.getSortedSet(((SolrIndexSearcher)searcher).getSlowAtomicReader(), fieldName);\n+      queryTermOrdinals = new LongBitSet(values.getValueCount());\n+      PrefixCodedTerms.TermIterator iterator = getTerms().iterator();\n+\n+      long lastOrdFound = 0;\n+      for(BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n+        long ord = lookupTerm(values, term, lastOrdFound);\n+        if (ord >= 0L) {\n+          matchesAtLeastOneTerm = true;\n+          queryTermOrdinals.set(ord);\n+          lastOrdFound = ord;\n+        }\n+      }\n+\n+      return new ConstantScoreWeight(this, boost) {\n+        public Scorer scorer(LeafReaderContext context) throws IOException {", "originalCommit": "aaa6765fdd337973f07f8d35791a2a3408f2b3d7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc1OTI3MQ==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r363759271", "bodyText": "I suggest renaming to \"topDocValues\".   The \"top\"-ness vs \"segment\" needs to be made more clear in all variables names here because we dance between them.", "author": "dsmiley", "createdAt": "2020-01-07T13:59:04Z", "path": "solr/core/src/java/org/apache/solr/search/TermsQParserPlugin.java", "diffHunk": "@@ -138,8 +164,128 @@ public Query parse() throws SyntaxError {\n           bytesRefs[i] = term.toBytesRef();\n         }\n \n-        return method.makeFilter(fname, bytesRefs);\n+        return method.makeFilter(fname, bytesRefs, localParams);\n       }\n     };\n   }\n+\n+  private static abstract class TopLevelTwoPhaseIterator extends TwoPhaseIterator {\n+    private final int docBase;\n+    private final int nextDocBase;\n+    public TopLevelTwoPhaseIterator(DocIdSetIterator approximation, int docBase, int nextDocBase) {\n+      super(new PerSegmentViewDocIdSetIterator(approximation, docBase, nextDocBase));\n+\n+      this.docBase = docBase;\n+      this.nextDocBase = nextDocBase;\n+    }\n+  }\n+\n+  private static class TopLevelDocValuesTermsQuery extends DocValuesTermsQuery implements ExtendedQuery{\n+    private final String fieldName;\n+    private SortedSetDocValues values;\n+    private LongBitSet queryTermOrdinals;\n+    private boolean matchesAtLeastOneTerm = false;\n+    private boolean cache = true;\n+    private boolean cacheSeparately = false;\n+    private int cost;\n+\n+\n+    public TopLevelDocValuesTermsQuery(String field, BytesRef... terms) {\n+      super(field, terms);\n+      this.fieldName = field;\n+    }\n+\n+    public Weight createWeight(IndexSearcher searcher, final ScoreMode scoreMode, float boost) throws IOException {\n+      values = DocValues.getSortedSet(((SolrIndexSearcher)searcher).getSlowAtomicReader(), fieldName);", "originalCommit": "aaa6765fdd337973f07f8d35791a2a3408f2b3d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc3NDA0OQ==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r363774049", "bodyText": "Another naming proposal is global_ordinals.", "author": "mkhludnev", "createdAt": "2020-01-07T14:31:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc1OTI3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDE5NzcxNQ==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r364197715", "bodyText": "I went with topLevelDocValues, as topDocValues might sounds like a PQueue or a list to those unfamiliar with the code.", "author": "gerlowskija", "createdAt": "2020-01-08T12:02:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc1OTI3MQ=="}], "type": "inlineReview"}, {"oid": "cf1b39aaa9295461ed8514b14fff0cf38e10ed79", "url": "https://github.com/apache/lucene-solr/commit/cf1b39aaa9295461ed8514b14fff0cf38e10ed79", "message": "SOLR-13890: Address review comments\n\nThanks to David and Mikhail for review.", "committedDate": "2020-01-08T12:36:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDI5ODc5Nw==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r364298797", "bodyText": "The advice about commit frequently and thus add a static warming query is very debatable.  \"commit frequently\" ~= NRT and NRT users want to dial down caching, even eliminate.  But but maybe they can tolerate longer latency for freshness provided the query response time isn't incurring costs post-commit.  There's no universal answer.  Yet you did say \"you may benefit\" so I guess what you wrote is fine.", "author": "dsmiley", "createdAt": "2020-01-08T15:45:34Z", "path": "solr/solr-ref-guide/src/other-parsers.adoc", "diffHunk": "@@ -1031,13 +1031,17 @@ The field on which to search. This parameter is required.\n Separator to use when parsing the input. If set to \" \" (a single blank space), will trim additional white space from the input terms. Defaults to  a comma (`,`).\n \n `method`::\n-An optional parameter used to determine which of several query implementations should be used by Solr.  Options are restricted to: `termsFilter`, `booleanQuery`, `automaton`, or `docValuesTermsFilter`.  If unspecified, the default value is `termsFilter`.  Each implementation has its own performance characteristics, and users are encouraged to experiment to determine which implementation is most performant for their use-case.  Heuristics are given below.\n+An optional parameter used to determine which of several query implementations should be used by Solr.  Options are restricted to: `termsFilter`, `booleanQuery`, `automaton`, `docValuesTermsFilterPerSegment`, `docValuesTermsFilterTopLevel` or `docValuesTermsFilter`.  If unspecified, the default value is `termsFilter`.  Each implementation has its own performance characteristics, and users are encouraged to experiment to determine which implementation is most performant for their use-case.  Heuristics are given below.\n +\n `booleanQuery` creates a `BooleanQuery` representing the request.  Scales well with index size, but poorly with the number of terms being searched for.\n +\n `termsFilter` the default `method`.  Uses a `BooleanQuery` or a `TermInSetQuery` depending on the number of terms.  Scales well with index size, but only moderately with the number of query terms.\n +\n-`docValuesTermsFilter` uses doc values data structures to process the request.  This method scales well to a large numbers of query terms.  It encompasses two implementations or submethods.  Solr uses heuristics to choose between these at runtime, but users can also pick explicitly by providing a `submethod` parameter with either `toplevel` or `persegment` as a value.  The `persegment` implementation is more general purpose, while `toplevel` is geared for anyone with particularly high numbers of query terms (several hundred to several thousand).  The `toplevel` submethod relies on data structures which are lazily populated after each commit.  If you use this submethod and commit frequently, you may benefit from adding a static warming query to `solrconfig.xml` so that this is done as a part of the commit, and doesn't slow down user requests.\n+`docValuesTermsFilter` chooses between the `docValuesTermsFilterTopLevel` and `docValuesTermsFilterPerSegment` methods (see below) using the number of query terms as a rough heuristic.  Users should typically use this method instead of using `docValuesTermsFilterTopLevel` or `docValuesTermsFilterPerSegment` directly, unless they've done performance testing to validate one or the other methods on queries of all sizes. Depending on the implementation picked, this method may rely on expensive data structures which are lazily populated after each commit.  If you commit frequently, you may benefit from adding a static warming query to `solrconfig.xml` so that this is done as a part of the commit itself and not attached directly to user requests.\n++\n+`docValuesTermsFilterTopLevel` uses top-level doc values data structures to find results.  These data structures are more efficient as the number of query terms grows high (over several hundred). But they are also expensive to build and need to be populated lazily after each commit, causing a sometimes-noticeable slowdown on the first query after each commit.  If you commit frequently, you may benefit from adding a static warming query to your `solrconfig.xml` so that this is done as a part of the commit itself and not attached directly to user requests.", "originalCommit": "cf1b39aaa9295461ed8514b14fff0cf38e10ed79", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDM5MzY3Mw==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r364393673", "bodyText": "Hmm, I see your point.  I don't want to take the advice out entirely because the first-query QTime is pretty startling and I don't want that to scare people away.  Maybe I'll leave the warning in but reword it to be a bit more conditional.", "author": "gerlowskija", "createdAt": "2020-01-08T19:05:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDI5ODc5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDI5OTg1Nw==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r364299857", "bodyText": "Maybe right up front here first declare that this method is only appropriate when the field has docValues?  That's more important and differentiates from terms index based methods.", "author": "dsmiley", "createdAt": "2020-01-08T15:47:11Z", "path": "solr/solr-ref-guide/src/other-parsers.adoc", "diffHunk": "@@ -1031,13 +1031,17 @@ The field on which to search. This parameter is required.\n Separator to use when parsing the input. If set to \" \" (a single blank space), will trim additional white space from the input terms. Defaults to  a comma (`,`).\n \n `method`::\n-An optional parameter used to determine which of several query implementations should be used by Solr.  Options are restricted to: `termsFilter`, `booleanQuery`, `automaton`, or `docValuesTermsFilter`.  If unspecified, the default value is `termsFilter`.  Each implementation has its own performance characteristics, and users are encouraged to experiment to determine which implementation is most performant for their use-case.  Heuristics are given below.\n+An optional parameter used to determine which of several query implementations should be used by Solr.  Options are restricted to: `termsFilter`, `booleanQuery`, `automaton`, `docValuesTermsFilterPerSegment`, `docValuesTermsFilterTopLevel` or `docValuesTermsFilter`.  If unspecified, the default value is `termsFilter`.  Each implementation has its own performance characteristics, and users are encouraged to experiment to determine which implementation is most performant for their use-case.  Heuristics are given below.\n +\n `booleanQuery` creates a `BooleanQuery` representing the request.  Scales well with index size, but poorly with the number of terms being searched for.\n +\n `termsFilter` the default `method`.  Uses a `BooleanQuery` or a `TermInSetQuery` depending on the number of terms.  Scales well with index size, but only moderately with the number of query terms.\n +\n-`docValuesTermsFilter` uses doc values data structures to process the request.  This method scales well to a large numbers of query terms.  It encompasses two implementations or submethods.  Solr uses heuristics to choose between these at runtime, but users can also pick explicitly by providing a `submethod` parameter with either `toplevel` or `persegment` as a value.  The `persegment` implementation is more general purpose, while `toplevel` is geared for anyone with particularly high numbers of query terms (several hundred to several thousand).  The `toplevel` submethod relies on data structures which are lazily populated after each commit.  If you use this submethod and commit frequently, you may benefit from adding a static warming query to `solrconfig.xml` so that this is done as a part of the commit, and doesn't slow down user requests.\n+`docValuesTermsFilter` chooses between the `docValuesTermsFilterTopLevel` and `docValuesTermsFilterPerSegment` methods (see below) using the number of query terms as a rough heuristic.  Users should typically use this method instead of using `docValuesTermsFilterTopLevel` or `docValuesTermsFilterPerSegment` directly, unless they've done performance testing to validate one or the other methods on queries of all sizes. Depending on the implementation picked, this method may rely on expensive data structures which are lazily populated after each commit.  If you commit frequently, you may benefit from adding a static warming query to `solrconfig.xml` so that this is done as a part of the commit itself and not attached directly to user requests.", "originalCommit": "cf1b39aaa9295461ed8514b14fff0cf38e10ed79", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDMwMTI1OQ==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r364301259", "bodyText": "\"doesn't have the same advantages\" without also listing some positives here makes me think this method is not useful when really it's excellent.  Lots of users would say 300 queries is a \"large number\", and this method is appropriate.  Also this method is very NRT friendly.", "author": "dsmiley", "createdAt": "2020-01-08T15:49:38Z", "path": "solr/solr-ref-guide/src/other-parsers.adoc", "diffHunk": "@@ -1031,13 +1031,17 @@ The field on which to search. This parameter is required.\n Separator to use when parsing the input. If set to \" \" (a single blank space), will trim additional white space from the input terms. Defaults to  a comma (`,`).\n \n `method`::\n-An optional parameter used to determine which of several query implementations should be used by Solr.  Options are restricted to: `termsFilter`, `booleanQuery`, `automaton`, or `docValuesTermsFilter`.  If unspecified, the default value is `termsFilter`.  Each implementation has its own performance characteristics, and users are encouraged to experiment to determine which implementation is most performant for their use-case.  Heuristics are given below.\n+An optional parameter used to determine which of several query implementations should be used by Solr.  Options are restricted to: `termsFilter`, `booleanQuery`, `automaton`, `docValuesTermsFilterPerSegment`, `docValuesTermsFilterTopLevel` or `docValuesTermsFilter`.  If unspecified, the default value is `termsFilter`.  Each implementation has its own performance characteristics, and users are encouraged to experiment to determine which implementation is most performant for their use-case.  Heuristics are given below.\n +\n `booleanQuery` creates a `BooleanQuery` representing the request.  Scales well with index size, but poorly with the number of terms being searched for.\n +\n `termsFilter` the default `method`.  Uses a `BooleanQuery` or a `TermInSetQuery` depending on the number of terms.  Scales well with index size, but only moderately with the number of query terms.\n +\n-`docValuesTermsFilter` uses doc values data structures to process the request.  This method scales well to a large numbers of query terms.  It encompasses two implementations or submethods.  Solr uses heuristics to choose between these at runtime, but users can also pick explicitly by providing a `submethod` parameter with either `toplevel` or `persegment` as a value.  The `persegment` implementation is more general purpose, while `toplevel` is geared for anyone with particularly high numbers of query terms (several hundred to several thousand).  The `toplevel` submethod relies on data structures which are lazily populated after each commit.  If you use this submethod and commit frequently, you may benefit from adding a static warming query to `solrconfig.xml` so that this is done as a part of the commit, and doesn't slow down user requests.\n+`docValuesTermsFilter` chooses between the `docValuesTermsFilterTopLevel` and `docValuesTermsFilterPerSegment` methods (see below) using the number of query terms as a rough heuristic.  Users should typically use this method instead of using `docValuesTermsFilterTopLevel` or `docValuesTermsFilterPerSegment` directly, unless they've done performance testing to validate one or the other methods on queries of all sizes. Depending on the implementation picked, this method may rely on expensive data structures which are lazily populated after each commit.  If you commit frequently, you may benefit from adding a static warming query to `solrconfig.xml` so that this is done as a part of the commit itself and not attached directly to user requests.\n++\n+`docValuesTermsFilterTopLevel` uses top-level doc values data structures to find results.  These data structures are more efficient as the number of query terms grows high (over several hundred). But they are also expensive to build and need to be populated lazily after each commit, causing a sometimes-noticeable slowdown on the first query after each commit.  If you commit frequently, you may benefit from adding a static warming query to your `solrconfig.xml` so that this is done as a part of the commit itself and not attached directly to user requests.\n++\n+`docValuesTermsFilterPerSegment` uses segment-level doc values data structures to find results.  This is more general purpose than the corresponding \"top level\" method, but doesn't have the same advantages at large numbers of query terms (see above).", "originalCommit": "cf1b39aaa9295461ed8514b14fff0cf38e10ed79", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDMwMjY1NQ==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r364302655", "bodyText": "If not a SolrIndexSearcher than return super.createWeight    (your idea based on Mikhail's comment)", "author": "dsmiley", "createdAt": "2020-01-08T15:52:05Z", "path": "solr/core/src/java/org/apache/solr/search/TermsQParserPlugin.java", "diffHunk": "@@ -142,4 +158,112 @@ public Query parse() throws SyntaxError {\n       }\n     };\n   }\n+\n+  private static class TopLevelDocValuesTermsQuery extends DocValuesTermsQuery implements ExtendedQuery{\n+    private final String fieldName;\n+    private SortedSetDocValues topLevelDocValues;\n+    private LongBitSet topLevelTermOrdinals;\n+    private boolean matchesAtLeastOneTerm = false;\n+    private boolean cache = true;\n+    private boolean cacheSeparately = false;\n+    private int cost;\n+\n+\n+    public TopLevelDocValuesTermsQuery(String field, BytesRef... terms) {\n+      super(field, terms);\n+      this.fieldName = field;\n+    }\n+\n+    public Weight createWeight(IndexSearcher searcher, final ScoreMode scoreMode, float boost) throws IOException {\n+      topLevelDocValues = DocValues.getSortedSet(((SolrIndexSearcher)searcher).getSlowAtomicReader(), fieldName);", "originalCommit": "cf1b39aaa9295461ed8514b14fff0cf38e10ed79", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d02c1f3300af549bdbae379a3bc802c916d3371c", "url": "https://github.com/apache/lucene-solr/commit/d02c1f3300af549bdbae379a3bc802c916d3371c", "message": "SOLR-13890: Address review comments, round 2", "committedDate": "2020-01-08T19:35:45Z", "type": "commit"}, {"oid": "a88e559f4f66fae5b02f73200dc359ee747216e9", "url": "https://github.com/apache/lucene-solr/commit/a88e559f4f66fae5b02f73200dc359ee747216e9", "message": "SOLR-13890: Address review comments, round 2b\n\nMissed the removal of the unnecessary ExtendedQuery methods", "committedDate": "2020-01-08T19:40:38Z", "type": "commit"}, {"oid": "54872295e1fa05a30cfa646fbe85e9fbb9fd92b7", "url": "https://github.com/apache/lucene-solr/commit/54872295e1fa05a30cfa646fbe85e9fbb9fd92b7", "message": "Merge branch 'master' into jira/solr-13890", "committedDate": "2020-01-08T19:42:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTA2NTkzMQ==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r365065931", "bodyText": "Compared to other TPIs, I think 3f is too low.  For example DVTQ (in the superclass) is 3f but we also must call advanceExact on the top level DV.  I suggest 10f.  It's a bike-shed number but I just want more than 3 and much less than 100 which is what some of the no-idea but probably expensive TPIs have.", "author": "dsmiley", "createdAt": "2020-01-10T04:09:44Z", "path": "solr/core/src/java/org/apache/solr/search/TermsQParserPlugin.java", "diffHunk": "@@ -142,4 +158,100 @@ public Query parse() throws SyntaxError {\n       }\n     };\n   }\n+\n+  private static class TopLevelDocValuesTermsQuery extends DocValuesTermsQuery {\n+    private final String fieldName;\n+    private SortedSetDocValues topLevelDocValues;\n+    private LongBitSet topLevelTermOrdinals;\n+    private boolean matchesAtLeastOneTerm = false;\n+\n+\n+    public TopLevelDocValuesTermsQuery(String field, BytesRef... terms) {\n+      super(field, terms);\n+      this.fieldName = field;\n+    }\n+\n+    public Weight createWeight(IndexSearcher searcher, final ScoreMode scoreMode, float boost) throws IOException {\n+      if (! (searcher instanceof SolrIndexSearcher)) {\n+        log.debug(\"Falling back to DocValuesTermsQuery because searcher [{}] is not the required SolrIndexSearcher\", searcher);\n+        return super.createWeight(searcher, scoreMode, boost);\n+      }\n+\n+      topLevelDocValues = DocValues.getSortedSet(((SolrIndexSearcher)searcher).getSlowAtomicReader(), fieldName);\n+      topLevelTermOrdinals = new LongBitSet(topLevelDocValues.getValueCount());\n+      PrefixCodedTerms.TermIterator iterator = getTerms().iterator();\n+\n+      long lastTermOrdFound = 0;\n+      for(BytesRef term = iterator.next(); term != null; term = iterator.next()) {\n+        long currentTermOrd = lookupTerm(topLevelDocValues, term, lastTermOrdFound);\n+        if (currentTermOrd >= 0L) {\n+          matchesAtLeastOneTerm = true;\n+          topLevelTermOrdinals.set(currentTermOrd);\n+          lastTermOrdFound = currentTermOrd;\n+        }\n+      }\n+\n+      return new ConstantScoreWeight(this, boost) {\n+        public Scorer scorer(LeafReaderContext context) throws IOException {\n+          if (! matchesAtLeastOneTerm) {\n+            return null;\n+          }\n+          \n+          SortedSetDocValues segmentDocValues = context.reader().getSortedSetDocValues(fieldName);\n+          if (segmentDocValues == null) {\n+            return null;\n+          }\n+\n+          final int docBase = context.docBase;\n+          return new ConstantScoreScorer(this, this.score(), scoreMode, new TwoPhaseIterator(segmentDocValues) {\n+            public boolean matches() throws IOException {\n+              topLevelDocValues.advanceExact(docBase + approximation.docID());\n+              for(long ord = topLevelDocValues.nextOrd(); ord != -1L; ord = topLevelDocValues.nextOrd()) {\n+                if (topLevelTermOrdinals.get(ord)) {\n+                  return true;\n+                }\n+              }\n+\n+              return false;\n+            }\n+\n+            public float matchCost() {\n+              return 3.0F;", "originalCommit": "54872295e1fa05a30cfa646fbe85e9fbb9fd92b7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTA2Njg3OQ==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r365066879", "bodyText": "I believe Joel argued strongly we should default both DV impls to cache=false?  You can do that here (and in the other method) easily via WrappedQuery wrapper and setting cache=false.  I mentioned another approach that messes with this.localParams but perhaps that might feel hacky compared to WrappedQuery.  Especially so since makeFilter doesn't have access to change the field this.localParams.", "author": "dsmiley", "createdAt": "2020-01-10T04:16:18Z", "path": "solr/core/src/java/org/apache/solr/search/TermsQParserPlugin.java", "diffHunk": "@@ -88,7 +91,20 @@ Query makeFilter(String fname, BytesRef[] byteRefs) {\n     docValuesTermsFilter {//on 4x this is FieldCacheTermsFilter but we use the 5x name any way\n       @Override\n       Query makeFilter(String fname, BytesRef[] byteRefs) {\n-        return new DocValuesTermsQuery(fname, byteRefs);//constant scores\n+        // TODO Further tune this heuristic number\n+        return (byteRefs.length > 700) ? new TopLevelDocValuesTermsQuery(fname, byteRefs) : new DocValuesTermsQuery(fname, byteRefs);\n+      }\n+    },\n+    docValuesTermsFilterTopLevel {\n+      @Override\n+      Query makeFilter(String fname, BytesRef[] byteRefs) {\n+        return new TopLevelDocValuesTermsQuery(fname, byteRefs);", "originalCommit": "54872295e1fa05a30cfa646fbe85e9fbb9fd92b7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMxNTQ3OQ==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r365315479", "bodyText": "I'd forgotten about this, done.\nFWIW I buy Joel's argument that most real-world use-cases are going to require cache=false.  But I worry that users who want caching will be bitten by this.  I guess it depends how hands-on you expect users to be with their query tuning.  For hands-off users, this change is best. But for hands-on users, we've just created a \"gotcha\".\nI'll make sure to add this to the ref-guide docs at the least.", "author": "gerlowskija", "createdAt": "2020-01-10T16:21:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTA2Njg3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTMzNjM0Mw==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r365336343", "bodyText": "This is just about a default.  So-called \"Hands-on users\" (experts) will be able to be explicit with cache=true.", "author": "dsmiley", "createdAt": "2020-01-10T17:05:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTA2Njg3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM0MTk1OA==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r365341958", "bodyText": "Sure, settingcache=true is trivial.  It's knowing that you need to be explicit for this one query in particular that's the tricky part.\nBut I'm just hand-wringing; I've already made the change.  It's documented in the ref-guide, so that's as good as we're going to get.", "author": "gerlowskija", "createdAt": "2020-01-10T17:18:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTA2Njg3OQ=="}], "type": "inlineReview"}, {"oid": "9404d92e0f10e6c9d64255f01c1379549cb81ce8", "url": "https://github.com/apache/lucene-solr/commit/9404d92e0f10e6c9d64255f01c1379549cb81ce8", "message": "SOLR-13890: Address review comments, round 3", "committedDate": "2020-01-10T16:07:25Z", "type": "commit"}, {"oid": "04ba90e18ff0cf94a336a94649f5777261bec8db", "url": "https://github.com/apache/lucene-solr/commit/04ba90e18ff0cf94a336a94649f5777261bec8db", "message": "SOLR-13890: Address review comments, 3b", "committedDate": "2020-01-10T16:25:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM0NDM5Nw==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r365344397", "bodyText": "right here simply call docValuesTermsFilterTopLevel.makeFilter or docValuesTermsFilterPerSegment.makeFilter.  Yes, enum methods may refer to other enums in the same enum :-)", "author": "dsmiley", "createdAt": "2020-01-10T17:24:06Z", "path": "solr/core/src/java/org/apache/solr/search/TermsQParserPlugin.java", "diffHunk": "@@ -92,22 +92,28 @@ Query makeFilter(String fname, BytesRef[] byteRefs) {\n       @Override\n       Query makeFilter(String fname, BytesRef[] byteRefs) {\n         // TODO Further tune this heuristic number\n-        return (byteRefs.length > 700) ? new TopLevelDocValuesTermsQuery(fname, byteRefs) : new DocValuesTermsQuery(fname, byteRefs);\n+        return disableCacheByDefault((byteRefs.length > 700) ? new TopLevelDocValuesTermsQuery(fname, byteRefs) : new DocValuesTermsQuery(fname, byteRefs));", "originalCommit": "9404d92e0f10e6c9d64255f01c1379549cb81ce8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1ODcxNQ==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r365358715", "bodyText": "Hah.  I don't know whether to think that's awesome or revolting.  Done.", "author": "gerlowskija", "createdAt": "2020-01-10T18:01:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM0NDM5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM2NDQ4Nw==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r365364487", "bodyText": "LOL there is something slightly unsettling about it I admit.  Though it's not confusing or anything.  Any way I value brevity over a lot and I'll take it!", "author": "dsmiley", "createdAt": "2020-01-10T18:16:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM0NDM5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM0NTE4NQ==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r365345185", "bodyText": "Just a side-comment about our ref docs:  In the ref docs I write or update, I convert them to one sentence per line.  This makes the diffs easy to read!  The pain of no newlines is very apparent here.  Change or not as you wish.  CC @ctargett", "author": "dsmiley", "createdAt": "2020-01-10T17:26:06Z", "path": "solr/solr-ref-guide/src/other-parsers.adoc", "diffHunk": "@@ -1037,11 +1037,11 @@ An optional parameter used to determine which of several query implementations s\n +\n `termsFilter` the default `method`.  Uses a `BooleanQuery` or a `TermInSetQuery` depending on the number of terms.  Scales well with index size, but only moderately with the number of query terms.\n +\n-`docValuesTermsFilter` can only be used on fields with docValues data.  Chooses between the `docValuesTermsFilterTopLevel` and `docValuesTermsFilterPerSegment` methods using the number of query terms as a rough heuristic.  Users should typically use this method instead of using `docValuesTermsFilterTopLevel` or `docValuesTermsFilterPerSegment` directly, unless they've done performance testing to validate one of the methods on queries of all sizes.  Depending on the implementation picked, this method may rely on expensive data structures which are lazily populated after each commit.  If you commit frequently and your use-case can tolerate a static warming query, consider adding one to `solrconfig.xml` so that this work is done as a part of the commit itself and not attached directly to user requests.\n+`docValuesTermsFilter` can only be used on fields with docValues data.  The `cache` parameter is false by default.  Chooses between the `docValuesTermsFilterTopLevel` and `docValuesTermsFilterPerSegment` methods using the number of query terms as a rough heuristic.  Users should typically use this method instead of using `docValuesTermsFilterTopLevel` or `docValuesTermsFilterPerSegment` directly, unless they've done performance testing to validate one of the methods on queries of all sizes.  Depending on the implementation picked, this method may rely on expensive data structures which are lazily populated after each commit.  If you commit frequently and your use-case can tolerate a static warming query, consider adding one to `solrconfig.xml` so that this work is done as a part of the commit itself and not attached directly to user requests.", "originalCommit": "04ba90e18ff0cf94a336a94649f5777261bec8db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM1NjY2Ng==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r365356666", "bodyText": "I thought about this too when I saw the diff.  I remember it coming up as a discussion point when the ref-guide was initially being hashed out too.\nI won't change my docs here, as it's probably worth keeping the file as a whole consistent in the strategy it uses.  But maybe it's worth revisiting at some point.", "author": "gerlowskija", "createdAt": "2020-01-10T17:55:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM0NTE4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTQwNjI5OQ==", "url": "https://github.com/apache/lucene-solr/pull/1151#discussion_r365406299", "bodyText": "When I think of it, I've been changing to one sentence per line when I'm editing also (but I often forget). I don't know that it really changes that much to have a whole page consistent - we should probably encourage one sentence per line, but if it's a big file and you can only do a little, I think that's fine and maybe someone else will get inspired later to do the rest.", "author": "ctargett", "createdAt": "2020-01-10T19:57:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTM0NTE4NQ=="}], "type": "inlineReview"}, {"oid": "9c676e831c3a118966e3a022074560995d3c1f9f", "url": "https://github.com/apache/lucene-solr/commit/9c676e831c3a118966e3a022074560995d3c1f9f", "message": "SOLR-13890: Address review commends, round 4", "committedDate": "2020-01-10T17:59:41Z", "type": "commit"}]}