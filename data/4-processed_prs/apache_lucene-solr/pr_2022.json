{"pr_number": 2022, "pr_title": "LUCENE-9004: KNN vector search using NSW graphs", "pr_createdAt": "2020-10-23T22:31:19Z", "pr_url": "https://github.com/apache/lucene-solr/pull/2022", "timeline": [{"oid": "9c54fd787413c4763330d2e42ca89d349cc513bc", "url": "https://github.com/apache/lucene-solr/commit/9c54fd787413c4763330d2e42ca89d349cc513bc", "message": "WIP not complete", "committedDate": "2020-10-23T21:40:56Z", "type": "commit"}, {"oid": "350443acbf4d73d76001d947fe66f32d015b864c", "url": "https://github.com/apache/lucene-solr/commit/350443acbf4d73d76001d947fe66f32d015b864c", "message": "restore some changes that got lost when merging commits", "committedDate": "2020-10-23T21:45:08Z", "type": "commit"}, {"oid": "0c70d3ba1bf0102bc5dc0436911a8ad70978d30d", "url": "https://github.com/apache/lucene-solr/commit/0c70d3ba1bf0102bc5dc0436911a8ad70978d30d", "message": "rename ScoreFunction to SearchStrategy", "committedDate": "2020-10-23T22:02:42Z", "type": "commit"}, {"oid": "3e5f2539786c5cfe9cd937f93d7705965833ced4", "url": "https://github.com/apache/lucene-solr/commit/3e5f2539786c5cfe9cd937f93d7705965833ced4", "message": "LUCENE-9582: rename VectorValues.ScoreFunction to SearchStrategy", "committedDate": "2020-10-23T22:04:44Z", "type": "commit"}, {"oid": "b7704f41c3e6eb30bc44d00432f640a0ea0437a4", "url": "https://github.com/apache/lucene-solr/commit/b7704f41c3e6eb30bc44d00432f640a0ea0437a4", "message": "refactor knn graph codec support for better extensibility", "committedDate": "2020-10-23T22:05:52Z", "type": "commit"}, {"oid": "0802b9e6e424a31f66be4bfb3d874456c323d491", "url": "https://github.com/apache/lucene-solr/commit/0802b9e6e424a31f66be4bfb3d874456c323d491", "message": "improve naming and docs", "committedDate": "2020-10-23T22:05:52Z", "type": "commit"}, {"oid": "5a4a744e6adebb5313b9e6d681a795a6540081b7", "url": "https://github.com/apache/lucene-solr/commit/5a4a744e6adebb5313b9e6d681a795a6540081b7", "message": "cleaning up BoundsChecker and added a test", "committedDate": "2020-10-23T22:05:52Z", "type": "commit"}, {"oid": "1d23e48f7ae7352761081fd19eba5f110fd7d011", "url": "https://github.com/apache/lucene-solr/commit/1d23e48f7ae7352761081fd19eba5f110fd7d011", "message": "removed annealing after test showed it is redundant", "committedDate": "2020-10-23T22:05:52Z", "type": "commit"}, {"oid": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "url": "https://github.com/apache/lucene-solr/commit/c10b88a38b25ca52e87be009ed8011ccc1b94683", "message": "move KNN search our of VectorValues.RandomAccess interface", "committedDate": "2020-10-23T22:08:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTIwMjIyNQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r511202225", "bodyText": "PREDICTABLE_RANDOM:  This random generator (java.util.Random) is predictable (details)", "author": "sonatype-lift", "createdAt": "2020-10-24T00:01:15Z", "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorReader.java", "diffHunk": "@@ -165,42 +191,88 @@ public VectorValues getVectorValues(String field) throws IOException {\n     return new OffHeapVectorValues(fieldEntry, bytesSlice);\n   }\n \n+  // exposed for testing\n+  public KnnGraphValues getGraphValues(String field) throws IOException {\n+    FieldInfo info = fieldInfos.fieldInfo(field);\n+    if (info == null) {\n+      throw new IllegalArgumentException(\"No such field '\" + field + \"'\");\n+    }\n+    FieldEntry entry = fields.get(field);\n+    if (entry != null && entry.indexDataLength > 0) {\n+      return getGraphValues(entry);\n+    } else {\n+      return KnnGraphValues.EMPTY;\n+    }\n+  }\n+\n+  private KnnGraphValues getGraphValues(FieldEntry entry) throws IOException {\n+    if (isHnswStrategy(entry.searchStrategy)) {\n+      HnswGraphFieldEntry graphEntry = (HnswGraphFieldEntry) entry;\n+      IndexInput bytesSlice = vectorIndex.slice(\"graph-data\", entry.indexDataOffset, entry.indexDataLength);\n+      return new IndexedKnnGraphReader(graphEntry, bytesSlice);\n+    } else {\n+      return KnnGraphValues.EMPTY;\n+    }\n+  }\n+\n   @Override\n   public void close() throws IOException {\n-    vectorData.close();\n+    IOUtils.close(vectorData, vectorIndex);\n   }\n \n   private static class FieldEntry {\n \n     final int dimension;\n     final VectorValues.SearchStrategy searchStrategy;\n-    final int maxDoc;\n \n     final long vectorDataOffset;\n     final long vectorDataLength;\n+    final long indexDataOffset;\n+    final long indexDataLength;\n     final int[] ordToDoc;\n \n-    FieldEntry(int dimension, VectorValues.SearchStrategy searchStrategy, int maxDoc,\n-               long vectorDataOffset, long vectorDataLength, int[] ordToDoc) {\n-      this.dimension = dimension;\n+    FieldEntry(DataInput input, VectorValues.SearchStrategy searchStrategy) throws IOException {\n       this.searchStrategy = searchStrategy;\n-      this.maxDoc = maxDoc;\n-      this.vectorDataOffset = vectorDataOffset;\n-      this.vectorDataLength = vectorDataLength;\n-      this.ordToDoc = ordToDoc;\n+      vectorDataOffset = input.readVLong();\n+      vectorDataLength = input.readVLong();\n+      indexDataOffset = input.readVLong();\n+      indexDataLength = input.readVLong();\n+      dimension = input.readInt();\n+      int size = input.readInt();\n+      ordToDoc = new int[size];\n+      for (int i = 0; i < size; i++) {\n+        int doc = input.readVInt();\n+        ordToDoc[i] = doc;\n+      }\n     }\n \n     int size() {\n       return ordToDoc.length;\n     }\n   }\n \n+  private static class HnswGraphFieldEntry extends FieldEntry {\n+\n+    final long[] ordOffsets;\n+\n+    HnswGraphFieldEntry(DataInput input, VectorValues.SearchStrategy searchStrategy) throws IOException {\n+      super(input, searchStrategy);\n+      ordOffsets = new long[size()];\n+      long offset = 0;\n+      for (int i = 0; i < ordOffsets.length; i++) {\n+        offset += input.readVLong();\n+        ordOffsets[i] = offset;\n+      }\n+    }\n+  }\n+\n   /** Read the vector values from the index input. This supports both iterated and random access. */\n-  private final static class OffHeapVectorValues extends VectorValues {\n+  private final class OffHeapVectorValues extends VectorValues {\n \n     final FieldEntry fieldEntry;\n     final IndexInput dataIn;\n \n+    final Random random = new Random();", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTIwMjIzNg==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r511202236", "bodyText": "PREDICTABLE_RANDOM:  This random generator (java.util.Random) is predictable (details)", "author": "sonatype-lift", "createdAt": "2020-10-24T00:01:16Z", "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraphBuilder.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Random;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+import org.apache.lucene.util.BytesRef;\n+\n+/**\n+ * Builder for HNSW graph. See {@link HnswGraph} for a gloss on the algorithm and the meaning of the hyperparameters.\n+ */\n+public final class HnswGraphBuilder {\n+\n+  // default random seed for level generation\n+  private static final long DEFAULT_RAND_SEED = System.currentTimeMillis();\n+\n+  // expose for testing.\n+  public static long randSeed = DEFAULT_RAND_SEED;\n+\n+  // These \"default\" hyperparameter settings are exposed (and nonfinal) to enable performance testing\n+  // since the indexing API doesn't provide any control over them.\n+\n+  // default max connections per node\n+  static int DEFAULT_MAX_CONN = 16;\n+\n+  // default candidate list size\n+  static int DEFAULT_BEAM_WIDTH = 16;\n+\n+  private final int maxConn;\n+  private final int beamWidth;\n+  private final BoundedVectorValues boundedVectors;\n+  private final VectorValues.SearchStrategy searchStrategy;\n+  private final HnswGraph hnsw;\n+  private final Random random;\n+\n+  /**\n+   * Reads all the vectors from a VectorValues, builds a graph connecting them by their dense ordinals, using default\n+   * hyperparameter settings, and returns the resulting graph.\n+   * @param vectorValues the vectors whose relations are represented by the graph\n+   */\n+  public static HnswGraph build(VectorValues vectorValues) throws IOException {\n+    HnswGraphBuilder builder = new HnswGraphBuilder(vectorValues.randomAccess());\n+    return builder.build(vectorValues.randomAccess());\n+  }\n+\n+  /**\n+   * Reads all the vectors from a VectorValues, builds a graph connecting them by their dense ordinals, using the given\n+   * hyperparameter settings, and returns the resulting graph.\n+   * @param vectorValues the vectors whose relations are represented by the graph\n+   * @param maxConn the number of connections to make when adding a new graph node; roughly speaking the graph fanout.\n+   * @param beamWidth the size of the beam search to use when finding nearest neighbors.\n+   * @param seed the seed for a random number generator used during graph construction. Provide this to ensure repeatable construction.\n+   */\n+  public static HnswGraph build(VectorValues vectorValues, int maxConn, int beamWidth, long seed) throws IOException {\n+    HnswGraphBuilder builder = new HnswGraphBuilder(vectorValues.randomAccess(), maxConn, beamWidth, seed);\n+    return builder.build(vectorValues.randomAccess());\n+  }\n+\n+  /**\n+   * Reads all the vectors from two copies of a random access VectorValues. Providing two copies enables efficient retrieval\n+   * without extra data copying, while avoiding collision of the returned values.\n+   * @param vectors the vectors for which to build a nearest neighbors graph. Must be an independet accessor for the vectors\n+   */\n+  private HnswGraph build(VectorValues.RandomAccess vectors) throws IOException {\n+    for (int node = 1; node < vectors.size(); node++) {\n+      insert(vectors.vectorValue(node));\n+    }\n+    return hnsw;\n+  }\n+\n+  /** Construct the builder with default configurations */\n+  private HnswGraphBuilder(VectorValues.RandomAccess vectors) {\n+    this(vectors, DEFAULT_MAX_CONN, DEFAULT_BEAM_WIDTH, randSeed);\n+  }\n+\n+  /** Full constructor */\n+  private HnswGraphBuilder(VectorValues.RandomAccess vectors, int maxConn, int beamWidth, long seed) {\n+    searchStrategy = vectors.searchStrategy();\n+    if (searchStrategy == VectorValues.SearchStrategy.NONE) {\n+      throw new IllegalStateException(\"No distance function\");\n+    }\n+    this.maxConn = maxConn;\n+    this.beamWidth = beamWidth;\n+    boundedVectors = new BoundedVectorValues(vectors);\n+    this.hnsw = new HnswGraph();\n+    random = new Random(seed);", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d17a2dd676dd9f3babc6ed3b3df307364db32606", "url": "https://github.com/apache/lucene-solr/commit/d17a2dd676dd9f3babc6ed3b3df307364db32606", "message": "extract separate RandomAccessVectorValues interface", "committedDate": "2020-10-26T16:32:48Z", "type": "commit"}, {"oid": "c33757ab28b540b2f028fb826a51b50772101700", "url": "https://github.com/apache/lucene-solr/commit/c33757ab28b540b2f028fb826a51b50772101700", "message": "use index checksum as seed for reproducible Random so we get consistent query response", "committedDate": "2020-10-26T23:14:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NTAzOA==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515075038", "bodyText": "Does this mean Lucene users are free to chose to simply store / retrieve vectors, even after we push this change?  I.e. the ANN is optional?", "author": "mikemccand", "createdAt": "2020-10-30T12:52:24Z", "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorReader.java", "diffHunk": "@@ -102,23 +122,28 @@ private void readFields(ChecksumIndexInput meta, FieldInfos infos) throws IOExce\n       if (info == null) {\n         throw new CorruptIndexException(\"Invalid field number: \" + fieldNumber, meta);\n       }\n-      int searchStrategyId = meta.readInt();\n-      if (searchStrategyId < 0 || searchStrategyId >= VectorValues.SearchStrategy.values().length) {\n-        throw new CorruptIndexException(\"Invalid search strategy id: \" + searchStrategyId, meta);\n-      }\n-      VectorValues.SearchStrategy searchStrategy = VectorValues.SearchStrategy.values()[searchStrategyId];\n-      long vectorDataOffset = meta.readVLong();\n-      long vectorDataLength = meta.readVLong();\n-      int dimension = meta.readInt();\n-      int size = meta.readInt();\n-      int[] ordToDoc = new int[size];\n-      for (int i = 0; i < size; i++) {\n-        int doc = meta.readVInt();\n-        ordToDoc[i] = doc;\n-      }\n-      FieldEntry fieldEntry = new FieldEntry(dimension, searchStrategy, maxDoc, vectorDataOffset, vectorDataLength,\n-                                              ordToDoc);\n-      fields.put(info.name, fieldEntry);\n+      fields.put(info.name, readField(meta));\n+    }\n+  }\n+\n+  private VectorValues.SearchStrategy readSearchStrategy(DataInput input) throws IOException {\n+    int searchStrategyId = input.readInt();\n+    if (searchStrategyId < 0 || searchStrategyId >= VectorValues.SearchStrategy.values().length) {\n+      throw new CorruptIndexException(\"Invalid search strategy id: \" + searchStrategyId, input);\n+    }\n+    return VectorValues.SearchStrategy.values()[searchStrategyId];\n+  }\n+\n+  private FieldEntry readField(DataInput input) throws IOException {\n+    VectorValues.SearchStrategy searchStrategy = readSearchStrategy(input);\n+    switch(searchStrategy) {\n+      case NONE:\n+        return new FieldEntry(input, searchStrategy);", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3MDgwNg==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515170806", "bodyText": "right; they may choose an indexing approach based on a strategy (the names indicate algorithm/metric, but could be anything), or NONE. That can be useful for calculating vector score only for the purpose of ranking hits matched by other means.", "author": "msokolov", "createdAt": "2020-10-30T15:13:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NTAzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NTk1MA==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515075950", "bodyText": "Why only testing?  It looks like it would be a useful API for users!", "author": "mikemccand", "createdAt": "2020-10-30T12:54:21Z", "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorReader.java", "diffHunk": "@@ -165,42 +191,88 @@ public VectorValues getVectorValues(String field) throws IOException {\n     return new OffHeapVectorValues(fieldEntry, bytesSlice);\n   }\n \n+  // exposed for testing", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3Mjg2MA==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515172860", "bodyText": "Fair; mostly I think the idea was to minimize the new API surface area that needs to be documented and maintained, trying to stick to VectorValues as the main public API with the KnnGraph as an internal indexing data structure", "author": "msokolov", "createdAt": "2020-10-30T15:16:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NTk1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NzgyOQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515077829", "bodyText": "Isn't there also an index-time fanout control?  Do we allow users to tune that (where?)?  If so, maybe link to that from this search-time fanout javadoc too?", "author": "mikemccand", "createdAt": "2020-10-30T12:57:52Z", "path": "lucene/core/src/java/org/apache/lucene/index/VectorValues.java", "diffHunk": "@@ -74,6 +74,18 @@ public BytesRef binaryValue() throws IOException {\n     throw new UnsupportedOperationException();\n   }\n \n+  /**\n+   * Return the k nearest neighbor documents as determined by comparison of their vector values\n+   * for this field, to the given vector, by the field's search strategy. If the search strategy is\n+   * reversed, lower values indicate nearer vectors, otherwise higher scores indicate nearer\n+   * vectors. Unlike relevance scores, vector scores may be negative.\n+   * @param target the vector-valued query\n+   * @param k      the number of docs to return\n+   * @param fanout control the accuracy/speed tradeoff - larger values give better recall at higher cost", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTE3NDM2Nw==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515174367", "bodyText": "Yeah, I think there needs to be a follow-on exposing the index-time controls, which indeed are much more potent than this search-time fanout, which has only a small impact on recall and latency. In this patch they are globals in HnswGraphBuilder, but there is no API for setting them. I am thinking the index-time hyperparameters would be specified in IndexWriterConfig?", "author": "msokolov", "createdAt": "2020-10-30T15:18:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NzgyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODc5Nzg2MQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r518797861", "bodyText": "Yeah, I think there needs to be a follow-on exposing the index-time controls, which indeed are much more potent than this search-time fanout, which has only a small impact on recall and latency. In this patch they are globals in HnswGraphBuilder, but there is no API for setting them.\n\nOK, makes sense.\n\nI am thinking the index-time hyperparameters would be specified in IndexWriterConfig?\n\nHmm, maybe these could be codec level controls?  Or maybe FieldInfo?  They would be per-vector-field configuration right?", "author": "mikemccand", "createdAt": "2020-11-06T14:47:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NzgyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODkwMjI3Ng==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r518902276", "bodyText": "Yeah that's a good point. While experimenting with GloVe I'm learning that different settings are appropriate for different vectors, so field-level control might be needed. I'm not sure how codec-level controls are exposed. Don't Codecs get created automatically using no-args constructors and service autodiscovery? Did you mean something like perFieldVectorFormat? Except I doubt we need a new format; it's more about some metadata values that we would store in the field, so I think yeah it would go in FieldInfo. But I'm reluctant to expose hnsw-specific hyperparameters in VectorField, which we want to support other algorithms as well. Maybe this is a good use case for IndexableField.getAttributes()?", "author": "msokolov", "createdAt": "2020-11-06T17:36:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NzgyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODk5NzgxMQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r518997811", "bodyText": "Yeah this probably needs to be field level. Different strokes for different collections of vectors. I'm not sure how to expose since the parameters will be different for different ANN implementations. Might be a good use case for generic IndexedField.attributes?", "author": "msokolov", "createdAt": "2020-11-06T20:49:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NzgyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTg3MzQ1NQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r519873455", "bodyText": "Don't Codecs get created automatically using no-args constructors and service autodiscovery?\n\nThey do at read (search) time!  But at write time, you can pass parameters that alter how the Codec does its work, as long as the resulting index is then readable at search time with no-args constructors.\nI vaguely remember talking about having ways for Codec at read-time to also take options, but I'm not sure that was ever fully designed / pushed ... @s1monw may remember?\n\nBut I'm reluctant to expose hnsw-specific hyperparameters in VectorField, which we want to support other algorithms as well.\nMight be a good use case for generic IndexedField.attributes?\n\nYeah, maybe?  I agree it is not obvious where the API should live and how it then finds its way into the ANN data structure construction when writing each segment.", "author": "mikemccand", "createdAt": "2020-11-09T14:54:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NzgyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTk5MjExMQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r521992111", "bodyText": "@mikemccand it was pushed but removed again in https://issues.apache.org/jira/browse/LUCENE-9257 a little while ago. I get why it's removed but it seems useful maybe we add it back?", "author": "s1monw", "createdAt": "2020-11-12T10:16:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NzgyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjE2NDI5Ng==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r522164296", "bodyText": "Ahh OK thanks for the context @s1monw.", "author": "mikemccand", "createdAt": "2020-11-12T14:51:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA3NzgyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4MDA0Mg==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515080042", "bodyText": "A node corresponds to an indexed vector, right?  And it is represented using its compact vector ordinal?", "author": "mikemccand", "createdAt": "2020-10-30T13:01:52Z", "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+import static org.apache.lucene.util.VectorUtil.dotProduct;\n+import static org.apache.lucene.util.VectorUtil.squareDistance;\n+\n+/**\n+ * Navigable Small-world graph. Provides efficient approximate nearest neighbor\n+ * search for high dimensional vectors.  See <a href=\"https://doi.org/10.1016/j.is.2013.10.006\">Approximate nearest\n+ * neighbor algorithm based on navigable small world graphs [2014]</a> and <a\n+ * href=\"https://arxiv.org/abs/1603.09320\">this paper [2018]</a> for details.\n+ *\n+ * This implementation is actually more like the one in the same authors' earlier 2014 paper in that\n+ * there is no hierarchy (just one layer), and no fanout restriction on the graph: nodes are allowed to accumulate\n+ * an unbounded number of outbound links, but it does incorporate some of the innovations of the later paper, like\n+ * using a priority queue to perform a beam search while traversing the graph. The nomenclature is a bit different\n+ * here from what's used in those papers:\n+ *\n+ * <h3>Hyperparameters</h3>\n+ * <ul>\n+ *   <li><code>numSeed</code> is the equivalent of <code>m</code> in the 2012 paper; it controls the number of random entry points to sample.</li>\n+ *   <li><code>beamWidth</code> in {@link HnswGraphBuilder} has the same meaning as <code>efConst</code> in the 2016 paper. It is the number of\n+ *   nearest neighbor candidates to track while searching the graph for each newly inserted node.</li>\n+ *   <li><code>maxConn</code> has the same meaning as <code>M</code> in the later paper; it controls how many of the <code>efConst</code> neighbors are\n+ *   connected to the new node</li>\n+ *   <li><code>fanout</code> the fanout parameter of {@link VectorValues#search(float[], int, int)}\n+ *   is used to control the values of <code>numSeed</code> and <code>topK</code> that are passed to this API.\n+ *   Thus <code>fanout</code> is like a combination of <code>ef</code> (search beam width) from the 2016 paper and <code>m</code> from the 2014 paper.\n+ *   </li>\n+ * </ul>\n+ *\n+ * <p>Note: The graph may be searched by multiple threads concurrently, but updates are not thread-safe. Also note: there is no notion of\n+ * deletions. Document searching built on top of this must do its own deletion-filtering.</p>\n+ */\n+public final class HnswGraph {\n+\n+  // each entry lists the neighbors of a node, in node order", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODk5Nzg3OQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r518997879", "bodyText": "Yes, although this class is agnostic as to the interpretation of these nodes. They could just as well be docIds, or social security numbers. But yeah, the only usage is as you describe, so I'll add a note to the javadoc.", "author": "msokolov", "createdAt": "2020-11-06T20:49:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4MDA0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4MjAxOQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515082019", "bodyText": "Maybe we could add this as a method on the enum constants instead?  So then caller could just call SearchStrategy.isReversed?", "author": "mikemccand", "createdAt": "2020-10-30T13:05:44Z", "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+import static org.apache.lucene.util.VectorUtil.dotProduct;\n+import static org.apache.lucene.util.VectorUtil.squareDistance;\n+\n+/**\n+ * Navigable Small-world graph. Provides efficient approximate nearest neighbor\n+ * search for high dimensional vectors.  See <a href=\"https://doi.org/10.1016/j.is.2013.10.006\">Approximate nearest\n+ * neighbor algorithm based on navigable small world graphs [2014]</a> and <a\n+ * href=\"https://arxiv.org/abs/1603.09320\">this paper [2018]</a> for details.\n+ *\n+ * This implementation is actually more like the one in the same authors' earlier 2014 paper in that\n+ * there is no hierarchy (just one layer), and no fanout restriction on the graph: nodes are allowed to accumulate\n+ * an unbounded number of outbound links, but it does incorporate some of the innovations of the later paper, like\n+ * using a priority queue to perform a beam search while traversing the graph. The nomenclature is a bit different\n+ * here from what's used in those papers:\n+ *\n+ * <h3>Hyperparameters</h3>\n+ * <ul>\n+ *   <li><code>numSeed</code> is the equivalent of <code>m</code> in the 2012 paper; it controls the number of random entry points to sample.</li>\n+ *   <li><code>beamWidth</code> in {@link HnswGraphBuilder} has the same meaning as <code>efConst</code> in the 2016 paper. It is the number of\n+ *   nearest neighbor candidates to track while searching the graph for each newly inserted node.</li>\n+ *   <li><code>maxConn</code> has the same meaning as <code>M</code> in the later paper; it controls how many of the <code>efConst</code> neighbors are\n+ *   connected to the new node</li>\n+ *   <li><code>fanout</code> the fanout parameter of {@link VectorValues#search(float[], int, int)}\n+ *   is used to control the values of <code>numSeed</code> and <code>topK</code> that are passed to this API.\n+ *   Thus <code>fanout</code> is like a combination of <code>ef</code> (search beam width) from the 2016 paper and <code>m</code> from the 2014 paper.\n+ *   </li>\n+ * </ul>\n+ *\n+ * <p>Note: The graph may be searched by multiple threads concurrently, but updates are not thread-safe. Also note: there is no notion of\n+ * deletions. Document searching built on top of this must do its own deletion-filtering.</p>\n+ */\n+public final class HnswGraph {\n+\n+  // each entry lists the neighbors of a node, in node order\n+  private final List<List<Neighbor>> graph;\n+\n+  HnswGraph() {\n+    graph = new ArrayList<>();\n+    graph.add(new ArrayList<>());\n+  }\n+\n+  /**\n+   * Searches for the nearest neighbors of a query vector.\n+   * @param query search query vector\n+   * @param topK the number of nodes to be returned\n+   * @param numSeed the number of random entry points to sample\n+   * @param vectors vector values\n+   * @param graphValues the graph values. May represent the entire graph, or a level in a hierarchical graph.\n+   * @param random a source of randomness, used for generating entry points to the graph\n+   * @return a priority queue holding the neighbors found\n+   */\n+  public static Neighbors search(float[] query, int topK, int numSeed, VectorValues.RandomAccess vectors, KnnGraphValues graphValues,\n+                                 Random random) throws IOException {\n+    VectorValues.SearchStrategy searchStrategy = vectors.searchStrategy();\n+    boolean scoreReversed = isReversed(searchStrategy);\n+    TreeSet<Neighbor> candidates;\n+    if (scoreReversed) {\n+      candidates = new TreeSet<>(Comparator.reverseOrder());\n+    } else {\n+      candidates = new TreeSet<>();\n+    }\n+    int size = vectors.size();\n+    for (int i = 0; i < numSeed && i < size; i++) {\n+      int entryPoint = random.nextInt(size);\n+      candidates.add(new Neighbor(entryPoint, compare(query, vectors.vectorValue(entryPoint), searchStrategy)));\n+    }\n+    // set of ordinals that have been visited by search on this layer, used to avoid backtracking\n+    //IntHashSet visited = new IntHashSet();\n+    Set<Integer> visited = new HashSet<>();\n+    // TODO: use PriorityQueue's sentinel optimization\n+    Neighbors results = Neighbors.create(topK, scoreReversed);\n+    for (Neighbor c :candidates) {\n+      visited.add(c.node);\n+      results.insertWithOverflow(c);\n+    }\n+    // Set the bound to the worst current result and below reject any newly-generated candidates failing\n+    // to exceed this bound\n+    BoundsChecker bound = BoundsChecker.create(scoreReversed);\n+    bound.bound = results.top().score;\n+    while (candidates.size() > 0) {\n+      // get the best candidate (closest or best scoring)\n+      Neighbor c = candidates.pollLast();\n+      if (results.size() >= topK) {\n+        if (bound.check(c.score)) {\n+          break;\n+        }\n+      }\n+      graphValues.seek(c.node);\n+      int friendOrd;\n+      while ((friendOrd = graphValues.nextArc()) != NO_MORE_DOCS) {\n+        if (visited.contains(friendOrd)) {\n+          continue;\n+        }\n+        visited.add(friendOrd);\n+        float score = compare(query, vectors.vectorValue(friendOrd), searchStrategy);\n+        if (results.size() < topK || bound.check(score) == false) {\n+          Neighbor n = new Neighbor(friendOrd, score);\n+          candidates.add(n);\n+          results.insertWithOverflow(n);\n+          bound.bound = results.top().score;\n+        }\n+      }\n+    }\n+    return results;\n+  }\n+\n+  /**\n+   * Returns the nodes connected to the given node by its outgoing arcs.\n+   * @param node the node whose friends are returned\n+   */\n+  public int[] getNeighbors(int node) {\n+    return graph.get(node).stream().mapToInt(Neighbor::node).toArray();\n+  }\n+\n+  /** Connects two nodes symmetrically.\n+   * node1 must be less than node2 and must already have been inserted to the graph */\n+  void connectNodes(int node1, int node2, float score, int maxConnections) {\n+    assert node1 >= 0 && node2 >= 0;\n+    assert node1 < node2;\n+    List<Neighbor> arcs1 = graph.get(node1);\n+    assert arcs1 != null;\n+    assert arcs1.isEmpty() || arcs1.get(arcs1.size() - 1).node < node2;\n+    arcs1.add(new Neighbor(node2, score));\n+    List<Neighbor> arcs2;\n+    if (node2 < graph.size()) {\n+      arcs2 = graph.get(node2);\n+      assert arcs2.get(arcs2.size() - 1).node < node1;\n+    } else {\n+      assert node2 == graph.size();\n+      arcs2 = new ArrayList<>();\n+      graph.add(arcs2);\n+    }\n+    arcs2.add(new Neighbor(node1, score));\n+\n+    // ensure #arcs <= maxConnections\n+    /*\n+    if (maxConnections > 0) {\n+      shrink(node2, maxConnections);\n+    }\n+     */\n+  }\n+\n+  /**\n+   * Calculates a similarity score between the two vectors with a specified function.\n+   * @param v1 a vector\n+   * @param v2 another vector, of the same dimension\n+   * @return the value of the strategy's score function applied to the two vectors\n+   */\n+  public static float compare(float[] v1, float[] v2, VectorValues.SearchStrategy searchStrategy) {\n+    switch (searchStrategy) {\n+      case EUCLIDEAN_HNSW:\n+        return squareDistance(v1, v2);\n+      case DOT_PRODUCT_HNSW:\n+        return dotProduct(v1, v2);\n+      default:\n+        throw new IllegalStateException(\"invalid search strategy: \" + searchStrategy);\n+    }\n+  }\n+\n+  /**\n+   * Return whether the given strategy returns lower values for nearer vectors\n+   * @param searchStrategy the strategy\n+   */\n+  public static boolean isReversed(VectorValues.SearchStrategy searchStrategy) {", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODk5OTU3Ng==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r518999576", "bodyText": "yeah that does seem cleaner. It was what I had in an earlier revision, but got thrown out with the bathwater of the vector scoring implementations.", "author": "msokolov", "createdAt": "2020-11-06T20:53:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4MjAxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4MjM3OA==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515082378", "bodyText": "Maybe this could also be a method on SearchStrategy enum?", "author": "mikemccand", "createdAt": "2020-10-30T13:06:21Z", "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+import static org.apache.lucene.util.VectorUtil.dotProduct;\n+import static org.apache.lucene.util.VectorUtil.squareDistance;\n+\n+/**\n+ * Navigable Small-world graph. Provides efficient approximate nearest neighbor\n+ * search for high dimensional vectors.  See <a href=\"https://doi.org/10.1016/j.is.2013.10.006\">Approximate nearest\n+ * neighbor algorithm based on navigable small world graphs [2014]</a> and <a\n+ * href=\"https://arxiv.org/abs/1603.09320\">this paper [2018]</a> for details.\n+ *\n+ * This implementation is actually more like the one in the same authors' earlier 2014 paper in that\n+ * there is no hierarchy (just one layer), and no fanout restriction on the graph: nodes are allowed to accumulate\n+ * an unbounded number of outbound links, but it does incorporate some of the innovations of the later paper, like\n+ * using a priority queue to perform a beam search while traversing the graph. The nomenclature is a bit different\n+ * here from what's used in those papers:\n+ *\n+ * <h3>Hyperparameters</h3>\n+ * <ul>\n+ *   <li><code>numSeed</code> is the equivalent of <code>m</code> in the 2012 paper; it controls the number of random entry points to sample.</li>\n+ *   <li><code>beamWidth</code> in {@link HnswGraphBuilder} has the same meaning as <code>efConst</code> in the 2016 paper. It is the number of\n+ *   nearest neighbor candidates to track while searching the graph for each newly inserted node.</li>\n+ *   <li><code>maxConn</code> has the same meaning as <code>M</code> in the later paper; it controls how many of the <code>efConst</code> neighbors are\n+ *   connected to the new node</li>\n+ *   <li><code>fanout</code> the fanout parameter of {@link VectorValues#search(float[], int, int)}\n+ *   is used to control the values of <code>numSeed</code> and <code>topK</code> that are passed to this API.\n+ *   Thus <code>fanout</code> is like a combination of <code>ef</code> (search beam width) from the 2016 paper and <code>m</code> from the 2014 paper.\n+ *   </li>\n+ * </ul>\n+ *\n+ * <p>Note: The graph may be searched by multiple threads concurrently, but updates are not thread-safe. Also note: there is no notion of\n+ * deletions. Document searching built on top of this must do its own deletion-filtering.</p>\n+ */\n+public final class HnswGraph {\n+\n+  // each entry lists the neighbors of a node, in node order\n+  private final List<List<Neighbor>> graph;\n+\n+  HnswGraph() {\n+    graph = new ArrayList<>();\n+    graph.add(new ArrayList<>());\n+  }\n+\n+  /**\n+   * Searches for the nearest neighbors of a query vector.\n+   * @param query search query vector\n+   * @param topK the number of nodes to be returned\n+   * @param numSeed the number of random entry points to sample\n+   * @param vectors vector values\n+   * @param graphValues the graph values. May represent the entire graph, or a level in a hierarchical graph.\n+   * @param random a source of randomness, used for generating entry points to the graph\n+   * @return a priority queue holding the neighbors found\n+   */\n+  public static Neighbors search(float[] query, int topK, int numSeed, VectorValues.RandomAccess vectors, KnnGraphValues graphValues,\n+                                 Random random) throws IOException {\n+    VectorValues.SearchStrategy searchStrategy = vectors.searchStrategy();\n+    boolean scoreReversed = isReversed(searchStrategy);\n+    TreeSet<Neighbor> candidates;\n+    if (scoreReversed) {\n+      candidates = new TreeSet<>(Comparator.reverseOrder());\n+    } else {\n+      candidates = new TreeSet<>();\n+    }\n+    int size = vectors.size();\n+    for (int i = 0; i < numSeed && i < size; i++) {\n+      int entryPoint = random.nextInt(size);\n+      candidates.add(new Neighbor(entryPoint, compare(query, vectors.vectorValue(entryPoint), searchStrategy)));\n+    }\n+    // set of ordinals that have been visited by search on this layer, used to avoid backtracking\n+    //IntHashSet visited = new IntHashSet();\n+    Set<Integer> visited = new HashSet<>();\n+    // TODO: use PriorityQueue's sentinel optimization\n+    Neighbors results = Neighbors.create(topK, scoreReversed);\n+    for (Neighbor c :candidates) {\n+      visited.add(c.node);\n+      results.insertWithOverflow(c);\n+    }\n+    // Set the bound to the worst current result and below reject any newly-generated candidates failing\n+    // to exceed this bound\n+    BoundsChecker bound = BoundsChecker.create(scoreReversed);\n+    bound.bound = results.top().score;\n+    while (candidates.size() > 0) {\n+      // get the best candidate (closest or best scoring)\n+      Neighbor c = candidates.pollLast();\n+      if (results.size() >= topK) {\n+        if (bound.check(c.score)) {\n+          break;\n+        }\n+      }\n+      graphValues.seek(c.node);\n+      int friendOrd;\n+      while ((friendOrd = graphValues.nextArc()) != NO_MORE_DOCS) {\n+        if (visited.contains(friendOrd)) {\n+          continue;\n+        }\n+        visited.add(friendOrd);\n+        float score = compare(query, vectors.vectorValue(friendOrd), searchStrategy);\n+        if (results.size() < topK || bound.check(score) == false) {\n+          Neighbor n = new Neighbor(friendOrd, score);\n+          candidates.add(n);\n+          results.insertWithOverflow(n);\n+          bound.bound = results.top().score;\n+        }\n+      }\n+    }\n+    return results;\n+  }\n+\n+  /**\n+   * Returns the nodes connected to the given node by its outgoing arcs.\n+   * @param node the node whose friends are returned\n+   */\n+  public int[] getNeighbors(int node) {\n+    return graph.get(node).stream().mapToInt(Neighbor::node).toArray();\n+  }\n+\n+  /** Connects two nodes symmetrically.\n+   * node1 must be less than node2 and must already have been inserted to the graph */\n+  void connectNodes(int node1, int node2, float score, int maxConnections) {\n+    assert node1 >= 0 && node2 >= 0;\n+    assert node1 < node2;\n+    List<Neighbor> arcs1 = graph.get(node1);\n+    assert arcs1 != null;\n+    assert arcs1.isEmpty() || arcs1.get(arcs1.size() - 1).node < node2;\n+    arcs1.add(new Neighbor(node2, score));\n+    List<Neighbor> arcs2;\n+    if (node2 < graph.size()) {\n+      arcs2 = graph.get(node2);\n+      assert arcs2.get(arcs2.size() - 1).node < node1;\n+    } else {\n+      assert node2 == graph.size();\n+      arcs2 = new ArrayList<>();\n+      graph.add(arcs2);\n+    }\n+    arcs2.add(new Neighbor(node1, score));\n+\n+    // ensure #arcs <= maxConnections\n+    /*\n+    if (maxConnections > 0) {\n+      shrink(node2, maxConnections);\n+    }\n+     */\n+  }\n+\n+  /**\n+   * Calculates a similarity score between the two vectors with a specified function.\n+   * @param v1 a vector\n+   * @param v2 another vector, of the same dimension\n+   * @return the value of the strategy's score function applied to the two vectors\n+   */\n+  public static float compare(float[] v1, float[] v2, VectorValues.SearchStrategy searchStrategy) {", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4NTk2MQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515085961", "bodyText": "Does our test-framework -Dtests.seed=XXX fix the seed here too?  So that (hopefully!) test failures are reproducible.", "author": "mikemccand", "createdAt": "2020-10-30T13:12:55Z", "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraphBuilder.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Random;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+import org.apache.lucene.util.BytesRef;\n+\n+/**\n+ * Builder for HNSW graph. See {@link HnswGraph} for a gloss on the algorithm and the meaning of the hyperparameters.\n+ */\n+public final class HnswGraphBuilder {\n+\n+  // default random seed for level generation\n+  private static final long DEFAULT_RAND_SEED = System.currentTimeMillis();\n+\n+  // expose for testing.\n+  public static long randSeed = DEFAULT_RAND_SEED;", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTAwMTAzMA==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r519001030", "bodyText": "yes!", "author": "msokolov", "createdAt": "2020-11-06T20:56:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4NTk2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4NjU1Mg==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515086552", "bodyText": "Oh I see -- users cannot (easily) change these defaults while indexing?  I would think we could provide these arguments to the Codec at write time and route them down to this HNSW building process...", "author": "mikemccand", "createdAt": "2020-10-30T13:13:43Z", "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraphBuilder.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Random;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+import org.apache.lucene.util.BytesRef;\n+\n+/**\n+ * Builder for HNSW graph. See {@link HnswGraph} for a gloss on the algorithm and the meaning of the hyperparameters.\n+ */\n+public final class HnswGraphBuilder {\n+\n+  // default random seed for level generation\n+  private static final long DEFAULT_RAND_SEED = System.currentTimeMillis();\n+\n+  // expose for testing.\n+  public static long randSeed = DEFAULT_RAND_SEED;\n+\n+  // These \"default\" hyperparameter settings are exposed (and nonfinal) to enable performance testing\n+  // since the indexing API doesn't provide any control over them.", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4ODUyOA==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515088528", "bodyText": "Hmm did we decide not to impose the maxConnections?", "author": "mikemccand", "createdAt": "2020-10-30T13:17:07Z", "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+import static org.apache.lucene.util.VectorUtil.dotProduct;\n+import static org.apache.lucene.util.VectorUtil.squareDistance;\n+\n+/**\n+ * Navigable Small-world graph. Provides efficient approximate nearest neighbor\n+ * search for high dimensional vectors.  See <a href=\"https://doi.org/10.1016/j.is.2013.10.006\">Approximate nearest\n+ * neighbor algorithm based on navigable small world graphs [2014]</a> and <a\n+ * href=\"https://arxiv.org/abs/1603.09320\">this paper [2018]</a> for details.\n+ *\n+ * This implementation is actually more like the one in the same authors' earlier 2014 paper in that\n+ * there is no hierarchy (just one layer), and no fanout restriction on the graph: nodes are allowed to accumulate\n+ * an unbounded number of outbound links, but it does incorporate some of the innovations of the later paper, like\n+ * using a priority queue to perform a beam search while traversing the graph. The nomenclature is a bit different\n+ * here from what's used in those papers:\n+ *\n+ * <h3>Hyperparameters</h3>\n+ * <ul>\n+ *   <li><code>numSeed</code> is the equivalent of <code>m</code> in the 2012 paper; it controls the number of random entry points to sample.</li>\n+ *   <li><code>beamWidth</code> in {@link HnswGraphBuilder} has the same meaning as <code>efConst</code> in the 2016 paper. It is the number of\n+ *   nearest neighbor candidates to track while searching the graph for each newly inserted node.</li>\n+ *   <li><code>maxConn</code> has the same meaning as <code>M</code> in the later paper; it controls how many of the <code>efConst</code> neighbors are\n+ *   connected to the new node</li>\n+ *   <li><code>fanout</code> the fanout parameter of {@link VectorValues#search(float[], int, int)}\n+ *   is used to control the values of <code>numSeed</code> and <code>topK</code> that are passed to this API.\n+ *   Thus <code>fanout</code> is like a combination of <code>ef</code> (search beam width) from the 2016 paper and <code>m</code> from the 2014 paper.\n+ *   </li>\n+ * </ul>\n+ *\n+ * <p>Note: The graph may be searched by multiple threads concurrently, but updates are not thread-safe. Also note: there is no notion of\n+ * deletions. Document searching built on top of this must do its own deletion-filtering.</p>\n+ */\n+public final class HnswGraph {\n+\n+  // each entry lists the neighbors of a node, in node order\n+  private final List<List<Neighbor>> graph;\n+\n+  HnswGraph() {\n+    graph = new ArrayList<>();\n+    graph.add(new ArrayList<>());\n+  }\n+\n+  /**\n+   * Searches for the nearest neighbors of a query vector.\n+   * @param query search query vector\n+   * @param topK the number of nodes to be returned\n+   * @param numSeed the number of random entry points to sample\n+   * @param vectors vector values\n+   * @param graphValues the graph values. May represent the entire graph, or a level in a hierarchical graph.\n+   * @param random a source of randomness, used for generating entry points to the graph\n+   * @return a priority queue holding the neighbors found\n+   */\n+  public static Neighbors search(float[] query, int topK, int numSeed, VectorValues.RandomAccess vectors, KnnGraphValues graphValues,\n+                                 Random random) throws IOException {\n+    VectorValues.SearchStrategy searchStrategy = vectors.searchStrategy();\n+    boolean scoreReversed = isReversed(searchStrategy);\n+    TreeSet<Neighbor> candidates;\n+    if (scoreReversed) {\n+      candidates = new TreeSet<>(Comparator.reverseOrder());\n+    } else {\n+      candidates = new TreeSet<>();\n+    }\n+    int size = vectors.size();\n+    for (int i = 0; i < numSeed && i < size; i++) {\n+      int entryPoint = random.nextInt(size);\n+      candidates.add(new Neighbor(entryPoint, compare(query, vectors.vectorValue(entryPoint), searchStrategy)));\n+    }\n+    // set of ordinals that have been visited by search on this layer, used to avoid backtracking\n+    //IntHashSet visited = new IntHashSet();\n+    Set<Integer> visited = new HashSet<>();\n+    // TODO: use PriorityQueue's sentinel optimization\n+    Neighbors results = Neighbors.create(topK, scoreReversed);\n+    for (Neighbor c :candidates) {\n+      visited.add(c.node);\n+      results.insertWithOverflow(c);\n+    }\n+    // Set the bound to the worst current result and below reject any newly-generated candidates failing\n+    // to exceed this bound\n+    BoundsChecker bound = BoundsChecker.create(scoreReversed);\n+    bound.bound = results.top().score;\n+    while (candidates.size() > 0) {\n+      // get the best candidate (closest or best scoring)\n+      Neighbor c = candidates.pollLast();\n+      if (results.size() >= topK) {\n+        if (bound.check(c.score)) {\n+          break;\n+        }\n+      }\n+      graphValues.seek(c.node);\n+      int friendOrd;\n+      while ((friendOrd = graphValues.nextArc()) != NO_MORE_DOCS) {\n+        if (visited.contains(friendOrd)) {\n+          continue;\n+        }\n+        visited.add(friendOrd);\n+        float score = compare(query, vectors.vectorValue(friendOrd), searchStrategy);\n+        if (results.size() < topK || bound.check(score) == false) {\n+          Neighbor n = new Neighbor(friendOrd, score);\n+          candidates.add(n);\n+          results.insertWithOverflow(n);\n+          bound.bound = results.top().score;\n+        }\n+      }\n+    }\n+    return results;\n+  }\n+\n+  /**\n+   * Returns the nodes connected to the given node by its outgoing arcs.\n+   * @param node the node whose friends are returned\n+   */\n+  public int[] getNeighbors(int node) {\n+    return graph.get(node).stream().mapToInt(Neighbor::node).toArray();\n+  }\n+\n+  /** Connects two nodes symmetrically.\n+   * node1 must be less than node2 and must already have been inserted to the graph */\n+  void connectNodes(int node1, int node2, float score, int maxConnections) {\n+    assert node1 >= 0 && node2 >= 0;\n+    assert node1 < node2;\n+    List<Neighbor> arcs1 = graph.get(node1);\n+    assert arcs1 != null;\n+    assert arcs1.isEmpty() || arcs1.get(arcs1.size() - 1).node < node2;\n+    arcs1.add(new Neighbor(node2, score));\n+    List<Neighbor> arcs2;\n+    if (node2 < graph.size()) {\n+      arcs2 = graph.get(node2);\n+      assert arcs2.get(arcs2.size() - 1).node < node1;\n+    } else {\n+      assert node2 == graph.size();\n+      arcs2 = new ArrayList<>();\n+      graph.add(arcs2);\n+    }\n+    arcs2.add(new Neighbor(node1, score));\n+\n+    // ensure #arcs <= maxConnections\n+    /*\n+    if (maxConnections > 0) {", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTAwMTEyMw==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r519001123", "bodyText": "Coming in the next revision", "author": "msokolov", "createdAt": "2020-11-06T20:56:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA4ODUyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5MDkxMQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515090911", "bodyText": "Maybe also make this a method on SearchStrategy enum?", "author": "mikemccand", "createdAt": "2020-10-30T13:20:54Z", "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorFormat.java", "diffHunk": "@@ -54,4 +56,10 @@ public VectorReader fieldsReader(SegmentReadState state) throws IOException {\n     return new Lucene90VectorReader(state);\n   }\n \n+  static boolean isHnswStrategy(VectorValues.SearchStrategy searchStrategy) {", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5MjEwNw==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515092107", "bodyText": "Is this class only used at segment-write time?  Or, is this also used to represent the HNSWGraph at search time?\nOK I think we do not use this at search time -- instead we .seek to a node, and then iterate through its int neighbors.  I guess we do not store the scores for each arc in the index.\nFrom your benchmarks, do you have a sense of how much heap is required (as a function of number of vectors) by this class to construct the ANN neighbors?\nAfter the one vector field for one segment is written, this class is GC'able?  So if I have three vector fields, the heap will only have one HnswGraph living at a time?", "author": "mikemccand", "createdAt": "2020-10-30T13:22:20Z", "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+import static org.apache.lucene.util.VectorUtil.dotProduct;\n+import static org.apache.lucene.util.VectorUtil.squareDistance;\n+\n+/**\n+ * Navigable Small-world graph. Provides efficient approximate nearest neighbor\n+ * search for high dimensional vectors.  See <a href=\"https://doi.org/10.1016/j.is.2013.10.006\">Approximate nearest\n+ * neighbor algorithm based on navigable small world graphs [2014]</a> and <a\n+ * href=\"https://arxiv.org/abs/1603.09320\">this paper [2018]</a> for details.\n+ *\n+ * This implementation is actually more like the one in the same authors' earlier 2014 paper in that\n+ * there is no hierarchy (just one layer), and no fanout restriction on the graph: nodes are allowed to accumulate\n+ * an unbounded number of outbound links, but it does incorporate some of the innovations of the later paper, like\n+ * using a priority queue to perform a beam search while traversing the graph. The nomenclature is a bit different\n+ * here from what's used in those papers:\n+ *\n+ * <h3>Hyperparameters</h3>\n+ * <ul>\n+ *   <li><code>numSeed</code> is the equivalent of <code>m</code> in the 2012 paper; it controls the number of random entry points to sample.</li>\n+ *   <li><code>beamWidth</code> in {@link HnswGraphBuilder} has the same meaning as <code>efConst</code> in the 2016 paper. It is the number of\n+ *   nearest neighbor candidates to track while searching the graph for each newly inserted node.</li>\n+ *   <li><code>maxConn</code> has the same meaning as <code>M</code> in the later paper; it controls how many of the <code>efConst</code> neighbors are\n+ *   connected to the new node</li>\n+ *   <li><code>fanout</code> the fanout parameter of {@link VectorValues#search(float[], int, int)}\n+ *   is used to control the values of <code>numSeed</code> and <code>topK</code> that are passed to this API.\n+ *   Thus <code>fanout</code> is like a combination of <code>ef</code> (search beam width) from the 2016 paper and <code>m</code> from the 2014 paper.\n+ *   </li>\n+ * </ul>\n+ *\n+ * <p>Note: The graph may be searched by multiple threads concurrently, but updates are not thread-safe. Also note: there is no notion of\n+ * deletions. Document searching built on top of this must do its own deletion-filtering.</p>\n+ */\n+public final class HnswGraph {\n+\n+  // each entry lists the neighbors of a node, in node order\n+  private final List<List<Neighbor>> graph;\n+\n+  HnswGraph() {", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTAwNDczMQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r519004731", "bodyText": "Right, we do not instantiate this class at search time, although we do use the static search method, which only relies on the abstract vector and graph values. Heap usage is quite high! It will scale with graph fanout * number of vectors. For each node, we store a PriorityQueue of Neighbor objects; each Neighbor has an int node id and a float score. I think for 1M vectors, with fanout of 64, we'll see around 1.5G heap usage, with lots of tiny objects on the heap during flush/merge. This can be dramatically reduced by eliminating the Neighbor objects in favor of parallel arrays, and the priority queues can then store int ordinals rather than object pointers, but I think that can be a fast follow?", "author": "msokolov", "createdAt": "2020-11-06T21:05:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5MjEwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTg4MTk3MA==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r519881970", "bodyText": "Yeah, +1 for fast follow!", "author": "mikemccand", "createdAt": "2020-11-09T15:05:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5MjEwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5MzY4Nw==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515093687", "bodyText": "An arc is the node id (compact ordinal) for the destination of the arc, right?  I.e. the neighbor nodes.\nMaybe rename arcs to neighborNodes?", "author": "mikemccand", "createdAt": "2020-10-30T13:24:48Z", "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+import static org.apache.lucene.util.VectorUtil.dotProduct;\n+import static org.apache.lucene.util.VectorUtil.squareDistance;\n+\n+/**\n+ * Navigable Small-world graph. Provides efficient approximate nearest neighbor\n+ * search for high dimensional vectors.  See <a href=\"https://doi.org/10.1016/j.is.2013.10.006\">Approximate nearest\n+ * neighbor algorithm based on navigable small world graphs [2014]</a> and <a\n+ * href=\"https://arxiv.org/abs/1603.09320\">this paper [2018]</a> for details.\n+ *\n+ * This implementation is actually more like the one in the same authors' earlier 2014 paper in that\n+ * there is no hierarchy (just one layer), and no fanout restriction on the graph: nodes are allowed to accumulate\n+ * an unbounded number of outbound links, but it does incorporate some of the innovations of the later paper, like\n+ * using a priority queue to perform a beam search while traversing the graph. The nomenclature is a bit different\n+ * here from what's used in those papers:\n+ *\n+ * <h3>Hyperparameters</h3>\n+ * <ul>\n+ *   <li><code>numSeed</code> is the equivalent of <code>m</code> in the 2012 paper; it controls the number of random entry points to sample.</li>\n+ *   <li><code>beamWidth</code> in {@link HnswGraphBuilder} has the same meaning as <code>efConst</code> in the 2016 paper. It is the number of\n+ *   nearest neighbor candidates to track while searching the graph for each newly inserted node.</li>\n+ *   <li><code>maxConn</code> has the same meaning as <code>M</code> in the later paper; it controls how many of the <code>efConst</code> neighbors are\n+ *   connected to the new node</li>\n+ *   <li><code>fanout</code> the fanout parameter of {@link VectorValues#search(float[], int, int)}\n+ *   is used to control the values of <code>numSeed</code> and <code>topK</code> that are passed to this API.\n+ *   Thus <code>fanout</code> is like a combination of <code>ef</code> (search beam width) from the 2016 paper and <code>m</code> from the 2014 paper.\n+ *   </li>\n+ * </ul>\n+ *\n+ * <p>Note: The graph may be searched by multiple threads concurrently, but updates are not thread-safe. Also note: there is no notion of\n+ * deletions. Document searching built on top of this must do its own deletion-filtering.</p>\n+ */\n+public final class HnswGraph {\n+\n+  // each entry lists the neighbors of a node, in node order\n+  private final List<List<Neighbor>> graph;\n+\n+  HnswGraph() {\n+    graph = new ArrayList<>();\n+    graph.add(new ArrayList<>());\n+  }\n+\n+  /**\n+   * Searches for the nearest neighbors of a query vector.\n+   * @param query search query vector\n+   * @param topK the number of nodes to be returned\n+   * @param numSeed the number of random entry points to sample\n+   * @param vectors vector values\n+   * @param graphValues the graph values. May represent the entire graph, or a level in a hierarchical graph.\n+   * @param random a source of randomness, used for generating entry points to the graph\n+   * @return a priority queue holding the neighbors found\n+   */\n+  public static Neighbors search(float[] query, int topK, int numSeed, VectorValues.RandomAccess vectors, KnnGraphValues graphValues,\n+                                 Random random) throws IOException {\n+    VectorValues.SearchStrategy searchStrategy = vectors.searchStrategy();\n+    boolean scoreReversed = isReversed(searchStrategy);\n+    TreeSet<Neighbor> candidates;\n+    if (scoreReversed) {\n+      candidates = new TreeSet<>(Comparator.reverseOrder());\n+    } else {\n+      candidates = new TreeSet<>();\n+    }\n+    int size = vectors.size();\n+    for (int i = 0; i < numSeed && i < size; i++) {\n+      int entryPoint = random.nextInt(size);\n+      candidates.add(new Neighbor(entryPoint, compare(query, vectors.vectorValue(entryPoint), searchStrategy)));\n+    }\n+    // set of ordinals that have been visited by search on this layer, used to avoid backtracking\n+    //IntHashSet visited = new IntHashSet();\n+    Set<Integer> visited = new HashSet<>();\n+    // TODO: use PriorityQueue's sentinel optimization\n+    Neighbors results = Neighbors.create(topK, scoreReversed);\n+    for (Neighbor c :candidates) {\n+      visited.add(c.node);\n+      results.insertWithOverflow(c);\n+    }\n+    // Set the bound to the worst current result and below reject any newly-generated candidates failing\n+    // to exceed this bound\n+    BoundsChecker bound = BoundsChecker.create(scoreReversed);\n+    bound.bound = results.top().score;\n+    while (candidates.size() > 0) {\n+      // get the best candidate (closest or best scoring)\n+      Neighbor c = candidates.pollLast();\n+      if (results.size() >= topK) {\n+        if (bound.check(c.score)) {\n+          break;\n+        }\n+      }\n+      graphValues.seek(c.node);\n+      int friendOrd;\n+      while ((friendOrd = graphValues.nextArc()) != NO_MORE_DOCS) {\n+        if (visited.contains(friendOrd)) {\n+          continue;\n+        }\n+        visited.add(friendOrd);\n+        float score = compare(query, vectors.vectorValue(friendOrd), searchStrategy);\n+        if (results.size() < topK || bound.check(score) == false) {\n+          Neighbor n = new Neighbor(friendOrd, score);\n+          candidates.add(n);\n+          results.insertWithOverflow(n);\n+          bound.bound = results.top().score;\n+        }\n+      }\n+    }\n+    return results;\n+  }\n+\n+  /**\n+   * Returns the nodes connected to the given node by its outgoing arcs.\n+   * @param node the node whose friends are returned\n+   */\n+  public int[] getNeighbors(int node) {\n+    return graph.get(node).stream().mapToInt(Neighbor::node).toArray();\n+  }\n+\n+  /** Connects two nodes symmetrically.\n+   * node1 must be less than node2 and must already have been inserted to the graph */\n+  void connectNodes(int node1, int node2, float score, int maxConnections) {\n+    assert node1 >= 0 && node2 >= 0;\n+    assert node1 < node2;\n+    List<Neighbor> arcs1 = graph.get(node1);\n+    assert arcs1 != null;\n+    assert arcs1.isEmpty() || arcs1.get(arcs1.size() - 1).node < node2;\n+    arcs1.add(new Neighbor(node2, score));\n+    List<Neighbor> arcs2;\n+    if (node2 < graph.size()) {\n+      arcs2 = graph.get(node2);\n+      assert arcs2.get(arcs2.size() - 1).node < node1;\n+    } else {\n+      assert node2 == graph.size();\n+      arcs2 = new ArrayList<>();\n+      graph.add(arcs2);\n+    }\n+    arcs2.add(new Neighbor(node1, score));\n+\n+    // ensure #arcs <= maxConnections\n+    /*\n+    if (maxConnections > 0) {\n+      shrink(node2, maxConnections);\n+    }\n+     */\n+  }\n+\n+  /**\n+   * Calculates a similarity score between the two vectors with a specified function.\n+   * @param v1 a vector\n+   * @param v2 another vector, of the same dimension\n+   * @return the value of the strategy's score function applied to the two vectors\n+   */\n+  public static float compare(float[] v1, float[] v2, VectorValues.SearchStrategy searchStrategy) {\n+    switch (searchStrategy) {\n+      case EUCLIDEAN_HNSW:\n+        return squareDistance(v1, v2);\n+      case DOT_PRODUCT_HNSW:\n+        return dotProduct(v1, v2);\n+      default:\n+        throw new IllegalStateException(\"invalid search strategy: \" + searchStrategy);\n+    }\n+  }\n+\n+  /**\n+   * Return whether the given strategy returns lower values for nearer vectors\n+   * @param searchStrategy the strategy\n+   */\n+  public static boolean isReversed(VectorValues.SearchStrategy searchStrategy) {\n+    switch (searchStrategy) {\n+      case EUCLIDEAN_HNSW:\n+        return true;\n+      case DOT_PRODUCT_HNSW:\n+        return false;\n+      default:\n+        throw new IllegalStateException(\"invalid search strategy: \" + searchStrategy);\n+    }\n+  }\n+\n+  KnnGraphValues getGraphValues() {\n+    return new HnswGraphValues();\n+  }\n+\n+  /**\n+   * Present this graph as KnnGraphValues, used for searching while inserting new nodes.\n+   */\n+  private class HnswGraphValues extends KnnGraphValues {\n+\n+    private int arcUpTo;\n+    private int[] arcs;", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTAwNjU3Mg==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r519006572", "bodyText": "sure, neighborNodes it is", "author": "msokolov", "createdAt": "2020-11-06T21:09:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5MzY4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5NzM2MQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515097361", "bodyText": "At first I thought we should use Float.MIN_VALUE here, but that is not right, since it is the smallest positive float.\nBut then I worried whether negating Float.MAX_VALUE produces a valid float (e.g. you cannot safely negate Integer.MIN_VALUE).\nMaybe just use Float.NEGATIVE_INFINITY here and Float.POSITIVE_INFINITY for Min?", "author": "mikemccand", "createdAt": "2020-10-30T13:30:19Z", "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/BoundsChecker.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+abstract class BoundsChecker {\n+\n+    float bound;\n+\n+    /**\n+     * Update the bound if sample is better\n+     */\n+    abstract void update(float sample);\n+\n+    /**\n+     * Return whether the sample exceeds (is worse than) the bound\n+     */\n+    abstract boolean check(float sample);\n+\n+    static BoundsChecker create(boolean reversed) {\n+        if (reversed) {\n+            return new Min();\n+        } else {\n+            return new Max();\n+        }\n+    }\n+\n+    static class Max extends BoundsChecker {\n+        Max() {\n+            bound = -Float.MAX_VALUE;", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTAwNzE4Nw==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r519007187", "bodyText": "Well, -Float.MAX_VALUE is reliable since the sign bit is separate from all the rest of the bits, but Float.NEGATIVE_INFINITY is less than that, so if we use it then any finite float will be a valid score, so +1 for that, and for +infinity as well", "author": "msokolov", "createdAt": "2020-11-06T21:11:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5NzM2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5OTEyMw==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515099123", "bodyText": "Remove extra blank line?", "author": "mikemccand", "createdAt": "2020-10-30T13:33:11Z", "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorFormat.java", "diffHunk": "@@ -54,4 +56,10 @@ public VectorReader fieldsReader(SegmentReadState state) throws IOException {\n     return new Lucene90VectorReader(state);\n   }\n \n+  static boolean isHnswStrategy(VectorValues.SearchStrategy searchStrategy) {\n+    return searchStrategy == VectorValues.SearchStrategy.DOT_PRODUCT_HNSW ||\n+        searchStrategy == VectorValues.SearchStrategy.EUCLIDEAN_HNSW;\n+  }\n+\n+", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTA5OTg5OQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515099899", "bodyText": "Hmm, why no longer public?  Users making their own Codec might want to use this constructor I think?", "author": "mikemccand", "createdAt": "2020-10-30T13:34:14Z", "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorFormat.java", "diffHunk": "@@ -33,15 +34,16 @@\n \n   static final String META_CODEC_NAME = \"Lucene90VectorFormatMeta\";\n   static final String VECTOR_DATA_CODEC_NAME = \"Lucene90VectorFormatData\";\n-\n+  static final String VECTOR_INDEX_CODEC_NAME = \"Lucene90VectorFormatIndex\";\n   static final String META_EXTENSION = \"vem\";\n   static final String VECTOR_DATA_EXTENSION = \"vec\";\n+  static final String VECTOR_INDEX_EXTENSION = \"vex\";\n \n   static final int VERSION_START = 0;\n   static final int VERSION_CURRENT = VERSION_START;\n \n   /** Sole constructor */\n-  public Lucene90VectorFormat() {\n+  Lucene90VectorFormat() {", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEwMDkzMw==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515100933", "bodyText": "Hmm, remove the TODO in here?\nAdd @lucene.experimental?", "author": "mikemccand", "createdAt": "2020-10-30T13:35:11Z", "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorFormat.java", "diffHunk": "@@ -24,6 +24,7 @@\n import org.apache.lucene.codecs.VectorWriter;\n import org.apache.lucene.index.SegmentReadState;\n import org.apache.lucene.index.SegmentWriteState;\n+import org.apache.lucene.index.VectorValues;\n \n /**\n  * Lucene 9.0 vector format, which encodes dense numeric vector values.", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEwMzU3NA==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515103574", "bodyText": "s/friends/neighbors?", "author": "mikemccand", "createdAt": "2020-10-30T13:39:17Z", "path": "lucene/core/src/java/org/apache/lucene/index/KnnGraphValues.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.index;\n+\n+import java.io.IOException;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+\n+/**\n+ * Access to per-document friends lists in a (hierarchical) knn search graph.", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEwMzk2OQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515103969", "bodyText": "Remove extra space before ;?", "author": "mikemccand", "createdAt": "2020-10-30T13:39:51Z", "path": "lucene/core/src/java/org/apache/lucene/index/KnnGraphValues.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.index;\n+\n+import java.io.IOException;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+\n+/**\n+ * Access to per-document friends lists in a (hierarchical) knn search graph.\n+ * TODO: replace with SortedNumericDocValues??\n+ */\n+public abstract class KnnGraphValues {\n+\n+  /** Sole constructor */\n+  protected KnnGraphValues() {}\n+\n+  /** Move the pointer to exactly {@code target}, the id of a node in the graph.\n+   *  After this method returns, call {@link #nextArc()} to return successive (ordered) connected node ordinals.\n+   * @param target must be a valid node in the graph, ie. &ge; 0 and &lt; {@link VectorValues#size()}.\n+   */\n+  public abstract void seek(int target) throws IOException;\n+\n+  /**\n+   * Iterates over the neighbor list. It is illegal to call this method after it returns\n+   * NO_MORE_DOCS without calling {@link #seek(int)}, which resets the iterator.\n+   * @return a node ordinal in the graph, or NO_MORE_DOCS if the iteration is complete.\n+   */\n+  public abstract int nextArc() throws IOException ;", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEwNDMxOA==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515104318", "bodyText": "Add @lucene.experimental?", "author": "mikemccand", "createdAt": "2020-10-30T13:40:18Z", "path": "lucene/core/src/java/org/apache/lucene/index/KnnGraphValues.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.index;\n+\n+import java.io.IOException;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+\n+/**\n+ * Access to per-document friends lists in a (hierarchical) knn search graph.\n+ * TODO: replace with SortedNumericDocValues??\n+ */\n+public abstract class KnnGraphValues {", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEwNTE4Mg==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r515105182", "bodyText": "This is expected to normally be used just during indexing?  Maybe explain that in the javadoc?  I.e. at search time, users should use the other search method that pulls neighbors from the index and recurses.", "author": "mikemccand", "createdAt": "2020-10-30T13:41:30Z", "path": "lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.util.hnsw;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.TreeSet;\n+\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.VectorValues;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n+import static org.apache.lucene.util.VectorUtil.dotProduct;\n+import static org.apache.lucene.util.VectorUtil.squareDistance;\n+\n+/**\n+ * Navigable Small-world graph. Provides efficient approximate nearest neighbor\n+ * search for high dimensional vectors.  See <a href=\"https://doi.org/10.1016/j.is.2013.10.006\">Approximate nearest\n+ * neighbor algorithm based on navigable small world graphs [2014]</a> and <a\n+ * href=\"https://arxiv.org/abs/1603.09320\">this paper [2018]</a> for details.\n+ *\n+ * This implementation is actually more like the one in the same authors' earlier 2014 paper in that\n+ * there is no hierarchy (just one layer), and no fanout restriction on the graph: nodes are allowed to accumulate\n+ * an unbounded number of outbound links, but it does incorporate some of the innovations of the later paper, like\n+ * using a priority queue to perform a beam search while traversing the graph. The nomenclature is a bit different\n+ * here from what's used in those papers:\n+ *\n+ * <h3>Hyperparameters</h3>\n+ * <ul>\n+ *   <li><code>numSeed</code> is the equivalent of <code>m</code> in the 2012 paper; it controls the number of random entry points to sample.</li>\n+ *   <li><code>beamWidth</code> in {@link HnswGraphBuilder} has the same meaning as <code>efConst</code> in the 2016 paper. It is the number of\n+ *   nearest neighbor candidates to track while searching the graph for each newly inserted node.</li>\n+ *   <li><code>maxConn</code> has the same meaning as <code>M</code> in the later paper; it controls how many of the <code>efConst</code> neighbors are\n+ *   connected to the new node</li>\n+ *   <li><code>fanout</code> the fanout parameter of {@link VectorValues#search(float[], int, int)}\n+ *   is used to control the values of <code>numSeed</code> and <code>topK</code> that are passed to this API.\n+ *   Thus <code>fanout</code> is like a combination of <code>ef</code> (search beam width) from the 2016 paper and <code>m</code> from the 2014 paper.\n+ *   </li>\n+ * </ul>\n+ *\n+ * <p>Note: The graph may be searched by multiple threads concurrently, but updates are not thread-safe. Also note: there is no notion of\n+ * deletions. Document searching built on top of this must do its own deletion-filtering.</p>\n+ */\n+public final class HnswGraph {\n+\n+  // each entry lists the neighbors of a node, in node order\n+  private final List<List<Neighbor>> graph;\n+\n+  HnswGraph() {\n+    graph = new ArrayList<>();\n+    graph.add(new ArrayList<>());\n+  }\n+\n+  /**\n+   * Searches for the nearest neighbors of a query vector.", "originalCommit": "c10b88a38b25ca52e87be009ed8011ccc1b94683", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTAwMDMyMw==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r519000323", "bodyText": "No this method is intended for use both when indexing and when searching. I guess this method could go in some other class (KnnGraphValues??) since it doesn't rely on Hnsw in any direct way (it only needs an abstract source of vectors and graph values). But it does use Neighbor/Neighbors and is heavily used by HnswGraphBuilder, so it seems natural to have it here.", "author": "msokolov", "createdAt": "2020-11-06T20:54:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTEwNTE4Mg=="}], "type": "inlineReview"}, {"oid": "3d4928bc6fc89b8e44ebba4b294ea5f761279db9", "url": "https://github.com/apache/lucene-solr/commit/3d4928bc6fc89b8e44ebba4b294ea5f761279db9", "message": "Restrict fanout by maxConn", "committedDate": "2020-11-01T19:21:53Z", "type": "commit"}, {"oid": "b74d5b176f876ef7eb5ca7d2aebb234e01f54309", "url": "https://github.com/apache/lucene-solr/commit/b74d5b176f876ef7eb5ca7d2aebb234e01f54309", "message": "remove unneeded sort of graph arcs", "committedDate": "2020-11-06T14:38:05Z", "type": "commit"}, {"oid": "83cf18f9bd3bb6214c500d23e7acf63178109bbe", "url": "https://github.com/apache/lucene-solr/commit/83cf18f9bd3bb6214c500d23e7acf63178109bbe", "message": "address comments", "committedDate": "2020-11-06T21:23:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTg5NTk0Nw==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r519895947", "bodyText": "Hmm is this unused?", "author": "mikemccand", "createdAt": "2020-11-09T15:24:29Z", "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorReader.java", "diffHunk": "@@ -22,39 +22,60 @@\n import java.nio.FloatBuffer;\n import java.util.HashMap;\n import java.util.Map;\n+import java.util.Random;\n \n import org.apache.lucene.codecs.CodecUtil;\n import org.apache.lucene.codecs.VectorReader;\n import org.apache.lucene.index.CorruptIndexException;\n import org.apache.lucene.index.FieldInfo;\n import org.apache.lucene.index.FieldInfos;\n import org.apache.lucene.index.IndexFileNames;\n+import org.apache.lucene.index.KnnGraphValues;\n+import org.apache.lucene.index.RandomAccessVectorValues;\n+import org.apache.lucene.index.RandomAccessVectorValuesProducer;\n import org.apache.lucene.index.SegmentReadState;\n import org.apache.lucene.index.VectorValues;\n+import org.apache.lucene.search.ScoreDoc;\n import org.apache.lucene.search.TopDocs;\n+import org.apache.lucene.search.TotalHits;\n import org.apache.lucene.store.ChecksumIndexInput;\n+import org.apache.lucene.store.DataInput;\n import org.apache.lucene.store.IndexInput;\n import org.apache.lucene.util.BytesRef;\n import org.apache.lucene.util.IOUtils;\n import org.apache.lucene.util.RamUsageEstimator;\n+import org.apache.lucene.util.hnsw.HnswGraph;\n+import org.apache.lucene.util.hnsw.Neighbor;\n+import org.apache.lucene.util.hnsw.Neighbors;\n+\n+import static org.apache.lucene.search.DocIdSetIterator.NO_MORE_DOCS;\n \n /**\n- * Reads vectors from the index segments.\n+ * Reads vectors from the index segments along with index data structures supporting KNN search.\n  * @lucene.experimental\n  */\n public final class Lucene90VectorReader extends VectorReader {\n \n   private final FieldInfos fieldInfos;\n   private final Map<String, FieldEntry> fields = new HashMap<>();\n   private final IndexInput vectorData;\n-  private final int maxDoc;\n+  private final IndexInput vectorIndex;\n+  private final long checksumSeed;\n \n   Lucene90VectorReader(SegmentReadState state) throws IOException {\n     this.fieldInfos = state.fieldInfos;\n-    this.maxDoc = state.segmentInfo.maxDoc();\n \n-    String metaFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, Lucene90VectorFormat.META_EXTENSION);\n+    int versionMeta = readMetadata(state, Lucene90VectorFormat.META_EXTENSION);\n+    long[] checksumRef = new long[1];\n+    vectorData = openDataInput(state, versionMeta, Lucene90VectorFormat.VECTOR_DATA_EXTENSION, Lucene90VectorFormat.VECTOR_DATA_CODEC_NAME, checksumRef);\n+    vectorIndex = openDataInput(state, versionMeta, Lucene90VectorFormat.VECTOR_INDEX_EXTENSION, Lucene90VectorFormat.VECTOR_INDEX_CODEC_NAME, checksumRef);\n+    checksumSeed = checksumRef[0];\n+  }\n+\n+  private int readMetadata(SegmentReadState state, String fileExtension) throws IOException {\n+    String metaFileName = IndexFileNames.segmentFileName(state.segmentInfo.name, state.segmentSuffix, fileExtension);\n     int versionMeta = -1;\n+    long checksum = -1;", "originalCommit": "83cf18f9bd3bb6214c500d23e7acf63178109bbe", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTg5Nzc4MQ==", "url": "https://github.com/apache/lucene-solr/pull/2022#discussion_r519897781", "bodyText": "Clever seed!", "author": "mikemccand", "createdAt": "2020-11-09T15:26:49Z", "path": "lucene/core/src/java/org/apache/lucene/codecs/lucene90/Lucene90VectorReader.java", "diffHunk": "@@ -277,24 +351,46 @@ public long cost() {\n     }\n \n     @Override\n-    public RandomAccess randomAccess() {\n+    public RandomAccessVectorValues randomAccess() {\n       return new OffHeapRandomAccess(dataIn.clone());\n     }\n \n+    @Override\n+    public TopDocs search(float[] vector, int topK, int fanout) throws IOException {\n+      // use a seed that is fixed for the index so we get reproducible results for the same query\n+      final Random random = new Random(checksumSeed);", "originalCommit": "83cf18f9bd3bb6214c500d23e7acf63178109bbe", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "c25c7b2da6ad845491545298565f666a8d9c4713", "url": "https://github.com/apache/lucene-solr/commit/c25c7b2da6ad845491545298565f666a8d9c4713", "message": "Merge remote-tracking branch 'apache/master' into LUCENE-9004", "committedDate": "2020-11-09T17:11:25Z", "type": "commit"}, {"oid": "f30bd409684ffe2283997e2ce504b96b262d6364", "url": "https://github.com/apache/lucene-solr/commit/f30bd409684ffe2283997e2ce504b96b262d6364", "message": "Make VectorValuesWriter.SortingVectorValues.randomAccess create its own non-shared vector", "committedDate": "2020-11-09T22:09:29Z", "type": "commit"}, {"oid": "cb64a5bec21c9d0ccea2d248c5dc5c04e3fa1ff1", "url": "https://github.com/apache/lucene-solr/commit/cb64a5bec21c9d0ccea2d248c5dc5c04e3fa1ff1", "message": "last minute tidying", "committedDate": "2020-11-13T13:41:09Z", "type": "commit"}]}