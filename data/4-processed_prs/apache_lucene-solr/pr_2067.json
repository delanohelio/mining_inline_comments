{"pr_number": 2067, "pr_title": "SOLR-14987: Reuse HttpSolrClient per node vs. one per Solr core when using CloudSolrStream", "pr_createdAt": "2020-11-06T21:53:51Z", "pr_url": "https://github.com/apache/lucene-solr/pull/2067", "timeline": [{"oid": "fed1e83fd7ffcbffa187d0c5aa7301d4b22e423c", "url": "https://github.com/apache/lucene-solr/commit/fed1e83fd7ffcbffa187d0c5aa7301d4b22e423c", "message": "SOLR-14987: Reuse HttpSolrClient per node vs. one per replica when using CloudSolrStream", "committedDate": "2020-11-06T21:26:54Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE5ODM5NQ==", "url": "https://github.com/apache/lucene-solr/pull/2067#discussion_r520198395", "bodyText": "related: can we update the javadoc on clusterState.getCollectionsMap to be more explicit that it will make a call to zk, instead of the current may", "author": "madrob", "createdAt": "2020-11-10T00:00:31Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/CloudSolrStream.java", "diffHunk": "@@ -334,11 +334,6 @@ private StreamComparator parseComp(String sort, String fl) throws IOException {\n   public static Slice[] getSlices(String collectionName, ZkStateReader zkStateReader, boolean checkAlias) throws IOException {\n     ClusterState clusterState = zkStateReader.getClusterState();\n \n-    Map<String, DocCollection> collectionsMap = clusterState.getCollectionsMap();", "originalCommit": "fed1e83fd7ffcbffa187d0c5aa7301d4b22e423c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTMzNTI0Ng==", "url": "https://github.com/apache/lucene-solr/pull/2067#discussion_r525335246", "bodyText": "good idea", "author": "thelabdude", "createdAt": "2020-11-17T17:09:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE5ODM5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE5OTA3Mw==", "url": "https://github.com/apache/lucene-solr/pull/2067#discussion_r520199073", "bodyText": "Should we cache the value of zkStateReader.getAliases below to avoid volatile reads?", "author": "madrob", "createdAt": "2020-11-10T00:02:36Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/CloudSolrStream.java", "diffHunk": "@@ -334,11 +334,6 @@ private StreamComparator parseComp(String sort, String fl) throws IOException {\n   public static Slice[] getSlices(String collectionName, ZkStateReader zkStateReader, boolean checkAlias) throws IOException {\n     ClusterState clusterState = zkStateReader.getClusterState();\n \n-    Map<String, DocCollection> collectionsMap = clusterState.getCollectionsMap();\n-\n-    //TODO we should probably split collection by comma to query more than one\n-    //  which is something already supported in other parts of Solr\n-\n     // check for alias or collection", "originalCommit": "fed1e83fd7ffcbffa187d0c5aa7301d4b22e423c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNzU1Nw==", "url": "https://github.com/apache/lucene-solr/pull/2067#discussion_r527027557", "bodyText": "Moved the call to getAliases out of the for loop", "author": "thelabdude", "createdAt": "2020-11-19T16:33:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDE5OTA3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDIwMjI4Mg==", "url": "https://github.com/apache/lucene-solr/pull/2067#discussion_r520202282", "bodyText": "Can we precomute this in the constructor?", "author": "madrob", "createdAt": "2020-11-10T00:12:14Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/SolrStream.java", "diffHunk": "@@ -126,6 +135,17 @@ public void open() throws IOException {\n     }\n   }\n \n+  private String getNodeUrl() {", "originalCommit": "fed1e83fd7ffcbffa187d0c5aa7301d4b22e423c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e445554c7e71e4d39b486c427d2efa59dac84dea", "url": "https://github.com/apache/lucene-solr/commit/e445554c7e71e4d39b486c427d2efa59dac84dea", "message": "Add unit test and use Replica metadata instead of parsing node / core", "committedDate": "2020-11-17T21:30:46Z", "type": "commit"}, {"oid": "1c6286911c1147cf59d7a9faca969385c970251c", "url": "https://github.com/apache/lucene-solr/commit/1c6286911c1147cf59d7a9faca969385c970251c", "message": "Remove unused import", "committedDate": "2020-11-17T21:34:48Z", "type": "commit"}, {"oid": "e6507ad92ef6dc6887140de5d5f9076f5c05d653", "url": "https://github.com/apache/lucene-solr/commit/e6507ad92ef6dc6887140de5d5f9076f5c05d653", "message": "Merge remote-tracking branch 'asf/master' into jira/solr-14987", "committedDate": "2020-11-17T21:37:33Z", "type": "commit"}, {"oid": "be1433745cc37b6999cb3fcf6bf0d770e8bfc242", "url": "https://github.com/apache/lucene-solr/commit/be1433745cc37b6999cb3fcf6bf0d770e8bfc242", "message": "Merge remote-tracking branch 'asf/master' into jira/solr-14987", "committedDate": "2020-11-19T15:43:26Z", "type": "commit"}, {"oid": "b9c1d7ec3453a46a33ea9f5123d8882a8dbf8245", "url": "https://github.com/apache/lucene-solr/commit/b9c1d7ec3453a46a33ea9f5123d8882a8dbf8245", "message": "Update changes.txt", "committedDate": "2020-11-19T15:44:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyNzIzNA==", "url": "https://github.com/apache/lucene-solr/pull/2067#discussion_r527027234", "bodyText": "I removed this b/c I don't think we should try to accommodate improperly cased collection names. No tests broke, but let me know if we need this for some reason I don't understand", "author": "thelabdude", "createdAt": "2020-11-19T16:33:21Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/CloudSolrStream.java", "diffHunk": "@@ -334,88 +330,76 @@ private StreamComparator parseComp(String sort, String fl) throws IOException {\n   public static Slice[] getSlices(String collectionName, ZkStateReader zkStateReader, boolean checkAlias) throws IOException {\n     ClusterState clusterState = zkStateReader.getClusterState();\n \n-    Map<String, DocCollection> collectionsMap = clusterState.getCollectionsMap();\n-\n-    //TODO we should probably split collection by comma to query more than one\n-    //  which is something already supported in other parts of Solr\n-\n     // check for alias or collection\n \n     List<String> allCollections = new ArrayList<>();\n     String[] collectionNames = collectionName.split(\",\");\n+    Aliases aliases = checkAlias ? zkStateReader.getAliases() : null;\n+\n     for(String col : collectionNames) {\n-      List<String> collections = checkAlias\n-          ? zkStateReader.getAliases().resolveAliases(col)  // if not an alias, returns collectionName\n+      List<String> collections = (aliases != null)\n+          ? aliases.resolveAliases(col)  // if not an alias, returns collectionName\n           : Collections.singletonList(collectionName);\n       allCollections.addAll(collections);\n     }\n \n     // Lookup all actives slices for these collections\n     List<Slice> slices = allCollections.stream()\n-        .map(collectionsMap::get)\n+        .map(c -> clusterState.getCollectionOrNull(c, true))\n         .filter(Objects::nonNull)\n         .flatMap(docCol -> Arrays.stream(docCol.getActiveSlicesArr()))\n         .collect(Collectors.toList());\n     if (!slices.isEmpty()) {\n-      return slices.toArray(new Slice[slices.size()]);\n-    }\n-\n-    // Check collection case insensitive\n-    for(Entry<String, DocCollection> entry : collectionsMap.entrySet()) {", "originalCommit": "b9c1d7ec3453a46a33ea9f5123d8882a8dbf8245", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyODE5OQ==", "url": "https://github.com/apache/lucene-solr/pull/2067#discussion_r527028199", "bodyText": "Here we're keeping the Replica so we have direct access to its baseUrl and core name instead of parsing those out of the shardUrl", "author": "thelabdude", "createdAt": "2020-11-19T16:34:40Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/CloudSolrStream.java", "diffHunk": "@@ -334,88 +330,76 @@ private StreamComparator parseComp(String sort, String fl) throws IOException {\n   public static Slice[] getSlices(String collectionName, ZkStateReader zkStateReader, boolean checkAlias) throws IOException {\n     ClusterState clusterState = zkStateReader.getClusterState();\n \n-    Map<String, DocCollection> collectionsMap = clusterState.getCollectionsMap();\n-\n-    //TODO we should probably split collection by comma to query more than one\n-    //  which is something already supported in other parts of Solr\n-\n     // check for alias or collection\n \n     List<String> allCollections = new ArrayList<>();\n     String[] collectionNames = collectionName.split(\",\");\n+    Aliases aliases = checkAlias ? zkStateReader.getAliases() : null;\n+\n     for(String col : collectionNames) {\n-      List<String> collections = checkAlias\n-          ? zkStateReader.getAliases().resolveAliases(col)  // if not an alias, returns collectionName\n+      List<String> collections = (aliases != null)\n+          ? aliases.resolveAliases(col)  // if not an alias, returns collectionName\n           : Collections.singletonList(collectionName);\n       allCollections.addAll(collections);\n     }\n \n     // Lookup all actives slices for these collections\n     List<Slice> slices = allCollections.stream()\n-        .map(collectionsMap::get)\n+        .map(c -> clusterState.getCollectionOrNull(c, true))\n         .filter(Objects::nonNull)\n         .flatMap(docCol -> Arrays.stream(docCol.getActiveSlicesArr()))\n         .collect(Collectors.toList());\n     if (!slices.isEmpty()) {\n-      return slices.toArray(new Slice[slices.size()]);\n-    }\n-\n-    // Check collection case insensitive\n-    for(Entry<String, DocCollection> entry : collectionsMap.entrySet()) {\n-      if(entry.getKey().equalsIgnoreCase(collectionName)) {\n-        return entry.getValue().getActiveSlicesArr();\n-      }\n+      return slices.toArray(new Slice[0]);\n     }\n \n     throw new IOException(\"Slices not found for \" + collectionName);\n   }\n \n   protected void constructStreams() throws IOException {\n+    final ModifiableSolrParams mParams = adjustParams(new ModifiableSolrParams(params));\n+    mParams.set(DISTRIB, \"false\"); // We are the aggregator.\n     try {\n+      final Stream<SolrStream> streamOfSolrStream;\n+      if (streamContext != null && streamContext.get(\"shards\") != null) {\n+        // stream of shard url with core\n+        streamOfSolrStream = getShards(this.zkHost, this.collection, this.streamContext, mParams).stream()\n+            .map(s -> new SolrStream(s, mParams));\n+      } else {\n+        // stream of replicas to reuse the same SolrHttpClient per baseUrl\n+        // avoids re-parsing data we already have in the replicas\n+        streamOfSolrStream = getReplicas(this.zkHost, this.collection, this.streamContext, mParams).stream()", "originalCommit": "b9c1d7ec3453a46a33ea9f5123d8882a8dbf8245", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzAyOTIwMQ==", "url": "https://github.com/apache/lucene-solr/pull/2067#discussion_r527029201", "bodyText": "Didn't seem like this method needed to be public and we already get a SolrClient in the open method, so no need to pass it. However, this breaks a public method signature, so is only for Solr 9.x and shouldn't be back-ported to 8.x", "author": "thelabdude", "createdAt": "2020-11-19T16:35:57Z", "path": "solr/solrj/src/java/org/apache/solr/client/solrj/io/stream/SolrStream.java", "diffHunk": "@@ -268,8 +275,7 @@ private Map mapFields(Map fields, Map<String,String> mappings) {\n     return fields;\n   }\n \n-  // temporary...\n-  public TupleStreamParser constructParser(SolrClient server, SolrParams requestParams) throws IOException, SolrServerException {\n+  private TupleStreamParser constructParser(SolrParams requestParams) throws IOException, SolrServerException {", "originalCommit": "b9c1d7ec3453a46a33ea9f5123d8882a8dbf8245", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1ccd1292b7f63948f7e6b66bf9da38c303bf0f2b", "url": "https://github.com/apache/lucene-solr/commit/1ccd1292b7f63948f7e6b66bf9da38c303bf0f2b", "message": "Merge remote-tracking branch 'asf/master' into jira/solr-14987", "committedDate": "2020-12-07T15:09:43Z", "type": "commit"}, {"oid": "7bb6068b31d8f881a6e10ca67c2dd9c4f4994735", "url": "https://github.com/apache/lucene-solr/commit/7bb6068b31d8f881a6e10ca67c2dd9c4f4994735", "message": "Improvement in 8.8", "committedDate": "2020-12-07T15:39:08Z", "type": "commit"}]}