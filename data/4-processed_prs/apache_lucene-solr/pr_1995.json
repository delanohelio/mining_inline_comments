{"pr_number": 1995, "pr_title": "LUCENE-9575 Add PatternTypingFilter to annotate tokens with flags and types", "pr_createdAt": "2020-10-16T15:10:23Z", "pr_url": "https://github.com/apache/lucene-solr/pull/1995", "timeline": [{"oid": "2eabb6e518dd1bcdd8717841894aadb9d0734cdd", "url": "https://github.com/apache/lucene-solr/commit/2eabb6e518dd1bcdd8717841894aadb9d0734cdd", "message": "LUCENE-9575 Add PatternTypingFilter to annotate tokens with flags and types if they match regex patterns.", "committedDate": "2020-10-16T15:04:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjUzMjA5NA==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r506532094", "bodyText": "hasAttribute is obsolete as it always returns true. Explanation: All tokenizers and filters in a chain share the same attribute instance. As you added it in line 46, it will alwys be there. So remove the whole if statemen.", "author": "uschindler", "createdAt": "2020-10-16T15:13:44Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTypingFilter.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.analysis.pattern;\n+\n+import java.io.IOException;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import org.apache.lucene.analysis.TokenFilter;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n+import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;\n+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;\n+\n+/**\n+ * Set a type attribute to a parameterized value when tokens are matched by any of a several regex patterns. The\n+ * value set in the type attribute is parameterized with the match groups of the regex used for matching.\n+ * In combination with TypeAsSynonymFilter and DropIfFlagged filter this can supply complex synonym patterns\n+ * that are protected from subsequent analysis, and optionally drop the original term based on the flag\n+ * set in this filter. See {@link PatternTypingFilterFactory} for full documentation.\n+ *\n+ * @since 8.8.0\n+ * @see PatternTypingFilterFactory\n+ */\n+public class PatternTypingFilter extends TokenFilter {\n+\n+  private final Map<Pattern, String> patterns;\n+  private final Map<Pattern, Integer> flags;\n+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n+  private final FlagsAttribute flagAtt = addAttribute(FlagsAttribute.class);\n+  private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n+\n+  public PatternTypingFilter(TokenStream input, LinkedHashMap<Pattern,String> patterns, Map<Pattern,Integer> flags) {\n+    super(input);\n+    this.patterns = patterns;\n+    this.flags = flags;\n+  }\n+\n+  @Override\n+  public final boolean incrementToken() throws IOException {\n+    if (input.incrementToken()) {\n+      if (hasAttribute(CharTermAttribute.class)) {", "originalCommit": "2eabb6e518dd1bcdd8717841894aadb9d0734cdd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjUzMjcwOQ==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r506532709", "bodyText": "You dont need to convert the termattribute to a termText String. You can dircetly pass termAtt to matcher, as termAtt implements CharSequence.", "author": "uschindler", "createdAt": "2020-10-16T15:14:38Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTypingFilter.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.analysis.pattern;\n+\n+import java.io.IOException;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import org.apache.lucene.analysis.TokenFilter;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n+import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;\n+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;\n+\n+/**\n+ * Set a type attribute to a parameterized value when tokens are matched by any of a several regex patterns. The\n+ * value set in the type attribute is parameterized with the match groups of the regex used for matching.\n+ * In combination with TypeAsSynonymFilter and DropIfFlagged filter this can supply complex synonym patterns\n+ * that are protected from subsequent analysis, and optionally drop the original term based on the flag\n+ * set in this filter. See {@link PatternTypingFilterFactory} for full documentation.\n+ *\n+ * @since 8.8.0\n+ * @see PatternTypingFilterFactory\n+ */\n+public class PatternTypingFilter extends TokenFilter {\n+\n+  private final Map<Pattern, String> patterns;\n+  private final Map<Pattern, Integer> flags;\n+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n+  private final FlagsAttribute flagAtt = addAttribute(FlagsAttribute.class);\n+  private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n+\n+  public PatternTypingFilter(TokenStream input, LinkedHashMap<Pattern,String> patterns, Map<Pattern,Integer> flags) {\n+    super(input);\n+    this.patterns = patterns;\n+    this.flags = flags;\n+  }\n+\n+  @Override\n+  public final boolean incrementToken() throws IOException {\n+    if (input.incrementToken()) {\n+      if (hasAttribute(CharTermAttribute.class)) {\n+        String termText = termAtt.toString();", "originalCommit": "2eabb6e518dd1bcdd8717841894aadb9d0734cdd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjUzMjk3OA==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r506532978", "bodyText": "pass termAtt instead of termText here.", "author": "uschindler", "createdAt": "2020-10-16T15:15:01Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTypingFilter.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.analysis.pattern;\n+\n+import java.io.IOException;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import org.apache.lucene.analysis.TokenFilter;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n+import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;\n+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;\n+\n+/**\n+ * Set a type attribute to a parameterized value when tokens are matched by any of a several regex patterns. The\n+ * value set in the type attribute is parameterized with the match groups of the regex used for matching.\n+ * In combination with TypeAsSynonymFilter and DropIfFlagged filter this can supply complex synonym patterns\n+ * that are protected from subsequent analysis, and optionally drop the original term based on the flag\n+ * set in this filter. See {@link PatternTypingFilterFactory} for full documentation.\n+ *\n+ * @since 8.8.0\n+ * @see PatternTypingFilterFactory\n+ */\n+public class PatternTypingFilter extends TokenFilter {\n+\n+  private final Map<Pattern, String> patterns;\n+  private final Map<Pattern, Integer> flags;\n+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n+  private final FlagsAttribute flagAtt = addAttribute(FlagsAttribute.class);\n+  private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n+\n+  public PatternTypingFilter(TokenStream input, LinkedHashMap<Pattern,String> patterns, Map<Pattern,Integer> flags) {\n+    super(input);\n+    this.patterns = patterns;\n+    this.flags = flags;\n+  }\n+\n+  @Override\n+  public final boolean incrementToken() throws IOException {\n+    if (input.incrementToken()) {\n+      if (hasAttribute(CharTermAttribute.class)) {\n+        String termText = termAtt.toString();\n+        for (Map.Entry<Pattern, String> patRep : patterns.entrySet()) {\n+          Pattern pattern = patRep.getKey();\n+          Matcher matcher = pattern.matcher(termText);", "originalCommit": "2eabb6e518dd1bcdd8717841894aadb9d0734cdd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU0Njk1NQ==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r506546955", "bodyText": "here the question is how to do the comparison without converting to a String. My idea:\nUse https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/regex/Matcher.html#replaceFirst(java.util.function.Function) to do the replacement. By that you get start() and end() of match and you can also check that the whole region of the term matched. IMHO, the filter should make sure that the regex always matches all the input? Or is there another intention?", "author": "uschindler", "createdAt": "2020-10-16T15:30:20Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTypingFilter.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.analysis.pattern;\n+\n+import java.io.IOException;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import org.apache.lucene.analysis.TokenFilter;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n+import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;\n+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;\n+\n+/**\n+ * Set a type attribute to a parameterized value when tokens are matched by any of a several regex patterns. The\n+ * value set in the type attribute is parameterized with the match groups of the regex used for matching.\n+ * In combination with TypeAsSynonymFilter and DropIfFlagged filter this can supply complex synonym patterns\n+ * that are protected from subsequent analysis, and optionally drop the original term based on the flag\n+ * set in this filter. See {@link PatternTypingFilterFactory} for full documentation.\n+ *\n+ * @since 8.8.0\n+ * @see PatternTypingFilterFactory\n+ */\n+public class PatternTypingFilter extends TokenFilter {\n+\n+  private final Map<Pattern, String> patterns;\n+  private final Map<Pattern, Integer> flags;\n+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n+  private final FlagsAttribute flagAtt = addAttribute(FlagsAttribute.class);\n+  private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n+\n+  public PatternTypingFilter(TokenStream input, LinkedHashMap<Pattern,String> patterns, Map<Pattern,Integer> flags) {\n+    super(input);\n+    this.patterns = patterns;\n+    this.flags = flags;\n+  }\n+\n+  @Override\n+  public final boolean incrementToken() throws IOException {\n+    if (input.incrementToken()) {\n+      if (hasAttribute(CharTermAttribute.class)) {\n+        String termText = termAtt.toString();\n+        for (Map.Entry<Pattern, String> patRep : patterns.entrySet()) {\n+          Pattern pattern = patRep.getKey();\n+          Matcher matcher = pattern.matcher(termText);\n+          String replaced = matcher.replaceFirst(patRep.getValue());\n+          // N.B. Does not support producing a synonym identical to the original term.\n+          // Avoids having to match() then replace() which performs a second find().\n+          if (!replaced.equals(termText)) {", "originalCommit": "2eabb6e518dd1bcdd8717841894aadb9d0734cdd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDExNDI3MQ==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r510114271", "bodyText": "I think the problem with this is in the event of a non-match start() and end() and any other MatchResult method will throw exceptions... that sounds very expensive since matches would be rare. As for matching the whole input, I intend to leave that up to the writer of the regex. We're not replacing the text, just adding a type/flags. No reason to limit the user's options there I think.", "author": "gus-asf", "createdAt": "2020-10-22T12:19:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU0Njk1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDEzMzIwMg==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r510133202", "bodyText": "I guess maybe, on the idea that matches will be rare in most cases, it might be better to just let the find() happen a second time when a match does occur to avoid the string creation?\n        if (matcher.find()) {\n          String replaced = matcher.replaceFirst(pattern);\n          typeAtt.setType(replaced);\n... etc\n        }", "author": "gus-asf", "createdAt": "2020-10-22T12:49:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU0Njk1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg2MTE0Ng==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r510861146", "bodyText": "@uschindler any further thoughts? If you agree with the above, I think all would be resolved.", "author": "gus-asf", "createdAt": "2020-10-23T12:50:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU0Njk1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg2NDAxMw==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r510864013", "bodyText": "I think that's fine.", "author": "uschindler", "createdAt": "2020-10-23T12:56:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU0Njk1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjU1MDk5NQ==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r506550995", "bodyText": "would't it be better to only have one hashmap, returning tuples of replacement and flags? You may use https://docs.oracle.com/javase/9/docs/api/java/util/Map.html#entry-K-V- (e.g. Map.entry(replacement, flag) as a workaround to hold two values as a pair.", "author": "uschindler", "createdAt": "2020-10-16T15:34:42Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTypingFilter.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.analysis.pattern;\n+\n+import java.io.IOException;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import org.apache.lucene.analysis.TokenFilter;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n+import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;\n+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;\n+\n+/**\n+ * Set a type attribute to a parameterized value when tokens are matched by any of a several regex patterns. The\n+ * value set in the type attribute is parameterized with the match groups of the regex used for matching.\n+ * In combination with TypeAsSynonymFilter and DropIfFlagged filter this can supply complex synonym patterns\n+ * that are protected from subsequent analysis, and optionally drop the original term based on the flag\n+ * set in this filter. See {@link PatternTypingFilterFactory} for full documentation.\n+ *\n+ * @since 8.8.0\n+ * @see PatternTypingFilterFactory\n+ */\n+public class PatternTypingFilter extends TokenFilter {\n+\n+  private final Map<Pattern, String> patterns;", "originalCommit": "2eabb6e518dd1bcdd8717841894aadb9d0734cdd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjY4OTc1Mw==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r506689753", "bodyText": "Space character is missing after the comma in the Map and LinkedHashMap!", "author": "danmuzi", "createdAt": "2020-10-16T19:50:12Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTypingFilter.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.analysis.pattern;\n+\n+import java.io.IOException;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import org.apache.lucene.analysis.TokenFilter;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n+import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;\n+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;\n+\n+/**\n+ * Set a type attribute to a parameterized value when tokens are matched by any of a several regex patterns. The\n+ * value set in the type attribute is parameterized with the match groups of the regex used for matching.\n+ * In combination with TypeAsSynonymFilter and DropIfFlagged filter this can supply complex synonym patterns\n+ * that are protected from subsequent analysis, and optionally drop the original term based on the flag\n+ * set in this filter. See {@link PatternTypingFilterFactory} for full documentation.\n+ *\n+ * @since 8.8.0\n+ * @see PatternTypingFilterFactory\n+ */\n+public class PatternTypingFilter extends TokenFilter {\n+\n+  private final Map<Pattern, String> patterns;\n+  private final Map<Pattern, Integer> flags;\n+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n+  private final FlagsAttribute flagAtt = addAttribute(FlagsAttribute.class);\n+  private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n+\n+  public PatternTypingFilter(TokenStream input, LinkedHashMap<Pattern,String> patterns, Map<Pattern,Integer> flags) {", "originalCommit": "2eabb6e518dd1bcdd8717841894aadb9d0734cdd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjY5MTU3MQ==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r506691571", "bodyText": "There is a typo in the comment.\nKeepWordFilterFactory -> PatternTypingFilterFactory", "author": "danmuzi", "createdAt": "2020-10-16T19:54:29Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTypingFilterFactory.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.analysis.pattern;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+import org.apache.lucene.analysis.TokenFilterFactory;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.util.ResourceLoader;\n+import org.apache.lucene.util.ResourceLoaderAware;\n+\n+\n+/**\n+ * Provides a filter that will analyze tokens with the analyzer from an arbitrary field type. By itself this\n+ * filter is not very useful. Normally it is combined with a filter that reacts to types or flags.\n+ *\n+ * <pre class=\"prettyprint\" >\n+ * &lt;fieldType name=\"text_taf\" class=\"solr.TextField\" positionIncrementGap=\"100\"&gt;\n+ *   &lt;analyzer&gt;\n+ *     &lt;tokenizer class=\"solr.WhitespaceTokenizerFactory\"/&gt;\n+ *     &lt;filter class=\"com.example.PatternTypingFilter\" patternFile=\"patterns.txt\"/&gt;\n+ *     &lt;filter class=\"solr.TokenAnalyzerFilter\" asType=\"text_en\" preserveType=\"true\"/&gt;\n+ *     &lt;filter class=\"solr.TypeAsSynonymFilterFactory\" prefix=\"__TAS__\"\n+ *               ignore=\"word,&amp;lt;ALPHANUM&amp;gt;,&amp;lt;NUM&amp;gt;,&amp;lt;SOUTHEAST_ASIAN&amp;gt;,&amp;lt;IDEOGRAPHIC&amp;gt;,&amp;lt;HIRAGANA&amp;gt;,&amp;lt;KATAKANA&amp;gt;,&amp;lt;HANGUL&amp;gt;,&amp;lt;EMOJI&amp;gt;\"/&gt;\n+ *   &lt;/analyzer&gt;\n+ * &lt;/fieldType&gt;</pre>\n+ * <p>\n+ * Note that a configuration such as above may interfere with multi-word synonyms. The patterns file has the format:\n+ * <pre>\n+ * (flags) (pattern) ::: (replacement)\n+ * </pre>\n+ * Therefore to set the first 2 flag bits on the original token matching 401k or 401(k) and adding a type of\n+ * 'legal2_401_k' whenever either one is encountered one would use:\n+ * <pre>\n+ * 3 (\\d+)\\(?([a-z])\\)? ::: legal2_$1_$2\n+ * </pre>\n+ * Note that the number indicating the flag bits to set must not have leading spaces and be followed by a single\n+ * space, and must be 0 if no flags should be set. The flags number should not contain commas or a decimal point.\n+ * Lines for which the first character is <code>#</code> will be ignored as comments.  Does not support producing\n+ * a synonym textually identical to the original term.\n+ *\n+ * @lucene.spi {@value #NAME}\n+ * @since 8.8\n+ */\n+public class PatternTypingFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {\n+\n+  /**\n+   * SPI name\n+   */\n+  public static final String NAME = \"patternTyping\";\n+\n+  private final String patternFile;\n+  // todo, perhaps this could be turned into an FST (wanted: regex FST with capturing groups in java)\n+  private final LinkedHashMap<Pattern, String> patterns = new LinkedHashMap<>();\n+  private final Map<Pattern, Integer> flags = new HashMap<>();\n+\n+  /**\n+   * Creates a new KeepWordFilterFactory", "originalCommit": "2eabb6e518dd1bcdd8717841894aadb9d0734cdd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDExNjgyNQ==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r510116825", "bodyText": "thx", "author": "gus-asf", "createdAt": "2020-10-22T12:23:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjY5MTU3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjY5NTUwNQ==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r506695505", "bodyText": "This part seems to be checked in WordlistLoader.getLines!\n\n  \n    \n      lucene-solr/lucene/core/src/java/org/apache/lucene/analysis/AbstractAnalysisFactory.java\n    \n    \n        Lines 280 to 282\n      in\n      f7be9e8\n    \n    \n    \n    \n\n        \n          \n           protected final List<String> getLines(ResourceLoader loader, String resource) throws IOException { \n        \n\n        \n          \n             return WordlistLoader.getLines(loader.openResource(resource), StandardCharsets.UTF_8); \n        \n\n        \n          \n           } \n        \n    \n  \n\n\n\n  \n    \n      lucene-solr/lucene/core/src/java/org/apache/lucene/analysis/WordlistLoader.java\n    \n    \n        Lines 217 to 227\n      in\n      f7be9e8\n    \n    \n    \n    \n\n        \n          \n           for (String word=null; (word=input.readLine())!=null;) { \n        \n\n        \n          \n             // skip initial bom marker \n        \n\n        \n          \n             if (lines.isEmpty() && word.length() > 0 && word.charAt(0) == '\\uFEFF') \n        \n\n        \n          \n               word = word.substring(1); \n        \n\n        \n          \n             // skip comments \n        \n\n        \n          \n             if (word.startsWith(\"#\")) continue; \n        \n\n        \n          \n             word=word.trim(); \n        \n\n        \n          \n             // skip blank lines \n        \n\n        \n          \n             if (word.length()==0) continue; \n        \n\n        \n          \n             lines.add(word); \n        \n\n        \n          \n           }", "author": "danmuzi", "createdAt": "2020-10-16T20:03:45Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTypingFilterFactory.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.analysis.pattern;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+import org.apache.lucene.analysis.TokenFilterFactory;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.util.ResourceLoader;\n+import org.apache.lucene.util.ResourceLoaderAware;\n+\n+\n+/**\n+ * Provides a filter that will analyze tokens with the analyzer from an arbitrary field type. By itself this\n+ * filter is not very useful. Normally it is combined with a filter that reacts to types or flags.\n+ *\n+ * <pre class=\"prettyprint\" >\n+ * &lt;fieldType name=\"text_taf\" class=\"solr.TextField\" positionIncrementGap=\"100\"&gt;\n+ *   &lt;analyzer&gt;\n+ *     &lt;tokenizer class=\"solr.WhitespaceTokenizerFactory\"/&gt;\n+ *     &lt;filter class=\"com.example.PatternTypingFilter\" patternFile=\"patterns.txt\"/&gt;\n+ *     &lt;filter class=\"solr.TokenAnalyzerFilter\" asType=\"text_en\" preserveType=\"true\"/&gt;\n+ *     &lt;filter class=\"solr.TypeAsSynonymFilterFactory\" prefix=\"__TAS__\"\n+ *               ignore=\"word,&amp;lt;ALPHANUM&amp;gt;,&amp;lt;NUM&amp;gt;,&amp;lt;SOUTHEAST_ASIAN&amp;gt;,&amp;lt;IDEOGRAPHIC&amp;gt;,&amp;lt;HIRAGANA&amp;gt;,&amp;lt;KATAKANA&amp;gt;,&amp;lt;HANGUL&amp;gt;,&amp;lt;EMOJI&amp;gt;\"/&gt;\n+ *   &lt;/analyzer&gt;\n+ * &lt;/fieldType&gt;</pre>\n+ * <p>\n+ * Note that a configuration such as above may interfere with multi-word synonyms. The patterns file has the format:\n+ * <pre>\n+ * (flags) (pattern) ::: (replacement)\n+ * </pre>\n+ * Therefore to set the first 2 flag bits on the original token matching 401k or 401(k) and adding a type of\n+ * 'legal2_401_k' whenever either one is encountered one would use:\n+ * <pre>\n+ * 3 (\\d+)\\(?([a-z])\\)? ::: legal2_$1_$2\n+ * </pre>\n+ * Note that the number indicating the flag bits to set must not have leading spaces and be followed by a single\n+ * space, and must be 0 if no flags should be set. The flags number should not contain commas or a decimal point.\n+ * Lines for which the first character is <code>#</code> will be ignored as comments.  Does not support producing\n+ * a synonym textually identical to the original term.\n+ *\n+ * @lucene.spi {@value #NAME}\n+ * @since 8.8\n+ */\n+public class PatternTypingFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {\n+\n+  /**\n+   * SPI name\n+   */\n+  public static final String NAME = \"patternTyping\";\n+\n+  private final String patternFile;\n+  // todo, perhaps this could be turned into an FST (wanted: regex FST with capturing groups in java)\n+  private final LinkedHashMap<Pattern, String> patterns = new LinkedHashMap<>();\n+  private final Map<Pattern, Integer> flags = new HashMap<>();\n+\n+  /**\n+   * Creates a new KeepWordFilterFactory\n+   */\n+  public PatternTypingFilterFactory(Map<String, String> args) {\n+    super(args);\n+    patternFile = require(args, \"patternFile\");\n+    if (!args.isEmpty()) {\n+      throw new IllegalArgumentException(\"Unknown parameters: \" + args);\n+    }\n+  }\n+\n+  /** Default ctor for compatibility with SPI */\n+  public PatternTypingFilterFactory() {\n+    throw defaultCtorException();\n+  }\n+\n+  @Override\n+  public void inform(ResourceLoader loader) throws IOException {\n+    List<String> lines = getLines(loader, patternFile);\n+    // format: # regex ::: typename[_$1[_$2 ...]]    (technically _$1 does not need the '_' but it usually makes sense)\n+    // eg: 2 (\\d+\\(?([a-z])\\)?\\(?(\\d+)\\)? ::: legal3_$1_$2_3\n+    // which yields legal3_501_c_3 for 501(c)(3) or 501c3 and sets the second lowest bit in flags\n+    for (String line : lines) {\n+      if (line.trim().startsWith(\"#\")) {", "originalCommit": "2eabb6e518dd1bcdd8717841894aadb9d0734cdd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjY5ODc4NA==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r506698784", "bodyText": "Space character is missing after the comma in the substring method parameter!", "author": "danmuzi", "createdAt": "2020-10-16T20:11:47Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTypingFilterFactory.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.analysis.pattern;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+import org.apache.lucene.analysis.TokenFilterFactory;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.util.ResourceLoader;\n+import org.apache.lucene.util.ResourceLoaderAware;\n+\n+\n+/**\n+ * Provides a filter that will analyze tokens with the analyzer from an arbitrary field type. By itself this\n+ * filter is not very useful. Normally it is combined with a filter that reacts to types or flags.\n+ *\n+ * <pre class=\"prettyprint\" >\n+ * &lt;fieldType name=\"text_taf\" class=\"solr.TextField\" positionIncrementGap=\"100\"&gt;\n+ *   &lt;analyzer&gt;\n+ *     &lt;tokenizer class=\"solr.WhitespaceTokenizerFactory\"/&gt;\n+ *     &lt;filter class=\"com.example.PatternTypingFilter\" patternFile=\"patterns.txt\"/&gt;\n+ *     &lt;filter class=\"solr.TokenAnalyzerFilter\" asType=\"text_en\" preserveType=\"true\"/&gt;\n+ *     &lt;filter class=\"solr.TypeAsSynonymFilterFactory\" prefix=\"__TAS__\"\n+ *               ignore=\"word,&amp;lt;ALPHANUM&amp;gt;,&amp;lt;NUM&amp;gt;,&amp;lt;SOUTHEAST_ASIAN&amp;gt;,&amp;lt;IDEOGRAPHIC&amp;gt;,&amp;lt;HIRAGANA&amp;gt;,&amp;lt;KATAKANA&amp;gt;,&amp;lt;HANGUL&amp;gt;,&amp;lt;EMOJI&amp;gt;\"/&gt;\n+ *   &lt;/analyzer&gt;\n+ * &lt;/fieldType&gt;</pre>\n+ * <p>\n+ * Note that a configuration such as above may interfere with multi-word synonyms. The patterns file has the format:\n+ * <pre>\n+ * (flags) (pattern) ::: (replacement)\n+ * </pre>\n+ * Therefore to set the first 2 flag bits on the original token matching 401k or 401(k) and adding a type of\n+ * 'legal2_401_k' whenever either one is encountered one would use:\n+ * <pre>\n+ * 3 (\\d+)\\(?([a-z])\\)? ::: legal2_$1_$2\n+ * </pre>\n+ * Note that the number indicating the flag bits to set must not have leading spaces and be followed by a single\n+ * space, and must be 0 if no flags should be set. The flags number should not contain commas or a decimal point.\n+ * Lines for which the first character is <code>#</code> will be ignored as comments.  Does not support producing\n+ * a synonym textually identical to the original term.\n+ *\n+ * @lucene.spi {@value #NAME}\n+ * @since 8.8\n+ */\n+public class PatternTypingFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {\n+\n+  /**\n+   * SPI name\n+   */\n+  public static final String NAME = \"patternTyping\";\n+\n+  private final String patternFile;\n+  // todo, perhaps this could be turned into an FST (wanted: regex FST with capturing groups in java)\n+  private final LinkedHashMap<Pattern, String> patterns = new LinkedHashMap<>();\n+  private final Map<Pattern, Integer> flags = new HashMap<>();\n+\n+  /**\n+   * Creates a new KeepWordFilterFactory\n+   */\n+  public PatternTypingFilterFactory(Map<String, String> args) {\n+    super(args);\n+    patternFile = require(args, \"patternFile\");\n+    if (!args.isEmpty()) {\n+      throw new IllegalArgumentException(\"Unknown parameters: \" + args);\n+    }\n+  }\n+\n+  /** Default ctor for compatibility with SPI */\n+  public PatternTypingFilterFactory() {\n+    throw defaultCtorException();\n+  }\n+\n+  @Override\n+  public void inform(ResourceLoader loader) throws IOException {\n+    List<String> lines = getLines(loader, patternFile);\n+    // format: # regex ::: typename[_$1[_$2 ...]]    (technically _$1 does not need the '_' but it usually makes sense)\n+    // eg: 2 (\\d+\\(?([a-z])\\)?\\(?(\\d+)\\)? ::: legal3_$1_$2_3\n+    // which yields legal3_501_c_3 for 501(c)(3) or 501c3 and sets the second lowest bit in flags\n+    for (String line : lines) {\n+      if (line.trim().startsWith(\"#\")) {\n+        continue; // allow for comments\n+      }\n+      int firstSpace = line.indexOf(\" \"); // no leading spaces allowed\n+      int flagsVal = Integer.parseInt(line.substring(0,firstSpace));", "originalCommit": "2eabb6e518dd1bcdd8717841894aadb9d0734cdd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjcwMDgyNw==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r506700827", "bodyText": "Perhaps PatternTypingFilter is right instead of PatternRecognizerFilter.", "author": "danmuzi", "createdAt": "2020-10-16T20:16:36Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTypingFilterFactory.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.analysis.pattern;\n+\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+import org.apache.lucene.analysis.TokenFilterFactory;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.util.ResourceLoader;\n+import org.apache.lucene.util.ResourceLoaderAware;\n+\n+\n+/**\n+ * Provides a filter that will analyze tokens with the analyzer from an arbitrary field type. By itself this\n+ * filter is not very useful. Normally it is combined with a filter that reacts to types or flags.\n+ *\n+ * <pre class=\"prettyprint\" >\n+ * &lt;fieldType name=\"text_taf\" class=\"solr.TextField\" positionIncrementGap=\"100\"&gt;\n+ *   &lt;analyzer&gt;\n+ *     &lt;tokenizer class=\"solr.WhitespaceTokenizerFactory\"/&gt;\n+ *     &lt;filter class=\"com.example.PatternTypingFilter\" patternFile=\"patterns.txt\"/&gt;\n+ *     &lt;filter class=\"solr.TokenAnalyzerFilter\" asType=\"text_en\" preserveType=\"true\"/&gt;\n+ *     &lt;filter class=\"solr.TypeAsSynonymFilterFactory\" prefix=\"__TAS__\"\n+ *               ignore=\"word,&amp;lt;ALPHANUM&amp;gt;,&amp;lt;NUM&amp;gt;,&amp;lt;SOUTHEAST_ASIAN&amp;gt;,&amp;lt;IDEOGRAPHIC&amp;gt;,&amp;lt;HIRAGANA&amp;gt;,&amp;lt;KATAKANA&amp;gt;,&amp;lt;HANGUL&amp;gt;,&amp;lt;EMOJI&amp;gt;\"/&gt;\n+ *   &lt;/analyzer&gt;\n+ * &lt;/fieldType&gt;</pre>\n+ * <p>\n+ * Note that a configuration such as above may interfere with multi-word synonyms. The patterns file has the format:\n+ * <pre>\n+ * (flags) (pattern) ::: (replacement)\n+ * </pre>\n+ * Therefore to set the first 2 flag bits on the original token matching 401k or 401(k) and adding a type of\n+ * 'legal2_401_k' whenever either one is encountered one would use:\n+ * <pre>\n+ * 3 (\\d+)\\(?([a-z])\\)? ::: legal2_$1_$2\n+ * </pre>\n+ * Note that the number indicating the flag bits to set must not have leading spaces and be followed by a single\n+ * space, and must be 0 if no flags should be set. The flags number should not contain commas or a decimal point.\n+ * Lines for which the first character is <code>#</code> will be ignored as comments.  Does not support producing\n+ * a synonym textually identical to the original term.\n+ *\n+ * @lucene.spi {@value #NAME}\n+ * @since 8.8\n+ */\n+public class PatternTypingFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {\n+\n+  /**\n+   * SPI name\n+   */\n+  public static final String NAME = \"patternTyping\";\n+\n+  private final String patternFile;\n+  // todo, perhaps this could be turned into an FST (wanted: regex FST with capturing groups in java)\n+  private final LinkedHashMap<Pattern, String> patterns = new LinkedHashMap<>();\n+  private final Map<Pattern, Integer> flags = new HashMap<>();\n+\n+  /**\n+   * Creates a new KeepWordFilterFactory\n+   */\n+  public PatternTypingFilterFactory(Map<String, String> args) {\n+    super(args);\n+    patternFile = require(args, \"patternFile\");\n+    if (!args.isEmpty()) {\n+      throw new IllegalArgumentException(\"Unknown parameters: \" + args);\n+    }\n+  }\n+\n+  /** Default ctor for compatibility with SPI */\n+  public PatternTypingFilterFactory() {\n+    throw defaultCtorException();\n+  }\n+\n+  @Override\n+  public void inform(ResourceLoader loader) throws IOException {\n+    List<String> lines = getLines(loader, patternFile);\n+    // format: # regex ::: typename[_$1[_$2 ...]]    (technically _$1 does not need the '_' but it usually makes sense)\n+    // eg: 2 (\\d+\\(?([a-z])\\)?\\(?(\\d+)\\)? ::: legal3_$1_$2_3\n+    // which yields legal3_501_c_3 for 501(c)(3) or 501c3 and sets the second lowest bit in flags\n+    for (String line : lines) {\n+      if (line.trim().startsWith(\"#\")) {\n+        continue; // allow for comments\n+      }\n+      int firstSpace = line.indexOf(\" \"); // no leading spaces allowed\n+      int flagsVal = Integer.parseInt(line.substring(0,firstSpace));\n+      line = line.substring(firstSpace + 1);\n+      String[] split = line.split(\" ::: \"); // arbitrary, unlikely to occur in a useful regex easy to read\n+      if (split.length != 2) {\n+        throw new RuntimeException(\"The PatternRecognizerFilter: Always two there are, no more, no less, a pattern and a replacement (separated by ' ::: ' )\");", "originalCommit": "2eabb6e518dd1bcdd8717841894aadb9d0734cdd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "543737ddbcf2b38174729eebfe8e65b44ed55e26", "url": "https://github.com/apache/lucene-solr/commit/543737ddbcf2b38174729eebfe8e65b44ed55e26", "message": "LUCENE-9575 - updates per feedback", "committedDate": "2020-10-22T13:38:04Z", "type": "commit"}, {"oid": "b5ecf28bed955d4bb4344d922b33ffac1bbaf2eb", "url": "https://github.com/apache/lucene-solr/commit/b5ecf28bed955d4bb4344d922b33ffac1bbaf2eb", "message": "LUCENE-9575 - whoops one inline too many, no need for 2 matchers", "committedDate": "2020-10-22T13:45:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDIxODUyMQ==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r510218521", "bodyText": "Thank you for checking my comments.\nWhat do you think about PatternTypingFilterFactory?\nIt's changed from KeepWordFilterFactory to PatternTypingFilter.", "author": "danmuzi", "createdAt": "2020-10-22T14:41:06Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTypingFilterFactory.java", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.analysis.pattern;\n+\n+import org.apache.lucene.analysis.TokenFilterFactory;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.util.ResourceLoader;\n+import org.apache.lucene.util.ResourceLoaderAware;\n+\n+import java.io.IOException;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Pattern;\n+\n+\n+/**\n+ * Provides a filter that will analyze tokens with the analyzer from an arbitrary field type. By itself this\n+ * filter is not very useful. Normally it is combined with a filter that reacts to types or flags.\n+ *\n+ * <pre class=\"prettyprint\" >\n+ * &lt;fieldType name=\"text_taf\" class=\"solr.TextField\" positionIncrementGap=\"100\"&gt;\n+ *   &lt;analyzer&gt;\n+ *     &lt;tokenizer class=\"solr.WhitespaceTokenizerFactory\"/&gt;\n+ *     &lt;filter class=\"com.example.PatternTypingFilter\" patternFile=\"patterns.txt\"/&gt;\n+ *     &lt;filter class=\"solr.TokenAnalyzerFilter\" asType=\"text_en\" preserveType=\"true\"/&gt;\n+ *     &lt;filter class=\"solr.TypeAsSynonymFilterFactory\" prefix=\"__TAS__\"\n+ *               ignore=\"word,&amp;lt;ALPHANUM&amp;gt;,&amp;lt;NUM&amp;gt;,&amp;lt;SOUTHEAST_ASIAN&amp;gt;,&amp;lt;IDEOGRAPHIC&amp;gt;,&amp;lt;HIRAGANA&amp;gt;,&amp;lt;KATAKANA&amp;gt;,&amp;lt;HANGUL&amp;gt;,&amp;lt;EMOJI&amp;gt;\"/&gt;\n+ *   &lt;/analyzer&gt;\n+ * &lt;/fieldType&gt;</pre>\n+ * <p>\n+ * Note that a configuration such as above may interfere with multi-word synonyms. The patterns file has the format:\n+ * <pre>\n+ * (flags) (pattern) ::: (replacement)\n+ * </pre>\n+ * Therefore to set the first 2 flag bits on the original token matching 401k or 401(k) and adding a type of\n+ * 'legal2_401_k' whenever either one is encountered one would use:\n+ * <pre>\n+ * 3 (\\d+)\\(?([a-z])\\)? ::: legal2_$1_$2\n+ * </pre>\n+ * Note that the number indicating the flag bits to set must not have leading spaces and be followed by a single\n+ * space, and must be 0 if no flags should be set. The flags number should not contain commas or a decimal point.\n+ * Lines for which the first character is <code>#</code> will be ignored as comments.  Does not support producing\n+ * a synonym textually identical to the original term.\n+ *\n+ * @lucene.spi {@value #NAME}\n+ * @since 8.8\n+ */\n+public class PatternTypingFilterFactory extends TokenFilterFactory implements ResourceLoaderAware {\n+\n+  /**\n+   * SPI name\n+   */\n+  public static final String NAME = \"patternTyping\";\n+\n+  private final String patternFile;\n+  private final LinkedHashMap<Pattern, Map.Entry<String, Integer>> replacementAndFlagByPattern = new LinkedHashMap<>();\n+\n+  /**\n+   * Creates a new PatternTypingFilter", "originalCommit": "b5ecf28bed955d4bb4344d922b33ffac1bbaf2eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDI4ODc1Mg==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r510288752", "bodyText": "oh darn thx :)", "author": "gus-asf", "createdAt": "2020-10-22T16:14:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDIxODUyMQ=="}], "type": "inlineReview"}, {"oid": "98fd7664117dbb538103f398a7d2fb786dd03b80", "url": "https://github.com/apache/lucene-solr/commit/98fd7664117dbb538103f398a7d2fb786dd03b80", "message": "LUCENE-9575 fix comment", "committedDate": "2020-10-22T16:18:36Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg2ODc1OQ==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r510868759", "bodyText": "Explicitely saying LinkedHashMap sounds strange. I know the list must be sorted, so it's more a list.\nI  would like it to use a <Pattern,String,Integer> record. This would be a classical exple of the new Java 16 record types!\nThis is a public API, any client code may call this - also non-Solr users. So maybe the constructor argument should be a List<PatternTypingRule> (a new class, which may actually be a Record in Java 16/17).", "author": "uschindler", "createdAt": "2020-10-23T13:04:07Z", "path": "lucene/analysis/common/src/java/org/apache/lucene/analysis/pattern/PatternTypingFilter.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.lucene.analysis.pattern;\n+\n+import org.apache.lucene.analysis.TokenFilter;\n+import org.apache.lucene.analysis.TokenStream;\n+import org.apache.lucene.analysis.tokenattributes.CharTermAttribute;\n+import org.apache.lucene.analysis.tokenattributes.FlagsAttribute;\n+import org.apache.lucene.analysis.tokenattributes.TypeAttribute;\n+\n+import java.io.IOException;\n+import java.util.LinkedHashMap;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * Set a type attribute to a parameterized value when tokens are matched by any of a several regex patterns. The\n+ * value set in the type attribute is parameterized with the match groups of the regex used for matching.\n+ * In combination with TypeAsSynonymFilter and DropIfFlagged filter this can supply complex synonym patterns\n+ * that are protected from subsequent analysis, and optionally drop the original term based on the flag\n+ * set in this filter. See {@link PatternTypingFilterFactory} for full documentation.\n+ *\n+ * @see PatternTypingFilterFactory\n+ * @since 8.8.0\n+ */\n+public class PatternTypingFilter extends TokenFilter {\n+\n+  private final Map<Pattern, Map.Entry<String, Integer>> replacementAndFlagByPattern;\n+  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n+  private final FlagsAttribute flagAtt = addAttribute(FlagsAttribute.class);\n+  private final TypeAttribute typeAtt = addAttribute(TypeAttribute.class);\n+\n+  public PatternTypingFilter(TokenStream input, LinkedHashMap<Pattern, Map.Entry<String, Integer>> replacementAndFlagByPattern) {", "originalCommit": "98fd7664117dbb538103f398a7d2fb786dd03b80", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg2OTIzNQ==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r510869235", "bodyText": "FYI, I was not aware that the Map of Patterns and Elements are exposed as public API.", "author": "uschindler", "createdAt": "2020-10-23T13:05:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg2ODc1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg3MDM4Mg==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r510870382", "bodyText": "If we have a class PatternTypingRule we can make constructors to create those: new PatternTypeingRule(Pattern pattern, String replacement, int flag) but also new PatternTypingRule(String pattern, String replacement, int flag).\nI would strongly prefer to not misuse maps.\nWe should also add a varargs constructor PatternTypingFilter(TokenStream input, PatternTypeingRule... rules)", "author": "uschindler", "createdAt": "2020-10-23T13:06:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg2ODc1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzYyODQxMA==", "url": "https://github.com/apache/lucene-solr/pull/1995#discussion_r513628410", "bodyText": "Updated. I agree that this is cleaner. I've started getting some time pressure on this due to end of month approaching so hopefully if you like what I've done we can get this committed. I think we've made good improvements and further refinements have time to be contemplated before 8.8. Getting it in will allow an updated patch for the primary AQP feature.", "author": "gus-asf", "createdAt": "2020-10-28T17:23:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDg2ODc1OQ=="}], "type": "inlineReview"}, {"oid": "06fb121331558d4ec2a4c63183b420287ca76095", "url": "https://github.com/apache/lucene-solr/commit/06fb121331558d4ec2a4c63183b420287ca76095", "message": "LUCENE-9575 add PatternTypingRule", "committedDate": "2020-10-28T17:10:33Z", "type": "commit"}]}