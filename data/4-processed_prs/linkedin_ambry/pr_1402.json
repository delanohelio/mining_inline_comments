{"pr_number": 1402, "pr_title": "Add more tests to hard deleter for undelete record", "pr_createdAt": "2020-02-27T01:50:28Z", "pr_url": "https://github.com/linkedin/ambry/pull/1402", "timeline": [{"oid": "800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "url": "https://github.com/linkedin/ambry/commit/800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "message": "Add even more tests", "committedDate": "2020-02-28T21:41:59Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY1MjE3OA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r386652178", "bodyText": "java doc for this class please", "author": "jsjtzyy", "createdAt": "2020-03-02T21:11:13Z", "path": "ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java", "diffHunk": "@@ -653,22 +680,39 @@ private void performHardDeletes(List<MessageInfo> messageInfoList) throws StoreE\n     }\n   }\n \n+  class HardDeletePersistItem {", "originalCommit": "800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM4MTEzNQ==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r387381135", "bodyText": "updated", "author": "justinlin-linkedin", "createdAt": "2020-03-04T00:46:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY1MjE3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY1MzE0MA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r386653140", "bodyText": "What if recovery range has been pruned but failed to persist cleanup token, will it be a problem?", "author": "jsjtzyy", "createdAt": "2020-03-02T21:13:05Z", "path": "ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java", "diffHunk": "@@ -352,6 +359,24 @@ void preLogFlush() {\n   void postLogFlush() {\n     /* start token saved before the flush is now safe to be persisted */\n     startTokenSafeToPersist = startTokenBeforeLogFlush;\n+\n+    hardDeleteLock.lock();\n+    try {\n+      // PersistCleanupToken because startTokenSafeToPersist changed.\n+      pruneHardDeleteRecoveryRange();\n+      persistCleanupToken();", "originalCommit": "800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM4MjExMA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r387382110", "bodyText": "It's fine if it's fails to persist, then we will wait for the next one.\nThe assumption is that the file on the disk contains a valid range and all the records between this range. And every time we change the file (prune and then persist), we replace the old range with a new one. If we fail to persist it, then next time when we restart, we are going to recover from a older range, which is totally fine, since the hard delete operation is idempotent.", "author": "justinlin-linkedin", "createdAt": "2020-03-04T00:49:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY1MzE0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY1ODY5OA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r386658698", "bodyText": "any reason to change the ordering here? Throttle the hard delete I/O ?", "author": "jsjtzyy", "createdAt": "2020-03-02T21:23:58Z", "path": "ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java", "diffHunk": "@@ -625,9 +652,9 @@ private void performHardDeletes(List<MessageInfo> messageInfoList) throws StoreE\n           throw new StoreException(\"Aborting hard deletes as store is shutting down\",\n               StoreErrorCodes.Store_Shutting_Down);\n         }\n+        diskIOScheduler.getSlice(HARD_DELETE_CLEANUP_JOB_NAME, HARD_DELETE_CLEANUP_JOB_NAME, logWriteInfo.size);", "originalCommit": "800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM4MzAxMQ==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r387383011", "bodyText": "the reason for changing the order is to use diskIOScheduler.getSlice to throw an exception before  modify the log file. The reason why I want to throw an exception is to mock the situation when we persist the HardDeleteRecoveryRange but fail to actually hard delete the records in the log file. Under such situation, we can test if the recovery actually works or not.", "author": "justinlin-linkedin", "createdAt": "2020-03-04T00:52:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY1ODY5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY2MDk5OA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r386660998", "bodyText": "The method looks good, minor suggestion is to align with your comment and do a token type check at the very beginning. (Reject Journal based token)", "author": "jsjtzyy", "createdAt": "2020-03-02T21:28:46Z", "path": "ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java", "diffHunk": "@@ -705,52 +751,64 @@ int getSize() {\n       DataOutputStream dataOutputStream = new DataOutputStream(outStream);\n \n       /* Write the number of entries */\n-      dataOutputStream.writeInt(blobReadOptionsList.size());\n+      dataOutputStream.writeInt(items.size());\n \n       /* Write all the blobReadOptions */\n-      for (BlobReadOptions blobReadOptions : blobReadOptionsList) {\n-        dataOutputStream.write(blobReadOptions.toBytes());\n+      for (HardDeletePersistItem item : items) {\n+        dataOutputStream.write(item.blobReadOptions.toBytes());\n       }\n \n       /* Write all the messageStoreRecoveryInfos */\n-      for (byte[] recoveryInfo : messageStoreRecoveryInfoList) {\n+      for (HardDeletePersistItem item : items) {\n         /* First write the size of the recoveryInfo */\n-        dataOutputStream.writeInt(recoveryInfo.length);\n+        dataOutputStream.writeInt(item.messagesStoreRecoveryInfo.length);\n \n         /* Now, write the recoveryInfo */\n-        dataOutputStream.write(recoveryInfo);\n+        dataOutputStream.write(item.messagesStoreRecoveryInfo);\n       }\n \n       return outStream.toByteArray();\n     }\n \n     /**\n-     * Prunes entries in the range from the start up to, but excluding, the entry with the passed in key.\n+     * Prunes entries in the range from the start up to, but excluding, the entry with the passed in token.\n+     * Token passed to this method has to be a indexed based one.\n      */\n-    void pruneTill(StoreKey storeKey) {\n-      Iterator<BlobReadOptions> blobReadOptionsListIterator = blobReadOptionsList.iterator();\n-      Iterator<byte[]> messageStoreRecoveryListIterator = messageStoreRecoveryInfoList.iterator();\n-      while (blobReadOptionsListIterator.hasNext()) {\n-      /* Note: In the off chance that there are multiple presence of the same key in this range due to prior software\n-         bugs, note that this method prunes only till the first occurrence of the key. If it so happens that a\n-         later occurrence is the one really associated with this token, it does not affect the safety.\n-         Persisting more than what is required is okay as hard deleting a blob is an idempotent operation. */\n-        messageStoreRecoveryListIterator.next();\n-        if (blobReadOptionsListIterator.next().getMessageInfo().getStoreKey().equals(storeKey)) {\n-          break;\n+    void pruneTill(StoreFindToken token) {\n+      Iterator<HardDeletePersistItem> itemsIterator = items.iterator();\n+      while (itemsIterator.hasNext()) {\n+        HardDeletePersistItem item = itemsIterator.next();\n+        if (item.startTokenForBlobReadOptions.getType() == FindTokenType.Uninitialized) {\n+          itemsIterator.remove();\n         } else {\n-          blobReadOptionsListIterator.remove();\n-          messageStoreRecoveryListIterator.remove();\n+          if (compareTwoTokens(item.startTokenForBlobReadOptions, token) >= 0) {\n+            break;\n+          } else {\n+            itemsIterator.remove();\n+          }\n         }\n       }\n     }\n \n-    private List<BlobReadOptions> getBlobReadOptionsList() {\n-      return blobReadOptionsList;\n+    /**\n+     * Compare two StoreFindTokens and return the result as an integer like compareTo interface.\n+     * These two tokens have to be IndexBased tokens.\n+     * @param token1 The first token to compare.\n+     * @param token2 The second tokent to compare.\n+     * @return 0 means they are equal. negative number means token1 is less than token2. postive number means the opposite.\n+     */\n+    int compareTwoTokens(StoreFindToken token1, StoreFindToken token2) {", "originalCommit": "800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM4MzA2NQ==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r387383065", "bodyText": "good catch, updated.", "author": "justinlin-linkedin", "createdAt": "2020-03-04T00:52:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY2MDk5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY2NzkzMA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r386667930", "bodyText": "Could you explain a little bit about this case?", "author": "jsjtzyy", "createdAt": "2020-03-02T21:42:27Z", "path": "ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java", "diffHunk": "@@ -705,52 +751,64 @@ int getSize() {\n       DataOutputStream dataOutputStream = new DataOutputStream(outStream);\n \n       /* Write the number of entries */\n-      dataOutputStream.writeInt(blobReadOptionsList.size());\n+      dataOutputStream.writeInt(items.size());\n \n       /* Write all the blobReadOptions */\n-      for (BlobReadOptions blobReadOptions : blobReadOptionsList) {\n-        dataOutputStream.write(blobReadOptions.toBytes());\n+      for (HardDeletePersistItem item : items) {\n+        dataOutputStream.write(item.blobReadOptions.toBytes());\n       }\n \n       /* Write all the messageStoreRecoveryInfos */\n-      for (byte[] recoveryInfo : messageStoreRecoveryInfoList) {\n+      for (HardDeletePersistItem item : items) {\n         /* First write the size of the recoveryInfo */\n-        dataOutputStream.writeInt(recoveryInfo.length);\n+        dataOutputStream.writeInt(item.messagesStoreRecoveryInfo.length);\n \n         /* Now, write the recoveryInfo */\n-        dataOutputStream.write(recoveryInfo);\n+        dataOutputStream.write(item.messagesStoreRecoveryInfo);\n       }\n \n       return outStream.toByteArray();\n     }\n \n     /**\n-     * Prunes entries in the range from the start up to, but excluding, the entry with the passed in key.\n+     * Prunes entries in the range from the start up to, but excluding, the entry with the passed in token.\n+     * Token passed to this method has to be a indexed based one.\n      */\n-    void pruneTill(StoreKey storeKey) {\n-      Iterator<BlobReadOptions> blobReadOptionsListIterator = blobReadOptionsList.iterator();\n-      Iterator<byte[]> messageStoreRecoveryListIterator = messageStoreRecoveryInfoList.iterator();\n-      while (blobReadOptionsListIterator.hasNext()) {\n-      /* Note: In the off chance that there are multiple presence of the same key in this range due to prior software\n-         bugs, note that this method prunes only till the first occurrence of the key. If it so happens that a\n-         later occurrence is the one really associated with this token, it does not affect the safety.\n-         Persisting more than what is required is okay as hard deleting a blob is an idempotent operation. */\n-        messageStoreRecoveryListIterator.next();\n-        if (blobReadOptionsListIterator.next().getMessageInfo().getStoreKey().equals(storeKey)) {\n-          break;\n+    void pruneTill(StoreFindToken token) {\n+      Iterator<HardDeletePersistItem> itemsIterator = items.iterator();\n+      while (itemsIterator.hasNext()) {\n+        HardDeletePersistItem item = itemsIterator.next();\n+        if (item.startTokenForBlobReadOptions.getType() == FindTokenType.Uninitialized) {", "originalCommit": "800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM4MzQ0NA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r387383444", "bodyText": "The very first time when we starting scanning through the log file, we are using a Uninitialized FindToken. And since it's at the very first beginning of a log file, we can assume they are always prior to any IndexBased FindToken.", "author": "justinlin-linkedin", "createdAt": "2020-03-04T00:54:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY2NzkzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY3MTI2Ng==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r386671266", "bodyText": "For concurrency, let's make sure all variables shared by HardDeleter thread and Index persistor thread to be volatile.", "author": "jsjtzyy", "createdAt": "2020-03-02T21:49:07Z", "path": "ambry-store/src/main/java/com.github.ambry.store/HardDeleter.java", "diffHunk": "@@ -89,9 +89,9 @@\n    * startTokenBeforeLogFlush: This token is set to the current start token just before log flush and once the log is\n    *                           flushed, this is used to set startTokenSafeToPersist.\n    */\n-  private FindToken startToken;\n   private FindToken startTokenBeforeLogFlush;\n-  private FindToken startTokenSafeToPersist;\n+  private volatile FindToken startTokenSafeToPersist;", "originalCommit": "800ca7861ec747243c4bd0bb3ee6c4f103bb511e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM4MzQ2NA==", "url": "https://github.com/linkedin/ambry/pull/1402#discussion_r387383464", "bodyText": "sure.", "author": "justinlin-linkedin", "createdAt": "2020-03-04T00:54:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY3MTI2Ng=="}], "type": "inlineReview"}, {"oid": "d0c0c1d86e969f1645bee8112fb1c6e3a0931a25", "url": "https://github.com/linkedin/ambry/commit/d0c0c1d86e969f1645bee8112fb1c6e3a0931a25", "message": "Add more tests to hard deleter for undelete record", "committedDate": "2020-03-04T00:01:35Z", "type": "commit"}, {"oid": "e4345cd6237deb736526c9f1bf7351120e3942c0", "url": "https://github.com/linkedin/ambry/commit/e4345cd6237deb736526c9f1bf7351120e3942c0", "message": "Add even more tests", "committedDate": "2020-03-04T00:01:35Z", "type": "commit"}, {"oid": "a4412c6929a5950386f6a2af694a703be3d41531", "url": "https://github.com/linkedin/ambry/commit/a4412c6929a5950386f6a2af694a703be3d41531", "message": "Add something", "committedDate": "2020-03-04T00:46:07Z", "type": "commit"}, {"oid": "a4412c6929a5950386f6a2af694a703be3d41531", "url": "https://github.com/linkedin/ambry/commit/a4412c6929a5950386f6a2af694a703be3d41531", "message": "Add something", "committedDate": "2020-03-04T00:46:07Z", "type": "forcePushed"}]}