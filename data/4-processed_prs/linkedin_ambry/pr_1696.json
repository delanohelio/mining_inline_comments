{"pr_number": 1696, "pr_title": "[StorageQuota]Implement container storage usage report with MySQL", "pr_createdAt": "2020-11-17T06:51:31Z", "pr_url": "https://github.com/linkedin/ambry/pull/1696", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUxODEwNw==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r525518107", "bodyText": "javadoc for these two methods", "author": "lightningrob", "createdAt": "2020-11-17T20:54:44Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountStatsMySqlStore.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.codahale.metrics.Histogram;\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import com.github.ambry.mysql.MySqlMetrics;\n+import com.github.ambry.mysql.MySqlUtils;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import java.io.File;\n+import java.sql.SQLException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import joptsimple.internal.Strings;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * This class publishes container storage usage to mysql. It saves previous copy of {@link StatsWrapper} and compare\n+ * the current {@link StatsWrapper} with the previous and only update the containers that have different storage usage.\n+ * It also assumes a local copy of {@link StatsWrapper} will be saved after publishing to mysql database, so it can recover\n+ * the previous {@link StatsWrapper} from crashing or restarting.\n+ */\n+public class AccountStatsMySqlStore {\n+\n+  private final AccountReportsDao accountReportsDao;\n+  private StatsWrapper previousStats;\n+  private final Metrics storeMetrics;\n+\n+  /**\n+   * Metrics for {@link AccountStatsMySqlStore}.\n+   */\n+  private static class Metrics {\n+    public final Histogram batchSize;\n+    public final Histogram publishTimeMs;\n+\n+    /**\n+     * Constructor to create the Metrics.\n+     * @param registry The {@link MetricRegistry}.\n+     */\n+    public Metrics(MetricRegistry registry) {\n+      batchSize = registry.histogram(MetricRegistry.name(AccountStatsMySqlStore.class, \"BatchSize\"));\n+      publishTimeMs = registry.histogram(MetricRegistry.name(AccountStatsMySqlStore.class, \"PublishTimeMs\"));\n+    }\n+  }\n+\n+  /**\n+   * Constructor to create {@link AccountStatsMySqlStore}.\n+   * @param dbEndpoints MySql DB end points.\n+   * @param localDatacenter The local datacenter name. Endpoints from local datacenter are preferred when creating connection to MySql DB.\n+   * @param clustername  The name of the cluster, like Ambry-prod.\n+   * @param hostname The name of the host.\n+   * @param localBackupFilePath The filepath to local backup file.\n+   * @param registry The {@link MetricRegistry}.\n+   * @throws SQLException\n+   */\n+  public AccountStatsMySqlStore(List<MySqlUtils.DbEndpoint> dbEndpoints, String localDatacenter, String clustername,\n+      String hostname, String localBackupFilePath, MetricRegistry registry) throws SQLException {\n+    this(new MySqlDataAccessor(dbEndpoints, localDatacenter, new MySqlMetrics(AccountStatsMySqlStore.class, registry)),\n+        clustername, hostname, localBackupFilePath, registry);\n+  }\n+\n+  /**\n+   * Constructor to create link {@link AccountStatsMySqlStore}. It's only used in tests.\n+   * @param dataAccessor The {@link MySqlDataAccessor}.\n+   * @param clustername  The name of the cluster, like Ambry-prod.\n+   * @param hostname The name of the host.\n+   * @param localBackupFilePath The filepath to local backup file.\n+   * @param registry The {@link MetricRegistry}.\n+   */\n+  AccountStatsMySqlStore(MySqlDataAccessor dataAccessor, String clustername, String hostname,\n+      String localBackupFilePath, MetricRegistry registry) {\n+    accountReportsDao = new AccountReportsDao(dataAccessor, clustername, hostname);\n+    storeMetrics = new AccountStatsMySqlStore.Metrics(registry);\n+    if (!Strings.isNullOrEmpty(localBackupFilePath)) {\n+      // load backup file and this backup is the previous stats\n+      ObjectMapper objectMapper = new ObjectMapper();\n+      try {\n+        this.previousStats = objectMapper.readValue(new File(localBackupFilePath), StatsWrapper.class);\n+      } catch (Exception e) {\n+        this.previousStats = null;\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Publish the {@link StatsWrapper} to mysql database. This method ignores the error information from {@link StatsWrapper}\n+   * and only publish the container storage usages that are different from the previous one.\n+   * @param statsWrapper The {@link StatsWrapper} to publish.\n+   */\n+  public void publish(StatsWrapper statsWrapper) {\n+    if (previousStats == null) {\n+      applyFunctionToContainerUsageInStatsSnapshot(statsWrapper.getSnapshot(), accountReportsDao::updateStorageUsage);\n+    } else {\n+      applyFunctionToContainerUsageInDifferentStatsSnapshots(statsWrapper.getSnapshot(), previousStats.getSnapshot(),\n+          accountReportsDao::updateStorageUsage);\n+    }\n+    previousStats = statsWrapper;\n+  }\n+\n+  StatsWrapper getPreviousStats() {\n+    return previousStats;\n+  }\n+\n+  private void applyFunctionToContainerUsageInStatsSnapshot(StatsSnapshot statsSnapshot, ContainerUsageFunction func) {", "originalCommit": "8c6b172b6155c3f7925bebece034b7472a692c9e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMDMzNw==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r525520337", "bodyText": "It's not clear what batchSize represents here, since the DB inserts are made one by one rather than batched.  Is batching planned for later?", "author": "lightningrob", "createdAt": "2020-11-17T20:58:53Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountStatsMySqlStore.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.codahale.metrics.Histogram;\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import com.github.ambry.mysql.MySqlMetrics;\n+import com.github.ambry.mysql.MySqlUtils;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import java.io.File;\n+import java.sql.SQLException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import joptsimple.internal.Strings;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * This class publishes container storage usage to mysql. It saves previous copy of {@link StatsWrapper} and compare\n+ * the current {@link StatsWrapper} with the previous and only update the containers that have different storage usage.\n+ * It also assumes a local copy of {@link StatsWrapper} will be saved after publishing to mysql database, so it can recover\n+ * the previous {@link StatsWrapper} from crashing or restarting.\n+ */\n+public class AccountStatsMySqlStore {\n+\n+  private final AccountReportsDao accountReportsDao;\n+  private StatsWrapper previousStats;\n+  private final Metrics storeMetrics;\n+\n+  /**\n+   * Metrics for {@link AccountStatsMySqlStore}.\n+   */\n+  private static class Metrics {\n+    public final Histogram batchSize;\n+    public final Histogram publishTimeMs;\n+\n+    /**\n+     * Constructor to create the Metrics.\n+     * @param registry The {@link MetricRegistry}.\n+     */\n+    public Metrics(MetricRegistry registry) {\n+      batchSize = registry.histogram(MetricRegistry.name(AccountStatsMySqlStore.class, \"BatchSize\"));\n+      publishTimeMs = registry.histogram(MetricRegistry.name(AccountStatsMySqlStore.class, \"PublishTimeMs\"));\n+    }\n+  }\n+\n+  /**\n+   * Constructor to create {@link AccountStatsMySqlStore}.\n+   * @param dbEndpoints MySql DB end points.\n+   * @param localDatacenter The local datacenter name. Endpoints from local datacenter are preferred when creating connection to MySql DB.\n+   * @param clustername  The name of the cluster, like Ambry-prod.\n+   * @param hostname The name of the host.\n+   * @param localBackupFilePath The filepath to local backup file.\n+   * @param registry The {@link MetricRegistry}.\n+   * @throws SQLException\n+   */\n+  public AccountStatsMySqlStore(List<MySqlUtils.DbEndpoint> dbEndpoints, String localDatacenter, String clustername,\n+      String hostname, String localBackupFilePath, MetricRegistry registry) throws SQLException {\n+    this(new MySqlDataAccessor(dbEndpoints, localDatacenter, new MySqlMetrics(AccountStatsMySqlStore.class, registry)),\n+        clustername, hostname, localBackupFilePath, registry);\n+  }\n+\n+  /**\n+   * Constructor to create link {@link AccountStatsMySqlStore}. It's only used in tests.\n+   * @param dataAccessor The {@link MySqlDataAccessor}.\n+   * @param clustername  The name of the cluster, like Ambry-prod.\n+   * @param hostname The name of the host.\n+   * @param localBackupFilePath The filepath to local backup file.\n+   * @param registry The {@link MetricRegistry}.\n+   */\n+  AccountStatsMySqlStore(MySqlDataAccessor dataAccessor, String clustername, String hostname,\n+      String localBackupFilePath, MetricRegistry registry) {\n+    accountReportsDao = new AccountReportsDao(dataAccessor, clustername, hostname);\n+    storeMetrics = new AccountStatsMySqlStore.Metrics(registry);\n+    if (!Strings.isNullOrEmpty(localBackupFilePath)) {\n+      // load backup file and this backup is the previous stats\n+      ObjectMapper objectMapper = new ObjectMapper();\n+      try {\n+        this.previousStats = objectMapper.readValue(new File(localBackupFilePath), StatsWrapper.class);\n+      } catch (Exception e) {\n+        this.previousStats = null;\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Publish the {@link StatsWrapper} to mysql database. This method ignores the error information from {@link StatsWrapper}\n+   * and only publish the container storage usages that are different from the previous one.\n+   * @param statsWrapper The {@link StatsWrapper} to publish.\n+   */\n+  public void publish(StatsWrapper statsWrapper) {\n+    if (previousStats == null) {\n+      applyFunctionToContainerUsageInStatsSnapshot(statsWrapper.getSnapshot(), accountReportsDao::updateStorageUsage);\n+    } else {\n+      applyFunctionToContainerUsageInDifferentStatsSnapshots(statsWrapper.getSnapshot(), previousStats.getSnapshot(),\n+          accountReportsDao::updateStorageUsage);\n+    }\n+    previousStats = statsWrapper;\n+  }\n+\n+  StatsWrapper getPreviousStats() {\n+    return previousStats;\n+  }\n+\n+  private void applyFunctionToContainerUsageInStatsSnapshot(StatsSnapshot statsSnapshot, ContainerUsageFunction func) {\n+    int batchSize = 0;\n+    long startTimeMs = System.currentTimeMillis();\n+    // StatsSnapshot has three levels, Parition -> Account -> Container\n+    Map<String, StatsSnapshot> partitionMap = statsSnapshot.getSubMap();\n+    for (Map.Entry<String, StatsSnapshot> partitionMapEntry : partitionMap.entrySet()) {\n+      String partitionIdKey = partitionMapEntry.getKey();\n+      StatsSnapshot accountStatsSnapshot = partitionMapEntry.getValue();\n+      short partitionId = Short.valueOf(partitionIdKey.substring(\"Partition[\".length(), partitionIdKey.length() - 1));\n+      Map<String, StatsSnapshot> accountMap = accountStatsSnapshot.getSubMap();\n+      for (Map.Entry<String, StatsSnapshot> accountMapEntry : accountMap.entrySet()) {\n+        String accountIdKey = accountMapEntry.getKey();\n+        StatsSnapshot containerStatsSnapshot = accountMapEntry.getValue();\n+        short accountId = Short.valueOf(accountIdKey.substring(2, accountIdKey.length() - 1));\n+        Map<String, StatsSnapshot> containerMap = containerStatsSnapshot.getSubMap();\n+        for (Map.Entry<String, StatsSnapshot> containerMapEntry : containerMap.entrySet()) {\n+          String containerIdKey = containerMapEntry.getKey();\n+          short containerId = Short.valueOf(containerIdKey.substring(2, containerIdKey.length() - 1));\n+          long storageUsage = containerMapEntry.getValue().getValue();\n+          func.apply(partitionId, accountId, containerId, storageUsage);\n+          batchSize++;", "originalCommit": "8c6b172b6155c3f7925bebece034b7472a692c9e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQzOTc4Ng==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r526439786", "bodyText": "I am seeing addBatch method from java.sql.Statement. There might be a way to batch those writes to mysql database later. Besides, I also want to know how many container has changed after last update. This would give us a way to know the write traffic to mysql database.", "author": "justinlin-linkedin", "createdAt": "2020-11-18T21:41:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMDMzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyNDA1NQ==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r525524055", "bodyText": "Do you want to pass all of the DB endpoints to the store or just the one(s) in local colo?  If local endpoint is down, the MySqlDataAccessor will try to publish the data to a remote endpoint.  My understanding from our discussion was that you didn't want that.", "author": "lightningrob", "createdAt": "2020-11-17T21:05:32Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountStatsMySqlStoreFactory.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.config.AccountStatsMySqlConfig;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.config.StatsManagerConfig;\n+import com.github.ambry.config.VerifiableProperties;\n+import java.sql.SQLException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.mysql.MySqlUtils.*;\n+\n+\n+/**\n+ * Factory to create a {@link AccountStatsMySqlStore}.\n+ */\n+public class AccountStatsMySqlStoreFactory {\n+  private static final Logger logger = LoggerFactory.getLogger(AccountStatsMySqlStoreFactory.class);\n+\n+  private final AccountStatsMySqlConfig accountStatsMySqlConfig;\n+  private final String localDC;\n+  private final String clustername;\n+  private final String hostname;\n+  private final MetricRegistry registry;\n+  private final String localBackupFilePath;\n+\n+  /**\n+   * Constructor to create a {@link AccountStatsMySqlStoreFactory}.\n+   * @param verifiableProperties\n+   * @param clusterMapConfig\n+   * @param statsManagerConfig\n+   * @param registry\n+   */\n+  public AccountStatsMySqlStoreFactory(VerifiableProperties verifiableProperties, ClusterMapConfig clusterMapConfig,\n+      StatsManagerConfig statsManagerConfig, MetricRegistry registry) {\n+    accountStatsMySqlConfig = new AccountStatsMySqlConfig(verifiableProperties);\n+    clustername = clusterMapConfig.clusterMapClusterName;\n+    String[] domainNamesToRemove = accountStatsMySqlConfig.domainNamesToRemove.split(\",\");\n+\n+    String fullyQualifiedDomainName = clusterMapConfig.clusterMapHostName;\n+    int port = clusterMapConfig.clusterMapPort;\n+    for (String domainName : domainNamesToRemove) {\n+      if (domainName.charAt(0) != '.') {\n+        domainName = \".\" + domainName;\n+      }\n+      fullyQualifiedDomainName = fullyQualifiedDomainName.replace(domainName, \"\");\n+    }\n+    hostname = String.format(\"%s_%d\", fullyQualifiedDomainName, port);\n+    localDC = clusterMapConfig.clusterMapDatacenterName;\n+    localBackupFilePath = statsManagerConfig.outputFilePath;\n+    this.registry = registry;\n+  }\n+\n+  /**\n+   * Return {@link AccountStatsMySqlStore}.\n+   * @return\n+   * @throws SQLException\n+   */\n+  public AccountStatsMySqlStore getAccountStatsMySqlStore() throws SQLException {\n+    Map<String, List<DbEndpoint>> dcToMySqlDBEndpoints = getDbEndpointsPerDC(accountStatsMySqlConfig.dbInfo);\n+    // Flatten to List (TODO: does utility method need to return map?)\n+    List<DbEndpoint> dbEndpoints = new ArrayList<>();\n+    dcToMySqlDBEndpoints.values().forEach(endpointList -> dbEndpoints.addAll(endpointList));", "originalCommit": "8c6b172b6155c3f7925bebece034b7472a692c9e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQzODUxMA==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r526438510", "bodyText": "Updated, to only use the db endpoints from local dc.", "author": "justinlin-linkedin", "createdAt": "2020-11-18T21:39:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyNDA1NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyNjIxMg==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r525526212", "bodyText": "An integration test would be good too.  You could probably extend this class to one that uses an actual mysql db.", "author": "lightningrob", "createdAt": "2020-11-17T21:09:55Z", "path": "ambry-server/src/test/java/com/github/ambry/server/mysql/AccountStatsMySqlStoreTest.java", "diffHunk": "@@ -0,0 +1,238 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import com.github.ambry.mysql.MySqlMetrics;\n+import com.github.ambry.mysql.MySqlUtils;\n+import com.github.ambry.server.StatsHeader;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.sql.Connection;\n+import java.sql.Driver;\n+import java.sql.PreparedStatement;\n+import java.sql.SQLException;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Random;\n+import org.codehaus.jackson.map.ObjectMapper;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+import static org.mockito.Mockito.*;\n+\n+\n+public class AccountStatsMySqlStoreTest {\n+  private final Connection mockConnection;\n+  private final MySqlDataAccessor dataAccessor;\n+  private final MySqlMetrics metrics;\n+  private static final String clustername = \"Ambry-test\";\n+  private static final String hostname = \"test1.ambry_1300\";\n+  private static final long MAX_CONTAINER_USAGE = 100000;\n+  private static final long MIN_CONTAINER_USAGE = 1000;\n+  private static final long DEFAULT_CONTAINER_USAGE = 5000;\n+  private static final int BASE_PARTITION_ID = 100;\n+  private static final int BASE_ACCOUNT_ID = 1000;\n+  private static final int BASE_CONTAINER_ID = 1;\n+\n+  public AccountStatsMySqlStoreTest() throws SQLException {\n+    mockConnection = mock(Connection.class);", "originalCommit": "8c6b172b6155c3f7925bebece034b7472a692c9e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQzNTE2Mw==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r526435163", "bodyText": "integration test added", "author": "justinlin-linkedin", "createdAt": "2020-11-18T21:33:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyNjIxMg=="}], "type": "inlineReview"}, {"oid": "40a63dea7e1bd0ed3f70f398ec98686e92b36cb3", "url": "https://github.com/linkedin/ambry/commit/40a63dea7e1bd0ed3f70f398ec98686e92b36cb3", "message": "Add integration test", "committedDate": "2020-11-18T06:04:56Z", "type": "forcePushed"}, {"oid": "c465ea57c8cba41b4caabac0c563b873a38cd276", "url": "https://github.com/linkedin/ambry/commit/c465ea57c8cba41b4caabac0c563b873a38cd276", "message": "Add integration test", "committedDate": "2020-11-18T06:05:42Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQwNDM1MA==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r526404350", "bodyText": "It looks suspicious that the method is eating the exception just so it can be called as a function.  That also raises the question: what if the mysql instance is down during the whole report run - will the report complete successfully even though every sql update failed and logged an error?", "author": "lightningrob", "createdAt": "2020-11-18T20:37:01Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountReportsDao.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.Objects;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.mysql.MySqlDataAccessor.OperationType.*;\n+\n+\n+/**\n+ * AccountReports Data Access Object.\n+ */\n+public class AccountReportsDao {\n+  public static final String ACCOUNT_REPORTS_TABLE = \"AccountReports\";\n+  public static final String CLUSTERNAME_COLUMN = \"clusterName\";\n+  public static final String HOSTNAME_COLUMN = \"hostname\";\n+  public static final String PARTITION_ID_COLUMN = \"partitionId\";\n+  public static final String ACCOUNT_ID_COLUMN = \"accountId\";\n+  public static final String CONTAINER_ID_COLUMN = \"containerId\";\n+  public static final String STORAGE_USAGE_COLUMN = \"storageUsage\";\n+  public static final String UPDATED_AT_COLUMN = \"updatedAt\";\n+\n+  private static final Logger logger = LoggerFactory.getLogger(AccountReportsDao.class);\n+  private static final String insertSql =\n+      String.format(\"INSERT INTO %s (%s, %s, %s, %s, %s, %s, %s) VALUES (?, ?, ?, ?, ?, ?, NOW())\",\n+          ACCOUNT_REPORTS_TABLE, CLUSTERNAME_COLUMN, HOSTNAME_COLUMN, PARTITION_ID_COLUMN, ACCOUNT_ID_COLUMN,\n+          CONTAINER_ID_COLUMN, STORAGE_USAGE_COLUMN, UPDATED_AT_COLUMN);\n+  private static final String querySqlForClusterAndHost =\n+      String.format(\"SELECT %s, %s, %s, %s FROM %s WHERE %s = ? AND %s = ?\", PARTITION_ID_COLUMN, ACCOUNT_ID_COLUMN,\n+          CONTAINER_ID_COLUMN, STORAGE_USAGE_COLUMN, ACCOUNT_REPORTS_TABLE, CLUSTERNAME_COLUMN, HOSTNAME_COLUMN);\n+  private final MySqlDataAccessor dataAccessor;\n+  private final String clustername;\n+  private final String hostname;\n+\n+  /**\n+   * Constructor to create a {@link AccountReportsDao}.\n+   * @param dataAccessor The underlying {@link MySqlDataAccessor}.\n+   * @param clustername The name of the cluster this host is belonging to, like Ambry-prod, Ambry-video.\n+   * @param hostname The name of the host. It should include the hostname and the port.\n+   */\n+  public AccountReportsDao(MySqlDataAccessor dataAccessor, String clustername, String hostname) {\n+    this.dataAccessor = Objects.requireNonNull(dataAccessor, \"MySqlDataAccessor is empty\");\n+    this.clustername = Objects.requireNonNull(clustername, \"clustername is empty\");\n+    this.hostname = Objects.requireNonNull(hostname, \"hostname is empty\");\n+  }\n+\n+  /**\n+   * Update the storage usage for the given account/container.\n+   * @param partitionId The partition id of this account/container usage.\n+   * @param accountId The account id.\n+   * @param containerId The container id.\n+   * @param storageUsage The storage usage in bytes.\n+   */\n+  public void updateStorageUsage(short partitionId, short accountId, short containerId, long storageUsage) {\n+    try {\n+      long startTimeMs = System.currentTimeMillis();\n+      PreparedStatement insertStatement = dataAccessor.getPreparedStatement(insertSql, true);\n+      insertStatement.setString(1, clustername);\n+      insertStatement.setString(2, hostname);\n+      // The data type of partition id, account id and container id are not SMALLINT, but INT in MySQL, for\n+      // future extension\n+      insertStatement.setInt(3, partitionId);\n+      insertStatement.setInt(4, accountId);\n+      insertStatement.setInt(5, containerId);\n+      insertStatement.setLong(6, storageUsage);\n+      insertStatement.executeUpdate();\n+      dataAccessor.onSuccess(Write, System.currentTimeMillis() - startTimeMs);\n+    } catch (SQLException e) {", "originalCommit": "38da83a0aaf2e0edcfb8ed7ac0add41866dfc0fb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ0MDk4Mg==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r526440982", "bodyText": "It will and that's by design. Reporting container storage usage will be done periodically in every 10 minutes. If the writes failed, it's fine to move on and wait for next reports. Besides, reporting container usage is not an essential components for ambry, ambry can survive without it.", "author": "justinlin-linkedin", "createdAt": "2020-11-18T21:43:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQwNDM1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MDc0Ng==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r526490746", "bodyText": "The part about the report makes sense.  But that knowledge shouldn't be hard wired into the DAO method.  I'd prefer to have it throw SQLException, add a wrapper method in AccountStatsMySqlStore to call it and suppress the exception, and use the wrapper method as your lambda.", "author": "lightningrob", "createdAt": "2020-11-18T23:28:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQwNDM1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzEwMjgzOQ==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527102839", "bodyText": "updated as commented.", "author": "justinlin-linkedin", "createdAt": "2020-11-19T18:21:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQwNDM1MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0MTExNQ==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527141115", "bodyText": "minor: since statsWrapper is not modified in accountStatsMySqlStore.publish(), we can reuse it in original publish() method", "author": "jsjtzyy", "createdAt": "2020-11-19T19:25:13Z", "path": "ambry-server/src/main/java/com/github/ambry/server/StatsManager.java", "diffHunk": "@@ -335,6 +341,11 @@ public void run() {\n           StatsHeader statsHeader = new StatsHeader(StatsHeader.StatsDescription.STORED_DATA_SIZE, time.milliseconds(),\n               partitionToReplicaMap.keySet().size(), partitionToReplicaMap.keySet().size() - unreachableStores.size(),\n               unreachableStores);\n+          // First write to account stats\n+          StatsWrapper statsWrapper = new StatsWrapper(statsHeader, aggregatedSnapshot);\n+          if (accountStatsMySqlStore != null) {\n+            accountStatsMySqlStore.publish(statsWrapper);\n+          }\n           publish(new StatsWrapper(statsHeader, aggregatedSnapshot));", "originalCommit": "81555acbb6587e63d3203966e7e1f4a50d23e807", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzkyNjEzMw==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527926133", "bodyText": "updated.", "author": "justinlin-linkedin", "createdAt": "2020-11-20T19:29:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0MTExNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0MzkwNQ==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527143905", "bodyText": "Honestly, I would prefer to pass AccountStatsMySqlStore into StatsManager ctor rather than the start method. This can be improved in future PR once the Mysql based stats service is verified.", "author": "jsjtzyy", "createdAt": "2020-11-19T19:29:35Z", "path": "ambry-server/src/main/java/com/github/ambry/server/StatsManager.java", "diffHunk": "@@ -98,9 +99,9 @@\n   /**\n    * Start the stats manager by scheduling the periodic task that collect, aggregate and publish stats.\n    */\n-  void start() {\n+  void start(AccountStatsMySqlStore accountStatsMySqlStore) {", "originalCommit": "81555acbb6587e63d3203966e7e1f4a50d23e807", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzkyNjIyNA==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527926224", "bodyText": "updated.", "author": "justinlin-linkedin", "createdAt": "2020-11-20T19:30:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0MzkwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0NDcxNg==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527144716", "bodyText": "nit: clusterName  (please update all relevant variables in this file)", "author": "jsjtzyy", "createdAt": "2020-11-19T19:30:49Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountReportsDao.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.Objects;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.mysql.MySqlDataAccessor.OperationType.*;\n+\n+\n+/**\n+ * AccountReports Data Access Object.\n+ */\n+public class AccountReportsDao {\n+  public static final String ACCOUNT_REPORTS_TABLE = \"AccountReports\";\n+  public static final String CLUSTERNAME_COLUMN = \"clusterName\";\n+  public static final String HOSTNAME_COLUMN = \"hostname\";\n+  public static final String PARTITION_ID_COLUMN = \"partitionId\";\n+  public static final String ACCOUNT_ID_COLUMN = \"accountId\";\n+  public static final String CONTAINER_ID_COLUMN = \"containerId\";\n+  public static final String STORAGE_USAGE_COLUMN = \"storageUsage\";\n+  public static final String UPDATED_AT_COLUMN = \"updatedAt\";\n+\n+  private static final Logger logger = LoggerFactory.getLogger(AccountReportsDao.class);\n+  private static final String insertSql =\n+      String.format(\"INSERT INTO %s (%s, %s, %s, %s, %s, %s, %s) VALUES (?, ?, ?, ?, ?, ?, NOW())\",\n+          ACCOUNT_REPORTS_TABLE, CLUSTERNAME_COLUMN, HOSTNAME_COLUMN, PARTITION_ID_COLUMN, ACCOUNT_ID_COLUMN,\n+          CONTAINER_ID_COLUMN, STORAGE_USAGE_COLUMN, UPDATED_AT_COLUMN);\n+  private static final String querySqlForClusterAndHost =\n+      String.format(\"SELECT %s, %s, %s, %s FROM %s WHERE %s = ? AND %s = ?\", PARTITION_ID_COLUMN, ACCOUNT_ID_COLUMN,\n+          CONTAINER_ID_COLUMN, STORAGE_USAGE_COLUMN, ACCOUNT_REPORTS_TABLE, CLUSTERNAME_COLUMN, HOSTNAME_COLUMN);\n+  private final MySqlDataAccessor dataAccessor;\n+  private final String clustername;", "originalCommit": "81555acbb6587e63d3203966e7e1f4a50d23e807", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzkyNjMxNQ==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527926315", "bodyText": "updated.", "author": "justinlin-linkedin", "createdAt": "2020-11-20T19:30:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0NDcxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0OTY2MQ==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527149661", "bodyText": "Where the startTimeMs is used?", "author": "jsjtzyy", "createdAt": "2020-11-19T19:39:24Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountReportsDao.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.Objects;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.mysql.MySqlDataAccessor.OperationType.*;\n+\n+\n+/**\n+ * AccountReports Data Access Object.\n+ */\n+public class AccountReportsDao {\n+  public static final String ACCOUNT_REPORTS_TABLE = \"AccountReports\";\n+  public static final String CLUSTERNAME_COLUMN = \"clusterName\";\n+  public static final String HOSTNAME_COLUMN = \"hostname\";\n+  public static final String PARTITION_ID_COLUMN = \"partitionId\";\n+  public static final String ACCOUNT_ID_COLUMN = \"accountId\";\n+  public static final String CONTAINER_ID_COLUMN = \"containerId\";\n+  public static final String STORAGE_USAGE_COLUMN = \"storageUsage\";\n+  public static final String UPDATED_AT_COLUMN = \"updatedAt\";\n+\n+  private static final Logger logger = LoggerFactory.getLogger(AccountReportsDao.class);\n+  private static final String insertSql =\n+      String.format(\"INSERT INTO %s (%s, %s, %s, %s, %s, %s, %s) VALUES (?, ?, ?, ?, ?, ?, NOW())\",\n+          ACCOUNT_REPORTS_TABLE, CLUSTERNAME_COLUMN, HOSTNAME_COLUMN, PARTITION_ID_COLUMN, ACCOUNT_ID_COLUMN,\n+          CONTAINER_ID_COLUMN, STORAGE_USAGE_COLUMN, UPDATED_AT_COLUMN);\n+  private static final String querySqlForClusterAndHost =\n+      String.format(\"SELECT %s, %s, %s, %s FROM %s WHERE %s = ? AND %s = ?\", PARTITION_ID_COLUMN, ACCOUNT_ID_COLUMN,\n+          CONTAINER_ID_COLUMN, STORAGE_USAGE_COLUMN, ACCOUNT_REPORTS_TABLE, CLUSTERNAME_COLUMN, HOSTNAME_COLUMN);\n+  private final MySqlDataAccessor dataAccessor;\n+  private final String clustername;\n+  private final String hostname;\n+\n+  /**\n+   * Constructor to create a {@link AccountReportsDao}.\n+   * @param dataAccessor The underlying {@link MySqlDataAccessor}.\n+   * @param clustername The name of the cluster this host is belonging to, like Ambry-prod, Ambry-video.\n+   * @param hostname The name of the host. It should include the hostname and the port.\n+   */\n+  public AccountReportsDao(MySqlDataAccessor dataAccessor, String clustername, String hostname) {\n+    this.dataAccessor = Objects.requireNonNull(dataAccessor, \"MySqlDataAccessor is empty\");\n+    this.clustername = Objects.requireNonNull(clustername, \"clustername is empty\");\n+    this.hostname = Objects.requireNonNull(hostname, \"hostname is empty\");\n+  }\n+\n+  /**\n+   * Update the storage usage for the given account/container.\n+   * @param partitionId The partition id of this account/container usage.\n+   * @param accountId The account id.\n+   * @param containerId The container id.\n+   * @param storageUsage The storage usage in bytes.\n+   */\n+  public void updateStorageUsage(short partitionId, short accountId, short containerId, long storageUsage)\n+      throws SQLException {\n+    try {\n+      long startTimeMs = System.currentTimeMillis();\n+      PreparedStatement insertStatement = dataAccessor.getPreparedStatement(insertSql, true);\n+      insertStatement.setString(1, clustername);\n+      insertStatement.setString(2, hostname);\n+      // The data type of partition id, account id and container id are not SMALLINT, but INT in MySQL, for\n+      // future extension\n+      insertStatement.setInt(3, partitionId);\n+      insertStatement.setInt(4, accountId);\n+      insertStatement.setInt(5, containerId);\n+      insertStatement.setLong(6, storageUsage);\n+      insertStatement.executeUpdate();\n+      dataAccessor.onSuccess(Write, System.currentTimeMillis() - startTimeMs);\n+    } catch (SQLException e) {\n+      dataAccessor.onException(e, Write);\n+      logger.error(String.format(\"Failed to execute updated on %s, with parameter %d %d %d %d\", ACCOUNT_REPORTS_TABLE,\n+          partitionId, accountId, containerId, storageUsage), e);\n+      throw e;\n+    }\n+  }\n+\n+  public void queryForClusterAndHost(String clustername, String hostname, ContainerUsageFunction func)\n+      throws SQLException {\n+    try {\n+      long startTimeMs = System.currentTimeMillis();", "originalCommit": "81555acbb6587e63d3203966e7e1f4a50d23e807", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzkyNjQ4MQ==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527926481", "bodyText": "used to recorded the latency. updated.", "author": "justinlin-linkedin", "createdAt": "2020-11-20T19:30:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE0OTY2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE1MTc5Ng==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527151796", "bodyText": "I think this method will be called by single node when updating node-level stats (correct me if I am wrong).\nThis reminds me that if a replica is removed from this node, do we have a way to delete the entry associated with this partitionId?  (The ZK based solution doesn't have this issue as it overrides the whole znode every time.)", "author": "jsjtzyy", "createdAt": "2020-11-19T19:42:52Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountReportsDao.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.Objects;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.mysql.MySqlDataAccessor.OperationType.*;\n+\n+\n+/**\n+ * AccountReports Data Access Object.\n+ */\n+public class AccountReportsDao {\n+  public static final String ACCOUNT_REPORTS_TABLE = \"AccountReports\";\n+  public static final String CLUSTERNAME_COLUMN = \"clusterName\";\n+  public static final String HOSTNAME_COLUMN = \"hostname\";\n+  public static final String PARTITION_ID_COLUMN = \"partitionId\";\n+  public static final String ACCOUNT_ID_COLUMN = \"accountId\";\n+  public static final String CONTAINER_ID_COLUMN = \"containerId\";\n+  public static final String STORAGE_USAGE_COLUMN = \"storageUsage\";\n+  public static final String UPDATED_AT_COLUMN = \"updatedAt\";\n+\n+  private static final Logger logger = LoggerFactory.getLogger(AccountReportsDao.class);\n+  private static final String insertSql =\n+      String.format(\"INSERT INTO %s (%s, %s, %s, %s, %s, %s, %s) VALUES (?, ?, ?, ?, ?, ?, NOW())\",\n+          ACCOUNT_REPORTS_TABLE, CLUSTERNAME_COLUMN, HOSTNAME_COLUMN, PARTITION_ID_COLUMN, ACCOUNT_ID_COLUMN,\n+          CONTAINER_ID_COLUMN, STORAGE_USAGE_COLUMN, UPDATED_AT_COLUMN);\n+  private static final String querySqlForClusterAndHost =\n+      String.format(\"SELECT %s, %s, %s, %s FROM %s WHERE %s = ? AND %s = ?\", PARTITION_ID_COLUMN, ACCOUNT_ID_COLUMN,\n+          CONTAINER_ID_COLUMN, STORAGE_USAGE_COLUMN, ACCOUNT_REPORTS_TABLE, CLUSTERNAME_COLUMN, HOSTNAME_COLUMN);\n+  private final MySqlDataAccessor dataAccessor;\n+  private final String clustername;\n+  private final String hostname;\n+\n+  /**\n+   * Constructor to create a {@link AccountReportsDao}.\n+   * @param dataAccessor The underlying {@link MySqlDataAccessor}.\n+   * @param clustername The name of the cluster this host is belonging to, like Ambry-prod, Ambry-video.\n+   * @param hostname The name of the host. It should include the hostname and the port.\n+   */\n+  public AccountReportsDao(MySqlDataAccessor dataAccessor, String clustername, String hostname) {\n+    this.dataAccessor = Objects.requireNonNull(dataAccessor, \"MySqlDataAccessor is empty\");\n+    this.clustername = Objects.requireNonNull(clustername, \"clustername is empty\");\n+    this.hostname = Objects.requireNonNull(hostname, \"hostname is empty\");\n+  }\n+\n+  /**\n+   * Update the storage usage for the given account/container.\n+   * @param partitionId The partition id of this account/container usage.\n+   * @param accountId The account id.\n+   * @param containerId The container id.\n+   * @param storageUsage The storage usage in bytes.\n+   */\n+  public void updateStorageUsage(short partitionId, short accountId, short containerId, long storageUsage)", "originalCommit": "81555acbb6587e63d3203966e7e1f4a50d23e807", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzkyNjc5NA==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527926794", "bodyText": "currently we don't have a way to do so, but I will update it in a separate PR to delete those partitions.", "author": "justinlin-linkedin", "createdAt": "2020-11-20T19:30:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzE1MTc5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIwMTI2MQ==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527201261", "bodyText": "minor: java doc for this method", "author": "jsjtzyy", "createdAt": "2020-11-19T21:11:40Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountReportsDao.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import java.sql.PreparedStatement;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.util.Objects;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static com.github.ambry.mysql.MySqlDataAccessor.OperationType.*;\n+\n+\n+/**\n+ * AccountReports Data Access Object.\n+ */\n+public class AccountReportsDao {\n+  public static final String ACCOUNT_REPORTS_TABLE = \"AccountReports\";\n+  public static final String CLUSTERNAME_COLUMN = \"clusterName\";\n+  public static final String HOSTNAME_COLUMN = \"hostname\";\n+  public static final String PARTITION_ID_COLUMN = \"partitionId\";\n+  public static final String ACCOUNT_ID_COLUMN = \"accountId\";\n+  public static final String CONTAINER_ID_COLUMN = \"containerId\";\n+  public static final String STORAGE_USAGE_COLUMN = \"storageUsage\";\n+  public static final String UPDATED_AT_COLUMN = \"updatedAt\";\n+\n+  private static final Logger logger = LoggerFactory.getLogger(AccountReportsDao.class);\n+  private static final String insertSql =\n+      String.format(\"INSERT INTO %s (%s, %s, %s, %s, %s, %s, %s) VALUES (?, ?, ?, ?, ?, ?, NOW())\",\n+          ACCOUNT_REPORTS_TABLE, CLUSTERNAME_COLUMN, HOSTNAME_COLUMN, PARTITION_ID_COLUMN, ACCOUNT_ID_COLUMN,\n+          CONTAINER_ID_COLUMN, STORAGE_USAGE_COLUMN, UPDATED_AT_COLUMN);\n+  private static final String querySqlForClusterAndHost =\n+      String.format(\"SELECT %s, %s, %s, %s FROM %s WHERE %s = ? AND %s = ?\", PARTITION_ID_COLUMN, ACCOUNT_ID_COLUMN,\n+          CONTAINER_ID_COLUMN, STORAGE_USAGE_COLUMN, ACCOUNT_REPORTS_TABLE, CLUSTERNAME_COLUMN, HOSTNAME_COLUMN);\n+  private final MySqlDataAccessor dataAccessor;\n+  private final String clustername;\n+  private final String hostname;\n+\n+  /**\n+   * Constructor to create a {@link AccountReportsDao}.\n+   * @param dataAccessor The underlying {@link MySqlDataAccessor}.\n+   * @param clustername The name of the cluster this host is belonging to, like Ambry-prod, Ambry-video.\n+   * @param hostname The name of the host. It should include the hostname and the port.\n+   */\n+  public AccountReportsDao(MySqlDataAccessor dataAccessor, String clustername, String hostname) {\n+    this.dataAccessor = Objects.requireNonNull(dataAccessor, \"MySqlDataAccessor is empty\");\n+    this.clustername = Objects.requireNonNull(clustername, \"clustername is empty\");\n+    this.hostname = Objects.requireNonNull(hostname, \"hostname is empty\");\n+  }\n+\n+  /**\n+   * Update the storage usage for the given account/container.\n+   * @param partitionId The partition id of this account/container usage.\n+   * @param accountId The account id.\n+   * @param containerId The container id.\n+   * @param storageUsage The storage usage in bytes.\n+   */\n+  public void updateStorageUsage(short partitionId, short accountId, short containerId, long storageUsage)\n+      throws SQLException {\n+    try {\n+      long startTimeMs = System.currentTimeMillis();\n+      PreparedStatement insertStatement = dataAccessor.getPreparedStatement(insertSql, true);\n+      insertStatement.setString(1, clustername);\n+      insertStatement.setString(2, hostname);\n+      // The data type of partition id, account id and container id are not SMALLINT, but INT in MySQL, for\n+      // future extension\n+      insertStatement.setInt(3, partitionId);\n+      insertStatement.setInt(4, accountId);\n+      insertStatement.setInt(5, containerId);\n+      insertStatement.setLong(6, storageUsage);\n+      insertStatement.executeUpdate();\n+      dataAccessor.onSuccess(Write, System.currentTimeMillis() - startTimeMs);\n+    } catch (SQLException e) {\n+      dataAccessor.onException(e, Write);\n+      logger.error(String.format(\"Failed to execute updated on %s, with parameter %d %d %d %d\", ACCOUNT_REPORTS_TABLE,\n+          partitionId, accountId, containerId, storageUsage), e);\n+      throw e;\n+    }\n+  }\n+\n+  public void queryForClusterAndHost(String clustername, String hostname, ContainerUsageFunction func)", "originalCommit": "81555acbb6587e63d3203966e7e1f4a50d23e807", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIxMTQ0Ng==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527211446", "bodyText": "Also, can we rename the method to queryStorageUsageForHost?  The host should only come from a specific cluster. I think cluster name is probably not a must-have column but I see it's already in schema and I guess it would be useful to preclude some edge cases where host is moved from one cluster to another.", "author": "jsjtzyy", "createdAt": "2020-11-19T21:30:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIwMTI2MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzkyNzQ4OQ==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527927489", "bodyText": "The reason to use cluster name is to do one query one given cluster name and get the stats for all hosts. It's not implemented yet, but it might be a good idea in the future.", "author": "justinlin-linkedin", "createdAt": "2020-11-20T19:32:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIwMTI2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyNTc5Mg==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527225792", "bodyText": "nit: format this file", "author": "jsjtzyy", "createdAt": "2020-11-19T21:50:56Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountStatsMySqlStore.java", "diffHunk": "@@ -0,0 +1,223 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.codahale.metrics.Histogram;\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import com.github.ambry.mysql.MySqlMetrics;\n+import com.github.ambry.mysql.MySqlUtils;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import java.io.File;\n+import java.sql.SQLException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import joptsimple.internal.Strings;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * This class publishes container storage usage to mysql. It saves previous copy of {@link StatsWrapper} and compare\n+ * the current {@link StatsWrapper} with the previous and only update the containers that have different storage usage.\n+ * It also assumes a local copy of {@link StatsWrapper} will be saved after publishing to mysql database, so it can recover\n+ * the previous {@link StatsWrapper} from crashing or restarting.\n+ */\n+public class AccountStatsMySqlStore {\n+\n+  private final MySqlDataAccessor mySqlDataAccessor;\n+  private final AccountReportsDao accountReportsDao;\n+  private final HostnameHelper hostnameHelper;\n+  private StatsWrapper previousStats;", "originalCommit": "81555acbb6587e63d3203966e7e1f4a50d23e807", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzkyNzU1Ng==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527927556", "bodyText": "updated.", "author": "justinlin-linkedin", "createdAt": "2020-11-20T19:32:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyNTc5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyNjMzMw==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527226333", "bodyText": "Add a warn log here?", "author": "jsjtzyy", "createdAt": "2020-11-19T21:51:56Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountStatsMySqlStore.java", "diffHunk": "@@ -0,0 +1,223 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.codahale.metrics.Histogram;\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import com.github.ambry.mysql.MySqlMetrics;\n+import com.github.ambry.mysql.MySqlUtils;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import java.io.File;\n+import java.sql.SQLException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import joptsimple.internal.Strings;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * This class publishes container storage usage to mysql. It saves previous copy of {@link StatsWrapper} and compare\n+ * the current {@link StatsWrapper} with the previous and only update the containers that have different storage usage.\n+ * It also assumes a local copy of {@link StatsWrapper} will be saved after publishing to mysql database, so it can recover\n+ * the previous {@link StatsWrapper} from crashing or restarting.\n+ */\n+public class AccountStatsMySqlStore {\n+\n+  private final MySqlDataAccessor mySqlDataAccessor;\n+  private final AccountReportsDao accountReportsDao;\n+  private final HostnameHelper hostnameHelper;\n+  private StatsWrapper previousStats;\n+  private final Metrics storeMetrics;\n+\n+  /**\n+   * Metrics for {@link AccountStatsMySqlStore}.\n+   */\n+  private static class Metrics {\n+    public final Histogram batchSize;\n+    public final Histogram publishTimeMs;\n+\n+    /**\n+     * Constructor to create the Metrics.\n+     * @param registry The {@link MetricRegistry}.\n+     */\n+    public Metrics(MetricRegistry registry) {\n+      batchSize = registry.histogram(MetricRegistry.name(AccountStatsMySqlStore.class, \"BatchSize\"));\n+      publishTimeMs = registry.histogram(MetricRegistry.name(AccountStatsMySqlStore.class, \"PublishTimeMs\"));\n+    }\n+  }\n+\n+  /**\n+   * Constructor to create {@link AccountStatsMySqlStore}.\n+   * @param dbEndpoints MySql DB end points.\n+   * @param localDatacenter The local datacenter name. Endpoints from local datacenter are preferred when creating connection to MySql DB.\n+   * @param clustername  The name of the cluster, like Ambry-prod.\n+   * @param hostname The name of the host.\n+   * @param localBackupFilePath The filepath to local backup file.\n+   * @param hostnameHelper The {@link HostnameHelper} to simplify the hostname.\n+   * @param registry The {@link MetricRegistry}.\n+   * @throws SQLException\n+   */\n+  public AccountStatsMySqlStore(List<MySqlUtils.DbEndpoint> dbEndpoints, String localDatacenter, String clustername,\n+      String hostname, String localBackupFilePath, HostnameHelper hostnameHelper, MetricRegistry registry)\n+      throws SQLException {\n+    this(new MySqlDataAccessor(dbEndpoints, localDatacenter, new MySqlMetrics(AccountStatsMySqlStore.class, registry)),\n+        clustername, hostname, localBackupFilePath, hostnameHelper, registry);\n+  }\n+\n+  /**\n+   * Constructor to create link {@link AccountStatsMySqlStore}. It's only used in tests.\n+   * @param dataAccessor The {@link MySqlDataAccessor}.\n+   * @param clustername  The name of the cluster, like Ambry-prod.\n+   * @param hostname The name of the host.\n+   * @param localBackupFilePath The filepath to local backup file.\n+   * @param hostnameHelper The {@link HostnameHelper} to simplify the hostname.\n+   * @param registry The {@link MetricRegistry}.\n+   */\n+  AccountStatsMySqlStore(MySqlDataAccessor dataAccessor, String clustername, String hostname,\n+      String localBackupFilePath, HostnameHelper hostnameHelper, MetricRegistry registry) {\n+    mySqlDataAccessor = dataAccessor;\n+    accountReportsDao = new AccountReportsDao(dataAccessor, clustername, hostname);\n+    this.hostnameHelper = hostnameHelper;\n+    storeMetrics = new AccountStatsMySqlStore.Metrics(registry);\n+    if (!Strings.isNullOrEmpty(localBackupFilePath)) {\n+      // load backup file and this backup is the previous stats\n+      ObjectMapper objectMapper = new ObjectMapper();\n+      try {\n+        this.previousStats = objectMapper.readValue(new File(localBackupFilePath), StatsWrapper.class);\n+      } catch (Exception e) {\n+        this.previousStats = null;\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Publish the {@link StatsWrapper} to mysql database. This method ignores the error information from {@link StatsWrapper}\n+   * and only publish the container storage usages that are different from the previous one.\n+   * @param statsWrapper The {@link StatsWrapper} to publish.\n+   */\n+  public void publish(StatsWrapper statsWrapper) {\n+    StatsSnapshot prevSnapshot =\n+        previousStats == null ? new StatsSnapshot((long) -1, new HashMap<>()) : previousStats.getSnapshot();\n+    applyFunctionToContainerUsageInDifferentStatsSnapshots(statsWrapper.getSnapshot(), prevSnapshot,\n+        this::tryUpdateStorageUsage);\n+    previousStats = statsWrapper;\n+  }\n+\n+  /**\n+   * Query mysql database to get all the container storage usage for given {@code clustername} and {@code hostname} and\n+   * construct a {@link StatsSnapshot} from them.\n+   * @param clustername the clustername.\n+   * @param hostname the hostname\n+   * @return {@link StatsSnapshot} published by the given host.\n+   * @throws SQLException\n+   */\n+  public StatsSnapshot queryStatsSnapshotOf(String clustername, String hostname) throws SQLException {\n+    hostname = hostnameHelper.simplifyHostname(hostname);\n+    Map<String, StatsSnapshot> partitionSubMap = new HashMap<>();\n+    StatsSnapshot hostSnapshot = new StatsSnapshot((long) 0, partitionSubMap);\n+    accountReportsDao.queryForClusterAndHost(clustername, hostname,\n+        (partitionId, accountId, containerId, storageUsage) -> {\n+          StatsSnapshot partitionSnapshot = hostSnapshot.getSubMap()\n+              .computeIfAbsent(\"Partition[\" + partitionId + \"]\", k -> new StatsSnapshot((long) 0, new HashMap<>()));\n+          StatsSnapshot accountSnapshot = partitionSnapshot.getSubMap()\n+              .computeIfAbsent(\"A[\" + accountId + \"]\", k -> new StatsSnapshot((long) 0, new HashMap<>()));\n+          accountSnapshot.getSubMap().put(\"C[\" + containerId + \"]\", new StatsSnapshot(storageUsage, null));\n+        });\n+\n+    hostSnapshot.updateValue();\n+    return hostSnapshot;\n+  }\n+\n+  /**\n+   * Return {@link #previousStats}. Only used in test.\n+   * @return\n+   */\n+  StatsWrapper getPreviousStats() {\n+    return previousStats;\n+  }\n+\n+  /**\n+   * Return {@link #mySqlDataAccessor}. Only used in test.\n+   * @return\n+   */\n+  public MySqlDataAccessor getMySqlDataAccessor() {\n+    return mySqlDataAccessor;\n+  }\n+\n+  /**\n+   * Find the differences between two {@link StatsSnapshot} and apply them to the given {@link ContainerUsageFunction}.\n+   * The difference is defined as\n+   * 1. If a container storage usage exists in both StatsSnapshot, and the values are different.\n+   * 2. If a container storage usage only exists in first StatsSnapshot.\n+   * If a container storage usage only exists in the second StatsSnapshot, then it will not be applied to the given function.\n+   * @param currentStats The current StatsSnapshot.\n+   * @param previousStats The previous StatsSnapshot.\n+   * @param func The function to apply the differences to.\n+   */\n+  private void applyFunctionToContainerUsageInDifferentStatsSnapshots(StatsSnapshot currentStats,\n+      StatsSnapshot previousStats, ContainerUsageFunction func) {\n+    int batchSize = 0;\n+    long startTimeMs = System.currentTimeMillis();\n+    Map<String, StatsSnapshot> currPartitionMap = currentStats.getSubMap();\n+    Map<String, StatsSnapshot> prevPartitionMap = previousStats.getSubMap();\n+    for (Map.Entry<String, StatsSnapshot> currPartitionMapEntry : currPartitionMap.entrySet()) {\n+      String partitionIdKey = currPartitionMapEntry.getKey();\n+      StatsSnapshot currAccountStatsSnapshot = currPartitionMapEntry.getValue();\n+      StatsSnapshot prevAccountStatsSnapshot =\n+          prevPartitionMap.getOrDefault(partitionIdKey, new StatsSnapshot((long) 0, new HashMap<>()));\n+      short partitionId = Short.valueOf(partitionIdKey.substring(\"Partition[\".length(), partitionIdKey.length() - 1));\n+      Map<String, StatsSnapshot> currAccountMap = currAccountStatsSnapshot.getSubMap();\n+      Map<String, StatsSnapshot> prevAccountMap = prevAccountStatsSnapshot.getSubMap();\n+      for (Map.Entry<String, StatsSnapshot> currAccountMapEntry : currAccountMap.entrySet()) {\n+        String accountIdKey = currAccountMapEntry.getKey();\n+        StatsSnapshot currContainerStatsSnapshot = currAccountMapEntry.getValue();\n+        StatsSnapshot prevContainerStatsSnapshot =\n+            prevAccountMap.getOrDefault(accountIdKey, new StatsSnapshot((long) 0, new HashMap<>()));\n+        short accountId = Short.valueOf(accountIdKey.substring(2, accountIdKey.length() - 1));\n+        Map<String, StatsSnapshot> currContainerMap = currContainerStatsSnapshot.getSubMap();\n+        Map<String, StatsSnapshot> prevContainerMap = prevContainerStatsSnapshot.getSubMap();\n+        for (Map.Entry<String, StatsSnapshot> currContainerMapEntry : currContainerMap.entrySet()) {\n+          String containerIdKey = currContainerMapEntry.getKey();\n+          short containerId = Short.valueOf(containerIdKey.substring(2, containerIdKey.length() - 1));\n+          long currStorageUsage = currContainerMapEntry.getValue().getValue();\n+          long prevStorageUsage =\n+              prevContainerMap.getOrDefault(containerIdKey, new StatsSnapshot((long) -1, null)).getValue();\n+          if (currStorageUsage != prevStorageUsage) {\n+            func.apply(partitionId, accountId, containerId, currStorageUsage);\n+            batchSize++;\n+          }\n+        }\n+      }\n+    }\n+    storeMetrics.publishTimeMs.update(System.currentTimeMillis() - startTimeMs);\n+    storeMetrics.batchSize.update(batchSize);\n+  }\n+\n+  /**\n+   * Update storage usage with {@link AccountReportsDao} but ignore the exception.\n+   * @param partitionId The partition id of this account/container usage.\n+   * @param accountId The account id.\n+   * @param containerId The container id.\n+   * @param storageUsage The storage usage in bytes.\n+   */\n+  private void tryUpdateStorageUsage(short partitionId, short accountId, short containerId, long storageUsage) {\n+    try {\n+      accountReportsDao.updateStorageUsage(partitionId, accountId, containerId, storageUsage);\n+    } catch (Exception e) {\n+    }", "originalCommit": "81555acbb6587e63d3203966e7e1f4a50d23e807", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzkyNzc2Mg==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527927762", "bodyText": "there is already an error log in AccountReportsDao.java file.", "author": "justinlin-linkedin", "createdAt": "2020-11-20T19:32:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIyNjMzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIzNTk5Ng==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527235996", "bodyText": "minor:  clustername -> clusterName, also remove \"Ambry-prod\"  (or use \"Ambry-Test\" instead)", "author": "jsjtzyy", "createdAt": "2020-11-19T22:10:29Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountStatsMySqlStore.java", "diffHunk": "@@ -0,0 +1,223 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.codahale.metrics.Histogram;\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import com.github.ambry.mysql.MySqlMetrics;\n+import com.github.ambry.mysql.MySqlUtils;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import java.io.File;\n+import java.sql.SQLException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import joptsimple.internal.Strings;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * This class publishes container storage usage to mysql. It saves previous copy of {@link StatsWrapper} and compare\n+ * the current {@link StatsWrapper} with the previous and only update the containers that have different storage usage.\n+ * It also assumes a local copy of {@link StatsWrapper} will be saved after publishing to mysql database, so it can recover\n+ * the previous {@link StatsWrapper} from crashing or restarting.\n+ */\n+public class AccountStatsMySqlStore {\n+\n+  private final MySqlDataAccessor mySqlDataAccessor;\n+  private final AccountReportsDao accountReportsDao;\n+  private final HostnameHelper hostnameHelper;\n+  private StatsWrapper previousStats;\n+  private final Metrics storeMetrics;\n+\n+  /**\n+   * Metrics for {@link AccountStatsMySqlStore}.\n+   */\n+  private static class Metrics {\n+    public final Histogram batchSize;\n+    public final Histogram publishTimeMs;\n+\n+    /**\n+     * Constructor to create the Metrics.\n+     * @param registry The {@link MetricRegistry}.\n+     */\n+    public Metrics(MetricRegistry registry) {\n+      batchSize = registry.histogram(MetricRegistry.name(AccountStatsMySqlStore.class, \"BatchSize\"));\n+      publishTimeMs = registry.histogram(MetricRegistry.name(AccountStatsMySqlStore.class, \"PublishTimeMs\"));\n+    }\n+  }\n+\n+  /**\n+   * Constructor to create {@link AccountStatsMySqlStore}.\n+   * @param dbEndpoints MySql DB end points.\n+   * @param localDatacenter The local datacenter name. Endpoints from local datacenter are preferred when creating connection to MySql DB.\n+   * @param clustername  The name of the cluster, like Ambry-prod.", "originalCommit": "81555acbb6587e63d3203966e7e1f4a50d23e807", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzkyNzg1MA==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527927850", "bodyText": "updated.", "author": "justinlin-linkedin", "createdAt": "2020-11-20T19:33:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzIzNTk5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI0Mjg0OQ==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527242849", "bodyText": "same here", "author": "jsjtzyy", "createdAt": "2020-11-19T22:20:54Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountStatsMySqlStore.java", "diffHunk": "@@ -0,0 +1,223 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.codahale.metrics.Histogram;\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import com.github.ambry.mysql.MySqlMetrics;\n+import com.github.ambry.mysql.MySqlUtils;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import java.io.File;\n+import java.sql.SQLException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import joptsimple.internal.Strings;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * This class publishes container storage usage to mysql. It saves previous copy of {@link StatsWrapper} and compare\n+ * the current {@link StatsWrapper} with the previous and only update the containers that have different storage usage.\n+ * It also assumes a local copy of {@link StatsWrapper} will be saved after publishing to mysql database, so it can recover\n+ * the previous {@link StatsWrapper} from crashing or restarting.\n+ */\n+public class AccountStatsMySqlStore {\n+\n+  private final MySqlDataAccessor mySqlDataAccessor;\n+  private final AccountReportsDao accountReportsDao;\n+  private final HostnameHelper hostnameHelper;\n+  private StatsWrapper previousStats;\n+  private final Metrics storeMetrics;\n+\n+  /**\n+   * Metrics for {@link AccountStatsMySqlStore}.\n+   */\n+  private static class Metrics {\n+    public final Histogram batchSize;\n+    public final Histogram publishTimeMs;\n+\n+    /**\n+     * Constructor to create the Metrics.\n+     * @param registry The {@link MetricRegistry}.\n+     */\n+    public Metrics(MetricRegistry registry) {\n+      batchSize = registry.histogram(MetricRegistry.name(AccountStatsMySqlStore.class, \"BatchSize\"));\n+      publishTimeMs = registry.histogram(MetricRegistry.name(AccountStatsMySqlStore.class, \"PublishTimeMs\"));\n+    }\n+  }\n+\n+  /**\n+   * Constructor to create {@link AccountStatsMySqlStore}.\n+   * @param dbEndpoints MySql DB end points.\n+   * @param localDatacenter The local datacenter name. Endpoints from local datacenter are preferred when creating connection to MySql DB.\n+   * @param clustername  The name of the cluster, like Ambry-prod.\n+   * @param hostname The name of the host.\n+   * @param localBackupFilePath The filepath to local backup file.\n+   * @param hostnameHelper The {@link HostnameHelper} to simplify the hostname.\n+   * @param registry The {@link MetricRegistry}.\n+   * @throws SQLException\n+   */\n+  public AccountStatsMySqlStore(List<MySqlUtils.DbEndpoint> dbEndpoints, String localDatacenter, String clustername,\n+      String hostname, String localBackupFilePath, HostnameHelper hostnameHelper, MetricRegistry registry)\n+      throws SQLException {\n+    this(new MySqlDataAccessor(dbEndpoints, localDatacenter, new MySqlMetrics(AccountStatsMySqlStore.class, registry)),\n+        clustername, hostname, localBackupFilePath, hostnameHelper, registry);\n+  }\n+\n+  /**\n+   * Constructor to create link {@link AccountStatsMySqlStore}. It's only used in tests.\n+   * @param dataAccessor The {@link MySqlDataAccessor}.\n+   * @param clustername  The name of the cluster, like Ambry-prod.", "originalCommit": "81555acbb6587e63d3203966e7e1f4a50d23e807", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzM1MzA3NA==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527353074", "bodyText": "Looks like this method is called in tests only?", "author": "jsjtzyy", "createdAt": "2020-11-20T02:25:02Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountStatsMySqlStore.java", "diffHunk": "@@ -0,0 +1,223 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.codahale.metrics.Histogram;\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import com.github.ambry.mysql.MySqlMetrics;\n+import com.github.ambry.mysql.MySqlUtils;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import java.io.File;\n+import java.sql.SQLException;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import joptsimple.internal.Strings;\n+import org.codehaus.jackson.map.ObjectMapper;\n+\n+\n+/**\n+ * This class publishes container storage usage to mysql. It saves previous copy of {@link StatsWrapper} and compare\n+ * the current {@link StatsWrapper} with the previous and only update the containers that have different storage usage.\n+ * It also assumes a local copy of {@link StatsWrapper} will be saved after publishing to mysql database, so it can recover\n+ * the previous {@link StatsWrapper} from crashing or restarting.\n+ */\n+public class AccountStatsMySqlStore {\n+\n+  private final MySqlDataAccessor mySqlDataAccessor;\n+  private final AccountReportsDao accountReportsDao;\n+  private final HostnameHelper hostnameHelper;\n+  private StatsWrapper previousStats;\n+  private final Metrics storeMetrics;\n+\n+  /**\n+   * Metrics for {@link AccountStatsMySqlStore}.\n+   */\n+  private static class Metrics {\n+    public final Histogram batchSize;\n+    public final Histogram publishTimeMs;\n+\n+    /**\n+     * Constructor to create the Metrics.\n+     * @param registry The {@link MetricRegistry}.\n+     */\n+    public Metrics(MetricRegistry registry) {\n+      batchSize = registry.histogram(MetricRegistry.name(AccountStatsMySqlStore.class, \"BatchSize\"));\n+      publishTimeMs = registry.histogram(MetricRegistry.name(AccountStatsMySqlStore.class, \"PublishTimeMs\"));\n+    }\n+  }\n+\n+  /**\n+   * Constructor to create {@link AccountStatsMySqlStore}.\n+   * @param dbEndpoints MySql DB end points.\n+   * @param localDatacenter The local datacenter name. Endpoints from local datacenter are preferred when creating connection to MySql DB.\n+   * @param clustername  The name of the cluster, like Ambry-prod.\n+   * @param hostname The name of the host.\n+   * @param localBackupFilePath The filepath to local backup file.\n+   * @param hostnameHelper The {@link HostnameHelper} to simplify the hostname.\n+   * @param registry The {@link MetricRegistry}.\n+   * @throws SQLException\n+   */\n+  public AccountStatsMySqlStore(List<MySqlUtils.DbEndpoint> dbEndpoints, String localDatacenter, String clustername,\n+      String hostname, String localBackupFilePath, HostnameHelper hostnameHelper, MetricRegistry registry)\n+      throws SQLException {\n+    this(new MySqlDataAccessor(dbEndpoints, localDatacenter, new MySqlMetrics(AccountStatsMySqlStore.class, registry)),\n+        clustername, hostname, localBackupFilePath, hostnameHelper, registry);\n+  }\n+\n+  /**\n+   * Constructor to create link {@link AccountStatsMySqlStore}. It's only used in tests.\n+   * @param dataAccessor The {@link MySqlDataAccessor}.\n+   * @param clustername  The name of the cluster, like Ambry-prod.\n+   * @param hostname The name of the host.\n+   * @param localBackupFilePath The filepath to local backup file.\n+   * @param hostnameHelper The {@link HostnameHelper} to simplify the hostname.\n+   * @param registry The {@link MetricRegistry}.\n+   */\n+  AccountStatsMySqlStore(MySqlDataAccessor dataAccessor, String clustername, String hostname,\n+      String localBackupFilePath, HostnameHelper hostnameHelper, MetricRegistry registry) {\n+    mySqlDataAccessor = dataAccessor;\n+    accountReportsDao = new AccountReportsDao(dataAccessor, clustername, hostname);\n+    this.hostnameHelper = hostnameHelper;\n+    storeMetrics = new AccountStatsMySqlStore.Metrics(registry);\n+    if (!Strings.isNullOrEmpty(localBackupFilePath)) {\n+      // load backup file and this backup is the previous stats\n+      ObjectMapper objectMapper = new ObjectMapper();\n+      try {\n+        this.previousStats = objectMapper.readValue(new File(localBackupFilePath), StatsWrapper.class);\n+      } catch (Exception e) {\n+        this.previousStats = null;\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Publish the {@link StatsWrapper} to mysql database. This method ignores the error information from {@link StatsWrapper}\n+   * and only publish the container storage usages that are different from the previous one.\n+   * @param statsWrapper The {@link StatsWrapper} to publish.\n+   */\n+  public void publish(StatsWrapper statsWrapper) {\n+    StatsSnapshot prevSnapshot =\n+        previousStats == null ? new StatsSnapshot((long) -1, new HashMap<>()) : previousStats.getSnapshot();\n+    applyFunctionToContainerUsageInDifferentStatsSnapshots(statsWrapper.getSnapshot(), prevSnapshot,\n+        this::tryUpdateStorageUsage);\n+    previousStats = statsWrapper;\n+  }\n+\n+  /**\n+   * Query mysql database to get all the container storage usage for given {@code clustername} and {@code hostname} and\n+   * construct a {@link StatsSnapshot} from them.\n+   * @param clustername the clustername.\n+   * @param hostname the hostname\n+   * @return {@link StatsSnapshot} published by the given host.\n+   * @throws SQLException\n+   */\n+  public StatsSnapshot queryStatsSnapshotOf(String clustername, String hostname) throws SQLException {", "originalCommit": "81555acbb6587e63d3203966e7e1f4a50d23e807", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzkyODEzOA==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527928138", "bodyText": "it's now, but in my next PR, to implement mysql database aggregation task, it will be used to query the stats from a given host.", "author": "justinlin-linkedin", "createdAt": "2020-11-20T19:33:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzM1MzA3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzM1NjgyNw==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527356827", "bodyText": "This import can be removed. Maybe format this file?", "author": "jsjtzyy", "createdAt": "2020-11-20T02:38:25Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/AccountStatsMySqlStoreFactory.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.config.AccountStatsMySqlConfig;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.config.StatsManagerConfig;\n+import com.github.ambry.config.VerifiableProperties;\n+import java.sql.SQLException;\n+import java.util.ArrayList;", "originalCommit": "81555acbb6587e63d3203966e7e1f4a50d23e807", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzM1Njk2Ng==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527356966", "bodyText": "nit: partitionId", "author": "jsjtzyy", "createdAt": "2020-11-20T02:38:53Z", "path": "ambry-server/src/main/java/com/github/ambry/server/mysql/ContainerUsageFunction.java", "diffHunk": "@@ -0,0 +1,19 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+@FunctionalInterface\n+public interface ContainerUsageFunction {\n+  void apply(short partitionID, short accountId, short containerId, long storageUsage);", "originalCommit": "81555acbb6587e63d3203966e7e1f4a50d23e807", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzM2MDI2Nw==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r527360267", "bodyText": "This containerId is redundant.", "author": "jsjtzyy", "createdAt": "2020-11-20T02:50:42Z", "path": "ambry-server/src/test/java/com/github/ambry/server/mysql/AccountStatsMySqlStoreTest.java", "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server.mysql;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import com.github.ambry.mysql.MySqlMetrics;\n+import com.github.ambry.mysql.MySqlUtils;\n+import com.github.ambry.server.StatsHeader;\n+import com.github.ambry.server.StatsSnapshot;\n+import com.github.ambry.server.StatsWrapper;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.sql.Connection;\n+import java.sql.Driver;\n+import java.sql.PreparedStatement;\n+import java.sql.SQLException;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.Random;\n+import org.codehaus.jackson.map.ObjectMapper;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+import static org.mockito.Mockito.*;\n+\n+\n+/**\n+ * Unit test for {@link AccountStatsMySqlStore}.\n+ */\n+public class AccountStatsMySqlStoreTest {\n+  private final Connection mockConnection;\n+  private final MySqlDataAccessor dataAccessor;\n+  private final MySqlMetrics metrics;\n+  private static final String clustername = \"Ambry-test\";\n+  private static final String hostname = \"test1.ambry_1300\";\n+  private static final long MAX_CONTAINER_USAGE = 100000;\n+  private static final long MIN_CONTAINER_USAGE = 1000;\n+  private static final long DEFAULT_CONTAINER_USAGE = 5000;\n+  private static final int BASE_PARTITION_ID = 100;\n+  private static final int BASE_ACCOUNT_ID = 1000;\n+  private static final int BASE_CONTAINER_ID = 1;\n+\n+  public AccountStatsMySqlStoreTest() throws SQLException {\n+    mockConnection = mock(Connection.class);\n+    PreparedStatement mockInsertStatement = mock(PreparedStatement.class);\n+    when(mockConnection.prepareStatement(contains(\"INSERT\"))).thenReturn(mockInsertStatement);\n+    when(mockInsertStatement.executeUpdate()).thenReturn(1);\n+\n+    metrics = new MySqlMetrics(AccountStatsMySqlStore.class, new MetricRegistry());\n+    dataAccessor = getDataAccessor(mockConnection, metrics);\n+  }\n+\n+  /**\n+   * Utility to get a {@link MySqlDataAccessor}.\n+   * @param mockConnection the connection to use.\n+   * @return the {@link MySqlDataAccessor}.\n+   * @throws SQLException\n+   */\n+  static MySqlDataAccessor getDataAccessor(Connection mockConnection, MySqlMetrics metrics) throws SQLException {\n+    Driver mockDriver = mock(Driver.class);\n+    when(mockDriver.connect(anyString(), any(Properties.class))).thenReturn(mockConnection);\n+    MySqlUtils.DbEndpoint dbEndpoint =\n+        new MySqlUtils.DbEndpoint(\"jdbc:mysql://localhost/ambry_container_storage_stats\", \"dc1\", true, \"ambry\",\n+            \"ambry\");\n+    return new MySqlDataAccessor(Collections.singletonList(dbEndpoint), mockDriver, metrics);\n+  }\n+\n+  @Test\n+  public void testLocalBackupFile() throws IOException {\n+    // First, make sure there is no local backup file.\n+    Path tempDir = Files.createTempDirectory(\"AccountStatsMySqlStoreTest\");\n+    Path localBackupFilePath = tempDir.resolve(\"localbackup\");\n+    AccountStatsMySqlStore store =\n+        new AccountStatsMySqlStore(dataAccessor, clustername, hostname, localBackupFilePath.toString(), null,\n+            new MetricRegistry());\n+    assertNull(store.getPreviousStats());\n+    // Second, save a backup file.\n+    StatsSnapshot snapshot = createStatsSnapshot(10, 10, 10, false);\n+    StatsHeader header =\n+        new StatsHeader(StatsHeader.StatsDescription.STORED_DATA_SIZE, System.currentTimeMillis(), 10, 10, null);\n+    StatsWrapper statsWrapper = new StatsWrapper(header, snapshot);\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    objectMapper.writeValue(localBackupFilePath.toFile(), statsWrapper);\n+    store = new AccountStatsMySqlStore(dataAccessor, clustername, hostname, localBackupFilePath.toString(), null,\n+        new MetricRegistry());\n+\n+    StatsWrapper backupWrapper = store.getPreviousStats();\n+    assertNotNull(backupWrapper);\n+    assertStatsHeader(backupWrapper.getHeader(), 10, 10);\n+    assertStatsSnapshot(backupWrapper.getSnapshot(), 10, 10, 10);\n+  }\n+\n+  @Test\n+  public void testLocalBackupAndPublish() throws Exception {\n+    Path tempDir = Files.createTempDirectory(\"AccountStatsMySqlStoreTest\");\n+    Path localBackupFilePath = tempDir.resolve(\"localbackup\");\n+    AccountStatsMySqlStore store =\n+        new AccountStatsMySqlStore(dataAccessor, clustername, hostname, localBackupFilePath.toString(), null,\n+            new MetricRegistry());\n+    StatsSnapshot snapshot = createStatsSnapshot(10, 10, 1, false);\n+    StatsHeader header =\n+        new StatsHeader(StatsHeader.StatsDescription.STORED_DATA_SIZE, System.currentTimeMillis(), 10, 10, null);\n+    StatsWrapper statsWrapper = new StatsWrapper(header, snapshot);\n+    store.publish(statsWrapper);\n+    assertEquals(\"Write success count should be \" + (10 * 10), 10 * 10, metrics.writeSuccessCount.getCount());\n+\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    objectMapper.writeValue(localBackupFilePath.toFile(), statsWrapper);\n+\n+    store = new AccountStatsMySqlStore(dataAccessor, clustername, hostname, localBackupFilePath.toString(), null,\n+        new MetricRegistry());\n+\n+    // We have a local backup to start with.\n+    // Write the statsWrapper from local backup\n+    store.publish(statsWrapper);\n+    assertEquals(\"Write success count should be \" + (10 * 10), (10 * 10), metrics.writeSuccessCount.getCount());\n+  }\n+\n+  @Test\n+  public void testMultiPublish() throws Exception {\n+    Path tempDir = Files.createTempDirectory(\"AccountStatsMySqlStoreTest\");\n+    Path localBackupFilePath = tempDir.resolve(\"localbackup\");\n+\n+    StatsSnapshot snapshot = createStatsSnapshot(10, 10, 1, true);\n+    StatsHeader header =\n+        new StatsHeader(StatsHeader.StatsDescription.STORED_DATA_SIZE, System.currentTimeMillis(), 10, 10, null);\n+    StatsWrapper statsWrapper = new StatsWrapper(header, snapshot);\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    objectMapper.writeValue(localBackupFilePath.toFile(), statsWrapper);\n+\n+    // create a store with a local backup file and try to publish it again.\n+    AccountStatsMySqlStore store =\n+        new AccountStatsMySqlStore(dataAccessor, clustername, hostname, localBackupFilePath.toString(), null,\n+            new MetricRegistry());\n+    store.publish(statsWrapper);\n+    assertEquals(\"Write success count should be 0\", 0, metrics.writeSuccessCount.getCount());\n+\n+    // Since all container storage usages are default values, second Snapshot should be the same as the first snapshot\n+    StatsSnapshot secondSnapshot = createStatsSnapshot(10, 10, 1, true);\n+    StatsWrapper secondStatsWrapper = new StatsWrapper(header, secondSnapshot);\n+    store.publish(secondStatsWrapper);\n+    assertEquals(\"Write success count should be 0\", 0, metrics.writeSuccessCount.getCount());\n+    // Now the previous stats wrapper should be the second statsWrapper\n+    assertTrue(secondStatsWrapper == store.getPreviousStats());\n+\n+    // Change one of the value in statsWrapper\n+    int partitionId = BASE_PARTITION_ID + 1;\n+    int accountId = BASE_ACCOUNT_ID + 1;\n+    int containerId = BASE_CONTAINER_ID;", "originalCommit": "81555acbb6587e63d3203966e7e1f4a50d23e807", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8f1659c2b9f53cf071eaf98bd9cd6e02ad27754f", "url": "https://github.com/linkedin/ambry/commit/8f1659c2b9f53cf071eaf98bd9cd6e02ad27754f", "message": "WIP", "committedDate": "2020-11-20T18:09:25Z", "type": "commit"}, {"oid": "5a47d3d290181e0a5d69e77cc4d990c992ad4bfa", "url": "https://github.com/linkedin/ambry/commit/5a47d3d290181e0a5d69e77cc4d990c992ad4bfa", "message": "[StorageQuota] Implement mysql container storage usage report", "committedDate": "2020-11-20T18:09:25Z", "type": "commit"}, {"oid": "bae2b3da3fbfdaa1a99d09978e67371867b43dae", "url": "https://github.com/linkedin/ambry/commit/bae2b3da3fbfdaa1a99d09978e67371867b43dae", "message": "Fix test", "committedDate": "2020-11-20T18:09:25Z", "type": "commit"}, {"oid": "eec39ee59e2a7acfe3ca738d7223e3a55090dc67", "url": "https://github.com/linkedin/ambry/commit/eec39ee59e2a7acfe3ca738d7223e3a55090dc67", "message": "Add integration test", "committedDate": "2020-11-20T18:09:25Z", "type": "commit"}, {"oid": "feb32702701a255106d40249cadbb3ffa4464e82", "url": "https://github.com/linkedin/ambry/commit/feb32702701a255106d40249cadbb3ffa4464e82", "message": "Comments", "committedDate": "2020-11-20T18:09:25Z", "type": "commit"}, {"oid": "4ac4bce2618eb110442e5194db8986dd37cff2ca", "url": "https://github.com/linkedin/ambry/commit/4ac4bce2618eb110442e5194db8986dd37cff2ca", "message": "comments", "committedDate": "2020-11-20T18:09:25Z", "type": "commit"}, {"oid": "217028223593e182a35504a6e2fc53fe71d903f3", "url": "https://github.com/linkedin/ambry/commit/217028223593e182a35504a6e2fc53fe71d903f3", "message": "Fix test", "committedDate": "2020-11-20T18:09:25Z", "type": "commit"}, {"oid": "d6fae68e0fcf0876ae9e53067f2153e077684e41", "url": "https://github.com/linkedin/ambry/commit/d6fae68e0fcf0876ae9e53067f2153e077684e41", "message": "Comments", "committedDate": "2020-11-20T19:20:33Z", "type": "commit"}, {"oid": "d6fae68e0fcf0876ae9e53067f2153e077684e41", "url": "https://github.com/linkedin/ambry/commit/d6fae68e0fcf0876ae9e53067f2153e077684e41", "message": "Comments", "committedDate": "2020-11-20T19:20:33Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAxNjA4Mw==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r528016083", "bodyText": "This may cause NPE.", "author": "jsjtzyy", "createdAt": "2020-11-20T23:03:47Z", "path": "ambry-server/src/integration-test/java/com/github/ambry/server/AccountStatsMySqlStoreIntegrationTest.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.server;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.config.AccountStatsMySqlConfig;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.config.StatsManagerConfig;\n+import com.github.ambry.config.VerifiableProperties;\n+import com.github.ambry.mysql.MySqlDataAccessor;\n+import com.github.ambry.server.mysql.AccountReportsDao;\n+import com.github.ambry.server.mysql.AccountStatsMySqlStore;\n+import com.github.ambry.server.mysql.AccountStatsMySqlStoreFactory;\n+import com.github.ambry.utils.TestUtils;\n+import com.github.ambry.utils.Utils;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.sql.Connection;\n+import java.sql.ResultSet;\n+import java.sql.SQLException;\n+import java.sql.Statement;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.Random;\n+import org.codehaus.jackson.map.ObjectMapper;\n+import org.junit.Test;\n+\n+import static org.junit.Assert.*;\n+\n+\n+/**\n+ * Integration tests for {@link AccountStatsMySqlStore}.\n+ */\n+public class AccountStatsMySqlStoreIntegrationTest {\n+  private static final String clusterName1 = \"Ambry-test\";\n+  private static final String clusterName2 = \"Ambry-random\";\n+  private static final String hostname1 = \"ambry1.test.github.com\";\n+  private static final String hostname2 = \"ambry2.test.github.com\";\n+  private static final String hostname3 = \"ambry3.test.github.com\";\n+  private static final int port = 12345;\n+\n+  public AccountStatsMySqlStoreIntegrationTest() throws Exception {\n+    AccountStatsMySqlStore mySqlStore = createAccountStatsMySqlStore(clusterName1, hostname1, false);\n+    cleanup(mySqlStore.getMySqlDataAccessor());\n+  }\n+\n+  /**\n+   * Tests to publish multiple stats and recover stats from database.\n+   * @throws Exception\n+   */\n+  @Test\n+  public void testMultiStorePublish() throws Exception {\n+    AccountStatsMySqlStore mySqlStore1 = createAccountStatsMySqlStore(clusterName1, hostname1, false);\n+    AccountStatsMySqlStore mySqlStore2 = createAccountStatsMySqlStore(clusterName1, hostname2, false);\n+    AccountStatsMySqlStore mySqlStore3 = createAccountStatsMySqlStore(clusterName2, hostname3, false);\n+\n+    StatsWrapper stats1 = generateStatsWrapper(10, 10, 1);\n+    StatsWrapper stats2 = generateStatsWrapper(10, 10, 1);\n+    StatsWrapper stats3 = generateStatsWrapper(10, 10, 1);\n+    mySqlStore1.publish(stats1);\n+    mySqlStore2.publish(stats2);\n+    mySqlStore3.publish(stats3);\n+\n+    assertTableSize(mySqlStore1.getMySqlDataAccessor(), 3 * 10 * 10);\n+\n+    StatsSnapshot obtainedStats1 = mySqlStore1.queryStatsSnapshotOf(clusterName1, hostname1);\n+    StatsSnapshot obtainedStats2 = mySqlStore2.queryStatsSnapshotOf(clusterName1, hostname2);\n+    StatsSnapshot obtainedStats3 = mySqlStore3.queryStatsSnapshotOf(clusterName2, hostname3);\n+    assertTwoStatsSnapshots(obtainedStats1, stats1.getSnapshot());\n+    assertTwoStatsSnapshots(obtainedStats2, stats2.getSnapshot());\n+    assertTwoStatsSnapshots(obtainedStats3, stats3.getSnapshot());\n+  }\n+\n+  private AccountStatsMySqlStore createAccountStatsMySqlStore(String clustername, String hostname,\n+      boolean withLocalbackup) throws Exception {\n+    Path localBackupFilePath = withLocalbackup ? createLocalBackup(10, 10, 1) : createTemporaryFile();\n+    Properties configProps = Utils.loadPropsFromResource(\"mysql.properties\");\n+    configProps.setProperty(ClusterMapConfig.CLUSTERMAP_CLUSTER_NAME, clustername);\n+    configProps.setProperty(ClusterMapConfig.CLUSTERMAP_HOST_NAME, hostname);\n+    configProps.setProperty(ClusterMapConfig.CLUSTERMAP_DATACENTER_NAME, \"dc1\");\n+    configProps.setProperty(ClusterMapConfig.CLUSTERMAP_PORT, String.valueOf(port));\n+    configProps.setProperty(AccountStatsMySqlConfig.DOMAIN_NAMES_TO_REMOVE, \".github.com\");\n+    configProps.setProperty(StatsManagerConfig.STATS_OUTPUT_FILE_PATH, localBackupFilePath.toString());\n+    VerifiableProperties verifiableProperties = new VerifiableProperties(configProps);\n+    return new AccountStatsMySqlStoreFactory(verifiableProperties, new ClusterMapConfig(verifiableProperties),\n+        new StatsManagerConfig(verifiableProperties), new MetricRegistry()).getAccountStatsMySqlStore();\n+  }\n+\n+  private static Path createLocalBackup(int numPartitions, int numAccounts, int numContainers) throws IOException {\n+    Path localBackupFilePath = createTemporaryFile();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    objectMapper.writeValue(localBackupFilePath.toFile(),\n+        generateStatsWrapper(numPartitions, numAccounts, numContainers));\n+    return localBackupFilePath;\n+  }\n+\n+  private static Path createTemporaryFile() throws IOException {\n+    Path tempDir = Files.createTempDirectory(\"AccountStatsMySqlStoreTest\");\n+    return tempDir.resolve(\"localbackup\");\n+  }\n+\n+  private static StatsWrapper generateStatsWrapper(int numPartitions, int numAccounts, int numContainers) {\n+    Random random = new Random();\n+    List<StatsSnapshot> storeSnapshots = new ArrayList<>();\n+    for (int i = 0; i < numPartitions; i++) {\n+      storeSnapshots.add(\n+          TestUtils.generateStoreStats(numAccounts, numContainers, random, StatsReportType.ACCOUNT_REPORT));\n+    }\n+    return TestUtils.generateNodeStats(storeSnapshots, 1000, StatsReportType.ACCOUNT_REPORT);\n+  }\n+\n+  private void cleanup(MySqlDataAccessor dataAccessor) throws SQLException {\n+    Connection dbConnection = dataAccessor.getDatabaseConnection(true);\n+    Statement statement = dbConnection.createStatement();\n+    statement.executeUpdate(\"DELETE FROM \" + AccountReportsDao.ACCOUNT_REPORTS_TABLE);\n+  }\n+\n+  private void assertTableSize(MySqlDataAccessor dataAccessor, int expectedNumRows) throws SQLException {\n+    Connection dbConnection = dataAccessor.getDatabaseConnection(true);\n+    Statement statement = dbConnection.createStatement();\n+    ResultSet resultSet = statement.executeQuery(\"SELECT * FROM \" + AccountReportsDao.ACCOUNT_REPORTS_TABLE);\n+    int numRows = 0;\n+    if (resultSet != null) {\n+      while (resultSet.next()) {\n+        numRows++;\n+      }\n+    }\n+    resultSet.close();", "originalCommit": "d6fae68e0fcf0876ae9e53067f2153e077684e41", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAxNzM1Ng==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r528017356", "bodyText": "Feel free to move closeQuietly() from MySqlDataAccessor to MySqlUtils and call it from here.", "author": "lightningrob", "createdAt": "2020-11-20T23:08:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAxNjA4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAyMjA1Mg==", "url": "https://github.com/linkedin/ambry/pull/1696#discussion_r528022052", "bodyText": "updated.", "author": "justinlin-linkedin", "createdAt": "2020-11-20T23:24:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAxNjA4Mw=="}], "type": "inlineReview"}, {"oid": "47f319dd4ba551c448739453955ad21a921885dc", "url": "https://github.com/linkedin/ambry/commit/47f319dd4ba551c448739453955ad21a921885dc", "message": "Fix an issue", "committedDate": "2020-11-20T23:24:45Z", "type": "commit"}]}