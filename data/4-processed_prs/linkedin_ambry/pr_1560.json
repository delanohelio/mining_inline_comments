{"pr_number": 1560, "pr_title": "Add more integration test for undelete in ambry-server", "pr_createdAt": "2020-06-11T21:53:48Z", "pr_url": "https://github.com/linkedin/ambry/pull/1560", "timeline": [{"oid": "d040a4bbc62c9b5b33ea7038be30c14b56e5385b", "url": "https://github.com/linkedin/ambry/commit/d040a4bbc62c9b5b33ea7038be30c14b56e5385b", "message": "Add more integration test for undelete in ambry-server", "committedDate": "2020-06-15T16:48:14Z", "type": "commit"}, {"oid": "2a75d56c095fa591046ba4a35400b474f0d6156a", "url": "https://github.com/linkedin/ambry/commit/2a75d56c095fa591046ba4a35400b474f0d6156a", "message": "Fix a test failure", "committedDate": "2020-06-15T16:56:20Z", "type": "commit"}, {"oid": "2a75d56c095fa591046ba4a35400b474f0d6156a", "url": "https://github.com/linkedin/ambry/commit/2a75d56c095fa591046ba4a35400b474f0d6156a", "message": "Fix a test failure", "committedDate": "2020-06-15T16:56:20Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk3NTkxNg==", "url": "https://github.com/linkedin/ambry/pull/1560#discussion_r441975916", "bodyText": "Good fix. Btw, could you format this file? (At least import java.util.concurrent.Executors; can be removed)", "author": "jsjtzyy", "createdAt": "2020-06-18T05:27:10Z", "path": "ambry-network/src/main/java/com/github/ambry/network/Selector.java", "diffHunk": "@@ -243,6 +244,9 @@ public void close() {\n       metrics.selectorNioCloseErrorCount.inc();\n       logger.error(\"Exception closing nioSelector:\", e);\n     }\n+    if (executorPool != null) {\n+      executorPool.shutdown();", "originalCommit": "2a75d56c095fa591046ba4a35400b474f0d6156a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk3NzM4Mg==", "url": "https://github.com/linkedin/ambry/pull/1560#discussion_r441977382", "bodyText": "minor: format this file", "author": "jsjtzyy", "createdAt": "2020-06-18T05:32:22Z", "path": "ambry-server/src/integration-test/java/com/github/ambry/server/ServerTestUtil.java", "diffHunk": "@@ -2051,6 +2059,290 @@ static void endToEndReplicationWithMultiNodeSinglePartitionTest(String routerDat\n     }\n   }\n \n+  static void undeleteCornerCasesTest(MockCluster cluster, PortType portType, SSLConfig clientSSLConfig1,\n+      SSLConfig clientSSLConfig2, SSLConfig clientSSLConfig3, SSLSocketFactory clientSSLSocketFactory1,\n+      SSLSocketFactory clientSSLSocketFactory2, SSLSocketFactory clientSSLSocketFactory3,\n+      MockNotificationSystem notificationSystem, Properties routerProps, boolean testEncryption) {\n+    MockClusterMap clusterMap = cluster.getClusterMap();\n+    BlobIdFactory blobIdFactory = new BlobIdFactory(clusterMap);\n+    byte[] usermetadata = new byte[1000];\n+    byte[] data = new byte[31870];\n+    byte[] encryptionKey = new byte[100];\n+    short accountId = Utils.getRandomShort(TestUtils.RANDOM);\n+    short containerId = Utils.getRandomShort(TestUtils.RANDOM);\n+    BlobProperties properties = new BlobProperties(31870, \"serviceid1\", accountId, containerId, testEncryption);\n+    TestUtils.RANDOM.nextBytes(usermetadata);\n+    TestUtils.RANDOM.nextBytes(data);\n+    if (testEncryption) {\n+      TestUtils.RANDOM.nextBytes(encryptionKey);\n+    }\n+    short blobIdVersion = CommonTestUtils.getCurrentBlobIdVersion();\n+    Map<String, List<DataNodeId>> dataNodesPerDC =\n+        clusterMap.getDataNodes().stream().collect(Collectors.groupingBy(d -> d.getDatacenterName()));\n+    Map<String, Pair<SSLConfig, SSLSocketFactory>> sslSettingPerDC = new HashMap<>();\n+    sslSettingPerDC.put(\"DC1\", new Pair<>(clientSSLConfig1, clientSSLSocketFactory1));\n+    sslSettingPerDC.put(\"DC2\", new Pair<>(clientSSLConfig2, clientSSLSocketFactory2));\n+    sslSettingPerDC.put(\"DC3\", new Pair<>(clientSSLConfig3, clientSSLSocketFactory3));\n+\n+    List<PartitionId> partitionIds = clusterMap.getWritablePartitionIds(MockClusterMap.DEFAULT_PARTITION_CLASS);\n+    DataNodeId dataNodeId = cluster.getOneDataNodeFromEachDatacenter(Arrays.asList(\"DC1\")).get(0);\n+    Router router = null;\n+    try {\n+      Properties routerProperties = getRouterProps(\"DC1\");\n+      routerProperties.putAll(routerProps);\n+      VerifiableProperties routerVerifiableProps = new VerifiableProperties(routerProperties);\n+      AccountService accountService = new InMemAccountService(false, true);\n+      router = new NonBlockingRouterFactory(routerVerifiableProps, clusterMap, new MockNotificationSystem(clusterMap),\n+          getSSLFactoryIfRequired(routerVerifiableProps), accountService).getRouter();\n+\n+      // channels to all datanodes\n+      List<ConnectedChannel> channels = new ArrayList<>();\n+      for (Map.Entry<String, List<DataNodeId>> entry : dataNodesPerDC.entrySet()) {\n+        Pair<SSLConfig, SSLSocketFactory> pair = sslSettingPerDC.get(entry.getKey());\n+        for (DataNodeId node : entry.getValue()) {\n+          ConnectedChannel connectedChannel =\n+              getBlockingChannelBasedOnPortType(portType, node, pair.getSecond(), pair.getFirst());\n+          connectedChannel.connect();\n+          channels.add(connectedChannel);\n+        }\n+      }\n+\n+      //////////////////////////////////////////////////////\n+      // Corner case 1: When only one datacenter has delete\n+      //////////////////////////////////////////////////////\n+      BlobId blobId1 = new BlobId(blobIdVersion, BlobId.BlobIdType.NATIVE, clusterMap.getLocalDatacenterId(),\n+          properties.getAccountId(), properties.getContainerId(), partitionIds.get(0), false,\n+          BlobId.BlobDataType.DATACHUNK);\n+      ConnectedChannel channel =\n+          getBlockingChannelBasedOnPortType(portType, dataNodeId, clientSSLSocketFactory1, clientSSLConfig1);\n+      channel.connect();\n+\n+      PutRequest putRequest =\n+          new PutRequest(1, \"client1\", blobId1, properties, ByteBuffer.wrap(usermetadata), Unpooled.wrappedBuffer(data),\n+              properties.getBlobSize(), BlobType.DataBlob, testEncryption ? ByteBuffer.wrap(encryptionKey) : null);\n+      channel.send(putRequest);\n+\n+      InputStream putResponseStream = channel.receive().getInputStream();\n+      PutResponse response = PutResponse.readFrom(new DataInputStream(putResponseStream));\n+      assertEquals(ServerErrorCode.No_Error, response.getError());\n+\n+      notificationSystem.awaitBlobCreations(blobId1.toString());\n+\n+      // Now stop the replications this partition.\n+      PartitionId partitionId = blobId1.getPartition();\n+      controlReplicationForPartition(channels, partitionId, false);\n+\n+      // Now send the delete to two data nodes in the same DC\n+      List<DataNodeId> toBeDeleteDataNodes = dataNodesPerDC.values().stream().findFirst().get();\n+      Pair<SSLConfig, SSLSocketFactory> pair = sslSettingPerDC.get(toBeDeleteDataNodes.get(0).getDatacenterName());\n+      ConnectedChannel channel1 =\n+          getBlockingChannelBasedOnPortType(portType, toBeDeleteDataNodes.get(0), pair.getSecond(), pair.getFirst());\n+      channel1.connect();\n+      ConnectedChannel channel2 =\n+          getBlockingChannelBasedOnPortType(portType, toBeDeleteDataNodes.get(1), pair.getSecond(), pair.getFirst());\n+      channel2.connect();\n+      DeleteRequest deleteRequest1 = new DeleteRequest(1, \"deleteClient\", blobId1, System.currentTimeMillis());\n+      channel1.send(deleteRequest1);\n+      DeleteResponse deleteResponse = DeleteResponse.readFrom(new DataInputStream(channel1.receive().getInputStream()));\n+      assertEquals(ServerErrorCode.No_Error, deleteResponse.getError());\n+      DeleteRequest deleteRequest2 =\n+          new DeleteRequest(1, \"deleteClient\", blobId1, deleteRequest1.getDeletionTimeInMs());\n+      channel2.send(deleteRequest2);\n+      deleteResponse = DeleteResponse.readFrom(new DataInputStream(channel2.receive().getInputStream()));\n+      assertEquals(ServerErrorCode.No_Error, deleteResponse.getError());\n+\n+      // Now send the undelete operation through router, and it should fail because of not deleted error.\n+      Future<Void> future = router.undeleteBlob(blobId1.toString(), \"service\", null);\n+      try {\n+        future.get();\n+        fail(\"Undelete blob \" + blobId1.toString() + \" should fail\");\n+      } catch (ExecutionException e) {\n+        assertTrue(e.getCause() instanceof RouterException);\n+        assertEquals(RouterErrorCode.BlobNotDeleted, ((RouterException) e.getCause()).getErrorCode());\n+      }\n+\n+      // Now see if either data node 1 or data node 2 has undelete or not, if so, undelete would replicate. If not,\n+      // delete would replicate.\n+      List<PartitionRequestInfo> partitionRequestInfoList = getPartitionRequestInfoListFromBlobId(blobId1);\n+      boolean hasUndelete = false;\n+      for (ConnectedChannel connectedChannel : new ConnectedChannel[]{channel1, channel2}) {\n+        GetRequest getRequest =\n+            new GetRequest(1, \"clientId1\", MessageFormatFlags.BlobProperties, partitionRequestInfoList,\n+                GetOption.Include_All);\n+        channel1.send(getRequest);\n+        GetResponse getResponse =\n+            GetResponse.readFrom(new DataInputStream(channel1.receive().getInputStream()), clusterMap);\n+        assertEquals(ServerErrorCode.No_Error, getResponse.getPartitionResponseInfoList().get(0).getErrorCode());\n+        try {\n+          BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(getResponse.getInputStream());\n+          hasUndelete = getResponse.getPartitionResponseInfoList().get(0).getMessageInfoList().get(0).getLifeVersion()\n+              == (short) 1;\n+        } catch (MessageFormatException e) {\n+          e.printStackTrace();\n+          fail();\n+        }\n+        if (hasUndelete) {\n+          break;\n+        }\n+      }\n+\n+      // Now restart the replication\n+      controlReplicationForPartition(channels, partitionId, true);\n+      if (hasUndelete) {\n+        notificationSystem.awaitBlobUndeletes(blobId1.toString());\n+      } else {\n+        notificationSystem.awaitBlobDeletions(blobId1.toString());\n+      }\n+\n+      for (ConnectedChannel connectedChannel : channels) {\n+        GetRequest getRequest =\n+            new GetRequest(1, \"clientId1\", MessageFormatFlags.BlobProperties, partitionRequestInfoList,\n+                GetOption.Include_All);\n+        connectedChannel.send(getRequest);\n+        GetResponse getResponse =\n+            GetResponse.readFrom(new DataInputStream(connectedChannel.receive().getInputStream()), clusterMap);\n+        assertEquals(ServerErrorCode.No_Error, getResponse.getPartitionResponseInfoList().get(0).getErrorCode());\n+        MessageFormatRecord.deserializeBlobProperties(getResponse.getInputStream());\n+        if (hasUndelete) {\n+          assertEquals((short) 1,\n+              getResponse.getPartitionResponseInfoList().get(0).getMessageInfoList().get(0).getLifeVersion());\n+          assertTrue(getResponse.getPartitionResponseInfoList().get(0).getMessageInfoList().get(0).isUndeleted());\n+          assertFalse(getResponse.getPartitionResponseInfoList().get(0).getMessageInfoList().get(0).isDeleted());\n+        } else {\n+          assertEquals((short) 0,\n+              getResponse.getPartitionResponseInfoList().get(0).getMessageInfoList().get(0).getLifeVersion());\n+          assertTrue(getResponse.getPartitionResponseInfoList().get(0).getMessageInfoList().get(0).isDeleted());\n+          assertFalse(getResponse.getPartitionResponseInfoList().get(0).getMessageInfoList().get(0).isUndeleted());\n+        }\n+      }\n+\n+      /////////////////////////////////////////////////////////////\n+      // Corner case 2: two data nodes have different life versions\n+      ////////////////////////////////////////////////////////////\n+      BlobId blobId2 = new BlobId(blobIdVersion, BlobId.BlobIdType.NATIVE, clusterMap.getLocalDatacenterId(),\n+          properties.getAccountId(), properties.getContainerId(), partitionIds.get(0), false,\n+          BlobId.BlobDataType.DATACHUNK);\n+      putRequest =\n+          new PutRequest(1, \"client1\", blobId2, properties, ByteBuffer.wrap(usermetadata), Unpooled.wrappedBuffer(data),\n+              properties.getBlobSize(), BlobType.DataBlob, testEncryption ? ByteBuffer.wrap(encryptionKey) : null);\n+      channel.send(putRequest);\n+      putResponseStream = channel.receive().getInputStream();\n+      response = PutResponse.readFrom(new DataInputStream(putResponseStream));\n+      assertEquals(ServerErrorCode.No_Error, response.getError());\n+      notificationSystem.awaitBlobCreations(blobId2.toString());\n+\n+      // Now delete this blob on all servers.\n+      DeleteRequest deleteRequest = new DeleteRequest(1, \"deleteClient\", blobId2, System.currentTimeMillis());\n+      channel.send(deleteRequest);\n+      deleteResponse = DeleteResponse.readFrom(new DataInputStream(channel.receive().getInputStream()));\n+      assertEquals(ServerErrorCode.No_Error, deleteResponse.getError());\n+      notificationSystem.awaitBlobDeletions(blobId2.toString());\n+\n+      // Now stop the replication\n+      partitionId = blobId2.getPartition();\n+      controlReplicationForPartition(channels, partitionId, false);\n+\n+      // Now send the undelete to two data nodes in the same DC and then send delete\n+      UndeleteRequest undeleteRequest = new UndeleteRequest(1, \"undeleteClient\", blobId2, System.currentTimeMillis());\n+      channel1.send(undeleteRequest);\n+      UndeleteResponse undeleteResponse =\n+          UndeleteResponse.readFrom(new DataInputStream(channel1.receive().getInputStream()));\n+      assertEquals(ServerErrorCode.No_Error, undeleteResponse.getError());\n+      assertEquals((short) 1, undeleteResponse.getLifeVersion());\n+      undeleteRequest = new UndeleteRequest(1, \"undeleteClient\", blobId2, undeleteRequest.getOperationTimeMs());\n+      channel2.send(undeleteRequest);\n+      undeleteResponse = UndeleteResponse.readFrom(new DataInputStream(channel2.receive().getInputStream()));\n+      assertEquals(ServerErrorCode.No_Error, undeleteResponse.getError());\n+      assertEquals((short) 1, undeleteResponse.getLifeVersion());\n+\n+      deleteRequest1 = new DeleteRequest(1, \"deleteClient\", blobId2, System.currentTimeMillis());\n+      channel1.send(deleteRequest1);\n+      deleteResponse = DeleteResponse.readFrom(new DataInputStream(channel1.receive().getInputStream()));\n+      assertEquals(ServerErrorCode.No_Error, deleteResponse.getError());\n+      deleteRequest2 = new DeleteRequest(1, \"deleteClient\", blobId2, deleteRequest1.getDeletionTimeInMs());\n+      channel2.send(deleteRequest2);\n+      deleteResponse = DeleteResponse.readFrom(new DataInputStream(channel2.receive().getInputStream()));\n+      assertEquals(ServerErrorCode.No_Error, deleteResponse.getError());\n+\n+      // Now send the undelete operation through router, and it should fail because of lifeVersion conflict error.\n+      future = router.undeleteBlob(blobId2.toString(), \"service\", null);\n+      try {\n+        future.get();\n+        fail(\"Undelete blob \" + blobId2.toString() + \" should fail\");\n+      } catch (ExecutionException e) {\n+        assertTrue(e.getCause() instanceof RouterException);\n+        assertEquals(RouterErrorCode.LifeVersionConflict, ((RouterException) e.getCause()).getErrorCode());\n+      }\n+\n+      // Now restart the replication\n+      controlReplicationForPartition(channels, partitionId, true);\n+      notificationSystem.awaitBlobUndeletes(blobId2.toString());\n+\n+      // Now after replication is resumed, the undelete of lifeversion 2 will eventually be replicated to all servers.\n+      partitionRequestInfoList = getPartitionRequestInfoListFromBlobId(blobId2);\n+      for (ConnectedChannel connectedChannel : channels) {\n+        // Even if the notificationSystem acknowledged the undelete, it might be triggered by undelete at lifeversion 1.\n+        // So check in a loop with a time out.\n+        long deadline = System.currentTimeMillis() + TimeUnit.SECONDS.toMillis(10);\n+        while (true) {\n+          GetRequest getRequest =", "originalCommit": "2a75d56c095fa591046ba4a35400b474f0d6156a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk3NzU5MA==", "url": "https://github.com/linkedin/ambry/pull/1560#discussion_r441977590", "bodyText": "minor: blobIdFactory is never used", "author": "jsjtzyy", "createdAt": "2020-06-18T05:33:11Z", "path": "ambry-server/src/integration-test/java/com/github/ambry/server/ServerTestUtil.java", "diffHunk": "@@ -2051,6 +2059,290 @@ static void endToEndReplicationWithMultiNodeSinglePartitionTest(String routerDat\n     }\n   }\n \n+  static void undeleteCornerCasesTest(MockCluster cluster, PortType portType, SSLConfig clientSSLConfig1,\n+      SSLConfig clientSSLConfig2, SSLConfig clientSSLConfig3, SSLSocketFactory clientSSLSocketFactory1,\n+      SSLSocketFactory clientSSLSocketFactory2, SSLSocketFactory clientSSLSocketFactory3,\n+      MockNotificationSystem notificationSystem, Properties routerProps, boolean testEncryption) {\n+    MockClusterMap clusterMap = cluster.getClusterMap();\n+    BlobIdFactory blobIdFactory = new BlobIdFactory(clusterMap);", "originalCommit": "2a75d56c095fa591046ba4a35400b474f0d6156a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk3ODk3NQ==", "url": "https://github.com/linkedin/ambry/pull/1560#discussion_r441978975", "bodyText": "Can be simplified to:\nDataNodeId dataNodeId = dataNodesPerDC.get(\"DC1\").get(0);", "author": "jsjtzyy", "createdAt": "2020-06-18T05:38:10Z", "path": "ambry-server/src/integration-test/java/com/github/ambry/server/ServerTestUtil.java", "diffHunk": "@@ -2051,6 +2059,290 @@ static void endToEndReplicationWithMultiNodeSinglePartitionTest(String routerDat\n     }\n   }\n \n+  static void undeleteCornerCasesTest(MockCluster cluster, PortType portType, SSLConfig clientSSLConfig1,\n+      SSLConfig clientSSLConfig2, SSLConfig clientSSLConfig3, SSLSocketFactory clientSSLSocketFactory1,\n+      SSLSocketFactory clientSSLSocketFactory2, SSLSocketFactory clientSSLSocketFactory3,\n+      MockNotificationSystem notificationSystem, Properties routerProps, boolean testEncryption) {\n+    MockClusterMap clusterMap = cluster.getClusterMap();\n+    BlobIdFactory blobIdFactory = new BlobIdFactory(clusterMap);\n+    byte[] usermetadata = new byte[1000];\n+    byte[] data = new byte[31870];\n+    byte[] encryptionKey = new byte[100];\n+    short accountId = Utils.getRandomShort(TestUtils.RANDOM);\n+    short containerId = Utils.getRandomShort(TestUtils.RANDOM);\n+    BlobProperties properties = new BlobProperties(31870, \"serviceid1\", accountId, containerId, testEncryption);\n+    TestUtils.RANDOM.nextBytes(usermetadata);\n+    TestUtils.RANDOM.nextBytes(data);\n+    if (testEncryption) {\n+      TestUtils.RANDOM.nextBytes(encryptionKey);\n+    }\n+    short blobIdVersion = CommonTestUtils.getCurrentBlobIdVersion();\n+    Map<String, List<DataNodeId>> dataNodesPerDC =\n+        clusterMap.getDataNodes().stream().collect(Collectors.groupingBy(d -> d.getDatacenterName()));\n+    Map<String, Pair<SSLConfig, SSLSocketFactory>> sslSettingPerDC = new HashMap<>();\n+    sslSettingPerDC.put(\"DC1\", new Pair<>(clientSSLConfig1, clientSSLSocketFactory1));\n+    sslSettingPerDC.put(\"DC2\", new Pair<>(clientSSLConfig2, clientSSLSocketFactory2));\n+    sslSettingPerDC.put(\"DC3\", new Pair<>(clientSSLConfig3, clientSSLSocketFactory3));\n+\n+    List<PartitionId> partitionIds = clusterMap.getWritablePartitionIds(MockClusterMap.DEFAULT_PARTITION_CLASS);\n+    DataNodeId dataNodeId = cluster.getOneDataNodeFromEachDatacenter(Arrays.asList(\"DC1\")).get(0);", "originalCommit": "2a75d56c095fa591046ba4a35400b474f0d6156a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk4MjMyMQ==", "url": "https://github.com/linkedin/ambry/pull/1560#discussion_r441982321", "bodyText": "Does this only test deserialization of blob properties? It seems propertyOutput is never used.", "author": "jsjtzyy", "createdAt": "2020-06-18T05:50:00Z", "path": "ambry-server/src/integration-test/java/com/github/ambry/server/ServerTestUtil.java", "diffHunk": "@@ -2051,6 +2059,290 @@ static void endToEndReplicationWithMultiNodeSinglePartitionTest(String routerDat\n     }\n   }\n \n+  static void undeleteCornerCasesTest(MockCluster cluster, PortType portType, SSLConfig clientSSLConfig1,\n+      SSLConfig clientSSLConfig2, SSLConfig clientSSLConfig3, SSLSocketFactory clientSSLSocketFactory1,\n+      SSLSocketFactory clientSSLSocketFactory2, SSLSocketFactory clientSSLSocketFactory3,\n+      MockNotificationSystem notificationSystem, Properties routerProps, boolean testEncryption) {\n+    MockClusterMap clusterMap = cluster.getClusterMap();\n+    BlobIdFactory blobIdFactory = new BlobIdFactory(clusterMap);\n+    byte[] usermetadata = new byte[1000];\n+    byte[] data = new byte[31870];\n+    byte[] encryptionKey = new byte[100];\n+    short accountId = Utils.getRandomShort(TestUtils.RANDOM);\n+    short containerId = Utils.getRandomShort(TestUtils.RANDOM);\n+    BlobProperties properties = new BlobProperties(31870, \"serviceid1\", accountId, containerId, testEncryption);\n+    TestUtils.RANDOM.nextBytes(usermetadata);\n+    TestUtils.RANDOM.nextBytes(data);\n+    if (testEncryption) {\n+      TestUtils.RANDOM.nextBytes(encryptionKey);\n+    }\n+    short blobIdVersion = CommonTestUtils.getCurrentBlobIdVersion();\n+    Map<String, List<DataNodeId>> dataNodesPerDC =\n+        clusterMap.getDataNodes().stream().collect(Collectors.groupingBy(d -> d.getDatacenterName()));\n+    Map<String, Pair<SSLConfig, SSLSocketFactory>> sslSettingPerDC = new HashMap<>();\n+    sslSettingPerDC.put(\"DC1\", new Pair<>(clientSSLConfig1, clientSSLSocketFactory1));\n+    sslSettingPerDC.put(\"DC2\", new Pair<>(clientSSLConfig2, clientSSLSocketFactory2));\n+    sslSettingPerDC.put(\"DC3\", new Pair<>(clientSSLConfig3, clientSSLSocketFactory3));\n+\n+    List<PartitionId> partitionIds = clusterMap.getWritablePartitionIds(MockClusterMap.DEFAULT_PARTITION_CLASS);\n+    DataNodeId dataNodeId = cluster.getOneDataNodeFromEachDatacenter(Arrays.asList(\"DC1\")).get(0);\n+    Router router = null;\n+    try {\n+      Properties routerProperties = getRouterProps(\"DC1\");\n+      routerProperties.putAll(routerProps);\n+      VerifiableProperties routerVerifiableProps = new VerifiableProperties(routerProperties);\n+      AccountService accountService = new InMemAccountService(false, true);\n+      router = new NonBlockingRouterFactory(routerVerifiableProps, clusterMap, new MockNotificationSystem(clusterMap),\n+          getSSLFactoryIfRequired(routerVerifiableProps), accountService).getRouter();\n+\n+      // channels to all datanodes\n+      List<ConnectedChannel> channels = new ArrayList<>();\n+      for (Map.Entry<String, List<DataNodeId>> entry : dataNodesPerDC.entrySet()) {\n+        Pair<SSLConfig, SSLSocketFactory> pair = sslSettingPerDC.get(entry.getKey());\n+        for (DataNodeId node : entry.getValue()) {\n+          ConnectedChannel connectedChannel =\n+              getBlockingChannelBasedOnPortType(portType, node, pair.getSecond(), pair.getFirst());\n+          connectedChannel.connect();\n+          channels.add(connectedChannel);\n+        }\n+      }\n+\n+      //////////////////////////////////////////////////////\n+      // Corner case 1: When only one datacenter has delete\n+      //////////////////////////////////////////////////////\n+      BlobId blobId1 = new BlobId(blobIdVersion, BlobId.BlobIdType.NATIVE, clusterMap.getLocalDatacenterId(),\n+          properties.getAccountId(), properties.getContainerId(), partitionIds.get(0), false,\n+          BlobId.BlobDataType.DATACHUNK);\n+      ConnectedChannel channel =\n+          getBlockingChannelBasedOnPortType(portType, dataNodeId, clientSSLSocketFactory1, clientSSLConfig1);\n+      channel.connect();\n+\n+      PutRequest putRequest =\n+          new PutRequest(1, \"client1\", blobId1, properties, ByteBuffer.wrap(usermetadata), Unpooled.wrappedBuffer(data),\n+              properties.getBlobSize(), BlobType.DataBlob, testEncryption ? ByteBuffer.wrap(encryptionKey) : null);\n+      channel.send(putRequest);\n+\n+      InputStream putResponseStream = channel.receive().getInputStream();\n+      PutResponse response = PutResponse.readFrom(new DataInputStream(putResponseStream));\n+      assertEquals(ServerErrorCode.No_Error, response.getError());\n+\n+      notificationSystem.awaitBlobCreations(blobId1.toString());\n+\n+      // Now stop the replications this partition.\n+      PartitionId partitionId = blobId1.getPartition();\n+      controlReplicationForPartition(channels, partitionId, false);\n+\n+      // Now send the delete to two data nodes in the same DC\n+      List<DataNodeId> toBeDeleteDataNodes = dataNodesPerDC.values().stream().findFirst().get();\n+      Pair<SSLConfig, SSLSocketFactory> pair = sslSettingPerDC.get(toBeDeleteDataNodes.get(0).getDatacenterName());\n+      ConnectedChannel channel1 =\n+          getBlockingChannelBasedOnPortType(portType, toBeDeleteDataNodes.get(0), pair.getSecond(), pair.getFirst());\n+      channel1.connect();\n+      ConnectedChannel channel2 =\n+          getBlockingChannelBasedOnPortType(portType, toBeDeleteDataNodes.get(1), pair.getSecond(), pair.getFirst());\n+      channel2.connect();\n+      DeleteRequest deleteRequest1 = new DeleteRequest(1, \"deleteClient\", blobId1, System.currentTimeMillis());\n+      channel1.send(deleteRequest1);\n+      DeleteResponse deleteResponse = DeleteResponse.readFrom(new DataInputStream(channel1.receive().getInputStream()));\n+      assertEquals(ServerErrorCode.No_Error, deleteResponse.getError());\n+      DeleteRequest deleteRequest2 =\n+          new DeleteRequest(1, \"deleteClient\", blobId1, deleteRequest1.getDeletionTimeInMs());\n+      channel2.send(deleteRequest2);\n+      deleteResponse = DeleteResponse.readFrom(new DataInputStream(channel2.receive().getInputStream()));\n+      assertEquals(ServerErrorCode.No_Error, deleteResponse.getError());\n+\n+      // Now send the undelete operation through router, and it should fail because of not deleted error.\n+      Future<Void> future = router.undeleteBlob(blobId1.toString(), \"service\", null);\n+      try {\n+        future.get();\n+        fail(\"Undelete blob \" + blobId1.toString() + \" should fail\");\n+      } catch (ExecutionException e) {\n+        assertTrue(e.getCause() instanceof RouterException);\n+        assertEquals(RouterErrorCode.BlobNotDeleted, ((RouterException) e.getCause()).getErrorCode());\n+      }\n+\n+      // Now see if either data node 1 or data node 2 has undelete or not, if so, undelete would replicate. If not,\n+      // delete would replicate.\n+      List<PartitionRequestInfo> partitionRequestInfoList = getPartitionRequestInfoListFromBlobId(blobId1);\n+      boolean hasUndelete = false;\n+      for (ConnectedChannel connectedChannel : new ConnectedChannel[]{channel1, channel2}) {\n+        GetRequest getRequest =\n+            new GetRequest(1, \"clientId1\", MessageFormatFlags.BlobProperties, partitionRequestInfoList,\n+                GetOption.Include_All);\n+        channel1.send(getRequest);\n+        GetResponse getResponse =\n+            GetResponse.readFrom(new DataInputStream(channel1.receive().getInputStream()), clusterMap);\n+        assertEquals(ServerErrorCode.No_Error, getResponse.getPartitionResponseInfoList().get(0).getErrorCode());\n+        try {\n+          BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(getResponse.getInputStream());", "originalCommit": "2a75d56c095fa591046ba4a35400b474f0d6156a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTk4MjcxNw==", "url": "https://github.com/linkedin/ambry/pull/1560#discussion_r441982717", "bodyText": "seems to be redundant, can be removed", "author": "jsjtzyy", "createdAt": "2020-06-18T05:51:05Z", "path": "ambry-server/src/integration-test/java/com/github/ambry/server/ServerTestUtil.java", "diffHunk": "@@ -2051,6 +2059,290 @@ static void endToEndReplicationWithMultiNodeSinglePartitionTest(String routerDat\n     }\n   }\n \n+  static void undeleteCornerCasesTest(MockCluster cluster, PortType portType, SSLConfig clientSSLConfig1,\n+      SSLConfig clientSSLConfig2, SSLConfig clientSSLConfig3, SSLSocketFactory clientSSLSocketFactory1,\n+      SSLSocketFactory clientSSLSocketFactory2, SSLSocketFactory clientSSLSocketFactory3,\n+      MockNotificationSystem notificationSystem, Properties routerProps, boolean testEncryption) {\n+    MockClusterMap clusterMap = cluster.getClusterMap();\n+    BlobIdFactory blobIdFactory = new BlobIdFactory(clusterMap);\n+    byte[] usermetadata = new byte[1000];\n+    byte[] data = new byte[31870];\n+    byte[] encryptionKey = new byte[100];\n+    short accountId = Utils.getRandomShort(TestUtils.RANDOM);\n+    short containerId = Utils.getRandomShort(TestUtils.RANDOM);\n+    BlobProperties properties = new BlobProperties(31870, \"serviceid1\", accountId, containerId, testEncryption);\n+    TestUtils.RANDOM.nextBytes(usermetadata);\n+    TestUtils.RANDOM.nextBytes(data);\n+    if (testEncryption) {\n+      TestUtils.RANDOM.nextBytes(encryptionKey);\n+    }\n+    short blobIdVersion = CommonTestUtils.getCurrentBlobIdVersion();\n+    Map<String, List<DataNodeId>> dataNodesPerDC =\n+        clusterMap.getDataNodes().stream().collect(Collectors.groupingBy(d -> d.getDatacenterName()));\n+    Map<String, Pair<SSLConfig, SSLSocketFactory>> sslSettingPerDC = new HashMap<>();\n+    sslSettingPerDC.put(\"DC1\", new Pair<>(clientSSLConfig1, clientSSLSocketFactory1));\n+    sslSettingPerDC.put(\"DC2\", new Pair<>(clientSSLConfig2, clientSSLSocketFactory2));\n+    sslSettingPerDC.put(\"DC3\", new Pair<>(clientSSLConfig3, clientSSLSocketFactory3));\n+\n+    List<PartitionId> partitionIds = clusterMap.getWritablePartitionIds(MockClusterMap.DEFAULT_PARTITION_CLASS);\n+    DataNodeId dataNodeId = cluster.getOneDataNodeFromEachDatacenter(Arrays.asList(\"DC1\")).get(0);\n+    Router router = null;\n+    try {\n+      Properties routerProperties = getRouterProps(\"DC1\");\n+      routerProperties.putAll(routerProps);\n+      VerifiableProperties routerVerifiableProps = new VerifiableProperties(routerProperties);\n+      AccountService accountService = new InMemAccountService(false, true);\n+      router = new NonBlockingRouterFactory(routerVerifiableProps, clusterMap, new MockNotificationSystem(clusterMap),\n+          getSSLFactoryIfRequired(routerVerifiableProps), accountService).getRouter();\n+\n+      // channels to all datanodes\n+      List<ConnectedChannel> channels = new ArrayList<>();\n+      for (Map.Entry<String, List<DataNodeId>> entry : dataNodesPerDC.entrySet()) {\n+        Pair<SSLConfig, SSLSocketFactory> pair = sslSettingPerDC.get(entry.getKey());\n+        for (DataNodeId node : entry.getValue()) {\n+          ConnectedChannel connectedChannel =\n+              getBlockingChannelBasedOnPortType(portType, node, pair.getSecond(), pair.getFirst());\n+          connectedChannel.connect();\n+          channels.add(connectedChannel);\n+        }\n+      }\n+\n+      //////////////////////////////////////////////////////\n+      // Corner case 1: When only one datacenter has delete\n+      //////////////////////////////////////////////////////\n+      BlobId blobId1 = new BlobId(blobIdVersion, BlobId.BlobIdType.NATIVE, clusterMap.getLocalDatacenterId(),\n+          properties.getAccountId(), properties.getContainerId(), partitionIds.get(0), false,\n+          BlobId.BlobDataType.DATACHUNK);\n+      ConnectedChannel channel =\n+          getBlockingChannelBasedOnPortType(portType, dataNodeId, clientSSLSocketFactory1, clientSSLConfig1);\n+      channel.connect();\n+\n+      PutRequest putRequest =\n+          new PutRequest(1, \"client1\", blobId1, properties, ByteBuffer.wrap(usermetadata), Unpooled.wrappedBuffer(data),\n+              properties.getBlobSize(), BlobType.DataBlob, testEncryption ? ByteBuffer.wrap(encryptionKey) : null);\n+      channel.send(putRequest);\n+\n+      InputStream putResponseStream = channel.receive().getInputStream();\n+      PutResponse response = PutResponse.readFrom(new DataInputStream(putResponseStream));\n+      assertEquals(ServerErrorCode.No_Error, response.getError());\n+\n+      notificationSystem.awaitBlobCreations(blobId1.toString());\n+\n+      // Now stop the replications this partition.\n+      PartitionId partitionId = blobId1.getPartition();\n+      controlReplicationForPartition(channels, partitionId, false);\n+\n+      // Now send the delete to two data nodes in the same DC\n+      List<DataNodeId> toBeDeleteDataNodes = dataNodesPerDC.values().stream().findFirst().get();\n+      Pair<SSLConfig, SSLSocketFactory> pair = sslSettingPerDC.get(toBeDeleteDataNodes.get(0).getDatacenterName());\n+      ConnectedChannel channel1 =\n+          getBlockingChannelBasedOnPortType(portType, toBeDeleteDataNodes.get(0), pair.getSecond(), pair.getFirst());\n+      channel1.connect();\n+      ConnectedChannel channel2 =\n+          getBlockingChannelBasedOnPortType(portType, toBeDeleteDataNodes.get(1), pair.getSecond(), pair.getFirst());\n+      channel2.connect();\n+      DeleteRequest deleteRequest1 = new DeleteRequest(1, \"deleteClient\", blobId1, System.currentTimeMillis());\n+      channel1.send(deleteRequest1);\n+      DeleteResponse deleteResponse = DeleteResponse.readFrom(new DataInputStream(channel1.receive().getInputStream()));\n+      assertEquals(ServerErrorCode.No_Error, deleteResponse.getError());\n+      DeleteRequest deleteRequest2 =\n+          new DeleteRequest(1, \"deleteClient\", blobId1, deleteRequest1.getDeletionTimeInMs());\n+      channel2.send(deleteRequest2);\n+      deleteResponse = DeleteResponse.readFrom(new DataInputStream(channel2.receive().getInputStream()));\n+      assertEquals(ServerErrorCode.No_Error, deleteResponse.getError());\n+\n+      // Now send the undelete operation through router, and it should fail because of not deleted error.\n+      Future<Void> future = router.undeleteBlob(blobId1.toString(), \"service\", null);\n+      try {\n+        future.get();\n+        fail(\"Undelete blob \" + blobId1.toString() + \" should fail\");\n+      } catch (ExecutionException e) {\n+        assertTrue(e.getCause() instanceof RouterException);\n+        assertEquals(RouterErrorCode.BlobNotDeleted, ((RouterException) e.getCause()).getErrorCode());\n+      }\n+\n+      // Now see if either data node 1 or data node 2 has undelete or not, if so, undelete would replicate. If not,\n+      // delete would replicate.\n+      List<PartitionRequestInfo> partitionRequestInfoList = getPartitionRequestInfoListFromBlobId(blobId1);\n+      boolean hasUndelete = false;\n+      for (ConnectedChannel connectedChannel : new ConnectedChannel[]{channel1, channel2}) {\n+        GetRequest getRequest =\n+            new GetRequest(1, \"clientId1\", MessageFormatFlags.BlobProperties, partitionRequestInfoList,\n+                GetOption.Include_All);\n+        channel1.send(getRequest);\n+        GetResponse getResponse =\n+            GetResponse.readFrom(new DataInputStream(channel1.receive().getInputStream()), clusterMap);\n+        assertEquals(ServerErrorCode.No_Error, getResponse.getPartitionResponseInfoList().get(0).getErrorCode());\n+        try {\n+          BlobProperties propertyOutput = MessageFormatRecord.deserializeBlobProperties(getResponse.getInputStream());\n+          hasUndelete = getResponse.getPartitionResponseInfoList().get(0).getMessageInfoList().get(0).getLifeVersion()\n+              == (short) 1;\n+        } catch (MessageFormatException e) {\n+          e.printStackTrace();\n+          fail();", "originalCommit": "2a75d56c095fa591046ba4a35400b474f0d6156a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a12eb2bf57e3d85ab1de1c0e82edf2fe034d062b", "url": "https://github.com/linkedin/ambry/commit/a12eb2bf57e3d85ab1de1c0e82edf2fe034d062b", "message": "Commentsg", "committedDate": "2020-06-18T06:01:47Z", "type": "commit"}, {"oid": "5621be7ed6c33f3d2a50f193d537de124edfb48c", "url": "https://github.com/linkedin/ambry/commit/5621be7ed6c33f3d2a50f193d537de124edfb48c", "message": "Typo", "committedDate": "2020-06-18T06:03:10Z", "type": "commit"}]}