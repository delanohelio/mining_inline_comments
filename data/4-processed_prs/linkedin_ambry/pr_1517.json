{"pr_number": 1517, "pr_title": "Cloud blob store changes for serving data", "pr_createdAt": "2020-05-11T20:05:33Z", "pr_url": "https://github.com/linkedin/ambry/pull/1517", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDAxMg==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425910012", "bodyText": "This misses the expired blobs.", "author": "lightningrob", "createdAt": "2020-05-15T16:20:55Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobMetadata.java", "diffHunk": "@@ -435,8 +435,36 @@ public void setLifeVersion(short lifeVersion) {\n    * @return true if this blob is deleted or expired, otherwise false.\n    */\n   public boolean isDeletedOrExpired() {\n-    return (expirationTime != Utils.Infinite_Time && expirationTime < System.currentTimeMillis())\n-        || deletionTime != Utils.Infinite_Time;\n+    return isExpired() || isDeleted();\n+  }\n+\n+  /**\n+   * @return true if this blob is marked as deleted, false otherwise.\n+   */\n+  public boolean isDeleted() {\n+    return (deletionTime != Utils.Infinite_Time);\n+  }\n+\n+  /**\n+   * @return true if this blob has expired, false otherwise.\n+   */\n+  public boolean isExpired() {\n+    return expirationTime != Utils.Infinite_Time && expirationTime < System.currentTimeMillis();\n+  }\n+\n+  /**\n+   * @return true if this blob is undeleted.\n+   */\n+  public boolean isUndeleted() {\n+    return !isDeleted() && lifeVersion > 0;\n+  }\n+\n+  /**\n+   * @param retentionPeriod period for which blobs marked a deleted aren't compacted away.\n+   * @return true if deletion time is outside retention window. false otherwise.\n+   */\n+  public boolean isCompactionCandidate(long retentionPeriod) {\n+    return isDeleted() && deletionTime <= (System.currentTimeMillis() - retentionPeriod);", "originalCommit": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU4NDM5Ng==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r429584396", "bodyText": "fixed.", "author": "ankagrawal", "createdAt": "2020-05-23T22:56:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDAxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDI3MA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425910270", "bodyText": "caller", "author": "lightningrob", "createdAt": "2020-05-15T16:21:23Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudDestination.java", "diffHunk": "@@ -53,28 +53,34 @@ boolean uploadBlob(BlobId blobId, long inputLength, CloudBlobMetadata cloudBlobM\n    * @param blobId id of the Ambry blob\n    * @param deletionTime time of blob deletion\n    * @param lifeVersion life version of the blob to be deleted.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.", "originalCommit": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDQ2Nw==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425910467", "bodyText": "And validate the delete.", "author": "lightningrob", "createdAt": "2020-05-15T16:21:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDI3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU4NDk0OQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r429584949", "bodyText": "fixed.", "author": "ankagrawal", "createdAt": "2020-05-23T23:09:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDI3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDcwMQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425910701", "bodyText": "caller to validate the undelete", "author": "lightningrob", "createdAt": "2020-05-15T16:22:08Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudDestination.java", "diffHunk": "@@ -53,28 +53,34 @@ boolean uploadBlob(BlobId blobId, long inputLength, CloudBlobMetadata cloudBlobM\n    * @param blobId id of the Ambry blob\n    * @param deletionTime time of blob deletion\n    * @param lifeVersion life version of the blob to be deleted.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.\n    * @return flag indicating whether the blob was deleted\n    * @throws CloudStorageException if the deletion encounters an error.\n    */\n-  boolean deleteBlob(BlobId blobId, long deletionTime, short lifeVersion) throws CloudStorageException;\n+  boolean deleteBlob(BlobId blobId, long deletionTime, short lifeVersion, CloudUpdateValidator cloudUpdateValidator)\n+      throws CloudStorageException;\n \n   /**\n    * Undelete the blob from cloud destination, and update the new life version.\n    * @param blobId id of the Ambry blob.\n    * @param lifeVersion new life version to update.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.", "originalCommit": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU4NDk1Mg==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r429584952", "bodyText": "fixed.", "author": "ankagrawal", "createdAt": "2020-05-23T23:09:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDcwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDg2OQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425910869", "bodyText": "caller", "author": "lightningrob", "createdAt": "2020-05-15T16:22:26Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudDestination.java", "diffHunk": "@@ -53,28 +53,34 @@ boolean uploadBlob(BlobId blobId, long inputLength, CloudBlobMetadata cloudBlobM\n    * @param blobId id of the Ambry blob\n    * @param deletionTime time of blob deletion\n    * @param lifeVersion life version of the blob to be deleted.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.\n    * @return flag indicating whether the blob was deleted\n    * @throws CloudStorageException if the deletion encounters an error.\n    */\n-  boolean deleteBlob(BlobId blobId, long deletionTime, short lifeVersion) throws CloudStorageException;\n+  boolean deleteBlob(BlobId blobId, long deletionTime, short lifeVersion, CloudUpdateValidator cloudUpdateValidator)\n+      throws CloudStorageException;\n \n   /**\n    * Undelete the blob from cloud destination, and update the new life version.\n    * @param blobId id of the Ambry blob.\n    * @param lifeVersion new life version to update.\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.\n    * @return final live version of the undeleted blob.\n    * @throws CloudStorageException if the undelete encounters an error.\n    */\n-  short undeleteBlob(BlobId blobId, short lifeVersion) throws CloudStorageException;\n+  short undeleteBlob(BlobId blobId, short lifeVersion, CloudUpdateValidator cloudUpdateValidator)\n+      throws CloudStorageException;\n \n   /**\n    * Update expiration time of blob in the cloud destination.\n    * @param blobId id of the Ambry blob\n    * @param expirationTime the new expiration time\n-   * @return flag indicating whether the blob was updated\n+   * @param cloudUpdateValidator {@link CloudUpdateValidator} object passed by called to validate the update.", "originalCommit": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU4NDk1Ng==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r429584956", "bodyText": "fixed.", "author": "ankagrawal", "createdAt": "2020-05-23T23:09:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMDg2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMTgyMg==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425911822", "bodyText": "new requested life version doesn't appear to be an argument.", "author": "lightningrob", "createdAt": "2020-05-15T16:24:06Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudUpdateValidator.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.github.ambry.store.StoreException;\n+import com.github.ambry.store.StoreKey;\n+import java.util.Map;\n+\n+\n+/**\n+ * Interface for Ambry validation logic for updates requested from cloud destination.\n+ */\n+public interface CloudUpdateValidator {\n+  /**\n+   * Validate operation on {@link CloudBlobMetadata} in cloud destination for the operation on blob with\n+   * given {@link StoreKey} and new requested life version.", "originalCommit": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkyNjE2OA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425926168", "bodyText": "I'd like to see clearer description of what is validated, or what would cause validation to fail.  And specifically that you are validating application of update fields to existing metadata.", "author": "lightningrob", "createdAt": "2020-05-15T16:49:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMTgyMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU4NDk5NQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r429584995", "bodyText": "Added comments to capture the description, while keeping it relatively generic so that it can potentially be applied to future CloudDestination extensions. Let me know if it looks good.", "author": "ankagrawal", "createdAt": "2020-05-23T23:10:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMTgyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTkxMzQ1NA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r425913454", "bodyText": "It seems strange that a class in cloud package is throwing StoreException.", "author": "lightningrob", "createdAt": "2020-05-15T16:27:09Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudUpdateValidator.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.github.ambry.store.StoreException;\n+import com.github.ambry.store.StoreKey;\n+import java.util.Map;\n+\n+\n+/**\n+ * Interface for Ambry validation logic for updates requested from cloud destination.\n+ */\n+public interface CloudUpdateValidator {\n+  /**\n+   * Validate operation on {@link CloudBlobMetadata} in cloud destination for the operation on blob with\n+   * given {@link StoreKey} and new requested life version.\n+   * @param metadata {@link CloudBlobMetadata} object obtained from cloud destination.\n+   * @param key {@link StoreKey} of the blob being updated.\n+   * @param updateFields {@link Map} of fields and new values requested for update.\n+   * @throws StoreException if validation fails.\n+   */\n+  void validateUpdate(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields) throws StoreException;", "originalCommit": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAwNjA4MA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r427006080", "bodyText": "We might need to distinguish between vcr and live traffic.  For VCR, shouldUpload() can return false if the TTL is low.", "author": "lightningrob", "createdAt": "2020-05-19T03:16:34Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -391,11 +377,15 @@ private boolean deleteIfNeeded(BlobId blobId, long deletionTime, short lifeVersi\n     // Note: always check cache before operation attempt, since this could be a retry after a CONFLICT error,\n     // in which case the cache may have been updated by another thread.\n     if (!checkCacheState(blobKey, lifeVersion, BlobState.DELETED)) {\n-      boolean deleted = cloudDestination.deleteBlob(blobId, deletionTime, lifeVersion);\n+      boolean deleted = cloudDestination.deleteBlob(blobId, deletionTime, lifeVersion,\n+          (metadata, key, updateFields) -> preDeleteValidation(metadata, key, updateFields));\n       addToCache(blobKey, lifeVersion, BlobState.DELETED);\n       return deleted;\n+    } else {\n+      throw new CloudStorageException(\"Error updating blob metadata\",", "originalCommit": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU4NDQ4Mw==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r429584483", "bodyText": "shouldUpload() gets called only for PUT request.\nIn this case, delete() can be called either by ReplicaThread or by AmbryRequests. Delete coming from AmbryRequests, for a lifeVersion that we have already seen, should throw an error. In case it comes from ReplicaThread, its ok for it to throw error. ReplicaThread::applyDelete handles StoreErrorCodes::ID_Deleted gracefully. Also such a behavior from CloudBlobStore seems to be in sync with BlobStore.", "author": "ankagrawal", "createdAt": "2020-05-23T22:58:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAwNjA4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAwNjUyNA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r427006524", "bodyText": "Why not just throw a StoreException here?\nAlso, for VCR case it may not be an error (that's why we mark it skipped).", "author": "lightningrob", "createdAt": "2020-05-19T03:18:26Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -314,13 +290,20 @@ private void putBlob(MessageInfo messageInfo, ByteBuffer messageBuf, long size)\n             new CloudBlobMetadata(blobId, messageInfo.getOperationTimeMs(), messageInfo.getExpirationTimeInMs(),\n                 messageInfo.getSize(), encryptionOrigin);\n         InputStream uploadInputStream = new ByteBufferInputStream(messageBuf);\n-        requestAgent.doWithRetries(() -> cloudDestination.uploadBlob(blobId, size, blobMetadata, uploadInputStream),\n-            \"Upload\", partitionId.toPathString());\n+        uploaded =\n+            requestAgent.doWithRetries(() -> cloudDestination.uploadBlob(blobId, size, blobMetadata, uploadInputStream),\n+                \"Upload\", partitionId.toPathString());\n       }\n       addToCache(blobId.getID(), (short) 0, BlobState.CREATED);\n+      if (!uploaded) {\n+        throw new StoreException(String.format(\"Another blob with same key %s exists in store\", blobId.getID()),\n+            StoreErrorCodes.Already_Exist);\n+      }\n     } else {\n-      logger.trace(\"Blob is skipped: {}\", messageInfo);\n       vcrMetrics.blobUploadSkippedCount.inc();\n+      throw new CloudStorageException(\"Error updating blob metadata\", new StoreException(", "originalCommit": "8209a5c500dc7c8c5a0b47c4528c3e4ad5379519", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU4NDQxOA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r429584418", "bodyText": "fixed.", "author": "ankagrawal", "createdAt": "2020-05-23T22:56:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAwNjUyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg0MDg5NA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430840894", "bodyText": "Expiration needs the same retention check.", "author": "lightningrob", "createdAt": "2020-05-27T03:45:15Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobMetadata.java", "diffHunk": "@@ -432,11 +432,32 @@ public void setLifeVersion(short lifeVersion) {\n   }\n \n   /**\n-   * @return true if this blob is deleted or expired, otherwise false.\n+   * @return true if this blob is marked as deleted, false otherwise.\n    */\n-  public boolean isDeletedOrExpired() {\n-    return (expirationTime != Utils.Infinite_Time && expirationTime < System.currentTimeMillis())\n-        || deletionTime != Utils.Infinite_Time;\n+  public boolean isDeleted() {\n+    return (deletionTime != Utils.Infinite_Time);\n+  }\n+\n+  /**\n+   * @return true if this blob has expired, false otherwise.\n+   */\n+  public boolean isExpired() {\n+    return expirationTime != Utils.Infinite_Time && expirationTime < System.currentTimeMillis();\n+  }\n+\n+  /**\n+   * @return true if this blob is undeleted.\n+   */\n+  public boolean isUndeleted() {\n+    return !isDeleted() && lifeVersion > 0;\n+  }\n+\n+  /**\n+   * @param retentionPeriod period for which blobs marked a deleted aren't compacted away.\n+   * @return true if deletion time is outside retention window or blob is expired. false otherwise.\n+   */\n+  public boolean isCompactionCandidate(long retentionPeriod) {\n+    return (isDeleted() && deletionTime <= (System.currentTimeMillis() - retentionPeriod)) || isExpired();", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4MjA2Ng==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431482066", "bodyText": "ok.", "author": "ankagrawal", "createdAt": "2020-05-27T22:37:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg0MDg5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1MjgyMw==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430852823", "bodyText": "We can get to this else clause if isVcr and uploaded are both true, in which case nothing was skipped.", "author": "lightningrob", "createdAt": "2020-05-27T04:39:43Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -295,15 +295,23 @@ private void putBlob(MessageInfo messageInfo, ByteBuffer messageBuf, long size)\n                 \"Upload\", partitionId.toPathString());\n       }\n       addToCache(blobId.getID(), (short) 0, BlobState.CREATED);\n-      if (!uploaded) {\n+      if (!uploaded && !isVcr) {\n+        // If put is coming from frontend, then uploadBlob must be true. Its not acceptable that a blob already exists.\n+        // If put is coming from vcr, then findMissingKeys might have reported a key to be missing even though the blob\n+        // was uploaded to ABS. This can happen, if previously, the upload to ABS succeeded but the upload couldn't make\n+        // it to cosmos.\n         throw new StoreException(String.format(\"Another blob with same key %s exists in store\", blobId.getID()),\n             StoreErrorCodes.Already_Exist);\n       }\n     } else {\n       vcrMetrics.blobUploadSkippedCount.inc();", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4MzE2OA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431483168", "bodyText": "I guess this (line 307) is the else case for shouldUpload() check. So should be fine.", "author": "ankagrawal", "createdAt": "2020-05-27T22:41:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1MjgyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NDYxOQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430854619", "bodyText": "Let's avoid mentioning Azure stuff in this class.  The logic should be independent anyway.", "author": "lightningrob", "createdAt": "2020-05-27T04:47:17Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -522,12 +530,20 @@ private void validateAccountAndContainer(Map<String, CloudBlobMetadata> cloudBlo\n    * @param metadata existing {@link CloudBlobMetadata} in cloud.\n    * @param key {@link StoreKey} being deleted.\n    * @param updateFields {@link Map} of fields and values being updated.\n+   * @return false only for vcr if local cloud destination life version is more recent. true if validation successful.\n    * @throws StoreException if validation fails.\n    */\n-  private void preDeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n+  private boolean preDeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n       throws StoreException {\n     validateAccountAndContainer(Collections.singletonMap(metadata.getId(), metadata), Collections.singletonList(key));\n     short requestedLifeVersion = (short) updateFields.get(FIELD_LIFE_VERSION);\n+    if (isVcr) {\n+      // This is a delete request from vcr. Apply delete only if incoming life version is more recent. Don't throw any\n+      // exception because replication relies on findMissingKeys which in turn relies on cosmos state for CloudBlobStore.\n+      // Cosmos could be missing some updates that were applied to ABS.", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4ODg4MA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431488880", "bodyText": "ok.", "author": "ankagrawal", "createdAt": "2020-05-27T22:57:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NDYxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NTEzOA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430855138", "bodyText": "Remove Cosmos/ABS mentions", "author": "lightningrob", "createdAt": "2020-05-27T04:49:34Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -554,12 +563,19 @@ private void preDeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<S\n    * @param metadata existing {@link CloudBlobMetadata} in cloud.\n    * @param key {@link StoreKey} being updated.\n    * @param updateFields {@link Map} of fields and values being updated.\n+   * @return false only for vcr if ttl is already applied on blob. true in all other cases if validation is successful.\n    * @throws StoreException if validation fails.\n    */\n-  private void preTtlUpdateValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n+  private boolean preTtlUpdateValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n       throws StoreException {\n     validateAccountAndContainer(Collections.singletonMap(metadata.getId(), metadata), Collections.singletonList(key));\n     long now = System.currentTimeMillis();\n+    if (isVcr) {\n+      // For vcr don't update ttl if already updated. Don't throw any exception because replication relies on\n+      // findMissingKeys which in turn relies on cosmos state for CloudBlobStore. Cosmos could be missing some updates", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4ODkxOA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431488918", "bodyText": "ok", "author": "ankagrawal", "createdAt": "2020-05-27T22:57:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NTEzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NTYyOQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430855629", "bodyText": "Same here.", "author": "lightningrob", "createdAt": "2020-05-27T04:51:42Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -579,10 +596,16 @@ private void preTtlUpdateValidation(CloudBlobMetadata metadata, StoreKey key, Ma\n    * @param updateFields {@link Map} of fields and values being updated.\n    * @throws StoreException if validation fails.\n    */\n-  private void preUndeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n+  private boolean preUndeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n       throws StoreException {\n     validateAccountAndContainer(Collections.singletonMap(metadata.getId(), metadata), Collections.singletonList(key));\n     short requestedLifeVersion = (short) updateFields.get(FIELD_LIFE_VERSION);\n+    if (isVcr) {\n+      // This is an undelete request from vcr. Apply undelete only if incoming life version is more recent. Don't throw\n+      // any exception because replication relies on findMissingKeys which in turn relies on cosmos state for CloudBlobStore.\n+      // Cosmos could be missing some updates that were applied to ABS.", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4ODk4OA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431488988", "bodyText": "ok", "author": "ankagrawal", "createdAt": "2020-05-27T22:57:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NTYyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NjA4OA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430856088", "bodyText": "Add @return javadoc", "author": "lightningrob", "createdAt": "2020-05-27T04:53:31Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -579,10 +596,16 @@ private void preTtlUpdateValidation(CloudBlobMetadata metadata, StoreKey key, Ma\n    * @param updateFields {@link Map} of fields and values being updated.\n    * @throws StoreException if validation fails.\n    */\n-  private void preUndeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n+  private boolean preUndeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4ODk1OA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431488958", "bodyText": "ok", "author": "ankagrawal", "createdAt": "2020-05-27T22:57:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NjA4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NzYyOQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430857629", "bodyText": "I don't understand this logic.  What about the case where we have reset the replica tokens but not deleted the blob store?  The put needs to be idempotent for VCR.", "author": "lightningrob", "createdAt": "2020-05-27T05:00:07Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -295,15 +295,23 @@ private void putBlob(MessageInfo messageInfo, ByteBuffer messageBuf, long size)\n                 \"Upload\", partitionId.toPathString());\n       }\n       addToCache(blobId.getID(), (short) 0, BlobState.CREATED);\n-      if (!uploaded) {\n+      if (!uploaded && !isVcr) {\n+        // If put is coming from frontend, then uploadBlob must be true. Its not acceptable that a blob already exists.\n+        // If put is coming from vcr, then findMissingKeys might have reported a key to be missing even though the blob\n+        // was uploaded to ABS. This can happen, if previously, the upload to ABS succeeded but the upload couldn't make\n+        // it to cosmos.\n         throw new StoreException(String.format(\"Another blob with same key %s exists in store\", blobId.getID()),\n             StoreErrorCodes.Already_Exist);\n       }\n     } else {\n       vcrMetrics.blobUploadSkippedCount.inc();\n-      throw new CloudStorageException(\"Error updating blob metadata\", new StoreException(\n-          String.format(\"Another blob with same key %s exists in store\", messageInfo.getStoreKey().getID()),\n-          StoreErrorCodes.Already_Exist));\n+      // The only case where its ok to see a put request for a already seen blob is, during replication if the blob is\n+      // expiring within {@link CloudConfig#vcrMinTtlDays} for vcr to upload.\n+      if (isVcr && !isExpiringSoon(messageInfo)) {", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4ODY1OQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431488659", "bodyText": "I guess one way to look at this is that for vcr (replication), put happens when ReplicaThread has made the determination that this blob is not present locally by calling the CloudBlobStore::findMissingKeys(). So in case where we have reset the replica tokens but not deleted the blob store, a call to findMissingKeys should say that this blob is indeed present, and Replica Thread should not attempt a put() for this blob.\nLet me know if I am missing something here.", "author": "ankagrawal", "createdAt": "2020-05-27T22:56:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NzYyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIxMzYzNg==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r434213636", "bodyText": "Okay, you may be right.", "author": "lightningrob", "createdAt": "2020-06-02T22:39:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1NzYyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1ODkyNA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r430858924", "bodyText": "Rephrase as:\n@return true if the operation can proceed, or false if it is not needed (e.g. cloud state is more recent).\nThe exception part is implicit.", "author": "lightningrob", "createdAt": "2020-05-27T05:05:21Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudUpdateValidator.java", "diffHunk": "@@ -23,12 +23,15 @@\n  */\n public interface CloudUpdateValidator {\n   /**\n-   * Validate operation on {@link CloudBlobMetadata} in cloud destination for the operation on blob with\n-   * given {@link StoreKey} and new requested life version.\n+   * Validate the sanity of update operation on given {@code updateFields} against existing {@link CloudBlobMetadata} in\n+   * cloud destination for the blob with key {@code key}. This can be used to hook Ambry store related validation logic\n+   * during {@link CloudDestination} specific get-check-update flow.\n    * @param metadata {@link CloudBlobMetadata} object obtained from cloud destination.\n    * @param key {@link StoreKey} of the blob being updated.\n    * @param updateFields {@link Map} of fields and new values requested for update.\n+   * @return if no exception needs to thrown, return false if the operation is not needed (maybe cloud state is more\n+   * recent). true otherwise.", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTQ4OTA3NA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431489074", "bodyText": "ok", "author": "ankagrawal", "createdAt": "2020-05-27T22:58:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDg1ODkyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYwODc2Nw==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431608767", "bodyText": "could you simplify the lambda to this::preUndeleteValidation? Same in other places where this method is used.", "author": "cgtz", "createdAt": "2020-05-28T06:29:37Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -419,32 +417,34 @@ public short undelete(MessageInfo info) throws StoreException {\n    * @throws CloudStorageException in case any exception happens during undelete.\n    */\n   private short undeleteIfNeeded(BlobId blobId, short lifeVersion) throws CloudStorageException {\n-    // TODO: Currently this is implemented for undeletes via replication only for DR.\n     // See note in deleteIfNeeded.\n     if (!checkCacheState(blobId.getID(), lifeVersion, BlobState.CREATED)) {\n-      short newLifeVersion = cloudDestination.undeleteBlob(blobId, lifeVersion);\n+      short newLifeVersion = cloudDestination.undeleteBlob(blobId, lifeVersion,\n+          (metadata, key, updateFields) -> preUndeleteValidation(metadata, key, updateFields));", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM5NzI3NQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r433397275", "bodyText": "done.", "author": "ankagrawal", "createdAt": "2020-06-01T18:00:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYwODc2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMjIxNA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431612214", "bodyText": "does undelete change the operation time?", "author": "cgtz", "createdAt": "2020-05-28T06:38:30Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -469,17 +469,171 @@ public void updateTtl(List<MessageInfo> infos) throws StoreException {\n   private boolean updateTtlIfNeeded(BlobId blobId) throws CloudStorageException {\n     String blobKey = blobId.getID();\n     // See note in deleteIfNeeded.\n-    if (!checkCacheState(blobKey, BlobState.TTL_UPDATED, BlobState.DELETED)) {\n-      boolean updated = cloudDestination.updateBlobExpiration(blobId, Utils.Infinite_Time);\n-      // We do not have the definitive value of life version here. So we add to cache with minimum valid value.\n-      // If the key is present in cache, then correct life version will be updated. (see method {@link addToCache}).\n-      // If not then in worst case, the cache might let some operations with higher life version go through again.\n-      addToCache(blobKey, (short) 0, BlobState.TTL_UPDATED);\n-      return updated;\n+    if (!checkCacheState(blobKey, BlobState.TTL_UPDATED)) {\n+      short lifeVersion = cloudDestination.updateBlobExpiration(blobId, Utils.Infinite_Time,\n+          (metadata, key, updateFields) -> preTtlUpdateValidation(metadata, key, updateFields));\n+      addToCache(blobKey, lifeVersion, BlobState.TTL_UPDATED);\n+      return (lifeVersion != -1);\n     }\n     return false;\n   }\n \n+  /**\n+   * Validate {@link CloudBlobMetadata} map to make sure it has metadata for all keys, and they meet the {@code storeGetOptions} requirements.\n+   * @param cloudBlobMetadataMap {@link CloudBlobMetadata} map.\n+   * @param storeGetOptions {@link StoreGetOptions} requirements.\n+   * @param currentTimestamp current time stamp.\n+   * @throws StoreException if the {@code CloudBlobMetadata} isnt valid\n+   */\n+  private void validateCloudMetadata(Map<String, CloudBlobMetadata> cloudBlobMetadataMap,\n+      EnumSet<StoreGetOptions> storeGetOptions, long currentTimestamp, List<? extends StoreKey> ids)\n+      throws StoreException {\n+    for (String key : cloudBlobMetadataMap.keySet()) {\n+      if (isBlobDeleted(cloudBlobMetadataMap.get(key)) && !storeGetOptions.contains(\n+          StoreGetOptions.Store_Include_Deleted)) {\n+        throw new StoreException(\"Id \" + key + \" has been deleted on the cloud\", StoreErrorCodes.ID_Deleted);\n+      }\n+      if (isBlobExpired(cloudBlobMetadataMap.get(key), currentTimestamp) && !storeGetOptions.contains(\n+          StoreGetOptions.Store_Include_Expired)) {\n+        throw new StoreException(\"Id \" + key + \" has expired on the cloud\", StoreErrorCodes.TTL_Expired);\n+      }\n+    }\n+    validateAccountAndContainer(cloudBlobMetadataMap, ids);\n+  }\n+\n+  /**\n+   * Validate account id and container id for blobs in {@link CloudBlobMetadata} map match those in {@link StoreKey} list.\n+   * @param cloudBlobMetadataMap {@link Map} of {@link CloudBlobMetadata}.\n+   * @param storeKeys {@link List} of {@link StoreKey}s.\n+   */\n+  private void validateAccountAndContainer(Map<String, CloudBlobMetadata> cloudBlobMetadataMap,\n+      List<? extends StoreKey> storeKeys) throws StoreException {\n+    for (StoreKey key : storeKeys) {\n+      CloudBlobMetadata cloudBlobMetadata = cloudBlobMetadataMap.get(key.getID());\n+      // validate accountId and containerId\n+      if (!key.isAccountContainerMatch((short) cloudBlobMetadata.getAccountId(),\n+          (short) cloudBlobMetadata.getContainerId())) {\n+        if (storeConfig.storeValidateAuthorization) {\n+          throw new StoreException(\"GET authorization failure. Key: \" + key.getID() + \" Actual accountId: \"\n+              + cloudBlobMetadata.getAccountId() + \" Actual containerId: \" + cloudBlobMetadata.getAccountId(),\n+              StoreErrorCodes.Authorization_Failure);\n+        } else {\n+          logger.warn(\"GET authorization failure. Key: {} Actually accountId: {} Actually containerId: {}\", key.getID(),\n+              cloudBlobMetadata.getAccountId(), cloudBlobMetadata.getContainerId());\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Validates existing metadata in cloud destination against requested update for delete.\n+   * @param metadata existing {@link CloudBlobMetadata} in cloud.\n+   * @param key {@link StoreKey} being deleted.\n+   * @param updateFields {@link Map} of fields and values being updated.\n+   * @return false only for vcr if local cloud destination life version is more recent. true if validation successful.\n+   * @throws StoreException if validation fails.\n+   */\n+  private boolean preDeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n+      throws StoreException {\n+    validateAccountAndContainer(Collections.singletonMap(metadata.getId(), metadata), Collections.singletonList(key));\n+    short requestedLifeVersion = (short) updateFields.get(FIELD_LIFE_VERSION);\n+    if (isVcr) {\n+      // This is a delete request from vcr. Apply delete only if incoming life version is more recent. Don't throw any\n+      // exception because replication relies on findMissingKeys which in turn relies on cosmos state for CloudBlobStore.\n+      // Cosmos could be missing some updates that were applied to ABS.\n+      return (!metadata.isDeleted() || metadata.getLifeVersion() < requestedLifeVersion) && (metadata.getLifeVersion()\n+          <= requestedLifeVersion);\n+    }\n+    if (requestedLifeVersion == MessageInfo.LIFE_VERSION_FROM_FRONTEND) {\n+      // This is a delete request from frontend\n+      if (metadata.isDeleted()) {\n+        throw new StoreException(\n+            \"Cannot delete id \" + metadata.getId() + \" since it is already marked as deleted in cloud.\",\n+            StoreErrorCodes.ID_Deleted);\n+      }\n+      // this is delete request from frontend, we use life version only for validation.\n+      updateFields.remove(FIELD_LIFE_VERSION);\n+    }\n+    return true;\n+  }\n+\n+  /**\n+   * Validates existing metadata in cloud destination against requested update for ttl.\n+   * Note that this method also has an unclean side effect of updating the {@code updateFields}.\n+   * @param metadata existing {@link CloudBlobMetadata} in cloud.\n+   * @param key {@link StoreKey} being updated.\n+   * @param updateFields {@link Map} of fields and values being updated.\n+   * @return false only for vcr if ttl is already applied on blob. true in all other cases if validation is successful.\n+   * @throws StoreException if validation fails.\n+   */\n+  private boolean preTtlUpdateValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n+      throws StoreException {\n+    validateAccountAndContainer(Collections.singletonMap(metadata.getId(), metadata), Collections.singletonList(key));\n+    long now = System.currentTimeMillis();\n+    if (isVcr) {\n+      // For vcr don't update ttl if already updated. Don't throw any exception because replication relies on\n+      // findMissingKeys which in turn relies on cosmos state for CloudBlobStore. Cosmos could be missing some updates\n+      // that were applied to ABS.\n+      return metadata.getExpirationTime() != Utils.Infinite_Time;\n+    }\n+    if (metadata.isDeleted()) {\n+      throw new StoreException(\"Cannot update TTL of \" + key.getID() + \" since it is already deleted in the index.\",\n+          StoreErrorCodes.ID_Deleted);\n+    } else if (metadata.getExpirationTime() != Utils.Infinite_Time\n+        && metadata.getExpirationTime() < now + ttlUpdateBufferTimeMs) {\n+      throw new StoreException(\n+          \"TTL of \" + key.getID() + \" cannot be updated because it is too close to expiry. Minimum Op time (ms): \" + now\n+              + \". ExpiresAtMs: \" + metadata.getExpirationTime(), StoreErrorCodes.Update_Not_Allowed);\n+    }\n+    return true;\n+  }\n+\n+  /**\n+   * Validates existing metadata in cloud destination against requested undelete.\n+   * Note that this method also has an unclean side effect of updating the {@code updateFields}.\n+   * @param metadata existing {@link CloudBlobMetadata} in cloud.\n+   * @param key {@link StoreKey} being updated.\n+   * @param updateFields {@link Map} of fields and values being updated.\n+   * @throws StoreException if validation fails.\n+   */\n+  private boolean preUndeleteValidation(CloudBlobMetadata metadata, StoreKey key, Map<String, Object> updateFields)\n+      throws StoreException {\n+    validateAccountAndContainer(Collections.singletonMap(metadata.getId(), metadata), Collections.singletonList(key));\n+    short requestedLifeVersion = (short) updateFields.get(FIELD_LIFE_VERSION);\n+    if (isVcr) {\n+      // This is an undelete request from vcr. Apply undelete only if incoming life version is more recent. Don't throw\n+      // any exception because replication relies on findMissingKeys which in turn relies on cosmos state for CloudBlobStore.\n+      // Cosmos could be missing some updates that were applied to ABS.\n+      return metadata.getLifeVersion() < requestedLifeVersion;\n+    }\n+    if (metadata.isExpired()) {\n+      throw new StoreException(\"Id \" + key + \" already expired in cloud \", StoreErrorCodes.TTL_Expired);\n+    } else if (metadata.isUndeleted()) {\n+      throw new StoreException(\"Id \" + key + \" is already undeleted in cloud\", StoreErrorCodes.ID_Undeleted);\n+    } else if (!metadata.isDeleted()) {\n+      throw new StoreException(\"Id \" + key + \" is not deleted yet in cloud \", StoreErrorCodes.ID_Not_Deleted);\n+    } else if (metadata.getDeletionTime() + TimeUnit.DAYS.toMillis(storeConfig.storeDeletedMessageRetentionDays)\n+        < System.currentTimeMillis()) {\n+      throw new StoreException(\"Id \" + key + \" already permanently deleted in cloud \",\n+          StoreErrorCodes.ID_Deleted_Permanently);\n+    }\n+    // Update life version to appropriate value for frontend requests.\n+    updateFields.put(FIELD_LIFE_VERSION, metadata.getLifeVersion() + 1);\n+    return true;\n+  }\n+\n+  /**\n+   * Gets the operation time for a blob from blob metadata based on the blob's current state and timestamp recorded for that state.\n+   * @param metadata blob metadata from which to derive operation time.\n+   * @return operation time.\n+   */\n+  private long getOperationTime(CloudBlobMetadata metadata) {\n+    if (isBlobDeleted(metadata)) {\n+      return metadata.getDeletionTime();\n+    }\n+    return (metadata.getCreationTime() == Utils.Infinite_Time) ? metadata.getUploadTime() : metadata.getCreationTime();", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzQwNDgzNQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r433404835", "bodyText": "The operation time in cosmos is represented by system _ts field, which is always updated by cosmos on any update.", "author": "ankagrawal", "createdAt": "2020-06-01T18:15:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxMjIxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxNDI3NQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431614275", "bodyText": "why is this clause added? seems like it is immediately rethrowing the same exc.", "author": "cgtz", "createdAt": "2020-05-28T06:43:48Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -811,6 +990,8 @@ public void appendFrom(ReadableByteChannel channel, long size) throws StoreExcep\n         messageBuf.flip();\n         cloudBlobStore.putBlob(messageInfo, messageBuf, size);\n         messageIndex++;\n+      } catch (StoreException se) {", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzQwNTAwNA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r433405004", "bodyText": "true. Removed it.", "author": "ankagrawal", "createdAt": "2020-06-01T18:15:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxNDI3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxNDU5OA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431614598", "bodyText": "note that  the validator may change fields within this map.", "author": "cgtz", "createdAt": "2020-05-28T06:44:33Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudUpdateValidator.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.github.ambry.store.StoreException;\n+import com.github.ambry.store.StoreKey;\n+import java.util.Map;\n+\n+\n+/**\n+ * Interface for Ambry validation logic for updates requested from cloud destination.\n+ */\n+public interface CloudUpdateValidator {\n+  /**\n+   * Validate the sanity of update operation on given {@code updateFields} against existing {@link CloudBlobMetadata} in\n+   * cloud destination for the blob with key {@code key}. This can be used to hook Ambry store related validation logic\n+   * during {@link CloudDestination} specific get-check-update flow.\n+   * @param metadata {@link CloudBlobMetadata} object obtained from cloud destination.\n+   * @param key {@link StoreKey} of the blob being updated.\n+   * @param updateFields {@link Map} of fields and new values requested for update.", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzQwNjI4MQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r433406281", "bodyText": "done.", "author": "ankagrawal", "createdAt": "2020-06-01T18:18:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxNDU5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxNzE0Ng==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431617146", "bodyText": "What is the case where a StoreException gets here? Is this when the CloudUpdateValidator throws?", "author": "cgtz", "createdAt": "2020-05-28T06:50:52Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureCloudDestination.java", "diffHunk": "@@ -473,7 +483,7 @@ private CloudStorageException toCloudStorageException(String message, Exception\n       statusCode = StatusCodes.INTERNAL_SERVER_ERROR;\n     }\n     // Everything is retryable except NOT_FOUND\n-    boolean isRetryable = (statusCode != StatusCodes.NOTFOUND);\n+    boolean isRetryable = (statusCode != StatusCodes.NOTFOUND && !(e instanceof StoreException));", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzQ0NTE3Mg==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r433445172", "bodyText": "yes.", "author": "ankagrawal", "createdAt": "2020-06-01T19:34:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYxNzE0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYyMDM1OQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431620359", "bodyText": "It seems like the code will now throw in this case. Is there a reason for the change?", "author": "cgtz", "createdAt": "2020-05-28T06:57:52Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureCloudDestination.java", "diffHunk": "@@ -293,21 +306,18 @@ private boolean updateBlobMetadata(BlobId blobId, Map<String, Object> updateFiel\n           // attempt fails.  So we check for that case here.\n           CloudBlobMetadata cosmosMetadata = cosmosDataAccessor.getMetadataOrNull(blobId);\n           if (cosmosMetadata != null) {\n-            if (cosmosMetadata.isDeletedOrExpired()) {\n+            if (cosmosMetadata.isCompactionCandidate(\n+                TimeUnit.HOURS.toMillis(cloudConfig.cloudBlobCompactionIntervalHours))) {\n               logger.warn(\"Inconsistency: Cosmos contains record for inactive blob {}, removing it.\", blobId.getID());\n               cosmosDataAccessor.deleteMetadata(cosmosMetadata);\n               azureMetrics.blobUpdateRecoverCount.inc();", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzQxNjE4NQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r433416185", "bodyText": "A blob that is compacted away is as good as NOT_FOUND for all purposes. So if there is inconsistency between ABS and cosmos, and we know that the inconsistency is due to compaction failure (the blob in cosmos should have been compacted away, but its not) then we fix the inconsistency. But we must throw an exception anyways, both for replication(vcr) and frontend.\nFor frontend, this is as good as blob is not found.\nFor replication, it could have happened that the ReplicaThread might have thought that this blob is present locally as findMissingKeys would have reported present (since findMissingKeys refers to only cosmos). But actually the blob is not present. If we don't throw an exception, then ReplicaThread will not retry the operation in next replicate loop. Its important for this operation to be retried, now that we support lifeVersion and undelete operation. Its possible that the blob was deleted and then undeleted, but due to replication lag that undelete couldn't make it to cloud before the deleted blob was compacted away.\nLet me know if logic sounds reasonable to you.", "author": "ankagrawal", "createdAt": "2020-06-01T18:37:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYyMDM1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIyMzM5MQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r434223391", "bodyText": "Thanks for the explanation. I think that makes sense", "author": "cgtz", "createdAt": "2020-06-02T23:09:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYyMDM1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYyMDcxMg==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r431620712", "bodyText": "unused import?", "author": "cgtz", "createdAt": "2020-05-28T06:58:35Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudStorageManager.java", "diffHunk": "@@ -16,6 +16,7 @@\n import com.github.ambry.clustermap.ClusterMap;\n import com.github.ambry.clustermap.PartitionId;\n import com.github.ambry.clustermap.ReplicaId;\n+import com.github.ambry.config.StoreConfig;", "originalCommit": "fb47a16339867695075be0f6b421a59bba8c95df", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzQwNTIyOA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r433405228", "bodyText": "fixed.", "author": "ankagrawal", "createdAt": "2020-06-01T18:16:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTYyMDcxMg=="}], "type": "inlineReview"}, {"oid": "e9e7105d292e1d7de29ec52220f044f8fad837f0", "url": "https://github.com/linkedin/ambry/commit/e9e7105d292e1d7de29ec52220f044f8fad837f0", "message": "Fix cloudblobstore tests.", "committedDate": "2020-06-02T19:39:02Z", "type": "forcePushed"}, {"oid": "d28f668503e739abb7588b21f8bb1b38990249d3", "url": "https://github.com/linkedin/ambry/commit/d28f668503e739abb7588b21f8bb1b38990249d3", "message": "Change the CloudBlobStore to make it compatible with BlobStore and make it ready for serving reqeusts.", "committedDate": "2020-06-05T03:23:37Z", "type": "commit"}, {"oid": "b827babba0d3470b3e22a5195750510058c5868d", "url": "https://github.com/linkedin/ambry/commit/b827babba0d3470b3e22a5195750510058c5868d", "message": "Update license", "committedDate": "2020-06-05T03:23:46Z", "type": "commit"}, {"oid": "976566752a52ec49009092e8499456c7e80e3a9e", "url": "https://github.com/linkedin/ambry/commit/976566752a52ec49009092e8499456c7e80e3a9e", "message": "Fix tests.", "committedDate": "2020-06-05T03:23:47Z", "type": "commit"}, {"oid": "44ffacf4349cfe6f61aa3351b1b04b82033050bf", "url": "https://github.com/linkedin/ambry/commit/44ffacf4349cfe6f61aa3351b1b04b82033050bf", "message": "Address review comments.", "committedDate": "2020-06-05T03:23:47Z", "type": "commit"}, {"oid": "4eefe8263c0ec609c5cc20143a1568a1482f0657", "url": "https://github.com/linkedin/ambry/commit/4eefe8263c0ec609c5cc20143a1568a1482f0657", "message": "Fix review comments.", "committedDate": "2020-06-05T03:23:47Z", "type": "commit"}, {"oid": "873d2ab09a2ed79f140f33f13da9680cb8cf960e", "url": "https://github.com/linkedin/ambry/commit/873d2ab09a2ed79f140f33f13da9680cb8cf960e", "message": "Update test", "committedDate": "2020-06-05T03:23:47Z", "type": "commit"}, {"oid": "13f48449ead375865376458a29f6f6e2bb68c862", "url": "https://github.com/linkedin/ambry/commit/13f48449ead375865376458a29f6f6e2bb68c862", "message": "Fix tests", "committedDate": "2020-06-05T03:23:47Z", "type": "commit"}, {"oid": "bde000b7feaabb1892c878f9944ce2c14c0f1358", "url": "https://github.com/linkedin/ambry/commit/bde000b7feaabb1892c878f9944ce2c14c0f1358", "message": "Fix cloudblobstore tests.", "committedDate": "2020-06-05T03:23:47Z", "type": "commit"}, {"oid": "da55bac18bcdd1b274e37e03e8631834fa375962", "url": "https://github.com/linkedin/ambry/commit/da55bac18bcdd1b274e37e03e8631834fa375962", "message": "cleanup", "committedDate": "2020-06-05T03:23:47Z", "type": "commit"}, {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb", "url": "https://github.com/linkedin/ambry/commit/43ddd899be3828bc01b2c6e5635e5991f51951bb", "message": "Add integration test for cloudblob store. Also add more test cases and fix minor bugs.", "committedDate": "2020-06-05T03:23:47Z", "type": "commit"}, {"oid": "43ddd899be3828bc01b2c6e5635e5991f51951bb", "url": "https://github.com/linkedin/ambry/commit/43ddd899be3828bc01b2c6e5635e5991f51951bb", "message": "Add integration test for cloudblob store. Also add more test cases and fix minor bugs.", "committedDate": "2020-06-05T03:23:47Z", "type": "forcePushed"}, {"oid": "89a230c8e53fdb485db7a7cc3745f14855828058", "url": "https://github.com/linkedin/ambry/commit/89a230c8e53fdb485db7a7cc3745f14855828058", "message": "Ignore AzureIntegrationTest", "committedDate": "2020-06-05T03:31:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyNTIxNQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r435725215", "bodyText": "This doesn't make sense, you can't expect the method to return false and throw an exception.", "author": "lightningrob", "createdAt": "2020-06-05T06:58:16Z", "path": "ambry-cloud/src/test/java/com/github/ambry/cloud/azure/AzureIntegrationTest.java", "diffHunk": "@@ -502,8 +502,12 @@ public void testRepairAfterIncompleteCompaction() throws Exception {\n     azureDest.getAzureBlobDataAccessor().purgeBlobs(Collections.singletonList(cloudBlobMetadata));\n \n     // Try to delete again (to trigger recovery), verify removed from Cosmos\n-    assertFalse(\"Expected delete to return false\",\n-        azureDest.deleteBlob(blobId, deletionTime, (short) 0, dummyCloudUpdateValidator));\n+    try {\n+      assertFalse(\"Expected delete to return false\",\n+          azureDest.deleteBlob(blobId, deletionTime, (short) 0, dummyCloudUpdateValidator));\n+    } catch (CloudStorageException cex) {\n+      assertEquals(\"Unexpected error code\", HttpConstants.StatusCodes.NOTFOUND, cex.getStatusCode());", "originalCommit": "43ddd899be3828bc01b2c6e5635e5991f51951bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE3MTQ0OQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436171449", "bodyText": "fixed.", "author": "ankagrawal", "createdAt": "2020-06-05T21:26:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyNTIxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyNTc4OA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r435725788", "bodyText": "The methods in this class seem unrelated to anything cloud.", "author": "lightningrob", "createdAt": "2020-06-05T06:59:52Z", "path": "ambry-cloud/src/test/java/com/github/ambry/cloud/CloudTestUtil.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/**\n+ * Copyright 2019 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.commons.BlobId;\n+import com.github.ambry.store.MessageInfo;\n+import com.github.ambry.store.MockMessageWriteSet;\n+import com.github.ambry.utils.TestUtils;\n+import java.nio.ByteBuffer;\n+import java.util.Random;\n+\n+import static com.github.ambry.commons.BlobId.*;\n+\n+\n+public class CloudTestUtil {", "originalCommit": "43ddd899be3828bc01b2c6e5635e5991f51951bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTcyNjcxNg==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r435726716", "bodyText": "Cool, thanks for adding this.", "author": "lightningrob", "createdAt": "2020-06-05T07:02:15Z", "path": "ambry-cloud/src/test/java/com/github/ambry/cloud/CloudBlobStoreIntegrationTest.java", "diffHunk": "@@ -0,0 +1,515 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.cloud.azure.AzureCloudConfig;\n+import com.github.ambry.cloud.azure.AzureMetrics;\n+import com.github.ambry.clustermap.ClusterMap;\n+import com.github.ambry.clustermap.MockClusterMap;\n+import com.github.ambry.clustermap.MockDataNodeId;\n+import com.github.ambry.clustermap.Partition;\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.PartitionState;\n+import com.github.ambry.config.CloudConfig;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.config.VerifiableProperties;\n+import com.github.ambry.network.Port;\n+import com.github.ambry.network.PortType;\n+import com.github.ambry.store.MessageInfo;\n+import com.github.ambry.store.MockMessageWriteSet;\n+import com.github.ambry.store.StoreErrorCodes;\n+import com.github.ambry.store.StoreException;\n+import com.github.ambry.store.StoreGetOptions;\n+import com.github.ambry.store.StoreInfo;\n+import com.github.ambry.utils.Utils;\n+import com.microsoft.azure.cosmosdb.ConnectionPolicy;\n+import com.microsoft.azure.cosmosdb.ConsistencyLevel;\n+import com.microsoft.azure.cosmosdb.Document;\n+import com.microsoft.azure.cosmosdb.FeedOptions;\n+import com.microsoft.azure.cosmosdb.FeedResponse;\n+import com.microsoft.azure.cosmosdb.PartitionKey;\n+import com.microsoft.azure.cosmosdb.RequestOptions;\n+import com.microsoft.azure.cosmosdb.SqlQuerySpec;\n+import com.microsoft.azure.cosmosdb.rx.AsyncDocumentClient;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.Random;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import static com.github.ambry.cloud.CloudTestUtil.*;\n+import static org.junit.Assert.*;\n+\n+\n+/**\n+ * Integration Test cases for {@link CloudBlobStore}\n+ * Must supply file azure-test.properties in classpath with valid config property values.\n+ */\n+//@Ignore\n+@RunWith(Parameterized.class)\n+public class CloudBlobStoreIntegrationTest {", "originalCommit": "43ddd899be3828bc01b2c6e5635e5991f51951bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA1OTM4Mg==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436059382", "bodyText": "Is it possible that is has been deleted in the cloud but didn't go through this vcr so the cache entry is stale?", "author": "lightningrob", "createdAt": "2020-06-05T17:24:39Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/CloudBlobStore.java", "diffHunk": "@@ -416,16 +416,21 @@ public short undelete(MessageInfo info) throws StoreException {\n    * @param lifeVersion life version of the deleted blob.\n    * @return final updated life version of the blob.\n    * @throws CloudStorageException in case any exception happens during undelete.\n+   * @throws StoreException in case any {@link StoreException} is thrown.\n    */\n-  private short undeleteIfNeeded(BlobId blobId, short lifeVersion) throws CloudStorageException {\n+  private short undeleteIfNeeded(BlobId blobId, short lifeVersion) throws CloudStorageException, StoreException {\n     // See note in deleteIfNeeded.\n     if (!checkCacheState(blobId.getID(), lifeVersion, BlobState.CREATED)) {\n       short newLifeVersion = cloudDestination.undeleteBlob(blobId, lifeVersion, this::preUndeleteValidation);\n       addToCache(blobId.getID(), newLifeVersion, BlobState.CREATED);\n       return newLifeVersion;\n     } else {\n-      throw new CloudStorageException(\"Error updating blob metadata\",\n-          new StoreException(\"Id \" + blobId.getID() + \" is already undeleted in cloud\", StoreErrorCodes.ID_Undeleted));\n+      if (lifeVersion > 0) {\n+        throw new StoreException(\"Id \" + blobId.getID() + \" is already undeleted in cloud\",\n+            StoreErrorCodes.ID_Undeleted);\n+      } else {\n+        throw new StoreException(\"Id \" + blobId.getID() + \" not deleted yet in cloud\", StoreErrorCodes.ID_Not_Deleted);", "originalCommit": "43ddd899be3828bc01b2c6e5635e5991f51951bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjExODE3Mg==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436118172", "bodyText": "Yes this is correct. We cannot make a determination that a blob was never deleted just by looking at cache. Fixed it and the corresponding test as well.", "author": "ankagrawal", "createdAt": "2020-06-05T19:20:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA1OTM4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2MDQ3Mw==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436060473", "bodyText": "I think you can use Map.getOrDefault() here.", "author": "lightningrob", "createdAt": "2020-06-05T17:26:47Z", "path": "ambry-cloud/src/main/java/com/github/ambry/cloud/azure/AzureCloudDestination.java", "diffHunk": "@@ -195,8 +195,8 @@ public short undeleteBlob(BlobId blobId, short lifeVersion, CloudUpdateValidator\n     updateFields.put(CloudBlobMetadata.FIELD_LIFE_VERSION, lifeVersion);\n     updateFields.put(CloudBlobMetadata.FIELD_DELETION_TIME, Utils.Infinite_Time);\n     UpdateResponse updateResponse = updateBlobMetadata(blobId, updateFields, cloudUpdateValidator);\n-    return updateResponse.metadata.containsKey(CloudBlobMetadata.FIELD_LIFE_VERSION) ? 0\n-        : Short.parseShort(updateResponse.metadata.get(CloudBlobMetadata.FIELD_LIFE_VERSION));\n+    return updateResponse.metadata.containsKey(CloudBlobMetadata.FIELD_LIFE_VERSION) ? Short.parseShort(\n+        updateResponse.metadata.get(CloudBlobMetadata.FIELD_LIFE_VERSION)) : 0;", "originalCommit": "43ddd899be3828bc01b2c6e5635e5991f51951bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjEyMDUzMQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436120531", "bodyText": "fixed.", "author": "ankagrawal", "createdAt": "2020-06-05T19:26:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2MDQ3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2MTgwMA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436061800", "bodyText": "Comment doesn't seem to match code.", "author": "lightningrob", "createdAt": "2020-06-05T17:29:21Z", "path": "ambry-cloud/src/test/java/com/github/ambry/cloud/CloudBlobStoreIntegrationTest.java", "diffHunk": "@@ -0,0 +1,515 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.cloud.azure.AzureCloudConfig;\n+import com.github.ambry.cloud.azure.AzureMetrics;\n+import com.github.ambry.clustermap.ClusterMap;\n+import com.github.ambry.clustermap.MockClusterMap;\n+import com.github.ambry.clustermap.MockDataNodeId;\n+import com.github.ambry.clustermap.Partition;\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.PartitionState;\n+import com.github.ambry.config.CloudConfig;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.config.VerifiableProperties;\n+import com.github.ambry.network.Port;\n+import com.github.ambry.network.PortType;\n+import com.github.ambry.store.MessageInfo;\n+import com.github.ambry.store.MockMessageWriteSet;\n+import com.github.ambry.store.StoreErrorCodes;\n+import com.github.ambry.store.StoreException;\n+import com.github.ambry.store.StoreGetOptions;\n+import com.github.ambry.store.StoreInfo;\n+import com.github.ambry.utils.Utils;\n+import com.microsoft.azure.cosmosdb.ConnectionPolicy;\n+import com.microsoft.azure.cosmosdb.ConsistencyLevel;\n+import com.microsoft.azure.cosmosdb.Document;\n+import com.microsoft.azure.cosmosdb.FeedOptions;\n+import com.microsoft.azure.cosmosdb.FeedResponse;\n+import com.microsoft.azure.cosmosdb.PartitionKey;\n+import com.microsoft.azure.cosmosdb.RequestOptions;\n+import com.microsoft.azure.cosmosdb.SqlQuerySpec;\n+import com.microsoft.azure.cosmosdb.rx.AsyncDocumentClient;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.Random;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import static com.github.ambry.cloud.CloudTestUtil.*;\n+import static org.junit.Assert.*;\n+\n+\n+/**\n+ * Integration Test cases for {@link CloudBlobStore}\n+ * Must supply file azure-test.properties in classpath with valid config property values.\n+ */\n+//@Ignore\n+@RunWith(Parameterized.class)\n+public class CloudBlobStoreIntegrationTest {\n+\n+  private VerifiableProperties verifiableProperties;\n+  private CloudBlobStore cloudBlobStore;\n+  private CloudDestination cloudDestination;\n+  private Random random = new Random();\n+  private short accountId = 101;\n+  private short containerId = 5;\n+  private long operationTime = System.currentTimeMillis();\n+  private boolean isVcr;\n+  private PartitionId partitionId;\n+  // one day retention", "originalCommit": "43ddd899be3828bc01b2c6e5635e5991f51951bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE0NDg0NQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436144845", "bodyText": "fixed.", "author": "ankagrawal", "createdAt": "2020-06-05T20:18:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2MTgwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2NDgyNg==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436064826", "bodyText": "Can this be a common utility used by both (and future) integration tests, like CloudTestUtil?", "author": "lightningrob", "createdAt": "2020-06-05T17:34:07Z", "path": "ambry-cloud/src/test/java/com/github/ambry/cloud/CloudBlobStoreIntegrationTest.java", "diffHunk": "@@ -0,0 +1,515 @@\n+/**\n+ * Copyright 2020 LinkedIn Corp. All rights reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ */\n+package com.github.ambry.cloud;\n+\n+import com.codahale.metrics.MetricRegistry;\n+import com.github.ambry.cloud.azure.AzureCloudConfig;\n+import com.github.ambry.cloud.azure.AzureMetrics;\n+import com.github.ambry.clustermap.ClusterMap;\n+import com.github.ambry.clustermap.MockClusterMap;\n+import com.github.ambry.clustermap.MockDataNodeId;\n+import com.github.ambry.clustermap.Partition;\n+import com.github.ambry.clustermap.PartitionId;\n+import com.github.ambry.clustermap.PartitionState;\n+import com.github.ambry.config.CloudConfig;\n+import com.github.ambry.config.ClusterMapConfig;\n+import com.github.ambry.config.StoreConfig;\n+import com.github.ambry.config.VerifiableProperties;\n+import com.github.ambry.network.Port;\n+import com.github.ambry.network.PortType;\n+import com.github.ambry.store.MessageInfo;\n+import com.github.ambry.store.MockMessageWriteSet;\n+import com.github.ambry.store.StoreErrorCodes;\n+import com.github.ambry.store.StoreException;\n+import com.github.ambry.store.StoreGetOptions;\n+import com.github.ambry.store.StoreInfo;\n+import com.github.ambry.utils.Utils;\n+import com.microsoft.azure.cosmosdb.ConnectionPolicy;\n+import com.microsoft.azure.cosmosdb.ConsistencyLevel;\n+import com.microsoft.azure.cosmosdb.Document;\n+import com.microsoft.azure.cosmosdb.FeedOptions;\n+import com.microsoft.azure.cosmosdb.FeedResponse;\n+import com.microsoft.azure.cosmosdb.PartitionKey;\n+import com.microsoft.azure.cosmosdb.RequestOptions;\n+import com.microsoft.azure.cosmosdb.SqlQuerySpec;\n+import com.microsoft.azure.cosmosdb.rx.AsyncDocumentClient;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.EnumSet;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Properties;\n+import java.util.Random;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import static com.github.ambry.cloud.CloudTestUtil.*;\n+import static org.junit.Assert.*;\n+\n+\n+/**\n+ * Integration Test cases for {@link CloudBlobStore}\n+ * Must supply file azure-test.properties in classpath with valid config property values.\n+ */\n+//@Ignore\n+@RunWith(Parameterized.class)\n+public class CloudBlobStoreIntegrationTest {\n+\n+  private VerifiableProperties verifiableProperties;\n+  private CloudBlobStore cloudBlobStore;\n+  private CloudDestination cloudDestination;\n+  private Random random = new Random();\n+  private short accountId = 101;\n+  private short containerId = 5;\n+  private long operationTime = System.currentTimeMillis();\n+  private boolean isVcr;\n+  private PartitionId partitionId;\n+  // one day retention\n+  private final String PROPS_FILE_NAME = \"azure-test.properties\";\n+  private VcrMetrics vcrMetrics;\n+  private AzureMetrics azureMetrics;\n+\n+  /**\n+   * Run in both VCR and live serving mode.\n+   * @return an array with both {@code false} and {@code true}.\n+   */\n+  @Parameterized.Parameters\n+  public static List<Object[]> data() {\n+    return Arrays.asList(new Object[][]{{false}, {true}});\n+  }\n+\n+  /**\n+   * Constructor for {@link CloudBlobStoreIntegrationTest}.\n+   * @param isVcr true if testing for vcr. false otherwise.\n+   */\n+  public CloudBlobStoreIntegrationTest(boolean isVcr) {\n+    this.isVcr = isVcr;\n+  }\n+\n+  @Before\n+  public void setup() throws ReflectiveOperationException {\n+    Properties testProperties = new Properties();\n+    try (InputStream input = this.getClass().getClassLoader().getResourceAsStream(PROPS_FILE_NAME)) {\n+      if (input == null) {\n+        throw new IllegalStateException(\"Could not find resource: \" + PROPS_FILE_NAME);\n+      }\n+      testProperties.load(input);\n+    } catch (IOException ex) {\n+      throw new IllegalStateException(\"Could not load properties from resource: \" + PROPS_FILE_NAME);\n+    }\n+    testProperties.setProperty(\"clustermap.cluster.name\", \"Integration-Test\");\n+    testProperties.setProperty(\"clustermap.datacenter.name\", \"uswest\");\n+    testProperties.setProperty(\"clustermap.host.name\", \"localhost\");\n+    testProperties.setProperty(\"kms.default.container.key\",\n+        \"B374A26A71490437AA024E4FADD5B497FDFF1A8EA6FF12F6FB65AF2720B59CCF\");\n+\n+    testProperties.setProperty(CloudConfig.CLOUD_DELETED_BLOB_RETENTION_DAYS, String.valueOf(1));\n+    testProperties.setProperty(AzureCloudConfig.AZURE_PURGE_BATCH_SIZE, \"10\");\n+    testProperties.setProperty(CloudConfig.CLOUD_IS_VCR, \"\" + isVcr);\n+    verifiableProperties = new VerifiableProperties(testProperties);\n+    ClusterMapConfig clusterMapConfig = new ClusterMapConfig(verifiableProperties);\n+    CloudConfig cloudConfig = new CloudConfig(verifiableProperties);\n+    partitionId = new Partition(666, clusterMapConfig.clusterMapDefaultPartitionClass, PartitionState.READ_WRITE,\n+        100 * 1024 * 1024 * 1024L);\n+    ClusterMap clusterMap = new MockClusterMap(false, Collections.singletonList(\n+        new MockDataNodeId(Collections.singletonList(new Port(6666, PortType.PLAINTEXT)),\n+            Collections.singletonList(\"test\"), \"AzureTest\")), 1, Collections.singletonList(partitionId), \"AzureTest\");\n+    MetricRegistry registry = new MetricRegistry();\n+    vcrMetrics = new VcrMetrics(registry);\n+    azureMetrics = new AzureMetrics(registry);\n+    CloudDestinationFactory cloudDestinationFactory =\n+        Utils.getObj(cloudConfig.cloudDestinationFactoryClass, verifiableProperties, registry);\n+    cloudDestination = cloudDestinationFactory.getCloudDestination();\n+    cloudBlobStore = new CloudBlobStore(verifiableProperties, partitionId, cloudDestination, clusterMap, vcrMetrics);\n+    cloudBlobStore.start();\n+  }\n+\n+  @After\n+  public void destroy() throws IOException {\n+    cleanup();\n+    if (cloudBlobStore != null) {\n+      cloudBlobStore.shutdown();\n+    }\n+    if (cloudDestination != null) {\n+      cloudDestination.close();\n+    }\n+  }\n+\n+  /** Test {@link CloudBlobStore#put} method. */\n+  @Test\n+  public void testPut() throws StoreException {\n+    // Put blobs with and without expiration and encryption\n+    MockMessageWriteSet messageWriteSet = new MockMessageWriteSet();\n+    int count = 5;\n+    int expectedUploads = 0;\n+    int expectedEncryptions = 0;\n+    for (int j = 0; j < count; j++) {\n+      long size = Math.abs(random.nextLong()) % 10000;\n+      // Permanent and encrypted, should be uploaded and not reencrypted\n+      addBlobToMessageSet(messageWriteSet, size, Utils.Infinite_Time, accountId, containerId, true, false, partitionId,\n+          operationTime, isVcr);\n+      expectedUploads++;\n+      // Permanent and unencrypted\n+      addBlobToMessageSet(messageWriteSet, size, Utils.Infinite_Time, accountId, containerId, false, false, partitionId,\n+          operationTime, isVcr);\n+      expectedUploads++;\n+    }\n+    cloudBlobStore.put(messageWriteSet);\n+    assertEquals(\"Unexpected blobs count\", expectedUploads, azureMetrics.blobUploadSuccessCount.getCount());\n+    assertEquals(\"Unexpected encryption count\", expectedEncryptions, vcrMetrics.blobEncryptionCount.getCount());\n+  }\n+\n+  /** Test {@link CloudBlobStore#get} method. */\n+  @Test\n+  public void testGet() throws StoreException {\n+    MockMessageWriteSet messageWriteSet = new MockMessageWriteSet();\n+    addBlobToMessageSet(messageWriteSet, Utils.Infinite_Time, accountId, containerId, partitionId,\n+        operationTime, (short) 2);\n+    cloudBlobStore.put(messageWriteSet);\n+\n+    // verify that the blob was uploaded with expected metadata.\n+    StoreInfo storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected blob id\", messageWriteSet.getMessageSetInfo().get(0).getStoreKey(),\n+        storeInfo.getMessageReadSetInfo().get(0).getStoreKey());\n+    assertEquals(\"Unexpected live version\", messageWriteSet.getMessageSetInfo().get(0).getLifeVersion(),\n+        storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertEquals(\"Unexpected delete status\", messageWriteSet.getMessageSetInfo().get(0).isDeleted(),\n+        storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+    assertEquals(\"Unexpected blob size\", messageWriteSet.getMessageSetInfo().get(0).getSize(),\n+        storeInfo.getMessageReadSetInfo().get(0).getSize());\n+    assertEquals(\"Unexpected ttl update status\", messageWriteSet.getMessageSetInfo().get(0).isTtlUpdated(),\n+        storeInfo.getMessageReadSetInfo().get(0).isTtlUpdated());\n+    assertEquals(\"Unexpected account id\", messageWriteSet.getMessageSetInfo().get(0).getAccountId(),\n+        storeInfo.getMessageReadSetInfo().get(0).getAccountId());\n+    assertEquals(\"Unexpected container id\", messageWriteSet.getMessageSetInfo().get(0).getContainerId(),\n+        storeInfo.getMessageReadSetInfo().get(0).getContainerId());\n+    assertEquals(\"Unexpected operation time\", messageWriteSet.getMessageSetInfo().get(0).getOperationTimeMs(),\n+        storeInfo.getMessageReadSetInfo().get(0).getOperationTimeMs());\n+  }\n+\n+  /** Test {@link CloudBlobStore#delete} method. */\n+  @Test\n+  public void testDelete() throws StoreException {\n+    cleanup();\n+    if (isVcr) {\n+      testDeleteFromVcr();\n+    } else {\n+      testDeleteFromFrontend();\n+    }\n+  }\n+\n+  /** Test {@link CloudBlobStore#delete} method for vcr. */\n+  public void testDeleteFromVcr() throws StoreException {\n+    // First upload a blob with a life version 2\n+    MockMessageWriteSet messageWriteSet = new MockMessageWriteSet();\n+    addBlobToMessageSet(messageWriteSet, Utils.Infinite_Time, accountId, containerId, partitionId,\n+        operationTime, (short) 2);\n+    cloudBlobStore.put(messageWriteSet);\n+\n+    // verify that the blob was uploaded with expected metadata.\n+    StoreInfo storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", messageWriteSet.getMessageSetInfo().get(0).getLifeVersion(),\n+        storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertEquals(\"Unexpected delete status\", messageWriteSet.getMessageSetInfo().get(0).isDeleted(),\n+        storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+\n+    // Now delete with a smaller life version should fail silently without updating the life version.\n+    MessageInfo messageInfo = messageWriteSet.getMessageSetInfo().get(0);\n+    MessageInfo deleteMessageInfo =\n+        new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+            messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+            messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+            messageInfo.getOperationTimeMs(), (short) 1);\n+    cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", messageWriteSet.getMessageSetInfo().get(0).getLifeVersion(),\n+        storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertEquals(\"Unexpected delete status\", messageWriteSet.getMessageSetInfo().get(0).isDeleted(),\n+        storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+\n+    // Delete with same life version should pass without changing life version.\n+    deleteMessageInfo = new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+        messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+        messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+        messageInfo.getOperationTimeMs(), messageInfo.getLifeVersion());\n+    cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", messageWriteSet.getMessageSetInfo().get(0).getLifeVersion(),\n+        storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertTrue(\"Unexpected delete status\", storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+\n+    // Deleting a deleted blob with higher life version should update life version.\n+    deleteMessageInfo = new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+        messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+        messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+        messageInfo.getOperationTimeMs(), (short) 3);\n+    cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", 3, storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertTrue(\"Unexpected delete status\", storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+\n+    // Deleting again with smaller life version should fail with exception.\n+    deleteMessageInfo = new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+        messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+        messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+        messageInfo.getOperationTimeMs(), (short) 1);\n+    try {\n+      cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+      fail(\"Delete should fail with ID_Deleted StoreException\");\n+    } catch (StoreException ex) {\n+      assertEquals(\"Unexpected error code\", ex.getErrorCode(), StoreErrorCodes.ID_Deleted);\n+    }\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", 3, storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertTrue(\"Unexpected delete status\", storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+\n+    // Restart cloud blob store to clear cache. Deleting again with smaller life version should fail silently without updating anything.\n+    cloudBlobStore.shutdown();\n+    cloudBlobStore.start();\n+    cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", 3, storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertTrue(\"Unexpected delete status\", storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+  }\n+\n+  /** Test {@link CloudBlobStore#delete} method from frontend. */\n+  public void testDeleteFromFrontend() throws StoreException {\n+    // First upload a blob with a life version 2\n+    MockMessageWriteSet messageWriteSet = new MockMessageWriteSet();\n+    addBlobToMessageSet(messageWriteSet, Utils.Infinite_Time, accountId, containerId, partitionId,\n+        operationTime, (short) -1);\n+    cloudBlobStore.put(messageWriteSet);\n+\n+    // verify that the blob was uploaded with expected metadata.\n+    StoreInfo storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", 0, storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertEquals(\"Unexpected delete status\", messageWriteSet.getMessageSetInfo().get(0).isDeleted(),\n+        storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+\n+    // Deleting again should fail with ID_Deleted exception.\n+    MessageInfo messageInfo = messageWriteSet.getMessageSetInfo().get(0);\n+    MessageInfo deleteMessageInfo =\n+        new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+            messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+            messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+            messageInfo.getOperationTimeMs(), (short) -1);\n+    try {\n+      cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+    } catch (StoreException ex) {\n+      assertEquals(\"Unexpected error code\", ex.getErrorCode(), StoreErrorCodes.ID_Deleted);\n+    }\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", 0, storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertTrue(\"Unexpected delete status\", storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+\n+    // Restart cloud blob store to clear cache. Deleting again should still fail with ID_Deleted Store Exception.\n+    cloudBlobStore.shutdown();\n+    cloudBlobStore.start();\n+    deleteMessageInfo = new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+        messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+        messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+        messageInfo.getOperationTimeMs(), (short) 3);\n+    try {\n+      cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+    } catch (StoreException ex) {\n+      assertEquals(\"Unexpected error code\", ex.getErrorCode(), StoreErrorCodes.ID_Deleted);\n+    }\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertEquals(\"Unexpected live version\", 3, storeInfo.getMessageReadSetInfo().get(0).getLifeVersion());\n+    assertTrue(\"Unexpected delete status\", storeInfo.getMessageReadSetInfo().get(0).isDeleted());\n+  }\n+\n+  /** Test {@link CloudBlobStore#undelete} method. */\n+  @Test\n+  public void testUndelete() throws StoreException {\n+    MockMessageWriteSet messageWriteSet = new MockMessageWriteSet();\n+    addBlobToMessageSet(messageWriteSet, Utils.Infinite_Time, accountId, containerId, partitionId,\n+        operationTime, initLifeVersion(isVcr));\n+    cloudBlobStore.put(messageWriteSet);\n+\n+    // Attempt to undelete a blob that is not deleted. Should fail silently for vcr and throw exception for frontend.\n+    MessageInfo messageInfo = messageWriteSet.getMessageSetInfo().get(0);\n+    MessageInfo undeleteMessageInfo =\n+        new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+            messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+            messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+            messageInfo.getOperationTimeMs(), initLifeVersion(isVcr));\n+    try {\n+      cloudBlobStore.undelete(undeleteMessageInfo);\n+      if (!isVcr) {\n+        fail(\"Undelete from frontend of a not deleted blob should throw exception.\");\n+      }\n+    } catch (StoreException ex) {\n+      assertEquals(\"Unexpected error message\", StoreErrorCodes.ID_Not_Deleted, ex.getErrorCode());\n+    }\n+\n+    // delete the blob.\n+    MessageInfo deleteMessageInfo =\n+        new MessageInfo(messageInfo.getStoreKey(), messageInfo.getSize(), messageInfo.isDeleted(),\n+            messageInfo.isTtlUpdated(), messageInfo.isUndeleted(), messageInfo.getExpirationTimeInMs(),\n+            messageInfo.getCrc(), messageInfo.getAccountId(), messageInfo.getContainerId(),\n+            messageInfo.getOperationTimeMs(), (short) (isVcr ? 1 : -1));\n+    cloudBlobStore.delete(Collections.singletonList(deleteMessageInfo));\n+\n+    // Attempt to undelete should pass\n+    short lifeVersion = cloudBlobStore.undelete(undeleteMessageInfo);\n+    assertEquals(\"Unexpected life version after undelete\", lifeVersion, 1);\n+  }\n+\n+  /** Test {@link CloudBlobStore#updateTtl} method. */\n+  @Test\n+  public void testUpdateTtl() throws StoreException {\n+    MockMessageWriteSet messageWriteSet = new MockMessageWriteSet();\n+    StoreConfig storeConfig = new StoreConfig(verifiableProperties);\n+    CloudConfig cloudConfig = new CloudConfig(verifiableProperties);\n+    long now = System.currentTimeMillis();\n+    long expirationTimeMs = now;\n+    if (isVcr) {\n+      // vcr doesn't upload a blob that is within CloudConfig#vcrMinTtlDays of expiry.\n+      expirationTimeMs += Math.max(TimeUnit.DAYS.toMillis(cloudConfig.vcrMinTtlDays),\n+          TimeUnit.SECONDS.toMillis(storeConfig.storeTtlUpdateBufferTimeSeconds));\n+    } else {\n+      expirationTimeMs += TimeUnit.SECONDS.toMillis(storeConfig.storeTtlUpdateBufferTimeSeconds);\n+    }\n+    expirationTimeMs += 100000;\n+    addBlobToMessageSet(messageWriteSet, expirationTimeMs, accountId, containerId, partitionId,\n+        operationTime, (short) -1);\n+    cloudBlobStore.put(messageWriteSet);\n+\n+    // verify that the blob was uploaded with expected metadata.\n+    StoreInfo storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertFalse(\"Unexpected ttl update status\", storeInfo.getMessageReadSetInfo().get(0).isTtlUpdated());\n+    assertEquals(\"Unexpected expiration time\", expirationTimeMs,\n+        storeInfo.getMessageReadSetInfo().get(0).getExpirationTimeInMs());\n+\n+    // Do a ttl update without setting ttl update flag.\n+    MessageInfo ttlUpdateMessageInfo =\n+        new MessageInfo(messageWriteSet.getMessageSetInfo().get(0).getStoreKey(), 100, false, true, -1, accountId,\n+            containerId, now);\n+    cloudBlobStore.updateTtl(Collections.singletonList(ttlUpdateMessageInfo));\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertTrue(\"Unexpected ttl update status\", storeInfo.getMessageReadSetInfo().get(0).isTtlUpdated());\n+    assertEquals(\"Unexpected expiration time\", -1, storeInfo.getMessageReadSetInfo().get(0).getExpirationTimeInMs());\n+\n+    // Do a ttl update on a updated blob. It should fail silently.\n+    ttlUpdateMessageInfo =\n+        new MessageInfo(messageWriteSet.getMessageSetInfo().get(0).getStoreKey(), 100, false, true, -1, accountId,\n+            containerId, now);\n+    cloudBlobStore.updateTtl(Collections.singletonList(ttlUpdateMessageInfo));\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertTrue(\"Unexpected ttl update status\", storeInfo.getMessageReadSetInfo().get(0).isTtlUpdated());\n+    assertEquals(\"Unexpected expiration time\", -1, storeInfo.getMessageReadSetInfo().get(0).getExpirationTimeInMs());\n+\n+    // Clear cache by restarting blob store. Do a ttl update on a updated blob. It should fail silently.\n+    cloudBlobStore.shutdown();\n+    cloudBlobStore.start();\n+    ttlUpdateMessageInfo =\n+        new MessageInfo(messageWriteSet.getMessageSetInfo().get(0).getStoreKey(), 100, false, true, -1, accountId,\n+            containerId, now);\n+    cloudBlobStore.updateTtl(Collections.singletonList(ttlUpdateMessageInfo));\n+    storeInfo = cloudBlobStore.get(\n+        messageWriteSet.getMessageSetInfo().stream().map(MessageInfo::getStoreKey).collect(Collectors.toList()),\n+        EnumSet.allOf(StoreGetOptions.class));\n+    assertTrue(\"Unexpected ttl update status\", storeInfo.getMessageReadSetInfo().get(0).isTtlUpdated());\n+    assertEquals(\"Unexpected expiration time\", -1, storeInfo.getMessageReadSetInfo().get(0).getExpirationTimeInMs());\n+\n+    // Delete the blob.\n+    cloudBlobStore.delete(Collections.singletonList(ttlUpdateMessageInfo));\n+\n+    // ttlupdate of a deleted blob should throw ID_Delete Store Exception for frontend and fail silently for vcr.\n+    try {\n+      cloudBlobStore.updateTtl(Collections.singletonList(ttlUpdateMessageInfo));\n+      if (!isVcr) {\n+        fail(\"Update ttl of a deleted blob should fail for frontend.\");\n+      }\n+    } catch (StoreException ex) {\n+      assertEquals(\"Unexcpected error code\", ex.getErrorCode(), StoreErrorCodes.ID_Deleted);\n+    }\n+\n+    // Clear cache by restarting blob store. ttlupdate of a deleted blob should throw ID_Delete Store Exception.\n+    cloudBlobStore.shutdown();\n+    cloudBlobStore.start();\n+    try {\n+      cloudBlobStore.updateTtl(Collections.singletonList(ttlUpdateMessageInfo));\n+      if (!isVcr) {\n+        fail(\"Update ttl of a deleted blob should fail.\");\n+      }\n+    } catch (StoreException ex) {\n+      assertEquals(\"Unexpected error code\", ex.getErrorCode(), StoreErrorCodes.ID_Deleted);\n+    }\n+  }\n+\n+  /**\n+   * Cleanup the test partition by deleting all the blobs of the test partition.\n+   */\n+  private void cleanup() {", "originalCommit": "43ddd899be3828bc01b2c6e5635e5991f51951bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE0ODYyNA==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436148624", "bodyText": "done.", "author": "ankagrawal", "createdAt": "2020-06-05T20:27:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2NDgyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2ODUxNw==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436068517", "bodyText": "Shouldn't these methods be removed here?", "author": "lightningrob", "createdAt": "2020-06-05T17:41:41Z", "path": "ambry-cloud/src/test/java/com/github/ambry/cloud/CloudBlobStoreTest.java", "diffHunk": "@@ -873,11 +940,11 @@ public void testPutWithTtl() throws Exception {\n    * @return the generated {@link BlobId}.\n    */\n   private BlobId addBlobToSet(MockMessageWriteSet messageWriteSet, long size, long expiresAtMs, short accountId,", "originalCommit": "43ddd899be3828bc01b2c6e5635e5991f51951bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE3MDM1NQ==", "url": "https://github.com/linkedin/ambry/pull/1517#discussion_r436170355", "bodyText": "done.", "author": "ankagrawal", "createdAt": "2020-06-05T21:23:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2ODUxNw=="}], "type": "inlineReview"}, {"oid": "15aa9f9ded08330f2656f6ff39067ae8f28598cc", "url": "https://github.com/linkedin/ambry/commit/15aa9f9ded08330f2656f6ff39067ae8f28598cc", "message": "Address Rob's review comments", "committedDate": "2020-06-05T21:36:33Z", "type": "commit"}, {"oid": "9cd0c8edcd75ac3b00bebd886b5000a562e3eb61", "url": "https://github.com/linkedin/ambry/commit/9cd0c8edcd75ac3b00bebd886b5000a562e3eb61", "message": "Fix cloudblob store test", "committedDate": "2020-06-05T23:04:20Z", "type": "commit"}]}