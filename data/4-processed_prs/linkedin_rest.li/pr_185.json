{"pr_number": 185, "pr_title": "AsyncPool Improvements and Fixes", "pr_createdAt": "2020-02-24T21:19:56Z", "pr_url": "https://github.com/linkedin/rest.li/pull/185", "timeline": [{"oid": "f0d1ed5cd84f87f06a8dcc84e9a059038be50971", "url": "https://github.com/linkedin/rest.li/commit/f0d1ed5cd84f87f06a8dcc84e9a059038be50971", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast", "committedDate": "2020-02-25T18:02:14Z", "type": "forcePushed"}, {"oid": "1c6856ecb5453d5166ffa2df74491a70236e2e88", "url": "https://github.com/linkedin/rest.li/commit/1c6856ecb5453d5166ffa2df74491a70236e2e88", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast", "committedDate": "2020-02-26T22:55:00Z", "type": "forcePushed"}, {"oid": "9ffb7476a604e571231c4d9830698470ef153512", "url": "https://github.com/linkedin/rest.li/commit/9ffb7476a604e571231c4d9830698470ef153512", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast", "committedDate": "2020-02-26T22:57:47Z", "type": "forcePushed"}, {"oid": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "url": "https://github.com/linkedin/rest.li/commit/4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast", "committedDate": "2020-02-26T22:59:11Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4MzI4NQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384883285", "bodyText": "CHANNELPOOL_SSL_CALLBACK_HANDLER?", "author": "FreCap", "createdAt": "2020-02-27T02:35:31Z", "path": "r2-netty/src/main/java/com/linkedin/r2/transport/http/client/common/ChannelPoolLifecycle.java", "diffHunk": "@@ -86,33 +92,56 @@ public ChannelPoolLifecycle(SocketAddress address, Bootstrap bootstrap, ChannelG\n   public void create(final Callback<Channel> channelCallback)\n   {\n     _bootstrap.connect(_remoteAddress).addListener((ChannelFutureListener) channelFuture -> {\n-      if (channelFuture.isSuccess())\n+      if (!channelFuture.isSuccess())\n+      {\n+        onError(channelCallback, channelFuture);\n+        return;\n+      }\n+\n+      Channel c = channelFuture.channel();\n+      c.attr(CHANNEL_CREATION_TIME_KEY).set(_clock.currentTimeMillis());\n+\n+      if (_tcpNoDelay)\n+      {\n+        c.config().setOption(ChannelOption.TCP_NODELAY, true);\n+      }\n+      _channelGroup.add(c);\n+\n+      if (c.pipeline().get(SslHandlerUtil.PIPELINE_SSL_HANDLER) == null)\n       {\n-        Channel c = channelFuture.channel();\n-        c.attr(CHANNEL_CREATION_TIME_KEY).set(_clock.currentTimeMillis());\n-        if (_tcpNoDelay)\n-        {\n-          c.config().setOption(ChannelOption.TCP_NODELAY, true);\n-        }\n-        _channelGroup.add(c);\n         channelCallback.onSuccess(c);\n+        return;\n       }\n-      else\n+\n+      c.pipeline().addAfter(SslHandlerUtil.PIPELINE_SSL_HANDLER, CHANNELPOOL_CALLBACK_HANDLER, new ChannelDuplexHandler()", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4NTExNA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384885114", "bodyText": "sslSessionTimeout -> sslHandshakeTimeout?", "author": "FreCap", "createdAt": "2020-02-27T02:42:59Z", "path": "r2-netty/src/main/java/com/linkedin/r2/transport/http/client/rest/HttpNettyChannelPoolFactory.java", "diffHunk": "@@ -54,19 +55,24 @@\n   private final ChannelGroup _allChannels;\n   private final ScheduledExecutorService _scheduler;\n   private final int _maxConcurrentConnectionInitializations;\n+  private final int _channelPoolWaiterTimeout;\n \n   public HttpNettyChannelPoolFactory(int maxPoolSize, long idleTimeout, int maxPoolWaiterSize, AsyncPoolImpl.Strategy strategy,\n                                      int minPoolSize, EventLoopGroup eventLoopGroup, SSLContext sslContext, SSLParameters sslParameters, int maxHeaderSize,\n                                      int maxChunkSize, int maxResponseSize, ScheduledExecutorService scheduler, int maxConcurrentConnectionInitializations,\n-                                     boolean enableSSLSessionResumption, ChannelGroup allChannels)\n+                                     boolean enableSSLSessionResumption, ChannelGroup allChannels, int channelPoolWaiterTimeout,\n+                                     int connectTimeout, int sslSessionTimeout)\n   {\n \n     _allChannels = allChannels;\n     _scheduler = scheduler;\n     _maxConcurrentConnectionInitializations = maxConcurrentConnectionInitializations;\n+    _channelPoolWaiterTimeout = channelPoolWaiterTimeout;\n     Bootstrap bootstrap = new Bootstrap().group(eventLoopGroup)\n       .channel(NioSocketChannel.class)\n-      .handler(new HttpClientPipelineInitializer(sslContext, sslParameters, maxHeaderSize, maxChunkSize, maxResponseSize, enableSSLSessionResumption));\n+      .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, connectTimeout)\n+      .handler(new HttpClientPipelineInitializer(sslContext, sslParameters, maxHeaderSize, maxChunkSize, maxResponseSize,\n+          enableSSLSessionResumption, sslSessionTimeout));", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4NTg3NQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384885875", "bodyText": "These changes are no longer needed right?", "author": "FreCap", "createdAt": "2020-02-27T02:46:06Z", "path": "r2-netty/src/main/java/com/linkedin/r2/netty/handler/common/SessionResumptionSslHandler.java", "diffHunk": "@@ -46,14 +50,19 @@\n public class SessionResumptionSslHandler extends ChannelOutboundHandlerAdapter\n {\n   public static final String PIPELINE_SESSION_RESUMPTION_HANDLER = \"SessionResumptionSslHandler\";\n+  public static final AttributeKey<SessionResumptionSslHandler> CHANNEL_SESSION_RESUMPTION_HANDLER =\n+      AttributeKey.valueOf(\"sslSessionResumptionHandler\");\n \n   private final SslHandlerGenerator _hostPortToSslHandler;\n+  private Future<Channel> _handshakeFuture;", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkxMDU3Mg==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384910572", "bodyText": "Good catch. I have removed other related changes, but missed removing these member variable. Removed it now.", "author": "nizarm", "createdAt": "2020-02-27T04:42:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4NTg3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4NjU3OA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384886578", "bodyText": "Can be deprecated", "author": "FreCap", "createdAt": "2020-02-27T02:48:52Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -156,6 +157,22 @@ public AsyncPoolImpl(String name,\n         maxWaiters, strategy, minSize, rateLimiter, SystemClock.instance(), new LongTracking());\n   }\n \n+  public AsyncPoolImpl(String name,", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4NjgzOA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384886838", "bodyText": "target -> deadline", "author": "FreCap", "createdAt": "2020-02-27T02:49:50Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -697,6 +751,23 @@ private void timeoutObjects()\n     return toReap;\n   }\n \n+  private <U> Collection<TimeTrackingCallback<U>> reapWaiters(Queue<TimeTrackingCallback<U>> queue, long timeout)\n+  {\n+    List<TimeTrackingCallback<U>> toReap = new ArrayList<>();\n+    long now = _clock.currentTimeMillis();\n+    long target = now - timeout;", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4NzAyMA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384887020", "bodyText": "getExpiredWaiters since they are not killed here", "author": "FreCap", "createdAt": "2020-02-27T02:50:37Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -697,6 +751,23 @@ private void timeoutObjects()\n     return toReap;\n   }\n \n+  private <U> Collection<TimeTrackingCallback<U>> reapWaiters(Queue<TimeTrackingCallback<U>> queue, long timeout)", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4OTIxNg==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384889216", "bodyText": "waittimeout can be very low, let's add a min of 20-50 ms", "author": "FreCap", "createdAt": "2020-02-27T03:00:02Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -255,13 +275,15 @@ public void start()\n         throw new IllegalStateException(_poolName + \" is \" + _state);\n       }\n       _state = State.RUNNING;\n-      if (_idleTimeout > 0)\n+      long timeOut = Math.min(_idleTimeout, _waitTimeout);\n+      if (timeOut > 0)\n       {\n-        long freq = Math.min(_idleTimeout / 10, 1000);\n+        long freq = Math.min(timeOut / 10, 1000);", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkxNTYwOQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384915609", "bodyText": "Sure,  20-50 ms will be too aggressive IMHO. But yea - this matters only when someone override the default.", "author": "nizarm", "createdAt": "2020-02-27T05:07:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg4OTIxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NTg2OQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384895869", "bodyText": "The correctness of this line is not immediately clear and we might want to clarify that it is tightly tied to the shouldCreate methd", "author": "FreCap", "createdAt": "2020-02-27T03:29:48Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -601,6 +623,25 @@ private void create()\n       @Override\n       public void run(final SimpleCallback callback)\n       {\n+        boolean shouldIgnore;\n+        synchronized (_lock) {\n+          // Ignore the object creation if no one is waiting for the object and the pool already has _minSize objects\n+          int totalObjects = _checkedOut + _idle.size();\n+          shouldIgnore = _waiters.size() == 0 && totalObjects >= _minSize;\n+          if (shouldIgnore) {\n+            _statsTracker.incrementIgnoredCreation();\n+            if (_poolSize >= 1)\n+            {\n+              _poolSize--;", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NjEyMw==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384896123", "bodyText": "also I'm not super clear why this would go below 1, at first sight it seem that it would be kind of a bug if ti went below.\nI'd be curious if it ever happens", "author": "FreCap", "createdAt": "2020-02-27T03:31:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NTg2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMTMxNg==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384901316", "bodyText": "This tightly coupled condition is very dangerous being so distant from the origin of the update", "author": "FreCap", "createdAt": "2020-02-27T03:56:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NTg2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkxNzk4Mg==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384917982", "bodyText": "Added a comment to make it clear.  If you closely watch the creation onError code path - this is exactly done there as well.  But yea - there is a good scope for improvement around handling state in this class.", "author": "nizarm", "createdAt": "2020-02-27T05:19:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NTg2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NjM4Nw==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384896387", "bodyText": "We can move the increment on line 731.\n        obj.onError(new WaiterTimeoutException(\"Waiter timeout after \" + _waitTimeout + \"ms\"));", "author": "FreCap", "createdAt": "2020-02-27T03:32:33Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -697,6 +751,23 @@ private void timeoutObjects()\n     return toReap;\n   }\n \n+  private <U> Collection<TimeTrackingCallback<U>> reapWaiters(Queue<TimeTrackingCallback<U>> queue, long timeout)\n+  {\n+    List<TimeTrackingCallback<U>> toReap = new ArrayList<>();\n+    long now = _clock.currentTimeMillis();\n+    long target = now - timeout;\n+\n+    synchronized (_lock)\n+    {\n+      for (TimeTrackingCallback<U> p; (p = queue.peek()) != null && p.getTime() < target;)\n+      {\n+        toReap.add(queue.poll());\n+        _statsTracker.incrementWaiterTimedOut();", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkxOTI4Mg==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384919282", "bodyText": "The reason that is not done is to avoid acquiring the lock again just for updating the status (similar to timeoutObjects method). Since any slight increase in wait in this class is in the critical path of the request - we should avoid that. Let me know.", "author": "nizarm", "createdAt": "2020-02-27T05:25:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NjM4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NjU1Nw==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384896557", "bodyText": "Is this method unused?", "author": "FreCap", "createdAt": "2020-02-27T03:33:22Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -797,14 +868,24 @@ public void onError(Throwable e)\n     @Override\n     public void onSuccess(T result)\n     {\n-      long waitTime = System.currentTimeMillis() - _startTime;\n+      long waitTime = _clock.currentTimeMillis() - _startTime;\n       synchronized (_lock)\n       {\n         _statsTracker.trackWaitTime(waitTime);\n         _statsTracker.sampleMaxWaitTime(waitTime);\n       }\n       _callback.onSuccess(result);\n     }\n+\n+    public Callback<T> get()\n+    {\n+      return _callback;\n+    }", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkxOTk3Ng==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384919976", "bodyText": "Good catch", "author": "nizarm", "createdAt": "2020-02-27T05:28:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NjU1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5Njc0Nw==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384896747", "bodyText": "totalCreationsIgnored\nor to be even more explicit\ntotalCreationsCancelledNoWaiter", "author": "FreCap", "createdAt": "2020-02-27T03:34:21Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolStats.java", "diffHunk": "@@ -64,6 +66,8 @@ public AsyncPoolStats(\n       int totalDestroyErrors,\n       int totalBadDestroyed,\n       int totalTimedOut,\n+      int totalWaiterTimedOut,\n+      int totalCreationIgnored,", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkyMDMxMQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384920311", "bodyText": "I will vote for totalCreationsIgnored", "author": "nizarm", "createdAt": "2020-02-27T05:29:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5Njc0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NzY2Ng==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384897666", "bodyText": "There is not explicit need for having this other than testing. Our usual stance is to add methods to interfaces only if really needed. Adding it in the interface means extra support in the future for any ratelimiter.\nI'd rather remove this and make the method @VisibleForTesting", "author": "FreCap", "createdAt": "2020-02-27T03:38:38Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/RateLimiter.java", "diffHunk": "@@ -57,6 +57,11 @@\n    */\n   Collection<Task> cancelPendingTasks();\n \n+  default int numberOfPendingTasks()\n+  {\n+    return -1;\n+  }\n+", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkyMTU5Ng==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384921596", "bodyText": "Sure, we do not have VisibleForTesting anywhere in pegasus. Need to have additional external dependency  for that. To make things simpler I will have this method part of ExponentialRateLimitor alone and not part of the interface.", "author": "nizarm", "createdAt": "2020-02-27T05:35:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5NzY2Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5ODE0Mg==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384898142", "bodyText": "Is this change actually part of your RB?", "author": "FreCap", "createdAt": "2020-02-27T03:41:01Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/ExponentialBackOffRateLimiter.java", "diffHunk": "@@ -173,24 +173,10 @@ public void incrementPeriod()\n   @Override\n   public void submit(Task t)\n   {\n-    boolean runNow = false;\n     synchronized (this)\n     {\n-      if (_period == 0 && _pending.isEmpty() && _runningTasks < _maxRunningTasks)\n-      {\n-        _runningTasks ++;\n-        runNow = true;\n-      }\n-      else\n-      {\n-        _pending.add(t);\n-        schedule();\n-      }\n-    }\n-\n-    if (runNow)\n-    {\n-      t.run(_doneCallback);\n+      _pending.add(t);\n+      schedule();", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkyMjQzMg==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384922432", "bodyText": "Yes,  to make it more asynchronous and the task submission always happens in the executor thread.", "author": "nizarm", "createdAt": "2020-02-27T05:39:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5ODE0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5ODI2NA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384898264", "bodyText": "@VisibleForTesting", "author": "FreCap", "createdAt": "2020-02-27T03:41:34Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/ExponentialBackOffRateLimiter.java", "diffHunk": "@@ -208,6 +194,12 @@ public void submit(Task t)\n     }\n   }\n \n+  @Override\n+  public int numberOfPendingTasks()", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkyMjUxMw==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384922513", "bodyText": "See my comments above for this.", "author": "nizarm", "createdAt": "2020-02-27T05:39:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5ODI2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5ODczMw==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384898733", "bodyText": "This comment is not updated anymore", "author": "FreCap", "createdAt": "2020-02-27T03:44:01Z", "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -534,7 +544,7 @@ public void testGetStatsWithErrors() throws Exception\n     Assert.assertEquals(stats.getCheckedOut(), GET - PUT_BAD - DISPOSE);\n     // When the each create fails, it will retry and cancel the waiter,\n     // resulting in a second create error.", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkyMzUzOA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384923538", "bodyText": "Good Catch. removed non relevant comments. Thanks", "author": "nizarm", "createdAt": "2020-02-27T05:43:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5ODczMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5ODgxNw==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384898817", "bodyText": "just formatting, no need of space before ! or :", "author": "FreCap", "createdAt": "2020-02-27T03:44:30Z", "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5OTAwMg==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384899002", "bodyText": "Could we add in what way it is unexpected?", "author": "FreCap", "createdAt": "2020-02-27T03:45:31Z", "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkyNDI3OQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384924279", "bodyText": "Done", "author": "nizarm", "createdAt": "2020-02-27T05:46:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5OTAwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5OTE0Mw==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384899143", "bodyText": "Here no need of catching all exceptions, we can just specify the ones that Thread.sleep returns", "author": "FreCap", "createdAt": "2020-02-27T03:46:04Z", "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5OTg1OQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384899859", "bodyText": "ClockedExecutor should extend Clock, so no need to have two", "author": "FreCap", "createdAt": "2020-02-27T03:49:34Z", "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    // Wait for all the tasks in the rate limiter executor to finish\n+    executor.shutdown();\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    // Verify all the expectations\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckouts-concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckouts);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getTotalDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalBadDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalTimedOut(), 0);\n+  }\n+\n+  /***\n+   * This test case verifies that the correct number of waiters are timed out while waiting for object from the pool\n+   *\n+   *     Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *   A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the rate\n+   *       limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *   B = In Phase B, O number of object checkout request again sent to the channel pool when the pool has already\n+   *       checkout N number of objects, In this phase, the object creation inside the pool is blocked\n+   *       and the rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *   C = Ih Phase C, P number of objects are returned to the pool which are created in Phase A, this will make\n+   *       the number of waiter queue size to be O-P\n+   *   D = In Phase D, A delay will be introduced to timeout the waiters and all the O-P waiters should be timed out.\n+   *       After the delay the object creation will be unblocked and it should create aleast the concurrency number of\n+   *       objects even though the waiters are timedout.\n+   *\n+   * @param numberOfCheckoutsInPhaseA the N number of checkout operations that will be performed in phase A\n+   * @param numberOfCheckoutsInPhaseB the O number of checkout operations that will be performed in Phase B\n+   * @param numbOfObjectsToBeReturnedInPhaseC the numeber of objects returned in Phase C\n+   * @param poolSize size of the pool,\n+   * @param concurrency concurrency of the rate limiter\n+   */\n+  @Test(dataProvider = \"waiterTimeoutDataProvider\")\n+  public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckoutsInPhaseB,\n+      int numbOfObjectsToBeReturnedInPhaseC,\n+      int poolSize, int concurrency, int waiterTimeout)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckoutsInPhaseB, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    ClockedExecutor clockedExecutor = new ClockedExecutor();\n+    SettableClock settableClock = new SettableClock();", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkyNDk2OA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384924968", "bodyText": "The settableClock is needed here to simulate the time.  or Am I missing something ?", "author": "nizarm", "createdAt": "2020-02-27T05:50:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5OTg1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkzMzYzMQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384933631", "bodyText": "clockedExecutor should do the same, no? if you replace all settableClock with the clockedExecutor, should work the same", "author": "FreCap", "createdAt": "2020-02-27T06:25:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5OTg1OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTM4NDczNQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385384735", "bodyText": "Updated, had to make a small adjustment to the until time to consider the pool thread interval.", "author": "nizarm", "createdAt": "2020-02-27T21:35:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5OTg1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5OTk3NA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384899974", "bodyText": "Expand exceptions everywhere :)", "author": "FreCap", "createdAt": "2020-02-27T03:50:11Z", "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    // Wait for all the tasks in the rate limiter executor to finish\n+    executor.shutdown();\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    // Verify all the expectations\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckouts-concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckouts);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getTotalDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalBadDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalTimedOut(), 0);\n+  }\n+\n+  /***\n+   * This test case verifies that the correct number of waiters are timed out while waiting for object from the pool\n+   *\n+   *     Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *   A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the rate\n+   *       limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *   B = In Phase B, O number of object checkout request again sent to the channel pool when the pool has already\n+   *       checkout N number of objects, In this phase, the object creation inside the pool is blocked\n+   *       and the rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *   C = Ih Phase C, P number of objects are returned to the pool which are created in Phase A, this will make\n+   *       the number of waiter queue size to be O-P\n+   *   D = In Phase D, A delay will be introduced to timeout the waiters and all the O-P waiters should be timed out.\n+   *       After the delay the object creation will be unblocked and it should create aleast the concurrency number of\n+   *       objects even though the waiters are timedout.\n+   *\n+   * @param numberOfCheckoutsInPhaseA the N number of checkout operations that will be performed in phase A\n+   * @param numberOfCheckoutsInPhaseB the O number of checkout operations that will be performed in Phase B\n+   * @param numbOfObjectsToBeReturnedInPhaseC the numeber of objects returned in Phase C\n+   * @param poolSize size of the pool,\n+   * @param concurrency concurrency of the rate limiter\n+   */\n+  @Test(dataProvider = \"waiterTimeoutDataProvider\")\n+  public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckoutsInPhaseB,\n+      int numbOfObjectsToBeReturnedInPhaseC,\n+      int poolSize, int concurrency, int waiterTimeout)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckoutsInPhaseB, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    ClockedExecutor clockedExecutor = new ClockedExecutor();\n+    SettableClock settableClock = new SettableClock();\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        waiterTimeout,\n+        clockedExecutor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter, settableClock, new LongTracking()\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckoutsInPhaseA' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckoutsInPhaseA, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckoutsInPhaseB' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckoutsInPhaseB,\n+        0, pool);\n+\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (int i = 0; i < numbOfObjectsToBeReturnedInPhaseC; i++)\n+    {\n+      pool.put(checkedOutObjects.remove(0));\n+    }\n+\n+    settableClock.addDuration(waiterTimeout+1);\n+    clockedExecutor.runFor(waiterTimeout+2);\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTg5NTE2MA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385895160", "bodyText": "I don't see the exception expanded to TimeoutException here", "author": "FreCap", "createdAt": "2020-02-28T19:58:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg5OTk3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMDIxMw==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384900213", "bodyText": "use AssertWithTimeout instead to avoid locking situations, here and in the other places with sleep", "author": "FreCap", "createdAt": "2020-02-27T03:51:28Z", "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    // Wait for all the tasks in the rate limiter executor to finish\n+    executor.shutdown();\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    // Verify all the expectations\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckouts-concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckouts);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getTotalDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalBadDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalTimedOut(), 0);\n+  }\n+\n+  /***\n+   * This test case verifies that the correct number of waiters are timed out while waiting for object from the pool\n+   *\n+   *     Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *   A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the rate\n+   *       limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *   B = In Phase B, O number of object checkout request again sent to the channel pool when the pool has already\n+   *       checkout N number of objects, In this phase, the object creation inside the pool is blocked\n+   *       and the rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *   C = Ih Phase C, P number of objects are returned to the pool which are created in Phase A, this will make\n+   *       the number of waiter queue size to be O-P\n+   *   D = In Phase D, A delay will be introduced to timeout the waiters and all the O-P waiters should be timed out.\n+   *       After the delay the object creation will be unblocked and it should create aleast the concurrency number of\n+   *       objects even though the waiters are timedout.\n+   *\n+   * @param numberOfCheckoutsInPhaseA the N number of checkout operations that will be performed in phase A\n+   * @param numberOfCheckoutsInPhaseB the O number of checkout operations that will be performed in Phase B\n+   * @param numbOfObjectsToBeReturnedInPhaseC the numeber of objects returned in Phase C\n+   * @param poolSize size of the pool,\n+   * @param concurrency concurrency of the rate limiter\n+   */\n+  @Test(dataProvider = \"waiterTimeoutDataProvider\")\n+  public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckoutsInPhaseB,\n+      int numbOfObjectsToBeReturnedInPhaseC,\n+      int poolSize, int concurrency, int waiterTimeout)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckoutsInPhaseB, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    ClockedExecutor clockedExecutor = new ClockedExecutor();\n+    SettableClock settableClock = new SettableClock();\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        waiterTimeout,\n+        clockedExecutor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter, settableClock, new LongTracking()\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckoutsInPhaseA' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckoutsInPhaseA, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckoutsInPhaseB' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckoutsInPhaseB,\n+        0, pool);\n+\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (int i = 0; i < numbOfObjectsToBeReturnedInPhaseC; i++)\n+    {\n+      pool.put(checkedOutObjects.remove(0));\n+    }\n+\n+    settableClock.addDuration(waiterTimeout+1);\n+    clockedExecutor.runFor(waiterTimeout+2);\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkyODczNg==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384928736", "bodyText": "Thanks.", "author": "nizarm", "createdAt": "2020-02-27T06:05:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMDIxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMDM3NQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384900375", "bodyText": "You can specify the name of the dataProvider including what kind of data it'll return", "author": "FreCap", "createdAt": "2020-02-27T03:52:05Z", "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    // Wait for all the tasks in the rate limiter executor to finish\n+    executor.shutdown();\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    // Verify all the expectations\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckouts-concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckouts);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getTotalDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalBadDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalTimedOut(), 0);\n+  }\n+\n+  /***\n+   * This test case verifies that the correct number of waiters are timed out while waiting for object from the pool\n+   *\n+   *     Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *   A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the rate\n+   *       limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *   B = In Phase B, O number of object checkout request again sent to the channel pool when the pool has already\n+   *       checkout N number of objects, In this phase, the object creation inside the pool is blocked\n+   *       and the rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *   C = Ih Phase C, P number of objects are returned to the pool which are created in Phase A, this will make\n+   *       the number of waiter queue size to be O-P\n+   *   D = In Phase D, A delay will be introduced to timeout the waiters and all the O-P waiters should be timed out.\n+   *       After the delay the object creation will be unblocked and it should create aleast the concurrency number of\n+   *       objects even though the waiters are timedout.\n+   *\n+   * @param numberOfCheckoutsInPhaseA the N number of checkout operations that will be performed in phase A\n+   * @param numberOfCheckoutsInPhaseB the O number of checkout operations that will be performed in Phase B\n+   * @param numbOfObjectsToBeReturnedInPhaseC the numeber of objects returned in Phase C\n+   * @param poolSize size of the pool,\n+   * @param concurrency concurrency of the rate limiter\n+   */\n+  @Test(dataProvider = \"waiterTimeoutDataProvider\")\n+  public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckoutsInPhaseB,\n+      int numbOfObjectsToBeReturnedInPhaseC,\n+      int poolSize, int concurrency, int waiterTimeout)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckoutsInPhaseB, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    ClockedExecutor clockedExecutor = new ClockedExecutor();\n+    SettableClock settableClock = new SettableClock();\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        waiterTimeout,\n+        clockedExecutor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter, settableClock, new LongTracking()\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckoutsInPhaseA' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckoutsInPhaseA, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckoutsInPhaseB' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckoutsInPhaseB,\n+        0, pool);\n+\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (int i = 0; i < numbOfObjectsToBeReturnedInPhaseC; i++)\n+    {\n+      pool.put(checkedOutObjects.remove(0));\n+    }\n+\n+    settableClock.addDuration(waiterTimeout+1);\n+    clockedExecutor.runFor(waiterTimeout+2);\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    executor.shutdown();\n+\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckoutsInPhaseB - concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckoutsInPhaseA);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckoutsInPhaseA + concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckoutsInPhaseA + concurrency);\n+    Assert.assertEquals(stats.getTotalWaiterTimedOut(), numberOfCheckoutsInPhaseB - numbOfObjectsToBeReturnedInPhaseC);\n+  }\n+\n+  @DataProvider\n+  public Object[][] dataProvider()", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMDQ0OA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384900448", "bodyText": "ThreadLocalRandom.current()", "author": "FreCap", "createdAt": "2020-02-27T03:52:31Z", "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    // Wait for all the tasks in the rate limiter executor to finish\n+    executor.shutdown();\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    // Verify all the expectations\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckouts-concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckouts);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getTotalDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalBadDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalTimedOut(), 0);\n+  }\n+\n+  /***\n+   * This test case verifies that the correct number of waiters are timed out while waiting for object from the pool\n+   *\n+   *     Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *   A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the rate\n+   *       limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *   B = In Phase B, O number of object checkout request again sent to the channel pool when the pool has already\n+   *       checkout N number of objects, In this phase, the object creation inside the pool is blocked\n+   *       and the rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *   C = Ih Phase C, P number of objects are returned to the pool which are created in Phase A, this will make\n+   *       the number of waiter queue size to be O-P\n+   *   D = In Phase D, A delay will be introduced to timeout the waiters and all the O-P waiters should be timed out.\n+   *       After the delay the object creation will be unblocked and it should create aleast the concurrency number of\n+   *       objects even though the waiters are timedout.\n+   *\n+   * @param numberOfCheckoutsInPhaseA the N number of checkout operations that will be performed in phase A\n+   * @param numberOfCheckoutsInPhaseB the O number of checkout operations that will be performed in Phase B\n+   * @param numbOfObjectsToBeReturnedInPhaseC the numeber of objects returned in Phase C\n+   * @param poolSize size of the pool,\n+   * @param concurrency concurrency of the rate limiter\n+   */\n+  @Test(dataProvider = \"waiterTimeoutDataProvider\")\n+  public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckoutsInPhaseB,\n+      int numbOfObjectsToBeReturnedInPhaseC,\n+      int poolSize, int concurrency, int waiterTimeout)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckoutsInPhaseB, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    ClockedExecutor clockedExecutor = new ClockedExecutor();\n+    SettableClock settableClock = new SettableClock();\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        waiterTimeout,\n+        clockedExecutor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter, settableClock, new LongTracking()\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckoutsInPhaseA' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckoutsInPhaseA, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckoutsInPhaseB' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckoutsInPhaseB,\n+        0, pool);\n+\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (int i = 0; i < numbOfObjectsToBeReturnedInPhaseC; i++)\n+    {\n+      pool.put(checkedOutObjects.remove(0));\n+    }\n+\n+    settableClock.addDuration(waiterTimeout+1);\n+    clockedExecutor.runFor(waiterTimeout+2);\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    executor.shutdown();\n+\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckoutsInPhaseB - concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckoutsInPhaseA);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckoutsInPhaseA + concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckoutsInPhaseA + concurrency);\n+    Assert.assertEquals(stats.getTotalWaiterTimedOut(), numberOfCheckoutsInPhaseB - numbOfObjectsToBeReturnedInPhaseC);\n+  }\n+\n+  @DataProvider\n+  public Object[][] dataProvider()\n+  {\n+    // 500 represent a good sample for the randomized data.\n+    // This has been verified against 100K test cases in local\n+    int numberOfTestCases = 500;\n+    Random randomNumberGenerator = new Random();", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkyOTI3OQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384929279", "bodyText": "Done. Curios, What is the difference between Random() and ThreadLocalRandom.current() ?", "author": "nizarm", "createdAt": "2020-02-27T06:08:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMDQ0OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkzNDAyMA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384934020", "bodyText": "I think here is not really important, but it was just to avoid using Random in general which if used in prod code brings slowness compared to ThreadLocal one. (still here we are not using it in prod, and both ways are good)", "author": "FreCap", "createdAt": "2020-02-27T06:26:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMDQ0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMDc0NQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384900745", "bodyText": "extra lines", "author": "FreCap", "createdAt": "2020-02-27T03:54:06Z", "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -570,6 +580,389 @@ public void testWaitTimeStats() throws Exception\n     Assert.assertEquals(stats.getWaitTimeAvg(), DELAY, DELTA * DELAY);\n   }\n \n+  /***\n+   * This test case verifies that if more request object creation requests are submitted to the rate limiter, it only\n+   * creates the absolute required maximum (see below example)\n+   *\n+   *  Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *  A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the\n+   *      rate limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *  B = In Phase B, N number of object checkout request again sent to the channel pool when the pool has already\n+   *      checkout N number of objects, In this phase, the object creation inside the pool is blocked and the\n+   *      rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *  C = Ih Phase C, N number of objects are returned to the pool which are created in Phase A, this will make\n+   *      the number of idle objects in the pool as N.\n+   *  D = In Phase D, All the object creation blocked in Phase B will get un blocked and create number of new objects\n+   *      that are equal to the rate limiter concurrency. When rate limiter executes the queued creation requests - it\n+   *      should ignore the creation requests as there are no object waiters in the pool and thus effectively only\n+   *      creating the absolute minimum required count (N+Concurrency)\n+   *\n+   * @param numberOfCheckouts the N number of checkout operations that will be performed in phase A & B\n+   * @param poolSize the maximum Object Pool Size\n+   * @param concurrency the maximum allowed concurrent object creation\n+   */\n+  @Test(dataProvider = \"dataProvider\")\n+  public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts, int poolSize, int concurrency)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckouts, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        _executor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckout' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckouts, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckout' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckouts, numberOfCheckouts, pool);\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (Object checkedOutObject : checkedOutObjects)\n+    {\n+      pool.put(checkedOutObject);\n+    }\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      // Wait for all object creation to be unblocked\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    // Wait for all the tasks in the rate limiter executor to finish\n+    executor.shutdown();\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    // Verify all the expectations\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckouts-concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckouts);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckouts+concurrency);\n+    Assert.assertEquals(stats.getTotalDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalBadDestroyed(), 0);\n+    Assert.assertEquals(stats.getTotalTimedOut(), 0);\n+  }\n+\n+  /***\n+   * This test case verifies that the correct number of waiters are timed out while waiting for object from the pool\n+   *\n+   *     Assumption: the channel pool max size is always bigger than the requested checkout size\n+   *\n+   *|----------A------------|---------------B---------------|---------------C--------------|-------------D--------------\n+   *   A = In Phase A , N number of object checkout request to the pool when there are no tasks pending in the rate\n+   *       limiter. A's Expected result = channel pool will create N number of new objects and check them out\n+   *   B = In Phase B, O number of object checkout request again sent to the channel pool when the pool has already\n+   *       checkout N number of objects, In this phase, the object creation inside the pool is blocked\n+   *       and the rate limiter will Queue the creation requests once it reached its maximum concurrency configured.\n+   *   C = Ih Phase C, P number of objects are returned to the pool which are created in Phase A, this will make\n+   *       the number of waiter queue size to be O-P\n+   *   D = In Phase D, A delay will be introduced to timeout the waiters and all the O-P waiters should be timed out.\n+   *       After the delay the object creation will be unblocked and it should create aleast the concurrency number of\n+   *       objects even though the waiters are timedout.\n+   *\n+   * @param numberOfCheckoutsInPhaseA the N number of checkout operations that will be performed in phase A\n+   * @param numberOfCheckoutsInPhaseB the O number of checkout operations that will be performed in Phase B\n+   * @param numbOfObjectsToBeReturnedInPhaseC the numeber of objects returned in Phase C\n+   * @param poolSize size of the pool,\n+   * @param concurrency concurrency of the rate limiter\n+   */\n+  @Test(dataProvider = \"waiterTimeoutDataProvider\")\n+  public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckoutsInPhaseB,\n+      int numbOfObjectsToBeReturnedInPhaseC,\n+      int poolSize, int concurrency, int waiterTimeout)\n+  {\n+    CreationBlockableSynchronousLifecycle blockableObjectCreator =\n+        new CreationBlockableSynchronousLifecycle(numberOfCheckoutsInPhaseB, concurrency);\n+    ScheduledExecutorService executor = Executors.newScheduledThreadPool(500);\n+    RateLimiter rateLimiter = new ExponentialBackOffRateLimiter(0, 5000,\n+        10, executor, concurrency);\n+\n+    ClockedExecutor clockedExecutor = new ClockedExecutor();\n+    SettableClock settableClock = new SettableClock();\n+\n+    final AsyncPool<Object> pool = new AsyncPoolImpl<Object>(\"object pool\",\n+        blockableObjectCreator,\n+        poolSize,\n+        Integer.MAX_VALUE,\n+        waiterTimeout,\n+        clockedExecutor,\n+        Integer.MAX_VALUE,\n+        AsyncPoolImpl.Strategy.MRU,\n+        0, rateLimiter, settableClock, new LongTracking()\n+    );\n+\n+    pool.start();\n+\n+    // Phase A : Checking out object 'numberOfCheckoutsInPhaseA' times !\n+    List<Object> checkedOutObjects = performCheckout(numberOfCheckoutsInPhaseA, pool);\n+\n+    // Phase B : Blocking object creation and performing the checkout 'numberOfCheckoutsInPhaseB' times again\n+    blockableObjectCreator.blockCreation();\n+    Future<None> future = performUnblockingCheckout(numberOfCheckoutsInPhaseB,\n+        0, pool);\n+\n+    blockableObjectCreator.waitUntilAllBlocked();\n+\n+    // Phase C : Returning the checkedOut objects from Phase A back to the object pool\n+    for (int i = 0; i < numbOfObjectsToBeReturnedInPhaseC; i++)\n+    {\n+      pool.put(checkedOutObjects.remove(0));\n+    }\n+\n+    settableClock.addDuration(waiterTimeout+1);\n+    clockedExecutor.runFor(waiterTimeout+2);\n+\n+    // Phase D : All the object creation in phase B gets unblocked now\n+    blockableObjectCreator.unblockCreation();\n+    try\n+    {\n+      future.get(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception e)\n+    {\n+      Assert.fail(\"Unexpected interruption\", e);\n+    }\n+\n+    // Making sure the rate limiter pending tasks are submitted to the executor\n+    while (rateLimiter.numberOfPendingTasks() > 0)\n+    {\n+      try\n+      {\n+        Thread.sleep(1);\n+      }\n+      catch (Exception e)\n+      {\n+        Assert.fail(\"Unexpected interruption\", e);\n+      }\n+    }\n+\n+    executor.shutdown();\n+\n+    try\n+    {\n+      if (!executor.awaitTermination(10, TimeUnit.SECONDS))\n+      {\n+        Assert.fail(\"Too long to finish\");\n+      }\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Unexpected interruption\", ex);\n+    }\n+\n+    PoolStats stats = pool.getStats();\n+    Assert.assertEquals(stats.getTotalCreationIgnored(), numberOfCheckoutsInPhaseB - concurrency);\n+    Assert.assertEquals(stats.getCheckedOut(), numberOfCheckoutsInPhaseA);\n+    Assert.assertEquals(stats.getIdleCount(), concurrency);\n+    Assert.assertEquals(stats.getTotalCreated(), numberOfCheckoutsInPhaseA + concurrency);\n+    Assert.assertEquals(stats.getPoolSize(), numberOfCheckoutsInPhaseA + concurrency);\n+    Assert.assertEquals(stats.getTotalWaiterTimedOut(), numberOfCheckoutsInPhaseB - numbOfObjectsToBeReturnedInPhaseC);\n+  }\n+\n+  @DataProvider\n+  public Object[][] dataProvider()\n+  {\n+    // 500 represent a good sample for the randomized data.\n+    // This has been verified against 100K test cases in local\n+    int numberOfTestCases = 500;\n+    Random randomNumberGenerator = new Random();\n+\n+    Object[][] data = new Object[numberOfTestCases][3];\n+    for (int i = 0; i < numberOfTestCases; i++)\n+    {\n+      int checkout = randomNumberGenerator.nextInt(200)+1;\n+      int poolSize = randomNumberGenerator.nextInt(checkout)+checkout*2;\n+      int concurrency = randomNumberGenerator.nextInt(Math.min(checkout,499))+1;\n+      data[i][0] = checkout;\n+      data[i][1] = poolSize;\n+      data[i][2] = concurrency;\n+    }\n+\n+    return data;\n+  }\n+\n+  @DataProvider\n+  public Object[][] waiterTimeoutDataProvider()\n+  {\n+    // 500 represent a good sample for the randomized data.\n+    // This has been verified against 100K test cases in local\n+    int numberOfTestCases = 500;\n+    Random randomNumberGenerator = new Random();\n+\n+    Object[][] data = new Object[numberOfTestCases][6];\n+    for (int i = 0; i < numberOfTestCases; i++)\n+    {\n+      int numberOfCheckoutsInPhaseA = randomNumberGenerator.nextInt(100)+1;\n+      int numberOfCheckoutsInPhaseB = randomNumberGenerator.nextInt(numberOfCheckoutsInPhaseA)+1;\n+      numberOfCheckoutsInPhaseB = Math.min(numberOfCheckoutsInPhaseA, numberOfCheckoutsInPhaseB);\n+      int numbOfObjectsToBeReturnedInPhaseC = randomNumberGenerator.nextInt(numberOfCheckoutsInPhaseB);\n+      int poolSize = randomNumberGenerator.nextInt(numberOfCheckoutsInPhaseA)+numberOfCheckoutsInPhaseA*2;\n+      int concurrency = randomNumberGenerator.nextInt(Math.min(numberOfCheckoutsInPhaseB,499))+1;\n+      concurrency = Math.min(concurrency, numberOfCheckoutsInPhaseB);\n+\n+      data[i][0] = numberOfCheckoutsInPhaseA;\n+      data[i][1] = numberOfCheckoutsInPhaseB;\n+      data[i][2] = numbOfObjectsToBeReturnedInPhaseC;\n+      data[i][3] = poolSize;\n+      data[i][4] = concurrency;\n+      data[i][5] = randomNumberGenerator.nextInt(500)+100;\n+    }\n+\n+    return data;\n+  }\n+\n+  private List<Object> performCheckout(int numberOfCheckouts, AsyncPool<Object> pool)\n+  {\n+    List<Object> checkedOutObjects = new ArrayList<>(numberOfCheckouts);\n+\n+    ScheduledExecutorService checkoutExecutor = Executors.newScheduledThreadPool(50);\n+    CountDownLatch checkoutLatch = new CountDownLatch(numberOfCheckouts);\n+    Runnable checkoutTask = getCheckoutTask(pool, checkedOutObjects, new Object(), checkoutLatch, new CountDownLatch(numberOfCheckouts));\n+\n+    for (int i = 0; i < numberOfCheckouts; i++)\n+    {\n+      checkoutExecutor.execute(checkoutTask);\n+    }\n+\n+    try\n+    {\n+      checkoutLatch.await(5, TimeUnit.SECONDS);\n+      checkoutExecutor.shutdownNow();\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Too long to perform checkout operation\");\n+    }\n+\n+    return checkedOutObjects;\n+  }\n+\n+  private Future<None> performUnblockingCheckout(int numberOfCheckoutRequests, int numberOfCheckouts, AsyncPool<Object> pool)\n+  {\n+    ScheduledExecutorService checkoutExecutor = Executors.newScheduledThreadPool(500);\n+\n+    CountDownLatch checkoutLatch = new CountDownLatch(numberOfCheckouts);\n+    CountDownLatch requestLatch = new CountDownLatch(numberOfCheckoutRequests);\n+    Runnable checkoutTask = getCheckoutTask(pool, new LinkedList<>(), new Object(), checkoutLatch,\n+        requestLatch);\n+\n+    for (int i = 0; i < numberOfCheckoutRequests; i++)\n+    {\n+      checkoutExecutor.execute(checkoutTask);\n+    }\n+\n+    try\n+    {\n+      requestLatch.await(5, TimeUnit.SECONDS);\n+    }\n+    catch (Exception ex)\n+    {\n+      Assert.fail(\"Too long to perform checkout operation\");\n+    }\n+\n+    return new DelayedFutureCallback<>(checkoutLatch, checkoutExecutor);\n+  }\n+\n+  private class DelayedFutureCallback<T> extends FutureCallback<T>\n+  {\n+    private CountDownLatch _checkoutLatch;\n+    private ScheduledExecutorService _checkoutExecutor;\n+\n+    public DelayedFutureCallback(CountDownLatch checkoutLatch, ScheduledExecutorService checkoutExecutor)\n+    {\n+      _checkoutLatch = checkoutLatch;\n+      _checkoutExecutor = checkoutExecutor;\n+    }\n+\n+    @Override\n+    public T get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException {\n+      _checkoutLatch.await(timeout, unit);\n+      _checkoutExecutor.shutdownNow();\n+      return null;\n+    }\n+\n+    @Override\n+    public T get() throws InterruptedException, ExecutionException {\n+      throw new ExecutionException(new Exception(\"Not Implemented\"));\n+    }\n+  }\n+\n+  private Runnable getCheckoutTask(AsyncPool<Object> pool, List<Object> checkedOutObjects, Object sync, CountDownLatch latch,\n+      CountDownLatch requestLatch)\n+  {\n+    return new Runnable()\n+    {\n+      @Override\n+      public void run()\n+      {\n+        FutureCallback<Object> cb = new FutureCallback<>();\n+        pool.get(cb);\n+        requestLatch.countDown();\n+        try\n+        {\n+          Object checkedOutObject = cb.get();\n+          synchronized (sync)\n+          {\n+            checkedOutObjects.add(checkedOutObject);\n+          }\n+\n+          latch.countDown();\n+", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDkwMDkwMA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r384900900", "bodyText": "missing exception. either log, rethrow runtime or rename exception ignored.\nExpand Exception", "author": "FreCap", "createdAt": "2020-02-27T03:55:01Z", "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -622,6 +1015,60 @@ public int getLive()\n     }\n   }\n \n+  public static class CreationBlockableSynchronousLifecycle extends SynchronousLifecycle\n+  {\n+    private CountDownLatch _blockersDoneLatch;\n+    private int _totalBlockers;\n+\n+    public CreationBlockableSynchronousLifecycle(int checkout, int concurrency) {\n+      _blockersDoneLatch = new CountDownLatch(checkout);\n+      _totalBlockers = concurrency;\n+    }\n+\n+    private CountDownLatch _doneLatch = new CountDownLatch(0);\n+\n+    public void unblockCreation()\n+    {\n+      _doneLatch.countDown();\n+    }\n+\n+    public void blockCreation()\n+    {\n+      _doneLatch = new CountDownLatch(1);\n+      _blockersDoneLatch = new CountDownLatch(_totalBlockers);\n+    }\n+\n+    public void waitUntilAllBlocked()\n+    {\n+      try\n+      {\n+        _blockersDoneLatch.await();\n+      }\n+      catch (Exception ex)\n+      {\n+", "originalCommit": "4f40f203344a8b3f5b46574aca36fdf7a51d72bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI5MDIyNg==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385290226", "bodyText": "What I meant here was to set an upper and lower bound like in   Math.max(50,Math.min(timeOut / 10, 1000));", "author": "FreCap", "createdAt": "2020-02-27T18:25:52Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -278,7 +279,7 @@ public void start()\n       long timeOut = Math.min(_idleTimeout, _waitTimeout);\n       if (timeOut > 0)\n       {\n-        long freq = Math.min(timeOut / 10, 1000);\n+        long freq = Math.min(timeOut / 10, 50);", "originalCommit": "d4b4f8912510dde6c7baf4b7e4c6aea1a383d386", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI5MTkyNg==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385291926", "bodyText": "AssertionMethods.assertWithTimeout(5000, () ->       Assert.assertEquals(rateLimiter.numberOfPendingTasks(),0,\"Number of tasks has to drop to 0\")", "author": "FreCap", "createdAt": "2020-02-27T18:29:00Z", "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -647,34 +648,35 @@ public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts,\n     }\n     catch (Exception e)\n     {\n-      Assert.fail(\"Unexpected interruption\", e);\n+      Assert.fail(\"Did not complete unblocked object creations on time, Unexpected interruption\", e);\n     }\n \n     // Making sure the rate limiter pending tasks are submitted to the executor\n-    while (rateLimiter.numberOfPendingTasks() > 0)\n-    {\n-      try\n-      {\n-        Thread.sleep(1);\n-      }\n-      catch (Exception e)\n+    AssertionMethods.assertWithTimeout(5000, () -> {\n+      while (rateLimiter.numberOfPendingTasks() > 0)\n       {\n-        Assert.fail(\"Unexpected interruption\", e);\n-      }\n-    }", "originalCommit": "d4b4f8912510dde6c7baf4b7e4c6aea1a383d386", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI5MjExNQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385292115", "bodyText": "Same for others", "author": "FreCap", "createdAt": "2020-02-27T18:29:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI5MTkyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTMxOTAxNQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385319015", "bodyText": "Neat !, Thank you", "author": "nizarm", "createdAt": "2020-02-27T19:19:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI5MTkyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTM5MTA0Mg==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385391042", "bodyText": "Please name the parameter and class variable consistently. _waitTimeout vs. waiterTimeout.", "author": "ssheng", "createdAt": "2020-02-27T21:48:54Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -209,11 +231,13 @@ public AsyncPoolImpl(String name,\n     _lifecycle = lifecycle;\n     _maxSize = maxSize;\n     _idleTimeout = idleTimeout;\n+    _waitTimeout = waiterTimeout;", "originalCommit": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQwNDEzNQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385404135", "bodyText": "reformat", "author": "FreCap", "createdAt": "2020-02-27T22:18:07Z", "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -647,34 +648,25 @@ public void testObjectsAreNotCreatedWhenThereAreNoWaiters(int numberOfCheckouts,\n     }\n     catch (Exception e)\n     {\n-      Assert.fail(\"Unexpected interruption\", e);\n+      Assert.fail(\"Did not complete unblocked object creations on time, Unexpected interruption\", e);\n     }\n \n     // Making sure the rate limiter pending tasks are submitted to the executor\n-    while (rateLimiter.numberOfPendingTasks() > 0)\n-    {\n-      try\n-      {\n-        Thread.sleep(1);\n-      }\n-      catch (Exception e)\n-      {\n-        Assert.fail(\"Unexpected interruption\", e);\n-      }\n-    }\n+    AssertionMethods.assertWithTimeout(5000, () ->\n+            Assert.assertEquals(rateLimiter.numberOfPendingTasks(),0,\"Number of tasks has to drop to 0\"));", "originalCommit": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQwNDg4NA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385404884", "bodyText": "I'd be ok also with copy pasting the formula ;)  Math.max(MIN_WAITER_TIMEOUT, Math.min(timeOut / 10, MAX_WAITER_TIMEOUT));", "author": "FreCap", "createdAt": "2020-02-27T22:19:56Z", "path": "r2-core/src/test/java/test/r2/transport/http/client/TestAsyncPool.java", "diffHunk": "@@ -755,8 +746,7 @@ public void testWaiterTimeout(int numberOfCheckoutsInPhaseA, int numberOfCheckou\n       pool.put(checkedOutObjects.remove(0));\n     }\n \n-    settableClock.addDuration(waiterTimeout+1);\n-    clockedExecutor.runFor(waiterTimeout+2);\n+    clockedExecutor.runFor(waiterTimeout + AsyncPoolImpl.MAX_WAITER_TIMEOUT);", "originalCommit": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQxNzQ0Nw==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385417447", "bodyText": "The waiters queue is already a class variable and doesn't need to be passed around as a parameter.", "author": "ssheng", "createdAt": "2020-02-27T22:51:43Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -697,6 +757,23 @@ private void timeoutObjects()\n     return toReap;\n   }\n \n+  private <U> Collection<TimeTrackingCallback<U>> getExpiredWaiters(Queue<TimeTrackingCallback<U>> queue, long timeout)", "originalCommit": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQ1NTY2NQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385455665", "bodyText": "Based this method on existing reap method. I have refactored that one as well.", "author": "nizarm", "createdAt": "2020-02-28T00:56:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQxNzQ0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQzODQ1NA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385438454", "bodyText": "_waiterTimeout to be consistent with the parameter.", "author": "ssheng", "createdAt": "2020-02-27T23:56:40Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -209,11 +231,13 @@ public AsyncPoolImpl(String name,\n     _lifecycle = lifecycle;\n     _maxSize = maxSize;\n     _idleTimeout = idleTimeout;\n+    _waitTimeout = waiterTimeout;", "originalCommit": "ed72ed47198758e9bd2d284c1e54c16d71e2d9ea", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a3512d71d040dcda2ea5d67e6c00783454819773", "url": "https://github.com/linkedin/rest.li/commit/a3512d71d040dcda2ea5d67e6c00783454819773", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast", "committedDate": "2020-02-28T01:15:17Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTg5MzUzOQ==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385893539", "bodyText": "Thinking more about this, instead of modifying the min timeout (which could have an impact on servers with thousand of AsyncPools when set to a low value), we could run the expire logic per request.\nThis would guarantee us that we are doing the checking work only when actually needed and not keep checking every 100-300ms x 5000 Async Pools which can be a lot of load on the servers if we don't actually have any new connection.", "author": "FreCap", "createdAt": "2020-02-28T19:55:11Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -255,13 +278,15 @@ public void start()\n         throw new IllegalStateException(_poolName + \" is \" + _state);\n       }\n       _state = State.RUNNING;\n-      if (_idleTimeout > 0)\n+      long timeOut = Math.min(_idleTimeout, _waiterTimeout);\n+      if (timeOut > 0)\n       {\n-        long freq = Math.min(_idleTimeout / 10, 1000);\n+        long freq = Math.max(MIN_WAITER_TIMEOUT, Math.min(timeOut / 10, MAX_WAITER_TIMEOUT));", "originalCommit": "05ea3ba9753c42ca4969fe0bd38a7a6ac1759a70", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4MzU4Nw==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385983587", "bodyText": "Thanks for the offline discussion. This absolutely make sense. I have pushed the changes as discussed.", "author": "nizarm", "createdAt": "2020-02-29T00:52:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTg5MzUzOQ=="}], "type": "inlineReview"}, {"oid": "a639a72a31dd128821d11fa6ed3417ea478ea96b", "url": "https://github.com/linkedin/rest.li/commit/a639a72a31dd128821d11fa6ed3417ea478ea96b", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast", "committedDate": "2020-02-29T00:49:20Z", "type": "commit"}, {"oid": "a639a72a31dd128821d11fa6ed3417ea478ea96b", "url": "https://github.com/linkedin/rest.li/commit/a639a72a31dd128821d11fa6ed3417ea478ea96b", "message": "AsyncPool Improvements and Fixes:\n1. Do not submit the object creation request in the rate limiter When there is no waiters for the object and when the pool is above the minimum size. This fix will make sure that only the absolute minimum required objects are created in the pool even when the object creation request rate is higher than the actual object creation rate itself.\n\n2. Currenltly in the chhanel pool, the concurrency control how many parallel channel creation requests are in progress. The netty channel creation returns the channel as soon as the channel is created and before the SSL handshake is completed. This behaviour makes the concurrency settings less efffective.\nFix: Fix the channel pool to return the channl after the ssl handshake (for ssl channels) and make the ssl handshake part of the concurrency\n\n3. When a downstream server is healthy - it will not take so much time for the pool to provide a channel to the waiter. If the waiter is too long in the waiters queue, somethign unhealthy in the downstream and it is always better to fail fast the request.\nFix: A new channel pool level configuration introduced. WaiterTimeout - to fail fast the waiter. These waiters will be re-tried in different downstream due to RetriableException\n\n4. Currently during channel creation - there is no easy way to fine tune the \"connectionTimeout\" and \"sslHandShakeTimeout\". It always use the default values.\nFix: Provide a configuration option to fine tune these to fail fast", "committedDate": "2020-02-29T00:49:20Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4NDEwMg==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385984102", "bodyText": "Unused", "author": "FreCap", "createdAt": "2020-02-29T00:56:04Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -64,11 +63,15 @@\n   private final int _maxSize;\n   private final int _maxWaiters;\n   private final long _idleTimeout;\n+  private final long _waiterTimeout;\n   private final ScheduledExecutorService _timeoutExecutor;\n   private final int _minSize;\n   private volatile ScheduledFuture<?> _objectTimeoutFuture;\n   private final RateLimiter _rateLimiter;\n \n+  public static final int MIN_WAITER_TIMEOUT = 300;\n+  public static final int MAX_WAITER_TIMEOUT = 3000;", "originalCommit": "a639a72a31dd128821d11fa6ed3417ea478ea96b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4NDMzOA==", "url": "https://github.com/linkedin/rest.li/pull/185#discussion_r385984338", "bodyText": "getIdleTimeoutExpiredObjects", "author": "FreCap", "createdAt": "2020-02-29T00:57:52Z", "path": "r2-core/src/main/java/com/linkedin/r2/transport/http/client/AsyncPoolImpl.java", "diffHunk": "@@ -668,33 +713,33 @@ public void onError(final Throwable e)\n \n   private void timeoutObjects()\n   {\n-    Collection<T> idle = reap(_idle, _idleTimeout);\n-    if (idle.size() > 0)\n+    Collection<T> expiredObjects = getExpiredObjects();\n+    if (expiredObjects.size() > 0)\n     {\n-      LOG.debug(\"{}: disposing {} objects due to idle timeout\", _poolName, idle.size());\n-      for (T obj : idle)\n+      LOG.debug(\"{}: disposing {} objects due to idle timeout\", _poolName, expiredObjects.size());\n+      for (T obj : expiredObjects)\n       {\n         destroy(obj, false);\n       }\n     }\n   }\n \n-  private <U> Collection<U> reap(Queue<TimedObject<U>> queue, long timeout)\n+  private Collection<T> getExpiredObjects()", "originalCommit": "a639a72a31dd128821d11fa6ed3417ea478ea96b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "036d31ba0085e5eaaabddd2d9c65408c381da1cd", "url": "https://github.com/linkedin/rest.li/commit/036d31ba0085e5eaaabddd2d9c65408c381da1cd", "message": "Merge branch 'master' into bugfix/asyncpool", "committedDate": "2020-02-29T01:09:08Z", "type": "commit"}]}