{"pr_number": 8409, "pr_title": "ISPN-11789 Update Query Guide", "pr_createdAt": "2020-05-29T16:26:58Z", "pr_url": "https://github.com/infinispan/infinispan/pull/8409", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzgxOTI5MQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r433819291", "bodyText": "we can do this in the doc PR but I think library.proto should be renamed to book.proto.", "author": "oraNod", "createdAt": "2020-06-02T11:55:19Z", "path": "documentation/src/main/asciidoc/topics/query.adoc", "diffHunk": "@@ -18,480 +18,570 @@ Apart from indexed queries, {brandname} can run queries over non-indexed or\n partially indexed data.\n \n In terms of Search APIs, {brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text\n-querying. The link:#query_dsl[Query DSL] can be used for both embedded and remote java clients when full-text is not required; for Java embedded clients\n-{brandname} offers the link:#query_hibernatesearch[Hibernate Search Query API] which supports running Lucene queries in the grid, apart from advanced search capabilities\n-like Faceted and Spatial search.\n+querying.\n \n Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n whenever the changed data matches the queries.\n \n-[[query_library]]\n-== Embedded Querying\n+== Indexing\n \n-Embedded querying is available when {brandname} is used as a library. No protobuf mapping is required, and both indexing and searching\n-are done on top of Java objects. When in library mode, it is possible to run Lucene queries directly and use all the available link:#query_apis[Query APIs] and it also allows flexible indexing configurations to keep latency to a minimal.\n+Indexing in {brandname} happens on a per-cache basis and by default a cache is not indexed. Enabling indexing is not mandatory but queries using an index will\n+have a vastly superior performance. On the other hand, enabling indexing can impact negatively the write throughput of a cluster, so make sure to check the link:#query_performance[query performance guide] for some strategies to minimize this impact depending on the cache type and use case.\n \n-=== Quick example\n+NOTE: When using the full-text operator (:) or any other full-text feature, indexing is mandatory. {brandname} will\n+throw an error if a full-text query is attempted in a non-indexed cache.\n \n-We're going to store _Book_ instances in an {brandname} cache called \"books\". _Book_ instances will be indexed, so we enable indexing for the cache,\n-letting {brandname} link:#query_autoconfig[configure the indexing automatically]:\n+=== Configuration\n \n-{brandname} configuration:\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+NOTE: The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n \n-.infinispan.xml\n [source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-include::config_examples/infinispan_distributed_cache_books.xml[]\n+include::config_examples/indexing.xml[]\n ----\n \n-Obtaining the cache:\n+Programmatic:\n \n [source,java]\n ----\n-import org.infinispan.Cache;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-\n-EmbeddedCacheManager manager = new DefaultCacheManager(\"infinispan.xml\");\n-Cache<String, Book> cache = manager.getCache(\"books\");\n+import org.infinispan.configuration.cache.*;\n \n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n ----\n \n-Each _Book_ will be defined as in the following example; we have to choose which properties are indexed, and for each property we can optionally choose advanced indexing options using the annotations defined in the Hibernate Search project.\n-\n-[source,java]\n-.Book.java\n-----\n-import org.hibernate.search.annotations.*;\n-import java.util.Date;\n-import java.util.HashSet;\n-import java.util.Set;\n+NOTE: When using programmatic configuration, indexing must be enabled explicitly by invoking the `enable()` method, as\n+no auto-enabling mechanism exist for programmatic configuration as in the case of XML configuration.\n \n-//Values you want to index need to be annotated with @Indexed, then you pick which fields and how they are to be indexed:\n-@Indexed\n-public class Book {\n-   @Field String title;\n-   @Field String description;\n-   @Field @DateBridge(resolution=Resolution.YEAR) Date publicationYear;\n-   @IndexedEmbedded Set<Author> authors = new HashSet<Author>();\n-}\n+=== Specifying indexed Entities\n \n-----\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+This can be done via xml:\n \n-[source,java]\n-.Author.java\n+[source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-\n-public class Author {\n-   @Field String name;\n-   @Field String surname;\n-   // hashCode() and equals() omitted\n-}\n-\n+include::config_examples/indexed_entities.xml[]\n ----\n \n-Now assuming we stored several _Book_ instances in our {brandname} _Cache_ , we can search them for any matching field as in the following example.\n-\n-Using a Lucene Query:\n+or programmatically:\n \n [source,java]\n ----\n-// get the search manager from the cache:\n-SearchManager searchManager = org.infinispan.query.Search.getSearchManager(cache);\n-\n-// create any standard Lucene query, via Lucene's QueryParser or any other means:\n-org.apache.lucene.search.Query fullTextQuery = //any Apache Lucene Query\n-\n-// convert the Lucene query to a CacheQuery:\n-CacheQuery cacheQuery = searchManager.getQuery( fullTextQuery );\n-\n-// get the results:\n-List<Object> found = cacheQuery.list();\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n \n ----\n \n-A Lucene Query is often created by parsing a query in text format such as \"title:infinispan AND authors.name:sanne\", or by using the query builder provided by Hibernate Search.\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n \n-[source,java]\n+[source,proto]\n ----\n-// get the search manager from the cache:\n-SearchManager searchManager = org.infinispan.query.Search.getSearchManager( cache );\n-\n-// you could make the queries via Lucene APIs, or use some helpers:\n-QueryBuilder queryBuilder = searchManager.buildQueryBuilderForClass(Book.class).get();\n-\n-// the queryBuilder has a nice fluent API which guides you through all options.\n-// this has some knowledge about your object, for example which Analyzers\n-// need to be applied, but the output is a fairly standard Lucene Query.\n-org.apache.lucene.search.Query luceneQuery = queryBuilder.phrase()\n-                  .onField(\"description\")\n-                  .andField(\"title\")\n-                  .sentence(\"a book on highly scalable query engines\")\n-                  .createQuery();\n-\n-// the query API itself accepts any Lucene Query, and on top of that\n-// you can restrict the result to selected class types:\n-CacheQuery query = searchManager.getQuery(luceneQuery, Book.class);\n-\n-// and there are your results!\n-List objectList = query.list();\n-\n-for (Object book : objectList) {\n-      System.out.println(book);\n-}\n-\n+include::config_examples/library.proto[]", "originalCommit": "906c35551245e100d474ad1d7f9c69c220014f56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTc3OTkzMg==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r435779932", "bodyText": "yes, let's do it later, as this file is reused elsewhere", "author": "gustavonalle", "createdAt": "2020-06-05T08:48:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzgxOTI5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk1NjY5Nw==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r433956697", "bodyText": "I know this is developer content but would \"Search\" be a more common/simpler term than \"Query\"?\nPerhaps \"Searching the Data Store\" or \"Searching {brandname} Caches\" might be more meaningful from a high level?", "author": "oraNod", "createdAt": "2020-06-02T15:17:37Z", "path": "documentation/src/main/asciidoc/topics/query.adoc", "diffHunk": "@@ -18,480 +18,570 @@ Apart from indexed queries, {brandname} can run queries over non-indexed or\n partially indexed data.\n \n In terms of Search APIs, {brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text\n-querying. The link:#query_dsl[Query DSL] can be used for both embedded and remote java clients when full-text is not required; for Java embedded clients\n-{brandname} offers the link:#query_hibernatesearch[Hibernate Search Query API] which supports running Lucene queries in the grid, apart from advanced search capabilities\n-like Faceted and Spatial search.\n+querying.\n \n Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n whenever the changed data matches the queries.\n \n-[[query_library]]\n-== Embedded Querying\n+== Indexing\n \n-Embedded querying is available when {brandname} is used as a library. No protobuf mapping is required, and both indexing and searching\n-are done on top of Java objects. When in library mode, it is possible to run Lucene queries directly and use all the available link:#query_apis[Query APIs] and it also allows flexible indexing configurations to keep latency to a minimal.\n+Indexing in {brandname} happens on a per-cache basis and by default a cache is not indexed. Enabling indexing is not mandatory but queries using an index will\n+have a vastly superior performance. On the other hand, enabling indexing can impact negatively the write throughput of a cluster, so make sure to check the link:#query_performance[query performance guide] for some strategies to minimize this impact depending on the cache type and use case.\n \n-=== Quick example\n+NOTE: When using the full-text operator (:) or any other full-text feature, indexing is mandatory. {brandname} will\n+throw an error if a full-text query is attempted in a non-indexed cache.\n \n-We're going to store _Book_ instances in an {brandname} cache called \"books\". _Book_ instances will be indexed, so we enable indexing for the cache,\n-letting {brandname} link:#query_autoconfig[configure the indexing automatically]:\n+=== Configuration\n \n-{brandname} configuration:\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+NOTE: The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n \n-.infinispan.xml\n [source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-include::config_examples/infinispan_distributed_cache_books.xml[]\n+include::config_examples/indexing.xml[]\n ----\n \n-Obtaining the cache:\n+Programmatic:\n \n [source,java]\n ----\n-import org.infinispan.Cache;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-\n-EmbeddedCacheManager manager = new DefaultCacheManager(\"infinispan.xml\");\n-Cache<String, Book> cache = manager.getCache(\"books\");\n+import org.infinispan.configuration.cache.*;\n \n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n ----\n \n-Each _Book_ will be defined as in the following example; we have to choose which properties are indexed, and for each property we can optionally choose advanced indexing options using the annotations defined in the Hibernate Search project.\n-\n-[source,java]\n-.Book.java\n-----\n-import org.hibernate.search.annotations.*;\n-import java.util.Date;\n-import java.util.HashSet;\n-import java.util.Set;\n+NOTE: When using programmatic configuration, indexing must be enabled explicitly by invoking the `enable()` method, as\n+no auto-enabling mechanism exist for programmatic configuration as in the case of XML configuration.\n \n-//Values you want to index need to be annotated with @Indexed, then you pick which fields and how they are to be indexed:\n-@Indexed\n-public class Book {\n-   @Field String title;\n-   @Field String description;\n-   @Field @DateBridge(resolution=Resolution.YEAR) Date publicationYear;\n-   @IndexedEmbedded Set<Author> authors = new HashSet<Author>();\n-}\n+=== Specifying indexed Entities\n \n-----\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+This can be done via xml:\n \n-[source,java]\n-.Author.java\n+[source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-\n-public class Author {\n-   @Field String name;\n-   @Field String surname;\n-   // hashCode() and equals() omitted\n-}\n-\n+include::config_examples/indexed_entities.xml[]\n ----\n \n-Now assuming we stored several _Book_ instances in our {brandname} _Cache_ , we can search them for any matching field as in the following example.\n-\n-Using a Lucene Query:\n+or programmatically:\n \n [source,java]\n ----\n-// get the search manager from the cache:\n-SearchManager searchManager = org.infinispan.query.Search.getSearchManager(cache);\n-\n-// create any standard Lucene query, via Lucene's QueryParser or any other means:\n-org.apache.lucene.search.Query fullTextQuery = //any Apache Lucene Query\n-\n-// convert the Lucene query to a CacheQuery:\n-CacheQuery cacheQuery = searchManager.getQuery( fullTextQuery );\n-\n-// get the results:\n-List<Object> found = cacheQuery.list();\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n \n ----\n \n-A Lucene Query is often created by parsing a query in text format such as \"title:infinispan AND authors.name:sanne\", or by using the query builder provided by Hibernate Search.\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n \n-[source,java]\n+[source,proto]\n ----\n-// get the search manager from the cache:\n-SearchManager searchManager = org.infinispan.query.Search.getSearchManager( cache );\n-\n-// you could make the queries via Lucene APIs, or use some helpers:\n-QueryBuilder queryBuilder = searchManager.buildQueryBuilderForClass(Book.class).get();\n-\n-// the queryBuilder has a nice fluent API which guides you through all options.\n-// this has some knowledge about your object, for example which Analyzers\n-// need to be applied, but the output is a fairly standard Lucene Query.\n-org.apache.lucene.search.Query luceneQuery = queryBuilder.phrase()\n-                  .onField(\"description\")\n-                  .andField(\"title\")\n-                  .sentence(\"a book on highly scalable query engines\")\n-                  .createQuery();\n-\n-// the query API itself accepts any Lucene Query, and on top of that\n-// you can restrict the result to selected class types:\n-CacheQuery query = searchManager.getQuery(luceneQuery, Book.class);\n-\n-// and there are your results!\n-List objectList = query.list();\n-\n-for (Object book : objectList) {\n-      System.out.println(book);\n-}\n-\n+include::config_examples/library.proto[]\n ----\n-Apart from _list()_ you have the option for streaming results, or use pagination.\n-\n \n-For searches that do not require Lucene or full-text capabilities and are mostly about aggregation and exact matches, we can use the {brandname} Query DSL API:\n+The config should be:\n \n-[source,java]\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n ----\n-import org.infinispan.query.dsl.QueryFactory;\n-import org.infinispan.query.dsl.Query;\n-import org.infinispan.query.Search;\n \n-// get the query factory:\n-QueryFactory queryFactory = Search.getQueryFactory(cache);\n+[[query_index_storage]]\n+=== Index Storage\n \n-Query q = queryFactory.from(Book.class)\n-            .having(\"author.surname\").eq(\"King\")\n-            .build();\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n \n-List<Book> list = q.list();\n+.Configuration for file system indexes:\n \n+[source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-\n-Finally, we can use an link:#query_ickle[Ickle] query directly, allowing for Lucene syntax in one or more predicates:\n-\n-[source,java]\n+include::config_examples/indexing_filesystem.xml[]\n ----\n-import org.infinispan.query.dsl.QueryFactory;\n-import org.infinispan.query.dsl.Query;\n \n-// get the query factory:\n-QueryFactory queryFactory = Search.getQueryFactory(cache);\n-\n-\n-Query q = queryFactory.create(\"from Book b where b.author.name = 'Stephen' and \" +\n-                \"b.description : (+'dark' -'tower')\");\n-\n-List<Book> list = q.list();\n+.Configuration for memory indexes:\n \n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n ----\n \n-=== Indexing\n-\n-Indexing in {brandname} happens on a per-cache basis and by default a cache is not indexed. Enabling indexing is not mandatory but queries using an index will\n-have a vastly superior performance. On the other hand, enabling indexing can impact negatively the write throughput of a cluster, so make sure to check the link:#query_performance[query performance guide] for some strategies to minimize this impact depending on the cache type and use case.\n+[[query_index_manager]]\n+=== Index Manager\n \n-==== Configuration\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n \n-===== General format\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n \n-To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, and optionally pass additional properties.\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n \n-NOTE: The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n-convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n-This behaviour exists only on schemas starting with version 11.\n+Example with `local-heap`:\n \n [source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-include::config_examples/indexing.xml[]\n+include::config_examples/indexing_near_real_time.xml[]\n ----\n \n-Programmatic:\n+Example with `filesystem`:\n \n-[source,java]\n+[source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-import org.infinispan.configuration.cache.*;\n-\n-ConfigurationBuilder cacheCfg = ...\n-cacheCfg.indexing().enable()\n-      .addProperty(\"property name\", \"propery value\")\n+include::config_examples/indexing_near_real_time_fs.xml[]\n ----\n \n-NOTE: When using programmatic configuration, indexing must be enabled explicitly by invoking the `enable()` method, as\n-no auto-enabling mechanism exist for programmatic configuration as in the case of XML configuration.\n-\n-===== Index names\n-\n-Each property inside the `index` element is prefixed with the index name, for the index named `org.infinispan.sample.Car` the `directory_provider` is `local-heap`:\n+[[query_massindexer]]\n+=== Re-indexing\n \n-[source,xml,options=\"nowrap\",subs=attributes+]\n-----\n-include::config_examples/indexing_property.xml[]\n-----\n+Occasionally you might need to rebuild the indexs by reconstructing it from the data stored in the Cache. You need to rebuild the index if you change the definition of what is indexed on your types, or if you change for example some _Analyzer_ parameter, as Analyzers affect how the index is written. Also, you might need to rebuild the index if you had it destroyed by some system administration mistake. To rebuild the index just get a reference to the Indexer and start it; beware it might take some time as it needs to reprocess all data in the grid!\n \n [source,java]\n ----\n-cacheCfg.indexing()\n-   .enable()\n-      .addProperty(\"org.infinispan.sample.Car.directory_provider\", \"local-heap\")\n-\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n ----\n \n-{brandname} creates an index for each entity existent in a cache, and it allows to configure those indexes independently.\n-For a class annotated with `@Indexed`, the index name is the fully qualified class name, unless overridden with the\n-`name` argument in the annotation.\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n \n-In the snippet below, the default storage for all entities is `infinispan`, but `Boat` instances will be stored on `local-heap` in an index named\n-`boatIndex`. `Airplane` entities will also be stored in `local-heap`. Any other entity's index will be configured with the property prefixed by `default`.\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n \n-[source,java]\n-----\n-package org.infinispan.sample;\n+== Querying", "originalCommit": "906c35551245e100d474ad1d7f9c69c220014f56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTc4MDY0OA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r435780648", "bodyText": "I also like more \"Searching\" than \"Querying\", will change the references", "author": "gustavonalle", "createdAt": "2020-06-05T08:50:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk1NjY5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk3MDQyOQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r433970429", "bodyText": "This reads slightly contradictory to me. We say enabling indexing is not mandatory in the previous paragraph then add a note to say it is mandatory for full-text queries.\nThe second sentence is also unnecessary. You mention that indexing is mandatory for full-text. It probably isn't necessary to document that Infinispan throws an error.\nIn the first couple of sentences I think clarity can be improved by picking out the different things you're saying. Maybe something along the lines of:\nIndexing entries in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing caches can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case.", "author": "oraNod", "createdAt": "2020-06-02T15:36:42Z", "path": "documentation/src/main/asciidoc/topics/query.adoc", "diffHunk": "@@ -18,480 +18,570 @@ Apart from indexed queries, {brandname} can run queries over non-indexed or\n partially indexed data.\n \n In terms of Search APIs, {brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text\n-querying. The link:#query_dsl[Query DSL] can be used for both embedded and remote java clients when full-text is not required; for Java embedded clients\n-{brandname} offers the link:#query_hibernatesearch[Hibernate Search Query API] which supports running Lucene queries in the grid, apart from advanced search capabilities\n-like Faceted and Spatial search.\n+querying.\n \n Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n whenever the changed data matches the queries.\n \n-[[query_library]]\n-== Embedded Querying\n+== Indexing\n \n-Embedded querying is available when {brandname} is used as a library. No protobuf mapping is required, and both indexing and searching\n-are done on top of Java objects. When in library mode, it is possible to run Lucene queries directly and use all the available link:#query_apis[Query APIs] and it also allows flexible indexing configurations to keep latency to a minimal.\n+Indexing in {brandname} happens on a per-cache basis and by default a cache is not indexed. Enabling indexing is not mandatory but queries using an index will\n+have a vastly superior performance. On the other hand, enabling indexing can impact negatively the write throughput of a cluster, so make sure to check the link:#query_performance[query performance guide] for some strategies to minimize this impact depending on the cache type and use case.\n \n-=== Quick example\n+NOTE: When using the full-text operator (:) or any other full-text feature, indexing is mandatory. {brandname} will\n+throw an error if a full-text query is attempted in a non-indexed cache.", "originalCommit": "906c35551245e100d474ad1d7f9c69c220014f56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk3MTY0Mg==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r433971642", "bodyText": "Creating Indexes for {brandname} Caches? | Indexing Entries in {brandname} Caches\nWhen we say indexing here, what do we really mean? Is it an index of the cache or an index of the entries in the cache? Maybe it's just me but I think expanding the title out helps with understanding.", "author": "oraNod", "createdAt": "2020-06-02T15:38:27Z", "path": "documentation/src/main/asciidoc/topics/query.adoc", "diffHunk": "@@ -18,480 +18,570 @@ Apart from indexed queries, {brandname} can run queries over non-indexed or\n partially indexed data.\n \n In terms of Search APIs, {brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text\n-querying. The link:#query_dsl[Query DSL] can be used for both embedded and remote java clients when full-text is not required; for Java embedded clients\n-{brandname} offers the link:#query_hibernatesearch[Hibernate Search Query API] which supports running Lucene queries in the grid, apart from advanced search capabilities\n-like Faceted and Spatial search.\n+querying.\n \n Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n whenever the changed data matches the queries.\n \n-[[query_library]]\n-== Embedded Querying\n+== Indexing", "originalCommit": "906c35551245e100d474ad1d7f9c69c220014f56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTc5NTYxMQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r435795611", "bodyText": "That's a good point. We should document that indexing is on the cache values.", "author": "gustavonalle", "createdAt": "2020-06-05T09:16:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk3MTY0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk3NjI5MA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r433976290", "bodyText": "One general comment is that admonitions should take the format of:\n[NOTE]\nNote text goes here.\nAlso this note seems to add complexity to a shortcut for users. Why don't we update the attribute to \"true\" in the XSD?\nAs this doc is going to be merged for v11 I don't think we need that last sentence.", "author": "oraNod", "createdAt": "2020-06-02T15:43:48Z", "path": "documentation/src/main/asciidoc/topics/query.adoc", "diffHunk": "@@ -18,480 +18,570 @@ Apart from indexed queries, {brandname} can run queries over non-indexed or\n partially indexed data.\n \n In terms of Search APIs, {brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text\n-querying. The link:#query_dsl[Query DSL] can be used for both embedded and remote java clients when full-text is not required; for Java embedded clients\n-{brandname} offers the link:#query_hibernatesearch[Hibernate Search Query API] which supports running Lucene queries in the grid, apart from advanced search capabilities\n-like Faceted and Spatial search.\n+querying.\n \n Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n whenever the changed data matches the queries.\n \n-[[query_library]]\n-== Embedded Querying\n+== Indexing\n \n-Embedded querying is available when {brandname} is used as a library. No protobuf mapping is required, and both indexing and searching\n-are done on top of Java objects. When in library mode, it is possible to run Lucene queries directly and use all the available link:#query_apis[Query APIs] and it also allows flexible indexing configurations to keep latency to a minimal.\n+Indexing in {brandname} happens on a per-cache basis and by default a cache is not indexed. Enabling indexing is not mandatory but queries using an index will\n+have a vastly superior performance. On the other hand, enabling indexing can impact negatively the write throughput of a cluster, so make sure to check the link:#query_performance[query performance guide] for some strategies to minimize this impact depending on the cache type and use case.\n \n-=== Quick example\n+NOTE: When using the full-text operator (:) or any other full-text feature, indexing is mandatory. {brandname} will\n+throw an error if a full-text query is attempted in a non-indexed cache.\n \n-We're going to store _Book_ instances in an {brandname} cache called \"books\". _Book_ instances will be indexed, so we enable indexing for the cache,\n-letting {brandname} link:#query_autoconfig[configure the indexing automatically]:\n+=== Configuration\n \n-{brandname} configuration:\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+NOTE: The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.", "originalCommit": "906c35551245e100d474ad1d7f9c69c220014f56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTc5ODY5MA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r435798690", "bodyText": "Let's not change the config now :)", "author": "gustavonalle", "createdAt": "2020-06-05T09:22:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk3NjI5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk3Nzg2NA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r433977864", "bodyText": "Here as well, I'd just say: \"You must invoke the enable() method to programmatically enable indexing.\"", "author": "oraNod", "createdAt": "2020-06-02T15:45:23Z", "path": "documentation/src/main/asciidoc/topics/query.adoc", "diffHunk": "@@ -18,480 +18,570 @@ Apart from indexed queries, {brandname} can run queries over non-indexed or\n partially indexed data.\n \n In terms of Search APIs, {brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text\n-querying. The link:#query_dsl[Query DSL] can be used for both embedded and remote java clients when full-text is not required; for Java embedded clients\n-{brandname} offers the link:#query_hibernatesearch[Hibernate Search Query API] which supports running Lucene queries in the grid, apart from advanced search capabilities\n-like Faceted and Spatial search.\n+querying.\n \n Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n whenever the changed data matches the queries.\n \n-[[query_library]]\n-== Embedded Querying\n+== Indexing\n \n-Embedded querying is available when {brandname} is used as a library. No protobuf mapping is required, and both indexing and searching\n-are done on top of Java objects. When in library mode, it is possible to run Lucene queries directly and use all the available link:#query_apis[Query APIs] and it also allows flexible indexing configurations to keep latency to a minimal.\n+Indexing in {brandname} happens on a per-cache basis and by default a cache is not indexed. Enabling indexing is not mandatory but queries using an index will\n+have a vastly superior performance. On the other hand, enabling indexing can impact negatively the write throughput of a cluster, so make sure to check the link:#query_performance[query performance guide] for some strategies to minimize this impact depending on the cache type and use case.\n \n-=== Quick example\n+NOTE: When using the full-text operator (:) or any other full-text feature, indexing is mandatory. {brandname} will\n+throw an error if a full-text query is attempted in a non-indexed cache.\n \n-We're going to store _Book_ instances in an {brandname} cache called \"books\". _Book_ instances will be indexed, so we enable indexing for the cache,\n-letting {brandname} link:#query_autoconfig[configure the indexing automatically]:\n+=== Configuration\n \n-{brandname} configuration:\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+NOTE: The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n \n-.infinispan.xml\n [source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-include::config_examples/infinispan_distributed_cache_books.xml[]\n+include::config_examples/indexing.xml[]\n ----\n \n-Obtaining the cache:\n+Programmatic:\n \n [source,java]\n ----\n-import org.infinispan.Cache;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-\n-EmbeddedCacheManager manager = new DefaultCacheManager(\"infinispan.xml\");\n-Cache<String, Book> cache = manager.getCache(\"books\");\n+import org.infinispan.configuration.cache.*;\n \n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n ----\n \n-Each _Book_ will be defined as in the following example; we have to choose which properties are indexed, and for each property we can optionally choose advanced indexing options using the annotations defined in the Hibernate Search project.\n-\n-[source,java]\n-.Book.java\n-----\n-import org.hibernate.search.annotations.*;\n-import java.util.Date;\n-import java.util.HashSet;\n-import java.util.Set;\n+NOTE: When using programmatic configuration, indexing must be enabled explicitly by invoking the `enable()` method, as\n+no auto-enabling mechanism exist for programmatic configuration as in the case of XML configuration.", "originalCommit": "906c35551245e100d474ad1d7f9c69c220014f56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk4Mjk0Ng==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r433982946", "bodyText": "I wonder if we could say \"You should declare indexed types because {brandname} ...\" then briefly explain why they will be mandatory in the next version.\nIt seems like we're adding a bit of maintenance overhead in the docs here too. This statement will need to be updated for 12 so might as well try to make the reason clear now.", "author": "oraNod", "createdAt": "2020-06-02T15:50:30Z", "path": "documentation/src/main/asciidoc/topics/query.adoc", "diffHunk": "@@ -18,480 +18,570 @@ Apart from indexed queries, {brandname} can run queries over non-indexed or\n partially indexed data.\n \n In terms of Search APIs, {brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text\n-querying. The link:#query_dsl[Query DSL] can be used for both embedded and remote java clients when full-text is not required; for Java embedded clients\n-{brandname} offers the link:#query_hibernatesearch[Hibernate Search Query API] which supports running Lucene queries in the grid, apart from advanced search capabilities\n-like Faceted and Spatial search.\n+querying.\n \n Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n whenever the changed data matches the queries.\n \n-[[query_library]]\n-== Embedded Querying\n+== Indexing\n \n-Embedded querying is available when {brandname} is used as a library. No protobuf mapping is required, and both indexing and searching\n-are done on top of Java objects. When in library mode, it is possible to run Lucene queries directly and use all the available link:#query_apis[Query APIs] and it also allows flexible indexing configurations to keep latency to a minimal.\n+Indexing in {brandname} happens on a per-cache basis and by default a cache is not indexed. Enabling indexing is not mandatory but queries using an index will\n+have a vastly superior performance. On the other hand, enabling indexing can impact negatively the write throughput of a cluster, so make sure to check the link:#query_performance[query performance guide] for some strategies to minimize this impact depending on the cache type and use case.\n \n-=== Quick example\n+NOTE: When using the full-text operator (:) or any other full-text feature, indexing is mandatory. {brandname} will\n+throw an error if a full-text query is attempted in a non-indexed cache.\n \n-We're going to store _Book_ instances in an {brandname} cache called \"books\". _Book_ instances will be indexed, so we enable indexing for the cache,\n-letting {brandname} link:#query_autoconfig[configure the indexing automatically]:\n+=== Configuration\n \n-{brandname} configuration:\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+NOTE: The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n \n-.infinispan.xml\n [source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-include::config_examples/infinispan_distributed_cache_books.xml[]\n+include::config_examples/indexing.xml[]\n ----\n \n-Obtaining the cache:\n+Programmatic:\n \n [source,java]\n ----\n-import org.infinispan.Cache;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-\n-EmbeddedCacheManager manager = new DefaultCacheManager(\"infinispan.xml\");\n-Cache<String, Book> cache = manager.getCache(\"books\");\n+import org.infinispan.configuration.cache.*;\n \n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n ----\n \n-Each _Book_ will be defined as in the following example; we have to choose which properties are indexed, and for each property we can optionally choose advanced indexing options using the annotations defined in the Hibernate Search project.\n-\n-[source,java]\n-.Book.java\n-----\n-import org.hibernate.search.annotations.*;\n-import java.util.Date;\n-import java.util.HashSet;\n-import java.util.Set;\n+NOTE: When using programmatic configuration, indexing must be enabled explicitly by invoking the `enable()` method, as\n+no auto-enabling mechanism exist for programmatic configuration as in the case of XML configuration.\n \n-//Values you want to index need to be annotated with @Indexed, then you pick which fields and how they are to be indexed:\n-@Indexed\n-public class Book {\n-   @Field String title;\n-   @Field String description;\n-   @Field @DateBridge(resolution=Resolution.YEAR) Date publicationYear;\n-   @IndexedEmbedded Set<Author> authors = new HashSet<Author>();\n-}\n+=== Specifying indexed Entities\n \n-----\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+This can be done via xml:", "originalCommit": "906c35551245e100d474ad1d7f9c69c220014f56", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTgwMTk1OA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r435801958", "bodyText": "why they will be mandatory in the next version.\n\nBecause we're moving away from it not being mandatory :)\nI would not worry about maintenance overhead of the query docs, it will suffer major changes in ISPN 12 as well", "author": "gustavonalle", "createdAt": "2020-06-05T09:28:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk4Mjk0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk4NjE5Mg==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r433986192", "bodyText": "One thing we've been doing elsewhere in docs, like marshalling, is to separate declarative and programmatic examples like this:\n.Declaratively\nxml snippet goes here\n.Programmatically\ncode snippet goes here", "author": "oraNod", "createdAt": "2020-06-02T15:53:38Z", "path": "documentation/src/main/asciidoc/topics/query.adoc", "diffHunk": "@@ -18,480 +18,570 @@ Apart from indexed queries, {brandname} can run queries over non-indexed or\n partially indexed data.\n \n In terms of Search APIs, {brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text\n-querying. The link:#query_dsl[Query DSL] can be used for both embedded and remote java clients when full-text is not required; for Java embedded clients\n-{brandname} offers the link:#query_hibernatesearch[Hibernate Search Query API] which supports running Lucene queries in the grid, apart from advanced search capabilities\n-like Faceted and Spatial search.\n+querying.\n \n Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n whenever the changed data matches the queries.\n \n-[[query_library]]\n-== Embedded Querying\n+== Indexing\n \n-Embedded querying is available when {brandname} is used as a library. No protobuf mapping is required, and both indexing and searching\n-are done on top of Java objects. When in library mode, it is possible to run Lucene queries directly and use all the available link:#query_apis[Query APIs] and it also allows flexible indexing configurations to keep latency to a minimal.\n+Indexing in {brandname} happens on a per-cache basis and by default a cache is not indexed. Enabling indexing is not mandatory but queries using an index will\n+have a vastly superior performance. On the other hand, enabling indexing can impact negatively the write throughput of a cluster, so make sure to check the link:#query_performance[query performance guide] for some strategies to minimize this impact depending on the cache type and use case.\n \n-=== Quick example\n+NOTE: When using the full-text operator (:) or any other full-text feature, indexing is mandatory. {brandname} will\n+throw an error if a full-text query is attempted in a non-indexed cache.\n \n-We're going to store _Book_ instances in an {brandname} cache called \"books\". _Book_ instances will be indexed, so we enable indexing for the cache,\n-letting {brandname} link:#query_autoconfig[configure the indexing automatically]:\n+=== Configuration\n \n-{brandname} configuration:\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+NOTE: The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n \n-.infinispan.xml\n [source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-include::config_examples/infinispan_distributed_cache_books.xml[]\n+include::config_examples/indexing.xml[]\n ----\n \n-Obtaining the cache:\n+Programmatic:\n \n [source,java]\n ----\n-import org.infinispan.Cache;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-\n-EmbeddedCacheManager manager = new DefaultCacheManager(\"infinispan.xml\");\n-Cache<String, Book> cache = manager.getCache(\"books\");\n+import org.infinispan.configuration.cache.*;\n \n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n ----\n \n-Each _Book_ will be defined as in the following example; we have to choose which properties are indexed, and for each property we can optionally choose advanced indexing options using the annotations defined in the Hibernate Search project.\n-\n-[source,java]\n-.Book.java\n-----\n-import org.hibernate.search.annotations.*;\n-import java.util.Date;\n-import java.util.HashSet;\n-import java.util.Set;\n+NOTE: When using programmatic configuration, indexing must be enabled explicitly by invoking the `enable()` method, as\n+no auto-enabling mechanism exist for programmatic configuration as in the case of XML configuration.\n \n-//Values you want to index need to be annotated with @Indexed, then you pick which fields and how they are to be indexed:\n-@Indexed\n-public class Book {\n-   @Field String title;\n-   @Field String description;\n-   @Field @DateBridge(resolution=Resolution.YEAR) Date publicationYear;\n-   @IndexedEmbedded Set<Author> authors = new HashSet<Author>();\n-}\n+=== Specifying indexed Entities\n \n-----\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+This can be done via xml:\n \n-[source,java]\n-.Author.java\n+[source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-\n-public class Author {\n-   @Field String name;\n-   @Field String surname;\n-   // hashCode() and equals() omitted\n-}\n-\n+include::config_examples/indexed_entities.xml[]\n ----\n \n-Now assuming we stored several _Book_ instances in our {brandname} _Cache_ , we can search them for any matching field as in the following example.\n-\n-Using a Lucene Query:\n+or programmatically:", "originalCommit": "906c35551245e100d474ad1d7f9c69c220014f56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk4OTM1MQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r433989351", "bodyText": "How about \"Rebuilding Indexes\"?", "author": "oraNod", "createdAt": "2020-06-02T15:56:45Z", "path": "documentation/src/main/asciidoc/topics/query.adoc", "diffHunk": "@@ -18,480 +18,570 @@ Apart from indexed queries, {brandname} can run queries over non-indexed or\n partially indexed data.\n \n In terms of Search APIs, {brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text\n-querying. The link:#query_dsl[Query DSL] can be used for both embedded and remote java clients when full-text is not required; for Java embedded clients\n-{brandname} offers the link:#query_hibernatesearch[Hibernate Search Query API] which supports running Lucene queries in the grid, apart from advanced search capabilities\n-like Faceted and Spatial search.\n+querying.\n \n Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n whenever the changed data matches the queries.\n \n-[[query_library]]\n-== Embedded Querying\n+== Indexing\n \n-Embedded querying is available when {brandname} is used as a library. No protobuf mapping is required, and both indexing and searching\n-are done on top of Java objects. When in library mode, it is possible to run Lucene queries directly and use all the available link:#query_apis[Query APIs] and it also allows flexible indexing configurations to keep latency to a minimal.\n+Indexing in {brandname} happens on a per-cache basis and by default a cache is not indexed. Enabling indexing is not mandatory but queries using an index will\n+have a vastly superior performance. On the other hand, enabling indexing can impact negatively the write throughput of a cluster, so make sure to check the link:#query_performance[query performance guide] for some strategies to minimize this impact depending on the cache type and use case.\n \n-=== Quick example\n+NOTE: When using the full-text operator (:) or any other full-text feature, indexing is mandatory. {brandname} will\n+throw an error if a full-text query is attempted in a non-indexed cache.\n \n-We're going to store _Book_ instances in an {brandname} cache called \"books\". _Book_ instances will be indexed, so we enable indexing for the cache,\n-letting {brandname} link:#query_autoconfig[configure the indexing automatically]:\n+=== Configuration\n \n-{brandname} configuration:\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+NOTE: The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n \n-.infinispan.xml\n [source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-include::config_examples/infinispan_distributed_cache_books.xml[]\n+include::config_examples/indexing.xml[]\n ----\n \n-Obtaining the cache:\n+Programmatic:\n \n [source,java]\n ----\n-import org.infinispan.Cache;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-\n-EmbeddedCacheManager manager = new DefaultCacheManager(\"infinispan.xml\");\n-Cache<String, Book> cache = manager.getCache(\"books\");\n+import org.infinispan.configuration.cache.*;\n \n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n ----\n \n-Each _Book_ will be defined as in the following example; we have to choose which properties are indexed, and for each property we can optionally choose advanced indexing options using the annotations defined in the Hibernate Search project.\n-\n-[source,java]\n-.Book.java\n-----\n-import org.hibernate.search.annotations.*;\n-import java.util.Date;\n-import java.util.HashSet;\n-import java.util.Set;\n+NOTE: When using programmatic configuration, indexing must be enabled explicitly by invoking the `enable()` method, as\n+no auto-enabling mechanism exist for programmatic configuration as in the case of XML configuration.\n \n-//Values you want to index need to be annotated with @Indexed, then you pick which fields and how they are to be indexed:\n-@Indexed\n-public class Book {\n-   @Field String title;\n-   @Field String description;\n-   @Field @DateBridge(resolution=Resolution.YEAR) Date publicationYear;\n-   @IndexedEmbedded Set<Author> authors = new HashSet<Author>();\n-}\n+=== Specifying indexed Entities\n \n-----\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+This can be done via xml:\n \n-[source,java]\n-.Author.java\n+[source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-\n-public class Author {\n-   @Field String name;\n-   @Field String surname;\n-   // hashCode() and equals() omitted\n-}\n-\n+include::config_examples/indexed_entities.xml[]\n ----\n \n-Now assuming we stored several _Book_ instances in our {brandname} _Cache_ , we can search them for any matching field as in the following example.\n-\n-Using a Lucene Query:\n+or programmatically:\n \n [source,java]\n ----\n-// get the search manager from the cache:\n-SearchManager searchManager = org.infinispan.query.Search.getSearchManager(cache);\n-\n-// create any standard Lucene query, via Lucene's QueryParser or any other means:\n-org.apache.lucene.search.Query fullTextQuery = //any Apache Lucene Query\n-\n-// convert the Lucene query to a CacheQuery:\n-CacheQuery cacheQuery = searchManager.getQuery( fullTextQuery );\n-\n-// get the results:\n-List<Object> found = cacheQuery.list();\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n \n ----\n \n-A Lucene Query is often created by parsing a query in text format such as \"title:infinispan AND authors.name:sanne\", or by using the query builder provided by Hibernate Search.\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n \n-[source,java]\n+[source,proto]\n ----\n-// get the search manager from the cache:\n-SearchManager searchManager = org.infinispan.query.Search.getSearchManager( cache );\n-\n-// you could make the queries via Lucene APIs, or use some helpers:\n-QueryBuilder queryBuilder = searchManager.buildQueryBuilderForClass(Book.class).get();\n-\n-// the queryBuilder has a nice fluent API which guides you through all options.\n-// this has some knowledge about your object, for example which Analyzers\n-// need to be applied, but the output is a fairly standard Lucene Query.\n-org.apache.lucene.search.Query luceneQuery = queryBuilder.phrase()\n-                  .onField(\"description\")\n-                  .andField(\"title\")\n-                  .sentence(\"a book on highly scalable query engines\")\n-                  .createQuery();\n-\n-// the query API itself accepts any Lucene Query, and on top of that\n-// you can restrict the result to selected class types:\n-CacheQuery query = searchManager.getQuery(luceneQuery, Book.class);\n-\n-// and there are your results!\n-List objectList = query.list();\n-\n-for (Object book : objectList) {\n-      System.out.println(book);\n-}\n-\n+include::config_examples/library.proto[]\n ----\n-Apart from _list()_ you have the option for streaming results, or use pagination.\n-\n \n-For searches that do not require Lucene or full-text capabilities and are mostly about aggregation and exact matches, we can use the {brandname} Query DSL API:\n+The config should be:\n \n-[source,java]\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n ----\n-import org.infinispan.query.dsl.QueryFactory;\n-import org.infinispan.query.dsl.Query;\n-import org.infinispan.query.Search;\n \n-// get the query factory:\n-QueryFactory queryFactory = Search.getQueryFactory(cache);\n+[[query_index_storage]]\n+=== Index Storage\n \n-Query q = queryFactory.from(Book.class)\n-            .having(\"author.surname\").eq(\"King\")\n-            .build();\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n \n-List<Book> list = q.list();\n+.Configuration for file system indexes:\n \n+[source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-\n-Finally, we can use an link:#query_ickle[Ickle] query directly, allowing for Lucene syntax in one or more predicates:\n-\n-[source,java]\n+include::config_examples/indexing_filesystem.xml[]\n ----\n-import org.infinispan.query.dsl.QueryFactory;\n-import org.infinispan.query.dsl.Query;\n \n-// get the query factory:\n-QueryFactory queryFactory = Search.getQueryFactory(cache);\n-\n-\n-Query q = queryFactory.create(\"from Book b where b.author.name = 'Stephen' and \" +\n-                \"b.description : (+'dark' -'tower')\");\n-\n-List<Book> list = q.list();\n+.Configuration for memory indexes:\n \n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n ----\n \n-=== Indexing\n-\n-Indexing in {brandname} happens on a per-cache basis and by default a cache is not indexed. Enabling indexing is not mandatory but queries using an index will\n-have a vastly superior performance. On the other hand, enabling indexing can impact negatively the write throughput of a cluster, so make sure to check the link:#query_performance[query performance guide] for some strategies to minimize this impact depending on the cache type and use case.\n+[[query_index_manager]]\n+=== Index Manager\n \n-==== Configuration\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n \n-===== General format\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n \n-To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, and optionally pass additional properties.\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n \n-NOTE: The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n-convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n-This behaviour exists only on schemas starting with version 11.\n+Example with `local-heap`:\n \n [source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-include::config_examples/indexing.xml[]\n+include::config_examples/indexing_near_real_time.xml[]\n ----\n \n-Programmatic:\n+Example with `filesystem`:\n \n-[source,java]\n+[source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-import org.infinispan.configuration.cache.*;\n-\n-ConfigurationBuilder cacheCfg = ...\n-cacheCfg.indexing().enable()\n-      .addProperty(\"property name\", \"propery value\")\n+include::config_examples/indexing_near_real_time_fs.xml[]\n ----\n \n-NOTE: When using programmatic configuration, indexing must be enabled explicitly by invoking the `enable()` method, as\n-no auto-enabling mechanism exist for programmatic configuration as in the case of XML configuration.\n-\n-===== Index names\n-\n-Each property inside the `index` element is prefixed with the index name, for the index named `org.infinispan.sample.Car` the `directory_provider` is `local-heap`:\n+[[query_massindexer]]\n+=== Re-indexing", "originalCommit": "906c35551245e100d474ad1d7f9c69c220014f56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzk5NTYxNg==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r433995616", "bodyText": "s/indexs/indexes\ncache should be lowercase. I'd also try to cut down on the word count here. \"Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like definitions of indexed types or Analyzer parameters. Likewise you might need to rebuild indexes if they are deleted for some reason.\"", "author": "oraNod", "createdAt": "2020-06-02T16:03:05Z", "path": "documentation/src/main/asciidoc/topics/query.adoc", "diffHunk": "@@ -18,480 +18,570 @@ Apart from indexed queries, {brandname} can run queries over non-indexed or\n partially indexed data.\n \n In terms of Search APIs, {brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text\n-querying. The link:#query_dsl[Query DSL] can be used for both embedded and remote java clients when full-text is not required; for Java embedded clients\n-{brandname} offers the link:#query_hibernatesearch[Hibernate Search Query API] which supports running Lucene queries in the grid, apart from advanced search capabilities\n-like Faceted and Spatial search.\n+querying.\n \n Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n whenever the changed data matches the queries.\n \n-[[query_library]]\n-== Embedded Querying\n+== Indexing\n \n-Embedded querying is available when {brandname} is used as a library. No protobuf mapping is required, and both indexing and searching\n-are done on top of Java objects. When in library mode, it is possible to run Lucene queries directly and use all the available link:#query_apis[Query APIs] and it also allows flexible indexing configurations to keep latency to a minimal.\n+Indexing in {brandname} happens on a per-cache basis and by default a cache is not indexed. Enabling indexing is not mandatory but queries using an index will\n+have a vastly superior performance. On the other hand, enabling indexing can impact negatively the write throughput of a cluster, so make sure to check the link:#query_performance[query performance guide] for some strategies to minimize this impact depending on the cache type and use case.\n \n-=== Quick example\n+NOTE: When using the full-text operator (:) or any other full-text feature, indexing is mandatory. {brandname} will\n+throw an error if a full-text query is attempted in a non-indexed cache.\n \n-We're going to store _Book_ instances in an {brandname} cache called \"books\". _Book_ instances will be indexed, so we enable indexing for the cache,\n-letting {brandname} link:#query_autoconfig[configure the indexing automatically]:\n+=== Configuration\n \n-{brandname} configuration:\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+NOTE: The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n \n-.infinispan.xml\n [source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-include::config_examples/infinispan_distributed_cache_books.xml[]\n+include::config_examples/indexing.xml[]\n ----\n \n-Obtaining the cache:\n+Programmatic:\n \n [source,java]\n ----\n-import org.infinispan.Cache;\n-import org.infinispan.manager.DefaultCacheManager;\n-import org.infinispan.manager.EmbeddedCacheManager;\n-\n-EmbeddedCacheManager manager = new DefaultCacheManager(\"infinispan.xml\");\n-Cache<String, Book> cache = manager.getCache(\"books\");\n+import org.infinispan.configuration.cache.*;\n \n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n ----\n \n-Each _Book_ will be defined as in the following example; we have to choose which properties are indexed, and for each property we can optionally choose advanced indexing options using the annotations defined in the Hibernate Search project.\n-\n-[source,java]\n-.Book.java\n-----\n-import org.hibernate.search.annotations.*;\n-import java.util.Date;\n-import java.util.HashSet;\n-import java.util.Set;\n+NOTE: When using programmatic configuration, indexing must be enabled explicitly by invoking the `enable()` method, as\n+no auto-enabling mechanism exist for programmatic configuration as in the case of XML configuration.\n \n-//Values you want to index need to be annotated with @Indexed, then you pick which fields and how they are to be indexed:\n-@Indexed\n-public class Book {\n-   @Field String title;\n-   @Field String description;\n-   @Field @DateBridge(resolution=Resolution.YEAR) Date publicationYear;\n-   @IndexedEmbedded Set<Author> authors = new HashSet<Author>();\n-}\n+=== Specifying indexed Entities\n \n-----\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+This can be done via xml:\n \n-[source,java]\n-.Author.java\n+[source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-\n-public class Author {\n-   @Field String name;\n-   @Field String surname;\n-   // hashCode() and equals() omitted\n-}\n-\n+include::config_examples/indexed_entities.xml[]\n ----\n \n-Now assuming we stored several _Book_ instances in our {brandname} _Cache_ , we can search them for any matching field as in the following example.\n-\n-Using a Lucene Query:\n+or programmatically:\n \n [source,java]\n ----\n-// get the search manager from the cache:\n-SearchManager searchManager = org.infinispan.query.Search.getSearchManager(cache);\n-\n-// create any standard Lucene query, via Lucene's QueryParser or any other means:\n-org.apache.lucene.search.Query fullTextQuery = //any Apache Lucene Query\n-\n-// convert the Lucene query to a CacheQuery:\n-CacheQuery cacheQuery = searchManager.getQuery( fullTextQuery );\n-\n-// get the results:\n-List<Object> found = cacheQuery.list();\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n \n ----\n \n-A Lucene Query is often created by parsing a query in text format such as \"title:infinispan AND authors.name:sanne\", or by using the query builder provided by Hibernate Search.\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n \n-[source,java]\n+[source,proto]\n ----\n-// get the search manager from the cache:\n-SearchManager searchManager = org.infinispan.query.Search.getSearchManager( cache );\n-\n-// you could make the queries via Lucene APIs, or use some helpers:\n-QueryBuilder queryBuilder = searchManager.buildQueryBuilderForClass(Book.class).get();\n-\n-// the queryBuilder has a nice fluent API which guides you through all options.\n-// this has some knowledge about your object, for example which Analyzers\n-// need to be applied, but the output is a fairly standard Lucene Query.\n-org.apache.lucene.search.Query luceneQuery = queryBuilder.phrase()\n-                  .onField(\"description\")\n-                  .andField(\"title\")\n-                  .sentence(\"a book on highly scalable query engines\")\n-                  .createQuery();\n-\n-// the query API itself accepts any Lucene Query, and on top of that\n-// you can restrict the result to selected class types:\n-CacheQuery query = searchManager.getQuery(luceneQuery, Book.class);\n-\n-// and there are your results!\n-List objectList = query.list();\n-\n-for (Object book : objectList) {\n-      System.out.println(book);\n-}\n-\n+include::config_examples/library.proto[]\n ----\n-Apart from _list()_ you have the option for streaming results, or use pagination.\n-\n \n-For searches that do not require Lucene or full-text capabilities and are mostly about aggregation and exact matches, we can use the {brandname} Query DSL API:\n+The config should be:\n \n-[source,java]\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n ----\n-import org.infinispan.query.dsl.QueryFactory;\n-import org.infinispan.query.dsl.Query;\n-import org.infinispan.query.Search;\n \n-// get the query factory:\n-QueryFactory queryFactory = Search.getQueryFactory(cache);\n+[[query_index_storage]]\n+=== Index Storage\n \n-Query q = queryFactory.from(Book.class)\n-            .having(\"author.surname\").eq(\"King\")\n-            .build();\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n \n-List<Book> list = q.list();\n+.Configuration for file system indexes:\n \n+[source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-\n-Finally, we can use an link:#query_ickle[Ickle] query directly, allowing for Lucene syntax in one or more predicates:\n-\n-[source,java]\n+include::config_examples/indexing_filesystem.xml[]\n ----\n-import org.infinispan.query.dsl.QueryFactory;\n-import org.infinispan.query.dsl.Query;\n \n-// get the query factory:\n-QueryFactory queryFactory = Search.getQueryFactory(cache);\n-\n-\n-Query q = queryFactory.create(\"from Book b where b.author.name = 'Stephen' and \" +\n-                \"b.description : (+'dark' -'tower')\");\n-\n-List<Book> list = q.list();\n+.Configuration for memory indexes:\n \n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n ----\n \n-=== Indexing\n-\n-Indexing in {brandname} happens on a per-cache basis and by default a cache is not indexed. Enabling indexing is not mandatory but queries using an index will\n-have a vastly superior performance. On the other hand, enabling indexing can impact negatively the write throughput of a cluster, so make sure to check the link:#query_performance[query performance guide] for some strategies to minimize this impact depending on the cache type and use case.\n+[[query_index_manager]]\n+=== Index Manager\n \n-==== Configuration\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n \n-===== General format\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n \n-To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, and optionally pass additional properties.\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n \n-NOTE: The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n-convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n-This behaviour exists only on schemas starting with version 11.\n+Example with `local-heap`:\n \n [source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-include::config_examples/indexing.xml[]\n+include::config_examples/indexing_near_real_time.xml[]\n ----\n \n-Programmatic:\n+Example with `filesystem`:\n \n-[source,java]\n+[source,xml,options=\"nowrap\",subs=attributes+]\n ----\n-import org.infinispan.configuration.cache.*;\n-\n-ConfigurationBuilder cacheCfg = ...\n-cacheCfg.indexing().enable()\n-      .addProperty(\"property name\", \"propery value\")\n+include::config_examples/indexing_near_real_time_fs.xml[]\n ----\n \n-NOTE: When using programmatic configuration, indexing must be enabled explicitly by invoking the `enable()` method, as\n-no auto-enabling mechanism exist for programmatic configuration as in the case of XML configuration.\n-\n-===== Index names\n-\n-Each property inside the `index` element is prefixed with the index name, for the index named `org.infinispan.sample.Car` the `directory_provider` is `local-heap`:\n+[[query_massindexer]]\n+=== Re-indexing\n \n-[source,xml,options=\"nowrap\",subs=attributes+]\n-----\n-include::config_examples/indexing_property.xml[]\n-----\n+Occasionally you might need to rebuild the indexs by reconstructing it from the data stored in the Cache. You need to rebuild the index if you change the definition of what is indexed on your types, or if you change for example some _Analyzer_ parameter, as Analyzers affect how the index is written. Also, you might need to rebuild the index if you had it destroyed by some system administration mistake. To rebuild the index just get a reference to the Indexer and start it; beware it might take some time as it needs to reprocess all data in the grid!", "originalCommit": "906c35551245e100d474ad1d7f9c69c220014f56", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "9d2f00c69a659db1aa4ba37fa151dbf23dff1a1f", "url": "https://github.com/infinispan/infinispan/commit/9d2f00c69a659db1aa4ba37fa151dbf23dff1a1f", "message": "Addressed reviews", "committedDate": "2020-06-05T09:45:55Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzMzNDEwMg==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437334102", "bodyText": "Notes, tips, and warnings should follow the format defined here https://infinispan.org/docs/11.0.x/titles/contributing/contributing.html#documentation_guidelines_format_reference\n[NOTE]\n====\nThis is a note that you should read.\n====", "author": "oraNod", "createdAt": "2020-06-09T11:23:14Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1096 @@\n+[[indexing_searching]]\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} supports indexing and searching of cache values stored as Java Pojo(s) or objects encoded via link:https://developers.google.com/protocol-buffers/[Protocol Buffers], using a powerful search API which complement its main Map-like API.\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+[NOTE]\n+====\n+You must invoke the `enable()` method to programmatically enable indexing\n+====\n+\n+=== Specifying indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+\n+NOTE: A query will always target a single entity type and is evaluated over the contents of a single cache. Running a", "originalCommit": "9d2f00c69a659db1aa4ba37fa151dbf23dff1a1f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzMzNjUwNw==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437336507", "bodyText": "There is a comma splice in the sentence. Also avoid adjectives such as \"powerful\" because they don't really add meaning and are subjective.\nHow about something like this: \"{brandname} provides a search API that lets you index and search cache values stored as Java POJOs or as objects encoded as Protocol Buffers.\"", "author": "oraNod", "createdAt": "2020-06-09T11:28:16Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1096 @@\n+[[indexing_searching]]\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} supports indexing and searching of cache values stored as Java Pojo(s) or objects encoded via link:https://developers.google.com/protocol-buffers/[Protocol Buffers], using a powerful search API which complement its main Map-like API.", "originalCommit": "9d2f00c69a659db1aa4ba37fa151dbf23dff1a1f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQwMzY4NA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437403684", "bodyText": "Also avoid adjectives such as \"powerful\" because they don't really add meaning and are subjective.\n\nWhat about \"Mighty\" ?  :)\nJust kidding, this has been in the guide for ages, I don't mind removing it", "author": "gustavonalle", "createdAt": "2020-06-09T13:10:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzMzNjUwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQxMDcxNQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437410715", "bodyText": "yeah I've seen powerful in the docs before. I should probably grep and kill any remaining instances.", "author": "oraNod", "createdAt": "2020-06-09T13:20:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzMzNjUwNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQxNDg4Nw==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437414887", "bodyText": "", "author": "gustavonalle", "createdAt": "2020-06-09T13:26:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzMzNjUwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzMzODAzNg==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437338036", "bodyText": "I'm not sure if this note is strictly necessary given that you should the enable() method in the code snippet. One idea might be to add callouts to the code block. https://asciidoctor.org/docs/user-manual/#callouts", "author": "oraNod", "createdAt": "2020-06-09T11:31:29Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1096 @@\n+[[indexing_searching]]\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} supports indexing and searching of cache values stored as Java Pojo(s) or objects encoded via link:https://developers.google.com/protocol-buffers/[Protocol Buffers], using a powerful search API which complement its main Map-like API.\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+[NOTE]\n+====\n+You must invoke the `enable()` method to programmatically enable indexing\n+====", "originalCommit": "9d2f00c69a659db1aa4ba37fa151dbf23dff1a1f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQwNzEzNg==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437407136", "bodyText": "This is because there are some differences to the programmatic config where enabled can be omitted. I will clarify the note", "author": "gustavonalle", "createdAt": "2020-06-09T13:15:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzMzODAzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzMzODQ2Mg==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437338462", "bodyText": "Inconsistent casing. \"Specifying Indexed Entities\"", "author": "oraNod", "createdAt": "2020-06-09T11:32:20Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1096 @@\n+[[indexing_searching]]\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} supports indexing and searching of cache values stored as Java Pojo(s) or objects encoded via link:https://developers.google.com/protocol-buffers/[Protocol Buffers], using a powerful search API which complement its main Map-like API.\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+[NOTE]\n+====\n+You must invoke the `enable()` method to programmatically enable indexing\n+====\n+\n+=== Specifying indexed Entities", "originalCommit": "9d2f00c69a659db1aa4ba37fa151dbf23dff1a1f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzMzOTM4MA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437339380", "bodyText": "Consider saying what is supported, rather than what is not supported. Possibly: \"Iteration is possible only when using {brandname} as an embedded library.\"", "author": "oraNod", "createdAt": "2020-06-09T11:34:18Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1096 @@\n+[[indexing_searching]]\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} supports indexing and searching of cache values stored as Java Pojo(s) or objects encoded via link:https://developers.google.com/protocol-buffers/[Protocol Buffers], using a powerful search API which complement its main Map-like API.\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+[NOTE]\n+====\n+You must invoke the `enable()` method to programmatically enable indexing\n+====\n+\n+=== Specifying indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+\n+NOTE: A query will always target a single entity type and is evaluated over the contents of a single cache. Running a\n+query over multiple caches or creating queries that target several entity types (joins) is not supported.\n+\n+Executing the query and fetching the results is as simple as invoking the `run()` method of the _Query_ object. Once\n+executed, calling `run()` on the same instance will re-execute the query.\n+\n+=== Pagination\n+\n+You can limit the number of returned results by using  the `Query.maxResults(int maxResults)`. This can be used in\n+conjunction with `Query.startOffset(long startOffset)` to achieve pagination of the result set.\n+\n+[source,java]\n+----\n+// sorted by year and match all books that have \"clustering\" in their title\n+// and return the third page of 10 results\n+Query<Book> query = queryFactory.create(\"FROM com.acme.Book WHERE title like '%clustering%' ORDER BY year\").startOffset(20).maxResults(10)\n+----\n+\n+=== Number of Hits\n+\n+The `QueryResult` object has the `.hitCount()` method to return the total number of results of the query, regardless\n+of any pagination parameter. The hit count is only available for indexed queries for performance reasons.\n+\n+\n+=== Iteration\n+\n+The `Query` object has the `.iterator()` method to obtain the results lazily. It returns an instance of `CloseableIterator` that\n+must be closed after usage.\n+\n+NOTE: Iteration is not currently implemented for Remote Queries", "originalCommit": "9d2f00c69a659db1aa4ba37fa151dbf23dff1a1f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQxMjAxNw==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437412017", "bodyText": "This is already outdated, this feature is now \"emulated\"", "author": "gustavonalle", "createdAt": "2020-06-09T13:22:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzMzOTM4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM0MTg4MA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437341880", "bodyText": "It's preferable to address the reader directly and use active voice construction with verb phrases.\n\"may be set at once\" uses passive voice and obscures the person/thing that performs the action. Also \"may\" is a modal verb that implies permission more than possibility. It's generally better to prefer \"can\" or \"might\" to \"may\".\nConsider revising as follows: \"Alternatively, you can supply a map of actual parameter values to set multiple parameters at once\"", "author": "oraNod", "createdAt": "2020-06-09T11:38:57Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1096 @@\n+[[indexing_searching]]\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} supports indexing and searching of cache values stored as Java Pojo(s) or objects encoded via link:https://developers.google.com/protocol-buffers/[Protocol Buffers], using a powerful search API which complement its main Map-like API.\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+[NOTE]\n+====\n+You must invoke the `enable()` method to programmatically enable indexing\n+====\n+\n+=== Specifying indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+\n+NOTE: A query will always target a single entity type and is evaluated over the contents of a single cache. Running a\n+query over multiple caches or creating queries that target several entity types (joins) is not supported.\n+\n+Executing the query and fetching the results is as simple as invoking the `run()` method of the _Query_ object. Once\n+executed, calling `run()` on the same instance will re-execute the query.\n+\n+=== Pagination\n+\n+You can limit the number of returned results by using  the `Query.maxResults(int maxResults)`. This can be used in\n+conjunction with `Query.startOffset(long startOffset)` to achieve pagination of the result set.\n+\n+[source,java]\n+----\n+// sorted by year and match all books that have \"clustering\" in their title\n+// and return the third page of 10 results\n+Query<Book> query = queryFactory.create(\"FROM com.acme.Book WHERE title like '%clustering%' ORDER BY year\").startOffset(20).maxResults(10)\n+----\n+\n+=== Number of Hits\n+\n+The `QueryResult` object has the `.hitCount()` method to return the total number of results of the query, regardless\n+of any pagination parameter. The hit count is only available for indexed queries for performance reasons.\n+\n+\n+=== Iteration\n+\n+The `Query` object has the `.iterator()` method to obtain the results lazily. It returns an instance of `CloseableIterator` that\n+must be closed after usage.\n+\n+NOTE: Iteration is not currently implemented for Remote Queries\n+\n+=== Using Named Query Parameters\n+\n+Instead of building a new Query object for every execution it is possible to include named parameters in the query which\n+can be substituted with actual values before execution. This allows a query to be defined once and be efficiently\n+executed many times. Parameters can only be used on the right-hand side of an operator and are defined when the query is\n+created by supplying an object produced by the _org.infinispan.query.dsl.Expression.param(String paramName)_ method to\n+the operator instead of the usual constant value. Once the parameters have been defined they can be set by invoking either\n+_Query.setParameter(parameterName, value)_ or _Query.setParameters(parameterMap)_ as shown in the examples below.\n+\u2060\n+[source,java,tile=\"Using Named Parameters\"]\n+----\n+QueryFactory queryFactory = Search.getQueryFactory(cache);\n+// Defining a query to search for various authors and publication years\n+Query<Book> query = queryFactory.create(\"SELECT title FROM com.acme.Book WHERE author = :authorName AND publicationYear = :publicationYear\").build();\n+\n+// Set actual parameter values\n+query.setParameter(\"authorName\", \"Doe\");\n+query.setParameter(\"publicationYear\", 2010);\n+\n+// Execute the query\n+List<Book> found = query.list();\n+----\n+\n+Alternatively, multiple parameters may be set at once by supplying a map of actual parameter values:", "originalCommit": "9d2f00c69a659db1aa4ba37fa151dbf23dff1a1f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM0MjkyOQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437342929", "bodyText": "I'd leave out the \"since 10.0\" because it doesn't work downstream. Also users probably don't care about the since so much as the fact it is deprecated.", "author": "oraNod", "createdAt": "2020-06-09T11:40:53Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1096 @@\n+[[indexing_searching]]\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} supports indexing and searching of cache values stored as Java Pojo(s) or objects encoded via link:https://developers.google.com/protocol-buffers/[Protocol Buffers], using a powerful search API which complement its main Map-like API.\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+[NOTE]\n+====\n+You must invoke the `enable()` method to programmatically enable indexing\n+====\n+\n+=== Specifying indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+\n+NOTE: A query will always target a single entity type and is evaluated over the contents of a single cache. Running a\n+query over multiple caches or creating queries that target several entity types (joins) is not supported.\n+\n+Executing the query and fetching the results is as simple as invoking the `run()` method of the _Query_ object. Once\n+executed, calling `run()` on the same instance will re-execute the query.\n+\n+=== Pagination\n+\n+You can limit the number of returned results by using  the `Query.maxResults(int maxResults)`. This can be used in\n+conjunction with `Query.startOffset(long startOffset)` to achieve pagination of the result set.\n+\n+[source,java]\n+----\n+// sorted by year and match all books that have \"clustering\" in their title\n+// and return the third page of 10 results\n+Query<Book> query = queryFactory.create(\"FROM com.acme.Book WHERE title like '%clustering%' ORDER BY year\").startOffset(20).maxResults(10)\n+----\n+\n+=== Number of Hits\n+\n+The `QueryResult` object has the `.hitCount()` method to return the total number of results of the query, regardless\n+of any pagination parameter. The hit count is only available for indexed queries for performance reasons.\n+\n+\n+=== Iteration\n+\n+The `Query` object has the `.iterator()` method to obtain the results lazily. It returns an instance of `CloseableIterator` that\n+must be closed after usage.\n+\n+NOTE: Iteration is not currently implemented for Remote Queries\n+\n+=== Using Named Query Parameters\n+\n+Instead of building a new Query object for every execution it is possible to include named parameters in the query which\n+can be substituted with actual values before execution. This allows a query to be defined once and be efficiently\n+executed many times. Parameters can only be used on the right-hand side of an operator and are defined when the query is\n+created by supplying an object produced by the _org.infinispan.query.dsl.Expression.param(String paramName)_ method to\n+the operator instead of the usual constant value. Once the parameters have been defined they can be set by invoking either\n+_Query.setParameter(parameterName, value)_ or _Query.setParameters(parameterMap)_ as shown in the examples below.\n+\u2060\n+[source,java,tile=\"Using Named Parameters\"]\n+----\n+QueryFactory queryFactory = Search.getQueryFactory(cache);\n+// Defining a query to search for various authors and publication years\n+Query<Book> query = queryFactory.create(\"SELECT title FROM com.acme.Book WHERE author = :authorName AND publicationYear = :publicationYear\").build();\n+\n+// Set actual parameter values\n+query.setParameter(\"authorName\", \"Doe\");\n+query.setParameter(\"publicationYear\", 2010);\n+\n+// Execute the query\n+List<Book> found = query.list();\n+----\n+\n+Alternatively, multiple parameters may be set at once by supplying a map of actual parameter values:\n+\u2060\n+[source,java,title=\"Setting multiple named parameters at once\"]\n+----\n+Map<String, Object> parameterMap = new HashMap<>();\n+parameterMap.put(\"authorName\", \"Doe\");\n+parameterMap.put(\"publicationYear\", 2010);\n+\n+query.setParameters(parameterMap);\n+----\n+\n+NOTE: A significant portion of the query parsing, validation and execution planning effort is performed during the first\n+execution of a query with parameters. This effort is not repeated during subsequent executions leading to better\n+performance compared to a similar query using constant values instead of query parameters.\n+\n+[[query_ickle]]\n+=== Ickle Query Language Parser Syntax\n+\n+The Ickle query language is small subset of the link:https://en.wikipedia.org/wiki/Java_Persistence_Query_Language[JPQL]\n+query language, with some extensions for full-text.\n+\n+The parser syntax has some notable rules:\n+\n+* Whitespace is not significant.\n+* Wildcards are not supported in field names.\n+* A field name or path must always be specified, as there is no default field.\n+* `&&` and `||` are accepted instead of `AND` or `OR` in both full-text and JPA predicates.\n+* `!` may be used instead of `NOT`.\n+* A missing boolean operator is interpreted as `OR`.\n+* String terms must be enclosed with either single or double quotes.\n+* Fuzziness and boosting are not accepted in arbitrary order; fuzziness always comes first.\n+* `!=` is accepted instead of `<>`.\n+* Boosting cannot be applied to `>`,`>=`,`<`,`<=` operators. Ranges may be used to achieve the same result.\n+\n+==== Filtering operators\n+\n+Ickle support many filtering operators that can be used for both indexed and non-indexed fields.\n+\n+[options=\"header\"]\n+|==============================================================================\n+| Operator | Description | Example\n+| in | Checks that the left operand is equal to one of the elements from the Collection of values given as argument.\n+|FROM Book WHERE isbn IN ('ZZ', 'X1234')\n+| like | Checks that the left argument (which is expected to be a String) matches a wildcard pattern that follows the JPA rules.| FROM Book WHERE title LIKE '%Java%'\n+|=| Checks that the left argument is an exact match of the given value         | FROM Book WHERE name = 'Programming Java'\n+|!=| Checks that the left argument is different from the given value            | FROM Book WHERE language != 'English'\n+|>| Checks that the left argument is greater than the given value.             | FROM Book WHERE price > 20\n+|>=| Checks that the left argument is greater than or equal to the given value. | FROM Book WHERE price >= 20\n+|<| Checks that the left argument is less than the given value.                | FROM Book WHERE year < 2012\n+|<=| Checks that the left argument is less than or equal to the given value.   | FROM Book WHERE price  <= 50\n+|between| Checks that the left argument is between the given range limits.  | FROM Book WHERE price BETWEEN 50 AND 100\n+|==============================================================================\n+\n+==== Boolean conditions\n+\n+Combining multiple attribute conditions with logical conjunction (`and`) and disjunction (`or`) operators in order to\n+create more complex conditions is demonstrated in the following example. The well known operator precedence rule for\n+boolean operators applies here, so the order of the operators is irrelevant. Here `and`\n+operator still has higher priority than `or` even though `or` was invoked first.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title\n+# or have an author named \"Manik\" and their description contains \"clustering\"\n+\n+FROM com.acme.Book WHERE title LIKE '%Data Grid%' OR author.name = 'Manik' AND description like '%clustering%'\n+----\n+\n+Boolean negation has highest precedence among logical operators and applies only to the next simple attribute condition.\n+\n+[source,sql]\n+----\n+# match all books that do not have \"Data Grid\" in their title and are authored by \"Manik\"\n+FROM com.acme.Book WHERE title != 'Data Grid' AND author.name = 'Manik'\n+\n+----\n+\n+==== Nested conditions\n+Changing the precedence of logical operators is achieved with parenthesis:\n+\n+[source,sql]\n+----\n+# match all books that have an author named \"Manik\" and their title contains\n+# \"Data Grid\" or their description contains \"clustering\"\n+FROM com.acme.Book WHERE author.name = 'Manik' AND ( title like '%Data Grid%' OR description like '% clustering%')\n+----\n+\n+==== Selecting attributes\n+In some use cases returning the whole domain object is overkill if only a small subset of the attributes are actually\n+used by the application, especially if the domain entity has embedded entities. The query language allows you to specify\n+a subset of attributes (or attribute paths) to return - the projection. If projections are used then the `QueryResult.list()`\n+will not return the whole domain entity but will return a _List_ of _Object[]_, each slot in the array corresponding to\n+a projected attribute.\n+\n+//TODO document what needs to be configured for an attribute to be available for projection.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return only their title and publication year\n+SELECT title, publicationYear FROM com.acme.Book WHERE title like '%Data Grid%' OR description like '%Data Grid%'\n+----\n+\n+==== Sorting\n+Ordering the results based on one or more attributes or attribute paths is done with the `ORDER BY` clause. If multiple sorting criteria\n+are specified, then the order will dictate their precedence.\n+\n+\n+//TODO document what needs to be configured for an attribute to be available for sorting.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return them sorted by the publication year and title\n+FROM com.acme.Book WHERE title like '%Data Grid%' ORDER BY publicationYear DESC, title ASC\n+----\n+\n+==== Grouping and Aggregation\n+\n+{brandname} has the ability to group query results according to a set of grouping fields and construct aggregations of\n+the results from each group by applying an aggregation function to the set of values that fall into each group.\n+Grouping and aggregation can only be applied to projection queries (queries with one or more field in the SELECT clause).\n+\n+The supported aggregations are: avg, sum, count, max, min.\n+\n+The set of grouping fields is specified with the `GROUP BY` clause and the order used for defining grouping fields is\n+not relevant. All fields selected in the projection must either be grouping fields\n+or else they must be aggregated using one of the grouping functions described below. A projection field can be\n+aggregated and used for grouping at the same time. A query that selects only grouping fields but no aggregation fields\n+is legal.\n+\u2060\n+Example: Grouping Books by author and counting them.\n+[source,sql]\n+----\n+SELECT author, COUNT(title) FROM com.acme.Book WHERE title LIKE '%engine%' GROUP BY author\n+----\n+\n+NOTE: A projection query in which all selected fields have an aggregation function applied and no fields are used for\n+grouping is allowed. In this case the aggregations will be computed globally as if there was a single global group.\n+\n+==== Aggregations\n+\n+The following aggregation functions may be applied to a field: avg, sum, count, max, min\n+\n+\n+* avg() - Computes the average of a set of numbers. Accepted values are primitive numbers and instances of _java.lang.Number_. The result is represented as _java.lang.Double_. If there are no non-null values the result is _null_ instead.\n+* count() - Counts the number of non-null rows and returns a _java.lang.Long_. If there are no non-null values the result is _0_ instead.\n+* max() - Returns the greatest value found. Accepted values must be instances of _java.lang.Comparable_. If there are no non-null values the result is _null_ instead.\n+* min() - Returns the smallest value found. Accepted values must be instances of _java.lang.Comparable_. If there are no non-null values the result is _null_ instead.\n+* sum() - Computes the sum of a set of Numbers. If there are no non-null values the result is _null_ instead. The following table indicates the return type based on the specified field.\n+\n+.Table sum return type\n+|===\n+|Field Type |Return Type\n+\n+|Integral (other than BigInteger)\n+|Long\n+\n+|Float or Double\n+|Double\n+\n+|BigInteger\n+|BigInteger\n+\n+|BigDecimal\n+|BigDecimal\n+|===\n+\n+==== Evaluation of queries with grouping and aggregation\n+\n+Aggregation queries can include filtering conditions, like usual queries. Filtering can be performed in two stages: before\n+and after the grouping operation. All filter conditions defined before invoking the _groupBy_ method will be applied\n+before the grouping operation is performed, directly to the cache entries (not to the final projection). These filter\n+conditions may reference any fields of the queried entity type, and are meant to restrict the data set that is going to\n+be the input for the grouping stage. All filter conditions defined after invoking the _groupBy_ method will be applied to\n+the projection that results from the projection and grouping operation. These filter conditions can either reference any\n+of the _groupBy_ fields or aggregated fields. Referencing aggregated fields that are not specified in the select clause\n+is allowed; however, referencing non-aggregated and non-grouping fields is forbidden. Filtering in this phase will\n+reduce the amount of groups based on their properties. Sorting may also be specified similar to usual queries. The\n+ordering operation is performed after the grouping operation and can reference any of the _groupBy_ fields or aggregated\n+fields.\n+\n+==== Using Full-text search\n+\n+===== Fuzzy Queries\n+\n+To execute a fuzzy query add `~` along with an integer, representing the distance from the term used, after the term.\n+For instance\n+\n+[source,sql,tile=\"Fuzzy Queries in Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'cofee'~2\n+----\n+\n+===== Range Queries\n+\n+To execute a range query define the given boundaries within a pair of braces, as seen in the following example:\n+\n+[source,sql,tile=\"Range queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE amount : [20 to 50]\n+----\n+\n+===== Phrase Queries\n+\n+A group of words may be searched by surrounding them in quotation marks, as seen in the following example:\n+\n+[source,sql,tile=\"Phrase queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'bus fare'\n+----\n+\n+===== Proximity Queries\n+\n+To execute a proximity query, finding two terms within a specific distance, add a `~` along with the distance after the phrase.\n+For instance, the following example will find the words canceling and fee provided they are not more than 3 words apart:\n+\n+[source,sql,tile=\"Proximity queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'canceling fee'~3\n+----\n+\n+===== Wildcard Queries\n+\n+Both single-character and multi-character wildcard searches may be performed:\n+\n+* A single-character wildcard search may be used with the ? character.\n+* A multi-character wildcard search may be used with the * character.\n+\n+To search for text or test the following single-character wildcard search would be used:\n+\n+[source,sql,tile=\"Single-character wildcard queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction where description : 'te?t'\n+----\n+\n+To search for test, tests, or tester the following multi-character wildcard search would be useD:\n+\n+[source,sql,tile=\"Multi-character wildcard queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction where description : 'test*'\n+----\n+\n+===== Regular Expression Queries\n+\n+Regular expression queries may be performed by specifying a pattern between /. Ickle uses Lucene\u2019s regular expression syntax, so to search for the words `moat` or `boat` the following could be used:\n+\n+[source,sql,tile=\"Regular Expression queries with Ickle\"]\n+----\n+FROM sample_library.Book  where title : /[mb]oat/\n+----\n+\n+===== Boosting Queries\n+\n+Terms may be boosted by adding a `^` after the term to increase their relevance in a given query, the higher the boost factor the more relevant the term will be. For instance to search for titles containing beer and wine with a higher relevance on beer, by a factor of 3, the following could be used:\n+\n+[source,sql,tile=\"Boosting queries with Ickle\"]\n+----\n+FROM sample_library.Book WHERE title : beer^3 OR wine\n+----\n+\n+[[query_library]]\n+== Embedded Search\n+\n+Embedded searching is available when {brandname} is used as a library. No protobuf mapping is required, and both indexing and searching are done on top of Java objects.\n+\n+=== Quick example\n+\n+We're going to store _Book_ instances in an {brandname} cache called \"books\". _Book_ instances will be indexed, so we enable indexing for the cache:\n+\n+{brandname} configuration:\n+\n+.infinispan.xml\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/infinispan_distributed_cache_books.xml[]\n+----\n+\n+Obtaining the cache:\n+\n+[source,java]\n+----\n+import org.infinispan.Cache;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+\n+EmbeddedCacheManager manager = new DefaultCacheManager(\"infinispan.xml\");\n+Cache<String, Book> cache = manager.getCache(\"books\");\n+\n+----\n+\n+Each _Book_ will be defined as in the following example; we have to choose which properties are indexed, and for each property we can optionally choose advanced indexing options using the annotations defined in the Hibernate Search project.\n+\n+[source,java]\n+.Book.java\n+----\n+import org.hibernate.search.annotations.*;\n+import java.util.Date;\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+//Values you want to index need to be annotated with @Indexed, then you pick which fields and how they are to be indexed:\n+@Indexed\n+public class Book {\n+   @Field String title;\n+   @Field String description;\n+   @Field @DateBridge(resolution=Resolution.YEAR) Date publicationYear;\n+   @IndexedEmbedded Set<Author> authors = new HashSet<Author>();\n+}\n+\n+----\n+\n+[source,java]\n+.Author.java\n+----\n+\n+public class Author {\n+   @Field String name;\n+   @Field String surname;\n+   // hashCode() and equals() omitted\n+}\n+\n+----\n+\n+Now assuming we stored several _Book_ instances in our {brandname} _Cache_ , we can search them for any matching field as in the following example.\n+\n+[source,java]\n+.QueryExample.java\n+----\n+include::code_examples/QueryExample.java[]\n+----\n+\n+Apart from _list()_ you have the option for obtaining on _iterator()_, or use pagination.\n+\n+[[mapping_embedded]]\n+=== Mapping Entities\n+\n+{brandname} relies on the rich API of link:http://hibernate.org/search/[Hibernate Search] in order to define fine grained configuration for indexing at entity level.\n+This configuration includes which fields are annotated, which analyzers should be used, how to map nested objects and so on.\n+Detailed documentation is available at link:https://docs.jboss.org/hibernate/stable/search/reference/en-US/html_single/#search-mapping[the Hibernate Search manual].\n+\n+==== @DocumentId\n+Unlike Hibernate Search, using _@DocumentId_ to mark a field as identifier does not apply to {brandname} values; in {brandname} the identifier for all _@Indexed_ objects is the key used to store the value. You can still customize how the key is indexed using a combination of _@Transformable_ , custom types and custom _FieldBridge_ implementations.\n+\n+==== @Transformable keys\n+The key for each value needs to be indexed as well, and the key instance must be transformed in a _String_. {brandname} includes some default transformation routines to encode common primitives, but to use a custom key you must provide an implementation of _org.infinispan.query.Transformer_ .\n+\n+[small]*Registering a key Transformer via annotations*\n+\n+You can annotate your key class with _org.infinispan.query.Transformable_ and your custom transformer implementation\n+will be picked up automatically:\n+\n+[source,java]\n+----\n+\n+@Transformable(transformer = CustomTransformer.class)\n+public class CustomKey {\n+   ...\n+}\n+\n+public class CustomTransformer implements Transformer {\n+   @Override\n+   public Object fromString(String s) {\n+      ...\n+      return new CustomKey(...);\n+   }\n+\n+   @Override\n+   public String toString(Object customType) {\n+      CustomKey ck = (CustomKey) customType;\n+      return ...\n+   }\n+}\n+\n+----\n+\n+[small]*Registering a key Transformer via the cache indexing configuration*\n+\n+You can use the _key-transformers_ xml element in both embedded and server config:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_key_transformer.xml[]\n+----\n+\n+or alternatively, you can achieve the same effect by using the Java configuration API (embedded mode):\n+\n+[source,java]\n+----\n+\n+   ConfigurationBuilder builder = ...\n+   builder.indexing().autoConfig(true)\n+         .addKeyTransformer(CustomKey.class, CustomTransformer.class);\n+\n+----\n+\n+[small]*Registering a Transformer programmatically at runtime*\n+\n+Using this technique, you don't have to annotate your custom key type and you also do not add the transformer to the,\n+cache indexing configuration, instead, you can add it to the _SearchManagerImplementor_ dynamically at runtime by invoking\n+_org.infinispan.query.spi.SearchManagerImplementor.registerKeyTransformer(Class<?>, Class<? extends Transformer>)_:\n+\n+[source,java]\n+----\n+org.infinispan.query.spi.SearchManagerImplementor manager = Search.getSearchManager(cache).unwrap(SearchManagerImplementor.class);\n+manager.registerKeyTransformer(keyClass, keyTransformerClass);\n+----\n+\n+NOTE: This approach is deprecated since 10.0 because it can lead to situations when a newly started node receives cache", "originalCommit": "9d2f00c69a659db1aa4ba37fa151dbf23dff1a1f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQyMDA3Mw==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437420073", "bodyText": "This is basically the 10.0 docs, I forgot to rework this section removing deprecated code", "author": "gustavonalle", "createdAt": "2020-06-09T13:33:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM0MjkyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM0MzE1MQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437343151", "bodyText": "s/must uses/must use", "author": "oraNod", "createdAt": "2020-06-09T11:41:21Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1096 @@\n+[[indexing_searching]]\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} supports indexing and searching of cache values stored as Java Pojo(s) or objects encoded via link:https://developers.google.com/protocol-buffers/[Protocol Buffers], using a powerful search API which complement its main Map-like API.\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+[NOTE]\n+====\n+You must invoke the `enable()` method to programmatically enable indexing\n+====\n+\n+=== Specifying indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+\n+NOTE: A query will always target a single entity type and is evaluated over the contents of a single cache. Running a\n+query over multiple caches or creating queries that target several entity types (joins) is not supported.\n+\n+Executing the query and fetching the results is as simple as invoking the `run()` method of the _Query_ object. Once\n+executed, calling `run()` on the same instance will re-execute the query.\n+\n+=== Pagination\n+\n+You can limit the number of returned results by using  the `Query.maxResults(int maxResults)`. This can be used in\n+conjunction with `Query.startOffset(long startOffset)` to achieve pagination of the result set.\n+\n+[source,java]\n+----\n+// sorted by year and match all books that have \"clustering\" in their title\n+// and return the third page of 10 results\n+Query<Book> query = queryFactory.create(\"FROM com.acme.Book WHERE title like '%clustering%' ORDER BY year\").startOffset(20).maxResults(10)\n+----\n+\n+=== Number of Hits\n+\n+The `QueryResult` object has the `.hitCount()` method to return the total number of results of the query, regardless\n+of any pagination parameter. The hit count is only available for indexed queries for performance reasons.\n+\n+\n+=== Iteration\n+\n+The `Query` object has the `.iterator()` method to obtain the results lazily. It returns an instance of `CloseableIterator` that\n+must be closed after usage.\n+\n+NOTE: Iteration is not currently implemented for Remote Queries\n+\n+=== Using Named Query Parameters\n+\n+Instead of building a new Query object for every execution it is possible to include named parameters in the query which\n+can be substituted with actual values before execution. This allows a query to be defined once and be efficiently\n+executed many times. Parameters can only be used on the right-hand side of an operator and are defined when the query is\n+created by supplying an object produced by the _org.infinispan.query.dsl.Expression.param(String paramName)_ method to\n+the operator instead of the usual constant value. Once the parameters have been defined they can be set by invoking either\n+_Query.setParameter(parameterName, value)_ or _Query.setParameters(parameterMap)_ as shown in the examples below.\n+\u2060\n+[source,java,tile=\"Using Named Parameters\"]\n+----\n+QueryFactory queryFactory = Search.getQueryFactory(cache);\n+// Defining a query to search for various authors and publication years\n+Query<Book> query = queryFactory.create(\"SELECT title FROM com.acme.Book WHERE author = :authorName AND publicationYear = :publicationYear\").build();\n+\n+// Set actual parameter values\n+query.setParameter(\"authorName\", \"Doe\");\n+query.setParameter(\"publicationYear\", 2010);\n+\n+// Execute the query\n+List<Book> found = query.list();\n+----\n+\n+Alternatively, multiple parameters may be set at once by supplying a map of actual parameter values:\n+\u2060\n+[source,java,title=\"Setting multiple named parameters at once\"]\n+----\n+Map<String, Object> parameterMap = new HashMap<>();\n+parameterMap.put(\"authorName\", \"Doe\");\n+parameterMap.put(\"publicationYear\", 2010);\n+\n+query.setParameters(parameterMap);\n+----\n+\n+NOTE: A significant portion of the query parsing, validation and execution planning effort is performed during the first\n+execution of a query with parameters. This effort is not repeated during subsequent executions leading to better\n+performance compared to a similar query using constant values instead of query parameters.\n+\n+[[query_ickle]]\n+=== Ickle Query Language Parser Syntax\n+\n+The Ickle query language is small subset of the link:https://en.wikipedia.org/wiki/Java_Persistence_Query_Language[JPQL]\n+query language, with some extensions for full-text.\n+\n+The parser syntax has some notable rules:\n+\n+* Whitespace is not significant.\n+* Wildcards are not supported in field names.\n+* A field name or path must always be specified, as there is no default field.\n+* `&&` and `||` are accepted instead of `AND` or `OR` in both full-text and JPA predicates.\n+* `!` may be used instead of `NOT`.\n+* A missing boolean operator is interpreted as `OR`.\n+* String terms must be enclosed with either single or double quotes.\n+* Fuzziness and boosting are not accepted in arbitrary order; fuzziness always comes first.\n+* `!=` is accepted instead of `<>`.\n+* Boosting cannot be applied to `>`,`>=`,`<`,`<=` operators. Ranges may be used to achieve the same result.\n+\n+==== Filtering operators\n+\n+Ickle support many filtering operators that can be used for both indexed and non-indexed fields.\n+\n+[options=\"header\"]\n+|==============================================================================\n+| Operator | Description | Example\n+| in | Checks that the left operand is equal to one of the elements from the Collection of values given as argument.\n+|FROM Book WHERE isbn IN ('ZZ', 'X1234')\n+| like | Checks that the left argument (which is expected to be a String) matches a wildcard pattern that follows the JPA rules.| FROM Book WHERE title LIKE '%Java%'\n+|=| Checks that the left argument is an exact match of the given value         | FROM Book WHERE name = 'Programming Java'\n+|!=| Checks that the left argument is different from the given value            | FROM Book WHERE language != 'English'\n+|>| Checks that the left argument is greater than the given value.             | FROM Book WHERE price > 20\n+|>=| Checks that the left argument is greater than or equal to the given value. | FROM Book WHERE price >= 20\n+|<| Checks that the left argument is less than the given value.                | FROM Book WHERE year < 2012\n+|<=| Checks that the left argument is less than or equal to the given value.   | FROM Book WHERE price  <= 50\n+|between| Checks that the left argument is between the given range limits.  | FROM Book WHERE price BETWEEN 50 AND 100\n+|==============================================================================\n+\n+==== Boolean conditions\n+\n+Combining multiple attribute conditions with logical conjunction (`and`) and disjunction (`or`) operators in order to\n+create more complex conditions is demonstrated in the following example. The well known operator precedence rule for\n+boolean operators applies here, so the order of the operators is irrelevant. Here `and`\n+operator still has higher priority than `or` even though `or` was invoked first.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title\n+# or have an author named \"Manik\" and their description contains \"clustering\"\n+\n+FROM com.acme.Book WHERE title LIKE '%Data Grid%' OR author.name = 'Manik' AND description like '%clustering%'\n+----\n+\n+Boolean negation has highest precedence among logical operators and applies only to the next simple attribute condition.\n+\n+[source,sql]\n+----\n+# match all books that do not have \"Data Grid\" in their title and are authored by \"Manik\"\n+FROM com.acme.Book WHERE title != 'Data Grid' AND author.name = 'Manik'\n+\n+----\n+\n+==== Nested conditions\n+Changing the precedence of logical operators is achieved with parenthesis:\n+\n+[source,sql]\n+----\n+# match all books that have an author named \"Manik\" and their title contains\n+# \"Data Grid\" or their description contains \"clustering\"\n+FROM com.acme.Book WHERE author.name = 'Manik' AND ( title like '%Data Grid%' OR description like '% clustering%')\n+----\n+\n+==== Selecting attributes\n+In some use cases returning the whole domain object is overkill if only a small subset of the attributes are actually\n+used by the application, especially if the domain entity has embedded entities. The query language allows you to specify\n+a subset of attributes (or attribute paths) to return - the projection. If projections are used then the `QueryResult.list()`\n+will not return the whole domain entity but will return a _List_ of _Object[]_, each slot in the array corresponding to\n+a projected attribute.\n+\n+//TODO document what needs to be configured for an attribute to be available for projection.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return only their title and publication year\n+SELECT title, publicationYear FROM com.acme.Book WHERE title like '%Data Grid%' OR description like '%Data Grid%'\n+----\n+\n+==== Sorting\n+Ordering the results based on one or more attributes or attribute paths is done with the `ORDER BY` clause. If multiple sorting criteria\n+are specified, then the order will dictate their precedence.\n+\n+\n+//TODO document what needs to be configured for an attribute to be available for sorting.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return them sorted by the publication year and title\n+FROM com.acme.Book WHERE title like '%Data Grid%' ORDER BY publicationYear DESC, title ASC\n+----\n+\n+==== Grouping and Aggregation\n+\n+{brandname} has the ability to group query results according to a set of grouping fields and construct aggregations of\n+the results from each group by applying an aggregation function to the set of values that fall into each group.\n+Grouping and aggregation can only be applied to projection queries (queries with one or more field in the SELECT clause).\n+\n+The supported aggregations are: avg, sum, count, max, min.\n+\n+The set of grouping fields is specified with the `GROUP BY` clause and the order used for defining grouping fields is\n+not relevant. All fields selected in the projection must either be grouping fields\n+or else they must be aggregated using one of the grouping functions described below. A projection field can be\n+aggregated and used for grouping at the same time. A query that selects only grouping fields but no aggregation fields\n+is legal.\n+\u2060\n+Example: Grouping Books by author and counting them.\n+[source,sql]\n+----\n+SELECT author, COUNT(title) FROM com.acme.Book WHERE title LIKE '%engine%' GROUP BY author\n+----\n+\n+NOTE: A projection query in which all selected fields have an aggregation function applied and no fields are used for\n+grouping is allowed. In this case the aggregations will be computed globally as if there was a single global group.\n+\n+==== Aggregations\n+\n+The following aggregation functions may be applied to a field: avg, sum, count, max, min\n+\n+\n+* avg() - Computes the average of a set of numbers. Accepted values are primitive numbers and instances of _java.lang.Number_. The result is represented as _java.lang.Double_. If there are no non-null values the result is _null_ instead.\n+* count() - Counts the number of non-null rows and returns a _java.lang.Long_. If there are no non-null values the result is _0_ instead.\n+* max() - Returns the greatest value found. Accepted values must be instances of _java.lang.Comparable_. If there are no non-null values the result is _null_ instead.\n+* min() - Returns the smallest value found. Accepted values must be instances of _java.lang.Comparable_. If there are no non-null values the result is _null_ instead.\n+* sum() - Computes the sum of a set of Numbers. If there are no non-null values the result is _null_ instead. The following table indicates the return type based on the specified field.\n+\n+.Table sum return type\n+|===\n+|Field Type |Return Type\n+\n+|Integral (other than BigInteger)\n+|Long\n+\n+|Float or Double\n+|Double\n+\n+|BigInteger\n+|BigInteger\n+\n+|BigDecimal\n+|BigDecimal\n+|===\n+\n+==== Evaluation of queries with grouping and aggregation\n+\n+Aggregation queries can include filtering conditions, like usual queries. Filtering can be performed in two stages: before\n+and after the grouping operation. All filter conditions defined before invoking the _groupBy_ method will be applied\n+before the grouping operation is performed, directly to the cache entries (not to the final projection). These filter\n+conditions may reference any fields of the queried entity type, and are meant to restrict the data set that is going to\n+be the input for the grouping stage. All filter conditions defined after invoking the _groupBy_ method will be applied to\n+the projection that results from the projection and grouping operation. These filter conditions can either reference any\n+of the _groupBy_ fields or aggregated fields. Referencing aggregated fields that are not specified in the select clause\n+is allowed; however, referencing non-aggregated and non-grouping fields is forbidden. Filtering in this phase will\n+reduce the amount of groups based on their properties. Sorting may also be specified similar to usual queries. The\n+ordering operation is performed after the grouping operation and can reference any of the _groupBy_ fields or aggregated\n+fields.\n+\n+==== Using Full-text search\n+\n+===== Fuzzy Queries\n+\n+To execute a fuzzy query add `~` along with an integer, representing the distance from the term used, after the term.\n+For instance\n+\n+[source,sql,tile=\"Fuzzy Queries in Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'cofee'~2\n+----\n+\n+===== Range Queries\n+\n+To execute a range query define the given boundaries within a pair of braces, as seen in the following example:\n+\n+[source,sql,tile=\"Range queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE amount : [20 to 50]\n+----\n+\n+===== Phrase Queries\n+\n+A group of words may be searched by surrounding them in quotation marks, as seen in the following example:\n+\n+[source,sql,tile=\"Phrase queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'bus fare'\n+----\n+\n+===== Proximity Queries\n+\n+To execute a proximity query, finding two terms within a specific distance, add a `~` along with the distance after the phrase.\n+For instance, the following example will find the words canceling and fee provided they are not more than 3 words apart:\n+\n+[source,sql,tile=\"Proximity queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'canceling fee'~3\n+----\n+\n+===== Wildcard Queries\n+\n+Both single-character and multi-character wildcard searches may be performed:\n+\n+* A single-character wildcard search may be used with the ? character.\n+* A multi-character wildcard search may be used with the * character.\n+\n+To search for text or test the following single-character wildcard search would be used:\n+\n+[source,sql,tile=\"Single-character wildcard queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction where description : 'te?t'\n+----\n+\n+To search for test, tests, or tester the following multi-character wildcard search would be useD:\n+\n+[source,sql,tile=\"Multi-character wildcard queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction where description : 'test*'\n+----\n+\n+===== Regular Expression Queries\n+\n+Regular expression queries may be performed by specifying a pattern between /. Ickle uses Lucene\u2019s regular expression syntax, so to search for the words `moat` or `boat` the following could be used:\n+\n+[source,sql,tile=\"Regular Expression queries with Ickle\"]\n+----\n+FROM sample_library.Book  where title : /[mb]oat/\n+----\n+\n+===== Boosting Queries\n+\n+Terms may be boosted by adding a `^` after the term to increase their relevance in a given query, the higher the boost factor the more relevant the term will be. For instance to search for titles containing beer and wine with a higher relevance on beer, by a factor of 3, the following could be used:\n+\n+[source,sql,tile=\"Boosting queries with Ickle\"]\n+----\n+FROM sample_library.Book WHERE title : beer^3 OR wine\n+----\n+\n+[[query_library]]\n+== Embedded Search\n+\n+Embedded searching is available when {brandname} is used as a library. No protobuf mapping is required, and both indexing and searching are done on top of Java objects.\n+\n+=== Quick example\n+\n+We're going to store _Book_ instances in an {brandname} cache called \"books\". _Book_ instances will be indexed, so we enable indexing for the cache:\n+\n+{brandname} configuration:\n+\n+.infinispan.xml\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/infinispan_distributed_cache_books.xml[]\n+----\n+\n+Obtaining the cache:\n+\n+[source,java]\n+----\n+import org.infinispan.Cache;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+\n+EmbeddedCacheManager manager = new DefaultCacheManager(\"infinispan.xml\");\n+Cache<String, Book> cache = manager.getCache(\"books\");\n+\n+----\n+\n+Each _Book_ will be defined as in the following example; we have to choose which properties are indexed, and for each property we can optionally choose advanced indexing options using the annotations defined in the Hibernate Search project.\n+\n+[source,java]\n+.Book.java\n+----\n+import org.hibernate.search.annotations.*;\n+import java.util.Date;\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+//Values you want to index need to be annotated with @Indexed, then you pick which fields and how they are to be indexed:\n+@Indexed\n+public class Book {\n+   @Field String title;\n+   @Field String description;\n+   @Field @DateBridge(resolution=Resolution.YEAR) Date publicationYear;\n+   @IndexedEmbedded Set<Author> authors = new HashSet<Author>();\n+}\n+\n+----\n+\n+[source,java]\n+.Author.java\n+----\n+\n+public class Author {\n+   @Field String name;\n+   @Field String surname;\n+   // hashCode() and equals() omitted\n+}\n+\n+----\n+\n+Now assuming we stored several _Book_ instances in our {brandname} _Cache_ , we can search them for any matching field as in the following example.\n+\n+[source,java]\n+.QueryExample.java\n+----\n+include::code_examples/QueryExample.java[]\n+----\n+\n+Apart from _list()_ you have the option for obtaining on _iterator()_, or use pagination.\n+\n+[[mapping_embedded]]\n+=== Mapping Entities\n+\n+{brandname} relies on the rich API of link:http://hibernate.org/search/[Hibernate Search] in order to define fine grained configuration for indexing at entity level.\n+This configuration includes which fields are annotated, which analyzers should be used, how to map nested objects and so on.\n+Detailed documentation is available at link:https://docs.jboss.org/hibernate/stable/search/reference/en-US/html_single/#search-mapping[the Hibernate Search manual].\n+\n+==== @DocumentId\n+Unlike Hibernate Search, using _@DocumentId_ to mark a field as identifier does not apply to {brandname} values; in {brandname} the identifier for all _@Indexed_ objects is the key used to store the value. You can still customize how the key is indexed using a combination of _@Transformable_ , custom types and custom _FieldBridge_ implementations.\n+\n+==== @Transformable keys\n+The key for each value needs to be indexed as well, and the key instance must be transformed in a _String_. {brandname} includes some default transformation routines to encode common primitives, but to use a custom key you must provide an implementation of _org.infinispan.query.Transformer_ .\n+\n+[small]*Registering a key Transformer via annotations*\n+\n+You can annotate your key class with _org.infinispan.query.Transformable_ and your custom transformer implementation\n+will be picked up automatically:\n+\n+[source,java]\n+----\n+\n+@Transformable(transformer = CustomTransformer.class)\n+public class CustomKey {\n+   ...\n+}\n+\n+public class CustomTransformer implements Transformer {\n+   @Override\n+   public Object fromString(String s) {\n+      ...\n+      return new CustomKey(...);\n+   }\n+\n+   @Override\n+   public String toString(Object customType) {\n+      CustomKey ck = (CustomKey) customType;\n+      return ...\n+   }\n+}\n+\n+----\n+\n+[small]*Registering a key Transformer via the cache indexing configuration*\n+\n+You can use the _key-transformers_ xml element in both embedded and server config:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_key_transformer.xml[]\n+----\n+\n+or alternatively, you can achieve the same effect by using the Java configuration API (embedded mode):\n+\n+[source,java]\n+----\n+\n+   ConfigurationBuilder builder = ...\n+   builder.indexing().autoConfig(true)\n+         .addKeyTransformer(CustomKey.class, CustomTransformer.class);\n+\n+----\n+\n+[small]*Registering a Transformer programmatically at runtime*\n+\n+Using this technique, you don't have to annotate your custom key type and you also do not add the transformer to the,\n+cache indexing configuration, instead, you can add it to the _SearchManagerImplementor_ dynamically at runtime by invoking\n+_org.infinispan.query.spi.SearchManagerImplementor.registerKeyTransformer(Class<?>, Class<? extends Transformer>)_:\n+\n+[source,java]\n+----\n+org.infinispan.query.spi.SearchManagerImplementor manager = Search.getSearchManager(cache).unwrap(SearchManagerImplementor.class);\n+manager.registerKeyTransformer(keyClass, keyTransformerClass);\n+----\n+\n+NOTE: This approach is deprecated since 10.0 because it can lead to situations when a newly started node receives cache\n+entries via initial state transfer and is not able to index them because the needed key transformers are not yet registered\n+(and can only be registered after the Cache has been fully started). This undesirable situation is avoided if you register\n+your key transformers using the other available approaches (configuration and annotation).\n+\n+[[query_configuration_api]]\n+==== Programmatic mapping\n+\n+Instead of using annotations to map an entity to the index, it's also possible to configure it programmatically.\n+\n+In the following example we map an object _Author_ which is to be stored in the grid and made searchable on two properties but without annotating the class.\n+\n+[source,java]\n+----\n+import org.apache.lucene.search.Query;\n+import org.hibernate.search.cfg.Environment;\n+import org.hibernate.search.cfg.SearchMapping;\n+import org.hibernate.search.query.dsl.QueryBuilder;\n+import org.infinispan.Cache;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.cache.ConfigurationBuilder;\n+import org.infinispan.configuration.cache.Index;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.query.CacheQuery;\n+import org.infinispan.query.Search;\n+import org.infinispan.query.SearchManager;\n+\n+import java.io.IOException;\n+import java.lang.annotation.ElementType;\n+import java.util.Properties;\n+\n+SearchMapping mapping = new SearchMapping();\n+mapping.entity(Author.class).indexed()\n+       .property(\"name\", ElementType.METHOD).field()\n+       .property(\"surname\", ElementType.METHOD).field();\n+\n+Properties properties = new Properties();\n+properties.put(Environment.MODEL_MAPPING, mapping);\n+properties.put(\"hibernate.search.[other options]\", \"[...]\");\n+\n+Configuration infinispanConfiguration = new ConfigurationBuilder()\n+        .indexing().index(Index.NONE)\n+        .withProperties(properties)\n+        .build();\n+\n+DefaultCacheManager cacheManager = new DefaultCacheManager(infinispanConfiguration);\n+\n+Cache<Long, Author> cache = cacheManager.getCache();\n+SearchManager sm = Search.getSearchManager(cache);\n+\n+Author author = new Author(1, \"Manik\", \"Surtani\");\n+cache.put(author.getId(), author);\n+\n+QueryBuilder qb = sm.buildQueryBuilderForClass(Author.class).get();\n+Query q = qb.keyword().onField(\"name\").matching(\"Manik\").createQuery();\n+CacheQuery cq = sm.getQuery(q, Author.class);\n+assert cq.getResultSize() == 1;\n+----\n+\n+\n+[[query_remote]]\n+== Remote Search\n+\n+Remote search is very similar to embedded with the notable difference that data must uses", "originalCommit": "9d2f00c69a659db1aa4ba37fa151dbf23dff1a1f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzM1MTg3NQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437351875", "bodyText": "This seems like it could be broken into a set of steps. Maybe something like the following sequence:\nTo create a continuous query, do the following:\n. Create a Query object. See link:#query_dsl[the Query DSL section].\n. Obtain the ContinuousQuery (org.infinispan.query.api.continuous.ContinuousQuery) object of your cache by calling the appropriate method:\n+\n\norg.infinispan.client.hotrod.Search.getContinuousQuery(RemoteCache<K, V> cache) for {brandname} servers.\norg.infinispan.query.Search.getContinuousQuery(Cache<K, V> cache) for embedded {brandname}.\n\n\n\n\n. Register the query and a continuous query listener (org.infinispan.query.api.continuous.ContinuousQueryListener) as follows:", "author": "oraNod", "createdAt": "2020-06-09T11:58:11Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1096 @@\n+[[indexing_searching]]\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} supports indexing and searching of cache values stored as Java Pojo(s) or objects encoded via link:https://developers.google.com/protocol-buffers/[Protocol Buffers], using a powerful search API which complement its main Map-like API.\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+[NOTE]\n+====\n+You must invoke the `enable()` method to programmatically enable indexing\n+====\n+\n+=== Specifying indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+\n+NOTE: A query will always target a single entity type and is evaluated over the contents of a single cache. Running a\n+query over multiple caches or creating queries that target several entity types (joins) is not supported.\n+\n+Executing the query and fetching the results is as simple as invoking the `run()` method of the _Query_ object. Once\n+executed, calling `run()` on the same instance will re-execute the query.\n+\n+=== Pagination\n+\n+You can limit the number of returned results by using  the `Query.maxResults(int maxResults)`. This can be used in\n+conjunction with `Query.startOffset(long startOffset)` to achieve pagination of the result set.\n+\n+[source,java]\n+----\n+// sorted by year and match all books that have \"clustering\" in their title\n+// and return the third page of 10 results\n+Query<Book> query = queryFactory.create(\"FROM com.acme.Book WHERE title like '%clustering%' ORDER BY year\").startOffset(20).maxResults(10)\n+----\n+\n+=== Number of Hits\n+\n+The `QueryResult` object has the `.hitCount()` method to return the total number of results of the query, regardless\n+of any pagination parameter. The hit count is only available for indexed queries for performance reasons.\n+\n+\n+=== Iteration\n+\n+The `Query` object has the `.iterator()` method to obtain the results lazily. It returns an instance of `CloseableIterator` that\n+must be closed after usage.\n+\n+NOTE: Iteration is not currently implemented for Remote Queries\n+\n+=== Using Named Query Parameters\n+\n+Instead of building a new Query object for every execution it is possible to include named parameters in the query which\n+can be substituted with actual values before execution. This allows a query to be defined once and be efficiently\n+executed many times. Parameters can only be used on the right-hand side of an operator and are defined when the query is\n+created by supplying an object produced by the _org.infinispan.query.dsl.Expression.param(String paramName)_ method to\n+the operator instead of the usual constant value. Once the parameters have been defined they can be set by invoking either\n+_Query.setParameter(parameterName, value)_ or _Query.setParameters(parameterMap)_ as shown in the examples below.\n+\u2060\n+[source,java,tile=\"Using Named Parameters\"]\n+----\n+QueryFactory queryFactory = Search.getQueryFactory(cache);\n+// Defining a query to search for various authors and publication years\n+Query<Book> query = queryFactory.create(\"SELECT title FROM com.acme.Book WHERE author = :authorName AND publicationYear = :publicationYear\").build();\n+\n+// Set actual parameter values\n+query.setParameter(\"authorName\", \"Doe\");\n+query.setParameter(\"publicationYear\", 2010);\n+\n+// Execute the query\n+List<Book> found = query.list();\n+----\n+\n+Alternatively, multiple parameters may be set at once by supplying a map of actual parameter values:\n+\u2060\n+[source,java,title=\"Setting multiple named parameters at once\"]\n+----\n+Map<String, Object> parameterMap = new HashMap<>();\n+parameterMap.put(\"authorName\", \"Doe\");\n+parameterMap.put(\"publicationYear\", 2010);\n+\n+query.setParameters(parameterMap);\n+----\n+\n+NOTE: A significant portion of the query parsing, validation and execution planning effort is performed during the first\n+execution of a query with parameters. This effort is not repeated during subsequent executions leading to better\n+performance compared to a similar query using constant values instead of query parameters.\n+\n+[[query_ickle]]\n+=== Ickle Query Language Parser Syntax\n+\n+The Ickle query language is small subset of the link:https://en.wikipedia.org/wiki/Java_Persistence_Query_Language[JPQL]\n+query language, with some extensions for full-text.\n+\n+The parser syntax has some notable rules:\n+\n+* Whitespace is not significant.\n+* Wildcards are not supported in field names.\n+* A field name or path must always be specified, as there is no default field.\n+* `&&` and `||` are accepted instead of `AND` or `OR` in both full-text and JPA predicates.\n+* `!` may be used instead of `NOT`.\n+* A missing boolean operator is interpreted as `OR`.\n+* String terms must be enclosed with either single or double quotes.\n+* Fuzziness and boosting are not accepted in arbitrary order; fuzziness always comes first.\n+* `!=` is accepted instead of `<>`.\n+* Boosting cannot be applied to `>`,`>=`,`<`,`<=` operators. Ranges may be used to achieve the same result.\n+\n+==== Filtering operators\n+\n+Ickle support many filtering operators that can be used for both indexed and non-indexed fields.\n+\n+[options=\"header\"]\n+|==============================================================================\n+| Operator | Description | Example\n+| in | Checks that the left operand is equal to one of the elements from the Collection of values given as argument.\n+|FROM Book WHERE isbn IN ('ZZ', 'X1234')\n+| like | Checks that the left argument (which is expected to be a String) matches a wildcard pattern that follows the JPA rules.| FROM Book WHERE title LIKE '%Java%'\n+|=| Checks that the left argument is an exact match of the given value         | FROM Book WHERE name = 'Programming Java'\n+|!=| Checks that the left argument is different from the given value            | FROM Book WHERE language != 'English'\n+|>| Checks that the left argument is greater than the given value.             | FROM Book WHERE price > 20\n+|>=| Checks that the left argument is greater than or equal to the given value. | FROM Book WHERE price >= 20\n+|<| Checks that the left argument is less than the given value.                | FROM Book WHERE year < 2012\n+|<=| Checks that the left argument is less than or equal to the given value.   | FROM Book WHERE price  <= 50\n+|between| Checks that the left argument is between the given range limits.  | FROM Book WHERE price BETWEEN 50 AND 100\n+|==============================================================================\n+\n+==== Boolean conditions\n+\n+Combining multiple attribute conditions with logical conjunction (`and`) and disjunction (`or`) operators in order to\n+create more complex conditions is demonstrated in the following example. The well known operator precedence rule for\n+boolean operators applies here, so the order of the operators is irrelevant. Here `and`\n+operator still has higher priority than `or` even though `or` was invoked first.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title\n+# or have an author named \"Manik\" and their description contains \"clustering\"\n+\n+FROM com.acme.Book WHERE title LIKE '%Data Grid%' OR author.name = 'Manik' AND description like '%clustering%'\n+----\n+\n+Boolean negation has highest precedence among logical operators and applies only to the next simple attribute condition.\n+\n+[source,sql]\n+----\n+# match all books that do not have \"Data Grid\" in their title and are authored by \"Manik\"\n+FROM com.acme.Book WHERE title != 'Data Grid' AND author.name = 'Manik'\n+\n+----\n+\n+==== Nested conditions\n+Changing the precedence of logical operators is achieved with parenthesis:\n+\n+[source,sql]\n+----\n+# match all books that have an author named \"Manik\" and their title contains\n+# \"Data Grid\" or their description contains \"clustering\"\n+FROM com.acme.Book WHERE author.name = 'Manik' AND ( title like '%Data Grid%' OR description like '% clustering%')\n+----\n+\n+==== Selecting attributes\n+In some use cases returning the whole domain object is overkill if only a small subset of the attributes are actually\n+used by the application, especially if the domain entity has embedded entities. The query language allows you to specify\n+a subset of attributes (or attribute paths) to return - the projection. If projections are used then the `QueryResult.list()`\n+will not return the whole domain entity but will return a _List_ of _Object[]_, each slot in the array corresponding to\n+a projected attribute.\n+\n+//TODO document what needs to be configured for an attribute to be available for projection.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return only their title and publication year\n+SELECT title, publicationYear FROM com.acme.Book WHERE title like '%Data Grid%' OR description like '%Data Grid%'\n+----\n+\n+==== Sorting\n+Ordering the results based on one or more attributes or attribute paths is done with the `ORDER BY` clause. If multiple sorting criteria\n+are specified, then the order will dictate their precedence.\n+\n+\n+//TODO document what needs to be configured for an attribute to be available for sorting.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return them sorted by the publication year and title\n+FROM com.acme.Book WHERE title like '%Data Grid%' ORDER BY publicationYear DESC, title ASC\n+----\n+\n+==== Grouping and Aggregation\n+\n+{brandname} has the ability to group query results according to a set of grouping fields and construct aggregations of\n+the results from each group by applying an aggregation function to the set of values that fall into each group.\n+Grouping and aggregation can only be applied to projection queries (queries with one or more field in the SELECT clause).\n+\n+The supported aggregations are: avg, sum, count, max, min.\n+\n+The set of grouping fields is specified with the `GROUP BY` clause and the order used for defining grouping fields is\n+not relevant. All fields selected in the projection must either be grouping fields\n+or else they must be aggregated using one of the grouping functions described below. A projection field can be\n+aggregated and used for grouping at the same time. A query that selects only grouping fields but no aggregation fields\n+is legal.\n+\u2060\n+Example: Grouping Books by author and counting them.\n+[source,sql]\n+----\n+SELECT author, COUNT(title) FROM com.acme.Book WHERE title LIKE '%engine%' GROUP BY author\n+----\n+\n+NOTE: A projection query in which all selected fields have an aggregation function applied and no fields are used for\n+grouping is allowed. In this case the aggregations will be computed globally as if there was a single global group.\n+\n+==== Aggregations\n+\n+The following aggregation functions may be applied to a field: avg, sum, count, max, min\n+\n+\n+* avg() - Computes the average of a set of numbers. Accepted values are primitive numbers and instances of _java.lang.Number_. The result is represented as _java.lang.Double_. If there are no non-null values the result is _null_ instead.\n+* count() - Counts the number of non-null rows and returns a _java.lang.Long_. If there are no non-null values the result is _0_ instead.\n+* max() - Returns the greatest value found. Accepted values must be instances of _java.lang.Comparable_. If there are no non-null values the result is _null_ instead.\n+* min() - Returns the smallest value found. Accepted values must be instances of _java.lang.Comparable_. If there are no non-null values the result is _null_ instead.\n+* sum() - Computes the sum of a set of Numbers. If there are no non-null values the result is _null_ instead. The following table indicates the return type based on the specified field.\n+\n+.Table sum return type\n+|===\n+|Field Type |Return Type\n+\n+|Integral (other than BigInteger)\n+|Long\n+\n+|Float or Double\n+|Double\n+\n+|BigInteger\n+|BigInteger\n+\n+|BigDecimal\n+|BigDecimal\n+|===\n+\n+==== Evaluation of queries with grouping and aggregation\n+\n+Aggregation queries can include filtering conditions, like usual queries. Filtering can be performed in two stages: before\n+and after the grouping operation. All filter conditions defined before invoking the _groupBy_ method will be applied\n+before the grouping operation is performed, directly to the cache entries (not to the final projection). These filter\n+conditions may reference any fields of the queried entity type, and are meant to restrict the data set that is going to\n+be the input for the grouping stage. All filter conditions defined after invoking the _groupBy_ method will be applied to\n+the projection that results from the projection and grouping operation. These filter conditions can either reference any\n+of the _groupBy_ fields or aggregated fields. Referencing aggregated fields that are not specified in the select clause\n+is allowed; however, referencing non-aggregated and non-grouping fields is forbidden. Filtering in this phase will\n+reduce the amount of groups based on their properties. Sorting may also be specified similar to usual queries. The\n+ordering operation is performed after the grouping operation and can reference any of the _groupBy_ fields or aggregated\n+fields.\n+\n+==== Using Full-text search\n+\n+===== Fuzzy Queries\n+\n+To execute a fuzzy query add `~` along with an integer, representing the distance from the term used, after the term.\n+For instance\n+\n+[source,sql,tile=\"Fuzzy Queries in Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'cofee'~2\n+----\n+\n+===== Range Queries\n+\n+To execute a range query define the given boundaries within a pair of braces, as seen in the following example:\n+\n+[source,sql,tile=\"Range queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE amount : [20 to 50]\n+----\n+\n+===== Phrase Queries\n+\n+A group of words may be searched by surrounding them in quotation marks, as seen in the following example:\n+\n+[source,sql,tile=\"Phrase queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'bus fare'\n+----\n+\n+===== Proximity Queries\n+\n+To execute a proximity query, finding two terms within a specific distance, add a `~` along with the distance after the phrase.\n+For instance, the following example will find the words canceling and fee provided they are not more than 3 words apart:\n+\n+[source,sql,tile=\"Proximity queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'canceling fee'~3\n+----\n+\n+===== Wildcard Queries\n+\n+Both single-character and multi-character wildcard searches may be performed:\n+\n+* A single-character wildcard search may be used with the ? character.\n+* A multi-character wildcard search may be used with the * character.\n+\n+To search for text or test the following single-character wildcard search would be used:\n+\n+[source,sql,tile=\"Single-character wildcard queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction where description : 'te?t'\n+----\n+\n+To search for test, tests, or tester the following multi-character wildcard search would be useD:\n+\n+[source,sql,tile=\"Multi-character wildcard queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction where description : 'test*'\n+----\n+\n+===== Regular Expression Queries\n+\n+Regular expression queries may be performed by specifying a pattern between /. Ickle uses Lucene\u2019s regular expression syntax, so to search for the words `moat` or `boat` the following could be used:\n+\n+[source,sql,tile=\"Regular Expression queries with Ickle\"]\n+----\n+FROM sample_library.Book  where title : /[mb]oat/\n+----\n+\n+===== Boosting Queries\n+\n+Terms may be boosted by adding a `^` after the term to increase their relevance in a given query, the higher the boost factor the more relevant the term will be. For instance to search for titles containing beer and wine with a higher relevance on beer, by a factor of 3, the following could be used:\n+\n+[source,sql,tile=\"Boosting queries with Ickle\"]\n+----\n+FROM sample_library.Book WHERE title : beer^3 OR wine\n+----\n+\n+[[query_library]]\n+== Embedded Search\n+\n+Embedded searching is available when {brandname} is used as a library. No protobuf mapping is required, and both indexing and searching are done on top of Java objects.\n+\n+=== Quick example\n+\n+We're going to store _Book_ instances in an {brandname} cache called \"books\". _Book_ instances will be indexed, so we enable indexing for the cache:\n+\n+{brandname} configuration:\n+\n+.infinispan.xml\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/infinispan_distributed_cache_books.xml[]\n+----\n+\n+Obtaining the cache:\n+\n+[source,java]\n+----\n+import org.infinispan.Cache;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+\n+EmbeddedCacheManager manager = new DefaultCacheManager(\"infinispan.xml\");\n+Cache<String, Book> cache = manager.getCache(\"books\");\n+\n+----\n+\n+Each _Book_ will be defined as in the following example; we have to choose which properties are indexed, and for each property we can optionally choose advanced indexing options using the annotations defined in the Hibernate Search project.\n+\n+[source,java]\n+.Book.java\n+----\n+import org.hibernate.search.annotations.*;\n+import java.util.Date;\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+//Values you want to index need to be annotated with @Indexed, then you pick which fields and how they are to be indexed:\n+@Indexed\n+public class Book {\n+   @Field String title;\n+   @Field String description;\n+   @Field @DateBridge(resolution=Resolution.YEAR) Date publicationYear;\n+   @IndexedEmbedded Set<Author> authors = new HashSet<Author>();\n+}\n+\n+----\n+\n+[source,java]\n+.Author.java\n+----\n+\n+public class Author {\n+   @Field String name;\n+   @Field String surname;\n+   // hashCode() and equals() omitted\n+}\n+\n+----\n+\n+Now assuming we stored several _Book_ instances in our {brandname} _Cache_ , we can search them for any matching field as in the following example.\n+\n+[source,java]\n+.QueryExample.java\n+----\n+include::code_examples/QueryExample.java[]\n+----\n+\n+Apart from _list()_ you have the option for obtaining on _iterator()_, or use pagination.\n+\n+[[mapping_embedded]]\n+=== Mapping Entities\n+\n+{brandname} relies on the rich API of link:http://hibernate.org/search/[Hibernate Search] in order to define fine grained configuration for indexing at entity level.\n+This configuration includes which fields are annotated, which analyzers should be used, how to map nested objects and so on.\n+Detailed documentation is available at link:https://docs.jboss.org/hibernate/stable/search/reference/en-US/html_single/#search-mapping[the Hibernate Search manual].\n+\n+==== @DocumentId\n+Unlike Hibernate Search, using _@DocumentId_ to mark a field as identifier does not apply to {brandname} values; in {brandname} the identifier for all _@Indexed_ objects is the key used to store the value. You can still customize how the key is indexed using a combination of _@Transformable_ , custom types and custom _FieldBridge_ implementations.\n+\n+==== @Transformable keys\n+The key for each value needs to be indexed as well, and the key instance must be transformed in a _String_. {brandname} includes some default transformation routines to encode common primitives, but to use a custom key you must provide an implementation of _org.infinispan.query.Transformer_ .\n+\n+[small]*Registering a key Transformer via annotations*\n+\n+You can annotate your key class with _org.infinispan.query.Transformable_ and your custom transformer implementation\n+will be picked up automatically:\n+\n+[source,java]\n+----\n+\n+@Transformable(transformer = CustomTransformer.class)\n+public class CustomKey {\n+   ...\n+}\n+\n+public class CustomTransformer implements Transformer {\n+   @Override\n+   public Object fromString(String s) {\n+      ...\n+      return new CustomKey(...);\n+   }\n+\n+   @Override\n+   public String toString(Object customType) {\n+      CustomKey ck = (CustomKey) customType;\n+      return ...\n+   }\n+}\n+\n+----\n+\n+[small]*Registering a key Transformer via the cache indexing configuration*\n+\n+You can use the _key-transformers_ xml element in both embedded and server config:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_key_transformer.xml[]\n+----\n+\n+or alternatively, you can achieve the same effect by using the Java configuration API (embedded mode):\n+\n+[source,java]\n+----\n+\n+   ConfigurationBuilder builder = ...\n+   builder.indexing().autoConfig(true)\n+         .addKeyTransformer(CustomKey.class, CustomTransformer.class);\n+\n+----\n+\n+[small]*Registering a Transformer programmatically at runtime*\n+\n+Using this technique, you don't have to annotate your custom key type and you also do not add the transformer to the,\n+cache indexing configuration, instead, you can add it to the _SearchManagerImplementor_ dynamically at runtime by invoking\n+_org.infinispan.query.spi.SearchManagerImplementor.registerKeyTransformer(Class<?>, Class<? extends Transformer>)_:\n+\n+[source,java]\n+----\n+org.infinispan.query.spi.SearchManagerImplementor manager = Search.getSearchManager(cache).unwrap(SearchManagerImplementor.class);\n+manager.registerKeyTransformer(keyClass, keyTransformerClass);\n+----\n+\n+NOTE: This approach is deprecated since 10.0 because it can lead to situations when a newly started node receives cache\n+entries via initial state transfer and is not able to index them because the needed key transformers are not yet registered\n+(and can only be registered after the Cache has been fully started). This undesirable situation is avoided if you register\n+your key transformers using the other available approaches (configuration and annotation).\n+\n+[[query_configuration_api]]\n+==== Programmatic mapping\n+\n+Instead of using annotations to map an entity to the index, it's also possible to configure it programmatically.\n+\n+In the following example we map an object _Author_ which is to be stored in the grid and made searchable on two properties but without annotating the class.\n+\n+[source,java]\n+----\n+import org.apache.lucene.search.Query;\n+import org.hibernate.search.cfg.Environment;\n+import org.hibernate.search.cfg.SearchMapping;\n+import org.hibernate.search.query.dsl.QueryBuilder;\n+import org.infinispan.Cache;\n+import org.infinispan.configuration.cache.Configuration;\n+import org.infinispan.configuration.cache.ConfigurationBuilder;\n+import org.infinispan.configuration.cache.Index;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.query.CacheQuery;\n+import org.infinispan.query.Search;\n+import org.infinispan.query.SearchManager;\n+\n+import java.io.IOException;\n+import java.lang.annotation.ElementType;\n+import java.util.Properties;\n+\n+SearchMapping mapping = new SearchMapping();\n+mapping.entity(Author.class).indexed()\n+       .property(\"name\", ElementType.METHOD).field()\n+       .property(\"surname\", ElementType.METHOD).field();\n+\n+Properties properties = new Properties();\n+properties.put(Environment.MODEL_MAPPING, mapping);\n+properties.put(\"hibernate.search.[other options]\", \"[...]\");\n+\n+Configuration infinispanConfiguration = new ConfigurationBuilder()\n+        .indexing().index(Index.NONE)\n+        .withProperties(properties)\n+        .build();\n+\n+DefaultCacheManager cacheManager = new DefaultCacheManager(infinispanConfiguration);\n+\n+Cache<Long, Author> cache = cacheManager.getCache();\n+SearchManager sm = Search.getSearchManager(cache);\n+\n+Author author = new Author(1, \"Manik\", \"Surtani\");\n+cache.put(author.getId(), author);\n+\n+QueryBuilder qb = sm.buildQueryBuilderForClass(Author.class).get();\n+Query q = qb.keyword().onField(\"name\").matching(\"Manik\").createQuery();\n+CacheQuery cq = sm.getQuery(q, Author.class);\n+assert cq.getResultSize() == 1;\n+----\n+\n+\n+[[query_remote]]\n+== Remote Search\n+\n+Remote search is very similar to embedded with the notable difference that data must uses\n+link:http://code.google.com/p/protobuf/[Google Protocol Buffers] as an encoding for both over-the-wire and storage.\n+Furthermore, it's necessary to write (or generate from Java classes) a protobuf schema defining the data structure and indexing elements instead of relying on Hibernate Search annotations.\n+\n+The usage of protobuf allows remote query to work not only for Java, but for REST, C# and Node.js clients.\n+\n+[[remote_query_example]]\n+=== A remote query example\n+\n+We are going to revisit the Book Sample from embedded query, but this time using the Java Hot Rod client and the\n+Infinispan server.\n+An object called `Book` will be stored in a Infinispan cache called \"books\". Book instances will be indexed, so we enable\n+indexing for the cache:\n+\n+.infinispan.xml\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+Alternatively, if indexing the cache is not indexed, we configure the `<encoding>` as `application/x-protostream` to make sure\n+the storage is queryable:\n+\n+.infinispan.xml\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/non_indexed_entities_proto.xml[]\n+----\n+\n+Each `Book` will be defined as in the following example: we use `@Protofield` annotations to identify the\n+protocol buffers message fields and the `@ProtoDoc` annotation on the fields to configure indexing attributes:\n+\n+[source,java, title=Book.java]\n+----\n+include::code_examples/BookIndexed.java[]\n+----\n+\n+The annotations above will generate during compilation the artifacts necessary to read, write  and query `Book` instances. To enable this generation, use the `@AutoProtoSchemaBuilder` annotation in a newly created class with empty constructor or interface:\n+\n+[source,java, title=RemoteQueryInitializer.java]\n+----\n+include::code_examples/RemoteQueryInitializer.java[]\n+----\n+\n+After compilation, a file `book.proto` file will be created in the configured `schemaFilePath`, along with an implementation\n+`RemoteQueryInitializerImpl.java` of the annotated interface. This concrete class can be used directly in the Hot Rod client\n+code to initialize the serialization context.\n+\n+Putting all together:\n+\n+[source,java, title=RemoteQuery.java]\n+----\n+include::code_examples/RemoteQuery.java[]\n+----\n+\n+\n+[[enable_indexing]]\n+=== Indexing of Protobuf encoded entries\n+\n+As seen in link:#remote_query_example[Remote Query example], one step necessary to query protobuf entities\n+is to provide the client and server with the relevant metadata about entities (.proto file).\n+\n+The descriptors are stored in a dedicated cache on the server named `___protobuf_metadata`.\n+Both keys and values in this cache are plain strings. Registering a new schema is therefore as simple as performing a _put_ operation on this cache using the schema's name as key and the schema file itself as the value.\n+\n+Alternatively you can use the CLI (via the `cache-container=*:register-proto-schemas()` operation),\n+the Management Console, the REST endpoint `/rest/v2/schemas` or the `ProtobufMetadataManager` MBean via JMX.\n+Be aware that, when security is enabled, access to the schema cache via the remote protocols requires\n+that the user belongs to the pass:['___schema_manager'] role.\n+\n+NOTE: Even if indexing is enabled for a cache no fields of Protobuf encoded entries will be indexed unless you use\n+the _@Indexed_ and _@Field_ inside protobuf schema documentation annotations `(@ProtoDoc)`  to specify what fields need to get indexed.\n+\n+[[analysis]]\n+=== Analysis\n+Analysis is a process that converts input data into one or more terms that you can index and query.\n+While in link:#mapping_embedded[Embedded Query] mapping is done through link:https://docs.jboss.org/hibernate/stable/search/reference/en-US/html_single/#_analysis[Hibernate Search annotations], that supports\n+a rich set of Lucene based analyzers, in client-server mode the analyzer definitions are declared in a platform neutral way\n+\n+==== Default Analyzers\n+{brandname} provides a set of default analyzers for remote query as follows:\n+\n+[%header,cols=2*]\n+|===\n+\n+| Definition\n+| Description\n+\n+| `standard`\n+| Splits text fields into tokens, treating whitespace and punctuation as delimiters.\n+\n+| `simple`\n+| Tokenizes input streams by delimiting at non-letters and then converting all letters to lowercase characters. Whitespace and non-letters are discarded.\n+\n+| `whitespace`\n+| Splits text streams on whitespace and returns sequences of non-whitespace characters as tokens.\n+\n+| `keyword`\n+| Treats entire text fields as single tokens.\n+\n+| `stemmer`\n+| Stems English words using the Snowball Porter filter.\n+\n+| `ngram`\n+| Generates n-gram tokens that are 3 grams in size by default.\n+\n+| `filename`\n+| Splits text fields into larger size tokens than the `standard` analyzer, treating whitespace as a delimiter and converts all letters to lowercase characters.\n+\n+|===\n+\n+These analyzer definitions are based on Apache Lucene and are provided \"as-is\".\n+For more information about tokenizers, filters, and CharFilters, see the\n+appropriate Lucene documentation.\n+\n+==== Using Analyzer Definitions\n+\n+To use analyzer definitions, reference them by name in the _.proto_ schema file.\n+\n+. Include the `Analyze.YES` attribute to indicate that the property is analyzed.\n+. Specify the analyzer definition with the `@Analyzer` annotation.\n+\n+The following example shows referenced analyzer definitions:\n+\n+[source,protobuf,options=\"nowrap\"]\n+----\n+/* @Indexed */\n+message TestEntity {\n+\n+    /* @Field(store = Store.YES, analyze = Analyze.YES, analyzer = @Analyzer(definition = \"keyword\")) */\n+    optional string id = 1;\n+\n+    /* @Field(store = Store.YES, analyze = Analyze.YES, analyzer = @Analyzer(definition = \"simple\")) */\n+    optional string name = 2;\n+}\n+----\n+\n+If using Java classes annotated with `@ProtoField`, the declaration is similar:\n+\n+[source,java,options=\"nowrap\"]\n+----\n+@ProtoDoc(\"@Field(store = Store.YES, analyze = Analyze.YES, analyzer = @Analyzer(definition = \\\"keyword\\\"))\")\n+@ProtoField(number = 1)\n+final String id;\n+\n+@ProtoDoc(\"@Field(store = Store.YES, analyze = Analyze.YES, analyzer = @Analyzer(definition = \\\"simple\\\"))\")\n+@ProtoField(number = 2)\n+final String description;\n+----\n+\n+\n+==== Creating Custom Analyzer Definitions\n+If you require custom analyzer definitions, do the following:\n+\n+. Create an implementation of the\n+`ProgrammaticSearchMappingProvider` interface packaged in a `JAR` file.\n+. Provide a file named `org.infinispan.query.spi.ProgrammaticSearchMappingProvider` in the\n+`META-INF/services/` directory of your `JAR`. This file should contain the fully qualified class name of your implementation.\n+. Copy the `JAR` to the `lib/` directory of your {brandname} installation.\n++\n+[IMPORTANT]\n+====\n+Your jar must be available to the {brandname} server during startup. You cannot add it if the server is already running.\n+====\n++\n+The following is an example implementation of the\n+`ProgrammaticSearchMappingProvider` interface:\n++\n+[source,java,options=\"nowrap\"]\n+----\n+import org.apache.lucene.analysis.core.LowerCaseFilterFactory;\n+import org.apache.lucene.analysis.core.StopFilterFactory;\n+import org.apache.lucene.analysis.standard.StandardFilterFactory;\n+import org.apache.lucene.analysis.standard.StandardTokenizerFactory;\n+import org.hibernate.search.cfg.SearchMapping;\n+import org.infinispan.Cache;\n+import org.infinispan.query.spi.ProgrammaticSearchMappingProvider;\n+\n+public final class MyAnalyzerProvider implements ProgrammaticSearchMappingProvider {\n+\n+   @Override\n+   public void defineMappings(Cache cache, SearchMapping searchMapping) {\n+      searchMapping\n+            .analyzerDef(\"standard-with-stop\", StandardTokenizerFactory.class)\n+               .filter(StandardFilterFactory.class)\n+               .filter(LowerCaseFilterFactory.class)\n+               .filter(StopFilterFactory.class);\n+   }\n+}\n+----\n+\n+\n+[[query_continuous]]\n+== Continuous Query\n+\n+Continuous Queries allow an application to register a listener which will receive the entries that currently match a\n+query filter, and will be continuously notified of any changes to the queried data set that result from further cache\n+operations. This includes incoming matches, for values that have joined the set, updated matches, for matching values\n+that were modified and continue to match, and outgoing matches, for values that have left the set. By using a Continuous\n+Query the application receives a steady stream of events instead of having to repeatedly execute the same query to\n+discover changes, resulting in a more efficient use of resources. For instance, all of the following use cases could\n+utilize Continuous Queries:\n+\n+* Return all persons with an age between 18 and 25 (assuming the Person entity has an _age_ property and is updated by\n+the user application).\n+* Return all transactions higher than $2000.\n+* Return all times where the lap speed of F1 racers were less than 1:45.00s (assuming the cache contains Lap entries and\n+that laps are entered live during the race).\n+\n+=== Continuous Query Execution\n+\n+A continuous query uses a listener that is notified when:\n+\n+* An entry starts matching the specified query, represented by a _Join_ event.\n+* A matching entry is updated and continues to match the query, represented by an _Update_ event.\n+* An entry stops matching the query, represented by a _Leave_ event.\n+\n+When a client registers a continuous query listener it immediately begins to receive the results currently matching the\n+query, received as _Join_ events as described above. In addition, it will receive subsequent notifications when other\n+entries begin matching the query, as _Join_ events, or stop matching the query, as _Leave_ events, as a consequence of\n+any cache operations that would normally generate creation, modification, removal, or expiration events. Updated cache\n+entries will generate _Update_ events if the entry matches the query filter before and after the operation. To\n+summarize, the logic used to determine if the listener receives a _Join_, _Update_ or _Leave_ event is:\n+\n+. If the query on both the old and new values evaluate false, then the event is suppressed.\n+. If the query on the old value evaluates false and on the new value evaluates true, then a _Join_ event is sent.\n+. If the query on both the old and new values evaluate true, then an _Update_ event is sent.\n+. If the query on the old value evaluates true and on the new value evaluates false, then a _Leave_ event is sent.\n+. If the query on the old value evaluates true and the entry is removed or expired, then a _Leave_ event is sent.\n+\n+NOTE: Continuous Queries can use the full power of the Query DSL except: grouping, aggregation, and sorting operations.\n+\n+=== Running Continuous Queries\n+\n+To create a continuous query you'll start by creating a Query object first. This is described in", "originalCommit": "9d2f00c69a659db1aa4ba37fa151dbf23dff1a1f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQ3MTQxNA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437471414", "bodyText": "Just looking at adding a link to the index.html page. Could we change this to [id='search_api'] ? That can be our permanent anchor for top-level search docs.", "author": "oraNod", "createdAt": "2020-06-09T14:34:06Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1087 @@\n+[[indexing_searching]]", "originalCommit": "9792b2d37e24551dcb2e43bb58a2b6dc220f2162", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQ4MDI0OA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437480248", "bodyText": "sure", "author": "gustavonalle", "createdAt": "2020-06-09T14:45:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQ3MTQxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQ4MTk4MQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437481981", "bodyText": "done", "author": "gustavonalle", "createdAt": "2020-06-09T14:47:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzQ3MTQxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk2Njk2OQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437966969", "bodyText": "@gustavonalle Perhaps consider dropping the \"Overview\" heading or move the first sentence (\"\n{brandname} provides a search API...\") under the top-level heading. Headers should always have some text underneath and not just float.", "author": "oraNod", "createdAt": "2020-06-10T08:53:35Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1087 @@\n+[id='search_api']\n+=  Indexing and Searching\n+", "originalCommit": "12fae93eb5e527da5781daf106152840b0e2ee51", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk2ODkxNA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437968914", "bodyText": "I'd drop \"This behaviour exists only on schemas starting with version 11.\" Hardcoding the version doesn't work downstream. Also, I'm not sure it adds value here.\nI seem to recall this but maybe it was somewhere else. Why don't we change the default to \"true\" in the XSD?", "author": "oraNod", "createdAt": "2020-06-10T08:55:54Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1087 @@\n+[id='search_api']\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} provides a search API that lets you index and search cache values stored as Java POJOs or as objects encoded as link:https://developers.google.com/protocol-buffers/[Protocol Buffers].\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.", "originalCommit": "12fae93eb5e527da5781daf106152840b0e2ee51", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3NjQ5Mw==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437976493", "bodyText": "it has to do with some weirdness in the configuration, I can't remember what it was (@anistor worked on it). I will just keep the note and remove the hardcoded version", "author": "gustavonalle", "createdAt": "2020-06-10T09:08:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk2ODkxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3MDU5OQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437970599", "bodyText": "Notes should all use the same format.\n[NOTE]\n====\nRead this note.\n====", "author": "oraNod", "createdAt": "2020-06-10T08:58:34Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1087 @@\n+[id='search_api']\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} provides a search API that lets you index and search cache values stored as Java POJOs or as objects encoded as link:https://developers.google.com/protocol-buffers/[Protocol Buffers].\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+\n+In the programmatic config, `enabled()` must be used.\n+\n+=== Specifying Indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+[[searching_ickle]]\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+[NOTE]\n+====\n+A query will always target a single entity type and is evaluated over the contents of a single cache. Running a\n+query over multiple caches or creating queries that target several entity types (joins) is not supported.\n+====\n+\n+Executing the query and fetching the results is as simple as invoking the `run()` method of the _Query_ object. Once\n+executed, calling `run()` on the same instance will re-execute the query.\n+\n+=== Pagination\n+\n+You can limit the number of returned results by using  the `Query.maxResults(int maxResults)`. This can be used in\n+conjunction with `Query.startOffset(long startOffset)` to achieve pagination of the result set.\n+\n+[source,java]\n+----\n+// sorted by year and match all books that have \"clustering\" in their title\n+// and return the third page of 10 results\n+Query<Book> query = queryFactory.create(\"FROM com.acme.Book WHERE title like '%clustering%' ORDER BY year\").startOffset(20).maxResults(10)\n+----\n+\n+=== Number of Hits\n+\n+The `QueryResult` object has the `.hitCount()` method to return the total number of results of the query, regardless\n+of any pagination parameter. The hit count is only available for indexed queries for performance reasons.\n+\n+\n+=== Iteration\n+\n+The `Query` object has the `.iterator()` method to obtain the results lazily. It returns an instance of `CloseableIterator` that must be closed after usage.\n+\n+[NOTE]\n+====\n+The iteration support for Remote Queries is currently limited, as it will first fetch all entries to the client\n+before iterating.\n+====\n+\n+=== Using Named Query Parameters\n+\n+Instead of building a new Query object for every execution it is possible to include named parameters in the query which\n+can be substituted with actual values before execution. This allows a query to be defined once and be efficiently\n+executed many times. Parameters can only be used on the right-hand side of an operator and are defined when the query is\n+created by supplying an object produced by the _org.infinispan.query.dsl.Expression.param(String paramName)_ method to\n+the operator instead of the usual constant value. Once the parameters have been defined they can be set by invoking either\n+_Query.setParameter(parameterName, value)_ or _Query.setParameters(parameterMap)_ as shown in the examples below.\n+\u2060\n+[source,java,tile=\"Using Named Parameters\"]\n+----\n+QueryFactory queryFactory = Search.getQueryFactory(cache);\n+// Defining a query to search for various authors and publication years\n+Query<Book> query = queryFactory.create(\"SELECT title FROM com.acme.Book WHERE author = :authorName AND publicationYear = :publicationYear\").build();\n+\n+// Set actual parameter values\n+query.setParameter(\"authorName\", \"Doe\");\n+query.setParameter(\"publicationYear\", 2010);\n+\n+// Execute the query\n+List<Book> found = query.list();\n+----\n+\n+Alternatively, you can supply a map of actual parameter values to set multiple parameters at once:\n+\u2060\n+[source,java,title=\"Setting multiple named parameters at once\"]\n+----\n+Map<String, Object> parameterMap = new HashMap<>();\n+parameterMap.put(\"authorName\", \"Doe\");\n+parameterMap.put(\"publicationYear\", 2010);\n+\n+query.setParameters(parameterMap);\n+----\n+\n+NOTE: A significant portion of the query parsing, validation and execution planning effort is performed during the first", "originalCommit": "12fae93eb5e527da5781daf106152840b0e2ee51", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3ODAxMw==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437978013", "bodyText": "right, there are quite a few NOTEs that need to be upgraded, I will change all", "author": "gustavonalle", "createdAt": "2020-06-10T09:11:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3MDU5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3MDc3Ng==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437970776", "bodyText": "Note format", "author": "oraNod", "createdAt": "2020-06-10T08:58:50Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1087 @@\n+[id='search_api']\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} provides a search API that lets you index and search cache values stored as Java POJOs or as objects encoded as link:https://developers.google.com/protocol-buffers/[Protocol Buffers].\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+\n+In the programmatic config, `enabled()` must be used.\n+\n+=== Specifying Indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+[[searching_ickle]]\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+[NOTE]\n+====\n+A query will always target a single entity type and is evaluated over the contents of a single cache. Running a\n+query over multiple caches or creating queries that target several entity types (joins) is not supported.\n+====\n+\n+Executing the query and fetching the results is as simple as invoking the `run()` method of the _Query_ object. Once\n+executed, calling `run()` on the same instance will re-execute the query.\n+\n+=== Pagination\n+\n+You can limit the number of returned results by using  the `Query.maxResults(int maxResults)`. This can be used in\n+conjunction with `Query.startOffset(long startOffset)` to achieve pagination of the result set.\n+\n+[source,java]\n+----\n+// sorted by year and match all books that have \"clustering\" in their title\n+// and return the third page of 10 results\n+Query<Book> query = queryFactory.create(\"FROM com.acme.Book WHERE title like '%clustering%' ORDER BY year\").startOffset(20).maxResults(10)\n+----\n+\n+=== Number of Hits\n+\n+The `QueryResult` object has the `.hitCount()` method to return the total number of results of the query, regardless\n+of any pagination parameter. The hit count is only available for indexed queries for performance reasons.\n+\n+\n+=== Iteration\n+\n+The `Query` object has the `.iterator()` method to obtain the results lazily. It returns an instance of `CloseableIterator` that must be closed after usage.\n+\n+[NOTE]\n+====\n+The iteration support for Remote Queries is currently limited, as it will first fetch all entries to the client\n+before iterating.\n+====\n+\n+=== Using Named Query Parameters\n+\n+Instead of building a new Query object for every execution it is possible to include named parameters in the query which\n+can be substituted with actual values before execution. This allows a query to be defined once and be efficiently\n+executed many times. Parameters can only be used on the right-hand side of an operator and are defined when the query is\n+created by supplying an object produced by the _org.infinispan.query.dsl.Expression.param(String paramName)_ method to\n+the operator instead of the usual constant value. Once the parameters have been defined they can be set by invoking either\n+_Query.setParameter(parameterName, value)_ or _Query.setParameters(parameterMap)_ as shown in the examples below.\n+\u2060\n+[source,java,tile=\"Using Named Parameters\"]\n+----\n+QueryFactory queryFactory = Search.getQueryFactory(cache);\n+// Defining a query to search for various authors and publication years\n+Query<Book> query = queryFactory.create(\"SELECT title FROM com.acme.Book WHERE author = :authorName AND publicationYear = :publicationYear\").build();\n+\n+// Set actual parameter values\n+query.setParameter(\"authorName\", \"Doe\");\n+query.setParameter(\"publicationYear\", 2010);\n+\n+// Execute the query\n+List<Book> found = query.list();\n+----\n+\n+Alternatively, you can supply a map of actual parameter values to set multiple parameters at once:\n+\u2060\n+[source,java,title=\"Setting multiple named parameters at once\"]\n+----\n+Map<String, Object> parameterMap = new HashMap<>();\n+parameterMap.put(\"authorName\", \"Doe\");\n+parameterMap.put(\"publicationYear\", 2010);\n+\n+query.setParameters(parameterMap);\n+----\n+\n+NOTE: A significant portion of the query parsing, validation and execution planning effort is performed during the first\n+execution of a query with parameters. This effort is not repeated during subsequent executions leading to better\n+performance compared to a similar query using constant values instead of query parameters.\n+\n+[[query_ickle]]\n+=== Ickle Query Language Parser Syntax\n+\n+The Ickle query language is small subset of the link:https://en.wikipedia.org/wiki/Java_Persistence_Query_Language[JPQL]\n+query language, with some extensions for full-text.\n+\n+The parser syntax has some notable rules:\n+\n+* Whitespace is not significant.\n+* Wildcards are not supported in field names.\n+* A field name or path must always be specified, as there is no default field.\n+* `&&` and `||` are accepted instead of `AND` or `OR` in both full-text and JPA predicates.\n+* `!` may be used instead of `NOT`.\n+* A missing boolean operator is interpreted as `OR`.\n+* String terms must be enclosed with either single or double quotes.\n+* Fuzziness and boosting are not accepted in arbitrary order; fuzziness always comes first.\n+* `!=` is accepted instead of `<>`.\n+* Boosting cannot be applied to `>`,`>=`,`<`,`<=` operators. Ranges may be used to achieve the same result.\n+\n+==== Filtering operators\n+\n+Ickle support many filtering operators that can be used for both indexed and non-indexed fields.\n+\n+[options=\"header\"]\n+|==============================================================================\n+| Operator | Description | Example\n+| in | Checks that the left operand is equal to one of the elements from the Collection of values given as argument.\n+|FROM Book WHERE isbn IN ('ZZ', 'X1234')\n+| like | Checks that the left argument (which is expected to be a String) matches a wildcard pattern that follows the JPA rules.| FROM Book WHERE title LIKE '%Java%'\n+|=| Checks that the left argument is an exact match of the given value         | FROM Book WHERE name = 'Programming Java'\n+|!=| Checks that the left argument is different from the given value            | FROM Book WHERE language != 'English'\n+|>| Checks that the left argument is greater than the given value.             | FROM Book WHERE price > 20\n+|>=| Checks that the left argument is greater than or equal to the given value. | FROM Book WHERE price >= 20\n+|<| Checks that the left argument is less than the given value.                | FROM Book WHERE year < 2012\n+|<=| Checks that the left argument is less than or equal to the given value.   | FROM Book WHERE price  <= 50\n+|between| Checks that the left argument is between the given range limits.  | FROM Book WHERE price BETWEEN 50 AND 100\n+|==============================================================================\n+\n+==== Boolean conditions\n+\n+Combining multiple attribute conditions with logical conjunction (`and`) and disjunction (`or`) operators in order to\n+create more complex conditions is demonstrated in the following example. The well known operator precedence rule for\n+boolean operators applies here, so the order of the operators is irrelevant. Here `and`\n+operator still has higher priority than `or` even though `or` was invoked first.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title\n+# or have an author named \"Manik\" and their description contains \"clustering\"\n+\n+FROM com.acme.Book WHERE title LIKE '%Data Grid%' OR author.name = 'Manik' AND description like '%clustering%'\n+----\n+\n+Boolean negation has highest precedence among logical operators and applies only to the next simple attribute condition.\n+\n+[source,sql]\n+----\n+# match all books that do not have \"Data Grid\" in their title and are authored by \"Manik\"\n+FROM com.acme.Book WHERE title != 'Data Grid' AND author.name = 'Manik'\n+\n+----\n+\n+==== Nested conditions\n+Changing the precedence of logical operators is achieved with parenthesis:\n+\n+[source,sql]\n+----\n+# match all books that have an author named \"Manik\" and their title contains\n+# \"Data Grid\" or their description contains \"clustering\"\n+FROM com.acme.Book WHERE author.name = 'Manik' AND ( title like '%Data Grid%' OR description like '% clustering%')\n+----\n+\n+==== Selecting attributes\n+In some use cases returning the whole domain object is overkill if only a small subset of the attributes are actually\n+used by the application, especially if the domain entity has embedded entities. The query language allows you to specify\n+a subset of attributes (or attribute paths) to return - the projection. If projections are used then the `QueryResult.list()`\n+will not return the whole domain entity but will return a _List_ of _Object[]_, each slot in the array corresponding to\n+a projected attribute.\n+\n+//TODO document what needs to be configured for an attribute to be available for projection.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return only their title and publication year\n+SELECT title, publicationYear FROM com.acme.Book WHERE title like '%Data Grid%' OR description like '%Data Grid%'\n+----\n+\n+==== Sorting\n+Ordering the results based on one or more attributes or attribute paths is done with the `ORDER BY` clause. If multiple sorting criteria\n+are specified, then the order will dictate their precedence.\n+\n+\n+//TODO document what needs to be configured for an attribute to be available for sorting.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return them sorted by the publication year and title\n+FROM com.acme.Book WHERE title like '%Data Grid%' ORDER BY publicationYear DESC, title ASC\n+----\n+\n+==== Grouping and Aggregation\n+\n+{brandname} has the ability to group query results according to a set of grouping fields and construct aggregations of\n+the results from each group by applying an aggregation function to the set of values that fall into each group.\n+Grouping and aggregation can only be applied to projection queries (queries with one or more field in the SELECT clause).\n+\n+The supported aggregations are: avg, sum, count, max, min.\n+\n+The set of grouping fields is specified with the `GROUP BY` clause and the order used for defining grouping fields is\n+not relevant. All fields selected in the projection must either be grouping fields\n+or else they must be aggregated using one of the grouping functions described below. A projection field can be\n+aggregated and used for grouping at the same time. A query that selects only grouping fields but no aggregation fields\n+is legal.\n+\u2060\n+Example: Grouping Books by author and counting them.\n+[source,sql]\n+----\n+SELECT author, COUNT(title) FROM com.acme.Book WHERE title LIKE '%engine%' GROUP BY author\n+----\n+\n+NOTE: A projection query in which all selected fields have an aggregation function applied and no fields are used for", "originalCommit": "12fae93eb5e527da5781daf106152840b0e2ee51", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3MTk2Mw==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437971963", "bodyText": "Better to address the reader directly, avoid passive voice, use \"can\" over \"may\".\nYou can apply the following aggregation functions to fields:\nIMO it's worth removing \"avg, sum, count, max, min\" because the sentence introduces the unordered list.", "author": "oraNod", "createdAt": "2020-06-10T09:00:45Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1087 @@\n+[id='search_api']\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} provides a search API that lets you index and search cache values stored as Java POJOs or as objects encoded as link:https://developers.google.com/protocol-buffers/[Protocol Buffers].\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+\n+In the programmatic config, `enabled()` must be used.\n+\n+=== Specifying Indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+[[searching_ickle]]\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+[NOTE]\n+====\n+A query will always target a single entity type and is evaluated over the contents of a single cache. Running a\n+query over multiple caches or creating queries that target several entity types (joins) is not supported.\n+====\n+\n+Executing the query and fetching the results is as simple as invoking the `run()` method of the _Query_ object. Once\n+executed, calling `run()` on the same instance will re-execute the query.\n+\n+=== Pagination\n+\n+You can limit the number of returned results by using  the `Query.maxResults(int maxResults)`. This can be used in\n+conjunction with `Query.startOffset(long startOffset)` to achieve pagination of the result set.\n+\n+[source,java]\n+----\n+// sorted by year and match all books that have \"clustering\" in their title\n+// and return the third page of 10 results\n+Query<Book> query = queryFactory.create(\"FROM com.acme.Book WHERE title like '%clustering%' ORDER BY year\").startOffset(20).maxResults(10)\n+----\n+\n+=== Number of Hits\n+\n+The `QueryResult` object has the `.hitCount()` method to return the total number of results of the query, regardless\n+of any pagination parameter. The hit count is only available for indexed queries for performance reasons.\n+\n+\n+=== Iteration\n+\n+The `Query` object has the `.iterator()` method to obtain the results lazily. It returns an instance of `CloseableIterator` that must be closed after usage.\n+\n+[NOTE]\n+====\n+The iteration support for Remote Queries is currently limited, as it will first fetch all entries to the client\n+before iterating.\n+====\n+\n+=== Using Named Query Parameters\n+\n+Instead of building a new Query object for every execution it is possible to include named parameters in the query which\n+can be substituted with actual values before execution. This allows a query to be defined once and be efficiently\n+executed many times. Parameters can only be used on the right-hand side of an operator and are defined when the query is\n+created by supplying an object produced by the _org.infinispan.query.dsl.Expression.param(String paramName)_ method to\n+the operator instead of the usual constant value. Once the parameters have been defined they can be set by invoking either\n+_Query.setParameter(parameterName, value)_ or _Query.setParameters(parameterMap)_ as shown in the examples below.\n+\u2060\n+[source,java,tile=\"Using Named Parameters\"]\n+----\n+QueryFactory queryFactory = Search.getQueryFactory(cache);\n+// Defining a query to search for various authors and publication years\n+Query<Book> query = queryFactory.create(\"SELECT title FROM com.acme.Book WHERE author = :authorName AND publicationYear = :publicationYear\").build();\n+\n+// Set actual parameter values\n+query.setParameter(\"authorName\", \"Doe\");\n+query.setParameter(\"publicationYear\", 2010);\n+\n+// Execute the query\n+List<Book> found = query.list();\n+----\n+\n+Alternatively, you can supply a map of actual parameter values to set multiple parameters at once:\n+\u2060\n+[source,java,title=\"Setting multiple named parameters at once\"]\n+----\n+Map<String, Object> parameterMap = new HashMap<>();\n+parameterMap.put(\"authorName\", \"Doe\");\n+parameterMap.put(\"publicationYear\", 2010);\n+\n+query.setParameters(parameterMap);\n+----\n+\n+NOTE: A significant portion of the query parsing, validation and execution planning effort is performed during the first\n+execution of a query with parameters. This effort is not repeated during subsequent executions leading to better\n+performance compared to a similar query using constant values instead of query parameters.\n+\n+[[query_ickle]]\n+=== Ickle Query Language Parser Syntax\n+\n+The Ickle query language is small subset of the link:https://en.wikipedia.org/wiki/Java_Persistence_Query_Language[JPQL]\n+query language, with some extensions for full-text.\n+\n+The parser syntax has some notable rules:\n+\n+* Whitespace is not significant.\n+* Wildcards are not supported in field names.\n+* A field name or path must always be specified, as there is no default field.\n+* `&&` and `||` are accepted instead of `AND` or `OR` in both full-text and JPA predicates.\n+* `!` may be used instead of `NOT`.\n+* A missing boolean operator is interpreted as `OR`.\n+* String terms must be enclosed with either single or double quotes.\n+* Fuzziness and boosting are not accepted in arbitrary order; fuzziness always comes first.\n+* `!=` is accepted instead of `<>`.\n+* Boosting cannot be applied to `>`,`>=`,`<`,`<=` operators. Ranges may be used to achieve the same result.\n+\n+==== Filtering operators\n+\n+Ickle support many filtering operators that can be used for both indexed and non-indexed fields.\n+\n+[options=\"header\"]\n+|==============================================================================\n+| Operator | Description | Example\n+| in | Checks that the left operand is equal to one of the elements from the Collection of values given as argument.\n+|FROM Book WHERE isbn IN ('ZZ', 'X1234')\n+| like | Checks that the left argument (which is expected to be a String) matches a wildcard pattern that follows the JPA rules.| FROM Book WHERE title LIKE '%Java%'\n+|=| Checks that the left argument is an exact match of the given value         | FROM Book WHERE name = 'Programming Java'\n+|!=| Checks that the left argument is different from the given value            | FROM Book WHERE language != 'English'\n+|>| Checks that the left argument is greater than the given value.             | FROM Book WHERE price > 20\n+|>=| Checks that the left argument is greater than or equal to the given value. | FROM Book WHERE price >= 20\n+|<| Checks that the left argument is less than the given value.                | FROM Book WHERE year < 2012\n+|<=| Checks that the left argument is less than or equal to the given value.   | FROM Book WHERE price  <= 50\n+|between| Checks that the left argument is between the given range limits.  | FROM Book WHERE price BETWEEN 50 AND 100\n+|==============================================================================\n+\n+==== Boolean conditions\n+\n+Combining multiple attribute conditions with logical conjunction (`and`) and disjunction (`or`) operators in order to\n+create more complex conditions is demonstrated in the following example. The well known operator precedence rule for\n+boolean operators applies here, so the order of the operators is irrelevant. Here `and`\n+operator still has higher priority than `or` even though `or` was invoked first.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title\n+# or have an author named \"Manik\" and their description contains \"clustering\"\n+\n+FROM com.acme.Book WHERE title LIKE '%Data Grid%' OR author.name = 'Manik' AND description like '%clustering%'\n+----\n+\n+Boolean negation has highest precedence among logical operators and applies only to the next simple attribute condition.\n+\n+[source,sql]\n+----\n+# match all books that do not have \"Data Grid\" in their title and are authored by \"Manik\"\n+FROM com.acme.Book WHERE title != 'Data Grid' AND author.name = 'Manik'\n+\n+----\n+\n+==== Nested conditions\n+Changing the precedence of logical operators is achieved with parenthesis:\n+\n+[source,sql]\n+----\n+# match all books that have an author named \"Manik\" and their title contains\n+# \"Data Grid\" or their description contains \"clustering\"\n+FROM com.acme.Book WHERE author.name = 'Manik' AND ( title like '%Data Grid%' OR description like '% clustering%')\n+----\n+\n+==== Selecting attributes\n+In some use cases returning the whole domain object is overkill if only a small subset of the attributes are actually\n+used by the application, especially if the domain entity has embedded entities. The query language allows you to specify\n+a subset of attributes (or attribute paths) to return - the projection. If projections are used then the `QueryResult.list()`\n+will not return the whole domain entity but will return a _List_ of _Object[]_, each slot in the array corresponding to\n+a projected attribute.\n+\n+//TODO document what needs to be configured for an attribute to be available for projection.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return only their title and publication year\n+SELECT title, publicationYear FROM com.acme.Book WHERE title like '%Data Grid%' OR description like '%Data Grid%'\n+----\n+\n+==== Sorting\n+Ordering the results based on one or more attributes or attribute paths is done with the `ORDER BY` clause. If multiple sorting criteria\n+are specified, then the order will dictate their precedence.\n+\n+\n+//TODO document what needs to be configured for an attribute to be available for sorting.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return them sorted by the publication year and title\n+FROM com.acme.Book WHERE title like '%Data Grid%' ORDER BY publicationYear DESC, title ASC\n+----\n+\n+==== Grouping and Aggregation\n+\n+{brandname} has the ability to group query results according to a set of grouping fields and construct aggregations of\n+the results from each group by applying an aggregation function to the set of values that fall into each group.\n+Grouping and aggregation can only be applied to projection queries (queries with one or more field in the SELECT clause).\n+\n+The supported aggregations are: avg, sum, count, max, min.\n+\n+The set of grouping fields is specified with the `GROUP BY` clause and the order used for defining grouping fields is\n+not relevant. All fields selected in the projection must either be grouping fields\n+or else they must be aggregated using one of the grouping functions described below. A projection field can be\n+aggregated and used for grouping at the same time. A query that selects only grouping fields but no aggregation fields\n+is legal.\n+\u2060\n+Example: Grouping Books by author and counting them.\n+[source,sql]\n+----\n+SELECT author, COUNT(title) FROM com.acme.Book WHERE title LIKE '%engine%' GROUP BY author\n+----\n+\n+NOTE: A projection query in which all selected fields have an aggregation function applied and no fields are used for\n+grouping is allowed. In this case the aggregations will be computed globally as if there was a single global group.\n+\n+==== Aggregations\n+\n+The following aggregation functions may be applied to a field: avg, sum, count, max, min", "originalCommit": "12fae93eb5e527da5781daf106152840b0e2ee51", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3OTE5OQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437979199", "bodyText": "You may be sure I will change this \ud83d\ude04", "author": "gustavonalle", "createdAt": "2020-06-10T09:13:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3MTk2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3MjM5Ng==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437972396", "bodyText": "Use code markup: avg()", "author": "oraNod", "createdAt": "2020-06-10T09:01:27Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1087 @@\n+[id='search_api']\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} provides a search API that lets you index and search cache values stored as Java POJOs or as objects encoded as link:https://developers.google.com/protocol-buffers/[Protocol Buffers].\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+\n+In the programmatic config, `enabled()` must be used.\n+\n+=== Specifying Indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+[[searching_ickle]]\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+[NOTE]\n+====\n+A query will always target a single entity type and is evaluated over the contents of a single cache. Running a\n+query over multiple caches or creating queries that target several entity types (joins) is not supported.\n+====\n+\n+Executing the query and fetching the results is as simple as invoking the `run()` method of the _Query_ object. Once\n+executed, calling `run()` on the same instance will re-execute the query.\n+\n+=== Pagination\n+\n+You can limit the number of returned results by using  the `Query.maxResults(int maxResults)`. This can be used in\n+conjunction with `Query.startOffset(long startOffset)` to achieve pagination of the result set.\n+\n+[source,java]\n+----\n+// sorted by year and match all books that have \"clustering\" in their title\n+// and return the third page of 10 results\n+Query<Book> query = queryFactory.create(\"FROM com.acme.Book WHERE title like '%clustering%' ORDER BY year\").startOffset(20).maxResults(10)\n+----\n+\n+=== Number of Hits\n+\n+The `QueryResult` object has the `.hitCount()` method to return the total number of results of the query, regardless\n+of any pagination parameter. The hit count is only available for indexed queries for performance reasons.\n+\n+\n+=== Iteration\n+\n+The `Query` object has the `.iterator()` method to obtain the results lazily. It returns an instance of `CloseableIterator` that must be closed after usage.\n+\n+[NOTE]\n+====\n+The iteration support for Remote Queries is currently limited, as it will first fetch all entries to the client\n+before iterating.\n+====\n+\n+=== Using Named Query Parameters\n+\n+Instead of building a new Query object for every execution it is possible to include named parameters in the query which\n+can be substituted with actual values before execution. This allows a query to be defined once and be efficiently\n+executed many times. Parameters can only be used on the right-hand side of an operator and are defined when the query is\n+created by supplying an object produced by the _org.infinispan.query.dsl.Expression.param(String paramName)_ method to\n+the operator instead of the usual constant value. Once the parameters have been defined they can be set by invoking either\n+_Query.setParameter(parameterName, value)_ or _Query.setParameters(parameterMap)_ as shown in the examples below.\n+\u2060\n+[source,java,tile=\"Using Named Parameters\"]\n+----\n+QueryFactory queryFactory = Search.getQueryFactory(cache);\n+// Defining a query to search for various authors and publication years\n+Query<Book> query = queryFactory.create(\"SELECT title FROM com.acme.Book WHERE author = :authorName AND publicationYear = :publicationYear\").build();\n+\n+// Set actual parameter values\n+query.setParameter(\"authorName\", \"Doe\");\n+query.setParameter(\"publicationYear\", 2010);\n+\n+// Execute the query\n+List<Book> found = query.list();\n+----\n+\n+Alternatively, you can supply a map of actual parameter values to set multiple parameters at once:\n+\u2060\n+[source,java,title=\"Setting multiple named parameters at once\"]\n+----\n+Map<String, Object> parameterMap = new HashMap<>();\n+parameterMap.put(\"authorName\", \"Doe\");\n+parameterMap.put(\"publicationYear\", 2010);\n+\n+query.setParameters(parameterMap);\n+----\n+\n+NOTE: A significant portion of the query parsing, validation and execution planning effort is performed during the first\n+execution of a query with parameters. This effort is not repeated during subsequent executions leading to better\n+performance compared to a similar query using constant values instead of query parameters.\n+\n+[[query_ickle]]\n+=== Ickle Query Language Parser Syntax\n+\n+The Ickle query language is small subset of the link:https://en.wikipedia.org/wiki/Java_Persistence_Query_Language[JPQL]\n+query language, with some extensions for full-text.\n+\n+The parser syntax has some notable rules:\n+\n+* Whitespace is not significant.\n+* Wildcards are not supported in field names.\n+* A field name or path must always be specified, as there is no default field.\n+* `&&` and `||` are accepted instead of `AND` or `OR` in both full-text and JPA predicates.\n+* `!` may be used instead of `NOT`.\n+* A missing boolean operator is interpreted as `OR`.\n+* String terms must be enclosed with either single or double quotes.\n+* Fuzziness and boosting are not accepted in arbitrary order; fuzziness always comes first.\n+* `!=` is accepted instead of `<>`.\n+* Boosting cannot be applied to `>`,`>=`,`<`,`<=` operators. Ranges may be used to achieve the same result.\n+\n+==== Filtering operators\n+\n+Ickle support many filtering operators that can be used for both indexed and non-indexed fields.\n+\n+[options=\"header\"]\n+|==============================================================================\n+| Operator | Description | Example\n+| in | Checks that the left operand is equal to one of the elements from the Collection of values given as argument.\n+|FROM Book WHERE isbn IN ('ZZ', 'X1234')\n+| like | Checks that the left argument (which is expected to be a String) matches a wildcard pattern that follows the JPA rules.| FROM Book WHERE title LIKE '%Java%'\n+|=| Checks that the left argument is an exact match of the given value         | FROM Book WHERE name = 'Programming Java'\n+|!=| Checks that the left argument is different from the given value            | FROM Book WHERE language != 'English'\n+|>| Checks that the left argument is greater than the given value.             | FROM Book WHERE price > 20\n+|>=| Checks that the left argument is greater than or equal to the given value. | FROM Book WHERE price >= 20\n+|<| Checks that the left argument is less than the given value.                | FROM Book WHERE year < 2012\n+|<=| Checks that the left argument is less than or equal to the given value.   | FROM Book WHERE price  <= 50\n+|between| Checks that the left argument is between the given range limits.  | FROM Book WHERE price BETWEEN 50 AND 100\n+|==============================================================================\n+\n+==== Boolean conditions\n+\n+Combining multiple attribute conditions with logical conjunction (`and`) and disjunction (`or`) operators in order to\n+create more complex conditions is demonstrated in the following example. The well known operator precedence rule for\n+boolean operators applies here, so the order of the operators is irrelevant. Here `and`\n+operator still has higher priority than `or` even though `or` was invoked first.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title\n+# or have an author named \"Manik\" and their description contains \"clustering\"\n+\n+FROM com.acme.Book WHERE title LIKE '%Data Grid%' OR author.name = 'Manik' AND description like '%clustering%'\n+----\n+\n+Boolean negation has highest precedence among logical operators and applies only to the next simple attribute condition.\n+\n+[source,sql]\n+----\n+# match all books that do not have \"Data Grid\" in their title and are authored by \"Manik\"\n+FROM com.acme.Book WHERE title != 'Data Grid' AND author.name = 'Manik'\n+\n+----\n+\n+==== Nested conditions\n+Changing the precedence of logical operators is achieved with parenthesis:\n+\n+[source,sql]\n+----\n+# match all books that have an author named \"Manik\" and their title contains\n+# \"Data Grid\" or their description contains \"clustering\"\n+FROM com.acme.Book WHERE author.name = 'Manik' AND ( title like '%Data Grid%' OR description like '% clustering%')\n+----\n+\n+==== Selecting attributes\n+In some use cases returning the whole domain object is overkill if only a small subset of the attributes are actually\n+used by the application, especially if the domain entity has embedded entities. The query language allows you to specify\n+a subset of attributes (or attribute paths) to return - the projection. If projections are used then the `QueryResult.list()`\n+will not return the whole domain entity but will return a _List_ of _Object[]_, each slot in the array corresponding to\n+a projected attribute.\n+\n+//TODO document what needs to be configured for an attribute to be available for projection.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return only their title and publication year\n+SELECT title, publicationYear FROM com.acme.Book WHERE title like '%Data Grid%' OR description like '%Data Grid%'\n+----\n+\n+==== Sorting\n+Ordering the results based on one or more attributes or attribute paths is done with the `ORDER BY` clause. If multiple sorting criteria\n+are specified, then the order will dictate their precedence.\n+\n+\n+//TODO document what needs to be configured for an attribute to be available for sorting.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return them sorted by the publication year and title\n+FROM com.acme.Book WHERE title like '%Data Grid%' ORDER BY publicationYear DESC, title ASC\n+----\n+\n+==== Grouping and Aggregation\n+\n+{brandname} has the ability to group query results according to a set of grouping fields and construct aggregations of\n+the results from each group by applying an aggregation function to the set of values that fall into each group.\n+Grouping and aggregation can only be applied to projection queries (queries with one or more field in the SELECT clause).\n+\n+The supported aggregations are: avg, sum, count, max, min.\n+\n+The set of grouping fields is specified with the `GROUP BY` clause and the order used for defining grouping fields is\n+not relevant. All fields selected in the projection must either be grouping fields\n+or else they must be aggregated using one of the grouping functions described below. A projection field can be\n+aggregated and used for grouping at the same time. A query that selects only grouping fields but no aggregation fields\n+is legal.\n+\u2060\n+Example: Grouping Books by author and counting them.\n+[source,sql]\n+----\n+SELECT author, COUNT(title) FROM com.acme.Book WHERE title LIKE '%engine%' GROUP BY author\n+----\n+\n+NOTE: A projection query in which all selected fields have an aggregation function applied and no fields are used for\n+grouping is allowed. In this case the aggregations will be computed globally as if there was a single global group.\n+\n+==== Aggregations\n+\n+The following aggregation functions may be applied to a field: avg, sum, count, max, min\n+\n+\n+* avg() - Computes the average of a set of numbers. Accepted values are primitive numbers and instances of _java.lang.Number_. The result is represented as _java.lang.Double_. If there are no non-null values the result is _null_ instead.", "originalCommit": "12fae93eb5e527da5781daf106152840b0e2ee51", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3Mjg1Mg==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437972852", "bodyText": "count()", "author": "oraNod", "createdAt": "2020-06-10T09:02:12Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1087 @@\n+[id='search_api']\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} provides a search API that lets you index and search cache values stored as Java POJOs or as objects encoded as link:https://developers.google.com/protocol-buffers/[Protocol Buffers].\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+\n+In the programmatic config, `enabled()` must be used.\n+\n+=== Specifying Indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+[[searching_ickle]]\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+[NOTE]\n+====\n+A query will always target a single entity type and is evaluated over the contents of a single cache. Running a\n+query over multiple caches or creating queries that target several entity types (joins) is not supported.\n+====\n+\n+Executing the query and fetching the results is as simple as invoking the `run()` method of the _Query_ object. Once\n+executed, calling `run()` on the same instance will re-execute the query.\n+\n+=== Pagination\n+\n+You can limit the number of returned results by using  the `Query.maxResults(int maxResults)`. This can be used in\n+conjunction with `Query.startOffset(long startOffset)` to achieve pagination of the result set.\n+\n+[source,java]\n+----\n+// sorted by year and match all books that have \"clustering\" in their title\n+// and return the third page of 10 results\n+Query<Book> query = queryFactory.create(\"FROM com.acme.Book WHERE title like '%clustering%' ORDER BY year\").startOffset(20).maxResults(10)\n+----\n+\n+=== Number of Hits\n+\n+The `QueryResult` object has the `.hitCount()` method to return the total number of results of the query, regardless\n+of any pagination parameter. The hit count is only available for indexed queries for performance reasons.\n+\n+\n+=== Iteration\n+\n+The `Query` object has the `.iterator()` method to obtain the results lazily. It returns an instance of `CloseableIterator` that must be closed after usage.\n+\n+[NOTE]\n+====\n+The iteration support for Remote Queries is currently limited, as it will first fetch all entries to the client\n+before iterating.\n+====\n+\n+=== Using Named Query Parameters\n+\n+Instead of building a new Query object for every execution it is possible to include named parameters in the query which\n+can be substituted with actual values before execution. This allows a query to be defined once and be efficiently\n+executed many times. Parameters can only be used on the right-hand side of an operator and are defined when the query is\n+created by supplying an object produced by the _org.infinispan.query.dsl.Expression.param(String paramName)_ method to\n+the operator instead of the usual constant value. Once the parameters have been defined they can be set by invoking either\n+_Query.setParameter(parameterName, value)_ or _Query.setParameters(parameterMap)_ as shown in the examples below.\n+\u2060\n+[source,java,tile=\"Using Named Parameters\"]\n+----\n+QueryFactory queryFactory = Search.getQueryFactory(cache);\n+// Defining a query to search for various authors and publication years\n+Query<Book> query = queryFactory.create(\"SELECT title FROM com.acme.Book WHERE author = :authorName AND publicationYear = :publicationYear\").build();\n+\n+// Set actual parameter values\n+query.setParameter(\"authorName\", \"Doe\");\n+query.setParameter(\"publicationYear\", 2010);\n+\n+// Execute the query\n+List<Book> found = query.list();\n+----\n+\n+Alternatively, you can supply a map of actual parameter values to set multiple parameters at once:\n+\u2060\n+[source,java,title=\"Setting multiple named parameters at once\"]\n+----\n+Map<String, Object> parameterMap = new HashMap<>();\n+parameterMap.put(\"authorName\", \"Doe\");\n+parameterMap.put(\"publicationYear\", 2010);\n+\n+query.setParameters(parameterMap);\n+----\n+\n+NOTE: A significant portion of the query parsing, validation and execution planning effort is performed during the first\n+execution of a query with parameters. This effort is not repeated during subsequent executions leading to better\n+performance compared to a similar query using constant values instead of query parameters.\n+\n+[[query_ickle]]\n+=== Ickle Query Language Parser Syntax\n+\n+The Ickle query language is small subset of the link:https://en.wikipedia.org/wiki/Java_Persistence_Query_Language[JPQL]\n+query language, with some extensions for full-text.\n+\n+The parser syntax has some notable rules:\n+\n+* Whitespace is not significant.\n+* Wildcards are not supported in field names.\n+* A field name or path must always be specified, as there is no default field.\n+* `&&` and `||` are accepted instead of `AND` or `OR` in both full-text and JPA predicates.\n+* `!` may be used instead of `NOT`.\n+* A missing boolean operator is interpreted as `OR`.\n+* String terms must be enclosed with either single or double quotes.\n+* Fuzziness and boosting are not accepted in arbitrary order; fuzziness always comes first.\n+* `!=` is accepted instead of `<>`.\n+* Boosting cannot be applied to `>`,`>=`,`<`,`<=` operators. Ranges may be used to achieve the same result.\n+\n+==== Filtering operators\n+\n+Ickle support many filtering operators that can be used for both indexed and non-indexed fields.\n+\n+[options=\"header\"]\n+|==============================================================================\n+| Operator | Description | Example\n+| in | Checks that the left operand is equal to one of the elements from the Collection of values given as argument.\n+|FROM Book WHERE isbn IN ('ZZ', 'X1234')\n+| like | Checks that the left argument (which is expected to be a String) matches a wildcard pattern that follows the JPA rules.| FROM Book WHERE title LIKE '%Java%'\n+|=| Checks that the left argument is an exact match of the given value         | FROM Book WHERE name = 'Programming Java'\n+|!=| Checks that the left argument is different from the given value            | FROM Book WHERE language != 'English'\n+|>| Checks that the left argument is greater than the given value.             | FROM Book WHERE price > 20\n+|>=| Checks that the left argument is greater than or equal to the given value. | FROM Book WHERE price >= 20\n+|<| Checks that the left argument is less than the given value.                | FROM Book WHERE year < 2012\n+|<=| Checks that the left argument is less than or equal to the given value.   | FROM Book WHERE price  <= 50\n+|between| Checks that the left argument is between the given range limits.  | FROM Book WHERE price BETWEEN 50 AND 100\n+|==============================================================================\n+\n+==== Boolean conditions\n+\n+Combining multiple attribute conditions with logical conjunction (`and`) and disjunction (`or`) operators in order to\n+create more complex conditions is demonstrated in the following example. The well known operator precedence rule for\n+boolean operators applies here, so the order of the operators is irrelevant. Here `and`\n+operator still has higher priority than `or` even though `or` was invoked first.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title\n+# or have an author named \"Manik\" and their description contains \"clustering\"\n+\n+FROM com.acme.Book WHERE title LIKE '%Data Grid%' OR author.name = 'Manik' AND description like '%clustering%'\n+----\n+\n+Boolean negation has highest precedence among logical operators and applies only to the next simple attribute condition.\n+\n+[source,sql]\n+----\n+# match all books that do not have \"Data Grid\" in their title and are authored by \"Manik\"\n+FROM com.acme.Book WHERE title != 'Data Grid' AND author.name = 'Manik'\n+\n+----\n+\n+==== Nested conditions\n+Changing the precedence of logical operators is achieved with parenthesis:\n+\n+[source,sql]\n+----\n+# match all books that have an author named \"Manik\" and their title contains\n+# \"Data Grid\" or their description contains \"clustering\"\n+FROM com.acme.Book WHERE author.name = 'Manik' AND ( title like '%Data Grid%' OR description like '% clustering%')\n+----\n+\n+==== Selecting attributes\n+In some use cases returning the whole domain object is overkill if only a small subset of the attributes are actually\n+used by the application, especially if the domain entity has embedded entities. The query language allows you to specify\n+a subset of attributes (or attribute paths) to return - the projection. If projections are used then the `QueryResult.list()`\n+will not return the whole domain entity but will return a _List_ of _Object[]_, each slot in the array corresponding to\n+a projected attribute.\n+\n+//TODO document what needs to be configured for an attribute to be available for projection.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return only their title and publication year\n+SELECT title, publicationYear FROM com.acme.Book WHERE title like '%Data Grid%' OR description like '%Data Grid%'\n+----\n+\n+==== Sorting\n+Ordering the results based on one or more attributes or attribute paths is done with the `ORDER BY` clause. If multiple sorting criteria\n+are specified, then the order will dictate their precedence.\n+\n+\n+//TODO document what needs to be configured for an attribute to be available for sorting.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return them sorted by the publication year and title\n+FROM com.acme.Book WHERE title like '%Data Grid%' ORDER BY publicationYear DESC, title ASC\n+----\n+\n+==== Grouping and Aggregation\n+\n+{brandname} has the ability to group query results according to a set of grouping fields and construct aggregations of\n+the results from each group by applying an aggregation function to the set of values that fall into each group.\n+Grouping and aggregation can only be applied to projection queries (queries with one or more field in the SELECT clause).\n+\n+The supported aggregations are: avg, sum, count, max, min.\n+\n+The set of grouping fields is specified with the `GROUP BY` clause and the order used for defining grouping fields is\n+not relevant. All fields selected in the projection must either be grouping fields\n+or else they must be aggregated using one of the grouping functions described below. A projection field can be\n+aggregated and used for grouping at the same time. A query that selects only grouping fields but no aggregation fields\n+is legal.\n+\u2060\n+Example: Grouping Books by author and counting them.\n+[source,sql]\n+----\n+SELECT author, COUNT(title) FROM com.acme.Book WHERE title LIKE '%engine%' GROUP BY author\n+----\n+\n+NOTE: A projection query in which all selected fields have an aggregation function applied and no fields are used for\n+grouping is allowed. In this case the aggregations will be computed globally as if there was a single global group.\n+\n+==== Aggregations\n+\n+The following aggregation functions may be applied to a field: avg, sum, count, max, min\n+\n+\n+* avg() - Computes the average of a set of numbers. Accepted values are primitive numbers and instances of _java.lang.Number_. The result is represented as _java.lang.Double_. If there are no non-null values the result is _null_ instead.\n+* count() - Counts the number of non-null rows and returns a _java.lang.Long_. If there are no non-null values the result is _0_ instead.", "originalCommit": "12fae93eb5e527da5781daf106152840b0e2ee51", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3MzA2NA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437973064", "bodyText": "applies to all the ones in this list", "author": "oraNod", "createdAt": "2020-06-10T09:02:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3Mjg1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3NTc1MQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437975751", "bodyText": "I've hesitated a little to mention it because I don't want to go overboard with lots of little comments. I mentioned it in an earlier comment though so I'll bring it up. Code should use monospace formatting rather than italics so we're consistent in the docs. https://infinispan.org/docs/11.0.x/titles/contributing/contributing.html#documentation_guidelines_format_reference\nAlso include \"()\" with method names. So groupBy should change to groupBy()", "author": "oraNod", "createdAt": "2020-06-10T09:07:14Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1087 @@\n+[id='search_api']\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} provides a search API that lets you index and search cache values stored as Java POJOs or as objects encoded as link:https://developers.google.com/protocol-buffers/[Protocol Buffers].\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+\n+In the programmatic config, `enabled()` must be used.\n+\n+=== Specifying Indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+[[searching_ickle]]\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+[NOTE]\n+====\n+A query will always target a single entity type and is evaluated over the contents of a single cache. Running a\n+query over multiple caches or creating queries that target several entity types (joins) is not supported.\n+====\n+\n+Executing the query and fetching the results is as simple as invoking the `run()` method of the _Query_ object. Once\n+executed, calling `run()` on the same instance will re-execute the query.\n+\n+=== Pagination\n+\n+You can limit the number of returned results by using  the `Query.maxResults(int maxResults)`. This can be used in\n+conjunction with `Query.startOffset(long startOffset)` to achieve pagination of the result set.\n+\n+[source,java]\n+----\n+// sorted by year and match all books that have \"clustering\" in their title\n+// and return the third page of 10 results\n+Query<Book> query = queryFactory.create(\"FROM com.acme.Book WHERE title like '%clustering%' ORDER BY year\").startOffset(20).maxResults(10)\n+----\n+\n+=== Number of Hits\n+\n+The `QueryResult` object has the `.hitCount()` method to return the total number of results of the query, regardless\n+of any pagination parameter. The hit count is only available for indexed queries for performance reasons.\n+\n+\n+=== Iteration\n+\n+The `Query` object has the `.iterator()` method to obtain the results lazily. It returns an instance of `CloseableIterator` that must be closed after usage.\n+\n+[NOTE]\n+====\n+The iteration support for Remote Queries is currently limited, as it will first fetch all entries to the client\n+before iterating.\n+====\n+\n+=== Using Named Query Parameters\n+\n+Instead of building a new Query object for every execution it is possible to include named parameters in the query which\n+can be substituted with actual values before execution. This allows a query to be defined once and be efficiently\n+executed many times. Parameters can only be used on the right-hand side of an operator and are defined when the query is\n+created by supplying an object produced by the _org.infinispan.query.dsl.Expression.param(String paramName)_ method to\n+the operator instead of the usual constant value. Once the parameters have been defined they can be set by invoking either\n+_Query.setParameter(parameterName, value)_ or _Query.setParameters(parameterMap)_ as shown in the examples below.\n+\u2060\n+[source,java,tile=\"Using Named Parameters\"]\n+----\n+QueryFactory queryFactory = Search.getQueryFactory(cache);\n+// Defining a query to search for various authors and publication years\n+Query<Book> query = queryFactory.create(\"SELECT title FROM com.acme.Book WHERE author = :authorName AND publicationYear = :publicationYear\").build();\n+\n+// Set actual parameter values\n+query.setParameter(\"authorName\", \"Doe\");\n+query.setParameter(\"publicationYear\", 2010);\n+\n+// Execute the query\n+List<Book> found = query.list();\n+----\n+\n+Alternatively, you can supply a map of actual parameter values to set multiple parameters at once:\n+\u2060\n+[source,java,title=\"Setting multiple named parameters at once\"]\n+----\n+Map<String, Object> parameterMap = new HashMap<>();\n+parameterMap.put(\"authorName\", \"Doe\");\n+parameterMap.put(\"publicationYear\", 2010);\n+\n+query.setParameters(parameterMap);\n+----\n+\n+NOTE: A significant portion of the query parsing, validation and execution planning effort is performed during the first\n+execution of a query with parameters. This effort is not repeated during subsequent executions leading to better\n+performance compared to a similar query using constant values instead of query parameters.\n+\n+[[query_ickle]]\n+=== Ickle Query Language Parser Syntax\n+\n+The Ickle query language is small subset of the link:https://en.wikipedia.org/wiki/Java_Persistence_Query_Language[JPQL]\n+query language, with some extensions for full-text.\n+\n+The parser syntax has some notable rules:\n+\n+* Whitespace is not significant.\n+* Wildcards are not supported in field names.\n+* A field name or path must always be specified, as there is no default field.\n+* `&&` and `||` are accepted instead of `AND` or `OR` in both full-text and JPA predicates.\n+* `!` may be used instead of `NOT`.\n+* A missing boolean operator is interpreted as `OR`.\n+* String terms must be enclosed with either single or double quotes.\n+* Fuzziness and boosting are not accepted in arbitrary order; fuzziness always comes first.\n+* `!=` is accepted instead of `<>`.\n+* Boosting cannot be applied to `>`,`>=`,`<`,`<=` operators. Ranges may be used to achieve the same result.\n+\n+==== Filtering operators\n+\n+Ickle support many filtering operators that can be used for both indexed and non-indexed fields.\n+\n+[options=\"header\"]\n+|==============================================================================\n+| Operator | Description | Example\n+| in | Checks that the left operand is equal to one of the elements from the Collection of values given as argument.\n+|FROM Book WHERE isbn IN ('ZZ', 'X1234')\n+| like | Checks that the left argument (which is expected to be a String) matches a wildcard pattern that follows the JPA rules.| FROM Book WHERE title LIKE '%Java%'\n+|=| Checks that the left argument is an exact match of the given value         | FROM Book WHERE name = 'Programming Java'\n+|!=| Checks that the left argument is different from the given value            | FROM Book WHERE language != 'English'\n+|>| Checks that the left argument is greater than the given value.             | FROM Book WHERE price > 20\n+|>=| Checks that the left argument is greater than or equal to the given value. | FROM Book WHERE price >= 20\n+|<| Checks that the left argument is less than the given value.                | FROM Book WHERE year < 2012\n+|<=| Checks that the left argument is less than or equal to the given value.   | FROM Book WHERE price  <= 50\n+|between| Checks that the left argument is between the given range limits.  | FROM Book WHERE price BETWEEN 50 AND 100\n+|==============================================================================\n+\n+==== Boolean conditions\n+\n+Combining multiple attribute conditions with logical conjunction (`and`) and disjunction (`or`) operators in order to\n+create more complex conditions is demonstrated in the following example. The well known operator precedence rule for\n+boolean operators applies here, so the order of the operators is irrelevant. Here `and`\n+operator still has higher priority than `or` even though `or` was invoked first.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title\n+# or have an author named \"Manik\" and their description contains \"clustering\"\n+\n+FROM com.acme.Book WHERE title LIKE '%Data Grid%' OR author.name = 'Manik' AND description like '%clustering%'\n+----\n+\n+Boolean negation has highest precedence among logical operators and applies only to the next simple attribute condition.\n+\n+[source,sql]\n+----\n+# match all books that do not have \"Data Grid\" in their title and are authored by \"Manik\"\n+FROM com.acme.Book WHERE title != 'Data Grid' AND author.name = 'Manik'\n+\n+----\n+\n+==== Nested conditions\n+Changing the precedence of logical operators is achieved with parenthesis:\n+\n+[source,sql]\n+----\n+# match all books that have an author named \"Manik\" and their title contains\n+# \"Data Grid\" or their description contains \"clustering\"\n+FROM com.acme.Book WHERE author.name = 'Manik' AND ( title like '%Data Grid%' OR description like '% clustering%')\n+----\n+\n+==== Selecting attributes\n+In some use cases returning the whole domain object is overkill if only a small subset of the attributes are actually\n+used by the application, especially if the domain entity has embedded entities. The query language allows you to specify\n+a subset of attributes (or attribute paths) to return - the projection. If projections are used then the `QueryResult.list()`\n+will not return the whole domain entity but will return a _List_ of _Object[]_, each slot in the array corresponding to\n+a projected attribute.\n+\n+//TODO document what needs to be configured for an attribute to be available for projection.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return only their title and publication year\n+SELECT title, publicationYear FROM com.acme.Book WHERE title like '%Data Grid%' OR description like '%Data Grid%'\n+----\n+\n+==== Sorting\n+Ordering the results based on one or more attributes or attribute paths is done with the `ORDER BY` clause. If multiple sorting criteria\n+are specified, then the order will dictate their precedence.\n+\n+\n+//TODO document what needs to be configured for an attribute to be available for sorting.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return them sorted by the publication year and title\n+FROM com.acme.Book WHERE title like '%Data Grid%' ORDER BY publicationYear DESC, title ASC\n+----\n+\n+==== Grouping and Aggregation\n+\n+{brandname} has the ability to group query results according to a set of grouping fields and construct aggregations of\n+the results from each group by applying an aggregation function to the set of values that fall into each group.\n+Grouping and aggregation can only be applied to projection queries (queries with one or more field in the SELECT clause).\n+\n+The supported aggregations are: avg, sum, count, max, min.\n+\n+The set of grouping fields is specified with the `GROUP BY` clause and the order used for defining grouping fields is\n+not relevant. All fields selected in the projection must either be grouping fields\n+or else they must be aggregated using one of the grouping functions described below. A projection field can be\n+aggregated and used for grouping at the same time. A query that selects only grouping fields but no aggregation fields\n+is legal.\n+\u2060\n+Example: Grouping Books by author and counting them.\n+[source,sql]\n+----\n+SELECT author, COUNT(title) FROM com.acme.Book WHERE title LIKE '%engine%' GROUP BY author\n+----\n+\n+NOTE: A projection query in which all selected fields have an aggregation function applied and no fields are used for\n+grouping is allowed. In this case the aggregations will be computed globally as if there was a single global group.\n+\n+==== Aggregations\n+\n+The following aggregation functions may be applied to a field: avg, sum, count, max, min\n+\n+\n+* avg() - Computes the average of a set of numbers. Accepted values are primitive numbers and instances of _java.lang.Number_. The result is represented as _java.lang.Double_. If there are no non-null values the result is _null_ instead.\n+* count() - Counts the number of non-null rows and returns a _java.lang.Long_. If there are no non-null values the result is _0_ instead.\n+* max() - Returns the greatest value found. Accepted values must be instances of _java.lang.Comparable_. If there are no non-null values the result is _null_ instead.\n+* min() - Returns the smallest value found. Accepted values must be instances of _java.lang.Comparable_. If there are no non-null values the result is _null_ instead.\n+* sum() - Computes the sum of a set of Numbers. If there are no non-null values the result is _null_ instead. The following table indicates the return type based on the specified field.\n+\n+.Table sum return type\n+|===\n+|Field Type |Return Type\n+\n+|Integral (other than BigInteger)\n+|Long\n+\n+|Float or Double\n+|Double\n+\n+|BigInteger\n+|BigInteger\n+\n+|BigDecimal\n+|BigDecimal\n+|===\n+\n+==== Evaluation of queries with grouping and aggregation\n+\n+Aggregation queries can include filtering conditions, like usual queries. Filtering can be performed in two stages: before\n+and after the grouping operation. All filter conditions defined before invoking the _groupBy_ method will be applied", "originalCommit": "12fae93eb5e527da5781daf106152840b0e2ee51", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk4MDE4OQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437980189", "bodyText": "Ok, I will remove all italics", "author": "gustavonalle", "createdAt": "2020-06-10T09:14:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3NTc1MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3NzIyNQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437977225", "bodyText": "s/useD/used\nConsider changing from passive voice. \"To search for \"test\", \"tests\", or \"tester\", use the following multi-character wildcard search:\"", "author": "oraNod", "createdAt": "2020-06-10T09:09:49Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1087 @@\n+[id='search_api']\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} provides a search API that lets you index and search cache values stored as Java POJOs or as objects encoded as link:https://developers.google.com/protocol-buffers/[Protocol Buffers].\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+\n+In the programmatic config, `enabled()` must be used.\n+\n+=== Specifying Indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+[[searching_ickle]]\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+[NOTE]\n+====\n+A query will always target a single entity type and is evaluated over the contents of a single cache. Running a\n+query over multiple caches or creating queries that target several entity types (joins) is not supported.\n+====\n+\n+Executing the query and fetching the results is as simple as invoking the `run()` method of the _Query_ object. Once\n+executed, calling `run()` on the same instance will re-execute the query.\n+\n+=== Pagination\n+\n+You can limit the number of returned results by using  the `Query.maxResults(int maxResults)`. This can be used in\n+conjunction with `Query.startOffset(long startOffset)` to achieve pagination of the result set.\n+\n+[source,java]\n+----\n+// sorted by year and match all books that have \"clustering\" in their title\n+// and return the third page of 10 results\n+Query<Book> query = queryFactory.create(\"FROM com.acme.Book WHERE title like '%clustering%' ORDER BY year\").startOffset(20).maxResults(10)\n+----\n+\n+=== Number of Hits\n+\n+The `QueryResult` object has the `.hitCount()` method to return the total number of results of the query, regardless\n+of any pagination parameter. The hit count is only available for indexed queries for performance reasons.\n+\n+\n+=== Iteration\n+\n+The `Query` object has the `.iterator()` method to obtain the results lazily. It returns an instance of `CloseableIterator` that must be closed after usage.\n+\n+[NOTE]\n+====\n+The iteration support for Remote Queries is currently limited, as it will first fetch all entries to the client\n+before iterating.\n+====\n+\n+=== Using Named Query Parameters\n+\n+Instead of building a new Query object for every execution it is possible to include named parameters in the query which\n+can be substituted with actual values before execution. This allows a query to be defined once and be efficiently\n+executed many times. Parameters can only be used on the right-hand side of an operator and are defined when the query is\n+created by supplying an object produced by the _org.infinispan.query.dsl.Expression.param(String paramName)_ method to\n+the operator instead of the usual constant value. Once the parameters have been defined they can be set by invoking either\n+_Query.setParameter(parameterName, value)_ or _Query.setParameters(parameterMap)_ as shown in the examples below.\n+\u2060\n+[source,java,tile=\"Using Named Parameters\"]\n+----\n+QueryFactory queryFactory = Search.getQueryFactory(cache);\n+// Defining a query to search for various authors and publication years\n+Query<Book> query = queryFactory.create(\"SELECT title FROM com.acme.Book WHERE author = :authorName AND publicationYear = :publicationYear\").build();\n+\n+// Set actual parameter values\n+query.setParameter(\"authorName\", \"Doe\");\n+query.setParameter(\"publicationYear\", 2010);\n+\n+// Execute the query\n+List<Book> found = query.list();\n+----\n+\n+Alternatively, you can supply a map of actual parameter values to set multiple parameters at once:\n+\u2060\n+[source,java,title=\"Setting multiple named parameters at once\"]\n+----\n+Map<String, Object> parameterMap = new HashMap<>();\n+parameterMap.put(\"authorName\", \"Doe\");\n+parameterMap.put(\"publicationYear\", 2010);\n+\n+query.setParameters(parameterMap);\n+----\n+\n+NOTE: A significant portion of the query parsing, validation and execution planning effort is performed during the first\n+execution of a query with parameters. This effort is not repeated during subsequent executions leading to better\n+performance compared to a similar query using constant values instead of query parameters.\n+\n+[[query_ickle]]\n+=== Ickle Query Language Parser Syntax\n+\n+The Ickle query language is small subset of the link:https://en.wikipedia.org/wiki/Java_Persistence_Query_Language[JPQL]\n+query language, with some extensions for full-text.\n+\n+The parser syntax has some notable rules:\n+\n+* Whitespace is not significant.\n+* Wildcards are not supported in field names.\n+* A field name or path must always be specified, as there is no default field.\n+* `&&` and `||` are accepted instead of `AND` or `OR` in both full-text and JPA predicates.\n+* `!` may be used instead of `NOT`.\n+* A missing boolean operator is interpreted as `OR`.\n+* String terms must be enclosed with either single or double quotes.\n+* Fuzziness and boosting are not accepted in arbitrary order; fuzziness always comes first.\n+* `!=` is accepted instead of `<>`.\n+* Boosting cannot be applied to `>`,`>=`,`<`,`<=` operators. Ranges may be used to achieve the same result.\n+\n+==== Filtering operators\n+\n+Ickle support many filtering operators that can be used for both indexed and non-indexed fields.\n+\n+[options=\"header\"]\n+|==============================================================================\n+| Operator | Description | Example\n+| in | Checks that the left operand is equal to one of the elements from the Collection of values given as argument.\n+|FROM Book WHERE isbn IN ('ZZ', 'X1234')\n+| like | Checks that the left argument (which is expected to be a String) matches a wildcard pattern that follows the JPA rules.| FROM Book WHERE title LIKE '%Java%'\n+|=| Checks that the left argument is an exact match of the given value         | FROM Book WHERE name = 'Programming Java'\n+|!=| Checks that the left argument is different from the given value            | FROM Book WHERE language != 'English'\n+|>| Checks that the left argument is greater than the given value.             | FROM Book WHERE price > 20\n+|>=| Checks that the left argument is greater than or equal to the given value. | FROM Book WHERE price >= 20\n+|<| Checks that the left argument is less than the given value.                | FROM Book WHERE year < 2012\n+|<=| Checks that the left argument is less than or equal to the given value.   | FROM Book WHERE price  <= 50\n+|between| Checks that the left argument is between the given range limits.  | FROM Book WHERE price BETWEEN 50 AND 100\n+|==============================================================================\n+\n+==== Boolean conditions\n+\n+Combining multiple attribute conditions with logical conjunction (`and`) and disjunction (`or`) operators in order to\n+create more complex conditions is demonstrated in the following example. The well known operator precedence rule for\n+boolean operators applies here, so the order of the operators is irrelevant. Here `and`\n+operator still has higher priority than `or` even though `or` was invoked first.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title\n+# or have an author named \"Manik\" and their description contains \"clustering\"\n+\n+FROM com.acme.Book WHERE title LIKE '%Data Grid%' OR author.name = 'Manik' AND description like '%clustering%'\n+----\n+\n+Boolean negation has highest precedence among logical operators and applies only to the next simple attribute condition.\n+\n+[source,sql]\n+----\n+# match all books that do not have \"Data Grid\" in their title and are authored by \"Manik\"\n+FROM com.acme.Book WHERE title != 'Data Grid' AND author.name = 'Manik'\n+\n+----\n+\n+==== Nested conditions\n+Changing the precedence of logical operators is achieved with parenthesis:\n+\n+[source,sql]\n+----\n+# match all books that have an author named \"Manik\" and their title contains\n+# \"Data Grid\" or their description contains \"clustering\"\n+FROM com.acme.Book WHERE author.name = 'Manik' AND ( title like '%Data Grid%' OR description like '% clustering%')\n+----\n+\n+==== Selecting attributes\n+In some use cases returning the whole domain object is overkill if only a small subset of the attributes are actually\n+used by the application, especially if the domain entity has embedded entities. The query language allows you to specify\n+a subset of attributes (or attribute paths) to return - the projection. If projections are used then the `QueryResult.list()`\n+will not return the whole domain entity but will return a _List_ of _Object[]_, each slot in the array corresponding to\n+a projected attribute.\n+\n+//TODO document what needs to be configured for an attribute to be available for projection.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return only their title and publication year\n+SELECT title, publicationYear FROM com.acme.Book WHERE title like '%Data Grid%' OR description like '%Data Grid%'\n+----\n+\n+==== Sorting\n+Ordering the results based on one or more attributes or attribute paths is done with the `ORDER BY` clause. If multiple sorting criteria\n+are specified, then the order will dictate their precedence.\n+\n+\n+//TODO document what needs to be configured for an attribute to be available for sorting.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return them sorted by the publication year and title\n+FROM com.acme.Book WHERE title like '%Data Grid%' ORDER BY publicationYear DESC, title ASC\n+----\n+\n+==== Grouping and Aggregation\n+\n+{brandname} has the ability to group query results according to a set of grouping fields and construct aggregations of\n+the results from each group by applying an aggregation function to the set of values that fall into each group.\n+Grouping and aggregation can only be applied to projection queries (queries with one or more field in the SELECT clause).\n+\n+The supported aggregations are: avg, sum, count, max, min.\n+\n+The set of grouping fields is specified with the `GROUP BY` clause and the order used for defining grouping fields is\n+not relevant. All fields selected in the projection must either be grouping fields\n+or else they must be aggregated using one of the grouping functions described below. A projection field can be\n+aggregated and used for grouping at the same time. A query that selects only grouping fields but no aggregation fields\n+is legal.\n+\u2060\n+Example: Grouping Books by author and counting them.\n+[source,sql]\n+----\n+SELECT author, COUNT(title) FROM com.acme.Book WHERE title LIKE '%engine%' GROUP BY author\n+----\n+\n+NOTE: A projection query in which all selected fields have an aggregation function applied and no fields are used for\n+grouping is allowed. In this case the aggregations will be computed globally as if there was a single global group.\n+\n+==== Aggregations\n+\n+The following aggregation functions may be applied to a field: avg, sum, count, max, min\n+\n+\n+* avg() - Computes the average of a set of numbers. Accepted values are primitive numbers and instances of _java.lang.Number_. The result is represented as _java.lang.Double_. If there are no non-null values the result is _null_ instead.\n+* count() - Counts the number of non-null rows and returns a _java.lang.Long_. If there are no non-null values the result is _0_ instead.\n+* max() - Returns the greatest value found. Accepted values must be instances of _java.lang.Comparable_. If there are no non-null values the result is _null_ instead.\n+* min() - Returns the smallest value found. Accepted values must be instances of _java.lang.Comparable_. If there are no non-null values the result is _null_ instead.\n+* sum() - Computes the sum of a set of Numbers. If there are no non-null values the result is _null_ instead. The following table indicates the return type based on the specified field.\n+\n+.Table sum return type\n+|===\n+|Field Type |Return Type\n+\n+|Integral (other than BigInteger)\n+|Long\n+\n+|Float or Double\n+|Double\n+\n+|BigInteger\n+|BigInteger\n+\n+|BigDecimal\n+|BigDecimal\n+|===\n+\n+==== Evaluation of queries with grouping and aggregation\n+\n+Aggregation queries can include filtering conditions, like usual queries. Filtering can be performed in two stages: before\n+and after the grouping operation. All filter conditions defined before invoking the _groupBy_ method will be applied\n+before the grouping operation is performed, directly to the cache entries (not to the final projection). These filter\n+conditions may reference any fields of the queried entity type, and are meant to restrict the data set that is going to\n+be the input for the grouping stage. All filter conditions defined after invoking the _groupBy_ method will be applied to\n+the projection that results from the projection and grouping operation. These filter conditions can either reference any\n+of the _groupBy_ fields or aggregated fields. Referencing aggregated fields that are not specified in the select clause\n+is allowed; however, referencing non-aggregated and non-grouping fields is forbidden. Filtering in this phase will\n+reduce the amount of groups based on their properties. Sorting may also be specified similar to usual queries. The\n+ordering operation is performed after the grouping operation and can reference any of the _groupBy_ fields or aggregated\n+fields.\n+\n+==== Using Full-text search\n+\n+===== Fuzzy Queries\n+\n+To execute a fuzzy query add `~` along with an integer, representing the distance from the term used, after the term.\n+For instance\n+\n+[source,sql,tile=\"Fuzzy Queries in Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'cofee'~2\n+----\n+\n+===== Range Queries\n+\n+To execute a range query define the given boundaries within a pair of braces, as seen in the following example:\n+\n+[source,sql,tile=\"Range queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE amount : [20 to 50]\n+----\n+\n+===== Phrase Queries\n+\n+A group of words may be searched by surrounding them in quotation marks, as seen in the following example:\n+\n+[source,sql,tile=\"Phrase queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'bus fare'\n+----\n+\n+===== Proximity Queries\n+\n+To execute a proximity query, finding two terms within a specific distance, add a `~` along with the distance after the phrase.\n+For instance, the following example will find the words canceling and fee provided they are not more than 3 words apart:\n+\n+[source,sql,tile=\"Proximity queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'canceling fee'~3\n+----\n+\n+===== Wildcard Queries\n+\n+Both single-character and multi-character wildcard searches may be performed:\n+\n+* A single-character wildcard search may be used with the ? character.\n+* A multi-character wildcard search may be used with the * character.\n+\n+To search for text or test the following single-character wildcard search would be used:\n+\n+[source,sql,tile=\"Single-character wildcard queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction where description : 'te?t'\n+----\n+\n+To search for test, tests, or tester the following multi-character wildcard search would be useD:", "originalCommit": "12fae93eb5e527da5781daf106152840b0e2ee51", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3NzkxOQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437977919", "bodyText": "Use ? and * in the following sentence to highlight the character.", "author": "oraNod", "createdAt": "2020-06-10T09:11:03Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1087 @@\n+[id='search_api']\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} provides a search API that lets you index and search cache values stored as Java POJOs or as objects encoded as link:https://developers.google.com/protocol-buffers/[Protocol Buffers].\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+\n+In the programmatic config, `enabled()` must be used.\n+\n+=== Specifying Indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+[[searching_ickle]]\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+[NOTE]\n+====\n+A query will always target a single entity type and is evaluated over the contents of a single cache. Running a\n+query over multiple caches or creating queries that target several entity types (joins) is not supported.\n+====\n+\n+Executing the query and fetching the results is as simple as invoking the `run()` method of the _Query_ object. Once\n+executed, calling `run()` on the same instance will re-execute the query.\n+\n+=== Pagination\n+\n+You can limit the number of returned results by using  the `Query.maxResults(int maxResults)`. This can be used in\n+conjunction with `Query.startOffset(long startOffset)` to achieve pagination of the result set.\n+\n+[source,java]\n+----\n+// sorted by year and match all books that have \"clustering\" in their title\n+// and return the third page of 10 results\n+Query<Book> query = queryFactory.create(\"FROM com.acme.Book WHERE title like '%clustering%' ORDER BY year\").startOffset(20).maxResults(10)\n+----\n+\n+=== Number of Hits\n+\n+The `QueryResult` object has the `.hitCount()` method to return the total number of results of the query, regardless\n+of any pagination parameter. The hit count is only available for indexed queries for performance reasons.\n+\n+\n+=== Iteration\n+\n+The `Query` object has the `.iterator()` method to obtain the results lazily. It returns an instance of `CloseableIterator` that must be closed after usage.\n+\n+[NOTE]\n+====\n+The iteration support for Remote Queries is currently limited, as it will first fetch all entries to the client\n+before iterating.\n+====\n+\n+=== Using Named Query Parameters\n+\n+Instead of building a new Query object for every execution it is possible to include named parameters in the query which\n+can be substituted with actual values before execution. This allows a query to be defined once and be efficiently\n+executed many times. Parameters can only be used on the right-hand side of an operator and are defined when the query is\n+created by supplying an object produced by the _org.infinispan.query.dsl.Expression.param(String paramName)_ method to\n+the operator instead of the usual constant value. Once the parameters have been defined they can be set by invoking either\n+_Query.setParameter(parameterName, value)_ or _Query.setParameters(parameterMap)_ as shown in the examples below.\n+\u2060\n+[source,java,tile=\"Using Named Parameters\"]\n+----\n+QueryFactory queryFactory = Search.getQueryFactory(cache);\n+// Defining a query to search for various authors and publication years\n+Query<Book> query = queryFactory.create(\"SELECT title FROM com.acme.Book WHERE author = :authorName AND publicationYear = :publicationYear\").build();\n+\n+// Set actual parameter values\n+query.setParameter(\"authorName\", \"Doe\");\n+query.setParameter(\"publicationYear\", 2010);\n+\n+// Execute the query\n+List<Book> found = query.list();\n+----\n+\n+Alternatively, you can supply a map of actual parameter values to set multiple parameters at once:\n+\u2060\n+[source,java,title=\"Setting multiple named parameters at once\"]\n+----\n+Map<String, Object> parameterMap = new HashMap<>();\n+parameterMap.put(\"authorName\", \"Doe\");\n+parameterMap.put(\"publicationYear\", 2010);\n+\n+query.setParameters(parameterMap);\n+----\n+\n+NOTE: A significant portion of the query parsing, validation and execution planning effort is performed during the first\n+execution of a query with parameters. This effort is not repeated during subsequent executions leading to better\n+performance compared to a similar query using constant values instead of query parameters.\n+\n+[[query_ickle]]\n+=== Ickle Query Language Parser Syntax\n+\n+The Ickle query language is small subset of the link:https://en.wikipedia.org/wiki/Java_Persistence_Query_Language[JPQL]\n+query language, with some extensions for full-text.\n+\n+The parser syntax has some notable rules:\n+\n+* Whitespace is not significant.\n+* Wildcards are not supported in field names.\n+* A field name or path must always be specified, as there is no default field.\n+* `&&` and `||` are accepted instead of `AND` or `OR` in both full-text and JPA predicates.\n+* `!` may be used instead of `NOT`.\n+* A missing boolean operator is interpreted as `OR`.\n+* String terms must be enclosed with either single or double quotes.\n+* Fuzziness and boosting are not accepted in arbitrary order; fuzziness always comes first.\n+* `!=` is accepted instead of `<>`.\n+* Boosting cannot be applied to `>`,`>=`,`<`,`<=` operators. Ranges may be used to achieve the same result.\n+\n+==== Filtering operators\n+\n+Ickle support many filtering operators that can be used for both indexed and non-indexed fields.\n+\n+[options=\"header\"]\n+|==============================================================================\n+| Operator | Description | Example\n+| in | Checks that the left operand is equal to one of the elements from the Collection of values given as argument.\n+|FROM Book WHERE isbn IN ('ZZ', 'X1234')\n+| like | Checks that the left argument (which is expected to be a String) matches a wildcard pattern that follows the JPA rules.| FROM Book WHERE title LIKE '%Java%'\n+|=| Checks that the left argument is an exact match of the given value         | FROM Book WHERE name = 'Programming Java'\n+|!=| Checks that the left argument is different from the given value            | FROM Book WHERE language != 'English'\n+|>| Checks that the left argument is greater than the given value.             | FROM Book WHERE price > 20\n+|>=| Checks that the left argument is greater than or equal to the given value. | FROM Book WHERE price >= 20\n+|<| Checks that the left argument is less than the given value.                | FROM Book WHERE year < 2012\n+|<=| Checks that the left argument is less than or equal to the given value.   | FROM Book WHERE price  <= 50\n+|between| Checks that the left argument is between the given range limits.  | FROM Book WHERE price BETWEEN 50 AND 100\n+|==============================================================================\n+\n+==== Boolean conditions\n+\n+Combining multiple attribute conditions with logical conjunction (`and`) and disjunction (`or`) operators in order to\n+create more complex conditions is demonstrated in the following example. The well known operator precedence rule for\n+boolean operators applies here, so the order of the operators is irrelevant. Here `and`\n+operator still has higher priority than `or` even though `or` was invoked first.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title\n+# or have an author named \"Manik\" and their description contains \"clustering\"\n+\n+FROM com.acme.Book WHERE title LIKE '%Data Grid%' OR author.name = 'Manik' AND description like '%clustering%'\n+----\n+\n+Boolean negation has highest precedence among logical operators and applies only to the next simple attribute condition.\n+\n+[source,sql]\n+----\n+# match all books that do not have \"Data Grid\" in their title and are authored by \"Manik\"\n+FROM com.acme.Book WHERE title != 'Data Grid' AND author.name = 'Manik'\n+\n+----\n+\n+==== Nested conditions\n+Changing the precedence of logical operators is achieved with parenthesis:\n+\n+[source,sql]\n+----\n+# match all books that have an author named \"Manik\" and their title contains\n+# \"Data Grid\" or their description contains \"clustering\"\n+FROM com.acme.Book WHERE author.name = 'Manik' AND ( title like '%Data Grid%' OR description like '% clustering%')\n+----\n+\n+==== Selecting attributes\n+In some use cases returning the whole domain object is overkill if only a small subset of the attributes are actually\n+used by the application, especially if the domain entity has embedded entities. The query language allows you to specify\n+a subset of attributes (or attribute paths) to return - the projection. If projections are used then the `QueryResult.list()`\n+will not return the whole domain entity but will return a _List_ of _Object[]_, each slot in the array corresponding to\n+a projected attribute.\n+\n+//TODO document what needs to be configured for an attribute to be available for projection.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return only their title and publication year\n+SELECT title, publicationYear FROM com.acme.Book WHERE title like '%Data Grid%' OR description like '%Data Grid%'\n+----\n+\n+==== Sorting\n+Ordering the results based on one or more attributes or attribute paths is done with the `ORDER BY` clause. If multiple sorting criteria\n+are specified, then the order will dictate their precedence.\n+\n+\n+//TODO document what needs to be configured for an attribute to be available for sorting.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return them sorted by the publication year and title\n+FROM com.acme.Book WHERE title like '%Data Grid%' ORDER BY publicationYear DESC, title ASC\n+----\n+\n+==== Grouping and Aggregation\n+\n+{brandname} has the ability to group query results according to a set of grouping fields and construct aggregations of\n+the results from each group by applying an aggregation function to the set of values that fall into each group.\n+Grouping and aggregation can only be applied to projection queries (queries with one or more field in the SELECT clause).\n+\n+The supported aggregations are: avg, sum, count, max, min.\n+\n+The set of grouping fields is specified with the `GROUP BY` clause and the order used for defining grouping fields is\n+not relevant. All fields selected in the projection must either be grouping fields\n+or else they must be aggregated using one of the grouping functions described below. A projection field can be\n+aggregated and used for grouping at the same time. A query that selects only grouping fields but no aggregation fields\n+is legal.\n+\u2060\n+Example: Grouping Books by author and counting them.\n+[source,sql]\n+----\n+SELECT author, COUNT(title) FROM com.acme.Book WHERE title LIKE '%engine%' GROUP BY author\n+----\n+\n+NOTE: A projection query in which all selected fields have an aggregation function applied and no fields are used for\n+grouping is allowed. In this case the aggregations will be computed globally as if there was a single global group.\n+\n+==== Aggregations\n+\n+The following aggregation functions may be applied to a field: avg, sum, count, max, min\n+\n+\n+* avg() - Computes the average of a set of numbers. Accepted values are primitive numbers and instances of _java.lang.Number_. The result is represented as _java.lang.Double_. If there are no non-null values the result is _null_ instead.\n+* count() - Counts the number of non-null rows and returns a _java.lang.Long_. If there are no non-null values the result is _0_ instead.\n+* max() - Returns the greatest value found. Accepted values must be instances of _java.lang.Comparable_. If there are no non-null values the result is _null_ instead.\n+* min() - Returns the smallest value found. Accepted values must be instances of _java.lang.Comparable_. If there are no non-null values the result is _null_ instead.\n+* sum() - Computes the sum of a set of Numbers. If there are no non-null values the result is _null_ instead. The following table indicates the return type based on the specified field.\n+\n+.Table sum return type\n+|===\n+|Field Type |Return Type\n+\n+|Integral (other than BigInteger)\n+|Long\n+\n+|Float or Double\n+|Double\n+\n+|BigInteger\n+|BigInteger\n+\n+|BigDecimal\n+|BigDecimal\n+|===\n+\n+==== Evaluation of queries with grouping and aggregation\n+\n+Aggregation queries can include filtering conditions, like usual queries. Filtering can be performed in two stages: before\n+and after the grouping operation. All filter conditions defined before invoking the _groupBy_ method will be applied\n+before the grouping operation is performed, directly to the cache entries (not to the final projection). These filter\n+conditions may reference any fields of the queried entity type, and are meant to restrict the data set that is going to\n+be the input for the grouping stage. All filter conditions defined after invoking the _groupBy_ method will be applied to\n+the projection that results from the projection and grouping operation. These filter conditions can either reference any\n+of the _groupBy_ fields or aggregated fields. Referencing aggregated fields that are not specified in the select clause\n+is allowed; however, referencing non-aggregated and non-grouping fields is forbidden. Filtering in this phase will\n+reduce the amount of groups based on their properties. Sorting may also be specified similar to usual queries. The\n+ordering operation is performed after the grouping operation and can reference any of the _groupBy_ fields or aggregated\n+fields.\n+\n+==== Using Full-text search\n+\n+===== Fuzzy Queries\n+\n+To execute a fuzzy query add `~` along with an integer, representing the distance from the term used, after the term.\n+For instance\n+\n+[source,sql,tile=\"Fuzzy Queries in Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'cofee'~2\n+----\n+\n+===== Range Queries\n+\n+To execute a range query define the given boundaries within a pair of braces, as seen in the following example:\n+\n+[source,sql,tile=\"Range queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE amount : [20 to 50]\n+----\n+\n+===== Phrase Queries\n+\n+A group of words may be searched by surrounding them in quotation marks, as seen in the following example:\n+\n+[source,sql,tile=\"Phrase queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'bus fare'\n+----\n+\n+===== Proximity Queries\n+\n+To execute a proximity query, finding two terms within a specific distance, add a `~` along with the distance after the phrase.\n+For instance, the following example will find the words canceling and fee provided they are not more than 3 words apart:\n+\n+[source,sql,tile=\"Proximity queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'canceling fee'~3\n+----\n+\n+===== Wildcard Queries\n+\n+Both single-character and multi-character wildcard searches may be performed:\n+\n+* A single-character wildcard search may be used with the ? character.", "originalCommit": "12fae93eb5e527da5781daf106152840b0e2ee51", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk4OTEyMg==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437989122", "bodyText": "I'll simplify this whole wildcard snippet, too much repetition", "author": "gustavonalle", "createdAt": "2020-06-10T09:29:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3NzkxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzk3OTIxOA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r437979218", "bodyText": "Start a new sentence here. \"Alternatively, you ...\"", "author": "oraNod", "createdAt": "2020-06-10T09:13:22Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1087 @@\n+[id='search_api']\n+=  Indexing and Searching\n+\n+== Overview\n+\n+{brandname} provides a search API that lets you index and search cache values stored as Java POJOs or as objects encoded as link:https://developers.google.com/protocol-buffers/[Protocol Buffers].\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called _link:#query_ickle[Ickle]_, which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.\n+\n+In the programmatic config, `enabled()` must be used.\n+\n+=== Specifying Indexed Entities\n+\n+It is recommended to declare the indexed types, as they will be mandatory in the next {brandname} version.\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+ cacheCfg.indexing()\n+       .addIndexedEntity(Car.class)\n+       .addIndexedEntity(Truck.class)\n+\n+----\n+\n+When the cache is storing protobuf, the indexed types should be the _Message_ declared in the protobuf schema.\n+For example, for the schema below:\n+\n+[source,proto]\n+----\n+include::config_examples/library.proto[]\n+----\n+\n+The config should be:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexed_entities_proto.xml[]\n+----\n+\n+[[query_index_storage]]\n+=== Index Storage\n+\n+{brandname} can store indexes in the file system or in memory (_local-heap_). File system is the recommended and the default configuration, and memory indexes should only be used for small to medium indexes that don't need to survive restart.\n+\n+.Configuration for file system indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_filesystem.xml[]\n+----\n+\n+.Configuration for memory indexes:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_local_heap.xml[]\n+----\n+\n+[[query_index_manager]]\n+=== Index Manager\n+\n+{brandname} uses internally a component called \"Index Manager\" to control how new data is applied to the index and\n+when the data is visible to searches.\n+\n+The default Index Manager `directory-based` writes to the index as soon as the data is written to the cache. The downside is it can slow down considerably cache writes specially under heavy writing scenarios, since it needs to do constant costly operations called \"flushes\" on the index.\n+\n+The `near-real-time` index manager is similar to the default index manager but takes advantage of the Near-Real-Time features of Lucene. It has better write performance because it flushes the index to the underlying store less often.\n+The drawback is that unflushed index changes can be lost in case of a non-clean shutdown. Can be used in conjunction with `local-heap` or `filesystem`.\n+\n+Example with `local-heap`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time.xml[]\n+----\n+\n+Example with `filesystem`:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_near_real_time_fs.xml[]\n+----\n+\n+[[query_massindexer]]\n+=== Rebuilding Indexes\n+\n+Rebuilding an index reconstructs it from data stored in the cache. You need to rebuild indexes if you change things like\n+definitions of indexed types or Analyzers. Likewise you might need to rebuild indexes if they are deleted for some reason.\n+Beware it might take some time as it needs to reprocess all data in the grid!\n+\n+[source,java]\n+----\n+Indexer indexer = Search.getIndexer(cache);\n+CompletionStage<Void> future = index.run();\n+----\n+\n+//TODO\n+//[[query_indexless]]\n+//==== Indexless\n+\n+//TODO\n+//[[query_hybrid]]\n+//==== Hybrid\n+\n+[[searching_ickle]]\n+== Searching\n+\n+Create relational and full-text queries in both Library and Remote Client-Server mode with the Ickle query language.\n+\n+To use the API, first obtain a QueryFactory to the cache and then call the `.create()` method, passing in the string\n+to use in the query. Each _QueryFactory_ instance is bound to the same _Cache_ instance as the _Search_, but it is\n+otherwise a stateless and thread-safe object that can be used for creating multiple queries in parallel.\n+\n+For instance:\n+\n+[source,java,tile=\"Using Ickle\"]\n+----\n+// Remote Query, using protobuf\n+QueryFactory qf = org.infinispan.client.hotrod.Search.getQueryFactory(remoteCache);\n+Query q = qf.create(\"from sample_bank_account.Transaction where amount > 20\");\n+\n+// Embedded Query using Java Objects\n+QueryFactory qf = org.infinispan.query.Search.getQueryFactory(cache);\n+Query q = qf.create(\"from com.acme.Book where price > 20\");\n+\n+// Execute the query\n+QueryResult<Book> queryResult = q.execute();\n+----\n+\n+[NOTE]\n+====\n+A query will always target a single entity type and is evaluated over the contents of a single cache. Running a\n+query over multiple caches or creating queries that target several entity types (joins) is not supported.\n+====\n+\n+Executing the query and fetching the results is as simple as invoking the `run()` method of the _Query_ object. Once\n+executed, calling `run()` on the same instance will re-execute the query.\n+\n+=== Pagination\n+\n+You can limit the number of returned results by using  the `Query.maxResults(int maxResults)`. This can be used in\n+conjunction with `Query.startOffset(long startOffset)` to achieve pagination of the result set.\n+\n+[source,java]\n+----\n+// sorted by year and match all books that have \"clustering\" in their title\n+// and return the third page of 10 results\n+Query<Book> query = queryFactory.create(\"FROM com.acme.Book WHERE title like '%clustering%' ORDER BY year\").startOffset(20).maxResults(10)\n+----\n+\n+=== Number of Hits\n+\n+The `QueryResult` object has the `.hitCount()` method to return the total number of results of the query, regardless\n+of any pagination parameter. The hit count is only available for indexed queries for performance reasons.\n+\n+\n+=== Iteration\n+\n+The `Query` object has the `.iterator()` method to obtain the results lazily. It returns an instance of `CloseableIterator` that must be closed after usage.\n+\n+[NOTE]\n+====\n+The iteration support for Remote Queries is currently limited, as it will first fetch all entries to the client\n+before iterating.\n+====\n+\n+=== Using Named Query Parameters\n+\n+Instead of building a new Query object for every execution it is possible to include named parameters in the query which\n+can be substituted with actual values before execution. This allows a query to be defined once and be efficiently\n+executed many times. Parameters can only be used on the right-hand side of an operator and are defined when the query is\n+created by supplying an object produced by the _org.infinispan.query.dsl.Expression.param(String paramName)_ method to\n+the operator instead of the usual constant value. Once the parameters have been defined they can be set by invoking either\n+_Query.setParameter(parameterName, value)_ or _Query.setParameters(parameterMap)_ as shown in the examples below.\n+\u2060\n+[source,java,tile=\"Using Named Parameters\"]\n+----\n+QueryFactory queryFactory = Search.getQueryFactory(cache);\n+// Defining a query to search for various authors and publication years\n+Query<Book> query = queryFactory.create(\"SELECT title FROM com.acme.Book WHERE author = :authorName AND publicationYear = :publicationYear\").build();\n+\n+// Set actual parameter values\n+query.setParameter(\"authorName\", \"Doe\");\n+query.setParameter(\"publicationYear\", 2010);\n+\n+// Execute the query\n+List<Book> found = query.list();\n+----\n+\n+Alternatively, you can supply a map of actual parameter values to set multiple parameters at once:\n+\u2060\n+[source,java,title=\"Setting multiple named parameters at once\"]\n+----\n+Map<String, Object> parameterMap = new HashMap<>();\n+parameterMap.put(\"authorName\", \"Doe\");\n+parameterMap.put(\"publicationYear\", 2010);\n+\n+query.setParameters(parameterMap);\n+----\n+\n+NOTE: A significant portion of the query parsing, validation and execution planning effort is performed during the first\n+execution of a query with parameters. This effort is not repeated during subsequent executions leading to better\n+performance compared to a similar query using constant values instead of query parameters.\n+\n+[[query_ickle]]\n+=== Ickle Query Language Parser Syntax\n+\n+The Ickle query language is small subset of the link:https://en.wikipedia.org/wiki/Java_Persistence_Query_Language[JPQL]\n+query language, with some extensions for full-text.\n+\n+The parser syntax has some notable rules:\n+\n+* Whitespace is not significant.\n+* Wildcards are not supported in field names.\n+* A field name or path must always be specified, as there is no default field.\n+* `&&` and `||` are accepted instead of `AND` or `OR` in both full-text and JPA predicates.\n+* `!` may be used instead of `NOT`.\n+* A missing boolean operator is interpreted as `OR`.\n+* String terms must be enclosed with either single or double quotes.\n+* Fuzziness and boosting are not accepted in arbitrary order; fuzziness always comes first.\n+* `!=` is accepted instead of `<>`.\n+* Boosting cannot be applied to `>`,`>=`,`<`,`<=` operators. Ranges may be used to achieve the same result.\n+\n+==== Filtering operators\n+\n+Ickle support many filtering operators that can be used for both indexed and non-indexed fields.\n+\n+[options=\"header\"]\n+|==============================================================================\n+| Operator | Description | Example\n+| in | Checks that the left operand is equal to one of the elements from the Collection of values given as argument.\n+|FROM Book WHERE isbn IN ('ZZ', 'X1234')\n+| like | Checks that the left argument (which is expected to be a String) matches a wildcard pattern that follows the JPA rules.| FROM Book WHERE title LIKE '%Java%'\n+|=| Checks that the left argument is an exact match of the given value         | FROM Book WHERE name = 'Programming Java'\n+|!=| Checks that the left argument is different from the given value            | FROM Book WHERE language != 'English'\n+|>| Checks that the left argument is greater than the given value.             | FROM Book WHERE price > 20\n+|>=| Checks that the left argument is greater than or equal to the given value. | FROM Book WHERE price >= 20\n+|<| Checks that the left argument is less than the given value.                | FROM Book WHERE year < 2012\n+|<=| Checks that the left argument is less than or equal to the given value.   | FROM Book WHERE price  <= 50\n+|between| Checks that the left argument is between the given range limits.  | FROM Book WHERE price BETWEEN 50 AND 100\n+|==============================================================================\n+\n+==== Boolean conditions\n+\n+Combining multiple attribute conditions with logical conjunction (`and`) and disjunction (`or`) operators in order to\n+create more complex conditions is demonstrated in the following example. The well known operator precedence rule for\n+boolean operators applies here, so the order of the operators is irrelevant. Here `and`\n+operator still has higher priority than `or` even though `or` was invoked first.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title\n+# or have an author named \"Manik\" and their description contains \"clustering\"\n+\n+FROM com.acme.Book WHERE title LIKE '%Data Grid%' OR author.name = 'Manik' AND description like '%clustering%'\n+----\n+\n+Boolean negation has highest precedence among logical operators and applies only to the next simple attribute condition.\n+\n+[source,sql]\n+----\n+# match all books that do not have \"Data Grid\" in their title and are authored by \"Manik\"\n+FROM com.acme.Book WHERE title != 'Data Grid' AND author.name = 'Manik'\n+\n+----\n+\n+==== Nested conditions\n+Changing the precedence of logical operators is achieved with parenthesis:\n+\n+[source,sql]\n+----\n+# match all books that have an author named \"Manik\" and their title contains\n+# \"Data Grid\" or their description contains \"clustering\"\n+FROM com.acme.Book WHERE author.name = 'Manik' AND ( title like '%Data Grid%' OR description like '% clustering%')\n+----\n+\n+==== Selecting attributes\n+In some use cases returning the whole domain object is overkill if only a small subset of the attributes are actually\n+used by the application, especially if the domain entity has embedded entities. The query language allows you to specify\n+a subset of attributes (or attribute paths) to return - the projection. If projections are used then the `QueryResult.list()`\n+will not return the whole domain entity but will return a _List_ of _Object[]_, each slot in the array corresponding to\n+a projected attribute.\n+\n+//TODO document what needs to be configured for an attribute to be available for projection.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return only their title and publication year\n+SELECT title, publicationYear FROM com.acme.Book WHERE title like '%Data Grid%' OR description like '%Data Grid%'\n+----\n+\n+==== Sorting\n+Ordering the results based on one or more attributes or attribute paths is done with the `ORDER BY` clause. If multiple sorting criteria\n+are specified, then the order will dictate their precedence.\n+\n+\n+//TODO document what needs to be configured for an attribute to be available for sorting.\n+\n+[source,sql]\n+----\n+# match all books that have \"Data Grid\" in their title or description\n+# and return them sorted by the publication year and title\n+FROM com.acme.Book WHERE title like '%Data Grid%' ORDER BY publicationYear DESC, title ASC\n+----\n+\n+==== Grouping and Aggregation\n+\n+{brandname} has the ability to group query results according to a set of grouping fields and construct aggregations of\n+the results from each group by applying an aggregation function to the set of values that fall into each group.\n+Grouping and aggregation can only be applied to projection queries (queries with one or more field in the SELECT clause).\n+\n+The supported aggregations are: avg, sum, count, max, min.\n+\n+The set of grouping fields is specified with the `GROUP BY` clause and the order used for defining grouping fields is\n+not relevant. All fields selected in the projection must either be grouping fields\n+or else they must be aggregated using one of the grouping functions described below. A projection field can be\n+aggregated and used for grouping at the same time. A query that selects only grouping fields but no aggregation fields\n+is legal.\n+\u2060\n+Example: Grouping Books by author and counting them.\n+[source,sql]\n+----\n+SELECT author, COUNT(title) FROM com.acme.Book WHERE title LIKE '%engine%' GROUP BY author\n+----\n+\n+NOTE: A projection query in which all selected fields have an aggregation function applied and no fields are used for\n+grouping is allowed. In this case the aggregations will be computed globally as if there was a single global group.\n+\n+==== Aggregations\n+\n+The following aggregation functions may be applied to a field: avg, sum, count, max, min\n+\n+\n+* avg() - Computes the average of a set of numbers. Accepted values are primitive numbers and instances of _java.lang.Number_. The result is represented as _java.lang.Double_. If there are no non-null values the result is _null_ instead.\n+* count() - Counts the number of non-null rows and returns a _java.lang.Long_. If there are no non-null values the result is _0_ instead.\n+* max() - Returns the greatest value found. Accepted values must be instances of _java.lang.Comparable_. If there are no non-null values the result is _null_ instead.\n+* min() - Returns the smallest value found. Accepted values must be instances of _java.lang.Comparable_. If there are no non-null values the result is _null_ instead.\n+* sum() - Computes the sum of a set of Numbers. If there are no non-null values the result is _null_ instead. The following table indicates the return type based on the specified field.\n+\n+.Table sum return type\n+|===\n+|Field Type |Return Type\n+\n+|Integral (other than BigInteger)\n+|Long\n+\n+|Float or Double\n+|Double\n+\n+|BigInteger\n+|BigInteger\n+\n+|BigDecimal\n+|BigDecimal\n+|===\n+\n+==== Evaluation of queries with grouping and aggregation\n+\n+Aggregation queries can include filtering conditions, like usual queries. Filtering can be performed in two stages: before\n+and after the grouping operation. All filter conditions defined before invoking the _groupBy_ method will be applied\n+before the grouping operation is performed, directly to the cache entries (not to the final projection). These filter\n+conditions may reference any fields of the queried entity type, and are meant to restrict the data set that is going to\n+be the input for the grouping stage. All filter conditions defined after invoking the _groupBy_ method will be applied to\n+the projection that results from the projection and grouping operation. These filter conditions can either reference any\n+of the _groupBy_ fields or aggregated fields. Referencing aggregated fields that are not specified in the select clause\n+is allowed; however, referencing non-aggregated and non-grouping fields is forbidden. Filtering in this phase will\n+reduce the amount of groups based on their properties. Sorting may also be specified similar to usual queries. The\n+ordering operation is performed after the grouping operation and can reference any of the _groupBy_ fields or aggregated\n+fields.\n+\n+==== Using Full-text search\n+\n+===== Fuzzy Queries\n+\n+To execute a fuzzy query add `~` along with an integer, representing the distance from the term used, after the term.\n+For instance\n+\n+[source,sql,tile=\"Fuzzy Queries in Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'cofee'~2\n+----\n+\n+===== Range Queries\n+\n+To execute a range query define the given boundaries within a pair of braces, as seen in the following example:\n+\n+[source,sql,tile=\"Range queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE amount : [20 to 50]\n+----\n+\n+===== Phrase Queries\n+\n+A group of words may be searched by surrounding them in quotation marks, as seen in the following example:\n+\n+[source,sql,tile=\"Phrase queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'bus fare'\n+----\n+\n+===== Proximity Queries\n+\n+To execute a proximity query, finding two terms within a specific distance, add a `~` along with the distance after the phrase.\n+For instance, the following example will find the words canceling and fee provided they are not more than 3 words apart:\n+\n+[source,sql,tile=\"Proximity queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction WHERE description : 'canceling fee'~3\n+----\n+\n+===== Wildcard Queries\n+\n+Both single-character and multi-character wildcard searches may be performed:\n+\n+* A single-character wildcard search may be used with the ? character.\n+* A multi-character wildcard search may be used with the * character.\n+\n+To search for text or test the following single-character wildcard search would be used:\n+\n+[source,sql,tile=\"Single-character wildcard queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction where description : 'te?t'\n+----\n+\n+To search for test, tests, or tester the following multi-character wildcard search would be useD:\n+\n+[source,sql,tile=\"Multi-character wildcard queries with Ickle\"]\n+----\n+FROM sample_bank_account.Transaction where description : 'test*'\n+----\n+\n+===== Regular Expression Queries\n+\n+Regular expression queries may be performed by specifying a pattern between /. Ickle uses Lucene\u2019s regular expression syntax, so to search for the words `moat` or `boat` the following could be used:\n+\n+[source,sql,tile=\"Regular Expression queries with Ickle\"]\n+----\n+FROM sample_library.Book  where title : /[mb]oat/\n+----\n+\n+===== Boosting Queries\n+\n+Terms may be boosted by adding a `^` after the term to increase their relevance in a given query, the higher the boost factor the more relevant the term will be. For instance to search for titles containing beer and wine with a higher relevance on beer, by a factor of 3, the following could be used:\n+\n+[source,sql,tile=\"Boosting queries with Ickle\"]\n+----\n+FROM sample_library.Book WHERE title : beer^3 OR wine\n+----\n+\n+[[query_library]]\n+== Embedded Search\n+\n+Embedded searching is available when {brandname} is used as a library. No protobuf mapping is required, and both indexing and searching are done on top of Java objects.\n+\n+=== Quick example\n+\n+We're going to store _Book_ instances in an {brandname} cache called \"books\". _Book_ instances will be indexed, so we enable indexing for the cache:\n+\n+{brandname} configuration:\n+\n+.infinispan.xml\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/infinispan_distributed_cache_books.xml[]\n+----\n+\n+Obtaining the cache:\n+\n+[source,java]\n+----\n+import org.infinispan.Cache;\n+import org.infinispan.manager.DefaultCacheManager;\n+import org.infinispan.manager.EmbeddedCacheManager;\n+\n+EmbeddedCacheManager manager = new DefaultCacheManager(\"infinispan.xml\");\n+Cache<String, Book> cache = manager.getCache(\"books\");\n+\n+----\n+\n+Each _Book_ will be defined as in the following example; we have to choose which properties are indexed, and for each property we can optionally choose advanced indexing options using the annotations defined in the Hibernate Search project.\n+\n+[source,java]\n+.Book.java\n+----\n+import org.hibernate.search.annotations.*;\n+import java.util.Date;\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+//Values you want to index need to be annotated with @Indexed, then you pick which fields and how they are to be indexed:\n+@Indexed\n+public class Book {\n+   @Field String title;\n+   @Field String description;\n+   @Field @DateBridge(resolution=Resolution.YEAR) Date publicationYear;\n+   @IndexedEmbedded Set<Author> authors = new HashSet<Author>();\n+}\n+\n+----\n+\n+[source,java]\n+.Author.java\n+----\n+\n+public class Author {\n+   @Field String name;\n+   @Field String surname;\n+   // hashCode() and equals() omitted\n+}\n+\n+----\n+\n+Now assuming we stored several _Book_ instances in our {brandname} _Cache_ , we can search them for any matching field as in the following example.\n+\n+[source,java]\n+.QueryExample.java\n+----\n+include::code_examples/QueryExample.java[]\n+----\n+\n+Apart from _list()_ you have the option for obtaining on _iterator()_, or use pagination.\n+\n+[[mapping_embedded]]\n+=== Mapping Entities\n+\n+{brandname} relies on the rich API of link:http://hibernate.org/search/[Hibernate Search] in order to define fine grained configuration for indexing at entity level.\n+This configuration includes which fields are annotated, which analyzers should be used, how to map nested objects and so on.\n+Detailed documentation is available at link:https://docs.jboss.org/hibernate/stable/search/reference/en-US/html_single/#search-mapping[the Hibernate Search manual].\n+\n+==== @DocumentId\n+Unlike Hibernate Search, using _@DocumentId_ to mark a field as identifier does not apply to {brandname} values; in {brandname} the identifier for all _@Indexed_ objects is the key used to store the value. You can still customize how the key is indexed using a combination of _@Transformable_ , custom types and custom _FieldBridge_ implementations.\n+\n+==== @Transformable keys\n+The key for each value needs to be indexed as well, and the key instance must be transformed in a _String_. {brandname} includes some default transformation routines to encode common primitives, but to use a custom key you must provide an implementation of _org.infinispan.query.Transformer_ .\n+\n+[small]*Registering a key Transformer via annotations*\n+\n+You can annotate your key class with _org.infinispan.query.Transformable_ and your custom transformer implementation\n+will be picked up automatically:\n+\n+[source,java]\n+----\n+\n+@Transformable(transformer = CustomTransformer.class)\n+public class CustomKey {\n+   ...\n+}\n+\n+public class CustomTransformer implements Transformer {\n+   @Override\n+   public Object fromString(String s) {\n+      ...\n+      return new CustomKey(...);\n+   }\n+\n+   @Override\n+   public String toString(Object customType) {\n+      CustomKey ck = (CustomKey) customType;\n+      return ...\n+   }\n+}\n+\n+----\n+\n+[small]*Registering a key Transformer via the cache indexing configuration*\n+\n+You can use the _key-transformers_ xml element in both embedded and server config:\n+\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing_key_transformer.xml[]\n+----\n+\n+or alternatively, you can achieve the same effect by using the Java configuration API (embedded mode):", "originalCommit": "12fae93eb5e527da5781daf106152840b0e2ee51", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODAwNDIyNg==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r438004226", "bodyText": "asciidoctor: ERROR: stories/assembly_cli_command_reference.adoc: line 35: include file not found: /home/dnaro/git/dnaro-query-review/cli/cli-client/src/main/resources/help//search.adoc\nThis should change back to query.adoc because references this file: https://github.com/infinispan/infinispan/blob/master/cli/cli-client/src/main/resources/help/query.adoc\nThat's the manpage for the query command. We include it in the CLI guide with the command reference section.\nI would agree that we should probably change \"query\" to \"search\" but that's probably out of scope at this point.", "author": "oraNod", "createdAt": "2020-06-10T09:54:28Z", "path": "documentation/src/main/asciidoc/stories/assembly_cli_command_reference.adoc", "diffHunk": "@@ -32,7 +32,7 @@ include::{cli_help}/help.adoc[leveloffset=+1]\n include::{cli_help}/ls.adoc[leveloffset=+1]\n include::{cli_help}/patch.adoc[leveloffset=+1]\n include::{cli_help}/put.adoc[leveloffset=+1]\n-include::{cli_help}/query.adoc[leveloffset=+1]\n+include::{cli_help}/search.adoc[leveloffset=+1]", "originalCommit": "fe6505ba3051a12742116780e4afb3294f36150e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODcwMzg3MQ==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r438703871", "bodyText": "ops", "author": "gustavonalle", "createdAt": "2020-06-11T10:57:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODAwNDIyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODAwODg3Nw==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r438008877", "bodyText": "Duplicate with the note above. I'd also move \"In the programmatic config, enabled() must be used.\" into the note.", "author": "oraNod", "createdAt": "2020-06-10T10:02:29Z", "path": "documentation/src/main/asciidoc/topics/search.adoc", "diffHunk": "@@ -0,0 +1,1093 @@\n+[id='search_api']\n+=  Indexing and Searching\n+\n+{brandname} provides a search API that lets you index and search cache values stored as Java POJOs or as objects encoded as link:https://developers.google.com/protocol-buffers/[Protocol Buffers].\n+\n+== Overview\n+\n+Searching is possible both in link:#query_library[library] and link:#query_remote[client/server mode] (for Java, C#, Node.js and other clients), and {brandname} can index data using link:http://lucene.apache.org/[Apache Lucene], offering an efficient link:https://en.wikipedia.org/wiki/Full-text_search[full-text] capable search engine in order to cover a wide range of data retrieval use cases.\n+\n+Indexing configuration relies on a schema definition, and for that {brandname} can use annotated Java classes when in library mode, and protobuf schemas for remote clients. By standardizing on protobuf, {brandname} allows full interoperability between Java and non-Java clients.\n+\n+{brandname} has its own query language called link:#query_ickle[Ickle], which is string-based and adds support for full-text searching. Ickle support searches over indexed data, partially indexed\n+data or non-indexed data.\n+\n+Finally, {brandname} has support for link:#query_continuous[Continuous Queries], which works in a reverse manner to the other APIs: instead of creating, executing a query\n+and obtain results, it allows a client to register queries that will be evaluated continuously as data in the cluster changes, generating notifications\n+whenever the changed data matches the queries.\n+\n+== Indexing Entry Values\n+\n+Indexing entry values in {brandname} caches dramatically improves search performance and allows you to perform full-text queries. However, indexing can degrade write throughput for {brandname} clusters. For this reason you should plan to use strategies to optimise query performance, depending on the cache mode and your use case. More information on link:#query_performance[query performance guide].\n+\n+=== Configuration\n+\n+To enable indexing via XML, you need to add the `<indexing>` element to your cache configuration, specify the entities that are indexed and optionally pass additional properties.\n+\n+[NOTE]\n+====\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+====\n+\n+.Declaratively\n+[source,xml,options=\"nowrap\",subs=attributes+]\n+----\n+include::config_examples/indexing.xml[]\n+----\n+\n+.Programmatically\n+[source,java]\n+----\n+import org.infinispan.configuration.cache.*;\n+\n+ConfigurationBuilder cacheCfg = ...\n+cacheCfg.indexing().enable()\n+            .addIndexedEntity(Book.class)\n+      .addProperty(\"property name\", \"propery value\")\n+----\n+\n+The presence of an `<indexing>` element which omits the `enabled` attribute will auto-enable indexing for your\n+convenience, even though the default value of the `enabled` attribute is defined as `\"false\"` in the XSD schema.\n+This behaviour exists only on schemas starting with version 11.", "originalCommit": "fe6505ba3051a12742116780e4afb3294f36150e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b4492c4f761d3e9bfd7f4f027916de99b33c6d7f", "url": "https://github.com/infinispan/infinispan/commit/b4492c4f761d3e9bfd7f4f027916de99b33c6d7f", "message": "ISPN-11789 Update Query Guide", "committedDate": "2020-06-11T13:42:37Z", "type": "commit"}, {"oid": "b4492c4f761d3e9bfd7f4f027916de99b33c6d7f", "url": "https://github.com/infinispan/infinispan/commit/b4492c4f761d3e9bfd7f4f027916de99b33c6d7f", "message": "ISPN-11789 Update Query Guide", "committedDate": "2020-06-11T13:42:37Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQyNjU5MA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r439426590", "bodyText": "@gustavonalle should be query.list(); ?", "author": "diegolovison", "createdAt": "2020-06-12T13:44:17Z", "path": "documentation/src/main/asciidoc/topics/code_examples/QueryExample.java", "diffHunk": "@@ -0,0 +1,14 @@\n+// get the query factory from the cache:\n+QueryFactory queryFactory = org.infinispan.query.Search.getQueryFactory(cache);\n+\n+// create an Ickle query that will do a full-text search (operator ':') on fields 'title' and 'authors.name'\n+Query<Book> fullTextQuery = queryFactory.create(\"FROM com.acme.Book WHERE title:'infinispan' AND authors.name:'sanne'\")\n+\n+// The ('=') operator is not a full-text operator, thus can be used in both indexed and non-indexed caches\n+Query<Book> exactMatchQuery = queryFactory.create(\"FROM com.acme.Book WHERE title = 'Programming Infinispan' AND authors.name = 'Sanne Grinnovero'\")\n+\n+// Full-text and non-full text operators can be part of the same query\n+Query q = queryFactory.create(\"FROM com.query.Book b where b.author.name = 'Stephen' and b.description : (+'dark' -'tower')\");\n+\n+// get the results\n+List<Book> found=query.execute().list();", "originalCommit": "b4492c4f761d3e9bfd7f4f027916de99b33c6d7f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQ4NDIyNA==", "url": "https://github.com/infinispan/infinispan/pull/8409#discussion_r439484224", "bodyText": "query.list() should also work, but it is deprecated in 11.0", "author": "gustavonalle", "createdAt": "2020-06-12T15:20:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTQyNjU5MA=="}], "type": "inlineReview"}]}