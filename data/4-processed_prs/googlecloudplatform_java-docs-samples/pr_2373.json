{"pr_number": 2373, "pr_title": "dataflow/flex-templates: Add Streaming BeamSQL and Kafka-to-BigQuery samples", "pr_createdAt": "2020-03-11T00:36:59Z", "pr_url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373", "timeline": [{"oid": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "message": "Added newline at EOF", "committedDate": "2020-03-11T00:37:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwNzE2Nw==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391307167", "bodyText": "A bit unexpected and incompatible with CloudBuild - you might wish to mention that in the README, but otherwise OK.", "author": "lesv", "createdAt": "2020-03-11T22:30:17Z", "path": "dataflow/flex-templates/kafka_to_bigquery/.gcloudignore", "diffHunk": "@@ -0,0 +1,7 @@\n+# Ignore everything from the Cloud Build command.", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMxNzU5Mw==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393317593", "bodyText": "That's a good point, I've added a note.", "author": "davidcavazos", "createdAt": "2020-03-16T21:22:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwNzE2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODExMg==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391308112", "bodyText": "Wow that's a lot of steps, I wonder if it wouldn't be easier on users to just use a script that asks them what it needs to know?", "author": "lesv", "createdAt": "2020-03-11T22:33:07Z", "path": "dataflow/flex-templates/kafka_to_bigquery/README.md", "diffHunk": "@@ -0,0 +1,337 @@\n+# Dataflow Flex templates - Kafka to BigQuery\n+\n+[![Open in Cloud Shell](http://gstatic.com/cloudssh/images/open-btn.svg)](https://console.cloud.google.com/cloudshell/editor)\n+\n+Samples showing how to create and run an\n+[Apache Beam](https://beam.apache.org/) template with a custom Docker image on\n+[Google Cloud Dataflow](https://cloud.google.com/dataflow/docs/).\n+\n+## Before you begin\n+\n+If you are not familiar with Dataflow Flex templates, please see the\n+[Streaming Beam SQL](../streaming-beam-sql/) sample first.\n+\n+Follow the\n+[Getting started with Google Cloud Dataflow](../README.md)\n+page, and make sure you have a Google Cloud project with billing enabled\n+and a *service account JSON key* set up in your `GOOGLE_APPLICATION_CREDENTIALS`\n+environment variable.\n+Additionally, for this sample you need the following:\n+\n+1. Create a [Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets).\n+\n+    ```sh\n+    export BUCKET=\"your-gcs-bucket\"\n+    gsutil mb gs://$BUCKET\n+    ```\n+\n+1. Create a [BigQuery dataset](https://cloud.google.com/bigquery/docs/datasets).\n+\n+    ```sh\n+    export PROJECT=\"$(gcloud config get-value project)\"\n+    export DATASET=\"beam_samples\"\n+    export TABLE=\"kafka_to_bigquery\"\n+\n+    bq mk --dataset \"$PROJECT:$DATASET\"\n+    ```\n+\n+1. Select the compute region and zone to use.\n+\n+    ```sh\n+    # Select your default compute/region, or default to \"us-central1\".\n+    export REGION=${\"$(gcloud config get-value compute/region)\":-\"us-central1\"}\n+\n+    # Select your default compute/zone, or default to \"$REGION-a\".\n+    # Note that the zone *must* be in $REGION.\n+    export ZONE=${\"$(gcloud config get-value compute/zone)\":-\"$REGION-a\"}\n+    ```\n+\n+1. Clone the `java-docs-samples` repository.\n+\n+    ```sh\n+    git clone https://github.com/GoogleCloudPlatform/java-docs-samples.git\n+    ```\n+\n+1. Navigate to the sample code directory.\n+\n+    ```sh\n+    cd java-docs-samples/dataflow/flex-templates/kafka_to_bigquery\n+    ```\n+\n+## Kafka to BigQuery sample\n+\n+This sample shows how to deploy an Apache Beam streaming pipeline that reads\n+[JSON encoded](https://www.w3schools.com/whatis/whatis_json.asp) messages from\n+[Apache Kafka](https://kafka.apache.org/), decodes them, and writes them into a\n+[BigQuery](https://cloud.google.com/bigquery) table.\n+\n+For this, we need two parts running:\n+\n+1. A Kafka server container accessible through an external IP address.\n+   This services publishes messages to a topic.\n+\n+    * [kafka/Dockerfile](kafka/Dockerfile)\n+    * [kafka/start-kafka.sh](kafka/start-kafka.sh)\n+    * [kafka/create-topic.sh](kafka/create-topic.sh)\n+\n+2. An Apache Beam streaming pipeline running in Dataflow Flex Templates.\n+   This subscribes to a Kafka topic, consumes the messages that are published\n+   to that topic, processes them, and writes them into a BigQuery table.\n+\n+    * [Dockerfile](Dockerfile)\n+    * [KafkaToBigQuery.java](src/main/java/org/apache/beam/samples/KafkaToBigQuery.java)\n+    * [pom.xml](pom.xml)\n+    * [metadata.json](metadata.json)\n+\n+### Starting the Kafka server", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMxOTQyMA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393319420", "bodyText": "That's a good idea. I'll go ahead and do that in a moment", "author": "davidcavazos", "createdAt": "2020-03-16T21:26:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODExMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM0NDQ4NA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393344484", "bodyText": "Decided not to script this in the end. Find explanation below.", "author": "davidcavazos", "createdAt": "2020-03-16T22:28:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODExMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODQ2MQ==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391308461", "bodyText": "Copyright & License?", "author": "lesv", "createdAt": "2020-03-11T22:33:49Z", "path": "dataflow/flex-templates/kafka_to_bigquery/Dockerfile", "diffHunk": "@@ -0,0 +1,8 @@\n+FROM gcr.io/dataflow-templates-base/java11-template-launcher-base:latest", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMxODMzMA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393318330", "bodyText": "Adding", "author": "davidcavazos", "createdAt": "2020-03-16T21:23:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODQ2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODY1Nw==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391308657", "bodyText": "Copyright & Licenses - general rule - if a human creates it, then it needs a copyright & license.", "author": "lesv", "createdAt": "2020-03-11T22:34:25Z", "path": "dataflow/flex-templates/kafka_to_bigquery/.gcloudignore", "diffHunk": "@@ -0,0 +1,7 @@\n+# Ignore everything from the Cloud Build command.", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMxNzc0OA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393317748", "bodyText": "Got it, I forgot about these files, adding copyright information", "author": "davidcavazos", "createdAt": "2020-03-16T21:22:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODY1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODc0Ng==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391308746", "bodyText": "Copyright & License?", "author": "lesv", "createdAt": "2020-03-11T22:34:41Z", "path": "dataflow/flex-templates/kafka_to_bigquery/kafka/Dockerfile", "diffHunk": "@@ -0,0 +1,37 @@\n+FROM openjdk:8-jre-alpine", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMxOTU3OQ==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393319579", "bodyText": "Added", "author": "davidcavazos", "createdAt": "2020-03-16T21:26:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwODc0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwOTIwMw==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391309203", "bodyText": "Copyright & License?", "author": "lesv", "createdAt": "2020-03-11T22:35:55Z", "path": "dataflow/flex-templates/kafka_to_bigquery/kafka/create-topic.sh", "diffHunk": "@@ -0,0 +1,20 @@\n+#!/bin/sh", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMxOTk4MA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393319980", "bodyText": "Added", "author": "davidcavazos", "createdAt": "2020-03-16T21:27:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwOTIwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwOTI5Mw==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391309293", "bodyText": "Copyright & License?", "author": "lesv", "createdAt": "2020-03-11T22:36:09Z", "path": "dataflow/flex-templates/kafka_to_bigquery/kafka/start-kafka.sh", "diffHunk": "@@ -0,0 +1,48 @@\n+#!/bin/sh\n+", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMyMDAzOA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393320038", "bodyText": "Added", "author": "davidcavazos", "createdAt": "2020-03-16T21:27:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMwOTI5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMDI0Ng==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391310246", "bodyText": "Ideally should have Copyright & License unless whatever reading it has a problem w/ that.\n\"_Copyright\" : \"Copyright 2020 Google, LLC\",\n\"_License\":\"....\",\nIf that doesn't work, then it's ok to skip.", "author": "lesv", "createdAt": "2020-03-11T22:38:51Z", "path": "dataflow/flex-templates/kafka_to_bigquery/metadata.json", "diffHunk": "@@ -0,0 +1,32 @@\n+{", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMTAxNQ==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391311015", "bodyText": "You might wish to mention this in the README; Copyright & License", "author": "lesv", "createdAt": "2020-03-11T22:41:01Z", "path": "dataflow/flex-templates/streaming_beam_sql/.gcloudignore", "diffHunk": "@@ -0,0 +1,7 @@\n+# Ignore everything from the Cloud Build command.", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMyMDYwOQ==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393320609", "bodyText": "Did the same as above.", "author": "davidcavazos", "createdAt": "2020-03-16T21:29:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMTAxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMTI3Ng==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391311276", "bodyText": "Copyright & License", "author": "lesv", "createdAt": "2020-03-11T22:41:42Z", "path": "dataflow/flex-templates/streaming_beam_sql/Dockerfile", "diffHunk": "@@ -0,0 +1,8 @@\n+FROM gcr.io/dataflow-templates-base/java11-template-launcher-base:latest", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMyMDY2Nw==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393320667", "bodyText": "Added", "author": "davidcavazos", "createdAt": "2020-03-16T21:29:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMTI3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMTkxMg==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391311912", "bodyText": "So this is interesting w/ that .cloudignore above -- I presume you've verified that things work.", "author": "lesv", "createdAt": "2020-03-11T22:43:40Z", "path": "dataflow/flex-templates/streaming_beam_sql/README.md", "diffHunk": "@@ -0,0 +1,315 @@\n+# Dataflow flex templates - Streaming Beam SQL\n+\n+[![Open in Cloud Shell](http://gstatic.com/cloudssh/images/open-btn.svg)](https://console.cloud.google.com/cloudshell/editor)\n+\n+\ud83d\udcdd Docs: [Using Flex Templates](https://cloud.google.com/dataflow/docs/guides/templates/using-flex-templates)\n+\n+Samples showing how to create and run an\n+[Apache Beam](https://beam.apache.org/) template with a custom Docker image on\n+[Google Cloud Dataflow](https://cloud.google.com/dataflow/docs/).\n+\n+## Before you begin\n+\n+Follow the\n+[Getting started with Google Cloud Dataflow](../README.md)\n+page, and make sure you have a Google Cloud project with billing enabled\n+and a *service account JSON key* set up in your `GOOGLE_APPLICATION_CREDENTIALS`\n+environment variable.\n+Additionally, for this sample you need the following:\n+\n+1. Create a\n+    [Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets).\n+\n+    ```sh\n+    export BUCKET=\"your-gcs-bucket\"\n+    gsutil mb gs://$BUCKET\n+    ```\n+\n+1. Create a\n+    [Pub/Sub topic](https://cloud.google.com/pubsub/docs/admin#creating_a_topic)\n+    and a\n+    [subscription](https://cloud.google.com/pubsub/docs/admin#creating_subscriptions)\n+    to that topic.\n+    This is a streaming source of data for the sample.\n+\n+    ```sh\n+    # For simplicity we use the same topic name as the subscription name.\n+    export TOPIC=\"messages\"\n+    export SUBSCRIPTION=\"$TOPIC\"\n+\n+    gcloud pubsub topics create $TOPIC\n+    gcloud pubsub subscriptions create --topic $TOPIC $SUBSCRIPTION\n+    ```\n+\n+1. Create a\n+    [Cloud Scheduler job](https://cloud.google.com/scheduler/docs/quickstart)\n+    to publish \"positive\" and \"negative\" ratings every\n+    [1 and 2 minutes](https://cloud.google.com/scheduler/docs/configuring/cron-job-schedules).\n+    This publishes messages to the Pub/Sub source topic.\n+\n+    ```sh\n+    # Create a publisher for \"positive ratings\" that publishes 1 message per minute\n+    # If an App Engine app does not exist for the project, this step will create one.\n+    gcloud scheduler jobs create pubsub thumbs-up-publisher \\\n+      --schedule=\"* * * * *\" \\\n+      --topic=\"$TOPIC\" \\\n+      --message-body='{\"url\": \"https://beam.apache.org/\", \"review\": \"positive\"}'\n+\n+    # Start the job.\n+    gcloud scheduler jobs run thumbs-up-publisher\n+\n+    # Create and run another similar publisher for \"negative ratings\" that\n+    # publishes 1 message every 2 minutes.\n+    gcloud scheduler jobs create pubsub thumbs-down-publisher \\\n+      --schedule=\"*/2 * * * *\" \\\n+      --topic=\"$TOPIC\" \\\n+      --message-body='{\"url\": \"https://beam.apache.org/\", \"review\": \"negative\"}'\n+\n+    gcloud scheduler jobs run thumbs-down-publisher\n+    ```\n+\n+1. Create a [BigQuery dataset](https://cloud.google.com/bigquery/docs/datasets).\n+    This is a table to write the output data.\n+\n+    ```sh\n+    export PROJECT=\"$(gcloud config get-value project)\"\n+    export DATASET=\"beam_samples\"\n+    export TABLE=\"streaming_beam_sql\"\n+\n+    bq mk --dataset \"$PROJECT:$DATASET\"\n+    ```\n+\n+1. Clone the\n+    [`java-docs-samples` repository](https://github.com/GoogleCloudPlatform/java-docs-samples)\n+    and navigate to the code sample.\n+\n+    ```sh\n+    git clone https://github.com/GoogleCloudPlatform/java-docs-samples.git\n+    cd java-docs-samples/dataflow/flex-templates/beam_sql\n+    ```\n+\n+## Pub/Sub to BigQuery with Beam SQL sample\n+\n+This sample shows how to deploy an Apache Beam streaming pipeline that reads\n+[JSON encoded](https://www.w3schools.com/whatis/whatis_json.asp) messages from\n+[Pub/Sub](https://cloud.google.com/pubsub), uses\n+[Beam SQL](https://beam.apache.org/documentation/dsls/sql/overview/)\n+to transform the message data, and writes the results to a\n+[BigQuery](https://cloud.google.com/bigquery) table.\n+\n+* [Dockerfile](Dockerfile)\n+* [StreamingBeamSQL.java](src/main/java/org/apache/beam/samples/StreamingBeamSQL.java)\n+* [pom.xml](pom.xml)\n+* [metadata.json](metadata.json)\n+\n+### Building a container image\n+\n+> <details><summary>\n+> <i>(Optional)</i> Run the Apache Beam pipeline locally for development.\n+> <i>(Click to expand)</i>\n+> </summary>\n+>\n+> ```sh\n+> mvn compile exec:java \\\n+>   -Dexec.mainClass=org.apache.beam.samples.StreamingBeamSQL \\\n+>   -Dexec.args=\"\\\n+>     --inputSubscription=$SUBSCRIPTION \\\n+>     --outputTable=$PROJECT:$DATASET.$TABLE \\\n+>     --tempLocation=gs://$BUCKET/samples/dataflow/temp\"\n+> ```\n+>\n+> </details>\n+\n+Build the Java project into an\n+[*Uber JAR* file](https://maven.apache.org/plugins/maven-shade-plugin/).\n+\n+```sh\n+# Build and package the application as an uber-jar file.\n+mvn clean package\n+\n+# (Optional) Note the size of the uber-jar file compared to the original.\n+ls -lh target/*.jar\n+```\n+\n+This *Uber JAR* file has all the dependencies embedded so it.\n+You can run this file as a standalone application with no external\n+dependencies on other libraries.\n+\n+Now, we build the\n+[Docker](https://docs.docker.com/engine/docker-overview/)\n+image for the Apache Beam pipeline.\n+We are using\n+[Cloud Build](https://cloud.google.com/cloud-build)\n+so we don't need a local installation of Docker.\n+\n+> *Note:* You can speed up subsequent builds with\n+> [Kaniko cache](https://cloud.google.com/cloud-build/docs/kaniko-cache)\n+> in Cloud Build.\n+>\n+> ```sh\n+> # (Optional) Enable to use Kaniko cache by default.\n+> gcloud config set builds/use_kaniko True\n+> ```\n+\n+Cloud Build allows you to\n+[build a Docker image using a `Dockerfile`](https://cloud.google.com/cloud-build/docs/quickstart-docker#build_using_dockerfile).\n+and saves it into\n+[Container Registry](https://cloud.google.com/container-registry/),\n+where the image is accessible to other Google Cloud products.\n+\n+```sh\n+export TEMPLATE_IMAGE=\"$PROJECT/samples/dataflow/streaming-beam-sql:latest\"\n+\n+# Build the image into Container Registry, this is roughly equivalent to:\n+#   gcloud auth configure-docker\n+#   docker image build -t $TEMPLATE_IMAGE .\n+#   docker push $TEMPLATE_IMAGE\n+gcloud builds submit --tag \"gcr.io/$TEMPLATE_IMAGE\" .\n+```", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjI3NQ==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391312275", "bodyText": "I wonder if you shouldn't just have a cleanup.sh script somewhere?", "author": "lesv", "createdAt": "2020-03-11T22:44:40Z", "path": "dataflow/flex-templates/streaming_beam_sql/README.md", "diffHunk": "@@ -0,0 +1,315 @@\n+# Dataflow flex templates - Streaming Beam SQL\n+\n+[![Open in Cloud Shell](http://gstatic.com/cloudssh/images/open-btn.svg)](https://console.cloud.google.com/cloudshell/editor)\n+\n+\ud83d\udcdd Docs: [Using Flex Templates](https://cloud.google.com/dataflow/docs/guides/templates/using-flex-templates)\n+\n+Samples showing how to create and run an\n+[Apache Beam](https://beam.apache.org/) template with a custom Docker image on\n+[Google Cloud Dataflow](https://cloud.google.com/dataflow/docs/).\n+\n+## Before you begin\n+\n+Follow the\n+[Getting started with Google Cloud Dataflow](../README.md)\n+page, and make sure you have a Google Cloud project with billing enabled\n+and a *service account JSON key* set up in your `GOOGLE_APPLICATION_CREDENTIALS`\n+environment variable.\n+Additionally, for this sample you need the following:\n+\n+1. Create a\n+    [Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets).\n+\n+    ```sh\n+    export BUCKET=\"your-gcs-bucket\"\n+    gsutil mb gs://$BUCKET\n+    ```\n+\n+1. Create a\n+    [Pub/Sub topic](https://cloud.google.com/pubsub/docs/admin#creating_a_topic)\n+    and a\n+    [subscription](https://cloud.google.com/pubsub/docs/admin#creating_subscriptions)\n+    to that topic.\n+    This is a streaming source of data for the sample.\n+\n+    ```sh\n+    # For simplicity we use the same topic name as the subscription name.\n+    export TOPIC=\"messages\"\n+    export SUBSCRIPTION=\"$TOPIC\"\n+\n+    gcloud pubsub topics create $TOPIC\n+    gcloud pubsub subscriptions create --topic $TOPIC $SUBSCRIPTION\n+    ```\n+\n+1. Create a\n+    [Cloud Scheduler job](https://cloud.google.com/scheduler/docs/quickstart)\n+    to publish \"positive\" and \"negative\" ratings every\n+    [1 and 2 minutes](https://cloud.google.com/scheduler/docs/configuring/cron-job-schedules).\n+    This publishes messages to the Pub/Sub source topic.\n+\n+    ```sh\n+    # Create a publisher for \"positive ratings\" that publishes 1 message per minute\n+    # If an App Engine app does not exist for the project, this step will create one.\n+    gcloud scheduler jobs create pubsub thumbs-up-publisher \\\n+      --schedule=\"* * * * *\" \\\n+      --topic=\"$TOPIC\" \\\n+      --message-body='{\"url\": \"https://beam.apache.org/\", \"review\": \"positive\"}'\n+\n+    # Start the job.\n+    gcloud scheduler jobs run thumbs-up-publisher\n+\n+    # Create and run another similar publisher for \"negative ratings\" that\n+    # publishes 1 message every 2 minutes.\n+    gcloud scheduler jobs create pubsub thumbs-down-publisher \\\n+      --schedule=\"*/2 * * * *\" \\\n+      --topic=\"$TOPIC\" \\\n+      --message-body='{\"url\": \"https://beam.apache.org/\", \"review\": \"negative\"}'\n+\n+    gcloud scheduler jobs run thumbs-down-publisher\n+    ```\n+\n+1. Create a [BigQuery dataset](https://cloud.google.com/bigquery/docs/datasets).\n+    This is a table to write the output data.\n+\n+    ```sh\n+    export PROJECT=\"$(gcloud config get-value project)\"\n+    export DATASET=\"beam_samples\"\n+    export TABLE=\"streaming_beam_sql\"\n+\n+    bq mk --dataset \"$PROJECT:$DATASET\"\n+    ```\n+\n+1. Clone the\n+    [`java-docs-samples` repository](https://github.com/GoogleCloudPlatform/java-docs-samples)\n+    and navigate to the code sample.\n+\n+    ```sh\n+    git clone https://github.com/GoogleCloudPlatform/java-docs-samples.git\n+    cd java-docs-samples/dataflow/flex-templates/beam_sql\n+    ```\n+\n+## Pub/Sub to BigQuery with Beam SQL sample\n+\n+This sample shows how to deploy an Apache Beam streaming pipeline that reads\n+[JSON encoded](https://www.w3schools.com/whatis/whatis_json.asp) messages from\n+[Pub/Sub](https://cloud.google.com/pubsub), uses\n+[Beam SQL](https://beam.apache.org/documentation/dsls/sql/overview/)\n+to transform the message data, and writes the results to a\n+[BigQuery](https://cloud.google.com/bigquery) table.\n+\n+* [Dockerfile](Dockerfile)\n+* [StreamingBeamSQL.java](src/main/java/org/apache/beam/samples/StreamingBeamSQL.java)\n+* [pom.xml](pom.xml)\n+* [metadata.json](metadata.json)\n+\n+### Building a container image\n+\n+> <details><summary>\n+> <i>(Optional)</i> Run the Apache Beam pipeline locally for development.\n+> <i>(Click to expand)</i>\n+> </summary>\n+>\n+> ```sh\n+> mvn compile exec:java \\\n+>   -Dexec.mainClass=org.apache.beam.samples.StreamingBeamSQL \\\n+>   -Dexec.args=\"\\\n+>     --inputSubscription=$SUBSCRIPTION \\\n+>     --outputTable=$PROJECT:$DATASET.$TABLE \\\n+>     --tempLocation=gs://$BUCKET/samples/dataflow/temp\"\n+> ```\n+>\n+> </details>\n+\n+Build the Java project into an\n+[*Uber JAR* file](https://maven.apache.org/plugins/maven-shade-plugin/).\n+\n+```sh\n+# Build and package the application as an uber-jar file.\n+mvn clean package\n+\n+# (Optional) Note the size of the uber-jar file compared to the original.\n+ls -lh target/*.jar\n+```\n+\n+This *Uber JAR* file has all the dependencies embedded so it.\n+You can run this file as a standalone application with no external\n+dependencies on other libraries.\n+\n+Now, we build the\n+[Docker](https://docs.docker.com/engine/docker-overview/)\n+image for the Apache Beam pipeline.\n+We are using\n+[Cloud Build](https://cloud.google.com/cloud-build)\n+so we don't need a local installation of Docker.\n+\n+> *Note:* You can speed up subsequent builds with\n+> [Kaniko cache](https://cloud.google.com/cloud-build/docs/kaniko-cache)\n+> in Cloud Build.\n+>\n+> ```sh\n+> # (Optional) Enable to use Kaniko cache by default.\n+> gcloud config set builds/use_kaniko True\n+> ```\n+\n+Cloud Build allows you to\n+[build a Docker image using a `Dockerfile`](https://cloud.google.com/cloud-build/docs/quickstart-docker#build_using_dockerfile).\n+and saves it into\n+[Container Registry](https://cloud.google.com/container-registry/),\n+where the image is accessible to other Google Cloud products.\n+\n+```sh\n+export TEMPLATE_IMAGE=\"$PROJECT/samples/dataflow/streaming-beam-sql:latest\"\n+\n+# Build the image into Container Registry, this is roughly equivalent to:\n+#   gcloud auth configure-docker\n+#   docker image build -t $TEMPLATE_IMAGE .\n+#   docker push $TEMPLATE_IMAGE\n+gcloud builds submit --tag \"gcr.io/$TEMPLATE_IMAGE\" .\n+```\n+\n+Images starting with `gcr.io/PROJECT/` are saved into your project's\n+Container Registry, where the image is accessible to other Google Cloud products.\n+\n+### Creating a Flex Template\n+\n+To run a template, you need to create a *template spec* file containing all the\n+necessary information to run the job, such as the SDK information and metadata.\n+\n+The [`metadata.json`](metadata.json) file contains additional information for\n+the template such as the \"name\", \"description\", and input \"parameters\" field.\n+\n+The template file must be created in a Cloud Storage location,\n+and is used to run a new Dataflow job.\n+\n+```sh\n+export TEMPLATE_PATH=\"gs://$BUCKET/samples/dataflow/templates/streaming-beam-sql.json\"\n+\n+# Build the Flex Template.\n+gcloud beta dataflow flex-template build $TEMPLATE_PATH \\\n+  --image \"gcr://$TEMPLATE_IMAGE\" \\\n+  --sdk-language \"JAVA\" \\\n+  --metadata-file \"metadata.json\"\n+```\n+\n+The template is now available through the template file in the Cloud Storage\n+location that you specified.\n+\n+### Running a Dataflow Flex Template pipeline\n+\n+You can now run the Apache Beam pipeline in Dataflow by referring to the\n+template file and passing the template\n+[parameters](https://cloud.devsite.corp.google.com/dataflow/docs/guides/specifying-exec-params#setting-other-cloud-dataflow-pipeline-options)\n+required by the pipeline.\n+\n+```sh\n+# Parameters before the `--` are passed to the `gcloud` command.\n+# Parameters after the `--` are passed to the Beam pipeline.\n+gcloud beta dataflow flex-template run \"streaming-beam-sql-`date +%Y%m%d-%H%M%S`\" \\\n+  --template-file-gcs-location \"$TEMPLATE_PATH\" \\\n+  --parameters \"inputSubscription=$SUBSCRIPTION,outputTable=$PROJECT:$DATASET.$TABLE\"\n+```\n+\n+Check the results in BigQuery by running the following query:\n+\n+```sh\n+bq query --use_legacy_sql=false 'SELECT * FROM `'\"$PROJECT.$DATASET.$TABLE\"'`'\n+```\n+\n+While this pipeline is running, you can see new rows appended into the BigQuery\n+table every minute.\n+\n+You can manually publish more messages from the\n+[Cloud Scheduler page](https://console.cloud.google.com/cloudscheduler)\n+to see how that affects the page review scores.\n+\n+You can also publish messages directly to a topic through the\n+[Pub/Sub topics page](https://console.cloud.google.com/cloudpubsub/topic/list)\n+by selecting the topic you want to publish to,\n+and then clicking the \"Publish message\" button at the top.\n+This way you can test your pipeline with different URLs,\n+just make sure you pass valid JSON data since this sample does not do any\n+error handling for code simplicity.\n+\n+Try sending the following message and check back the BigQuery table about\n+a minute later.\n+\n+```json\n+{\"url\": \"https://cloud.google.com/bigquery/\", \"review\": \"positive\"}\n+```\n+\n+### Cleaning up\n+\n+After you've finished this tutorial, you can clean up the resources you created\n+on Google Cloud so you won't be billed for them in the future.\n+The following sections describe how to delete or turn off these resources.\n+\n+#### Clean up the Flex template resources", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjY4MA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391312680", "bodyText": "Wow - this is long, I understand your trying to teach here, but I wonder if providing a script that does it and explains as it runs might be easier on users.  ./setup.sh", "author": "lesv", "createdAt": "2020-03-11T22:45:59Z", "path": "dataflow/flex-templates/streaming_beam_sql/README.md", "diffHunk": "@@ -0,0 +1,315 @@\n+# Dataflow flex templates - Streaming Beam SQL\n+\n+[![Open in Cloud Shell](http://gstatic.com/cloudssh/images/open-btn.svg)](https://console.cloud.google.com/cloudshell/editor)\n+\n+\ud83d\udcdd Docs: [Using Flex Templates](https://cloud.google.com/dataflow/docs/guides/templates/using-flex-templates)\n+\n+Samples showing how to create and run an\n+[Apache Beam](https://beam.apache.org/) template with a custom Docker image on\n+[Google Cloud Dataflow](https://cloud.google.com/dataflow/docs/).\n+\n+## Before you begin", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzOTgyNA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393339824", "bodyText": "I agree, it's a lot. I played a bit with creating a script, but now I would have to handle user confirmations when creating/deleting resources and much more validation. That would also make doing the setup/cleanup harder to port to windows. I will leave the instructions in the README for simplicity for now.\nThese instructions are also present in the docs, so we would prefer to keep them as compatible as possible.", "author": "davidcavazos", "createdAt": "2020-03-16T22:17:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjY4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzg3NjI4Mg==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393876282", "bodyText": "Why not link to the docs then?  Though I prefer README's where it's included, but a single source of truth is also a good idea.", "author": "lesv", "createdAt": "2020-03-17T18:12:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjY4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzk1NTg3MQ==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393955871", "bodyText": "They want to merge fast for the launch and I don't want to stall the launch since a script like that would take several weeks to develop. I agree that a script would be very handy, but at this point we all just want this to merge and get it over with.", "author": "davidcavazos", "createdAt": "2020-03-17T20:39:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjY4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI1Mjc4Ng==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r395252786", "bodyText": "Hi @lesv, sorry for my last response, I was a little frustrated with all the deadlines the product team wanted to meet. I did play around for just under an hour trying to implement a setup script, here's what I learned from it.\n\nWe have to check if a resource already exists before creating it\nWe need to ask for user confirmation before creating any resources\nRight now Windows users only have to make small changes to the commands, mainly the \\ for line continuations. But having a bash script would make it much more harder for them to run the sample.\nAll the complexity adds up and the script was turning out to be as large as the sample itself\nAlso having the explanations in Markdown makes the text clearer to read with all the nice formatting\nMost of the instructions (except for Cloud Scheduler), are actually instructions that users need to follow to use Flex Templates, so it makes sense to have them in the README\nThe docs are somewhat simplified to make them simpler and easier to follow, while the README has more detail on some of the commands and why/how to run them, so it makes sense to keep both.\n\nI had a chat with Meredith and we agreed to keep it like this for now. If we see there is a need from users in the future, we can allocate extra resources into creating these scripts.", "author": "davidcavazos", "createdAt": "2020-03-19T18:59:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjY4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTMxNzYyMw==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r395317623", "bodyText": "Sg - I already approved the PR", "author": "lesv", "createdAt": "2020-03-19T21:02:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjY4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMjg2OA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391312868", "bodyText": "Same comment about Copyright & Licenses at earlier.", "author": "lesv", "createdAt": "2020-03-11T22:46:27Z", "path": "dataflow/flex-templates/streaming_beam_sql/metadata.json", "diffHunk": "@@ -0,0 +1,23 @@\n+{", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMzA3Nw==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r391313077", "bodyText": "Why are we sending users to SNAPSHOT repositories?  That's not really good practice.", "author": "lesv", "createdAt": "2020-03-11T22:47:06Z", "path": "dataflow/flex-templates/streaming_beam_sql/pom.xml", "diffHunk": "@@ -0,0 +1,175 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one or more\n+    contributor license agreements.  See the NOTICE file distributed with\n+    this work for additional information regarding copyright ownership.\n+    The ASF licenses this file to You under the Apache License, Version 2.0\n+    (the \"License\"); you may not use this file except in compliance with\n+    the License.  You may obtain a copy of the License at\n+\n+       http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing, software\n+    distributed under the License is distributed on an \"AS IS\" BASIS,\n+    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+    See the License for the specific language governing permissions and\n+    limitations under the License.\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\" \n+  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+\n+  <groupId>org.apache.beam.samples</groupId>\n+  <artifactId>streaming-beam-sql</artifactId>\n+  <version>1.0</version>\n+\n+  <properties>\n+    <maven.compiler.source>11</maven.compiler.source>\n+    <maven.compiler.target>11</maven.compiler.target>\n+    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n+\n+    <beam.version>2.19.0</beam.version>\n+\n+    <maven-enforcer-plugin.version>3.0.0-M3</maven-enforcer-plugin.version>\n+    <maven-compiler-plugin.version>3.8.1</maven-compiler-plugin.version>\n+    <maven-shade-plugin.version>3.2.1</maven-shade-plugin.version>\n+    <maven-exec-plugin.version>1.6.0</maven-exec-plugin.version>\n+    <slf4j.version>1.7.30</slf4j.version>\n+  </properties>\n+\n+  <repositories>\n+    <repository>\n+      <id>apache.snapshots</id>\n+      <name>Apache Development Snapshot Repository</name>\n+      <url>https://repository.apache.org/content/repositories/snapshots/</url>\n+      <releases>\n+        <enabled>false</enabled>\n+      </releases>\n+      <snapshots>\n+        <enabled>true</enabled>\n+      </snapshots>\n+    </repository>\n+  </repositories>", "originalCommit": "9c157fcacc03ef3a9e4fc5532700e8df59d54dd8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMyMTczNw==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393321737", "bodyText": "I'm following what the Beam maven archetype creates for a new project. Is it safe to remove?", "author": "davidcavazos", "createdAt": "2020-03-16T21:31:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMzA3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzg3NzAxOA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r393877018", "bodyText": "Typically yes-  *-SNAPSHOT's are often not really versioned or rebuildable.  They are really only useful (on an OSS project) if you are following top of trunk, but it leads to non reproducible builds.", "author": "lesv", "createdAt": "2020-03-17T18:13:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMzA3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDAwMDkxOA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/2373#discussion_r394000918", "bodyText": "Got it, removed. Thank you!", "author": "davidcavazos", "createdAt": "2020-03-17T22:13:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTMxMzA3Nw=="}], "type": "inlineReview"}, {"oid": "046f5c3bc1034626d218ca3528ff7f9b5b927320", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/046f5c3bc1034626d218ca3528ff7f9b5b927320", "message": "Added license", "committedDate": "2020-03-16T22:17:24Z", "type": "forcePushed"}, {"oid": "9e80e53f273a70d7fe697dcc5e5b992cec844f34", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/9e80e53f273a70d7fe697dcc5e5b992cec844f34", "message": "Removed snapshots", "committedDate": "2020-03-17T22:14:59Z", "type": "forcePushed"}, {"oid": "f02dfc31eb35ca3170a1d447f96ca30ffca0a862", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/f02dfc31eb35ca3170a1d447f96ca30ffca0a862", "message": "dataflow: add flex templates sample", "committedDate": "2020-03-23T18:50:05Z", "type": "commit"}, {"oid": "00e033c15062013747c7dc318f804e4ae43919dc", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/00e033c15062013747c7dc318f804e4ae43919dc", "message": "Improved the README instructions", "committedDate": "2020-03-23T18:50:05Z", "type": "commit"}, {"oid": "01514151192cce3383bcbcc284b5e3f03a41bc60", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/01514151192cce3383bcbcc284b5e3f03a41bc60", "message": "Simplified command to create new pipeline", "committedDate": "2020-03-23T18:50:05Z", "type": "commit"}, {"oid": "7954d0116f5d1ea0fb53ad3ba22e9a30c39ddd9e", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/7954d0116f5d1ea0fb53ad3ba22e9a30c39ddd9e", "message": "Updated README and simplified files", "committedDate": "2020-03-23T18:50:06Z", "type": "commit"}, {"oid": "843aa48a29956caef18441f8b878bd5d35fa0a14", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/843aa48a29956caef18441f8b878bd5d35fa0a14", "message": "Add streaming-beam-sql sample", "committedDate": "2020-03-23T18:50:06Z", "type": "commit"}, {"oid": "c0150d1803d5ac709f14d9d7d6fc4c7564024427", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/c0150d1803d5ac709f14d9d7d6fc4c7564024427", "message": "Added BeamSQL and updated README", "committedDate": "2020-03-23T18:50:06Z", "type": "commit"}, {"oid": "91cf6ae89d2a07094f71115a19763305a7ec077d", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/91cf6ae89d2a07094f71115a19763305a7ec077d", "message": "Updated README", "committedDate": "2020-03-23T18:50:06Z", "type": "commit"}, {"oid": "5cf69d40ba09848782fd8b91a37eec7a290cb35b", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/5cf69d40ba09848782fd8b91a37eec7a290cb35b", "message": "Updated README", "committedDate": "2020-03-23T18:50:06Z", "type": "commit"}, {"oid": "3bcc1c31d0f06f49889e14b4bae3f8377ac413a3", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/3bcc1c31d0f06f49889e14b4bae3f8377ac413a3", "message": "Added newline at EOF", "committedDate": "2020-03-23T18:50:06Z", "type": "commit"}, {"oid": "548fc56a2e2904d349e36c46b0c97225c55c458b", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/548fc56a2e2904d349e36c46b0c97225c55c458b", "message": "Updated README", "committedDate": "2020-03-23T18:50:06Z", "type": "commit"}, {"oid": "21655d296edc0b75120da15d265fd2bcea4aec7d", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/21655d296edc0b75120da15d265fd2bcea4aec7d", "message": "Added license", "committedDate": "2020-03-23T18:50:06Z", "type": "commit"}, {"oid": "0b9b66e2fad380a5e4fc835c6de4cdd7e0ac467b", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/0b9b66e2fad380a5e4fc835c6de4cdd7e0ac467b", "message": "Minor fixes", "committedDate": "2020-03-23T18:50:06Z", "type": "commit"}, {"oid": "8c555b831ebbaf555820ccc4537a8d7cb43ed115", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/8c555b831ebbaf555820ccc4537a8d7cb43ed115", "message": "Removed snapshots", "committedDate": "2020-03-23T18:50:06Z", "type": "commit"}, {"oid": "0054d68b9d41a233d5cd964fef983da80bc66370", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/0054d68b9d41a233d5cd964fef983da80bc66370", "message": "Updated README", "committedDate": "2020-03-23T18:50:06Z", "type": "commit"}, {"oid": "0054d68b9d41a233d5cd964fef983da80bc66370", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/0054d68b9d41a233d5cd964fef983da80bc66370", "message": "Updated README", "committedDate": "2020-03-23T18:50:06Z", "type": "forcePushed"}]}