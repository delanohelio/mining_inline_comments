{"pr_number": 4384, "pr_title": "bigtable: spark example", "pr_createdAt": "2020-12-08T18:25:29Z", "pr_url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384", "timeline": [{"oid": "6f1fff9738c519c42fc6a8de191b3928de49b95f", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/6f1fff9738c519c42fc6a8de191b3928de49b95f", "message": "[WIP] Spark Applications for Cloud Bigtable (#3487)\n\n* [WIP] Spark Applications for Cloud Bigtable\r\n\r\n* Loading and saving using DataFrame API\r\n\r\n* Writing data using RDD API to Bigtable\r\n\r\n* Addressing comments after a code review\r\n\r\n* Submit DataFrameDemo to Cloud Dataproc\r\n\r\n* After code review\r\n\r\n* After code review\r\n\r\n* [Wordcount] Use Admin API to create tables\r\n\r\n* Command-line options + testing framework\r\n\r\n* Add the other cmd options + exclude tests in assembly\r\n\r\n* Tasts marked done (and removed)\r\n\r\n* No need for extra dep. Bye, bye scopt\r\n\r\n* No need for xml config. Command-line arguments enough\r\n\r\n* Create Tables before running demos\r\n\r\n* CopyTable - Copying tables\r\n\r\n* Integration test\r\n\r\n* Assert row count in integration test\r\n\r\n* BIGTABLE_SPARK_ROW_COUNT for IT test to assert the row count\r\n\r\n* Use \"stable\" file for integration test\r\n\r\n* Running Integration Test\r\n\r\n* License headers\r\n\r\n* Fix the last round of style comments\r\n\r\n* Deps to match Dataproc 1.4\r\n\r\n* No need for supersafe\r\n\r\n* Source Code Headers\r\n\r\nAs per the official doc at https://github.com/GoogleCloudPlatform/java-docs-samples#source-code-headers\r\n\r\n* Run Wordcount with Cloud Bigtable verified to work\r\n\r\n* Run Wordcount with Cloud Dataproc\r\n\r\n* Removing HBase version dep\r\n\r\n* Licence headers\r\n\r\n* README", "committedDate": "2020-09-24T19:09:41Z", "type": "commit"}, {"oid": "9efa370300ff4b1eb945cdb913c574d1f95ba369", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/9efa370300ff4b1eb945cdb913c574d1f95ba369", "message": "bigtable(spark): readme updates", "committedDate": "2020-09-29T15:10:19Z", "type": "commit"}, {"oid": "2627e64bff5c79d2f2155c315edbade55830bcb4", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/2627e64bff5c79d2f2155c315edbade55830bcb4", "message": "Wordcount on Dataproc WORKS! (No more NPEs) (#3884)\n\n* Wordcount on Dataproc WORKS! (No more NPEs)\r\n\r\n* Readme\r\n\r\n* After code review", "committedDate": "2020-10-06T22:46:35Z", "type": "commit"}, {"oid": "bdb2d7939db23ea09de01c7923f7898fe3de7fa3", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/bdb2d7939db23ea09de01c7923f7898fe3de7fa3", "message": "chore(bigtable): spark deps cleanup and readme updates (#4134)", "committedDate": "2020-11-03T20:17:14Z", "type": "commit"}, {"oid": "92a9f3e75b8b2c52f1cc711d9c3d05e2bedb4999", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/92a9f3e75b8b2c52f1cc711d9c3d05e2bedb4999", "message": "test(bigtable_spark): update integration test, update deps and readme (#4262)", "committedDate": "2020-11-18T19:14:15Z", "type": "commit"}, {"oid": "cb92666f2a26089148baeff5564984dcebaf33d1", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/cb92666f2a26089148baeff5564984dcebaf33d1", "message": "chore(bigtable_spark): readme cleanup", "committedDate": "2020-11-19T15:58:43Z", "type": "commit"}, {"oid": "2920220f4079b65526d804c2e976e2dcb8b426bf", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/2920220f4079b65526d804c2e976e2dcb8b426bf", "message": "chore(bigtable_spark): last round of readme updates (#4353)", "committedDate": "2020-12-07T19:02:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU4MzI5Mw==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539583293", "bodyText": "I'd expect this to be okay as long as we're controlling not having duplicate dependencies above.", "author": "BenWhitehead", "createdAt": "2020-12-09T19:25:32Z", "path": "bigtable/spark/build.sbt", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+name := \"bigtable-spark-samples\"\n+\n+version := \"0.1\"\n+\n+// Versions to match Dataproc 1.4\n+// https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-1.4\n+scalaVersion := \"2.11.12\"\n+val sparkVersion = \"2.4.6\"\n+val bigtableVersion = \"1.16.0\"\n+val hbaseVersion = \"1.3.6\"\n+\n+libraryDependencies ++= Seq(\n+  \"org.apache.spark\" %% \"spark-sql\" % sparkVersion % Provided,\n+  \"org.apache.hbase.connectors.spark\" % \"hbase-spark\" % \"1.0.0\" % Provided,\n+  \"com.google.cloud.bigtable\" % \"bigtable-hbase-2.x-hadoop\" % bigtableVersion\n+)\n+\n+val scalatestVersion = \"3.2.0\"\n+libraryDependencies += \"org.scalactic\" %% \"scalactic\" % scalatestVersion\n+libraryDependencies += \"org.scalatest\" %% \"scalatest\" % scalatestVersion % \"test\"\n+test in assembly := {}\n+\n+val fixes = Seq(\n+  // Required by 'value org.apache.hadoop.hbase.spark.HBaseContext.dstream'\n+  \"org.apache.spark\" %% \"spark-streaming\" % sparkVersion % Provided,\n+  // hbase-server is needed because HBaseContext references org/apache/hadoop/hbase/fs/HFileSystem\n+  // hbase-client is declared to override the version of hbase-client declared by bigtable-hbase-2.x-hadoop\n+  \"org.apache.hbase\" % \"hbase-server\" % hbaseVersion,\n+  \"org.apache.hbase\" % \"hbase-client\" % hbaseVersion\n+)\n+libraryDependencies ++= fixes\n+\n+// Fix for Exception: Incompatible Jackson 2.9.2\n+// Version conflict between HBase and Spark\n+// Forcing the version to match Spark\n+dependencyOverrides += \"com.fasterxml.jackson.module\" %% \"jackson-module-scala\" % \"2.9.10\"\n+\n+// Excluding duplicates for the uber-jar\n+// There are other deps to provide necessary packages\n+excludeDependencies ++= Seq(\n+  ExclusionRule(organization = \"asm\", \"asm\"),\n+  ExclusionRule(organization = \"commons-beanutils\", \"commons-beanutils\"),\n+  ExclusionRule(organization = \"commons-beanutils\", \"commons-beanutils-core\"),\n+  ExclusionRule(organization = \"org.mortbay.jetty\", \"servlet-api\")\n+)\n+\n+assemblyMergeStrategy in assembly := {\n+  case PathList(\"META-INF\", \"io.netty.versions.properties\") => MergeStrategy.first\n+  case PathList(\"META-INF\", \"MANIFEST.MF\") => MergeStrategy.discard\n+  case PathList(\"mozilla\", \"public-suffix-list.txt\") => MergeStrategy.first\n+  case PathList(\"google\", xs @ _*) => xs match {\n+    case ps @ (x :: xs) if ps.last.endsWith(\".proto\") => MergeStrategy.first", "originalCommit": "2920220f4079b65526d804c2e976e2dcb8b426bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU4NDcyNA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539584724", "bodyText": "This might cause issues with guava, since our libraries use the most up-to-date version and spark (and especially HBase) doesn't necessarily track as close there is a chance for a diamond. It might be worth asking tomo how we might run linkage checker against an assembly and seeing if it would work.", "author": "BenWhitehead", "createdAt": "2020-12-09T19:27:38Z", "path": "bigtable/spark/build.sbt", "diffHunk": "@@ -0,0 +1,76 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+name := \"bigtable-spark-samples\"\n+\n+version := \"0.1\"\n+\n+// Versions to match Dataproc 1.4\n+// https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-1.4\n+scalaVersion := \"2.11.12\"\n+val sparkVersion = \"2.4.6\"\n+val bigtableVersion = \"1.16.0\"\n+val hbaseVersion = \"1.3.6\"\n+\n+libraryDependencies ++= Seq(\n+  \"org.apache.spark\" %% \"spark-sql\" % sparkVersion % Provided,\n+  \"org.apache.hbase.connectors.spark\" % \"hbase-spark\" % \"1.0.0\" % Provided,\n+  \"com.google.cloud.bigtable\" % \"bigtable-hbase-2.x-hadoop\" % bigtableVersion\n+)\n+\n+val scalatestVersion = \"3.2.0\"\n+libraryDependencies += \"org.scalactic\" %% \"scalactic\" % scalatestVersion\n+libraryDependencies += \"org.scalatest\" %% \"scalatest\" % scalatestVersion % \"test\"\n+test in assembly := {}\n+\n+val fixes = Seq(\n+  // Required by 'value org.apache.hadoop.hbase.spark.HBaseContext.dstream'\n+  \"org.apache.spark\" %% \"spark-streaming\" % sparkVersion % Provided,\n+  // hbase-server is needed because HBaseContext references org/apache/hadoop/hbase/fs/HFileSystem\n+  // hbase-client is declared to override the version of hbase-client declared by bigtable-hbase-2.x-hadoop\n+  \"org.apache.hbase\" % \"hbase-server\" % hbaseVersion,\n+  \"org.apache.hbase\" % \"hbase-client\" % hbaseVersion\n+)\n+libraryDependencies ++= fixes\n+\n+// Fix for Exception: Incompatible Jackson 2.9.2\n+// Version conflict between HBase and Spark\n+// Forcing the version to match Spark\n+dependencyOverrides += \"com.fasterxml.jackson.module\" %% \"jackson-module-scala\" % \"2.9.10\"\n+\n+// Excluding duplicates for the uber-jar\n+// There are other deps to provide necessary packages\n+excludeDependencies ++= Seq(\n+  ExclusionRule(organization = \"asm\", \"asm\"),\n+  ExclusionRule(organization = \"commons-beanutils\", \"commons-beanutils\"),\n+  ExclusionRule(organization = \"commons-beanutils\", \"commons-beanutils-core\"),\n+  ExclusionRule(organization = \"org.mortbay.jetty\", \"servlet-api\")\n+)\n+\n+assemblyMergeStrategy in assembly := {\n+  case PathList(\"META-INF\", \"io.netty.versions.properties\") => MergeStrategy.first\n+  case PathList(\"META-INF\", \"MANIFEST.MF\") => MergeStrategy.discard\n+  case PathList(\"mozilla\", \"public-suffix-list.txt\") => MergeStrategy.first\n+  case PathList(\"google\", xs @ _*) => xs match {\n+    case ps @ (x :: xs) if ps.last.endsWith(\".proto\") => MergeStrategy.first\n+    case _ => MergeStrategy.deduplicate\n+  }\n+  case x =>\n+    val oldStrategy = (assemblyMergeStrategy in assembly).value\n+    oldStrategy(x)\n+    // FIXME Make sure first is OK (it's worked well so far)\n+    MergeStrategy.first", "originalCommit": "2920220f4079b65526d804c2e976e2dcb8b426bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTY2NDQ3Mg==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539664472", "bodyText": "We try to keep the dependency versions in line with HBase for the adapter, so this should be ok.", "author": "kolea2", "createdAt": "2020-12-09T21:34:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU4NDcyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU4NTQ0MQ==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539585441", "bodyText": "Is this tracking the same version as spark? (latest is 1.4.4 according to https://www.scala-sbt.org/download.html)", "author": "BenWhitehead", "createdAt": "2020-12-09T19:28:54Z", "path": "bigtable/spark/project/build.properties", "diffHunk": "@@ -0,0 +1,15 @@\n+# Copyright 2020 Google LLC\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     https://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+sbt.version = 1.3.13", "originalCommit": "2920220f4079b65526d804c2e976e2dcb8b426bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjQ3MTQxNA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r542471414", "bodyText": "I need to double check - this may have just been the latest at the time. For now, let's leave it as is.", "author": "kolea2", "createdAt": "2020-12-14T15:25:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU4NTQ0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU4NzM0NA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539587344", "bodyText": "The newline here will be kept in the output, not sure if that is intended.", "author": "BenWhitehead", "createdAt": "2020-12-09T19:31:40Z", "path": "bigtable/spark/src/main/scala/example/CopyTable.scala", "diffHunk": "@@ -0,0 +1,115 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package example\n+\n+import org.apache.hadoop.hbase.spark.datasources.{HBaseSparkConf, HBaseTableCatalog}\n+import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}\n+\n+object CopyTable extends App {\n+\n+  val appName = this.getClass.getSimpleName.replace(\"$\", \"\")\n+  println(s\"$appName Spark application is starting up...\")\n+\n+  val (projectId, instanceId, fromTable, toTable) = parse(args)\n+  println(\n+    s\"\"\"", "originalCommit": "2920220f4079b65526d804c2e976e2dcb8b426bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU4ODQ1Ng==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539588456", "bodyText": "Missing validation for args like there is in CopyTable", "author": "BenWhitehead", "createdAt": "2020-12-09T19:33:25Z", "path": "bigtable/spark/src/main/scala/example/Wordcount.scala", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package example\n+\n+import com.google.cloud.bigtable.hbase.BigtableConfiguration\n+import org.apache.hadoop.hbase.client._\n+import org.apache.hadoop.hbase.io.ImmutableBytesWritable\n+import org.apache.hadoop.hbase.mapreduce.TableOutputFormat\n+import org.apache.hadoop.hbase.util.Bytes\n+import org.apache.spark.SparkContext\n+\n+object Wordcount extends App {\n+\n+  val projectId = args(0)\n+  val instanceId = args(1)\n+  val table = args(2)\n+  val file = args(3)", "originalCommit": "2920220f4079b65526d804c2e976e2dcb8b426bf", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU5MDMwNg==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539590306", "bodyText": "I would split each of these two tests into their own test so you can track them independently. We should be able to factor most of this code so that it's reusable by taking a function for the specific asserts.", "author": "BenWhitehead", "createdAt": "2020-12-09T19:36:13Z", "path": "bigtable/spark/src/test/scala/example/IntegrationTest.scala", "diffHunk": "@@ -0,0 +1,77 @@\n+/*\n+ * Copyright 2020 Google LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     https://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package example\n+\n+import java.util.UUID\n+\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.admin.v2.BigtableTableAdminClient\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.admin.v2.models.CreateTableRequest\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.data.v2.models.Query\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.data.v2.{BigtableDataClient, BigtableDataSettings}\n+import org.scalatest.flatspec._\n+import org.scalatest.matchers._\n+\n+class IntegrationTest extends AnyFlatSpec\n+  with should.Matchers {\n+\n+  def getOrThrowException(envName: String): String = {\n+    sys.env.getOrElse(\n+      envName,\n+      throw new IllegalStateException(s\"Environment variable '$envName' is required to perform this integration test.\"))\n+  }\n+  val projectId: String = getOrThrowException(\"GOOGLE_CLOUD_PROJECT\")\n+  val instanceId: String = getOrThrowException(\"BIGTABLE_TESTING_INSTANCE\")\n+  val file = \"src/test/resources/Romeo-and-Juliet-prologue.txt\"\n+\n+  val wordcount_table_name: String = \"spark-wordcount-\" + UUID.randomUUID.toString.substring(0, 20);\n+  val copytable_table_name: String = \"spark-copytable-\" + UUID.randomUUID.toString.substring(0, 20);\n+\n+  val tableClient: BigtableTableAdminClient = BigtableTableAdminClient.create(projectId, instanceId)\n+  val settings: BigtableDataSettings =\n+    BigtableDataSettings.newBuilder().setProjectId(projectId).setInstanceId(instanceId).build()\n+  val dataClient: BigtableDataClient = BigtableDataClient.create(settings)\n+\n+  \"IntegrationTest\" should \"write records to Bigtable, copy them between tables\" in {\n+    try {\n+      import org.apache.spark.{SparkConf, SparkContext}\n+      val appName = getClass.getSimpleName.replace(\"$\", \"\")\n+      val config = new SparkConf().setMaster(\"local[*]\").setAppName(appName)\n+      SparkContext.getOrCreate(config)\n+\n+      val wordcountRequest = CreateTableRequest.of(wordcount_table_name).addFamily(\"cf\")\n+      tableClient.createTable(wordcountRequest)\n+\n+      val copytableRequest = CreateTableRequest.of(copytable_table_name).addFamily(\"cf\")\n+      tableClient.createTable(copytableRequest);\n+\n+      val wordcountArgs = Array(projectId, instanceId, wordcount_table_name, file)\n+      Wordcount.main(wordcountArgs)\n+      val copytableArgs = Array(projectId, instanceId, wordcount_table_name, copytable_table_name)\n+      CopyTable.main(copytableArgs)\n+\n+      import collection.JavaConverters._\n+      val wordcountRowCount = dataClient.readRows(Query.create(wordcount_table_name)).iterator().asScala.length\n+      val copytableRowCount = dataClient.readRows(Query.create(copytable_table_name)).iterator().asScala.length", "originalCommit": "2920220f4079b65526d804c2e976e2dcb8b426bf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTY3MDY1OQ==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r539670659", "bodyText": "Not sure I understand, copytable depends on wordcount running first. Can you explain a bit more what you had in mind?", "author": "kolea2", "createdAt": "2020-12-09T21:44:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU5MDMwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU0MDQzMA==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4384#discussion_r540540430", "bodyText": "Apologies, I missed the assertion wordcountRowCount should be(copytableRowCount) in my read through and everything looked the same for both things.", "author": "BenWhitehead", "createdAt": "2020-12-10T22:22:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU5MDMwNg=="}], "type": "inlineReview"}, {"oid": "1212d647cf890725031aae0becc1a9fd7d13a19d", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/1212d647cf890725031aae0becc1a9fd7d13a19d", "message": "validate args", "committedDate": "2020-12-09T22:08:51Z", "type": "commit"}]}