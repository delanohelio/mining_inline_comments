{"pr_number": 4262, "pr_title": "test(bigtable_spark): update integration test, update deps and readme", "pr_createdAt": "2020-11-18T17:52:07Z", "pr_url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4262", "timeline": [{"oid": "dc5d6b54db1b7723abd42e3429ff88b269da805a", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/commit/dc5d6b54db1b7723abd42e3429ff88b269da805a", "message": "test(bigtable_spark): update integration test, update deps and readme", "committedDate": "2020-11-18T17:49:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM1MzQ0NQ==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4262#discussion_r526353445", "bodyText": "@kolea2 I presume there isn't an alternative yet?", "author": "lesv", "createdAt": "2020-11-18T19:13:56Z", "path": "bigtable/spark/src/test/scala/example/IntegrationTest.scala", "diffHunk": "@@ -15,44 +15,63 @@\n  */\n package example\n \n+import java.util.UUID\n+\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.admin.v2.BigtableTableAdminClient\n+import com.google.bigtable.repackaged.com.google.cloud.bigtable.admin.v2.models.CreateTableRequest\n import com.google.bigtable.repackaged.com.google.cloud.bigtable.data.v2.models.Query\n import com.google.bigtable.repackaged.com.google.cloud.bigtable.data.v2.{BigtableDataClient, BigtableDataSettings}\n import org.scalatest.flatspec._\n import org.scalatest.matchers._\n \n class IntegrationTest extends AnyFlatSpec\n-    with should.Matchers {\n+  with should.Matchers {\n \n   def getOrThrowException(envName: String): String = {\n     sys.env.getOrElse(\n       envName,\n       throw new IllegalStateException(s\"Environment variable '$envName' is required to perform this integration test.\"))\n   }\n-  val projectId = getOrThrowException(\"BIGTABLE_SPARK_PROJECT_ID\")\n-  val instanceId = getOrThrowException(\"BIGTABLE_SPARK_INSTANCE_ID\")\n-  val table_wordcount = getOrThrowException(\"BIGTABLE_SPARK_WORDCOUNT_TABLE\")\n+  val projectId: String = getOrThrowException(\"GOOGLE_CLOUD_PROJECT\")\n+  val instanceId: String = getOrThrowException(\"BIGTABLE_TESTING_INSTANCE\")\n   val file = \"src/test/resources/Romeo-and-Juliet-prologue.txt\"\n-  val table_copytable = getOrThrowException(\"BIGTABLE_SPARK_COPYTABLE_TABLE\")\n-  val rowCount = 88\n+\n+  val wordcount_table_name: String = \"spark-wordcount-\" + UUID.randomUUID.toString.substring(0, 20);\n+  val copytable_table_name: String = \"spark-copytable-\" + UUID.randomUUID.toString.substring(0, 20);\n+\n+  val tableClient: BigtableTableAdminClient = BigtableTableAdminClient.create(projectId, instanceId)\n+  val settings: BigtableDataSettings =\n+    BigtableDataSettings.newBuilder().setProjectId(projectId).setInstanceId(instanceId).build()\n+  val dataClient: BigtableDataClient = BigtableDataClient.create(settings)\n \n   \"IntegrationTest\" should \"write records to Bigtable, copy them between tables\" in {\n-    import org.apache.spark.{SparkConf, SparkContext}\n-    val appName = getClass.getSimpleName.replace(\"$\", \"\")\n-    val config = new SparkConf().setMaster(\"local[*]\").setAppName(appName)\n-    SparkContext.getOrCreate(config)\n-\n-    val wordcountArgs = Array(projectId, instanceId, table_wordcount, file)\n-    Wordcount.main(wordcountArgs)\n-    val copytableArgs = Array(projectId, instanceId, table_wordcount, table_copytable)\n-    CopyTable.main(copytableArgs)\n-\n-    val settings =\n-      BigtableDataSettings.newBuilder().setProjectId(projectId).setInstanceId(instanceId).build()\n-    val dataClient = BigtableDataClient.create(settings)\n-    import collection.JavaConverters._\n-    val wordcountRowCount = dataClient.readRows(Query.create(table_wordcount)).iterator().asScala.length\n-    val copytableRowCount = dataClient.readRows(Query.create(table_copytable)).iterator().asScala.length\n-    wordcountRowCount should be(rowCount)\n-    wordcountRowCount should be(copytableRowCount)\n+    try {\n+      import org.apache.spark.{SparkConf, SparkContext}\n+      val appName = getClass.getSimpleName.replace(\"$\", \"\")\n+      val config = new SparkConf().setMaster(\"local[*]\").setAppName(appName)", "originalCommit": "dc5d6b54db1b7723abd42e3429ff88b269da805a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjk5Mjc4Mg==", "url": "https://github.com/GoogleCloudPlatform/java-docs-samples/pull/4262#discussion_r526992782", "bodyText": "@lesv Yes, I tried looking for a different API but couldn't find anything. If anyone is aware of an alternative, please LMK!", "author": "kolea2", "createdAt": "2020-11-19T15:48:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM1MzQ0NQ=="}], "type": "inlineReview"}]}