{"pr_number": 61467, "pr_title": "Speed up date_histogram by precomputing ranges", "pr_createdAt": "2020-08-24T13:02:40Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/61467", "timeline": [{"oid": "7687e30291243995cffeb7d633a93bf798c29f57", "url": "https://github.com/elastic/elasticsearch/commit/7687e30291243995cffeb7d633a93bf798c29f57", "message": "Speed up date_histogram by precomputing ranges\n\nA few of us were talking about ways to speed up the `date_histogram`\nusing the index for the timestamp rather than the doc values. To do that\nwe'd have to pre-compute all of the \"round down\" points in the index. It\nturns out that *just* precomputing those values speeds up rounding\nfairly significantly:\n```\nBenchmark  (count)      (interval)                   (range)            (zone)  Mode  Cnt          Score         Error  Units\nbefore    10000000  calendar month  2000-10-28 to 2000-10-31               UTC  avgt   10   96461080.982 \u00b1  616373.011  ns/op\nbefore    10000000  calendar month  2000-10-28 to 2000-10-31  America/New_York  avgt   10  130598950.850 \u00b1 1249189.867  ns/op\nafter     10000000  calendar month  2000-10-28 to 2000-10-31               UTC  avgt   10   52311775.080 \u00b1  107171.092  ns/op\nafter     10000000  calendar month  2000-10-28 to 2000-10-31  America/New_York  avgt   10   54800134.968 \u00b1  373844.796  ns/op\n```\n\nThat's a 46% speed up when there isn't a time zone and a 58% speed up\nwhen there is.\n\nThis doesn't work for every time zone, specifically those that have two\nmidnights in a single day due to daylight savings time will produce wonky\nresults. So they don't get the optimization.\n\nSecond, this requires a few expensive computation up front to make the\ntransition array. And if the transition array is too large then we give\nup and use the original mechanism, throwing away all of the work we did\nto build the array. This seems appropriate for most usages of `round`,\nbut this change uses it for *all* usages of `round`. That seems ok for\nnow, but it might be worth investigating in a follow up.\n\nI ran a macrobenchmark as well which showed an 11% preformance\nimprovement. *BUT* the benchmark wasn't tuned for my desktop so it\noverwhelmed it and might have produced \"funny\" results. I think it is\npretty clear that this is an improvement, but know the measurement is\nweird:\n\n```\nBenchmark  (count)      (interval)                   (range)            (zone)  Mode  Cnt          Score         Error  Units\nbefore    10000000  calendar month  2000-10-28 to 2000-10-31               UTC  avgt   10   96461080.982 \u00b1  616373.011  ns/op\nbefore    10000000  calendar month  2000-10-28 to 2000-10-31  America/New_York  avgt   10  g\u00b1 1249189.867  ns/op\nafter     10000000  calendar month  2000-10-28 to 2000-10-31               UTC  avgt   10   52311775.080 \u00b1  107171.092  ns/op\nafter     10000000  calendar month  2000-10-28 to 2000-10-31  America/New_York  avgt   10   54800134.968 \u00b1  373844.796  ns/op\n\nBefore:\n|               Min Throughput | hourly_agg |        0.11 |  ops/s |\n|            Median Throughput | hourly_agg |        0.11 |  ops/s |\n|               Max Throughput | hourly_agg |        0.11 |  ops/s |\n|      50th percentile latency | hourly_agg |      650623 |     ms |\n|      90th percentile latency | hourly_agg |      821478 |     ms |\n|      99th percentile latency | hourly_agg |      859780 |     ms |\n|     100th percentile latency | hourly_agg |      864030 |     ms |\n| 50th percentile service time | hourly_agg |     9268.71 |     ms |\n| 90th percentile service time | hourly_agg |        9380 |     ms |\n| 99th percentile service time | hourly_agg |     9626.88 |     ms |\n|100th percentile service time | hourly_agg |     9884.27 |     ms |\n|                   error rate | hourly_agg |           0 |      % |\n\nAfter:\n|               Min Throughput | hourly_agg |        0.12 |  ops/s |\n|            Median Throughput | hourly_agg |        0.12 |  ops/s |\n|               Max Throughput | hourly_agg |        0.12 |  ops/s |\n|      50th percentile latency | hourly_agg |      519254 |     ms |\n|      90th percentile latency | hourly_agg |      653099 |     ms |\n|      99th percentile latency | hourly_agg |      683276 |     ms |\n|     100th percentile latency | hourly_agg |      686611 |     ms |\n| 50th percentile service time | hourly_agg |     8371.41 |     ms |\n| 90th percentile service time | hourly_agg |     8407.02 |     ms |\n| 99th percentile service time | hourly_agg |     8536.64 |     ms |\n|100th percentile service time | hourly_agg |     8538.54 |     ms |\n|                   error rate | hourly_agg |           0 |      % |\n```", "committedDate": "2020-08-24T13:04:58Z", "type": "forcePushed"}, {"oid": "7687e30291243995cffeb7d633a93bf798c29f57", "url": "https://github.com/elastic/elasticsearch/commit/7687e30291243995cffeb7d633a93bf798c29f57", "message": "Speed up date_histogram by precomputing ranges\n\nA few of us were talking about ways to speed up the `date_histogram`\nusing the index for the timestamp rather than the doc values. To do that\nwe'd have to pre-compute all of the \"round down\" points in the index. It\nturns out that *just* precomputing those values speeds up rounding\nfairly significantly:\n```\nBenchmark  (count)      (interval)                   (range)            (zone)  Mode  Cnt          Score         Error  Units\nbefore    10000000  calendar month  2000-10-28 to 2000-10-31               UTC  avgt   10   96461080.982 \u00b1  616373.011  ns/op\nbefore    10000000  calendar month  2000-10-28 to 2000-10-31  America/New_York  avgt   10  130598950.850 \u00b1 1249189.867  ns/op\nafter     10000000  calendar month  2000-10-28 to 2000-10-31               UTC  avgt   10   52311775.080 \u00b1  107171.092  ns/op\nafter     10000000  calendar month  2000-10-28 to 2000-10-31  America/New_York  avgt   10   54800134.968 \u00b1  373844.796  ns/op\n```\n\nThat's a 46% speed up when there isn't a time zone and a 58% speed up\nwhen there is.\n\nThis doesn't work for every time zone, specifically those that have two\nmidnights in a single day due to daylight savings time will produce wonky\nresults. So they don't get the optimization.\n\nSecond, this requires a few expensive computation up front to make the\ntransition array. And if the transition array is too large then we give\nup and use the original mechanism, throwing away all of the work we did\nto build the array. This seems appropriate for most usages of `round`,\nbut this change uses it for *all* usages of `round`. That seems ok for\nnow, but it might be worth investigating in a follow up.\n\nI ran a macrobenchmark as well which showed an 11% preformance\nimprovement. *BUT* the benchmark wasn't tuned for my desktop so it\noverwhelmed it and might have produced \"funny\" results. I think it is\npretty clear that this is an improvement, but know the measurement is\nweird:\n\n```\nBenchmark  (count)      (interval)                   (range)            (zone)  Mode  Cnt          Score         Error  Units\nbefore    10000000  calendar month  2000-10-28 to 2000-10-31               UTC  avgt   10   96461080.982 \u00b1  616373.011  ns/op\nbefore    10000000  calendar month  2000-10-28 to 2000-10-31  America/New_York  avgt   10  g\u00b1 1249189.867  ns/op\nafter     10000000  calendar month  2000-10-28 to 2000-10-31               UTC  avgt   10   52311775.080 \u00b1  107171.092  ns/op\nafter     10000000  calendar month  2000-10-28 to 2000-10-31  America/New_York  avgt   10   54800134.968 \u00b1  373844.796  ns/op\n\nBefore:\n|               Min Throughput | hourly_agg |        0.11 |  ops/s |\n|            Median Throughput | hourly_agg |        0.11 |  ops/s |\n|               Max Throughput | hourly_agg |        0.11 |  ops/s |\n|      50th percentile latency | hourly_agg |      650623 |     ms |\n|      90th percentile latency | hourly_agg |      821478 |     ms |\n|      99th percentile latency | hourly_agg |      859780 |     ms |\n|     100th percentile latency | hourly_agg |      864030 |     ms |\n| 50th percentile service time | hourly_agg |     9268.71 |     ms |\n| 90th percentile service time | hourly_agg |        9380 |     ms |\n| 99th percentile service time | hourly_agg |     9626.88 |     ms |\n|100th percentile service time | hourly_agg |     9884.27 |     ms |\n|                   error rate | hourly_agg |           0 |      % |\n\nAfter:\n|               Min Throughput | hourly_agg |        0.12 |  ops/s |\n|            Median Throughput | hourly_agg |        0.12 |  ops/s |\n|               Max Throughput | hourly_agg |        0.12 |  ops/s |\n|      50th percentile latency | hourly_agg |      519254 |     ms |\n|      90th percentile latency | hourly_agg |      653099 |     ms |\n|      99th percentile latency | hourly_agg |      683276 |     ms |\n|     100th percentile latency | hourly_agg |      686611 |     ms |\n| 50th percentile service time | hourly_agg |     8371.41 |     ms |\n| 90th percentile service time | hourly_agg |     8407.02 |     ms |\n| 99th percentile service time | hourly_agg |     8536.64 |     ms |\n|100th percentile service time | hourly_agg |     8538.54 |     ms |\n|                   error rate | hourly_agg |           0 |      % |\n```", "committedDate": "2020-08-24T13:04:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r475598140", "bodyText": "would it be doable to detect timezones that don't work with this optimization at runtime instead of maintaining an allowlist?", "author": "jpountz", "createdAt": "2020-08-24T13:26:51Z", "path": "server/src/main/java/org/elasticsearch/common/Rounding.java", "diffHunk": "@@ -401,8 +404,22 @@ private LocalDateTime truncateLocalDateTime(LocalDateTime localDateTime) {\n             }\n         }\n \n+        /**\n+         * Time zones with two midnights get \"funny\" non-continuous rounding\n+         * that isn't compatible with the pre-computed array rounding.\n+         */\n+        private static final Set<String> HAS_TWO_MIDNIGHTS = Set.of(\"America/Moncton\", \"America/St_Johns\", \"Canada/Newfoundland\");", "originalCommit": "7687e30291243995cffeb7d633a93bf798c29f57", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTYwMTkyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r475601921", "bodyText": "I can't think of a way to do right now. At least, not a good way.", "author": "nik9000", "createdAt": "2020-08-24T13:32:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzU3OTc5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r477579791", "bodyText": "I thought Canada was changing time at 2 am, on another side, some other known time zones such as Asia/Gaza for example seems to indeed have 2 mightnights. I did some quick and dirty test and I have got a slightly different list for timezones in my JVM:\nAmerica/Asuncion 2020-03-22T00:00 -> 2020-03-21T23:00\nAmerica/Havana 2020-11-01T01:00 -> 2020-11-01T00:00\nAmerica/Santiago 2020-04-05T00:00 -> 2020-04-04T23:00\nAmerica/Scoresbysund 2020-10-25T01:00 -> 2020-10-25T00:00\nAsia/Amman 2020-10-30T01:00 -> 2020-10-30T00:00\nAsia/Beirut 2020-10-25T00:00 -> 2020-10-24T23:00\nAsia/Damascus 2020-10-30T00:00 -> 2020-10-29T23:00\nAsia/Gaza 2020-10-31T01:00 -> 2020-10-31T00:00\nAsia/Hebron 2020-10-31T01:00 -> 2020-10-31T00:00\nAsia/Tehran 2020-09-21T00:00 -> 2020-09-20T23:00\nAtlantic/Azores 2020-10-25T01:00 -> 2020-10-25T00:00\nChile/Continental 2020-04-05T00:00 -> 2020-04-04T23:00\nCuba 2020-11-01T01:00 -> 2020-11-01T00:00\nIran 2020-09-21T00:00 -> 2020-09-20T23:00", "author": "imotov", "createdAt": "2020-08-26T20:47:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzU4MjkwNA==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r477582904", "bodyText": "Very nice!", "author": "nik9000", "createdAt": "2020-08-26T20:54:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzYwMDk5Mw==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r477600993", "bodyText": "Is this really only a problem when there are two midnights, or is it a more general problem when the time goes back due to daylight savings, and you just need special values of offset to make the bug occur if the transition is not around midnight?", "author": "jpountz", "createdAt": "2020-08-26T21:30:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzY2NDgyOA==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r477664828", "bodyText": "@nik9000 please correct me if I am wrong, but the way I understand it, it is the way we truncate it to midnight that is causing the issues, I played with it a bit more and it looks like atStartOfDay will truncate 2020-03-22T00:00 to 22nd, but it will truncate the moment after it to 21st, which can cause all sorts of issues. For example:\n        // America/Asuncion 2020-03-22T00:00 -> 2020-03-21T23:00\n        TimeZone tz = TimeZone.getTimeZone(\"America/Asuncion\");\n        ZoneRules rules = tz.toZoneId().getRules();\n        ZoneOffsetTransitionRule fallback = rules.getTransitionRules().get(0);\n        ZoneOffsetTransition transition = fallback.createTransition(2020);\n        System.out.println(\"Before: \" + transition.getDateTimeBefore().toLocalDate().atStartOfDay());\n        System.out.println(\"After:  \" + transition.getDateTimeAfter().toLocalDate().atStartOfDay());\n\nwill give us\nBefore: 2020-03-22T00:00\nAfter:  2020-03-21T00:00\n\nThe same thing for America/New_York will return\nBefore: 2020-03-08T00:00\nAfter:  2020-03-08T00:00", "author": "imotov", "createdAt": "2020-08-26T23:22:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzY4NzY4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r477687689", "bodyText": "the way I understand it, it is the way we truncate it to midnight that is causing the issues, I played with it a bit more and it looks like atStartOfDay will truncate 2020-03-22T00:00 to 22nd, but it will truncate the moment after it to 21st, which can cause all sorts of issues.\n\nThis is pretty much what I saw, yes. In the one time zone I dug into deeply I saw a single instant gets rounded a day ahead of all of the instants around it. Its weird but it is what we have. If we didn't do that then we could use the array based rounding everywhere.\nI'll dig more tomorrow into your examples. The ones I found I did by randomized testing and the one that I dug into deeply was a problem with having two midnights. I should be able to answer much more precisely what the problem is when I have a closer look.\n\nIs this really only a problem when there are two midnights, or is it a more general problem when the time goes back due to daylight savings, and you just need special values of offset to make the bug occur if the transition is not around midnight?\n\noffset is pretty much incompatible with daylight savings time. At least, it doesn't work as advertised. See #56305 for some investigation.", "author": "nik9000", "createdAt": "2020-08-26T23:39:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2NzI5NQ==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r478667295", "bodyText": "Ok! I think it isn't that they have two midnights, it is that transitioned a minute after midnight:\nTransition[Gap at 2006-04-02T00:01-03:30 to -02:30]\n\nThis causes rounding to output:\n1162088880000  1162002600000\n1162088940000  1162002600000\n1162089000000  1162089000000   <---- This minute is in \"tomorrow\"\n1162089060000  1162002600000   <----- But this minute is in \"yesterday\"!\n1162089120000  1162002600000\n1162089180000  1162002600000\n1162089240000  1162002600000\n1162089300000  1162002600000\n\nIt is this kind of \"forwards and backwards\" dance that my simple array based rounding can't handle. I'll see if I can detect it.", "author": "nik9000", "createdAt": "2020-08-27T20:09:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY4OTU0MA==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r478689540", "bodyText": "Even if offsets are not working as advertised with DST, I worry that they would behave differently again with this optimization. It would be safer to disable this optimization whenever there are transitions that make the time go backwards in the local time in the time range of the index?", "author": "jpountz", "createdAt": "2020-08-27T20:54:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDE4MjUzOA==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r480182538", "bodyText": "I've pushed a change that disables the optimization if the range falls in one of the times when DST drags you back to \"yesterday\". And I've pushed a test that checks those times.\nAs it stands now, I don't think the offset feature of date rounding will effect this optimization.", "author": "nik9000", "createdAt": "2020-08-31T14:49:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzA2MTE5Ng==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r483061196", "bodyText": "I've played with offset to double check and can't cause issues with it. However do you think we could detect timezones that don't work dynamically instead of relying on a static list? E.g. could we iterate transitions in the considered interval and check whether there's one that brings us to a different day?", "author": "jpountz", "createdAt": "2020-09-03T15:21:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzA3MjMzNw==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r483072337", "bodyText": "We could use something like the test case uses to find candidates, but it'd require loading all of the time zone rules on startup. I'm hoping that the test can prevent us from having to do that by being very careful about this list.", "author": "nik9000", "createdAt": "2020-09-03T15:36:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzk0ODYwMg==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r487948602", "bodyText": "Actually I wasn't thinking about testing all timezones up-front on startup, I was more thinking of doing the test when building the Rounding object by only looking at transitions of the considered timezone.", "author": "jpountz", "createdAt": "2020-09-14T14:03:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Nzk1MzEyNA==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r487953124", "bodyText": "Hmmmm - the assert that I have below sort of asserts that. But it isn't nearly as strong. I'll think about it!", "author": "nik9000", "createdAt": "2020-09-14T14:07:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODEyMjg3NA==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r488122874", "bodyText": "@jpountz I've pushed a change that does this.", "author": "nik9000", "createdAt": "2020-09-14T18:02:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODE0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODk2OQ==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r475598969", "bodyText": "is this change fixing an existing bug?", "author": "jpountz", "createdAt": "2020-08-24T13:28:17Z", "path": "server/src/main/java/org/elasticsearch/common/Rounding.java", "diffHunk": "@@ -1015,7 +1031,7 @@ public byte id() {\n \n         @Override\n         public Prepared prepare(long minUtcMillis, long maxUtcMillis) {\n-            return wrapPreparedRounding(delegate.prepare(minUtcMillis, maxUtcMillis));\n+            return wrapPreparedRounding(delegate.prepare(minUtcMillis - offset, maxUtcMillis - offset));", "originalCommit": "7687e30291243995cffeb7d633a93bf798c29f57", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTYwMTk2Nw==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r475601967", "bodyText": "Yes, but I think the bug is worse with this change.", "author": "nik9000", "createdAt": "2020-08-24T13:32:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODk2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTY0OTMxOA==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r475649318", "bodyText": "The new assertions in the ArrayRounding fail without this.", "author": "nik9000", "createdAt": "2020-08-24T14:22:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTU5ODk2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTYwMDA1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r475600053", "bodyText": "make it final?", "author": "jpountz", "createdAt": "2020-08-24T13:29:55Z", "path": "server/src/main/java/org/elasticsearch/common/Rounding.java", "diffHunk": "@@ -1085,4 +1101,54 @@ public static Rounding read(StreamInput in) throws IOException {\n                 throw new ElasticsearchException(\"unknown rounding id [\" + id + \"]\");\n         }\n     }\n+\n+    /**\n+     * Attempt to build a {@link Prepared} implementation that relies on pre-calcuated\n+     * \"round down\" points. If there would be more than {@code max} points then return\n+     * the original implementation, otherwise return the new, faster implementation.\n+     */\n+    static Prepared maybeUseArray(Prepared orig, long minUtcMillis, long maxUtcMillis, int max) {\n+        long[] values = new long[1];\n+        long rounded = orig.round(minUtcMillis);\n+        int i = 0;\n+        values[i++] = rounded;\n+        while ((rounded = orig.nextRoundingValue(rounded)) <= maxUtcMillis) {\n+            if (i >= max) {\n+                return orig;\n+            }\n+            assert values[i - 1] == orig.round(rounded - 1);\n+            values = ArrayUtil.grow(values, i + 1);\n+            values[i++]= rounded;\n+        }\n+        return new ArrayRounding(values, i, orig);\n+    }\n+\n+    /**\n+     * Implementation of {@link Prepared} using pre-calculated \"round down\" points.\n+     */\n+    private static class ArrayRounding implements Prepared {\n+        private final long[] values;\n+        private int max;", "originalCommit": "7687e30291243995cffeb7d633a93bf798c29f57", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTYwMjQyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r475602421", "bodyText": "\ud83d\udc4d. I have no idea why I didn't do that the first time around.", "author": "nik9000", "createdAt": "2020-08-24T13:33:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTYwMDA1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTYwMDIwNQ==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r475600205", "bodyText": "maybe assert that idx is neither -1 nor -1 - max?", "author": "jpountz", "createdAt": "2020-08-24T13:30:11Z", "path": "server/src/main/java/org/elasticsearch/common/Rounding.java", "diffHunk": "@@ -1085,4 +1101,54 @@ public static Rounding read(StreamInput in) throws IOException {\n                 throw new ElasticsearchException(\"unknown rounding id [\" + id + \"]\");\n         }\n     }\n+\n+    /**\n+     * Attempt to build a {@link Prepared} implementation that relies on pre-calcuated\n+     * \"round down\" points. If there would be more than {@code max} points then return\n+     * the original implementation, otherwise return the new, faster implementation.\n+     */\n+    static Prepared maybeUseArray(Prepared orig, long minUtcMillis, long maxUtcMillis, int max) {\n+        long[] values = new long[1];\n+        long rounded = orig.round(minUtcMillis);\n+        int i = 0;\n+        values[i++] = rounded;\n+        while ((rounded = orig.nextRoundingValue(rounded)) <= maxUtcMillis) {\n+            if (i >= max) {\n+                return orig;\n+            }\n+            assert values[i - 1] == orig.round(rounded - 1);\n+            values = ArrayUtil.grow(values, i + 1);\n+            values[i++]= rounded;\n+        }\n+        return new ArrayRounding(values, i, orig);\n+    }\n+\n+    /**\n+     * Implementation of {@link Prepared} using pre-calculated \"round down\" points.\n+     */\n+    private static class ArrayRounding implements Prepared {\n+        private final long[] values;\n+        private int max;\n+        private final Prepared delegate;\n+\n+        private ArrayRounding(long[] values, int max, Prepared delegate) {\n+            this.values = values;\n+            this.max = max;\n+            this.delegate = delegate;\n+        }\n+\n+        @Override\n+        public long round(long utcMillis) {\n+            int idx = Arrays.binarySearch(values, 0, max, utcMillis);\n+            if (idx < 0) {", "originalCommit": "7687e30291243995cffeb7d633a93bf798c29f57", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTYwNTYwMg==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r475605602", "bodyText": "Sure!", "author": "nik9000", "createdAt": "2020-08-24T13:37:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTYwMDIwNQ=="}], "type": "inlineReview"}, {"oid": "e68463de6718e51ad5f37692b97877f146cda60b", "url": "https://github.com/elastic/elasticsearch/commit/e68463de6718e51ad5f37692b97877f146cda60b", "message": "iter", "committedDate": "2020-08-24T13:44:17Z", "type": "commit"}, {"oid": "c13740b5d975d2e19a1521f4fdd6d9de754ee9d1", "url": "https://github.com/elastic/elasticsearch/commit/c13740b5d975d2e19a1521f4fdd6d9de754ee9d1", "message": "Another test", "committedDate": "2020-08-24T14:23:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzU4MDk4Mg==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r477580982", "bodyText": "This will need to implement new methods added in #61369.", "author": "imotov", "createdAt": "2020-08-26T20:50:03Z", "path": "server/src/main/java/org/elasticsearch/common/Rounding.java", "diffHunk": "@@ -1085,4 +1101,57 @@ public static Rounding read(StreamInput in) throws IOException {\n                 throw new ElasticsearchException(\"unknown rounding id [\" + id + \"]\");\n         }\n     }\n+\n+    /**\n+     * Attempt to build a {@link Prepared} implementation that relies on pre-calcuated\n+     * \"round down\" points. If there would be more than {@code max} points then return\n+     * the original implementation, otherwise return the new, faster implementation.\n+     */\n+    static Prepared maybeUseArray(Prepared orig, long minUtcMillis, long maxUtcMillis, int max) {\n+        long[] values = new long[1];\n+        long rounded = orig.round(minUtcMillis);\n+        int i = 0;\n+        values[i++] = rounded;\n+        while ((rounded = orig.nextRoundingValue(rounded)) <= maxUtcMillis) {\n+            if (i >= max) {\n+                return orig;\n+            }\n+            assert values[i - 1] == orig.round(rounded - 1);\n+            values = ArrayUtil.grow(values, i + 1);\n+            values[i++]= rounded;\n+        }\n+        return new ArrayRounding(values, i, orig);\n+    }\n+\n+    /**\n+     * Implementation of {@link Prepared} using pre-calculated \"round down\" points.\n+     */\n+    private static class ArrayRounding implements Prepared {", "originalCommit": "c13740b5d975d2e19a1521f4fdd6d9de754ee9d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "4162ef1bcb55987e0127b2c839a0c937959842f1", "url": "https://github.com/elastic/elasticsearch/commit/4162ef1bcb55987e0127b2c839a0c937959842f1", "message": "Merge branch 'master' into binary_search_for_rounding", "committedDate": "2020-08-27T13:04:46Z", "type": "commit"}, {"oid": "02f0fe3b032c89f896118de6150d23ece8e91eab", "url": "https://github.com/elastic/elasticsearch/commit/02f0fe3b032c89f896118de6150d23ece8e91eab", "message": "Implement new method", "committedDate": "2020-08-27T14:10:00Z", "type": "commit"}, {"oid": "4fbcfbf0ae707e70536d9796aaa65ac6035f7a6f", "url": "https://github.com/elastic/elasticsearch/commit/4fbcfbf0ae707e70536d9796aaa65ac6035f7a6f", "message": "Skip method for bad times", "committedDate": "2020-08-31T14:47:06Z", "type": "commit"}, {"oid": "7a7ef49a6b0a65dcb8f86996401f5885883be745", "url": "https://github.com/elastic/elasticsearch/commit/7a7ef49a6b0a65dcb8f86996401f5885883be745", "message": "Merge branch 'master' into binary_search_for_rounding", "committedDate": "2020-09-01T15:13:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjIyMDQxNA==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r482220414", "bodyText": "Nit - It looks like this maps timezone name to milliseconds since epoch for when the zone changed to use a different transition time.  Can you just add a comment clarifying that's how the map is structured?  It seems unlikely we'd need to add to it, but just in case we do, it'd help to have a reference for how to do so handy.", "author": "not-napoleon", "createdAt": "2020-09-02T16:55:27Z", "path": "server/src/main/java/org/elasticsearch/common/Rounding.java", "diffHunk": "@@ -467,8 +470,33 @@ private LocalDateTime truncateLocalDateTime(LocalDateTime localDateTime) {\n             }\n         }\n \n+        /**\n+         * Time zones have a daylight savings time transition after midnight that\n+         * transitions back before midnight break the array-based rounding so\n+         * we don't use it for them during those transitions. Luckily they are\n+         * fairly rare and a while in the past. Note: we can use the array based\n+         * rounding if the transition is <strong>at</strong> midnight. Just not\n+         * if it is <strong>after</strong> it.\n+         */\n+        private static final Map<String, Long> FORWARDS_BACKWRADS_ZONES = Map.ofEntries(", "originalCommit": "7a7ef49a6b0a65dcb8f86996401f5885883be745", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzkwNzYxOA==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r487907618", "bodyText": "\ud83d\udc4d", "author": "nik9000", "createdAt": "2020-09-14T13:22:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjIyMDQxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjI0MjcyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r482242721", "bodyText": "It's not super clear to me what this assert is guarding against.  Can you add a comment please?", "author": "not-napoleon", "createdAt": "2020-09-02T17:26:20Z", "path": "server/src/main/java/org/elasticsearch/common/Rounding.java", "diffHunk": "@@ -1186,4 +1213,62 @@ public static Rounding read(StreamInput in) throws IOException {\n                 throw new ElasticsearchException(\"unknown rounding id [\" + id + \"]\");\n         }\n     }\n+\n+    /**\n+     * Attempt to build a {@link Prepared} implementation that relies on pre-calcuated\n+     * \"round down\" points. If there would be more than {@code max} points then return\n+     * the original implementation, otherwise return the new, faster implementation.\n+     */\n+    static Prepared maybeUseArray(Prepared orig, long minUtcMillis, long maxUtcMillis, int max) {\n+        long[] values = new long[1];\n+        long rounded = orig.round(minUtcMillis);\n+        int i = 0;\n+        values[i++] = rounded;\n+        while ((rounded = orig.nextRoundingValue(rounded)) <= maxUtcMillis) {\n+            if (i >= max) {\n+                return orig;\n+            }\n+            assert values[i - 1] == orig.round(rounded - 1);", "originalCommit": "7a7ef49a6b0a65dcb8f86996401f5885883be745", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzkwNzY3Mg==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r487907672", "bodyText": "\ud83d\udc4d", "author": "nik9000", "createdAt": "2020-09-14T13:22:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjI0MjcyMQ=="}], "type": "inlineReview"}, {"oid": "4f23de0f7431c34754f56f87f73edfed53ea12a9", "url": "https://github.com/elastic/elasticsearch/commit/4f23de0f7431c34754f56f87f73edfed53ea12a9", "message": "Merge branch 'master' into binary_search_for_rounding", "committedDate": "2020-09-14T13:25:01Z", "type": "commit"}, {"oid": "178a1586527a2f208189fc11a904c1f27c8ee3de", "url": "https://github.com/elastic/elasticsearch/commit/178a1586527a2f208189fc11a904c1f27c8ee3de", "message": "comments", "committedDate": "2020-09-14T13:36:52Z", "type": "commit"}, {"oid": "f201a25ba7be7f2dace68730a1e2abb8458d79c3", "url": "https://github.com/elastic/elasticsearch/commit/f201a25ba7be7f2dace68730a1e2abb8458d79c3", "message": "Detect!", "committedDate": "2020-09-14T16:00:21Z", "type": "commit"}, {"oid": "0e937293300f2c2796e1cf486350f6859d110464", "url": "https://github.com/elastic/elasticsearch/commit/0e937293300f2c2796e1cf486350f6859d110464", "message": "Test update", "committedDate": "2020-09-14T17:50:12Z", "type": "commit"}, {"oid": "35ef1c4e6f8757dcde5f47ba19678d9a9cd9a493", "url": "https://github.com/elastic/elasticsearch/commit/35ef1c4e6f8757dcde5f47ba19678d9a9cd9a493", "message": "Comment on number", "committedDate": "2020-09-14T18:07:00Z", "type": "commit"}, {"oid": "f1e286ebba0ce02bb37d3ee4ef8696852e6aec7b", "url": "https://github.com/elastic/elasticsearch/commit/f1e286ebba0ce02bb37d3ee4ef8696852e6aec7b", "message": "Only 12+", "committedDate": "2020-09-15T17:57:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgyNDIzNw==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r488824237", "bodyText": "This test fails in CI but not for me locally! I'm looking into it. Might be the specific JVM or something.", "author": "nik9000", "createdAt": "2020-09-15T17:05:08Z", "path": "server/src/test/java/org/elasticsearch/common/LocalTimeOffsetTests.java", "diffHunk": "@@ -241,6 +246,25 @@ public void testGap() {\n         assertThat(gapOffset.localToUtc(localSkippedTime, useValueForGap(gapValue)), equalTo(gapValue));\n     }\n \n+    public void testKnownMovesBackToPreviousDay() {\n+        assertKnownMovesBacktoPreviousDay(\"America/Goose_Bay\", \"2010-11-07T03:01:00\");\n+        assertKnownMovesBacktoPreviousDay(\"America/Moncton\", \"2006-10-29T03:01:00\");\n+        assertKnownMovesBacktoPreviousDay(\"America/Moncton\", \"2005-10-29T03:01:00\");\n+        assertKnownMovesBacktoPreviousDay(\"America/St_Johns\", \"2010-11-07T02:31:00\");\n+        assertKnownMovesBacktoPreviousDay(\"Canada/Newfoundland\", \"2010-11-07T02:31:00\");\n+        assertKnownMovesBacktoPreviousDay(\"Pacific/Guam\", \"1969-01-25T13:01:00\");", "originalCommit": "35ef1c4e6f8757dcde5f47ba19678d9a9cd9a493", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODg3OTI2OA==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r488879268", "bodyText": "As far as I understand this list constantly changes, so it might be different between versions of JVM and OSes.", "author": "imotov", "createdAt": "2020-09-15T18:32:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgyNDIzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODk1MzYxOA==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r488953618", "bodyText": "I had sort of thought the past was relatively well established, but it looks like it is a Java 12+ thing....", "author": "nik9000", "createdAt": "2020-09-15T20:28:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgyNDIzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg1NzU0NA==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r493857544", "bodyText": "should we check getHour() too for safety? Eg. if such a thing existed as moving from 1AM to 11PM the day before it looks like we'd still consider that the transition doesn't move back to the previous day with this code?", "author": "jpountz", "createdAt": "2020-09-23T19:55:14Z", "path": "server/src/main/java/org/elasticsearch/common/LocalTimeOffset.java", "diffHunk": "@@ -505,7 +558,25 @@ protected static Transition buildTransition(ZoneOffsetTransition transition, Loc\n             }\n             long firstOverlappingLocalTime = utcStart + offsetAfterMillis;\n             long firstNonOverlappingLocalTime = utcStart + offsetBeforeMillis;\n-            return new Overlap(offsetAfterMillis, previous, utcStart, firstOverlappingLocalTime, firstNonOverlappingLocalTime);\n+            return new Overlap(\n+                offsetAfterMillis,\n+                previous,\n+                utcStart,\n+                firstOverlappingLocalTime,\n+                firstNonOverlappingLocalTime,\n+                movesBackToPreviousDay(transition)\n+            );\n+        }\n+\n+        private static boolean movesBackToPreviousDay(ZoneOffsetTransition transition) {\n+            if (transition.getDateTimeBefore().getDayOfMonth() == transition.getDateTimeAfter().getDayOfMonth()) {\n+                return false;\n+            }\n+            if (transition.getDateTimeBefore().getMinute() == 0) {", "originalCommit": "f1e286ebba0ce02bb37d3ee4ef8696852e6aec7b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDI3OTUxNQ==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r494279515", "bodyText": "Yeah!", "author": "nik9000", "createdAt": "2020-09-24T12:35:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg1NzU0NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDI4NTMyOQ==", "url": "https://github.com/elastic/elasticsearch/pull/61467#discussion_r494285329", "bodyText": "I pushed a change that makes sure the \"NANO_OF_DAY\" is 0. That seems fairly good at covering it", "author": "nik9000", "createdAt": "2020-09-24T12:42:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg1NzU0NA=="}], "type": "inlineReview"}, {"oid": "d2f1d2321bb6ac1f0f0819ba126b0b115bc60e98", "url": "https://github.com/elastic/elasticsearch/commit/d2f1d2321bb6ac1f0f0819ba126b0b115bc60e98", "message": "Merge branch 'master' into binary_search_for_rounding", "committedDate": "2020-09-24T12:35:25Z", "type": "commit"}, {"oid": "2281d351f748d7b5030deeb04355f32616c444ed", "url": "https://github.com/elastic/elasticsearch/commit/2281d351f748d7b5030deeb04355f32616c444ed", "message": "Nano of day!", "committedDate": "2020-09-24T12:42:36Z", "type": "commit"}]}