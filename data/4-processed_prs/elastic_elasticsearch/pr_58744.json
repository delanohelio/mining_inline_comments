{"pr_number": 58744, "pr_title": "[Transform] separate pivot and extract function interface", "pr_createdAt": "2020-06-30T13:12:06Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/58744", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg4ODA3OA==", "url": "https://github.com/elastic/elasticsearch/pull/58744#discussion_r447888078", "bodyText": "It seems here we are effectively switching on a class type. Why can't we take advantage of polymorphism?", "author": "benwtrent", "createdAt": "2020-06-30T18:18:10Z", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/Pivot.java", "diffHunk": "@@ -147,33 +205,58 @@ public SearchRequest buildSearchRequest(SourceConfig sourceConfig, Map<String, O\n         return searchRequest;\n     }\n \n-    public AggregationBuilder buildAggregation(Map<String, Object> position, int pageSize) {\n+    @Override\n+    public SearchSourceBuilder buildSearchQuery(SearchSourceBuilder builder, Map<String, Object> position, int pageSize) {\n         cachedCompositeAggregation.aggregateAfter(position);\n         cachedCompositeAggregation.size(pageSize);\n \n-        return cachedCompositeAggregation;\n+        return builder.size(0).aggregation(cachedCompositeAggregation);\n     }\n \n-    public CompositeAggregationBuilder buildIncrementalBucketUpdateAggregation(int pageSize) {\n+    @Override\n+    public ChangeCollector buildChangeCollector(String synchronizationField) {\n+        Map<String, FieldCollector> fieldCollectors = new HashMap<>();\n \n-        CompositeAggregationBuilder compositeAgg = createCompositeAggregationSources(config, true);\n-        compositeAgg.size(pageSize);\n-\n-        return compositeAgg;\n-    }\n-\n-    public Map<String, Set<String>> initialIncrementalBucketUpdateMap() {\n-\n-        Map<String, Set<String>> changedBuckets = new HashMap<>();\n         for (Entry<String, SingleGroupSource> entry : config.getGroupConfig().getGroups().entrySet()) {\n-            if (entry.getValue().supportsIncrementalBucketUpdate()) {\n-                changedBuckets.put(entry.getKey(), new HashSet<>());\n+            switch (entry.getValue().getType()) {", "originalCommit": "3216d52deab945391d315cde160c28145192d25b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODE2MDkwOA==", "url": "https://github.com/elastic/elasticsearch/pull/58744#discussion_r448160908", "bodyText": "agree, this part disturbs me, too. Its error-prone, when adding a new group source, this can be easily forgotten and you won't realize until you use it in continuous mode.", "author": "hendrikmuhs", "createdAt": "2020-07-01T07:11:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg4ODA3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5MTEwMA==", "url": "https://github.com/elastic/elasticsearch/pull/58744#discussion_r447891100", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            public class FunctionFactory {\n          \n          \n            \n            public final class FunctionFactory {", "author": "benwtrent", "createdAt": "2020-06-30T18:23:21Z", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/FunctionFactory.java", "diffHunk": "@@ -0,0 +1,30 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms;\n+\n+import org.elasticsearch.xpack.core.transform.transforms.TransformConfig;\n+import org.elasticsearch.xpack.transform.transforms.pivot.Pivot;\n+\n+/**\n+ * Factory for creating the runtime instance for a function given the configuration\n+ */\n+public class FunctionFactory {", "originalCommit": "3216d52deab945391d315cde160c28145192d25b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODI5NDIxOA==", "url": "https://github.com/elastic/elasticsearch/pull/58744#discussion_r448294218", "bodyText": "Add a private ctor if all the methods are static", "author": "davidkyle", "createdAt": "2020-07-01T11:18:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzg5MTEwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDM5MjEzNw==", "url": "https://github.com/elastic/elasticsearch/pull/58744#discussion_r450392137", "bodyText": "I don't know what we are gaining by not having SingleGroupSource have a createFieldCollector method. We would avoid this switch statement.\nAre we just trying to keep from adding classes to core?", "author": "benwtrent", "createdAt": "2020-07-06T18:02:57Z", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/transforms/pivot/CompositeBucketsChangeCollector.java", "diffHunk": "@@ -0,0 +1,350 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.transform.transforms.pivot;\n+\n+import org.elasticsearch.action.search.SearchResponse;\n+import org.elasticsearch.common.Rounding;\n+import org.elasticsearch.common.geo.GeoPoint;\n+import org.elasticsearch.geometry.Rectangle;\n+import org.elasticsearch.index.query.BoolQueryBuilder;\n+import org.elasticsearch.index.query.GeoBoundingBoxQueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilder;\n+import org.elasticsearch.index.query.QueryBuilders;\n+import org.elasticsearch.index.query.RangeQueryBuilder;\n+import org.elasticsearch.index.query.TermsQueryBuilder;\n+import org.elasticsearch.search.aggregations.AggregationBuilder;\n+import org.elasticsearch.search.aggregations.Aggregations;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregation.Bucket;\n+import org.elasticsearch.search.aggregations.bucket.composite.CompositeAggregationBuilder;\n+import org.elasticsearch.search.aggregations.bucket.geogrid.GeoTileUtils;\n+import org.elasticsearch.search.builder.SearchSourceBuilder;\n+import org.elasticsearch.xpack.core.transform.transforms.pivot.DateHistogramGroupSource;\n+import org.elasticsearch.xpack.core.transform.transforms.pivot.SingleGroupSource;\n+import org.elasticsearch.xpack.transform.transforms.Function.ChangeCollector;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Set;\n+\n+/**\n+ * Utility class to collect bucket changes\n+ */\n+public class CompositeBucketsChangeCollector implements ChangeCollector {\n+\n+    private final Map<String, FieldCollector> fieldCollectors;\n+    private final CompositeAggregationBuilder compositeAggregation;\n+    private Map<String, Object> afterKey = null;\n+\n+    interface FieldCollector {\n+        boolean collectChanges(Collection<? extends Bucket> buckets);\n+\n+        AggregationBuilder aggregateChanges();\n+\n+        QueryBuilder filterByChanges(long lastCheckpointTimestamp, long nextcheckpointTimestamp);\n+\n+        void clear();\n+    }\n+\n+    static class TermsFieldCollector implements FieldCollector {\n+\n+        private final String sourceFieldName;\n+        private final String targetFieldName;\n+        private final Set<String> changedTerms;\n+\n+        public TermsFieldCollector(final String sourceFieldName, final String targetFieldName) {\n+            this.sourceFieldName = sourceFieldName;\n+            this.targetFieldName = targetFieldName;\n+            this.changedTerms = new HashSet<>();\n+        }\n+\n+        @Override\n+        public boolean collectChanges(Collection<? extends Bucket> buckets) {\n+            changedTerms.clear();\n+\n+            for (Bucket b : buckets) {\n+                Object term = b.getKey().get(targetFieldName);\n+                if (term != null) {\n+                    changedTerms.add(term.toString());\n+                }\n+            }\n+\n+            return true;\n+        }\n+\n+        @Override\n+        public QueryBuilder filterByChanges(long lastCheckpointTimestamp, long nextcheckpointTimestamp) {\n+            if (changedTerms.isEmpty() == false) {\n+                return new TermsQueryBuilder(sourceFieldName, changedTerms);\n+            }\n+            return null;\n+        }\n+\n+        @Override\n+        public void clear() {\n+            changedTerms.clear();\n+        }\n+\n+        @Override\n+        public AggregationBuilder aggregateChanges() {\n+            return null;\n+        }\n+    }\n+\n+    static class DateHistogramFieldCollector implements FieldCollector {\n+\n+        private final String sourceFieldName;\n+        private final String targetFieldName;\n+        private final boolean isSynchronizationField;\n+        private final Rounding.Prepared rounding;\n+\n+        public DateHistogramFieldCollector(\n+            final String sourceFieldName,\n+            final String targetFieldName,\n+            final Rounding.Prepared rounding,\n+            final boolean isSynchronizationField\n+        ) {\n+            this.sourceFieldName = sourceFieldName;\n+            this.targetFieldName = targetFieldName;\n+            this.rounding = rounding;\n+            this.isSynchronizationField = isSynchronizationField;\n+        }\n+\n+        @Override\n+        public boolean collectChanges(Collection<? extends Bucket> buckets) {\n+            // todo: implementation for isSynchronizationField == false\n+            return false;\n+        }\n+\n+        @Override\n+        public QueryBuilder filterByChanges(long lastCheckpointTimestamp, long nextcheckpointTimestamp) {\n+            if (isSynchronizationField && lastCheckpointTimestamp > 0) {\n+                return new RangeQueryBuilder(sourceFieldName).gte(rounding.round(lastCheckpointTimestamp)).format(\"epoch_millis\");\n+            }\n+\n+            // todo: implementation for isSynchronizationField == false\n+\n+            return null;\n+        }\n+\n+        @Override\n+        public void clear() {}\n+\n+        @Override\n+        public AggregationBuilder aggregateChanges() {\n+            return null;\n+        }\n+\n+    }\n+\n+    static class HistogramFieldCollector implements FieldCollector {\n+\n+        private final String sourceFieldName;\n+        private final String targetFieldName;\n+\n+        public HistogramFieldCollector(final String sourceFieldName, final String targetFieldName) {\n+            this.sourceFieldName = sourceFieldName;\n+            this.targetFieldName = targetFieldName;\n+        }\n+\n+        @Override\n+        public boolean collectChanges(Collection<? extends Bucket> buckets) {\n+            return false;\n+        }\n+\n+        @Override\n+        public QueryBuilder filterByChanges(long lastCheckpointTimestamp, long nextcheckpointTimestamp) {\n+            return null;\n+        }\n+\n+        @Override\n+        public void clear() {}\n+\n+        @Override\n+        public AggregationBuilder aggregateChanges() {\n+            return null;\n+        }\n+    }\n+\n+    static class GeoTileFieldCollector implements FieldCollector {\n+\n+        private final String sourceFieldName;\n+        private final String targetFieldName;\n+        private final Set<String> changedBuckets;\n+\n+        public GeoTileFieldCollector(final String sourceFieldName, final String targetFieldName) {\n+            this.sourceFieldName = sourceFieldName;\n+            this.targetFieldName = targetFieldName;\n+            this.changedBuckets = new HashSet<>();\n+        }\n+\n+        @Override\n+        public boolean collectChanges(Collection<? extends Bucket> buckets) {\n+            changedBuckets.clear();\n+\n+            for (Bucket b : buckets) {\n+                Object bucket = b.getKey().get(targetFieldName);\n+                if (bucket != null) {\n+                    changedBuckets.add(bucket.toString());\n+                }\n+            }\n+\n+            return true;\n+        }\n+\n+        @Override\n+        public QueryBuilder filterByChanges(long lastCheckpointTimestamp, long nextcheckpointTimestamp) {\n+            // todo: this limited by indices.query.bool.max_clause_count, default 1024 which is lower than the maximum page size\n+            if (changedBuckets != null && changedBuckets.isEmpty() == false) {\n+                BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();\n+                changedBuckets.stream().map(GeoTileUtils::toBoundingBox).map(this::toGeoQuery).forEach(boolQueryBuilder::should);\n+                return boolQueryBuilder;\n+            }\n+            return null;\n+        }\n+\n+        @Override\n+        public void clear() {}\n+\n+        @Override\n+        public AggregationBuilder aggregateChanges() {\n+            return null;\n+        }\n+\n+        private GeoBoundingBoxQueryBuilder toGeoQuery(Rectangle rectangle) {\n+            return QueryBuilders.geoBoundingBoxQuery(sourceFieldName)\n+                .setCorners(\n+                    new GeoPoint(rectangle.getMaxLat(), rectangle.getMinLon()),\n+                    new GeoPoint(rectangle.getMinLat(), rectangle.getMaxLon())\n+                );\n+        }\n+    }\n+\n+    public CompositeBucketsChangeCollector(CompositeAggregationBuilder compositeAggregation, Map<String, FieldCollector> fieldCollectors) {\n+        this.compositeAggregation = compositeAggregation;\n+        this.fieldCollectors = fieldCollectors;\n+    }\n+\n+    @Override\n+    public boolean processSearchResponse(final SearchResponse searchResponse) {\n+        final Aggregations aggregations = searchResponse.getAggregations();\n+        if (aggregations == null) {\n+            return true;\n+        }\n+\n+        final CompositeAggregation agg = aggregations.get(compositeAggregation.getName());\n+\n+        Collection<? extends Bucket> buckets = agg.getBuckets();\n+        afterKey = agg.afterKey();\n+\n+        if (buckets.isEmpty()) {\n+            return true;\n+        }\n+\n+        for (FieldCollector fieldCollector : fieldCollectors.values()) {\n+            fieldCollector.collectChanges(buckets);\n+        }\n+\n+        return false;\n+    }\n+\n+    @Override\n+    public QueryBuilder buildFilterQuery(long lastCheckpointTimestamp, long nextcheckpointTimestamp) {\n+        BoolQueryBuilder filteredQuery = new BoolQueryBuilder();\n+\n+        for (FieldCollector fieldCollector : fieldCollectors.values()) {\n+            QueryBuilder filter = fieldCollector.filterByChanges(lastCheckpointTimestamp, nextcheckpointTimestamp);\n+            if (filter != null) {\n+                filteredQuery.filter(filter);\n+            }\n+        }\n+\n+        return filteredQuery;\n+    }\n+\n+    @Override\n+    public SearchSourceBuilder buildChangesQuery(SearchSourceBuilder sourceBuilder, Map<String, Object> position, int pageSize) {\n+\n+        CompositeAggregationBuilder changesAgg = this.compositeAggregation;\n+        changesAgg.size(pageSize).aggregateAfter(position);\n+        sourceBuilder.aggregation(changesAgg);\n+        sourceBuilder.size(0);\n+        for (FieldCollector fieldCollector : fieldCollectors.values()) {\n+            AggregationBuilder aggregationForField = fieldCollector.aggregateChanges();\n+\n+            if (aggregationForField != null) {\n+                sourceBuilder.aggregation(aggregationForField);\n+            }\n+        }\n+\n+        return sourceBuilder;\n+    }\n+\n+    @Override\n+    public void clear() {\n+        fieldCollectors.forEach((k, c) -> c.clear());\n+    }\n+\n+    @Override\n+    public Map<String, Object> getBucketPosition() {\n+        return afterKey;\n+    }\n+\n+    public static ChangeCollector buildChangeCollector(\n+        CompositeAggregationBuilder compositeAggregationBuilder,\n+        Map<String, SingleGroupSource> groups,\n+        String synchronizationField\n+    ) {\n+        Map<String, FieldCollector> fieldCollectors = createFieldCollectors(groups, synchronizationField);\n+        return new CompositeBucketsChangeCollector(compositeAggregationBuilder, fieldCollectors);\n+    }\n+\n+    static Map<String, FieldCollector> createFieldCollectors(Map<String, SingleGroupSource> groups, String synchronizationField) {\n+        Map<String, FieldCollector> fieldCollectors = new HashMap<>();\n+\n+        for (Entry<String, SingleGroupSource> entry : groups.entrySet()) {", "originalCommit": "81cbdda0391e2301251cab210e9b9b11fcf266b5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDY0Mjg4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/58744#discussion_r450642889", "bodyText": "To me it seems unavoidable, config and implementation should be separate, like PivotConfig and Pivot. so far it was simple enough to put in into ...GroupSource (which was totally ok). With the re-factoring it gets more complicated and there are already plans, that will add more code (maybe one day we end up with 1 class per GroupSource).\nYes keeping code away from core is a reason. If I would add it the implementation to ...GroupSource, I would not only need to move the code there, but also the collector interface.\nI think this change is similar to what is done in other places. The boiler-plate (switch) isn't great, but I do not see a need for something registry-style (like aggregations), at least at the moment.", "author": "hendrikmuhs", "createdAt": "2020-07-07T06:42:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDM5MjEzNw=="}], "type": "inlineReview"}, {"oid": "9275afa941c7e89f38548269252550b79f24d8ec", "url": "https://github.com/elastic/elasticsearch/commit/9275afa941c7e89f38548269252550b79f24d8ec", "message": "checkstyle", "committedDate": "2020-07-06T20:16:48Z", "type": "forcePushed"}, {"oid": "e36b418f02505f5df0045dff397f927836ce5ef9", "url": "https://github.com/elastic/elasticsearch/commit/e36b418f02505f5df0045dff397f927836ce5ef9", "message": "add a test for the terms field collector", "committedDate": "2020-07-07T20:12:37Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjEwNjkzOA==", "url": "https://github.com/elastic/elasticsearch/pull/58744#discussion_r452106938", "bodyText": "If this is running in a different thread it will not fail the test as the exception does not propagate to the test runner. You need to set the exception to an atomic reference then check after the latch in the test thread.", "author": "davidkyle", "createdAt": "2020-07-09T10:02:55Z", "path": "x-pack/plugin/transform/qa/single-node-tests/src/test/java/org/elasticsearch/xpack/transform/integration/TransformProgressIT.java", "diffHunk": "@@ -194,9 +182,41 @@ protected Settings restClientSettings() {\n         return Settings.builder().put(ThreadContext.PREFIX + \".Authorization\", token).build();\n     }\n \n+    private TransformProgress getProgress(Function function, SearchRequest searchRequest) throws Exception {\n+        CountDownLatch latch = new CountDownLatch(1);\n+        final AtomicReference<TransformProgress> progressHolder = new AtomicReference<>();\n+\n+        try (RestHighLevelClient restClient = new TestRestHighLevelClient()) {\n+            SearchResponse response = restClient.search(searchRequest, RequestOptions.DEFAULT);\n+\n+            function.getInitialProgressFromResponse(\n+                response,\n+                new LatchedActionListener<>(\n+                    ActionListener.wrap(progressHolder::set, e -> { fail(\"got unexpected exception: \" + e); }),", "originalCommit": "e36b418f02505f5df0045dff397f927836ce5ef9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjExMDgwOQ==", "url": "https://github.com/elastic/elasticsearch/pull/58744#discussion_r452110809", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                    TransformDestIndexSettings generateddestIndexSettings = TransformIndex.createTransformDestIndexSettings(\n          \n          \n            \n                                    TransformDestIndexSettings generatedDestIndexSettings = TransformIndex.createTransformDestIndexSettings(\n          \n      \n    \n    \n  \n\n^ Camel case Dest", "author": "davidkyle", "createdAt": "2020-07-09T10:09:58Z", "path": "x-pack/plugin/transform/src/main/java/org/elasticsearch/xpack/transform/action/TransportPreviewTransformAction.java", "diffHunk": "@@ -211,69 +182,51 @@ private void getPreview(\n \n             listener.onResponse(new PreviewTransformAction.Response(docs, generateddestIndexSettings));\n         }, listener::onFailure);\n-        pivot.deduceMappings(client, source, ActionListener.wrap(deducedMappings -> {\n+        function.deduceMappings(client, source, ActionListener.wrap(deducedMappings -> {\n             mappings.set(deducedMappings);\n-            ClientHelper.executeWithHeadersAsync(\n-                threadPool.getThreadContext().getHeaders(),\n-                ClientHelper.TRANSFORM_ORIGIN,\n+            function.preview(\n                 client,\n-                SearchAction.INSTANCE,\n-                pivot.buildSearchRequest(source, null, NUMBER_OF_PREVIEW_BUCKETS),\n-                ActionListener.wrap(r -> {\n-                    try {\n-                        final Aggregations aggregations = r.getAggregations();\n-                        if (aggregations == null) {\n-                            listener.onFailure(\n-                                new ElasticsearchStatusException(\"Source indices have been deleted or closed.\", RestStatus.BAD_REQUEST)\n-                            );\n-                            return;\n-                        }\n-                        final CompositeAggregation agg = aggregations.get(COMPOSITE_AGGREGATION_NAME);\n-                        TransformIndexerStats stats = new TransformIndexerStats();\n-                        // remove all internal fields\n-\n-                        if (pipeline == null) {\n-                            List<Map<String, Object>> docs = pivot.extractResults(agg, deducedMappings, stats)\n-                                .peek(doc -> doc.keySet().removeIf(k -> k.startsWith(\"_\")))\n-                                .collect(Collectors.toList());\n-\n-                            TransformDestIndexSettings generateddestIndexSettings = TransformIndex.createTransformDestIndexSettings(\n-                                mappings.get(),\n-                                transformId,\n-                                Clock.systemUTC()\n+                threadPool.getThreadContext().getHeaders(),\n+                source,\n+                deducedMappings,\n+                NUMBER_OF_PREVIEW_BUCKETS,\n+                ActionListener.wrap(docs -> {\n+                    if (pipeline == null) {\n+                        TransformDestIndexSettings generateddestIndexSettings = TransformIndex.createTransformDestIndexSettings(", "originalCommit": "e36b418f02505f5df0045dff397f927836ce5ef9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "902cbcd51a320cc73aba737f6116b5463edca91d", "url": "https://github.com/elastic/elasticsearch/commit/902cbcd51a320cc73aba737f6116b5463edca91d", "message": "separate pivot and extract function interface", "committedDate": "2020-07-13T11:29:20Z", "type": "commit"}, {"oid": "4e25abd60c9eca6116f87fdf5e7f3d6a1dc6c7b2", "url": "https://github.com/elastic/elasticsearch/commit/4e25abd60c9eca6116f87fdf5e7f3d6a1dc6c7b2", "message": "reactivate disabled indexer test", "committedDate": "2020-07-13T11:29:20Z", "type": "commit"}, {"oid": "11e2a883a173ca2d1ae6b65fa17f9e7e54bfa93e", "url": "https://github.com/elastic/elasticsearch/commit/11e2a883a173ca2d1ae6b65fa17f9e7e54bfa93e", "message": "make FunctionFactory final and effectively disable the constructor", "committedDate": "2020-07-13T11:29:20Z", "type": "commit"}, {"oid": "0349cedffb97568920f92b0c5670f51865418758", "url": "https://github.com/elastic/elasticsearch/commit/0349cedffb97568920f92b0c5670f51865418758", "message": "add progress to function interface", "committedDate": "2020-07-13T11:29:20Z", "type": "commit"}, {"oid": "b3fed214c72033fd3a73fc9f453504ac4972f946", "url": "https://github.com/elastic/elasticsearch/commit/b3fed214c72033fd3a73fc9f453504ac4972f946", "message": "move changecollector factory method", "committedDate": "2020-07-13T11:29:20Z", "type": "commit"}, {"oid": "1a6e8f3c1655c45f5c1c9a2c2a21ba5f1facf378", "url": "https://github.com/elastic/elasticsearch/commit/1a6e8f3c1655c45f5c1c9a2c2a21ba5f1facf378", "message": "checkstyle", "committedDate": "2020-07-13T11:29:20Z", "type": "commit"}, {"oid": "6072825ddf2e8486ecdcfa872ae669f02c81e5a5", "url": "https://github.com/elastic/elasticsearch/commit/6072825ddf2e8486ecdcfa872ae669f02c81e5a5", "message": "document the field collector interface and implement page limit for geotile\ncollector", "committedDate": "2020-07-13T11:29:20Z", "type": "commit"}, {"oid": "0cb39463cd21d5288b04ecb8c9fdb20f945cf94f", "url": "https://github.com/elastic/elasticsearch/commit/0cb39463cd21d5288b04ecb8c9fdb20f945cf94f", "message": "fix doc string", "committedDate": "2020-07-13T11:29:20Z", "type": "commit"}, {"oid": "b00dbd5009d093fc92d5ac5b1173ac91c2801b88", "url": "https://github.com/elastic/elasticsearch/commit/b00dbd5009d093fc92d5ac5b1173ac91c2801b88", "message": "add tests to adapt the page size by field collector", "committedDate": "2020-07-13T11:29:20Z", "type": "commit"}, {"oid": "93f918c945d911b1582e234db0b4371dce574d18", "url": "https://github.com/elastic/elasticsearch/commit/93f918c945d911b1582e234db0b4371dce574d18", "message": "fix test", "committedDate": "2020-07-13T11:29:20Z", "type": "commit"}, {"oid": "e55f92f1fbfcbecf4a7d2a323770c37b09518e7f", "url": "https://github.com/elastic/elasticsearch/commit/e55f92f1fbfcbecf4a7d2a323770c37b09518e7f", "message": "add a test for the terms field collector", "committedDate": "2020-07-13T11:29:20Z", "type": "commit"}, {"oid": "12601c279da76deb186a412554f1395faae85205", "url": "https://github.com/elastic/elasticsearch/commit/12601c279da76deb186a412554f1395faae85205", "message": "apply review suggestions", "committedDate": "2020-07-13T11:29:20Z", "type": "commit"}, {"oid": "12601c279da76deb186a412554f1395faae85205", "url": "https://github.com/elastic/elasticsearch/commit/12601c279da76deb186a412554f1395faae85205", "message": "apply review suggestions", "committedDate": "2020-07-13T11:29:20Z", "type": "forcePushed"}]}