{"pr_number": 51182, "pr_title": "Rewire terms agg to use new VS registry", "pr_createdAt": "2020-01-17T19:42:38Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/51182", "timeline": [{"oid": "49ada121a280107799a218e59fc3f17fd2a5310d", "url": "https://github.com/elastic/elasticsearch/commit/49ada121a280107799a218e59fc3f17fd2a5310d", "message": "Rewire terms agg to use new registry", "committedDate": "2020-01-17T19:36:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNTg4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r368105889", "bodyText": "I opted to use type name checks rather than instanceof, thinking it might be a bit more future-proof.  Happy to change if we don't think this is a good idea.", "author": "polyfractal", "createdAt": "2020-01-17T19:43:54Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregatorFactory.java", "diffHunk": "@@ -59,18 +71,161 @@\n     private final TermsAggregator.BucketCountThresholds bucketCountThresholds;\n     private final boolean showTermDocCountError;\n \n+    // TODO: Registration should happen on the actual aggregator classes\n+    static void registerAggregators(ValuesSourceRegistry valuesSourceRegistry) {\n+        valuesSourceRegistry.register(TermsAggregationBuilder.NAME, CoreValuesSourceType.BYTES, TermsAggregatorFactory.bytesSupplier(),\n+            (fieldType, indexFieldData) -> fieldType.typeName().equals(KeywordFieldMapper.CONTENT_TYPE)", "originalCommit": "49ada121a280107799a218e59fc3f17fd2a5310d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTExNzM3MQ==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369117371", "bodyText": "That's a good question. I used instanceof checks because that's what ValuesSourceConfig used, but I'm not at all convinced it's the best pattern.  We should probably pick a convention and stick to it though.", "author": "not-napoleon", "createdAt": "2020-01-21T16:46:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNTg4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIyMTg1Ng==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369221856", "bodyText": "Yeah, no super strong opinion...the strings just felt a little cleaner and future-proof'y (and I have an illogical distaste for instanceof checks).  I also liked that we can do things like explicitly whitelist what we mean a \"numeric\" is, rather than just what extends the numeric IndexNumericFieldData.   E.g. if a new plugin implements a new field type that has IndexNumericFieldData, core numeric aggs would automatically start using that.  Unsure if that's a bug or feature :)\nBut some types (like Range) would be a little more difficult due to how they are setup.  I didn't dig too much to see how hard it would be though.", "author": "polyfractal", "createdAt": "2020-01-21T20:18:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNTg4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI3MTk0Ng==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369271946", "bodyText": "I think this is fine for this PR, but I want to think about it some more.  Might change it around before we go to master.  Honestly, I don't love passing in this lambda at all, doesn't feel like something people writing aggs should need to know about.  I'll think about it some more and we can touch base later in the week, but it's fine for this to merge as is.", "author": "not-napoleon", "createdAt": "2020-01-21T22:14:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNTg4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTEyNTY3NA==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369125674", "bodyText": "I really like this static method pattern, very readable and clear which VSTs get which aggregator.", "author": "not-napoleon", "createdAt": "2020-01-21T17:00:39Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregatorFactory.java", "diffHunk": "@@ -59,18 +71,161 @@\n     private final TermsAggregator.BucketCountThresholds bucketCountThresholds;\n     private final boolean showTermDocCountError;\n \n+    // TODO: Registration should happen on the actual aggregator classes\n+    static void registerAggregators(ValuesSourceRegistry valuesSourceRegistry) {\n+        valuesSourceRegistry.register(TermsAggregationBuilder.NAME, CoreValuesSourceType.BYTES, TermsAggregatorFactory.bytesSupplier(),\n+            (fieldType, indexFieldData) -> fieldType.typeName().equals(KeywordFieldMapper.CONTENT_TYPE)\n+                || fieldType.typeName().equals(BinaryFieldMapper.CONTENT_TYPE)\n+                || fieldType.typeName().equals(IdFieldMapper.CONTENT_TYPE)\n+                || fieldType.typeName().equals(IndexFieldMapper.CONTENT_TYPE)\n+        );\n+\n+        valuesSourceRegistry.register(TermsAggregationBuilder.NAME, CoreValuesSourceType.IP, TermsAggregatorFactory.bytesSupplier(),\n+            (fieldType, indexFieldData) -> fieldType.typeName().equals(IpFieldMapper.CONTENT_TYPE)\n+        );\n+\n+        valuesSourceRegistry.register(TermsAggregationBuilder.NAME, CoreValuesSourceType.DATE, TermsAggregatorFactory.numericSupplier(),\n+            (fieldType, indexFieldData) -> fieldType.typeName().equals(DateFieldMapper.CONTENT_TYPE)\n+        );\n+\n+        valuesSourceRegistry.register(TermsAggregationBuilder.NAME, CoreValuesSourceType.BOOLEAN, TermsAggregatorFactory.numericSupplier(),\n+            (fieldType, indexFieldData) -> fieldType.typeName().equals(BooleanFieldMapper.CONTENT_TYPE)\n+        );\n+\n+        valuesSourceRegistry.register(TermsAggregationBuilder.NAME, CoreValuesSourceType.NUMERIC, TermsAggregatorFactory.numericSupplier(),\n+            (fieldType, indexFieldData) -> {\n+                for (NumberFieldMapper.NumberType type : NumberFieldMapper.NumberType.values()) {\n+                    if (fieldType.typeName().equals(type.typeName())) {\n+                        return true;\n+                    }\n+                }\n+                return false;\n+            }\n+        );\n+    }\n+\n+    /**\n+     * This supplier is used for all the field types that should be aggregated as bytes/strings,\n+     * including those that need global ordinals\n+     */\n+    private static TermsAggregatorSupplier bytesSupplier() {", "originalCommit": "49ada121a280107799a218e59fc3f17fd2a5310d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTEzOTkyMg==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369139922", "bodyText": "Using reference equality here seems counterintuitive at best, brittle at worst.  Would factory.equals(AggregatorFactories.EMPTY) == false or even factory.isEmpty() == false be possible?\nNo reason to block merging on that though, since the old code did it this way and it clearly worked fine.", "author": "not-napoleon", "createdAt": "2020-01-21T17:28:11Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregatorFactory.java", "diffHunk": "@@ -59,18 +71,161 @@\n     private final TermsAggregator.BucketCountThresholds bucketCountThresholds;\n     private final boolean showTermDocCountError;\n \n+    // TODO: Registration should happen on the actual aggregator classes\n+    static void registerAggregators(ValuesSourceRegistry valuesSourceRegistry) {\n+        valuesSourceRegistry.register(TermsAggregationBuilder.NAME, CoreValuesSourceType.BYTES, TermsAggregatorFactory.bytesSupplier(),\n+            (fieldType, indexFieldData) -> fieldType.typeName().equals(KeywordFieldMapper.CONTENT_TYPE)\n+                || fieldType.typeName().equals(BinaryFieldMapper.CONTENT_TYPE)\n+                || fieldType.typeName().equals(IdFieldMapper.CONTENT_TYPE)\n+                || fieldType.typeName().equals(IndexFieldMapper.CONTENT_TYPE)\n+        );\n+\n+        valuesSourceRegistry.register(TermsAggregationBuilder.NAME, CoreValuesSourceType.IP, TermsAggregatorFactory.bytesSupplier(),\n+            (fieldType, indexFieldData) -> fieldType.typeName().equals(IpFieldMapper.CONTENT_TYPE)\n+        );\n+\n+        valuesSourceRegistry.register(TermsAggregationBuilder.NAME, CoreValuesSourceType.DATE, TermsAggregatorFactory.numericSupplier(),\n+            (fieldType, indexFieldData) -> fieldType.typeName().equals(DateFieldMapper.CONTENT_TYPE)\n+        );\n+\n+        valuesSourceRegistry.register(TermsAggregationBuilder.NAME, CoreValuesSourceType.BOOLEAN, TermsAggregatorFactory.numericSupplier(),\n+            (fieldType, indexFieldData) -> fieldType.typeName().equals(BooleanFieldMapper.CONTENT_TYPE)\n+        );\n+\n+        valuesSourceRegistry.register(TermsAggregationBuilder.NAME, CoreValuesSourceType.NUMERIC, TermsAggregatorFactory.numericSupplier(),\n+            (fieldType, indexFieldData) -> {\n+                for (NumberFieldMapper.NumberType type : NumberFieldMapper.NumberType.values()) {\n+                    if (fieldType.typeName().equals(type.typeName())) {\n+                        return true;\n+                    }\n+                }\n+                return false;\n+            }\n+        );\n+    }\n+\n+    /**\n+     * This supplier is used for all the field types that should be aggregated as bytes/strings,\n+     * including those that need global ordinals\n+     */\n+    private static TermsAggregatorSupplier bytesSupplier() {\n+        return new TermsAggregatorSupplier() {\n+            @Override\n+            public Aggregator build(String name,\n+                                    AggregatorFactories factories,\n+                                    ValuesSource valuesSource,\n+                                    BucketOrder order,\n+                                    DocValueFormat format,\n+                                    TermsAggregator.BucketCountThresholds bucketCountThresholds,\n+                                    IncludeExclude includeExclude,\n+                                    String executionHint,\n+                                    SearchContext context,\n+                                    Aggregator parent,\n+                                    SubAggCollectionMode subAggCollectMode,\n+                                    boolean showTermDocCountError,\n+                                    List<PipelineAggregator> pipelineAggregators,\n+                                    Map<String, Object> metaData) throws IOException {\n+\n+                ExecutionMode execution = null;\n+                if (executionHint != null) {\n+                    execution = ExecutionMode.fromString(executionHint, deprecationLogger);\n+                }\n+                // In some cases, using ordinals is just not supported: override it\n+                if (valuesSource instanceof ValuesSource.Bytes.WithOrdinals == false) {\n+                    execution = ExecutionMode.MAP;\n+                }\n+                final long maxOrd = execution == ExecutionMode.GLOBAL_ORDINALS ? getMaxOrd(valuesSource, context.searcher()) : -1;\n+                if (execution == null) {\n+                    execution = ExecutionMode.GLOBAL_ORDINALS;\n+                }\n+                if (subAggCollectMode == null) {\n+                    subAggCollectMode = SubAggCollectionMode.DEPTH_FIRST;\n+                    if (factories != AggregatorFactories.EMPTY) {", "originalCommit": "49ada121a280107799a218e59fc3f17fd2a5310d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIyNDMwMA==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369224300", "bodyText": "Yeah I'm not entirely sure the etymology here... not sure if there is a reason for differentiating from empty array and an \"empty\" instance.  I suspect it's just a quirk of old code, it appears to only be used by terms and friends (and anyone using NonCollectingAggregator for their unmapped agg)\nI'll leave a TODO, didn't want to change too much of the existing code for fear of breaking :)", "author": "polyfractal", "createdAt": "2020-01-21T20:24:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTEzOTkyMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE0NTMyNw==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369145327", "bodyText": "Just thinking out loud here - should we have some sort of validity check to make sure that the ValuesSource argument passed into doCreateInternal is actually of type config.valuesSourceType()?  Like, I don't see a way it couldn't be without forcing it into some weird state in a test, but still, seems like a weird possible miss-alignment.  Or maybe ValuesSource just needs a getValuesSourceType() method which we can use here instead of the one on config?  IDK, clearly I didn't think about it when I was wiring up Histogram.\nAgain, don't need to fix this here, but we should figure out what the right thing to do is, and then standardize on that.", "author": "not-napoleon", "createdAt": "2020-01-21T17:39:51Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregatorFactory.java", "diffHunk": "@@ -114,91 +269,39 @@ private static boolean isAggregationSort(BucketOrder order) {\n \n     @Override\n     protected Aggregator doCreateInternal(ValuesSource valuesSource,\n-                                            SearchContext searchContext,\n-                                            Aggregator parent,\n-                                            boolean collectsFromSingleBucket,\n-                                            List<PipelineAggregator> pipelineAggregators,\n-                                            Map<String, Object> metaData) throws IOException {\n+                                          SearchContext searchContext,\n+                                          Aggregator parent,\n+                                          boolean collectsFromSingleBucket,\n+                                          List<PipelineAggregator> pipelineAggregators,\n+                                          Map<String, Object> metaData) throws IOException {\n         if (collectsFromSingleBucket == false) {\n             return asMultiBucketAggregator(this, searchContext, parent);\n         }\n+\n+        AggregatorSupplier aggregatorSupplier = ValuesSourceRegistry.getInstance().getAggregator(config.valueSourceType(),", "originalCommit": "49ada121a280107799a218e59fc3f17fd2a5310d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIyNjAwOQ==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369226009", "bodyText": "Oh hmm good point.  Should this code be using the passed in valueSourceType instead of the config entirely?\nPerhaps we make the superclass config private so it isn't accessible?  I did a quick skim and it looks like most (all?) uses of config are just to get the formatter, so perhaps we add the formatter as a protected variable in ValuesSourceAggregatorFactory instead?", "author": "polyfractal", "createdAt": "2020-01-21T20:28:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE0NTMyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI3MzIwMQ==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369273201", "bodyText": "Yeah, I think that's the way to go.  I'll add a line item on the meta PR, and one of us can grab it soon.", "author": "not-napoleon", "createdAt": "2020-01-21T22:17:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE0NTMyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE0Njk5MA==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369146990", "bodyText": "Nit:  Unnecessary blank line.", "author": "not-napoleon", "createdAt": "2020-01-21T17:43:20Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/TermsAggregatorFactory.java", "diffHunk": "@@ -114,91 +269,39 @@ private static boolean isAggregationSort(BucketOrder order) {\n \n     @Override\n     protected Aggregator doCreateInternal(ValuesSource valuesSource,\n-                                            SearchContext searchContext,\n-                                            Aggregator parent,\n-                                            boolean collectsFromSingleBucket,\n-                                            List<PipelineAggregator> pipelineAggregators,\n-                                            Map<String, Object> metaData) throws IOException {\n+                                          SearchContext searchContext,\n+                                          Aggregator parent,\n+                                          boolean collectsFromSingleBucket,\n+                                          List<PipelineAggregator> pipelineAggregators,\n+                                          Map<String, Object> metaData) throws IOException {\n         if (collectsFromSingleBucket == false) {\n             return asMultiBucketAggregator(this, searchContext, parent);\n         }\n+\n+        AggregatorSupplier aggregatorSupplier = ValuesSourceRegistry.getInstance().getAggregator(config.valueSourceType(),\n+            TermsAggregationBuilder.NAME);\n+        if (aggregatorSupplier instanceof TermsAggregatorSupplier == false) {\n+            throw new AggregationExecutionException(\"Registry miss-match - expected TermsAggregatorSupplier, found [\" +\n+                aggregatorSupplier.getClass().toString() + \"]\");\n+        }\n+\n+        TermsAggregatorSupplier termsAggregatorSupplier = (TermsAggregatorSupplier) aggregatorSupplier;\n         BucketCountThresholds bucketCountThresholds = new BucketCountThresholds(this.bucketCountThresholds);\n         if (InternalOrder.isKeyOrder(order) == false\n-                && bucketCountThresholds.getShardSize() == TermsAggregationBuilder.DEFAULT_BUCKET_COUNT_THRESHOLDS.getShardSize()) {\n+            && bucketCountThresholds.getShardSize() == TermsAggregationBuilder.DEFAULT_BUCKET_COUNT_THRESHOLDS.getShardSize()) {\n             // The user has not made a shardSize selection. Use default\n             // heuristic to avoid any wrong-ranking caused by distributed\n             // counting\n             bucketCountThresholds.setShardSize(BucketUtils.suggestShardSideQueueSize(bucketCountThresholds.getRequiredSize()));\n         }\n         bucketCountThresholds.ensureValidity();\n-        if (valuesSource instanceof ValuesSource.Bytes) {\n-            ExecutionMode execution = null;\n-            if (executionHint != null) {\n-                execution = ExecutionMode.fromString(executionHint, deprecationLogger);\n-            }\n-            // In some cases, using ordinals is just not supported: override it\n-            if (valuesSource instanceof ValuesSource.Bytes.WithOrdinals == false) {\n-                execution = ExecutionMode.MAP;\n-            }\n-            final long maxOrd = execution == ExecutionMode.GLOBAL_ORDINALS ? getMaxOrd(valuesSource, searchContext.searcher()) : -1;\n-            if (execution == null) {\n-                execution = ExecutionMode.GLOBAL_ORDINALS;\n-            }\n-            SubAggCollectionMode cm = collectMode;\n-            if (cm == null) {\n-                cm = SubAggCollectionMode.DEPTH_FIRST;\n-                if (factories != AggregatorFactories.EMPTY) {\n-                    cm = subAggCollectionMode(bucketCountThresholds.getShardSize(), maxOrd);\n-                }\n-            }\n-\n-            DocValueFormat format = config.format();\n-            if ((includeExclude != null) && (includeExclude.isRegexBased()) && format != DocValueFormat.RAW) {\n-                throw new AggregationExecutionException(\"Aggregation [\" + name + \"] cannot support regular expression style \"\n-                        + \"include/exclude settings as they can only be applied to string fields. Use an array of values for \"\n-                        + \"include/exclude clauses\");\n-            }\n \n-            return execution.create(name, factories, valuesSource, order, format,\n-                bucketCountThresholds, includeExclude, searchContext, parent, cm, showTermDocCountError, pipelineAggregators, metaData);\n-        }\n-\n-        if ((includeExclude != null) && (includeExclude.isRegexBased())) {\n-            throw new AggregationExecutionException(\"Aggregation [\" + name + \"] cannot support regular expression style \"\n-                    + \"include/exclude settings as they can only be applied to string fields. Use an array of numeric values for \"\n-                    + \"include/exclude clauses used to filter numeric fields\");\n-        }\n-\n-        if (valuesSource instanceof ValuesSource.Numeric) {\n-            IncludeExclude.LongFilter longFilter = null;\n-            SubAggCollectionMode cm = collectMode;\n-            if (cm == null) {\n-                if (factories != AggregatorFactories.EMPTY) {\n-                    cm = subAggCollectionMode(bucketCountThresholds.getShardSize(), -1);\n-                } else {\n-                    cm = SubAggCollectionMode.DEPTH_FIRST;\n-                }\n-            }\n-            if (((ValuesSource.Numeric) valuesSource).isFloatingPoint()) {\n-                if (includeExclude != null) {\n-                    longFilter = includeExclude.convertToDoubleFilter();\n-                }\n-                return new DoubleTermsAggregator(name, factories, (ValuesSource.Numeric) valuesSource, config.format(), order,\n-                        bucketCountThresholds, searchContext, parent, cm, showTermDocCountError, longFilter,\n-                        pipelineAggregators, metaData);\n-            }\n-            if (includeExclude != null) {\n-                longFilter = includeExclude.convertToLongFilter(config.format());\n-            }\n-            return new LongTermsAggregator(name, factories, (ValuesSource.Numeric) valuesSource, config.format(), order,\n-                    bucketCountThresholds, searchContext, parent, cm, showTermDocCountError, longFilter, pipelineAggregators,\n-                    metaData);\n-        }\n-\n-        throw new AggregationExecutionException(\"terms aggregation cannot be applied to field [\" + config.fieldContext().field()\n-            + \"]. It can only be applied to numeric or string fields.\");\n+        return termsAggregatorSupplier.build(name, factories, valuesSource, order, config.format(),\n+            bucketCountThresholds, includeExclude, executionHint, searchContext, parent, collectMode,\n+            showTermDocCountError, pipelineAggregators, metaData);\n     }\n \n+", "originalCommit": "49ada121a280107799a218e59fc3f17fd2a5310d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE1MDY2MQ==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369150661", "bodyText": "Slightly confusing to me that we are including numeric test cases in a class called StringTermsAggregatorTests.  Should we have a NumericTermsAggregatorTests to hold these?  Or did you intend to set the userValueTypeHint to string for these?", "author": "not-napoleon", "createdAt": "2020-01-21T17:51:05Z", "path": "server/src/test/java/org/elasticsearch/search/aggregations/bucket/terms/StringTermsAggregatorTests.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.search.aggregations.bucket.terms;\n+\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.LongPoint;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.DirectoryReader;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.RandomIndexWriter;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.MatchAllDocsQuery;\n+import org.apache.lucene.search.MatchNoDocsQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.RegExp;\n+import org.elasticsearch.index.mapper.KeywordFieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.search.aggregations.AggregationExecutionException;\n+import org.elasticsearch.search.aggregations.AggregatorTestCase;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.Consumer;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class StringTermsAggregatorTests extends AggregatorTestCase {\n+    private static final String LONG_FIELD = \"numeric\";\n+    private static final String KEYWORD_FIELD = \"keyword\";\n+\n+    private static final List<Long> dataset;\n+    static {\n+        List<Long> d = new ArrayList<>(45);\n+        for (int i = 0; i < 10; i++) {\n+            for (int j = 0; j < i; j++) {\n+                d.add((long) i);\n+            }\n+        }\n+        dataset  = d;\n+    }\n+\n+    public void testMatchNoDocs() throws IOException {\n+        testBothCases(new MatchNoDocsQuery(), dataset,\n+            aggregation -> aggregation.field(KEYWORD_FIELD),\n+            agg -> assertEquals(0, agg.getBuckets().size()), ValueType.STRING\n+        );\n+        testBothCases(new MatchNoDocsQuery(), dataset,\n+            aggregation -> aggregation.field(LONG_FIELD),", "originalCommit": "49ada121a280107799a218e59fc3f17fd2a5310d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIyNzgyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369227821", "bodyText": "Ummmmm.... I think I started out with just String tests then added numerics and forgot the test class was called StringTermsAggregatorTests. \ud83d\ude05\nWill make a numeric class and separate", "author": "polyfractal", "createdAt": "2020-01-21T20:32:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE1MDY2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE1NTk4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369155989", "bodyText": "I'm concerned that all these tests are running with userValueTypeHint set.  We don't make it a required field in the parser, and I suspect most folks don't specify it.  We don't even specify it in the docs most of the time.  We should either test both with it set and not set, or default to not setting it.", "author": "not-napoleon", "createdAt": "2020-01-21T18:01:51Z", "path": "server/src/test/java/org/elasticsearch/search/aggregations/bucket/terms/StringTermsAggregatorTests.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.search.aggregations.bucket.terms;\n+\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.LongPoint;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.DirectoryReader;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.RandomIndexWriter;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.MatchAllDocsQuery;\n+import org.apache.lucene.search.MatchNoDocsQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.RegExp;\n+import org.elasticsearch.index.mapper.KeywordFieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.search.aggregations.AggregationExecutionException;\n+import org.elasticsearch.search.aggregations.AggregatorTestCase;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.Consumer;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class StringTermsAggregatorTests extends AggregatorTestCase {\n+    private static final String LONG_FIELD = \"numeric\";\n+    private static final String KEYWORD_FIELD = \"keyword\";\n+\n+    private static final List<Long> dataset;\n+    static {\n+        List<Long> d = new ArrayList<>(45);\n+        for (int i = 0; i < 10; i++) {\n+            for (int j = 0; j < i; j++) {\n+                d.add((long) i);\n+            }\n+        }\n+        dataset  = d;\n+    }\n+\n+    public void testMatchNoDocs() throws IOException {\n+        testBothCases(new MatchNoDocsQuery(), dataset,\n+            aggregation -> aggregation.field(KEYWORD_FIELD),\n+            agg -> assertEquals(0, agg.getBuckets().size()), ValueType.STRING\n+        );\n+        testBothCases(new MatchNoDocsQuery(), dataset,\n+            aggregation -> aggregation.field(LONG_FIELD),\n+            agg -> assertEquals(0, agg.getBuckets().size()), ValueType.NUMERIC\n+        );\n+    }\n+\n+    public void testMatchAllDocs() throws IOException {\n+        Query query = new MatchAllDocsQuery();\n+\n+        testBothCases(query, dataset,\n+            aggregation -> aggregation.field(LONG_FIELD),\n+            agg -> {\n+                assertEquals(9, agg.getBuckets().size());\n+                for (int i = 0; i < 9; i++) {\n+                    LongTerms.Bucket bucket = (LongTerms.Bucket) agg.getBuckets().get(i);\n+                    assertThat(bucket.getKey(), equalTo(9L - i));\n+                    assertThat(bucket.getDocCount(), equalTo(9L - i));\n+                }\n+            }, ValueType.NUMERIC\n+        );\n+        testBothCases(query, dataset,\n+            aggregation -> aggregation.field(KEYWORD_FIELD),\n+            agg -> {\n+                assertEquals(9, agg.getBuckets().size());\n+                for (int i = 0; i < 9; i++) {\n+                    StringTerms.Bucket bucket = (StringTerms.Bucket) agg.getBuckets().get(i);\n+                    assertThat(bucket.getKey(), equalTo(String.valueOf(9L - i)));\n+                    assertThat(bucket.getDocCount(), equalTo(9L - i));\n+                }\n+            }, ValueType.STRING\n+        );\n+    }\n+\n+    public void testBadIncludeExclude() throws IOException {\n+        IncludeExclude includeExclude = new IncludeExclude(new RegExp(\"foo\"), null);\n+\n+        // Bytes fails if the formatter is not RAW.  Note this is still on the long field, just hinted as string\n+        AggregationExecutionException e = expectThrows(AggregationExecutionException.class,\n+            () -> testBothCases(new MatchNoDocsQuery(), dataset,\n+                aggregation -> aggregation.field(LONG_FIELD).includeExclude(includeExclude).format(\"yyyy-MM-dd\"),\n+                agg -> fail(\"test should have failed with exception\"), ValueType.STRING\n+        ));\n+        assertThat(e.getMessage(), equalTo(\"Aggregation [_name] cannot support regular expression style \" +\n+            \"include/exclude settings as they can only be applied to string fields. Use an array of numeric \" +\n+            \"values for include/exclude clauses used to filter numeric fields\"));\n+\n+        // Numeric cannot use regex at all\n+        e = expectThrows(AggregationExecutionException.class, () -> testBothCases(new MatchNoDocsQuery(), dataset,\n+            aggregation -> aggregation.field(LONG_FIELD).includeExclude(includeExclude),\n+            agg -> fail(\"test should have failed with exception\"), ValueType.NUMERIC\n+        ));\n+        assertThat(e.getMessage(), equalTo(\"Aggregation [_name] cannot support regular expression style include/exclude \" +\n+            \"settings as they can only be applied to string fields. Use an array of numeric values for include/exclude \" +\n+            \"clauses used to filter numeric fields\"));\n+    }\n+\n+    private void testSearchCase(Query query, List<Long> dataset,\n+                                Consumer<TermsAggregationBuilder> configure,\n+                                Consumer<InternalMappedTerms> verify, ValueType valueType) throws IOException {\n+        executeTestCase(false, query, dataset, configure, verify, valueType);\n+    }\n+\n+    private void testSearchAndReduceCase(Query query, List<Long> dataset,\n+                                         Consumer<TermsAggregationBuilder> configure,\n+                                         Consumer<InternalMappedTerms> verify, ValueType valueType) throws IOException {\n+        executeTestCase(true, query, dataset, configure, verify, valueType);\n+    }\n+\n+    private void testBothCases(Query query, List<Long> dataset,\n+                               Consumer<TermsAggregationBuilder> configure,\n+                               Consumer<InternalMappedTerms> verify, ValueType valueType) throws IOException {\n+        testSearchCase(query, dataset, configure, verify, valueType);\n+        testSearchAndReduceCase(query, dataset, configure, verify, valueType);\n+    }\n+\n+    private void executeTestCase(boolean reduced, Query query, List<Long> dataset,\n+                                 Consumer<TermsAggregationBuilder> configure,\n+                                 Consumer<InternalMappedTerms> verify, ValueType valueType) throws IOException {\n+\n+        try (Directory directory = newDirectory()) {\n+            try (RandomIndexWriter indexWriter = new RandomIndexWriter(random(), directory)) {\n+                Document document = new Document();\n+                for (Long value : dataset) {\n+                    if (frequently()) {\n+                        indexWriter.commit();\n+                    }\n+\n+                    document.add(new SortedNumericDocValuesField(LONG_FIELD, value));\n+                    document.add(new LongPoint(LONG_FIELD, value));\n+                    document.add(new SortedSetDocValuesField(KEYWORD_FIELD, new BytesRef(Long.toString(value))));\n+                    indexWriter.addDocument(document);\n+                    document.clear();\n+                }\n+            }\n+\n+            try (IndexReader indexReader = DirectoryReader.open(directory)) {\n+                IndexSearcher indexSearcher = newIndexSearcher(indexReader);\n+\n+                TermsAggregationBuilder aggregationBuilder = new TermsAggregationBuilder(\"_name\");\n+                aggregationBuilder.userValueTypeHint(valueType);", "originalCommit": "49ada121a280107799a218e59fc3f17fd2a5310d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE1ODU4OA==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369158588", "bodyText": "Comment is misleading, I think - this isn't testing the bytes case?  You can tell by the exception message it expects.  The string case doesn't end with \"used to filter numeric fields\"", "author": "not-napoleon", "createdAt": "2020-01-21T18:07:30Z", "path": "server/src/test/java/org/elasticsearch/search/aggregations/bucket/terms/StringTermsAggregatorTests.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.search.aggregations.bucket.terms;\n+\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.LongPoint;\n+import org.apache.lucene.document.SortedNumericDocValuesField;\n+import org.apache.lucene.document.SortedSetDocValuesField;\n+import org.apache.lucene.index.DirectoryReader;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.index.RandomIndexWriter;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.MatchAllDocsQuery;\n+import org.apache.lucene.search.MatchNoDocsQuery;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.util.BytesRef;\n+import org.apache.lucene.util.automaton.RegExp;\n+import org.elasticsearch.index.mapper.KeywordFieldMapper;\n+import org.elasticsearch.index.mapper.MappedFieldType;\n+import org.elasticsearch.index.mapper.NumberFieldMapper;\n+import org.elasticsearch.search.aggregations.AggregationExecutionException;\n+import org.elasticsearch.search.aggregations.AggregatorTestCase;\n+import org.elasticsearch.search.aggregations.support.ValueType;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.Consumer;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class StringTermsAggregatorTests extends AggregatorTestCase {\n+    private static final String LONG_FIELD = \"numeric\";\n+    private static final String KEYWORD_FIELD = \"keyword\";\n+\n+    private static final List<Long> dataset;\n+    static {\n+        List<Long> d = new ArrayList<>(45);\n+        for (int i = 0; i < 10; i++) {\n+            for (int j = 0; j < i; j++) {\n+                d.add((long) i);\n+            }\n+        }\n+        dataset  = d;\n+    }\n+\n+    public void testMatchNoDocs() throws IOException {\n+        testBothCases(new MatchNoDocsQuery(), dataset,\n+            aggregation -> aggregation.field(KEYWORD_FIELD),\n+            agg -> assertEquals(0, agg.getBuckets().size()), ValueType.STRING\n+        );\n+        testBothCases(new MatchNoDocsQuery(), dataset,\n+            aggregation -> aggregation.field(LONG_FIELD),\n+            agg -> assertEquals(0, agg.getBuckets().size()), ValueType.NUMERIC\n+        );\n+    }\n+\n+    public void testMatchAllDocs() throws IOException {\n+        Query query = new MatchAllDocsQuery();\n+\n+        testBothCases(query, dataset,\n+            aggregation -> aggregation.field(LONG_FIELD),\n+            agg -> {\n+                assertEquals(9, agg.getBuckets().size());\n+                for (int i = 0; i < 9; i++) {\n+                    LongTerms.Bucket bucket = (LongTerms.Bucket) agg.getBuckets().get(i);\n+                    assertThat(bucket.getKey(), equalTo(9L - i));\n+                    assertThat(bucket.getDocCount(), equalTo(9L - i));\n+                }\n+            }, ValueType.NUMERIC\n+        );\n+        testBothCases(query, dataset,\n+            aggregation -> aggregation.field(KEYWORD_FIELD),\n+            agg -> {\n+                assertEquals(9, agg.getBuckets().size());\n+                for (int i = 0; i < 9; i++) {\n+                    StringTerms.Bucket bucket = (StringTerms.Bucket) agg.getBuckets().get(i);\n+                    assertThat(bucket.getKey(), equalTo(String.valueOf(9L - i)));\n+                    assertThat(bucket.getDocCount(), equalTo(9L - i));\n+                }\n+            }, ValueType.STRING\n+        );\n+    }\n+\n+    public void testBadIncludeExclude() throws IOException {\n+        IncludeExclude includeExclude = new IncludeExclude(new RegExp(\"foo\"), null);\n+\n+        // Bytes fails if the formatter is not RAW.  Note this is still on the long field, just hinted as string", "originalCommit": "49ada121a280107799a218e59fc3f17fd2a5310d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "681233464e2383705cc8b6186199caf9e0842d2b", "url": "https://github.com/elastic/elasticsearch/commit/681233464e2383705cc8b6186199caf9e0842d2b", "message": "Fix tests\n\n- The only \"bytes\" that is even accepts a format is Binary, so\nsplit that into it's own test for include/exclude regex testing\n- Keyword test is now basically just match_all/match_none boilerplate,\nwaiting for some industrious soul to fill it out later\n- Numeric has include/exclude tests for all formatting\n- with and without user supplied type hints", "committedDate": "2020-01-21T22:12:08Z", "type": "commit"}, {"oid": "24aeb8f0fda9ab20bfb8069aa33904813dcbfdef", "url": "https://github.com/elastic/elasticsearch/commit/24aeb8f0fda9ab20bfb8069aa33904813dcbfdef", "message": "Merge branch 'feature/extensible-values-source' of github.com:elastic/elasticsearch into vs_refactor_terms_agg", "committedDate": "2020-01-21T22:15:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgwNjQwMA==", "url": "https://github.com/elastic/elasticsearch/pull/51182#discussion_r369806400", "bodyText": "Something I was thinking about while wiring up Cardinality - these aggregator supplier interfaces should probably go in the same package as the aggregators.  Their signature is tightly bound to the aggregator signature, and it means we don't need to increase the visibility on package private aggregators (which some of them are).", "author": "not-napoleon", "createdAt": "2020-01-22T21:13:34Z", "path": "server/src/main/java/org/elasticsearch/search/aggregations/support/TermsAggregatorSupplier.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.elasticsearch.search.aggregations.support;", "originalCommit": "24aeb8f0fda9ab20bfb8069aa33904813dcbfdef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "c5155066fec026f4a12fac6c4fa838d7db448ac1", "url": "https://github.com/elastic/elasticsearch/commit/c5155066fec026f4a12fac6c4fa838d7db448ac1", "message": "Merge branch 'feature/extensible-values-source' of github.com:elastic/elasticsearch into vs_refactor_terms_agg", "committedDate": "2020-01-28T17:36:42Z", "type": "commit"}, {"oid": "72a8d40bea1cb0e149a2bf4a3cf4a7eaa24bfa56", "url": "https://github.com/elastic/elasticsearch/commit/72a8d40bea1cb0e149a2bf4a3cf4a7eaa24bfa56", "message": "Address review, fix merge conflicts\n\n- Removes the need to whitelist due to merging in feature branch\n- adds some TODOs\n- Moves the Supplier into the terms package, makes it package-private", "committedDate": "2020-01-28T17:57:20Z", "type": "commit"}, {"oid": "4ae490591070f763190872e287ad024016e2d44a", "url": "https://github.com/elastic/elasticsearch/commit/4ae490591070f763190872e287ad024016e2d44a", "message": "checkstyle", "committedDate": "2020-01-28T20:04:27Z", "type": "commit"}]}