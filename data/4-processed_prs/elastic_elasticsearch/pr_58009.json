{"pr_number": 58009, "pr_title": "[ML] handles compressed model stream from native process", "pr_createdAt": "2020-06-11T19:24:12Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/58009", "timeline": [{"oid": "f3ccd195ccb02bd2ae617f9974d0a667f04d048f", "url": "https://github.com/elastic/elasticsearch/commit/f3ccd195ccb02bd2ae617f9974d0a667f04d048f", "message": "[ML] handles compressed model stream from native process", "committedDate": "2020-06-11T19:16:47Z", "type": "commit"}, {"oid": "f3ccd195ccb02bd2ae617f9974d0a667f04d048f", "url": "https://github.com/elastic/elasticsearch/commit/f3ccd195ccb02bd2ae617f9974d0a667f04d048f", "message": "[ML] handles compressed model stream from native process", "committedDate": "2020-06-11T19:16:47Z", "type": "forcePushed"}, {"oid": "7082531824b0775c6a06204b06359e3372c2cb55", "url": "https://github.com/elastic/elasticsearch/commit/7082531824b0775c6a06204b06359e3372c2cb55", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-analytics-handle-compressed-model-stream", "committedDate": "2020-06-26T11:54:50Z", "type": "commit"}, {"oid": "3a5ce9301d227876ea178c118b8b97b7cd1bc6c5", "url": "https://github.com/elastic/elasticsearch/commit/3a5ce9301d227876ea178c118b8b97b7cd1bc6c5", "message": "fixing after merge", "committedDate": "2020-06-26T13:55:10Z", "type": "commit"}, {"oid": "354fc25be4b26de9d1625d69e7b7f75f26099eb4", "url": "https://github.com/elastic/elasticsearch/commit/354fc25be4b26de9d1625d69e7b7f75f26099eb4", "message": "adjusting doc storage format", "committedDate": "2020-06-26T15:27:47Z", "type": "commit"}, {"oid": "ff192a4704a855cd5aa0b6a8e2e5b0ac9d8df351", "url": "https://github.com/elastic/elasticsearch/commit/ff192a4704a855cd5aa0b6a8e2e5b0ac9d8df351", "message": "fixing model storage", "committedDate": "2020-06-26T17:58:45Z", "type": "commit"}, {"oid": "ad877b075dbe1aae50aa64e2745ba3ab923563b8", "url": "https://github.com/elastic/elasticsearch/commit/ad877b075dbe1aae50aa64e2745ba3ab923563b8", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-analytics-handle-compressed-model-stream", "committedDate": "2020-06-26T19:29:52Z", "type": "commit"}, {"oid": "40571e2ad2daa05eda3f1130f7c923a8f65bae5b", "url": "https://github.com/elastic/elasticsearch/commit/40571e2ad2daa05eda3f1130f7c923a8f65bae5b", "message": "unmuting tests", "committedDate": "2020-06-26T19:30:09Z", "type": "commit"}, {"oid": "8a340bfac24b19cbb32170f16a8d7323ae296854", "url": "https://github.com/elastic/elasticsearch/commit/8a340bfac24b19cbb32170f16a8d7323ae296854", "message": "unmuting tests", "committedDate": "2020-06-26T19:30:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwMTYwMA==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447601600", "bodyText": "nice name, but I guess moodel -> model ;-)", "author": "hendrikmuhs", "createdAt": "2020-06-30T11:09:20Z", "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYyMzMyOA==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447623328", "bodyText": ":D", "author": "benwtrent", "createdAt": "2020-06-30T11:52:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwMTYwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYzMzI3Mw==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447633273", "bodyText": "\ud83d\udc2e", "author": "droberts195", "createdAt": "2020-06-30T12:10:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwMTYwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwNjI0MA==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447606240", "bodyText": "nit: abbreviation looks strange if everything else is written out", "author": "hendrikmuhs", "createdAt": "2020-06-30T11:18:44Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelDefinitionDoc.java", "diffHunk": "@@ -48,6 +49,7 @@\n         parser.declareInt(TrainedModelDefinitionDoc.Builder::setCompressionVersion, COMPRESSION_VERSION);\n         parser.declareLong(TrainedModelDefinitionDoc.Builder::setDefinitionLength, DEFINITION_LENGTH);\n         parser.declareLong(TrainedModelDefinitionDoc.Builder::setTotalDefinitionLength, TOTAL_DEFINITION_LENGTH);\n+        parser.declareBoolean(TrainedModelDefinitionDoc.Builder::setEos, EOS);", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxMzUwOQ==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447613509", "bodyText": "should currentModelId be reset, too (after LOGGER.info)?", "author": "hendrikmuhs", "createdAt": "2020-06-30T11:33:05Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxMzg5Mg==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447613892", "bodyText": "why not initialize it empty?", "author": "hendrikmuhs", "createdAt": "2020-06-30T11:33:56Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY2MjIxOQ==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447662219", "bodyText": "it is empty?", "author": "benwtrent", "createdAt": "2020-06-30T13:00:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxMzg5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODI5OTYyMw==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r448299623", "bodyText": "well, ... I mean new AtomicReference<>()", "author": "hendrikmuhs", "createdAt": "2020-07-01T11:29:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxMzg5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxNTM0OA==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447615348", "bodyText": "I wonder if AtomicBoolean would be nicer with things like updateAndGet", "author": "hendrikmuhs", "createdAt": "2020-06-30T11:36:50Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxNjE0OQ==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447616149", "bodyText": "consider a constant for the timeout", "author": "hendrikmuhs", "createdAt": "2020-06-30T11:38:30Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));\n+        try {\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for chunked inference definition to be stored\"));\n+        }\n+    }\n+\n+    public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSize) {\n+        if (readyToStoreNewModel == false) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"new inference model is attempting to be stored before completion previous model storage\"\n+            ));\n+            return;\n+        }\n+        TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n+        CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n+        try {\n+            readyToStoreNewModel = false;\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxOTczNg==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447619736", "bodyText": "if this happens, it seems the persister can get stuck, because the doc gets never be stored and readyToStoreNewModel is never reset? Correct me if I am wrong.", "author": "hendrikmuhs", "createdAt": "2020-06-30T11:45:33Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));\n+        try {\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for chunked inference definition to be stored\"));\n+        }\n+    }\n+\n+    public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSize) {\n+        if (readyToStoreNewModel == false) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"new inference model is attempting to be stored before completion previous model storage\"\n+            ));\n+            return;\n+        }\n+        TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n+        CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n+        try {\n+            readyToStoreNewModel = false;\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for inference model metadata to be stored\", analytics.getId());", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYyMzcyOQ==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447623729", "bodyText": "yeah, it should reset. Good catch", "author": "benwtrent", "createdAt": "2020-06-30T11:53:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxOTczNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY3ODcxNw==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447678717", "bodyText": "I do not think it should switch back in this timeout check. If it times out, it just took a long time to persist.\nIf the persistence itself fails, then I will reset the boolean flag.\nSimilar behavior for the persistence of the definition docs. exception being, if the definition doc is the eos, then I will reset the flag.", "author": "benwtrent", "createdAt": "2020-06-30T13:24:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYxOTczNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwNjYzNg==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447606636", "bodyText": "Note there's a simple way to do ceil with integer arithmetic: (str.length() + chunkSize - 1) / chunkSize.", "author": "tveasey", "createdAt": "2020-06-30T11:19:30Z", "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {\n+\n+    private TrainedModelProvider trainedModelProvider;\n+\n+    @Before\n+    public void createComponents() throws Exception {\n+        trainedModelProvider = new TrainedModelProvider(client(), xContentRegistry());\n+        waitForMlTemplates();\n+    }\n+\n+    public void testStoreModelViaChunkedPersister() throws IOException {\n+        String modelId = \"stored-chunked-model\";\n+        DataFrameAnalyticsConfig analyticsConfig = new DataFrameAnalyticsConfig.Builder()\n+            .setId(modelId)\n+            .setSource(new DataFrameAnalyticsSource(new String[] {\"my_source\"}, null, null))\n+            .setDest(new DataFrameAnalyticsDest(\"my_dest\", null))\n+            .setAnalysis(new Regression(\"foo\"))\n+            .build();\n+        List<ExtractedField> extractedFieldList = Collections.singletonList(new DocValueField(\"foo\", Collections.emptySet()));\n+        TrainedModelConfig.Builder configBuilder = buildTrainedModelConfigBuilder(modelId);\n+        String compressedDefinition = configBuilder.build().getCompressedDefinition();\n+        int totalSize = compressedDefinition.length();\n+        List<String> chunks = chunkStringWithSize(compressedDefinition, totalSize/3);\n+\n+        ChunkedTrainedModelPersister persister = new ChunkedTrainedModelPersister(trainedModelProvider,\n+            analyticsConfig,\n+            new DataFrameAnalyticsAuditor(client(), \"test-node\"),\n+            (ex) -> { throw new ElasticsearchException(ex); },\n+            new ExtractedFields(extractedFieldList, Collections.emptyMap())\n+        );\n+\n+        //Accuracy for size is not tested here\n+        ModelSizeInfo modelSizeInfo = ModelSizeInfoTests.createRandom();\n+        persister.createAndIndexInferenceModelMetadata(modelSizeInfo);\n+        for (int i = 0; i < chunks.size(); i++) {\n+            persister.createAndIndexInferenceModelDoc(new TrainedModelDefinitionChunk(chunks.get(i), i, i == (chunks.size() - 1)));\n+        }\n+\n+        PlainActionFuture<Tuple<Long, Set<String>>> getIdsFuture = new PlainActionFuture<>();\n+        trainedModelProvider.expandIds(modelId + \"*\", false, PageParams.defaultParams(), Collections.emptySet(), getIdsFuture);\n+        Tuple<Long, Set<String>> ids = getIdsFuture.actionGet();\n+        assertThat(ids.v1(), equalTo(1L));\n+\n+        PlainActionFuture<TrainedModelConfig> getTrainedModelFuture = new PlainActionFuture<>();\n+        trainedModelProvider.getTrainedModel(ids.v2().iterator().next(), true, getTrainedModelFuture);\n+\n+        TrainedModelConfig storedConfig = getTrainedModelFuture.actionGet();\n+        assertThat(storedConfig.getCompressedDefinition(), equalTo(compressedDefinition));\n+        assertThat(storedConfig.getEstimatedOperations(), equalTo((long)modelSizeInfo.numOperations()));\n+        assertThat(storedConfig.getEstimatedHeapMemory(), equalTo(modelSizeInfo.ramBytesUsed()));\n+    }\n+\n+    private static TrainedModelConfig.Builder buildTrainedModelConfigBuilder(String modelId) {\n+        TrainedModelDefinition.Builder definitionBuilder = TrainedModelDefinitionTests.createRandomBuilder();\n+        long bytesUsed = definitionBuilder.build().ramBytesUsed();\n+        long operations = definitionBuilder.build().getTrainedModel().estimatedNumOperations();\n+        return TrainedModelConfig.builder()\n+            .setCreatedBy(\"ml_test\")\n+            .setParsedDefinition(TrainedModelDefinitionTests.createRandomBuilder(TargetType.REGRESSION))\n+            .setDescription(\"trained model config for test\")\n+            .setModelId(modelId)\n+            .setVersion(Version.CURRENT)\n+            .setLicenseLevel(License.OperationMode.PLATINUM.description())\n+            .setEstimatedHeapMemory(bytesUsed)\n+            .setEstimatedOperations(operations)\n+            .setInput(TrainedModelInputTests.createRandomInput());\n+    }\n+\n+    private static List<String> chunkStringWithSize(String str, int chunkSize) {\n+        List<String> subStrings = new ArrayList<>((int)Math.ceil(str.length()/(double)chunkSize));", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYwNzQ1MQ==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447607451", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    for (int i = 0; i < str.length();i += chunkSize) {\n          \n          \n            \n                    for (int i = 0; i < str.length(); i += chunkSize) {", "author": "tveasey", "createdAt": "2020-06-30T11:20:52Z", "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {\n+\n+    private TrainedModelProvider trainedModelProvider;\n+\n+    @Before\n+    public void createComponents() throws Exception {\n+        trainedModelProvider = new TrainedModelProvider(client(), xContentRegistry());\n+        waitForMlTemplates();\n+    }\n+\n+    public void testStoreModelViaChunkedPersister() throws IOException {\n+        String modelId = \"stored-chunked-model\";\n+        DataFrameAnalyticsConfig analyticsConfig = new DataFrameAnalyticsConfig.Builder()\n+            .setId(modelId)\n+            .setSource(new DataFrameAnalyticsSource(new String[] {\"my_source\"}, null, null))\n+            .setDest(new DataFrameAnalyticsDest(\"my_dest\", null))\n+            .setAnalysis(new Regression(\"foo\"))\n+            .build();\n+        List<ExtractedField> extractedFieldList = Collections.singletonList(new DocValueField(\"foo\", Collections.emptySet()));\n+        TrainedModelConfig.Builder configBuilder = buildTrainedModelConfigBuilder(modelId);\n+        String compressedDefinition = configBuilder.build().getCompressedDefinition();\n+        int totalSize = compressedDefinition.length();\n+        List<String> chunks = chunkStringWithSize(compressedDefinition, totalSize/3);\n+\n+        ChunkedTrainedModelPersister persister = new ChunkedTrainedModelPersister(trainedModelProvider,\n+            analyticsConfig,\n+            new DataFrameAnalyticsAuditor(client(), \"test-node\"),\n+            (ex) -> { throw new ElasticsearchException(ex); },\n+            new ExtractedFields(extractedFieldList, Collections.emptyMap())\n+        );\n+\n+        //Accuracy for size is not tested here\n+        ModelSizeInfo modelSizeInfo = ModelSizeInfoTests.createRandom();\n+        persister.createAndIndexInferenceModelMetadata(modelSizeInfo);\n+        for (int i = 0; i < chunks.size(); i++) {\n+            persister.createAndIndexInferenceModelDoc(new TrainedModelDefinitionChunk(chunks.get(i), i, i == (chunks.size() - 1)));\n+        }\n+\n+        PlainActionFuture<Tuple<Long, Set<String>>> getIdsFuture = new PlainActionFuture<>();\n+        trainedModelProvider.expandIds(modelId + \"*\", false, PageParams.defaultParams(), Collections.emptySet(), getIdsFuture);\n+        Tuple<Long, Set<String>> ids = getIdsFuture.actionGet();\n+        assertThat(ids.v1(), equalTo(1L));\n+\n+        PlainActionFuture<TrainedModelConfig> getTrainedModelFuture = new PlainActionFuture<>();\n+        trainedModelProvider.getTrainedModel(ids.v2().iterator().next(), true, getTrainedModelFuture);\n+\n+        TrainedModelConfig storedConfig = getTrainedModelFuture.actionGet();\n+        assertThat(storedConfig.getCompressedDefinition(), equalTo(compressedDefinition));\n+        assertThat(storedConfig.getEstimatedOperations(), equalTo((long)modelSizeInfo.numOperations()));\n+        assertThat(storedConfig.getEstimatedHeapMemory(), equalTo(modelSizeInfo.ramBytesUsed()));\n+    }\n+\n+    private static TrainedModelConfig.Builder buildTrainedModelConfigBuilder(String modelId) {\n+        TrainedModelDefinition.Builder definitionBuilder = TrainedModelDefinitionTests.createRandomBuilder();\n+        long bytesUsed = definitionBuilder.build().ramBytesUsed();\n+        long operations = definitionBuilder.build().getTrainedModel().estimatedNumOperations();\n+        return TrainedModelConfig.builder()\n+            .setCreatedBy(\"ml_test\")\n+            .setParsedDefinition(TrainedModelDefinitionTests.createRandomBuilder(TargetType.REGRESSION))\n+            .setDescription(\"trained model config for test\")\n+            .setModelId(modelId)\n+            .setVersion(Version.CURRENT)\n+            .setLicenseLevel(License.OperationMode.PLATINUM.description())\n+            .setEstimatedHeapMemory(bytesUsed)\n+            .setEstimatedOperations(operations)\n+            .setInput(TrainedModelInputTests.createRandomInput());\n+    }\n+\n+    private static List<String> chunkStringWithSize(String str, int chunkSize) {\n+        List<String> subStrings = new ArrayList<>((int)Math.ceil(str.length()/(double)chunkSize));\n+        for (int i = 0; i < str.length();i += chunkSize) {", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYyOTc1Ng==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447629756", "bodyText": "There's an asymmetry here with createAndIndexInferenceModelMetadata , which nicely separates setup and teardown from logic to write the docs, maybe it would be worth factoring this out into a storeTrainedModel function?", "author": "tveasey", "createdAt": "2020-06-30T12:04:24Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcyMzM5NA==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447723394", "bodyText": "will do", "author": "benwtrent", "createdAt": "2020-06-30T14:23:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYyOTc1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY0MDIwOQ==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447640209", "bodyText": "Maybe I missed them, but I don't see any tests for missing or truncated state. Maybe worth testing these error cases?", "author": "tveasey", "createdAt": "2020-06-30T12:22:49Z", "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersisterTests.java", "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.test.ESTestCase;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Mockito;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static org.hamcrest.Matchers.contains;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasKey;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.mockito.Matchers.any;\n+import static org.mockito.Matchers.eq;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+\n+public class ChunkedTrainedModelPersisterTests extends ESTestCase {", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcyMzMyNQ==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447723325", "bodyText": "The tests will be in the model provider test class. I will add one", "author": "benwtrent", "createdAt": "2020-06-30T14:23:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY0MDIwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYzMDU5Nw==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447630597", "bodyText": "FYI you can achieve the same with integer maths\n(str.length() + chunkSize -1) / chunkSize", "author": "davidkyle", "createdAt": "2020-06-30T12:05:53Z", "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/ChunkedTrainedMoodelPersisterIT.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.ml.integration;\n+\n+import org.elasticsearch.ElasticsearchException;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.support.PlainActionFuture;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.xcontent.NamedXContentRegistry;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.action.util.PageParams;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsDest;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsSource;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.MlInferenceNamedXContentProvider;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinition;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelDefinitionTests;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInputTests;\n+import org.elasticsearch.xpack.core.ml.inference.trainedmodel.TargetType;\n+import org.elasticsearch.xpack.ml.MlSingleNodeTestCase;\n+import org.elasticsearch.xpack.ml.dataframe.process.ChunkedTrainedModelPersister;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.DocValueField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.inference.modelsize.MlModelSizeNamedXContentProvider;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfoTests;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+import org.junit.Before;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Set;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class ChunkedTrainedMoodelPersisterIT extends MlSingleNodeTestCase {\n+\n+    private TrainedModelProvider trainedModelProvider;\n+\n+    @Before\n+    public void createComponents() throws Exception {\n+        trainedModelProvider = new TrainedModelProvider(client(), xContentRegistry());\n+        waitForMlTemplates();\n+    }\n+\n+    public void testStoreModelViaChunkedPersister() throws IOException {\n+        String modelId = \"stored-chunked-model\";\n+        DataFrameAnalyticsConfig analyticsConfig = new DataFrameAnalyticsConfig.Builder()\n+            .setId(modelId)\n+            .setSource(new DataFrameAnalyticsSource(new String[] {\"my_source\"}, null, null))\n+            .setDest(new DataFrameAnalyticsDest(\"my_dest\", null))\n+            .setAnalysis(new Regression(\"foo\"))\n+            .build();\n+        List<ExtractedField> extractedFieldList = Collections.singletonList(new DocValueField(\"foo\", Collections.emptySet()));\n+        TrainedModelConfig.Builder configBuilder = buildTrainedModelConfigBuilder(modelId);\n+        String compressedDefinition = configBuilder.build().getCompressedDefinition();\n+        int totalSize = compressedDefinition.length();\n+        List<String> chunks = chunkStringWithSize(compressedDefinition, totalSize/3);\n+\n+        ChunkedTrainedModelPersister persister = new ChunkedTrainedModelPersister(trainedModelProvider,\n+            analyticsConfig,\n+            new DataFrameAnalyticsAuditor(client(), \"test-node\"),\n+            (ex) -> { throw new ElasticsearchException(ex); },\n+            new ExtractedFields(extractedFieldList, Collections.emptyMap())\n+        );\n+\n+        //Accuracy for size is not tested here\n+        ModelSizeInfo modelSizeInfo = ModelSizeInfoTests.createRandom();\n+        persister.createAndIndexInferenceModelMetadata(modelSizeInfo);\n+        for (int i = 0; i < chunks.size(); i++) {\n+            persister.createAndIndexInferenceModelDoc(new TrainedModelDefinitionChunk(chunks.get(i), i, i == (chunks.size() - 1)));\n+        }\n+\n+        PlainActionFuture<Tuple<Long, Set<String>>> getIdsFuture = new PlainActionFuture<>();\n+        trainedModelProvider.expandIds(modelId + \"*\", false, PageParams.defaultParams(), Collections.emptySet(), getIdsFuture);\n+        Tuple<Long, Set<String>> ids = getIdsFuture.actionGet();\n+        assertThat(ids.v1(), equalTo(1L));\n+\n+        PlainActionFuture<TrainedModelConfig> getTrainedModelFuture = new PlainActionFuture<>();\n+        trainedModelProvider.getTrainedModel(ids.v2().iterator().next(), true, getTrainedModelFuture);\n+\n+        TrainedModelConfig storedConfig = getTrainedModelFuture.actionGet();\n+        assertThat(storedConfig.getCompressedDefinition(), equalTo(compressedDefinition));\n+        assertThat(storedConfig.getEstimatedOperations(), equalTo((long)modelSizeInfo.numOperations()));\n+        assertThat(storedConfig.getEstimatedHeapMemory(), equalTo(modelSizeInfo.ramBytesUsed()));\n+    }\n+\n+    private static TrainedModelConfig.Builder buildTrainedModelConfigBuilder(String modelId) {\n+        TrainedModelDefinition.Builder definitionBuilder = TrainedModelDefinitionTests.createRandomBuilder();\n+        long bytesUsed = definitionBuilder.build().ramBytesUsed();\n+        long operations = definitionBuilder.build().getTrainedModel().estimatedNumOperations();\n+        return TrainedModelConfig.builder()\n+            .setCreatedBy(\"ml_test\")\n+            .setParsedDefinition(TrainedModelDefinitionTests.createRandomBuilder(TargetType.REGRESSION))\n+            .setDescription(\"trained model config for test\")\n+            .setModelId(modelId)\n+            .setVersion(Version.CURRENT)\n+            .setLicenseLevel(License.OperationMode.PLATINUM.description())\n+            .setEstimatedHeapMemory(bytesUsed)\n+            .setEstimatedOperations(operations)\n+            .setInput(TrainedModelInputTests.createRandomInput());\n+    }\n+\n+    private static List<String> chunkStringWithSize(String str, int chunkSize) {\n+        List<String> subStrings = new ArrayList<>((int)Math.ceil(str.length()/(double)chunkSize));", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcyMzEwOA==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447723108", "bodyText": "will change it :)", "author": "benwtrent", "createdAt": "2020-06-30T14:22:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzYzMDU5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY0ODIyMA==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447648220", "bodyText": "Log the exception also\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                        refreshLatch));\n          \n          \n            \n            e -> LOGGER.warn(\"new ParameterizedMessage([{}] failed to refresh inference index after model store\", analytics.getId()), e),", "author": "davidkyle", "createdAt": "2020-06-30T12:37:03Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY1NTM1Mg==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447655352", "bodyText": "The log level shouldn't be any higher than debug.\nSame for the finished stored trained model definition chunks with id  message above", "author": "davidkyle", "createdAt": "2020-06-30T12:48:48Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));\n+        try {\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for chunked inference definition to be stored\"));\n+        }\n+    }\n+\n+    public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSize) {\n+        if (readyToStoreNewModel == false) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"new inference model is attempting to be stored before completion previous model storage\"\n+            ));\n+            return;\n+        }\n+        TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n+        CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n+        try {\n+            readyToStoreNewModel = false;\n+            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for inference model metadata to be stored\", analytics.getId());\n+            }\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for inference model metadata to be stored\"));\n+        }\n+    }\n+\n+    private CountDownLatch storeTrainedModelMetadata(TrainedModelConfig trainedModelConfig) {\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Boolean> storeListener = ActionListener.wrap(\n+            aBoolean -> {\n+                if (aBoolean == false) {\n+                    LOGGER.error(\"[{}] Storing trained model metadata responded false\", analytics.getId());\n+                    failureHandler.accept(ExceptionsHelper.serverError(\"storing trained model responded false\"));\n+                } else {\n+                    LOGGER.info(\"[{}] Stored trained model metadata with id [{}]\", analytics.getId(), trainedModelConfig.getModelId());", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY4NzYzMw==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447687633", "bodyText": "Ok the equivalent message before was logged at info but lets consider if this is necessary", "author": "davidkyle", "createdAt": "2020-06-30T13:36:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY1NTM1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcyMjM0MA==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447722340", "bodyText": "I am making the individual messages all DEBUG. But when EOS is read, I am logging that as INFO and simply stating that persistence has finished.", "author": "benwtrent", "createdAt": "2020-06-30T14:21:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY1NTM1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY4MTExMw==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447681113", "bodyText": "Add a boolean parameter here to refresh the index when the last doc is indexed that way you don't have to call  provider.refreshInferenceIndex() in the listener", "author": "davidkyle", "createdAt": "2020-06-30T13:27:41Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private volatile boolean readyToStoreNewModel = true;\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = new CountDownLatch(1);\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+\n+                if (trainedModelDefinitionChunk.isEos()) {\n+                    readyToStoreNewModel = true;\n+                    LOGGER.info(\n+                        \"[{}] finished stored trained model definition chunks with id [{}]\",\n+                        analytics.getId(),\n+                        this.currentModelId.get());\n+                    auditor.info(analytics.getId(), \"Stored trained model with id [\" + this.currentModelId.get() + \"]\");\n+                    CountDownLatch refreshLatch = new CountDownLatch(1);\n+                    provider.refreshInferenceIndex(\n+                        new LatchedActionListener<>(ActionListener.wrap(\n+                            refreshResponse -> LOGGER.debug(() -> new ParameterizedMessage(\n+                                \"[{}] refreshed inference index after model store\",\n+                                analytics.getId()\n+                            )),\n+                            e -> LOGGER.warn(\"[{}] failed to refresh inference index after model store\", analytics.getId())),\n+                            refreshLatch));\n+                    try {\n+                        if (refreshLatch.await(30, TimeUnit.SECONDS) == false) {\n+                            LOGGER.error(\"[{}] Timed out (30s) waiting for index refresh\", analytics.getId());\n+                        }\n+                    } catch (InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+            },\n+            e -> failureHandler.accept(ExceptionsHelper.serverError(\"error storing trained model definition chunk [{}] with id [{}]\", e,\n+                trainedModelDefinitionDoc.getModelId(), trainedModelDefinitionDoc.getDocNum()))\n+        );\n+        provider.storeTrainedModelDefinitionDoc(trainedModelDefinitionDoc, new LatchedActionListener<>(storeListener, latch));", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcyMjkwMg==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447722902", "bodyText": "I am refactoring this so that the latched listener is the refresh listener and the provider listener always calls the refresh listener (with null when we don't refresh).", "author": "benwtrent", "createdAt": "2020-06-30T14:22:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzY4MTExMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcwMTc5OA==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447701798", "bodyText": "Can the methods getTrainedModelForInference and getTrainedModel be refactored to avoid this duplication?", "author": "davidkyle", "createdAt": "2020-06-30T13:55:15Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/inference/persistence/TrainedModelProvider.java", "diffHunk": "@@ -363,10 +452,22 @@ public void getTrainedModel(final String modelId, final boolean includeDefinitio\n                         String compressedString = docs.stream()\n                             .map(TrainedModelDefinitionDoc::getCompressedString)\n                             .collect(Collectors.joining());\n-                        if (compressedString.length() != docs.get(0).getTotalDefinitionLength()) {\n-                            listener.onFailure(ExceptionsHelper.serverError(\n-                                Messages.getMessage(Messages.MODEL_DEFINITION_TRUNCATED, modelId)));\n-                            return;\n+                        // BWC for when we tracked the total definition length\n+                        // TODO: remove in 9\n+                        if (docs.get(0).getTotalDefinitionLength() != null) {", "originalCommit": "8a340bfac24b19cbb32170f16a8d7323ae296854", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcyMjk4NA==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447722984", "bodyText": "definitely", "author": "benwtrent", "createdAt": "2020-06-30T14:22:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzcwMTc5OA=="}], "type": "inlineReview"}, {"oid": "b20fb0586874ab6bdd92e4ccda019245c25a708a", "url": "https://github.com/elastic/elasticsearch/commit/b20fb0586874ab6bdd92e4ccda019245c25a708a", "message": "addressing pr comments", "committedDate": "2020-06-30T14:36:45Z", "type": "commit"}, {"oid": "3ad327ef45cacc5c4b63b62d33a6ea799359f34d", "url": "https://github.com/elastic/elasticsearch/commit/3ad327ef45cacc5c4b63b62d33a6ea799359f34d", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-analytics-handle-compressed-model-stream", "committedDate": "2020-06-30T14:36:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0Nzc0NzQ5Ng==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r447747496", "bodyText": "Is this valid here? i.e. should you be allowing this to start storing new models before logging, etc. Seems like there is a race to reset the currentModelId.", "author": "tveasey", "createdAt": "2020-06-30T14:53:37Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -135,29 +105,86 @@ public void createAndIndexInferenceModelMetadata(ModelSizeInfo inferenceModelSiz\n         TrainedModelConfig trainedModelConfig = createTrainedModelConfig(inferenceModelSize);\n         CountDownLatch latch = storeTrainedModelMetadata(trainedModelConfig);\n         try {\n-            readyToStoreNewModel = false;\n-            if (latch.await(30, TimeUnit.SECONDS) == false) {\n+            if (latch.await(STORE_TIMEOUT_SEC, TimeUnit.SECONDS) == false) {\n                 LOGGER.error(\"[{}] Timed out (30s) waiting for inference model metadata to be stored\", analytics.getId());\n             }\n         } catch (InterruptedException e) {\n             Thread.currentThread().interrupt();\n+            this.readyToStoreNewModel.set(true);\n             failureHandler.accept(ExceptionsHelper.serverError(\"interrupted waiting for inference model metadata to be stored\"));\n         }\n     }\n \n+    private CountDownLatch storeTrainedModelDoc(TrainedModelDefinitionDoc trainedModelDefinitionDoc) {\n+        CountDownLatch latch = new CountDownLatch(1);\n+\n+        // Latch is attached to this action as it is the last one to execute.\n+        ActionListener<RefreshResponse> refreshListener = new LatchedActionListener<>(ActionListener.wrap(\n+            refreshed -> {\n+                if (refreshed != null) {\n+                    LOGGER.debug(() -> new ParameterizedMessage(\n+                        \"[{}] refreshed inference index after model store\",\n+                        analytics.getId()\n+                    ));\n+                }\n+            },\n+            e -> LOGGER.warn(\n+                new ParameterizedMessage(\"[{}] failed to refresh inference index after model store\", analytics.getId()),\n+                e)\n+        ), latch);\n+\n+        // First, store the model and refresh is necessary\n+        ActionListener<Void> storeListener = ActionListener.wrap(\n+            r -> {\n+                LOGGER.debug(() -> new ParameterizedMessage(\n+                    \"[{}] stored trained model definition chunk [{}] [{}]\",\n+                    analytics.getId(),\n+                    trainedModelDefinitionDoc.getModelId(),\n+                    trainedModelDefinitionDoc.getDocNum()));\n+                if (trainedModelDefinitionDoc.isEos() == false) {\n+                    refreshListener.onResponse(null);\n+                    return;\n+                }\n+                readyToStoreNewModel.set(true);", "originalCommit": "b20fb0586874ab6bdd92e4ccda019245c25a708a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "398d9f94f7e200f968f9f5411c690c62cd7bd711", "url": "https://github.com/elastic/elasticsearch/commit/398d9f94f7e200f968f9f5411c690c62cd7bd711", "message": "moving boolean flag", "committedDate": "2020-06-30T14:58:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIwOTAxNw==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r448209017", "bodyText": "IntStream.range is end exclusive so we will never get to i == chunks.size() - 1\nShould it be set to false as Eos is set on the last doc in the list in line 223", "author": "davidkyle", "createdAt": "2020-07-01T08:39:16Z", "path": "x-pack/plugin/ml/src/internalClusterTest/java/org/elasticsearch/xpack/ml/integration/TrainedModelProviderIT.java", "diffHunk": "@@ -195,6 +198,51 @@ public void testGetTruncatedModelDefinition() throws Exception {\n         assertThat(exceptionHolder.get().getMessage(), equalTo(Messages.getMessage(Messages.MODEL_DEFINITION_TRUNCATED, modelId)));\n     }\n \n+    public void testGetTruncatedModelDefinition() throws Exception {\n+        String modelId = \"test-get-truncated-model-config\";\n+        TrainedModelConfig config = buildTrainedModelConfig(modelId);\n+        AtomicReference<Boolean> putConfigHolder = new AtomicReference<>();\n+        AtomicReference<Exception> exceptionHolder = new AtomicReference<>();\n+\n+        blockingCall(listener -> trainedModelProvider.storeTrainedModel(config, listener), putConfigHolder, exceptionHolder);\n+        assertThat(putConfigHolder.get(), is(true));\n+        assertThat(exceptionHolder.get(), is(nullValue()));\n+\n+        List<String> chunks = chunkStringWithSize(config.getCompressedDefinition(), config.getCompressedDefinition().length()/3);\n+\n+        List<TrainedModelDefinitionDoc.Builder> docBuilders = IntStream.range(0, chunks.size() - 1)\n+            .mapToObj(i -> new TrainedModelDefinitionDoc.Builder()\n+                .setDocNum(i)\n+                .setCompressedString(chunks.get(i))\n+                .setCompressionVersion(TrainedModelConfig.CURRENT_DEFINITION_COMPRESSION_VERSION)\n+                .setDefinitionLength(chunks.get(i).length())\n+                .setEos(i == chunks.size() - 1)", "originalCommit": "398d9f94f7e200f968f9f5411c690c62cd7bd711", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "caed31555c00c2060cfb0530ce3ed0647660d076", "url": "https://github.com/elastic/elasticsearch/commit/caed31555c00c2060cfb0530ce3ed0647660d076", "message": "fixing test", "committedDate": "2020-07-01T10:52:37Z", "type": "commit"}, {"oid": "dc25e38cba9eee95b97c7952ef6a2c2efa9e394c", "url": "https://github.com/elastic/elasticsearch/commit/dc25e38cba9eee95b97c7952ef6a2c2efa9e394c", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-analytics-handle-compressed-model-stream", "committedDate": "2020-07-01T11:15:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMwMTM1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r448301359", "bodyText": "nit: now that STORE_TIMEOUT_SEC is a constant, the log message can use it as argument (in other places, too)", "author": "hendrikmuhs", "createdAt": "2020-07-01T11:33:35Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/ChunkedTrainedModelPersister.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process;\n+\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.elasticsearch.Version;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.LatchedActionListener;\n+import org.elasticsearch.action.admin.indices.refresh.RefreshResponse;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.xcontent.XContentHelper;\n+import org.elasticsearch.common.xcontent.json.JsonXContent;\n+import org.elasticsearch.license.License;\n+import org.elasticsearch.xpack.core.ml.dataframe.DataFrameAnalyticsConfig;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Classification;\n+import org.elasticsearch.xpack.core.ml.dataframe.analyses.Regression;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelInput;\n+import org.elasticsearch.xpack.core.ml.utils.ExceptionsHelper;\n+import org.elasticsearch.xpack.core.security.user.XPackUser;\n+import org.elasticsearch.xpack.ml.dataframe.process.results.TrainedModelDefinitionChunk;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedField;\n+import org.elasticsearch.xpack.ml.extractor.ExtractedFields;\n+import org.elasticsearch.xpack.ml.extractor.MultiField;\n+import org.elasticsearch.xpack.ml.inference.modelsize.ModelSizeInfo;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelProvider;\n+import org.elasticsearch.xpack.ml.notifications.DataFrameAnalyticsAuditor;\n+\n+import java.time.Instant;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+public class ChunkedTrainedModelPersister {\n+\n+    private static final Logger LOGGER = LogManager.getLogger(ChunkedTrainedModelPersister.class);\n+    private static final int STORE_TIMEOUT_SEC = 30;\n+    private final TrainedModelProvider provider;\n+    private final AtomicReference<String> currentModelId;\n+    private final DataFrameAnalyticsConfig analytics;\n+    private final DataFrameAnalyticsAuditor auditor;\n+    private final Consumer<Exception> failureHandler;\n+    private final ExtractedFields extractedFields;\n+    private final AtomicBoolean readyToStoreNewModel = new AtomicBoolean(true);\n+\n+    public ChunkedTrainedModelPersister(TrainedModelProvider provider,\n+                                        DataFrameAnalyticsConfig analytics,\n+                                        DataFrameAnalyticsAuditor auditor,\n+                                        Consumer<Exception> failureHandler,\n+                                        ExtractedFields extractedFields) {\n+        this.provider = provider;\n+        this.currentModelId = new AtomicReference<>(\"\");\n+        this.analytics = analytics;\n+        this.auditor = auditor;\n+        this.failureHandler = failureHandler;\n+        this.extractedFields = extractedFields;\n+    }\n+\n+    public void createAndIndexInferenceModelDoc(TrainedModelDefinitionChunk trainedModelDefinitionChunk) {\n+        if (Strings.isNullOrEmpty(this.currentModelId.get())) {\n+            failureHandler.accept(ExceptionsHelper.serverError(\n+                \"chunked inference model definition is attempting to be stored before trained model configuration\"\n+            ));\n+            return;\n+        }\n+        TrainedModelDefinitionDoc trainedModelDefinitionDoc = trainedModelDefinitionChunk.createTrainedModelDoc(this.currentModelId.get());\n+\n+        CountDownLatch latch = storeTrainedModelDoc(trainedModelDefinitionDoc);\n+        try {\n+            if (latch.await(STORE_TIMEOUT_SEC, TimeUnit.SECONDS) == false) {\n+                LOGGER.error(\"[{}] Timed out (30s) waiting for chunked inference definition to be stored\", analytics.getId());", "originalCommit": "dc25e38cba9eee95b97c7952ef6a2c2efa9e394c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMwNTYyOQ==", "url": "https://github.com/elastic/elasticsearch/pull/58009#discussion_r448305629", "bodyText": "do we need a 3rd state (null)?\nin code it looks like null and false are false.\nit seems simpler to me to use boolean and handle null as part of parsing", "author": "hendrikmuhs", "createdAt": "2020-07-01T11:42:46Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/dataframe/process/results/TrainedModelDefinitionChunk.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.dataframe.process.results;\n+\n+import org.elasticsearch.common.ParseField;\n+import org.elasticsearch.common.xcontent.ConstructingObjectParser;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.xpack.core.ml.inference.TrainedModelConfig;\n+import org.elasticsearch.xpack.ml.inference.persistence.TrainedModelDefinitionDoc;\n+\n+import java.io.IOException;\n+import java.util.Objects;\n+\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.constructorArg;\n+import static org.elasticsearch.common.xcontent.ConstructingObjectParser.optionalConstructorArg;\n+\n+public class TrainedModelDefinitionChunk implements ToXContentObject {\n+\n+    private static final ParseField DEFINITION = new ParseField(\"definition\");\n+    private static final ParseField DOC_NUM = new ParseField(\"doc_num\");\n+    private static final ParseField EOS = new ParseField(\"eos\");\n+\n+    public static final ConstructingObjectParser<TrainedModelDefinitionChunk, Void> PARSER = new ConstructingObjectParser<>(\n+        \"chunked_trained_model_definition\",\n+        a -> new TrainedModelDefinitionChunk((String) a[0], (Integer) a[1], (Boolean) a[2]));\n+\n+    static {\n+        PARSER.declareString(constructorArg(), DEFINITION);\n+        PARSER.declareInt(constructorArg(), DOC_NUM);\n+        PARSER.declareBoolean(optionalConstructorArg(), EOS);\n+    }\n+\n+    private final String definition;\n+    private final int docNum;\n+    private final Boolean eos;", "originalCommit": "dc25e38cba9eee95b97c7952ef6a2c2efa9e394c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}