{"pr_number": 52039, "pr_title": "Upgrade to lucene-8.5.0-snapshot-d62f6307658", "pr_createdAt": "2020-02-07T11:34:06Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/52039", "timeline": [{"oid": "b780bbf72b50feca415001f9eca68c34e4d36246", "url": "https://github.com/elastic/elasticsearch/commit/b780bbf72b50feca415001f9eca68c34e4d36246", "message": "upgrade to lucene-snapshot-d62f6307658", "committedDate": "2020-02-07T11:04:59Z", "type": "commit"}, {"oid": "1f9334de4305c717d7e2af04f5685ed77faf7820", "url": "https://github.com/elastic/elasticsearch/commit/1f9334de4305c717d7e2af04f5685ed77faf7820", "message": "compile error and unused import", "committedDate": "2020-02-07T11:23:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM1NjIxMQ==", "url": "https://github.com/elastic/elasticsearch/pull/52039#discussion_r376356211", "bodyText": "@jpountz I am not sure about this change, and it seems the extension name has been changed. I think there are failures related with this change.", "author": "iverase", "createdAt": "2020-02-07T12:01:20Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/snapshots/SourceOnlySnapshot.java", "diffHunk": "@@ -51,7 +51,7 @@\n import java.util.function.Supplier;\n \n import static org.apache.lucene.codecs.compressing.CompressingStoredFieldsWriter.FIELDS_EXTENSION;\n-import static org.apache.lucene.codecs.compressing.CompressingStoredFieldsWriter.FIELDS_INDEX_EXTENSION;\n+import static org.apache.lucene.codecs.compressing.CompressingStoredFieldsWriter.INDEX_EXTENSION_PREFIX;", "originalCommit": "1f9334de4305c717d7e2af04f5685ed77faf7820", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM4OTYyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/52039#discussion_r376389621", "bodyText": "Can you try this patch?\ndiff --git a/x-pack/plugin/core/src/main/java/org/elasticsearch/snapshots/SourceOnlySnapshot.java b/x-pack/plugin/core/src/main/java/org/elasticsearch/snapshots/SourceOnlySnapshot.java\nindex 25f8a73..8959a77 100644\n--- a/x-pack/plugin/core/src/main/java/org/elasticsearch/snapshots/SourceOnlySnapshot.java\n+++ b/x-pack/plugin/core/src/main/java/org/elasticsearch/snapshots/SourceOnlySnapshot.java\n@@ -44,15 +44,13 @@ import java.io.ByteArrayOutputStream;\n import java.io.IOException;\n import java.io.PrintStream;\n import java.util.ArrayList;\n+import java.util.Arrays;\n import java.util.Collections;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.function.Supplier;\n \n-import static org.apache.lucene.codecs.compressing.CompressingStoredFieldsWriter.FIELDS_EXTENSION;\n-import static org.apache.lucene.codecs.compressing.CompressingStoredFieldsWriter.INDEX_EXTENSION_PREFIX;\n-\n public class SourceOnlySnapshot {\n     private final Directory targetDirectory;\n     private final Supplier<Query> deleteByQuerySupplier;\n@@ -206,14 +204,18 @@ public class SourceOnlySnapshot {\n             FieldInfos newFieldInfos = new FieldInfos(fieldInfoCopy.toArray(new FieldInfo[0]));\n             codec.fieldInfosFormat().write(trackingDir, newSegmentInfo, segmentSuffix, newFieldInfos, IOContext.DEFAULT);\n             newInfo.setFieldInfosFiles(trackingDir.getCreatedFiles());\n-            String idxFile = IndexFileNames.segmentFileName(newSegmentInfo.name, segmentSuffix, INDEX_EXTENSION_PREFIX);\n-            String dataFile = IndexFileNames.segmentFileName(newSegmentInfo.name, segmentSuffix, FIELDS_EXTENSION);\n+            String idxFile = IndexFileNames.segmentFileName(newSegmentInfo.name, segmentSuffix, \"fdx\");\n+            String dataFile = IndexFileNames.segmentFileName(newSegmentInfo.name, segmentSuffix, \"fdt\");\n+            String metaFile = IndexFileNames.segmentFileName(newSegmentInfo.name, segmentSuffix, \"fdm\"); // new since Lucene 8.5\n             Directory sourceDir = newSegmentInfo.dir;\n             if (si.getUseCompoundFile()) {\n                 sourceDir = codec.compoundFormat().getCompoundReader(sourceDir, si, IOContext.DEFAULT);\n             }\n             trackingDir.copyFrom(sourceDir, idxFile, idxFile, IOContext.DEFAULT);\n             trackingDir.copyFrom(sourceDir, dataFile, dataFile, IOContext.DEFAULT);\n+            if (Arrays.asList(sourceDir.listAll()).contains(metaFile)) { // only exists for Lucene 8.5+ indices\n+                trackingDir.copyFrom(sourceDir, dataFile, metaFile, IOContext.DEFAULT);\n+            }\n             if (sourceDir != newSegmentInfo.dir) {\n                 sourceDir.close();\n             }", "author": "jpountz", "createdAt": "2020-02-07T13:30:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM1NjIxMQ=="}], "type": "inlineReview"}, {"oid": "1663d2648a06c8e882d194ffb5b98c38a5c45b16", "url": "https://github.com/elastic/elasticsearch/commit/1663d2648a06c8e882d194ffb5b98c38a5c45b16", "message": "Adjust files created by new algorithm. I wonder if / how to support\nbackwards compatibility", "committedDate": "2020-02-07T13:35:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM5MzkxNQ==", "url": "https://github.com/elastic/elasticsearch/pull/52039#discussion_r376393915", "bodyText": "I believe it has to be done conditionally in order to support old indices.", "author": "jpountz", "createdAt": "2020-02-07T13:39:24Z", "path": "x-pack/plugin/core/src/main/java/org/elasticsearch/snapshots/SourceOnlySnapshot.java", "diffHunk": "@@ -206,13 +208,15 @@ private SegmentCommitInfo syncSegment(SegmentCommitInfo segmentCommitInfo, LiveD\n             FieldInfos newFieldInfos = new FieldInfos(fieldInfoCopy.toArray(new FieldInfo[0]));\n             codec.fieldInfosFormat().write(trackingDir, newSegmentInfo, segmentSuffix, newFieldInfos, IOContext.DEFAULT);\n             newInfo.setFieldInfosFiles(trackingDir.getCreatedFiles());\n-            String idxFile = IndexFileNames.segmentFileName(newSegmentInfo.name, segmentSuffix, INDEX_EXTENSION_PREFIX);\n+            String idxFile = IndexFileNames.segmentFileName(newSegmentInfo.name, segmentSuffix, INDEX_EXTENSION_PREFIX + FIELDS_INDEX_EXTENSION_SUFFIX);\n+            String metadataFile = IndexFileNames.segmentFileName(newSegmentInfo.name, segmentSuffix, INDEX_EXTENSION_PREFIX + FIELDS_META_EXTENSION_SUFFIX);\n             String dataFile = IndexFileNames.segmentFileName(newSegmentInfo.name, segmentSuffix, FIELDS_EXTENSION);\n             Directory sourceDir = newSegmentInfo.dir;\n             if (si.getUseCompoundFile()) {\n                 sourceDir = codec.compoundFormat().getCompoundReader(sourceDir, si, IOContext.DEFAULT);\n             }\n             trackingDir.copyFrom(sourceDir, idxFile, idxFile, IOContext.DEFAULT);\n+            trackingDir.copyFrom(sourceDir, metadataFile, metadataFile, IOContext.DEFAULT);", "originalCommit": "1663d2648a06c8e882d194ffb5b98c38a5c45b16", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjM5NDA2OA==", "url": "https://github.com/elastic/elasticsearch/pull/52039#discussion_r376394068", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        // we processed the segments_N file plus _1.si, _1.fdx, _1.fnm, _1.fdt, , _1.fdx\n          \n          \n            \n                        // we processed the segments_N file plus _1.si, _1.fdx, _1.fnm, _1.fdt, _1.fdm, _1.fdx", "author": "jpountz", "createdAt": "2020-02-07T13:39:41Z", "path": "x-pack/plugin/core/src/test/java/org/elasticsearch/snapshots/SourceOnlySnapshotShardTests.java", "diffHunk": "@@ -147,10 +147,10 @@ public void testIncrementalSnapshot() throws IOException {\n                 snapshotRef.getIndexCommit(), indexShardSnapshotStatus, true, Collections.emptyMap(), future));\n             shardGeneration = future.actionGet();\n             IndexShardSnapshotStatus.Copy copy = indexShardSnapshotStatus.asCopy();\n-            // we processed the segments_N file plus _1.si, _1.fdx, _1.fnm, _1.fdt\n-            assertEquals(5, copy.getIncrementalFileCount());\n+            // we processed the segments_N file plus _1.si, _1.fdx, _1.fnm, _1.fdt, , _1.fdx", "originalCommit": "1663d2648a06c8e882d194ffb5b98c38a5c45b16", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "36a29e0552595336c8c595676724fa9cc51a868c", "url": "https://github.com/elastic/elasticsearch/commit/36a29e0552595336c8c595676724fa9cc51a868c", "message": "add conditional in new file as only exists for new indices.", "committedDate": "2020-02-07T13:48:24Z", "type": "commit"}, {"oid": "1f720cdb4cce9b17f3c4b98c14b116f8d71e735e", "url": "https://github.com/elastic/elasticsearch/commit/1f720cdb4cce9b17f3c4b98c14b116f8d71e735e", "message": "update comments to new number of files", "committedDate": "2020-02-07T13:51:42Z", "type": "commit"}, {"oid": "32b2839ab77d652f7d71be24279c6d4112ded07c", "url": "https://github.com/elastic/elasticsearch/commit/32b2839ab77d652f7d71be24279c6d4112ded07c", "message": "update number of files of yaml test. I still think it can run in\ndifferent versions so it might not be the proper fix.", "committedDate": "2020-02-07T15:16:17Z", "type": "commit"}, {"oid": "f9f582bf7205ee2a6caef354ae3e7f8d17752524", "url": "https://github.com/elastic/elasticsearch/commit/f9f582bf7205ee2a6caef354ae3e7f8d17752524", "message": "make sure the test does not fail in mixed version cluster", "committedDate": "2020-02-07T15:37:43Z", "type": "commit"}]}