{"pr_number": 55693, "pr_title": "[DOCS] Reformat `stemmer` token filter", "pr_createdAt": "2020-04-23T20:01:55Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/55693", "timeline": [{"oid": "4e41b4f0a8d231caa02a988e2ff4324a833295a5", "url": "https://github.com/elastic/elasticsearch/commit/4e41b4f0a8d231caa02a988e2ff4324a833295a5", "message": "[DOCS] Reformat `stemmer` token filter\n\nMakes the following changes to the `stemmer` token filter docs:\n\n* Adds detailed analyze example\n* Rewrites parameter definitions\n* Adds custom analyzer example\n* Adds a `language` value for the `estonian` stemmer\n* Reorders the `language` values to show recommended algorithms first,\n  followed by other values alphabetically", "committedDate": "2020-04-23T19:59:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDA4NjQyOQ==", "url": "https://github.com/elastic/elasticsearch/pull/55693#discussion_r414086429", "bodyText": "I can xref algorithmic stemming with https://github.com/elastic/elasticsearch/pull/55156/files#diff-8dbd6670213faa5eccc209176d0dd22bR33 when #55156 is merged.", "author": "jrodewig", "createdAt": "2020-04-23T20:02:43Z", "path": "docs/reference/analysis/tokenfilters/stemmer-tokenfilter.asciidoc", "diffHunk": "@@ -4,189 +4,278 @@\n <titleabbrev>Stemmer</titleabbrev>\n ++++\n \n-// Adds attribute for the 'minimal_portuguese' stemmer values link.\n-// This link contains ~, which is converted to subscript.\n-// This attribute prevents that substitution.\n-// See https://github.com/asciidoctor/asciidoctor/wiki/How-to-prevent-URLs-containing-formatting-characters-from-getting-mangled\n-:min-pt-stemmer-values-url: http://www.inf.ufrgs.br/~buriol/papers/Orengo_CLEF07.pdf\n+Provides algorithmic stemming for several languages, some with additional", "originalCommit": "4e41b4f0a8d231caa02a988e2ff4324a833295a5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDQxMDAzNQ==", "url": "https://github.com/elastic/elasticsearch/pull/55693#discussion_r414410035", "bodyText": "\ud83d\udc4d", "author": "romseygeek", "createdAt": "2020-04-24T08:54:43Z", "path": "docs/reference/analysis/tokenfilters/stemmer-tokenfilter.asciidoc", "diffHunk": "@@ -4,189 +4,278 @@\n <titleabbrev>Stemmer</titleabbrev>\n ++++\n \n-// Adds attribute for the 'minimal_portuguese' stemmer values link.\n-// This link contains ~, which is converted to subscript.\n-// This attribute prevents that substitution.\n-// See https://github.com/asciidoctor/asciidoctor/wiki/How-to-prevent-URLs-containing-formatting-characters-from-getting-mangled\n-:min-pt-stemmer-values-url: http://www.inf.ufrgs.br/~buriol/papers/Orengo_CLEF07.pdf\n+Provides algorithmic stemming for several languages, some with additional\n+variants. For a list of supported languages, see the\n+<<analysis-stemmer-tokenfilter-language-parm,`language`>> parameter.\n \n-A filter that provides access to (almost) all of the available stemming token\n-filters through a single unified interface. For example:\n+When not customized, the filter uses the\n+http://snowball.tartarus.org/algorithms/porter/stemmer.html[porter stemming\n+algorithm] for English.\n+\n+[[analysis-stemmer-graph-tokenfilter-analyze-ex]]\n+==== Example\n+\n+The following analyze API request uses the `stemmer` filter's default porter\n+stemming algorithm to stem `the foxes jumping quickly` to `the fox jump\n+quickli`:\n \n [source,console]\n---------------------------------------------------\n+----\n+GET /_analyze\n+{\n+  \"tokenizer\": \"standard\",\n+  \"filter\": [ \"stemmer\" ],\n+  \"text\": \"the foxes jumping quickly\"\n+}\n+----\n+\n+The filter produces the following tokens:\n+\n+[source,text]\n+----\n+[ the, fox, jump, quickli ]\n+----\n+\n+////\n+[source,console-result]\n+----\n+{\n+  \"tokens\": [\n+    {\n+      \"token\": \"the\",\n+      \"start_offset\": 0,\n+      \"end_offset\": 3,\n+      \"type\": \"<ALPHANUM>\",\n+      \"position\": 0\n+    },\n+    {\n+      \"token\": \"fox\",\n+      \"start_offset\": 4,\n+      \"end_offset\": 9,\n+      \"type\": \"<ALPHANUM>\",\n+      \"position\": 1\n+    },\n+    {\n+      \"token\": \"jump\",\n+      \"start_offset\": 10,\n+      \"end_offset\": 17,\n+      \"type\": \"<ALPHANUM>\",\n+      \"position\": 2\n+    },\n+    {\n+      \"token\": \"quickli\",\n+      \"start_offset\": 18,\n+      \"end_offset\": 25,\n+      \"type\": \"<ALPHANUM>\",\n+      \"position\": 3\n+    }\n+  ]\n+}\n+----\n+////\n+\n+[[analysis-stemmer-tokenfilter-analyzer-ex]]\n+==== Add to an analyzer\n+\n+The following <<indices-create-index,create index API>> request uses the\n+`stemmer` filter to configure a new <<analysis-custom-analyzer,custom\n+analyzer>>.\n+\n+[source,console]\n+----\n PUT /my_index\n {\n-    \"settings\": {\n-        \"analysis\" : {\n-            \"analyzer\" : {\n-                \"my_analyzer\" : {\n-                    \"tokenizer\" : \"standard\",\n-                    \"filter\" : [\"lowercase\", \"my_stemmer\"]\n-                }\n-            },\n-            \"filter\" : {\n-                \"my_stemmer\" : {\n-                    \"type\" : \"stemmer\",\n-                    \"name\" : \"light_german\"\n-                }\n-            }\n+  \"settings\": {\n+    \"analysis\": {\n+      \"analyzer\": {\n+        \"my_analyzer\": {\n+          \"tokenizer\": \"whitespace\",\n+          \"filter\": [ \"stemmer\" ]\n         }\n+      }\n     }\n+  }\n }\n---------------------------------------------------\n-\n-The `language`/`name` parameter controls the stemmer with the following\n-available values (the preferred filters are marked in *bold*):\n+----\n+\n+[role=\"child_attributes\"]\n+[[analysis-stemmer-tokenfilter-configure-parms]]\n+==== Configurable parameters\n+\n+[[analysis-stemmer-tokenfilter-language-parm]]\n+`language`::\n+(Optional, string)\n+Language-dependent stemming algorithm used to stem tokens. If both this and the\n+`name` parameter are specified, the `language` parameter argument is used.\n++\n+[%collapsible%open]\n+.Valid values for `language`\n+====\n+Valid values are sorted by language. Defaults to\n+http://snowball.tartarus.org/algorithms/porter/stemmer.html[*`english`*].\n+Recommended algorithms are *bolded*.\n \n-[horizontal]\n Arabic::\n-\n-http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/ar/ArabicStemmer.html[*`arabic`*]\n+{lucene-analysis-docs}/ar/ArabicStemmer.html[*`arabic`*]", "originalCommit": "4e41b4f0a8d231caa02a988e2ff4324a833295a5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "50b33963c9115e6bf174ea564f155cbe1fda0e36", "url": "https://github.com/elastic/elasticsearch/commit/50b33963c9115e6bf174ea564f155cbe1fda0e36", "message": "Merge branch 'master' into docs__reformat-stemmer-tokenfilter", "committedDate": "2020-04-24T14:42:11Z", "type": "commit"}, {"oid": "8db7b11c2e377fe656c00df566f3209c8987d38f", "url": "https://github.com/elastic/elasticsearch/commit/8db7b11c2e377fe656c00df566f3209c8987d38f", "message": "add xref", "committedDate": "2020-04-24T14:43:03Z", "type": "commit"}]}