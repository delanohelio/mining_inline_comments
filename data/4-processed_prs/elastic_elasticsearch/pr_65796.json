{"pr_number": 65796, "pr_title": "SQL: Fix SUM(all zeroes) to return 0 instead of NULL", "pr_createdAt": "2020-12-03T00:40:36Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/65796", "timeline": [{"oid": "d2ba958dab02c599527308be755fc0c89c9283e3", "url": "https://github.com/elastic/elasticsearch/commit/d2ba958dab02c599527308be755fc0c89c9283e3", "message": "SQL: Fix SUM(all zeroes)\n\nPreviously the SUM(all zeroes) was `NULL`, but after this change the SUM\nSQL function call is automatically upgraded into a `stats` aggregation\ninstead of a `sum` aggregation. The `stats` aggregation only results in\n`NULL` if the there were no rows, no values to aggregate, which is the\nexpected behaviour across different SQL implementations.\n\nThis is a workaround for #45251 .", "committedDate": "2020-12-03T00:12:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDczMDI3Mg==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534730272", "bodyText": "I'm not against tests for FIRST and LAST, but why are these relevant for SUM() returning 0 instead of NULL?", "author": "astefan", "createdAt": "2020-12-03T06:29:48Z", "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.csv-spec", "diffHunk": "@@ -0,0 +1,359 @@\n+\n+aggregatingAllZerosWithFirst\n+schema::FIRST_AllZeros:i\n+SELECT FIRST(bytes_in) as \"FIRST_AllZeros\" FROM logs WHERE bytes_in = 0;", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDczMTc3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534731779", "bodyText": "Also, to make a bit more complex, I'd also add SELECT COUNT(*), FIRST(bytes_in) as FIRST_AllZeros, FIRST(bytes_out) as FIRST_AllNulls FROM logs WHERE bytes_in = 0 AND bytes_out IS NULL.", "author": "astefan", "createdAt": "2020-12-03T06:31:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDczMDI3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjM4OTExMQ==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r536389111", "bodyText": "Regarding the non-SUM aggregation function: I can move them to a separate commit, but I wanted to check the behaviour of each of the aggregation functions with NULL vs 0, to understand if any other aggregation beside the SUM is also impacted.\n+1 on the more complex cases. I checked them, but they did not make it to the integration test file, will add them.", "author": "palesz", "createdAt": "2020-12-04T21:26:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDczMDI3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDczNTY1NA==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534735654", "bodyText": "I don't think a new csv-spec file is needed. There are two (agg.sql-spec and agg.csv-spec) that deal with aggregations already. I'd add the tests below to the existing file(s).", "author": "astefan", "createdAt": "2020-12-03T06:35:20Z", "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.csv-spec", "diffHunk": "@@ -0,0 +1,359 @@\n+", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTI1MTM4OA==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r535251388", "bodyText": "+1", "author": "matriv", "createdAt": "2020-12-03T14:03:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDczNTY1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDczNjQzMw==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534736433", "bodyText": "We already have a test that deals with this scenario: SELECT COUNT(*) count FROM test_emp WHERE first_name IS NULL", "author": "astefan", "createdAt": "2020-12-03T06:36:08Z", "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.csv-spec", "diffHunk": "@@ -0,0 +1,359 @@\n+\n+aggregatingAllZerosWithFirst\n+schema::FIRST_AllZeros:i\n+SELECT FIRST(bytes_in) as \"FIRST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+FIRST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllNullsWithFirst\n+schema::FIRST_AllNulls:i\n+SELECT FIRST(bytes_out) as \"FIRST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+FIRST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+aggregatingAllZerosWithLast\n+schema::LAST_AllZeros:i\n+SELECT LAST(bytes_in) as \"LAST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ LAST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllNullsWithLast\n+schema::LAST_AllNulls:i\n+SELECT LAST(bytes_out) as \"LAST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ LAST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+aggregatingAllZerosWithCount\n+schema::COUNT_AllZeros:l\n+SELECT COUNT(bytes_in) as \"COUNT_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+COUNT_AllZeros \n+---------------\n+2              \n+;\n+\n+\n+aggregatingAllNullsWithCount\n+schema::COUNT_AllNulls:l\n+SELECT COUNT(bytes_out) as \"COUNT_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+COUNT_AllNulls \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllZerosWithCountStar\n+schema::COUNT_AllZeros:l\n+SELECT COUNT(*) as \"COUNT_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+COUNT_AllZeros \n+---------------\n+2              \n+;\n+\n+\n+aggregatingAllNullsWithCountStar\n+schema::COUNT_AllNulls:l\n+SELECT COUNT(*) as \"COUNT_AllNulls\" FROM logs WHERE bytes_out IS NULL;", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDc3MDM0NA==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534770344", "bodyText": "I would look in checking if adding or changing one of the entries in logs to have bytes_in as null would have a big impact on the existing tests.  If not, then I would make the change (either adding an entry or changing an existent one) and then a more complex query like SELECT bytes_in, SUM(bytes_in) as SUM_AllNulls, MIN(bytes_in), MAX(bytes_in), AVG(bytes_in) FROM logs WHERE bytes_in = 0 OR bytes_in IS NULL GROUP BY bytes_in would be possible.", "author": "astefan", "createdAt": "2020-12-03T07:03:56Z", "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.csv-spec", "diffHunk": "@@ -0,0 +1,359 @@\n+\n+aggregatingAllZerosWithFirst\n+schema::FIRST_AllZeros:i\n+SELECT FIRST(bytes_in) as \"FIRST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+FIRST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllNullsWithFirst\n+schema::FIRST_AllNulls:i\n+SELECT FIRST(bytes_out) as \"FIRST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+FIRST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+aggregatingAllZerosWithLast\n+schema::LAST_AllZeros:i\n+SELECT LAST(bytes_in) as \"LAST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ LAST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllNullsWithLast\n+schema::LAST_AllNulls:i\n+SELECT LAST(bytes_out) as \"LAST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ LAST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+aggregatingAllZerosWithCount\n+schema::COUNT_AllZeros:l\n+SELECT COUNT(bytes_in) as \"COUNT_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+COUNT_AllZeros \n+---------------\n+2              \n+;\n+\n+\n+aggregatingAllNullsWithCount\n+schema::COUNT_AllNulls:l\n+SELECT COUNT(bytes_out) as \"COUNT_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+COUNT_AllNulls \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllZerosWithCountStar\n+schema::COUNT_AllZeros:l\n+SELECT COUNT(*) as \"COUNT_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+COUNT_AllZeros \n+---------------\n+2              \n+;\n+\n+\n+aggregatingAllNullsWithCountStar\n+schema::COUNT_AllNulls:l\n+SELECT COUNT(*) as \"COUNT_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+COUNT_AllNulls \n+---------------\n+51             \n+;\n+\n+\n+aggregatingAllZerosWithAvg\n+schema::AVG_AllZeros:d\n+SELECT AVG(bytes_in) as \"AVG_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ AVG_AllZeros  \n+---------------\n+0.0            \n+;\n+\n+\n+aggregatingAllNullsWithAvg\n+schema::AVG_AllNulls:d\n+SELECT AVG(bytes_out) as \"AVG_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ AVG_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+aggregatingAllZerosWithMin\n+schema::MIN_AllZeros:i\n+SELECT MIN(bytes_in) as \"MIN_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MIN_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllNullsWithMin\n+schema::MIN_AllNulls:i\n+SELECT MIN(bytes_out) as \"MIN_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MIN_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+aggregatingAllZerosWithMax\n+schema::MAX_AllZeros:i\n+SELECT MAX(bytes_in) as \"MAX_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MAX_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllNullsWithMax\n+schema::MAX_AllNulls:i\n+SELECT MAX(bytes_out) as \"MAX_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MAX_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+aggregatingAllZerosWithSum\n+schema::SUM_AllZeros:i\n+SELECT SUM(bytes_in) as \"SUM_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ SUM_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+aggregatingAllNullsWithSum\n+schema::SUM_AllNulls:i\n+SELECT SUM(bytes_out) as \"SUM_AllNulls\" FROM logs WHERE bytes_out IS NULL;", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDc3MjM3Mg==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534772372", "bodyText": "Why -Ignore. Also, why adding the test as sql-spec if the test already exists in .csv-spec?", "author": "astefan", "createdAt": "2020-12-03T07:06:00Z", "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.sql-spec", "diffHunk": "@@ -0,0 +1,73 @@\n+\n+aggregatingAllZerosWithFirst-Ignore", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDc3MzQ2NQ==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534773465", "bodyText": "Same comment for this file, regarding the already existent aggs-related spec file.", "author": "astefan", "createdAt": "2020-12-03T07:06:44Z", "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.sql-spec", "diffHunk": "@@ -0,0 +1,73 @@\n+", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDgxNTUwNA==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534815504", "bodyText": "Either change the name of the file or add a new sql file (preferable) to be used with H2. setup_test_emp doesn't reflect the file content anymore.", "author": "astefan", "createdAt": "2020-12-03T07:33:35Z", "path": "x-pack/plugin/sql/qa/server/src/main/resources/setup_test_emp.sql", "diffHunk": "@@ -9,4 +9,17 @@ CREATE TABLE \"test_emp\" (\n                     \"last_name\" VARCHAR(50),", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkxNDYxMg==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534914612", "bodyText": "@Override goes on a separate line.", "author": "astefan", "createdAt": "2020-12-03T08:30:51Z", "path": "x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/optimizer/Optimizer.java", "diffHunk": "@@ -983,6 +984,37 @@ public LogicalPlan apply(LogicalPlan p) {\n         }\n     }\n \n+    static class ReplaceSumWithStats extends OptimizerBasicRule {\n+        // this is a workaround for the https://github.com/elastic/elasticsearch/issues/45251 issue\n+        // should be removed as soon as the issue is fixed\n+        // NOTE: this rule should always be applied AFTER the ReplaceAggsWithStats rule\n+\n+        @Override public LogicalPlan apply(LogicalPlan plan) {", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkyMjI3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534922279", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertEquals(Alias.class, p.aggregates().get(0).getClass());\n          \n          \n            \n                    assertTrue(p.aggregates().get(0) instanceof Alias);", "author": "astefan", "createdAt": "2020-12-03T08:35:20Z", "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/optimizer/OptimizerTests.java", "diffHunk": "@@ -1023,4 +1022,43 @@ public void testReplaceAttributesWithTarget() {\n         gt = (GreaterThan) and.left();\n         assertEquals(a, gt.left());\n     }\n+\n+    //\n+    // ReplaceSumWithStats rule\n+    //\n+    public void testSumIsReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+        \n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+        \n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertEquals(Aggregate.class, optimizedPlan.getClass());\n+        Aggregate p = (Aggregate) optimizedPlan; \n+        assertEquals(1, p.aggregates().size());\n+        assertEquals(Alias.class, p.aggregates().get(0).getClass());", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkyMjgzMw==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534922833", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertEquals(InnerAggregate.class, alias.child().getClass());\n          \n          \n            \n                    assertTrue(alias.child() instanceof InnerAggregate);", "author": "astefan", "createdAt": "2020-12-03T08:35:39Z", "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/optimizer/OptimizerTests.java", "diffHunk": "@@ -1023,4 +1022,43 @@ public void testReplaceAttributesWithTarget() {\n         gt = (GreaterThan) and.left();\n         assertEquals(a, gt.left());\n     }\n+\n+    //\n+    // ReplaceSumWithStats rule\n+    //\n+    public void testSumIsReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+        \n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+        \n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertEquals(Aggregate.class, optimizedPlan.getClass());\n+        Aggregate p = (Aggregate) optimizedPlan; \n+        assertEquals(1, p.aggregates().size());\n+        assertEquals(Alias.class, p.aggregates().get(0).getClass());\n+        Alias alias = (Alias) p.aggregates().get(0);\n+        assertEquals(InnerAggregate.class, alias.child().getClass());", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkyNDc5OQ==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534924799", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertEquals(Aggregate.class, optimizedPlan.getClass());\n          \n          \n            \n                    assertTrue(optimizedPlan instanceof Aggregate);", "author": "astefan", "createdAt": "2020-12-03T08:36:47Z", "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/optimizer/OptimizerTests.java", "diffHunk": "@@ -1023,4 +1022,43 @@ public void testReplaceAttributesWithTarget() {\n         gt = (GreaterThan) and.left();\n         assertEquals(a, gt.left());\n     }\n+\n+    //\n+    // ReplaceSumWithStats rule\n+    //\n+    public void testSumIsReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+        \n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+        \n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertEquals(Aggregate.class, optimizedPlan.getClass());", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTI1MzQ3Ng==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r535253476", "bodyText": "We have a mix of those assertions, I wouldn't mind keeping it as is.", "author": "matriv", "createdAt": "2020-12-03T14:05:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkyNDc5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkyNTUxNw==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534925517", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertEquals(sum, ((InnerAggregate)alias.child()).inner());\n          \n          \n            \n                    assertEquals(sum, ((InnerAggregate) alias.child()).inner());", "author": "astefan", "createdAt": "2020-12-03T08:37:21Z", "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/optimizer/OptimizerTests.java", "diffHunk": "@@ -1023,4 +1022,43 @@ public void testReplaceAttributesWithTarget() {\n         gt = (GreaterThan) and.left();\n         assertEquals(a, gt.left());\n     }\n+\n+    //\n+    // ReplaceSumWithStats rule\n+    //\n+    public void testSumIsReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+        \n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+        \n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertEquals(Aggregate.class, optimizedPlan.getClass());\n+        Aggregate p = (Aggregate) optimizedPlan; \n+        assertEquals(1, p.aggregates().size());\n+        assertEquals(Alias.class, p.aggregates().get(0).getClass());\n+        Alias alias = (Alias) p.aggregates().get(0);\n+        assertEquals(InnerAggregate.class, alias.child().getClass());\n+        assertEquals(sum, ((InnerAggregate)alias.child()).inner());", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDkyNjI1Ng==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r534926256", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    assertEquals(Aggregate.class, optimizedPlan.getClass());\n          \n          \n            \n                    assertTrue(optimizedPlan instanceof Aggregate);", "author": "astefan", "createdAt": "2020-12-03T08:37:56Z", "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/optimizer/OptimizerTests.java", "diffHunk": "@@ -1023,4 +1022,43 @@ public void testReplaceAttributesWithTarget() {\n         gt = (GreaterThan) and.left();\n         assertEquals(a, gt.left());\n     }\n+\n+    //\n+    // ReplaceSumWithStats rule\n+    //\n+    public void testSumIsReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+        \n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+        \n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertEquals(Aggregate.class, optimizedPlan.getClass());\n+        Aggregate p = (Aggregate) optimizedPlan; \n+        assertEquals(1, p.aggregates().size());\n+        assertEquals(Alias.class, p.aggregates().get(0).getClass());\n+        Alias alias = (Alias) p.aggregates().get(0);\n+        assertEquals(InnerAggregate.class, alias.child().getClass());\n+        assertEquals(sum, ((InnerAggregate)alias.child()).inner());\n+    }\n+\n+    /**\n+     * Once the bug is fixed, the above {@link OptimizerTests#testSumIsReplacedWithStats()} should be\n+     * invalid and should be deleted, and the test below should apply.\n+     */\n+    @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/issues/45251\")\n+    public void testSumIsNotReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+\n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+\n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertEquals(Aggregate.class, optimizedPlan.getClass());", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQxNzQ3Mw==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r535417473", "bodyText": "Class comment sound sit before the class declaration", "author": "costin", "createdAt": "2020-12-03T17:03:45Z", "path": "x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/optimizer/Optimizer.java", "diffHunk": "@@ -983,6 +984,37 @@ public LogicalPlan apply(LogicalPlan p) {\n         }\n     }\n \n+    static class ReplaceSumWithStats extends OptimizerBasicRule {\n+        // this is a workaround for the https://github.com/elastic/elasticsearch/issues/45251 issue", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyMDM4Mg==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r535420382", "bodyText": "Minor adjustment - to avoid having two return staments do the transformation if the list is non-empty and assign that to the plan\nif (statsPerField.isEmpty() == false) {\n   plan = plan.transformExpression()\n}\n\nreturn plan;", "author": "costin", "createdAt": "2020-12-03T17:06:38Z", "path": "x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/optimizer/Optimizer.java", "diffHunk": "@@ -983,6 +984,37 @@ public LogicalPlan apply(LogicalPlan p) {\n         }\n     }\n \n+    static class ReplaceSumWithStats extends OptimizerBasicRule {\n+        // this is a workaround for the https://github.com/elastic/elasticsearch/issues/45251 issue\n+        // should be removed as soon as the issue is fixed\n+        // NOTE: this rule should always be applied AFTER the ReplaceAggsWithStats rule\n+\n+        @Override public LogicalPlan apply(LogicalPlan plan) {\n+            final Map<Expression, Stats> statsPerField = new LinkedHashMap<>();\n+            \n+            plan.forEachExpressionsUp(e -> {\n+                if (e instanceof Sum) {\n+                    statsPerField.computeIfAbsent(((Sum) e).field(), field -> {\n+                        Source source = new Source(field.sourceLocation(), \"STATS(\" + field.sourceText() + \")\");\n+                        return new Stats(source, field);\n+                    });\n+                }\n+            });\n+            \n+            if (statsPerField.isEmpty()) {", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyNDkwMg==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r535424902", "bodyText": "To Andrei's point, isn't logs.csv used already and if not can you track down why we add it in the first place? Additionally instead of adding a new data file (assuming it is not used) you can emulate the null using a CASE function for bonus points.", "author": "costin", "createdAt": "2020-12-03T17:11:41Z", "path": "x-pack/plugin/sql/qa/server/src/main/resources/setup_test_emp.sql", "diffHunk": "@@ -9,4 +9,17 @@ CREATE TABLE \"test_emp\" (\n                     \"last_name\" VARCHAR(50),\n                     \"salary\" INT\n                    )\n-   AS SELECT * FROM CSVREAD('classpath:/employees.csv');\n\\ No newline at end of file\n+   AS SELECT * FROM CSVREAD('classpath:/employees.csv');\n+   \n+DROP TABLE IF EXISTS \"logs\";", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQwMTEwOQ==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r536401109", "bodyText": "The logs.csv was only used before in *.csv-spec tests and loaded by the DataLoader by this method:\n\n  \n    \n      elasticsearch/x-pack/plugin/sql/qa/server/src/main/java/org/elasticsearch/xpack/sql/qa/jdbc/DataLoader.java\n    \n    \n         Line 65\n      in\n      c874e6c\n    \n    \n    \n    \n\n        \n          \n           protected static void loadEmpDatasetIntoEs(RestClient client) throws Exception { \n        \n    \n  \n\n\n, but it was not loaded during the *.sql-spec tests into H2.\nlogs is used in the pivot.csv-spec and ip.csv-spec.\nRegarding CASE: Originally was thinking about using this trick, but the CASE only works for the stats and extended_stats aggregations, and does not work for the matrix_stats aggregations, hence I decided to go with just a field instead of emulating null with CASE.\nSELECT client_port\n  , SKEWNESS(CASE WHEN bytes_in < 30 THEN NULL ELSE bytes_in END)\nFROM logs\nGROUP BY client_port\n\nFound 1 problem\nline 2:14: [SKEWNESS()] cannot be used on top of operators or scalars", "author": "palesz", "createdAt": "2020-12-04T21:50:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyNDkwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQyNTk0Ng==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r535425946", "bodyText": "No need to prefix all tests with aggregating - that already happens through the file name.", "author": "costin", "createdAt": "2020-12-03T17:13:09Z", "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg-nulls-zeros.csv-spec", "diffHunk": "@@ -0,0 +1,359 @@\n+\n+aggregatingAllZerosWithFirst", "originalCommit": "d2ba958dab02c599527308be755fc0c89c9283e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "2381ca0b75817895c97c55572bbc053fbd573cd1", "url": "https://github.com/elastic/elasticsearch/commit/2381ca0b75817895c97c55572bbc053fbd573cd1", "message": "PR suggestions", "committedDate": "2020-12-07T22:03:29Z", "type": "commit"}, {"oid": "25fd2f036be25c03b0e1f32778682a653e32ef97", "url": "https://github.com/elastic/elasticsearch/commit/25fd2f036be25c03b0e1f32778682a653e32ef97", "message": "Merge remote-tracking branch 'origin/master' into fix/sum-null", "committedDate": "2020-12-07T22:04:39Z", "type": "commit"}, {"oid": "ebe06e8ba86d7ab7ec567108da31207578972591", "url": "https://github.com/elastic/elasticsearch/commit/ebe06e8ba86d7ab7ec567108da31207578972591", "message": "Minor test fixes", "committedDate": "2020-12-07T22:30:15Z", "type": "commit"}, {"oid": "89987b13ed981098bddff7d7968a05448172280a", "url": "https://github.com/elastic/elasticsearch/commit/89987b13ed981098bddff7d7968a05448172280a", "message": "Merge remote-tracking branch 'origin/master' into fix/sum-null", "committedDate": "2020-12-07T22:32:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODE3MDcyNw==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538170727", "bodyText": "Could you put comma at the end of the line instead of at the start?", "author": "astefan", "createdAt": "2020-12-08T09:22:38Z", "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg.csv-spec", "diffHunk": "@@ -1325,3 +1325,386 @@ F              |1964-10-18T00:00:00.000Z|1952-04-19T00:00:00.000Z\n M              |1965-01-03T00:00:00.000Z|1952-02-27T00:00:00.000Z\n ;\n \n+\n+//\n+// Aggregations on NULLs and Zeros\n+//\n+\n+allZerosWithFirst\n+schema::FIRST_AllZeros:i\n+SELECT FIRST(bytes_in) as \"FIRST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+FIRST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithFirst\n+schema::FIRST_AllNulls:i\n+SELECT FIRST(bytes_out) as \"FIRST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+FIRST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithLast\n+schema::LAST_AllZeros:i\n+SELECT LAST(bytes_in) as \"LAST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ LAST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithLast\n+schema::LAST_AllNulls:i\n+SELECT LAST(bytes_out) as \"LAST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ LAST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithCount\n+schema::COUNT_AllZeros:l\n+SELECT COUNT(bytes_in) as \"COUNT_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+COUNT_AllZeros \n+---------------\n+2              \n+;\n+\n+\n+allNullsWithCount\n+schema::COUNT_AllNulls:l\n+SELECT COUNT(bytes_out) as \"COUNT_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+COUNT_AllNulls \n+---------------\n+0              \n+;\n+\n+\n+\n+allZerosWithAvg\n+schema::AVG_AllZeros:d\n+SELECT AVG(bytes_in) as \"AVG_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ AVG_AllZeros  \n+---------------\n+0.0            \n+;\n+\n+\n+allNullsWithAvg\n+schema::AVG_AllNulls:d\n+SELECT AVG(bytes_out) as \"AVG_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ AVG_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithMin\n+schema::MIN_AllZeros:i\n+SELECT MIN(bytes_in) as \"MIN_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MIN_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithMin\n+schema::MIN_AllNulls:i\n+SELECT MIN(bytes_out) as \"MIN_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MIN_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithMax\n+schema::MAX_AllZeros:i\n+SELECT MAX(bytes_in) as \"MAX_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MAX_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithMax\n+schema::MAX_AllNulls:i\n+SELECT MAX(bytes_out) as \"MAX_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MAX_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithSum\n+schema::SUM_AllZeros:i\n+SELECT SUM(bytes_in) as \"SUM_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ SUM_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithSum\n+schema::SUM_AllNulls:i\n+SELECT SUM(bytes_out) as \"SUM_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ SUM_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithPercentile\n+schema::PERCENTILE_AllZeros:d\n+SELECT PERCENTILE(bytes_in, 0) as \"PERCENTILE_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+PERCENTILE_AllZeros\n+-------------------\n+0.0                \n+;\n+\n+\n+allNullsWithPercentile\n+schema::PERCENTILE_AllNulls:d\n+SELECT PERCENTILE(bytes_out, 0) as \"PERCENTILE_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+PERCENTILE_AllNulls\n+-------------------\n+null               \n+;\n+\n+\n+allZerosWithPercentileRank\n+schema::PERCENTILE_RANK_AllZeros:d\n+SELECT PERCENTILE_RANK(bytes_in, 0) as \"PERCENTILE_RANK_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+PERCENTILE_RANK_AllZeros\n+------------------------\n+100.0                   \n+;\n+\n+\n+allNullsWithPercentileRank\n+schema::PERCENTILE_RANK_AllNulls:d\n+SELECT PERCENTILE_RANK(bytes_out, 0) as \"PERCENTILE_RANK_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+PERCENTILE_RANK_AllNulls\n+------------------------\n+null                    \n+;\n+\n+\n+allZerosWithSumOfSquares\n+schema::SUM_OF_SQUARES_AllZeros:d\n+SELECT SUM_OF_SQUARES(bytes_in) as \"SUM_OF_SQUARES_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+SUM_OF_SQUARES_AllZeros\n+-----------------------\n+0.0                    \n+;\n+\n+\n+allNullsWithSumOfSquares\n+schema::SUM_OF_SQUARES_AllNulls:d\n+SELECT SUM_OF_SQUARES(bytes_out) as \"SUM_OF_SQUARES_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+SUM_OF_SQUARES_AllNulls\n+-----------------------\n+null                   \n+;\n+\n+\n+allZerosWithStddevPop\n+schema::STDDEV_POP_AllZeros:d\n+SELECT STDDEV_POP(bytes_in) as \"STDDEV_POP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+STDDEV_POP_AllZeros\n+-------------------\n+0.0                \n+;\n+\n+\n+allNullsWithStddevPop\n+schema::STDDEV_POP_AllNulls:d\n+SELECT STDDEV_POP(bytes_out) as \"STDDEV_POP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+STDDEV_POP_AllNulls\n+-------------------\n+null               \n+;\n+\n+\n+allZerosWithStddevSamp\n+schema::STDDEV_SAMP_AllZeros:d\n+SELECT STDDEV_SAMP(bytes_in) as \"STDDEV_SAMP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+STDDEV_SAMP_AllZeros\n+--------------------\n+0.0                 \n+;\n+\n+\n+allNullsWithStddevSamp\n+schema::STDDEV_SAMP_AllNulls:d\n+SELECT STDDEV_SAMP(bytes_out) as \"STDDEV_SAMP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+STDDEV_SAMP_AllNulls\n+--------------------\n+null                \n+;\n+\n+\n+allZerosWithVarSamp\n+schema::VAR_SAMP_AllZeros:d\n+SELECT VAR_SAMP(bytes_in) as \"VAR_SAMP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+VAR_SAMP_AllZeros\n+-----------------\n+0.0              \n+;\n+\n+\n+allNullsWithVarSamp\n+schema::VAR_SAMP_AllNulls:d\n+SELECT VAR_SAMP(bytes_out) as \"VAR_SAMP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+VAR_SAMP_AllNulls\n+-----------------\n+null             \n+;\n+\n+\n+allZerosWithVarPop\n+schema::VAR_POP_AllZeros:d\n+SELECT VAR_POP(bytes_in) as \"VAR_POP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+VAR_POP_AllZeros\n+----------------\n+0.0             \n+;\n+\n+\n+allNullsWithVarPop\n+schema::VAR_POP_AllNulls:d\n+SELECT VAR_POP(bytes_out) as \"VAR_POP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+VAR_POP_AllNulls\n+----------------\n+null            \n+;\n+\n+\n+allZerosWithSkewness\n+schema::SKEWNESS_AllZeros:d\n+SELECT SKEWNESS(bytes_in) as \"SKEWNESS_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+SKEWNESS_AllZeros\n+-----------------\n+NaN              \n+;\n+\n+\n+allNullsWithSkewness\n+schema::SKEWNESS_AllNulls:d\n+SELECT SKEWNESS(bytes_out) as \"SKEWNESS_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+SKEWNESS_AllNulls\n+-----------------\n+null             \n+;\n+\n+\n+allZerosWithMad\n+schema::MAD_AllZeros:d\n+SELECT MAD(bytes_in) as \"MAD_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MAD_AllZeros  \n+---------------\n+0.0            \n+;\n+\n+\n+allNullsWithMad\n+schema::MAD_AllNulls:d\n+SELECT MAD(bytes_out) as \"MAD_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MAD_AllNulls  \n+---------------\n+NaN            \n+;\n+\n+\n+allZerosWithKurtosis\n+schema::KURTOSIS_AllZeros:d\n+SELECT KURTOSIS(bytes_in) as \"KURTOSIS_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+KURTOSIS_AllZeros\n+-----------------\n+NaN              \n+;\n+\n+\n+allNullsWithKurtosis\n+schema::KURTOSIS_AllNulls:d\n+SELECT KURTOSIS(bytes_out) as \"KURTOSIS_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+KURTOSIS_AllNulls\n+-----------------\n+null             \n+;\n+\n+nullsAndZerosCombined\n+schema::COUNT(*):l|COUNT_AllZeros:l|COUNT_AllNulls:l|FIRST_AllZeros:i|FIRST_AllNulls:i|SUM_AllZeros:i|SUM_AllNulls:i\n+SELECT\n+    COUNT(*)\n+    , COUNT(bytes_in) AS \"COUNT_AllZeros\"\n+    , COUNT(bytes_out) AS \"COUNT_AllNulls\"", "originalCommit": "89987b13ed981098bddff7d7968a05448172280a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODUzMDU1OA==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538530558", "bodyText": "Will move those commas. Good old habit (easier to comment out fields this way).", "author": "palesz", "createdAt": "2020-12-08T15:56:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODE3MDcyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODE3Mzk0OA==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538173948", "bodyText": "Just a minor suggestion: ORDER BY ... DESC.", "author": "astefan", "createdAt": "2020-12-08T09:26:55Z", "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg.csv-spec", "diffHunk": "@@ -1325,3 +1325,386 @@ F              |1964-10-18T00:00:00.000Z|1952-04-19T00:00:00.000Z\n M              |1965-01-03T00:00:00.000Z|1952-02-27T00:00:00.000Z\n ;\n \n+\n+//\n+// Aggregations on NULLs and Zeros\n+//\n+\n+allZerosWithFirst\n+schema::FIRST_AllZeros:i\n+SELECT FIRST(bytes_in) as \"FIRST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+FIRST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithFirst\n+schema::FIRST_AllNulls:i\n+SELECT FIRST(bytes_out) as \"FIRST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+FIRST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithLast\n+schema::LAST_AllZeros:i\n+SELECT LAST(bytes_in) as \"LAST_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ LAST_AllZeros \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithLast\n+schema::LAST_AllNulls:i\n+SELECT LAST(bytes_out) as \"LAST_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ LAST_AllNulls \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithCount\n+schema::COUNT_AllZeros:l\n+SELECT COUNT(bytes_in) as \"COUNT_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+COUNT_AllZeros \n+---------------\n+2              \n+;\n+\n+\n+allNullsWithCount\n+schema::COUNT_AllNulls:l\n+SELECT COUNT(bytes_out) as \"COUNT_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+COUNT_AllNulls \n+---------------\n+0              \n+;\n+\n+\n+\n+allZerosWithAvg\n+schema::AVG_AllZeros:d\n+SELECT AVG(bytes_in) as \"AVG_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ AVG_AllZeros  \n+---------------\n+0.0            \n+;\n+\n+\n+allNullsWithAvg\n+schema::AVG_AllNulls:d\n+SELECT AVG(bytes_out) as \"AVG_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ AVG_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithMin\n+schema::MIN_AllZeros:i\n+SELECT MIN(bytes_in) as \"MIN_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MIN_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithMin\n+schema::MIN_AllNulls:i\n+SELECT MIN(bytes_out) as \"MIN_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MIN_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithMax\n+schema::MAX_AllZeros:i\n+SELECT MAX(bytes_in) as \"MAX_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MAX_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithMax\n+schema::MAX_AllNulls:i\n+SELECT MAX(bytes_out) as \"MAX_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MAX_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithSum\n+schema::SUM_AllZeros:i\n+SELECT SUM(bytes_in) as \"SUM_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ SUM_AllZeros  \n+---------------\n+0              \n+;\n+\n+\n+allNullsWithSum\n+schema::SUM_AllNulls:i\n+SELECT SUM(bytes_out) as \"SUM_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ SUM_AllNulls  \n+---------------\n+null           \n+;\n+\n+\n+allZerosWithPercentile\n+schema::PERCENTILE_AllZeros:d\n+SELECT PERCENTILE(bytes_in, 0) as \"PERCENTILE_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+PERCENTILE_AllZeros\n+-------------------\n+0.0                \n+;\n+\n+\n+allNullsWithPercentile\n+schema::PERCENTILE_AllNulls:d\n+SELECT PERCENTILE(bytes_out, 0) as \"PERCENTILE_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+PERCENTILE_AllNulls\n+-------------------\n+null               \n+;\n+\n+\n+allZerosWithPercentileRank\n+schema::PERCENTILE_RANK_AllZeros:d\n+SELECT PERCENTILE_RANK(bytes_in, 0) as \"PERCENTILE_RANK_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+PERCENTILE_RANK_AllZeros\n+------------------------\n+100.0                   \n+;\n+\n+\n+allNullsWithPercentileRank\n+schema::PERCENTILE_RANK_AllNulls:d\n+SELECT PERCENTILE_RANK(bytes_out, 0) as \"PERCENTILE_RANK_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+PERCENTILE_RANK_AllNulls\n+------------------------\n+null                    \n+;\n+\n+\n+allZerosWithSumOfSquares\n+schema::SUM_OF_SQUARES_AllZeros:d\n+SELECT SUM_OF_SQUARES(bytes_in) as \"SUM_OF_SQUARES_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+SUM_OF_SQUARES_AllZeros\n+-----------------------\n+0.0                    \n+;\n+\n+\n+allNullsWithSumOfSquares\n+schema::SUM_OF_SQUARES_AllNulls:d\n+SELECT SUM_OF_SQUARES(bytes_out) as \"SUM_OF_SQUARES_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+SUM_OF_SQUARES_AllNulls\n+-----------------------\n+null                   \n+;\n+\n+\n+allZerosWithStddevPop\n+schema::STDDEV_POP_AllZeros:d\n+SELECT STDDEV_POP(bytes_in) as \"STDDEV_POP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+STDDEV_POP_AllZeros\n+-------------------\n+0.0                \n+;\n+\n+\n+allNullsWithStddevPop\n+schema::STDDEV_POP_AllNulls:d\n+SELECT STDDEV_POP(bytes_out) as \"STDDEV_POP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+STDDEV_POP_AllNulls\n+-------------------\n+null               \n+;\n+\n+\n+allZerosWithStddevSamp\n+schema::STDDEV_SAMP_AllZeros:d\n+SELECT STDDEV_SAMP(bytes_in) as \"STDDEV_SAMP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+STDDEV_SAMP_AllZeros\n+--------------------\n+0.0                 \n+;\n+\n+\n+allNullsWithStddevSamp\n+schema::STDDEV_SAMP_AllNulls:d\n+SELECT STDDEV_SAMP(bytes_out) as \"STDDEV_SAMP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+STDDEV_SAMP_AllNulls\n+--------------------\n+null                \n+;\n+\n+\n+allZerosWithVarSamp\n+schema::VAR_SAMP_AllZeros:d\n+SELECT VAR_SAMP(bytes_in) as \"VAR_SAMP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+VAR_SAMP_AllZeros\n+-----------------\n+0.0              \n+;\n+\n+\n+allNullsWithVarSamp\n+schema::VAR_SAMP_AllNulls:d\n+SELECT VAR_SAMP(bytes_out) as \"VAR_SAMP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+VAR_SAMP_AllNulls\n+-----------------\n+null             \n+;\n+\n+\n+allZerosWithVarPop\n+schema::VAR_POP_AllZeros:d\n+SELECT VAR_POP(bytes_in) as \"VAR_POP_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+VAR_POP_AllZeros\n+----------------\n+0.0             \n+;\n+\n+\n+allNullsWithVarPop\n+schema::VAR_POP_AllNulls:d\n+SELECT VAR_POP(bytes_out) as \"VAR_POP_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+VAR_POP_AllNulls\n+----------------\n+null            \n+;\n+\n+\n+allZerosWithSkewness\n+schema::SKEWNESS_AllZeros:d\n+SELECT SKEWNESS(bytes_in) as \"SKEWNESS_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+SKEWNESS_AllZeros\n+-----------------\n+NaN              \n+;\n+\n+\n+allNullsWithSkewness\n+schema::SKEWNESS_AllNulls:d\n+SELECT SKEWNESS(bytes_out) as \"SKEWNESS_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+SKEWNESS_AllNulls\n+-----------------\n+null             \n+;\n+\n+\n+allZerosWithMad\n+schema::MAD_AllZeros:d\n+SELECT MAD(bytes_in) as \"MAD_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+ MAD_AllZeros  \n+---------------\n+0.0            \n+;\n+\n+\n+allNullsWithMad\n+schema::MAD_AllNulls:d\n+SELECT MAD(bytes_out) as \"MAD_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+ MAD_AllNulls  \n+---------------\n+NaN            \n+;\n+\n+\n+allZerosWithKurtosis\n+schema::KURTOSIS_AllZeros:d\n+SELECT KURTOSIS(bytes_in) as \"KURTOSIS_AllZeros\" FROM logs WHERE bytes_in = 0;\n+\n+KURTOSIS_AllZeros\n+-----------------\n+NaN              \n+;\n+\n+\n+allNullsWithKurtosis\n+schema::KURTOSIS_AllNulls:d\n+SELECT KURTOSIS(bytes_out) as \"KURTOSIS_AllNulls\" FROM logs WHERE bytes_out IS NULL;\n+\n+KURTOSIS_AllNulls\n+-----------------\n+null             \n+;\n+\n+nullsAndZerosCombined\n+schema::COUNT(*):l|COUNT_AllZeros:l|COUNT_AllNulls:l|FIRST_AllZeros:i|FIRST_AllNulls:i|SUM_AllZeros:i|SUM_AllNulls:i\n+SELECT\n+    COUNT(*)\n+    , COUNT(bytes_in) AS \"COUNT_AllZeros\"\n+    , COUNT(bytes_out) AS \"COUNT_AllNulls\"\n+    , FIRST(bytes_in) AS \"FIRST_AllZeros\"\n+    , FIRST(bytes_out) AS \"FIRST_AllNulls\"\n+    , SUM(bytes_in) AS \"SUM_AllZeros\"\n+    , SUM(bytes_out) AS \"SUM_AllNulls\"\n+FROM logs\n+WHERE bytes_in = 0 AND bytes_out IS NULL;\n+\n+   COUNT(*)    |COUNT(bytes_in)|COUNT(bytes_out)|FIRST_AllZeros |FIRST_AllNulls | SUM_AllZeros  | SUM_AllNulls  \n+---------------+---------------+----------------+---------------+---------------+---------------+---------------\n+1              |1              |0               |0              |null           |0              |null           \n+;\n+\n+\n+groupedByNullsAndZeros\n+schema::bytes_in:i|COUNT(*):l|SUM(bytes_in):i|MIN(bytes_in):i|MAX(bytes_in):i|AVG(bytes_in):d\n+SELECT\n+    bytes_in\n+    , COUNT(*)\n+    , SUM(bytes_in)\n+    , MIN(bytes_in)\n+    , MAX(bytes_in)\n+    , AVG(bytes_in)\n+FROM logs\n+WHERE NVL(bytes_in, 0) = 0\n+GROUP BY bytes_in\n+ORDER BY bytes_in;", "originalCommit": "89987b13ed981098bddff7d7968a05448172280a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODE4NDk2MA==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538184960", "bodyText": "Please, add one more test, that uses two SUMs and some other elements: SELECT SUM(bytes_in), SUM(bytes_out), client_ip, COUNT(*) AS c FROM logs WHERE client_ip = '10.0.0.0/16' AND NVL(bytes_out, 0) = 0 GROUP BY client_ip ORDER BY c DESC, SUM(bytes_in) ASC NULLS FIRST", "author": "astefan", "createdAt": "2020-12-08T09:42:00Z", "path": "x-pack/plugin/sql/qa/server/src/main/resources/agg.csv-spec", "diffHunk": "@@ -1325,3 +1325,386 @@ F              |1964-10-18T00:00:00.000Z|1952-04-19T00:00:00.000Z\n M              |1965-01-03T00:00:00.000Z|1952-02-27T00:00:00.000Z\n ;\n \n+", "originalCommit": "89987b13ed981098bddff7d7968a05448172280a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIyODM5MA==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538228390", "bodyText": "Why was this added and what would have happened without it?", "author": "costin", "createdAt": "2020-12-08T10:39:15Z", "path": "x-pack/plugin/sql/qa/server/src/main/resources/logs.csv", "diffHunk": "@@ -99,3 +99,4 @@ id,@timestamp,bytes_in,bytes_out,client_ip,client_port,dest_ip,status\n 98,2017-11-10T21:12:24Z,74,90,10.0.0.134,57203,172.20.10.1,OK\n 99,2017-11-10T21:17:37Z,39,512,10.0.0.128,29333,,OK\n 100,2017-11-10T03:21:36Z,64,183,10.0.0.129,4541,172.16.1.1,OK\n+101,2017-11-10T23:22:36Z,,,10.0.2.129,4541,172.20.11.1,OK", "originalCommit": "89987b13ed981098bddff7d7968a05448172280a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODI0Nzc1MA==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538247750", "bodyText": "@costin this a follow up to my suggestion here to allow a more complex test query to be added.", "author": "astefan", "createdAt": "2020-12-08T11:06:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIyODM5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIyOTc4Mg==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538229782", "bodyText": "I find this comment confusing.\nThis PR is a fix for #45251 itself due to an issue in Elasticsearch not SQL.\nOnce the issue in Elasticsearch is fixed the workaround in QL won't be needed. Pointing to the SQL issue itself asking for the workaround is incorrect.", "author": "costin", "createdAt": "2020-12-08T10:40:43Z", "path": "x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/optimizer/Optimizer.java", "diffHunk": "@@ -983,6 +984,38 @@ public LogicalPlan apply(LogicalPlan p) {\n         }\n     }\n \n+    // This is a workaround for the https://github.com/elastic/elasticsearch/issues/45251 issue\n+    // Should be removed as soon as the above issue is fixed\n+    // NOTE: this rule should always be applied AFTER the ReplaceAggsWithStats rule", "originalCommit": "89987b13ed981098bddff7d7968a05448172280a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODU2MDI2Mg==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538560262", "bodyText": "I intended to keep #45251 open after this PR and only close it after the sum aggregations can differentiate between SUM(all zeroes) and SUM(all nulls). Reworded the comment to make this more obvious.", "author": "palesz", "createdAt": "2020-12-08T16:22:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIyOTc4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIzMzQwMA==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538233400", "bodyText": "Incorrect issue referenced - this PR provides the workaround in SQL for ES. Once the issue in ES gets solved, this test can be enabled.", "author": "costin", "createdAt": "2020-12-08T10:45:26Z", "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/optimizer/OptimizerTests.java", "diffHunk": "@@ -1023,4 +1022,43 @@ public void testReplaceAttributesWithTarget() {\n         gt = (GreaterThan) and.left();\n         assertEquals(a, gt.left());\n     }\n+\n+    //\n+    // ReplaceSumWithStats rule\n+    //\n+    public void testSumIsReplacedWithStats() {\n+        FieldAttribute fa = getFieldAttribute();\n+        Sum sum = new Sum(EMPTY, fa);\n+        \n+        Alias sumAlias = new Alias(EMPTY, \"sum\", sum);\n+        \n+        Aggregate aggregate = new Aggregate(EMPTY, FROM(), emptyList(), asList(sumAlias));\n+        LogicalPlan optimizedPlan = new Optimizer().optimize(aggregate);\n+        assertTrue(optimizedPlan instanceof Aggregate);\n+        Aggregate p = (Aggregate) optimizedPlan; \n+        assertEquals(1, p.aggregates().size());\n+        assertTrue(p.aggregates().get(0) instanceof Alias);\n+        Alias alias = (Alias) p.aggregates().get(0);\n+        assertTrue(alias.child() instanceof InnerAggregate);\n+        assertEquals(sum, ((InnerAggregate) alias.child()).inner());\n+    }\n+\n+    /**\n+     * Once the bug is fixed, the above {@link OptimizerTests#testSumIsReplacedWithStats()} should be\n+     * invalid and should be deleted, and the test below should apply.\n+     */\n+    @AwaitsFix(bugUrl = \"https://github.com/elastic/elasticsearch/issues/45251\")", "originalCommit": "89987b13ed981098bddff7d7968a05448172280a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODIzMzc1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r538233759", "bodyText": "Same comment here regarding the Github issue.", "author": "costin", "createdAt": "2020-12-08T10:45:54Z", "path": "x-pack/plugin/sql/src/test/java/org/elasticsearch/xpack/sql/planner/QueryTranslatorTests.java", "diffHunk": "@@ -2443,4 +2443,19 @@ public void testPercentileOptimization() {\n         test.accept(\"PERCENTILE\", p -> ((PercentilesAggregationBuilder)p).percentiles());\n         test.accept(\"PERCENTILE_RANK\", p -> ((PercentileRanksAggregationBuilder)p).values());\n     }\n+\n+    // workaround for the https://github.com/elastic/elasticsearch/issues/45251 issue", "originalCommit": "89987b13ed981098bddff7d7968a05448172280a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "051d11cac05342dce4170c4a7180a3fe050c2d95", "url": "https://github.com/elastic/elasticsearch/commit/051d11cac05342dce4170c4a7180a3fe050c2d95", "message": "PR suggestions", "committedDate": "2020-12-08T16:17:05Z", "type": "commit"}, {"oid": "92c348287bbb1b3b268840ae0b2a9d5996acc13d", "url": "https://github.com/elastic/elasticsearch/commit/92c348287bbb1b3b268840ae0b2a9d5996acc13d", "message": "Merge remote-tracking branch 'origin/master' into fix/sum-null", "committedDate": "2020-12-08T16:17:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTEwODgyOA==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r539108828", "bodyText": "Not related to this PR, but I was wondering: most forEachExpressionsUp/Down methods invocations do pattern matching as first thing. Wouldn't an alternative method similar to Node#forEachUp/Down taking a type token make sense?", "author": "bpintea", "createdAt": "2020-12-09T08:36:59Z", "path": "x-pack/plugin/sql/src/main/java/org/elasticsearch/xpack/sql/optimizer/Optimizer.java", "diffHunk": "@@ -983,6 +984,39 @@ public LogicalPlan apply(LogicalPlan p) {\n         }\n     }\n \n+    // This class is a workaround for the SUM(all zeros) = NULL issue raised in https://github.com/elastic/elasticsearch/issues/45251 and\n+    // should be removed as soon as root cause is fixed and the sum aggregation results can differentiate between SUM(all zeroes) \n+    // and SUM(all nulls)\n+    // NOTE: this rule should always be applied AFTER the ReplaceAggsWithStats rule\n+    static class ReplaceSumWithStats extends OptimizerBasicRule {\n+        \n+        @Override \n+        public LogicalPlan apply(LogicalPlan plan) {\n+            final Map<Expression, Stats> statsPerField = new LinkedHashMap<>();\n+            \n+            plan.forEachExpressionsUp(e -> {", "originalCommit": "92c348287bbb1b3b268840ae0b2a9d5996acc13d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTIxMzQyNw==", "url": "https://github.com/elastic/elasticsearch/pull/65796#discussion_r539213427", "bodyText": "The issue lays with collections. Expressions are not just used as individual nodes but also as properties. Take Project(List<NamedExpression> projections) - this led to issues in not only filtering but in reconstructing said collections with the new expressions while preserving their types. See the comment in LogicalPlan.doTransformExpression\nIt would be nicer to do:\nplan.forEachExpressionsUp(s -> , Sum.class) instead of doing the instanceof check however the issue right now is preserving the type information before and after transformation without causing a CCE.\nThat said, I plan to take another look at this to see whether it can be sorted out.", "author": "costin", "createdAt": "2020-12-09T11:05:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTEwODgyOA=="}], "type": "inlineReview"}]}