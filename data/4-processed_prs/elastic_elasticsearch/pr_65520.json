{"pr_number": 65520, "pr_title": "Autoscaling reactive storage decider", "pr_createdAt": "2020-11-25T22:48:01Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/65520", "timeline": [{"oid": "a5e5f43afc6967d979f92949b74908ca89ce1309", "url": "https://github.com/elastic/elasticsearch/commit/a5e5f43afc6967d979f92949b74908ca89ce1309", "message": "Autoscaling reactive storage decider\n\nThe reactive storage decider will request additional capacity\nproportional to the size of shards that are either:\n* unassigned and unable to be allocated with only reason being storage\non a node\n* shards that cannot remain where they are with only reason being\nstorage and cannot be allocated anywhere else\n* shards that cannot remain where they are and cannot be allocated\non any node and at least one node has storage as the only reason for\nunable to allocate.\n\nThe reactive storage decider does not try to look into the future, thus\nat the time the reactive decider asks to scale up, the cluster is\nalready in a need for more storage.", "committedDate": "2020-11-25T22:46:54Z", "type": "commit"}, {"oid": "bf2d27e613b6b2af240fec6c46b26c5b49120cc0", "url": "https://github.com/elastic/elasticsearch/commit/bf2d27e613b6b2af240fec6c46b26c5b49120cc0", "message": "Extract DiskUsageIntegTestCase\n\nExtracted DiskUsageIntegTestCase from DiskThresholdDeciderIT to allow\nother tests to easily test functionality relying on disk usage.\n\nRelates #65520", "committedDate": "2020-11-26T11:02:06Z", "type": "commit"}, {"oid": "7fadd0b6257ca124e90f396bf78537ad8bb4ec00", "url": "https://github.com/elastic/elasticsearch/commit/7fadd0b6257ca124e90f396bf78537ad8bb4ec00", "message": "Added integration test.", "committedDate": "2020-11-26T11:02:24Z", "type": "commit"}, {"oid": "9f6a430f48b058675cbb7c419a6211a18323b396", "url": "https://github.com/elastic/elasticsearch/commit/9f6a430f48b058675cbb7c419a6211a18323b396", "message": "Added node minimum size too.", "committedDate": "2020-11-26T12:16:52Z", "type": "commit"}, {"oid": "3083ff0248d1293a306a26a1440a972b54e9eca0", "url": "https://github.com/elastic/elasticsearch/commit/3083ff0248d1293a306a26a1440a972b54e9eca0", "message": "Spotless.", "committedDate": "2020-11-26T12:18:50Z", "type": "commit"}, {"oid": "d06378e54d366bf273c52082fde91a4b144fd17e", "url": "https://github.com/elastic/elasticsearch/commit/d06378e54d366bf273c52082fde91a4b144fd17e", "message": "whitespace", "committedDate": "2020-11-26T17:00:47Z", "type": "commit"}, {"oid": "2c78a0e0e2f294700ce347603b4caf21eeb4e2d2", "url": "https://github.com/elastic/elasticsearch/commit/2c78a0e0e2f294700ce347603b4caf21eeb4e2d2", "message": "cleanup:\n\nallocationDeciders are now given to service at construction time.\nFew test fixes.", "committedDate": "2020-11-26T18:21:35Z", "type": "commit"}, {"oid": "e36f6e86d89699ffe9505b43df7e690b646f30c5", "url": "https://github.com/elastic/elasticsearch/commit/e36f6e86d89699ffe9505b43df7e690b646f30c5", "message": "cleanup:\n\nremove context.roles()\nfix unmovable test.", "committedDate": "2020-11-26T20:45:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTQwMDQwNw==", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r531400407", "bodyText": "The changes in this class does not need review, they are contained in #65540 and will be merged before this is merged.", "author": "henningandersen", "createdAt": "2020-11-27T06:13:12Z", "path": "server/src/internalClusterTest/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDeciderIT.java", "diffHunk": "@@ -37,107 +34,47 @@\n import org.elasticsearch.cluster.routing.allocation.decider.EnableAllocationDecider.Rebalance;\n import org.elasticsearch.cluster.service.ClusterService;\n import org.elasticsearch.common.Priority;\n-import org.elasticsearch.common.io.PathUtils;\n-import org.elasticsearch.common.io.PathUtilsForTesting;\n import org.elasticsearch.common.settings.Settings;\n import org.elasticsearch.common.unit.ByteSizeUnit;\n import org.elasticsearch.common.unit.ByteSizeValue;\n-import org.elasticsearch.core.internal.io.IOUtils;\n-import org.elasticsearch.env.Environment;\n import org.elasticsearch.env.NodeEnvironment;\n-import org.elasticsearch.monitor.fs.FsService;\n-import org.elasticsearch.plugins.Plugin;\n import org.elasticsearch.repositories.fs.FsRepository;\n import org.elasticsearch.snapshots.RestoreInfo;\n import org.elasticsearch.snapshots.SnapshotInfo;\n import org.elasticsearch.snapshots.SnapshotState;\n import org.elasticsearch.test.ESIntegTestCase;\n-import org.elasticsearch.test.InternalSettingsPlugin;\n import org.hamcrest.Matcher;\n-import org.junit.After;\n-import org.junit.Before;\n-\n-import java.io.FileNotFoundException;\n-import java.io.IOException;\n-import java.nio.file.DirectoryStream;\n-import java.nio.file.FileStore;\n-import java.nio.file.FileSystem;\n-import java.nio.file.Files;\n-import java.nio.file.NoSuchFileException;\n-import java.nio.file.NotDirectoryException;\n-import java.nio.file.Path;\n+\n import java.util.Arrays;\n-import java.util.Collection;\n import java.util.HashSet;\n-import java.util.List;\n import java.util.Locale;\n-import java.util.Map;\n import java.util.Set;\n import java.util.concurrent.TimeUnit;\n-import java.util.stream.Collectors;\n import java.util.stream.StreamSupport;\n \n-import static org.elasticsearch.common.util.concurrent.ConcurrentCollections.newConcurrentMap;\n import static org.elasticsearch.index.store.Store.INDEX_STORE_STATS_REFRESH_INTERVAL_SETTING;\n import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n-import static org.hamcrest.Matchers.anyOf;\n import static org.hamcrest.Matchers.empty;\n import static org.hamcrest.Matchers.equalTo;\n-import static org.hamcrest.Matchers.greaterThan;\n import static org.hamcrest.Matchers.hasSize;\n import static org.hamcrest.Matchers.is;\n \n @ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST, numDataNodes = 0)\n-public class DiskThresholdDeciderIT extends ESIntegTestCase {", "originalCommit": "e36f6e86d89699ffe9505b43df7e690b646f30c5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTQwMDQ0OA==", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r531400448", "bodyText": "The changes in this class does not need review, they are contained in #65540 and will be merged before this is merged.", "author": "henningandersen", "createdAt": "2020-11-27T06:13:26Z", "path": "test/framework/src/main/java/org/elasticsearch/cluster/DiskUsageIntegTestCase.java", "diffHunk": "@@ -0,0 +1,236 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.cluster;\n+\n+import org.apache.lucene.mockfile.FilterFileStore;\n+import org.apache.lucene.mockfile.FilterFileSystemProvider;\n+import org.apache.lucene.mockfile.FilterPath;\n+import org.apache.lucene.util.Constants;\n+import org.elasticsearch.common.io.PathUtils;\n+import org.elasticsearch.common.io.PathUtilsForTesting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.core.internal.io.IOUtils;\n+import org.elasticsearch.env.Environment;\n+import org.elasticsearch.monitor.fs.FsService;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.test.InternalSettingsPlugin;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.nio.file.DirectoryStream;\n+import java.nio.file.FileStore;\n+import java.nio.file.FileSystem;\n+import java.nio.file.Files;\n+import java.nio.file.NoSuchFileException;\n+import java.nio.file.NotDirectoryException;\n+import java.nio.file.Path;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+import static org.elasticsearch.common.util.concurrent.ConcurrentCollections.newConcurrentMap;\n+import static org.hamcrest.Matchers.anyOf;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+\n+/**\n+ * An integration test case that allows mocking the disk usage per node. Notice that only files count towards disk usage and translog and\n+ * state files are disregarded.\n+ */\n+public class DiskUsageIntegTestCase extends ESIntegTestCase {", "originalCommit": "e36f6e86d89699ffe9505b43df7e690b646f30c5", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ca90d2c50053db10eb9ebf79c490a9a5b83a4cb2", "url": "https://github.com/elastic/elasticsearch/commit/ca90d2c50053db10eb9ebf79c490a9a5b83a4cb2", "message": "cleanup:\n\nUse roles rather than node name in test.\nRemove unused logger.", "committedDate": "2020-11-27T13:57:13Z", "type": "commit"}, {"oid": "55e96e3522d20c93e534f97bdf32d79f7f7e79c7", "url": "https://github.com/elastic/elasticsearch/commit/55e96e3522d20c93e534f97bdf32d79f7f7e79c7", "message": "Remove AllocationState.state()", "committedDate": "2020-11-27T14:06:22Z", "type": "commit"}, {"oid": "c3f17bb486a376f983ca95156584159990e8ca96", "url": "https://github.com/elastic/elasticsearch/commit/c3f17bb486a376f983ca95156584159990e8ca96", "message": "Make AllocationState package private.", "committedDate": "2020-11-27T14:08:53Z", "type": "commit"}, {"oid": "d72b70ab725ee59419df9b5472643427863d8e6e", "url": "https://github.com/elastic/elasticsearch/commit/d72b70ab725ee59419df9b5472643427863d8e6e", "message": "spotless", "committedDate": "2020-11-27T14:12:00Z", "type": "commit"}, {"oid": "0567d0b6b83cd7338f4c61da3ba5a00539e538f6", "url": "https://github.com/elastic/elasticsearch/commit/0567d0b6b83cd7338f4c61da3ba5a00539e538f6", "message": "No copyShards", "committedDate": "2020-11-27T14:16:46Z", "type": "commit"}, {"oid": "ea2198963032f17db06c66de9c09824065feb397", "url": "https://github.com/elastic/elasticsearch/commit/ea2198963032f17db06c66de9c09824065feb397", "message": "spelling", "committedDate": "2020-11-27T14:18:39Z", "type": "commit"}, {"oid": "2a85928862aa5bb8a850adc9358e36dbb0453997", "url": "https://github.com/elastic/elasticsearch/commit/2a85928862aa5bb8a850adc9358e36dbb0453997", "message": "ClusterInfo.EMPTY", "committedDate": "2020-11-27T14:20:15Z", "type": "commit"}, {"oid": "0990564f6759c5200c9feb4736bf83e7b7901c3f", "url": "https://github.com/elastic/elasticsearch/commit/0990564f6759c5200c9feb4736bf83e7b7901c3f", "message": "simplify nodesInTier", "committedDate": "2020-11-28T17:39:57Z", "type": "commit"}, {"oid": "8aa29ee1dbab94eb6dd25c68c6c44e597248078a", "url": "https://github.com/elastic/elasticsearch/commit/8aa29ee1dbab94eb6dd25c68c6c44e597248078a", "message": "spotless", "committedDate": "2020-11-28T20:32:04Z", "type": "commit"}, {"oid": "9cade4f269cb323131d344342ff9e401d829ee61", "url": "https://github.com/elastic/elasticsearch/commit/9cade4f269cb323131d344342ff9e401d829ee61", "message": "Remove bad comment", "committedDate": "2020-11-28T20:33:46Z", "type": "commit"}, {"oid": "1a9fcc20184ed8fba2366cdf5ef6581a1460bf99", "url": "https://github.com/elastic/elasticsearch/commit/1a9fcc20184ed8fba2366cdf5ef6581a1460bf99", "message": "nodes are unnecessary for snapshot", "committedDate": "2020-11-28T20:37:22Z", "type": "commit"}, {"oid": "592117e9f0f1b879ae160418df4a4383be1308ca", "url": "https://github.com/elastic/elasticsearch/commit/592117e9f0f1b879ae160418df4a4383be1308ca", "message": "Add assert message to explain", "committedDate": "2020-11-28T20:51:22Z", "type": "commit"}, {"oid": "b716fefa977fcbef2fe230d8a004843572c8db1b", "url": "https://github.com/elastic/elasticsearch/commit/b716fefa977fcbef2fe230d8a004843572c8db1b", "message": "Use withRoutingAllocation", "committedDate": "2020-11-28T21:06:22Z", "type": "commit"}, {"oid": "d51abebc3113fd26fd754742dcad3459ab46394c", "url": "https://github.com/elastic/elasticsearch/commit/d51abebc3113fd26fd754742dcad3459ab46394c", "message": "private and VerificationSubject", "committedDate": "2020-11-28T21:31:06Z", "type": "commit"}, {"oid": "b93deb5bab184e0063188bc593982c7d5fafa163", "url": "https://github.com/elastic/elasticsearch/commit/b93deb5bab184e0063188bc593982c7d5fafa163", "message": "do not create deciders twice", "committedDate": "2020-11-28T21:36:14Z", "type": "commit"}, {"oid": "96aa72741c62987ada6d6df3785edf843b7a39b7", "url": "https://github.com/elastic/elasticsearch/commit/96aa72741c62987ada6d6df3785edf843b7a39b7", "message": "private and remove unused", "committedDate": "2020-11-28T21:48:53Z", "type": "commit"}, {"oid": "699c9dc12372ebd3af17917b30052c727cc71886", "url": "https://github.com/elastic/elasticsearch/commit/699c9dc12372ebd3af17917b30052c727cc71886", "message": "final and expression lambda", "committedDate": "2020-11-28T21:52:17Z", "type": "commit"}, {"oid": "281b1d3f50dbb0d3d215f42848040f34992eaedc", "url": "https://github.com/elastic/elasticsearch/commit/281b1d3f50dbb0d3d215f42848040f34992eaedc", "message": "ws", "committedDate": "2020-11-28T21:56:50Z", "type": "commit"}, {"oid": "692f39f6642c5efbaeb9cf774e2e0288962b81db", "url": "https://github.com/elastic/elasticsearch/commit/692f39f6642c5efbaeb9cf774e2e0288962b81db", "message": "Method order", "committedDate": "2020-11-28T22:08:36Z", "type": "commit"}, {"oid": "59b7f9efc1e1af1b5e34e5f59fc4b4dc0f33f5a0", "url": "https://github.com/elastic/elasticsearch/commit/59b7f9efc1e1af1b5e34e5f59fc4b4dc0f33f5a0", "message": "Merge remote-tracking branch 'origin/master' into enhance_reactive_storage_autoscaler_pr_final", "committedDate": "2020-11-28T22:11:52Z", "type": "commit"}, {"oid": "51a09f32f80390dbf3b579ff6edc9954e1e855de", "url": "https://github.com/elastic/elasticsearch/commit/51a09f32f80390dbf3b579ff6edc9954e1e855de", "message": "cs", "committedDate": "2020-11-28T23:08:14Z", "type": "commit"}, {"oid": "5738ed325539e4d5feac77cade2e2ebff01272e5", "url": "https://github.com/elastic/elasticsearch/commit/5738ed325539e4d5feac77cade2e2ebff01272e5", "message": "Merge remote-tracking branch 'origin/master' into enhance_reactive_storage_autoscaler_pr_final", "committedDate": "2020-12-04T07:35:37Z", "type": "commit"}, {"oid": "381c46348c027edd98b1d85bdfe913fed46b70fd", "url": "https://github.com/elastic/elasticsearch/commit/381c46348c027edd98b1d85bdfe913fed46b70fd", "message": "Wire serialization tests for reactive", "committedDate": "2020-12-07T11:23:38Z", "type": "commit"}, {"oid": "fa0f2b7caadb7fc40fabb861492d6764a8f0736f", "url": "https://github.com/elastic/elasticsearch/commit/fa0f2b7caadb7fc40fabb861492d6764a8f0736f", "message": "Merge branch 'master' into enhance_reactive_storage_autoscaler_pr_final", "committedDate": "2020-12-07T15:21:06Z", "type": "commit"}, {"oid": "5ec44064832aaefe1cf35b803d405b68ff549180", "url": "https://github.com/elastic/elasticsearch/commit/5ec44064832aaefe1cf35b803d405b68ff549180", "message": "Merge remote-tracking branch 'origin/master' into enhance_reactive_storage_autoscaler_pr_final", "committedDate": "2020-12-09T21:22:40Z", "type": "commit"}, {"oid": "35a937e237d12b94d0caeec49d01480e1fbd3dee", "url": "https://github.com/elastic/elasticsearch/commit/35a937e237d12b94d0caeec49d01480e1fbd3dee", "message": "Merge branch 'enhance_reactive_storage_autoscaler_pr_final' of github.com:henningandersen/elasticsearch into enhance_reactive_storage_autoscaler_pr_final", "committedDate": "2020-12-09T21:23:19Z", "type": "commit"}, {"oid": "f28fb9a0ed9cc82720505c884887107b0cb96270", "url": "https://github.com/elastic/elasticsearch/commit/f28fb9a0ed9cc82720505c884887107b0cb96270", "message": "Merge remote-tracking branch 'origin/master' into enhance_reactive_storage_autoscaler_pr_final", "committedDate": "2020-12-10T10:03:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyNDQ0Ng==", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541924446", "bodyText": "Could you add Javadocs to these new methods, and also state?", "author": "jasontedor", "createdAt": "2020-12-13T13:20:55Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/capacity/AutoscalingDeciderContext.java", "diffHunk": "@@ -24,4 +26,8 @@\n      * Return the nodes governed by the policy.\n      */\n     Set<DiscoveryNode> nodes();\n+\n+    ClusterInfo info();\n+\n+    SnapshotShardSizeInfo snapshotShardSizeInfo();", "originalCommit": "f28fb9a0ed9cc82720505c884887107b0cb96270", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk2MjYzOQ==", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541962639", "bodyText": "\ud83d\udc4d, 22456be", "author": "henningandersen", "createdAt": "2020-12-13T16:56:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyNDQ0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyNTI3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541925279", "bodyText": "We'll probably want a test that collects all the roles that return true for DiscoveryNodeRole#canContainData and ensure they are returned in this list. I'm thinking of when we add a role for frozen, ensuring that this list is maintained properly.", "author": "jasontedor", "createdAt": "2020-12-13T13:25:35Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE", "originalCommit": "f28fb9a0ed9cc82720505c884887107b0cb96270", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk2MjcxMw==", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541962713", "bodyText": "\ud83d\udc4d, 555991a", "author": "henningandersen", "createdAt": "2020-12-13T16:56:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyNTI3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyNjE3NA==", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541926174", "bodyText": "\ud83d\udc4d", "author": "jasontedor", "createdAt": "2020-12-13T13:30:46Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";\n+        AutoscalingCapacity requiredCapacity = AutoscalingCapacity.builder()\n+            .total(autoscalingCapacity.total().storage().getBytes() + unassigned + assigned, null)\n+            .node(maxShard, null)\n+            .build();\n+        return new AutoscalingDeciderResult(requiredCapacity, new ReactiveReason(message, unassigned, assigned));\n+    }\n+\n+    static boolean isDiskOnlyNoDecision(Decision decision) {\n+        // we consider throttling==yes, throttling should be temporary.", "originalCommit": "f28fb9a0ed9cc82720505c884887107b0cb96270", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyODI2Mw==", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541928263", "bodyText": "Can you leave a comment explaining why we need to enable allocation debugging here?", "author": "jasontedor", "createdAt": "2020-12-13T13:42:25Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";\n+        AutoscalingCapacity requiredCapacity = AutoscalingCapacity.builder()\n+            .total(autoscalingCapacity.total().storage().getBytes() + unassigned + assigned, null)\n+            .node(maxShard, null)\n+            .build();\n+        return new AutoscalingDeciderResult(requiredCapacity, new ReactiveReason(message, unassigned, assigned));\n+    }\n+\n+    static boolean isDiskOnlyNoDecision(Decision decision) {\n+        // we consider throttling==yes, throttling should be temporary.\n+        List<Decision> nos = decision.getDecisions()\n+            .stream()\n+            .filter(single -> single.type() == Decision.Type.NO)\n+            .collect(Collectors.toList());\n+        return nos.size() == 1 && DiskThresholdDecider.NAME.equals(nos.get(0).label());\n+    }\n+\n+    static class AllocationState {\n+        private final ClusterState state;\n+        private final AllocationDeciders allocationDeciders;\n+        private final DiskThresholdSettings diskThresholdSettings;\n+        private final ClusterInfo info;\n+        private final SnapshotShardSizeInfo shardSizeInfo;\n+        private final Predicate<DiscoveryNode> nodeTierPredicate;\n+        private final Set<DiscoveryNode> nodes;\n+\n+        AllocationState(\n+            AutoscalingDeciderContext context,\n+            DiskThresholdSettings diskThresholdSettings,\n+            AllocationDeciders allocationDeciders\n+        ) {\n+            this(\n+                context.state(),\n+                allocationDeciders,\n+                diskThresholdSettings,\n+                context.info(),\n+                context.snapshotShardSizeInfo(),\n+                context.nodes()\n+            );\n+        }\n+\n+        AllocationState(\n+            ClusterState state,\n+            AllocationDeciders allocationDeciders,\n+            DiskThresholdSettings diskThresholdSettings,\n+            ClusterInfo info,\n+            SnapshotShardSizeInfo shardSizeInfo,\n+            Set<DiscoveryNode> nodes\n+        ) {\n+            this.state = state;\n+            this.allocationDeciders = allocationDeciders;\n+            this.diskThresholdSettings = diskThresholdSettings;\n+            this.info = info;\n+            this.shardSizeInfo = shardSizeInfo;\n+            this.nodes = nodes;\n+            this.nodeTierPredicate = nodes::contains;\n+        }\n+\n+        public long storagePreventsAllocation() {\n+            RoutingNodes routingNodes = new RoutingNodes(state, false);\n+            RoutingAllocation allocation = new RoutingAllocation(\n+                allocationDeciders,\n+                routingNodes,\n+                state,\n+                info,\n+                shardSizeInfo,\n+                System.nanoTime()\n+            );\n+            return StreamSupport.stream(state.getRoutingNodes().unassigned().spliterator(), false)\n+                .filter(shard -> canAllocate(shard, allocation) == false)\n+                .filter(shard -> cannotAllocateDueToStorage(shard, allocation))\n+                .mapToLong(this::sizeOf)\n+                .sum();\n+        }\n+\n+        public long storagePreventsRemainOrMove() {\n+            RoutingNodes routingNodes = new RoutingNodes(state, false);\n+            RoutingAllocation allocation = new RoutingAllocation(\n+                allocationDeciders,\n+                routingNodes,\n+                state,\n+                info,\n+                shardSizeInfo,\n+                System.nanoTime()\n+            );\n+            List<ShardRouting> candidates = state.getRoutingNodes()\n+                .shardsWithState(ShardRoutingState.STARTED)\n+                .stream()\n+                .filter(shard -> allocationDeciders.canRemain(shard, routingNodes.node(shard.currentNodeId()), allocation) == Decision.NO)\n+                .filter(shard -> canAllocate(shard, allocation) == false)\n+                .collect(Collectors.toList());\n+\n+            // track these to ensure we do not double account if they both cannot remain and allocated due to storage.\n+            Set<ShardRouting> unmovableShards = candidates.stream()\n+                .filter(s -> allocatedToTier(s, allocation))\n+                .filter(s -> cannotRemainDueToStorage(s, allocation))\n+                .collect(Collectors.toSet());\n+            long unmovableBytes = unmovableShards.stream()\n+                .collect(Collectors.groupingBy(ShardRouting::currentNodeId))\n+                .entrySet()\n+                .stream()\n+                .mapToLong(e -> unmovableSize(e.getKey(), e.getValue()))\n+                .sum();\n+\n+            long unallocatableBytes = candidates.stream()\n+                .filter(Predicate.not(unmovableShards::contains))\n+                .filter(s1 -> cannotAllocateDueToStorage(s1, allocation))\n+                .mapToLong(this::sizeOf)\n+                .sum();\n+\n+            return unallocatableBytes + unmovableBytes;\n+        }\n+\n+        private boolean allocatedToTier(ShardRouting s, RoutingAllocation allocation) {\n+            return nodeTierPredicate.test(allocation.routingNodes().node(s.currentNodeId()).node());\n+        }\n+\n+        /**\n+         * Check that disk decider is only decider for a node preventing allocation of the shard.\n+         * @return true if and only if a node exists in the tier where only disk decider prevents allocation\n+         */\n+        private boolean cannotAllocateDueToStorage(ShardRouting shard, RoutingAllocation allocation) {\n+            assert allocation.debugDecision() == false;\n+            allocation.debugDecision(true);", "originalCommit": "f28fb9a0ed9cc82720505c884887107b0cb96270", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk2MjgwOQ==", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541962809", "bodyText": "\ud83d\udc4d, 6a9c5cb", "author": "henningandersen", "createdAt": "2020-12-13T16:56:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyODI2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyODI4NA==", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541928284", "bodyText": "Can you leave a comment explaining why we need to enable allocation debugging here?", "author": "jasontedor", "createdAt": "2020-12-13T13:42:30Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";\n+        AutoscalingCapacity requiredCapacity = AutoscalingCapacity.builder()\n+            .total(autoscalingCapacity.total().storage().getBytes() + unassigned + assigned, null)\n+            .node(maxShard, null)\n+            .build();\n+        return new AutoscalingDeciderResult(requiredCapacity, new ReactiveReason(message, unassigned, assigned));\n+    }\n+\n+    static boolean isDiskOnlyNoDecision(Decision decision) {\n+        // we consider throttling==yes, throttling should be temporary.\n+        List<Decision> nos = decision.getDecisions()\n+            .stream()\n+            .filter(single -> single.type() == Decision.Type.NO)\n+            .collect(Collectors.toList());\n+        return nos.size() == 1 && DiskThresholdDecider.NAME.equals(nos.get(0).label());\n+    }\n+\n+    static class AllocationState {\n+        private final ClusterState state;\n+        private final AllocationDeciders allocationDeciders;\n+        private final DiskThresholdSettings diskThresholdSettings;\n+        private final ClusterInfo info;\n+        private final SnapshotShardSizeInfo shardSizeInfo;\n+        private final Predicate<DiscoveryNode> nodeTierPredicate;\n+        private final Set<DiscoveryNode> nodes;\n+\n+        AllocationState(\n+            AutoscalingDeciderContext context,\n+            DiskThresholdSettings diskThresholdSettings,\n+            AllocationDeciders allocationDeciders\n+        ) {\n+            this(\n+                context.state(),\n+                allocationDeciders,\n+                diskThresholdSettings,\n+                context.info(),\n+                context.snapshotShardSizeInfo(),\n+                context.nodes()\n+            );\n+        }\n+\n+        AllocationState(\n+            ClusterState state,\n+            AllocationDeciders allocationDeciders,\n+            DiskThresholdSettings diskThresholdSettings,\n+            ClusterInfo info,\n+            SnapshotShardSizeInfo shardSizeInfo,\n+            Set<DiscoveryNode> nodes\n+        ) {\n+            this.state = state;\n+            this.allocationDeciders = allocationDeciders;\n+            this.diskThresholdSettings = diskThresholdSettings;\n+            this.info = info;\n+            this.shardSizeInfo = shardSizeInfo;\n+            this.nodes = nodes;\n+            this.nodeTierPredicate = nodes::contains;\n+        }\n+\n+        public long storagePreventsAllocation() {\n+            RoutingNodes routingNodes = new RoutingNodes(state, false);\n+            RoutingAllocation allocation = new RoutingAllocation(\n+                allocationDeciders,\n+                routingNodes,\n+                state,\n+                info,\n+                shardSizeInfo,\n+                System.nanoTime()\n+            );\n+            return StreamSupport.stream(state.getRoutingNodes().unassigned().spliterator(), false)\n+                .filter(shard -> canAllocate(shard, allocation) == false)\n+                .filter(shard -> cannotAllocateDueToStorage(shard, allocation))\n+                .mapToLong(this::sizeOf)\n+                .sum();\n+        }\n+\n+        public long storagePreventsRemainOrMove() {\n+            RoutingNodes routingNodes = new RoutingNodes(state, false);\n+            RoutingAllocation allocation = new RoutingAllocation(\n+                allocationDeciders,\n+                routingNodes,\n+                state,\n+                info,\n+                shardSizeInfo,\n+                System.nanoTime()\n+            );\n+            List<ShardRouting> candidates = state.getRoutingNodes()\n+                .shardsWithState(ShardRoutingState.STARTED)\n+                .stream()\n+                .filter(shard -> allocationDeciders.canRemain(shard, routingNodes.node(shard.currentNodeId()), allocation) == Decision.NO)\n+                .filter(shard -> canAllocate(shard, allocation) == false)\n+                .collect(Collectors.toList());\n+\n+            // track these to ensure we do not double account if they both cannot remain and allocated due to storage.\n+            Set<ShardRouting> unmovableShards = candidates.stream()\n+                .filter(s -> allocatedToTier(s, allocation))\n+                .filter(s -> cannotRemainDueToStorage(s, allocation))\n+                .collect(Collectors.toSet());\n+            long unmovableBytes = unmovableShards.stream()\n+                .collect(Collectors.groupingBy(ShardRouting::currentNodeId))\n+                .entrySet()\n+                .stream()\n+                .mapToLong(e -> unmovableSize(e.getKey(), e.getValue()))\n+                .sum();\n+\n+            long unallocatableBytes = candidates.stream()\n+                .filter(Predicate.not(unmovableShards::contains))\n+                .filter(s1 -> cannotAllocateDueToStorage(s1, allocation))\n+                .mapToLong(this::sizeOf)\n+                .sum();\n+\n+            return unallocatableBytes + unmovableBytes;\n+        }\n+\n+        private boolean allocatedToTier(ShardRouting s, RoutingAllocation allocation) {\n+            return nodeTierPredicate.test(allocation.routingNodes().node(s.currentNodeId()).node());\n+        }\n+\n+        /**\n+         * Check that disk decider is only decider for a node preventing allocation of the shard.\n+         * @return true if and only if a node exists in the tier where only disk decider prevents allocation\n+         */\n+        private boolean cannotAllocateDueToStorage(ShardRouting shard, RoutingAllocation allocation) {\n+            assert allocation.debugDecision() == false;\n+            allocation.debugDecision(true);\n+            try {\n+                return nodesInTier(allocation.routingNodes()).map(node -> allocationDeciders.canAllocate(shard, node, allocation))\n+                    .anyMatch(ReactiveStorageDeciderService::isDiskOnlyNoDecision);\n+            } finally {\n+                allocation.debugDecision(false);\n+            }\n+        }\n+\n+        /**\n+         * Check that the disk decider is only decider that says NO to let shard remain on current node.\n+         * @return true if and only if disk decider is only decider that says NO to canRemain.\n+         */\n+        private boolean cannotRemainDueToStorage(ShardRouting shard, RoutingAllocation allocation) {\n+            assert allocation.debugDecision() == false;\n+            allocation.debugDecision(true);", "originalCommit": "f28fb9a0ed9cc82720505c884887107b0cb96270", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyODU5Mw==", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541928593", "bodyText": "Minor nit: since these represent bytes and not a count of shards, could we clarify the names: unassignedBytes, assignedBytes, and maxShardSize?", "author": "jasontedor", "createdAt": "2020-12-13T13:44:30Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();", "originalCommit": "f28fb9a0ed9cc82720505c884887107b0cb96270", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyOTI3OA==", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541929278", "bodyText": "I wonder if this should be human readable bytes? So new ByteSizeValue(unassigned + assigned).toString()?", "author": "jasontedor", "createdAt": "2020-12-13T13:48:32Z", "path": "x-pack/plugin/autoscaling/src/main/java/org/elasticsearch/xpack/autoscaling/storage/ReactiveStorageDeciderService.java", "diffHunk": "@@ -0,0 +1,365 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.autoscaling.storage;\n+\n+import org.elasticsearch.cluster.ClusterInfo;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.DiskUsage;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.cluster.routing.RoutingNode;\n+import org.elasticsearch.cluster.routing.RoutingNodes;\n+import org.elasticsearch.cluster.routing.ShardRouting;\n+import org.elasticsearch.cluster.routing.ShardRoutingState;\n+import org.elasticsearch.cluster.routing.allocation.DiskThresholdSettings;\n+import org.elasticsearch.cluster.routing.allocation.RoutingAllocation;\n+import org.elasticsearch.cluster.routing.allocation.decider.AllocationDeciders;\n+import org.elasticsearch.cluster.routing.allocation.decider.Decision;\n+import org.elasticsearch.cluster.routing.allocation.decider.DiskThresholdDecider;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Setting;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeUnit;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.snapshots.SnapshotShardSizeInfo;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingCapacity;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderContext;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderResult;\n+import org.elasticsearch.xpack.autoscaling.capacity.AutoscalingDeciderService;\n+import org.elasticsearch.xpack.core.DataTier;\n+\n+import java.io.IOException;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class ReactiveStorageDeciderService implements AutoscalingDeciderService {\n+    public static final String NAME = \"reactive_storage\";\n+\n+    private final DiskThresholdSettings diskThresholdSettings;\n+    private final AllocationDeciders allocationDeciders;\n+\n+    public ReactiveStorageDeciderService(Settings settings, ClusterSettings clusterSettings, AllocationDeciders allocationDeciders) {\n+        this.diskThresholdSettings = new DiskThresholdSettings(settings, clusterSettings);\n+        this.allocationDeciders = allocationDeciders;\n+    }\n+\n+    @Override\n+    public String name() {\n+        return NAME;\n+    }\n+\n+    @Override\n+    public List<Setting<?>> deciderSettings() {\n+        return List.of();\n+    }\n+\n+    @Override\n+    public List<DiscoveryNodeRole> roles() {\n+        return List.of(\n+            DiscoveryNodeRole.DATA_ROLE,\n+            DataTier.DATA_CONTENT_NODE_ROLE,\n+            DataTier.DATA_HOT_NODE_ROLE,\n+            DataTier.DATA_WARM_NODE_ROLE,\n+            DataTier.DATA_COLD_NODE_ROLE\n+        );\n+    }\n+\n+    @Override\n+    public AutoscalingDeciderResult scale(Settings configuration, AutoscalingDeciderContext context) {\n+        AutoscalingCapacity autoscalingCapacity = context.currentCapacity();\n+        if (autoscalingCapacity == null || autoscalingCapacity.total().storage() == null) {\n+            return new AutoscalingDeciderResult(null, new ReactiveReason(\"current capacity not available\", -1, -1));\n+        }\n+\n+        AllocationState allocationState = new AllocationState(context, diskThresholdSettings, allocationDeciders);\n+        long unassigned = allocationState.storagePreventsAllocation();\n+        long assigned = allocationState.storagePreventsRemainOrMove();\n+        long maxShard = allocationState.maxShardSize();\n+        assert assigned >= 0;\n+        assert unassigned >= 0;\n+        assert maxShard >= 0;\n+        String message = unassigned > 0 || assigned > 0 ? \"not enough storage available, needs \" + (unassigned + assigned) : \"storage ok\";", "originalCommit": "f28fb9a0ed9cc82720505c884887107b0cb96270", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyOTM1NA==", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541929354", "bodyText": "And if not,  bytes should be appended to the message.", "author": "jasontedor", "createdAt": "2020-12-13T13:48:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyOTI3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTk2MzAwMg==", "url": "https://github.com/elastic/elasticsearch/pull/65520#discussion_r541963002", "bodyText": "\ud83d\udc4d, b58d294", "author": "henningandersen", "createdAt": "2020-12-13T16:58:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTkyOTI3OA=="}], "type": "inlineReview"}, {"oid": "22456be13356107f7d98e09b40a593d2a8de3220", "url": "https://github.com/elastic/elasticsearch/commit/22456be13356107f7d98e09b40a593d2a8de3220", "message": "Javadoc on AutoscalingDeciderContext", "committedDate": "2020-12-13T15:05:19Z", "type": "commit"}, {"oid": "555991a425f911d289a21c0a30c7e3834b9e2fd5", "url": "https://github.com/elastic/elasticsearch/commit/555991a425f911d289a21c0a30c7e3834b9e2fd5", "message": "Test roles().", "committedDate": "2020-12-13T15:18:21Z", "type": "commit"}, {"oid": "6a9c5cb37b021a45c592c283ebb00078eb1990ef", "url": "https://github.com/elastic/elasticsearch/commit/6a9c5cb37b021a45c592c283ebb00078eb1990ef", "message": "comment why we need debug decisions.", "committedDate": "2020-12-13T15:21:22Z", "type": "commit"}, {"oid": "b58d29462a12559caaeef09b7aae0193a4a65ef9", "url": "https://github.com/elastic/elasticsearch/commit/b58d29462a12559caaeef09b7aae0193a4a65ef9", "message": "Include byte unit in base message.", "committedDate": "2020-12-13T16:53:17Z", "type": "commit"}, {"oid": "7b5f370d70ba7e9b07ab0a30fd1f1e4944fa318b", "url": "https://github.com/elastic/elasticsearch/commit/7b5f370d70ba7e9b07ab0a30fd1f1e4944fa318b", "message": "Merge remote-tracking branch 'origin/master' into enhance_reactive_storage_autoscaler_pr_final", "committedDate": "2020-12-13T17:13:18Z", "type": "commit"}]}