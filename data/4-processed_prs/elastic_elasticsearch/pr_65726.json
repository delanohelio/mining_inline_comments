{"pr_number": 65726, "pr_title": "[DOCS] Adds Working with transforms at scale to docs", "pr_createdAt": "2020-12-02T10:49:29Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/65726", "timeline": [{"oid": "b73686ef844425b9f86773eb41d164c435641c44", "url": "https://github.com/elastic/elasticsearch/commit/b73686ef844425b9f86773eb41d164c435641c44", "message": "[DOCS] Adds Working with transforms at scale to docs.", "committedDate": "2020-12-02T10:29:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYwOTY4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534609689", "bodyText": "<<transform-overview,How to create {transforms}>>.\n\nThis link text seems misleading to me.  That page doesn't tell you how to create transforms as much as what transforms are at a high level.  Maybe the link text should be \"the purpose of transforms\" or \"basic concepts associated with transforms\". Or maybe omit the link all together?", "author": "lcawl", "createdAt": "2020-12-03T01:59:53Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxMjEwMA==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534612100", "bodyText": "These guildelines assume you\u2019re already familiar with:\n\nFrom subsequent paragraphs, it seems like the assumption is that you're not just familiar with these concepts, but you have a transform that you're now attempting to tune/debug.  Should that be the prerequisite instead?", "author": "lcawl", "createdAt": "2020-12-03T02:05:50Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: ", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxMzE5Mg==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534613192", "bodyText": "the factor that may be improved by following the given recommendation.\n\nI found myself wondering what a \"factor\" was.  Is it equivalent to the \"bottleneck areas\" mentioned earlier? If so, it might be helpful to clarify that here so readers don't get derailed wondering what it means.", "author": "lcawl", "createdAt": "2020-12-03T02:09:10Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxNDEzNw==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534614137", "bodyText": "== Measure {transforms} performance\n\nShould this section have a number too?  This feels like a necessary first step in the troubleshooting process.", "author": "lcawl", "createdAt": "2020-12-03T02:11:45Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTA5MTk1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r535091959", "bodyText": "This is a necessary first step while all the other steps are optional.\nWe say in the previous paragraph that \"[t]he following considerations are not sequential \u2013 the numbers help to navigate\nbetween the list items; you can take action on one or more of them in any order.\"\nI wanted to emphasize that it is a required step by not adding a number to it, so this way it is not a part of the list that enumerate optional steps.", "author": "szabosteve", "createdAt": "2020-12-03T10:49:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxNDEzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxNjQxNg==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534616416", "bodyText": "== 1. Optimize frequency (index)\n\nHave you considered putting all the index-related actions together? I found myself wondering why the sections flip from index-related to search-related then back to index-related suggestions. If there's a reason they're sorted that way, it wasn't obvious to me.", "author": "lcawl", "createdAt": "2020-12-03T02:17:52Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTEwNDk0MQ==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r535104941", "bodyText": "The list goes from the easy wins to the steps that are harder to execute. I added a sentence to explain it (line 34-35).", "author": "szabosteve", "createdAt": "2020-12-03T11:02:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxNjQxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTEzOTc5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r535139791", "bodyText": "The list goes from the easy wins to the steps that are harder to execute.  I added a sentence to explain it (line 34-35).\n\nThis isn't true enough to state .. for example limiting the scope of the query is at the bottom, but relatively easy to execute. We haven't ordered this particularly actively.", "author": "sophiec20", "createdAt": "2020-12-03T11:35:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxNjQxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE1NDk4MQ==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r535154981", "bodyText": "Then I group the actions in my next commit into four groups: index, search, process, storage.", "author": "szabosteve", "createdAt": "2020-12-03T11:50:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxNjQxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE2MTEyNg==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r535161126", "bodyText": "Addressed via d7d67fa.", "author": "szabosteve", "createdAt": "2020-12-03T11:57:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxNjQxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxNzAxMQ==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534617011", "bodyText": "In a continuous transform ... when the transform runs continuously.\n\nI think one of these phrases is redundant.", "author": "lcawl", "createdAt": "2020-12-03T02:19:36Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs ", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTEwNTU1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r535105553", "bodyText": "Editing error... thanks for spotting it!", "author": "szabosteve", "createdAt": "2020-12-03T11:03:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxNzAxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxODEwMw==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534618103", "bodyText": "Changing the frequency will change the profile of the transform workload.\n\nIMO this sentence is unnecessary and is a little too vague to be helpful. The subsequent sentence is more concrete.", "author": "lcawl", "createdAt": "2020-12-03T02:22:36Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs \n+continuously. If changes are detected, then the source data is searched and the \n+changes are applied to the destination index. Changing the frequency will change ", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxODM1NA==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534618354", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            `frequency` to a higher value (maximum is one hour) workload can be spread over \n          \n          \n            \n            `frequency` to a higher value (maximum is one hour), the workload can be spread over", "author": "lcawl", "createdAt": "2020-12-03T02:23:20Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs \n+continuously. If changes are detected, then the source data is searched and the \n+changes are applied to the destination index. Changing the frequency will change \n+the profile of the {transform} workload. Depending on your use case, you may \n+wish to reduce the frequency at which changes are applied. By setting \n+`frequency` to a higher value (maximum is one hour) workload can be spread over ", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxODUwMg==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534618502", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            time for the cost of less up-to-date data.\n          \n          \n            \n            time at the cost of less up-to-date data.", "author": "lcawl", "createdAt": "2020-12-03T02:23:36Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs \n+continuously. If changes are detected, then the source data is searched and the \n+changes are applied to the destination index. Changing the frequency will change \n+the profile of the {transform} workload. Depending on your use case, you may \n+wish to reduce the frequency at which changes are applied. By setting \n+`frequency` to a higher value (maximum is one hour) workload can be spread over \n+time for the cost of less up-to-date data.", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYxOTQ1MA==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534619450", "bodyText": "I don't think this needs to be capitalized:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            == 3. Use Index Sorting and `group_by` ordering (search, process)\n          \n          \n            \n            == 3. Use index sorting and `group_by` ordering (search, process)", "author": "lcawl", "createdAt": "2020-12-03T02:26:09Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs \n+continuously. If changes are detected, then the source data is searched and the \n+changes are applied to the destination index. Changing the frequency will change \n+the profile of the {transform} workload. Depending on your use case, you may \n+wish to reduce the frequency at which changes are applied. By setting \n+`frequency` to a higher value (maximum is one hour) workload can be spread over \n+time for the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 2. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[index-sorting-group-by-ordering]]\n+== 3. Use Index Sorting and `group_by` ordering (search, process)", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYyMjEzMw==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534622133", "bodyText": "in conjunction with the use of index sorting ...\n\nWhile reading this, I wondered if it was possible to change the index sorting for an existing index. The linked docs say \"\nIndex sorting can be defined only once at index creation. It is not allowed to add or update a sort on an existing index.\" Therefore perhaps we should clarify that this step can only be taken if you already have index sorting in place (or are able to reindex?)", "author": "lcawl", "createdAt": "2020-12-03T02:33:52Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs \n+continuously. If changes are detected, then the source data is searched and the \n+changes are applied to the destination index. Changing the frequency will change \n+the profile of the {transform} workload. Depending on your use case, you may \n+wish to reduce the frequency at which changes are applied. By setting \n+`frequency` to a higher value (maximum is one hour) workload can be spread over \n+time for the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 2. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[index-sorting-group-by-ordering]]\n+== 3. Use Index Sorting and `group_by` ordering (search, process)\n+\n+If you use more than one `group_by` field in your {transform}, then the order of \n+the fields in conjunction with the use of <<index-modules-index-sorting>> may \n+improve runtime.", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTE0ODk0Mw==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r535148943", "bodyText": "I've clarified it in the latest commit (2f95873).", "author": "szabosteve", "createdAt": "2020-12-03T11:44:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYyMjEzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYyNDE5OA==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534624198", "bodyText": "<<scalability,Depending on the size of the destination index>>, you may consider\n\nI think this link should be referenced separately, since I'm not sure why I'd click it here. Maybe something like this:\n\nDepending on the size of the index, you may consider increasing its shard count... create the destination index before you start the transform. For more information about how the number of shards affects scalability and resilience, refer to <<scalability>>.", "author": "lcawl", "createdAt": "2020-12-03T02:39:44Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs \n+continuously. If changes are detected, then the source data is searched and the \n+changes are applied to the destination index. Changing the frequency will change \n+the profile of the {transform} workload. Depending on your use case, you may \n+wish to reduce the frequency at which changes are applied. By setting \n+`frequency` to a higher value (maximum is one hour) workload can be spread over \n+time for the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 2. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[index-sorting-group-by-ordering]]\n+== 3. Use Index Sorting and `group_by` ordering (search, process)\n+\n+If you use more than one `group_by` field in your {transform}, then the order of \n+the fields in conjunction with the use of <<index-modules-index-sorting>> may \n+improve runtime.\n+\n+Index sorting enables you to store documents on disk in a specific order which \n+can improve query efficiency. The ideal sorting logic depends on your use case, \n+but the rule of thumb may be to sort the fields in descending order (high to low \n+cardinality) starting with the time-based fields. Then put the time-based \n+components first in the `group_by` if you have any, and then apply the same \n+order to your `group_by` fields as configured for index sorting. \n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 4. Increase the number of shards of the destination index (index)\n+\n+<<scalability,Depending on the size of the destination index>>, you may consider ", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYyNDU4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534624587", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Hint: Use the <<preview-transform>> to check the settings that the {transform} \n          \n          \n            \n            TIP: Use the <<preview-transform,preview transform API>> to check the settings that the {transform}", "author": "lcawl", "createdAt": "2020-12-03T02:40:55Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs \n+continuously. If changes are detected, then the source data is searched and the \n+changes are applied to the destination index. Changing the frequency will change \n+the profile of the {transform} workload. Depending on your use case, you may \n+wish to reduce the frequency at which changes are applied. By setting \n+`frequency` to a higher value (maximum is one hour) workload can be spread over \n+time for the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 2. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[index-sorting-group-by-ordering]]\n+== 3. Use Index Sorting and `group_by` ordering (search, process)\n+\n+If you use more than one `group_by` field in your {transform}, then the order of \n+the fields in conjunction with the use of <<index-modules-index-sorting>> may \n+improve runtime.\n+\n+Index sorting enables you to store documents on disk in a specific order which \n+can improve query efficiency. The ideal sorting logic depends on your use case, \n+but the rule of thumb may be to sort the fields in descending order (high to low \n+cardinality) starting with the time-based fields. Then put the time-based \n+components first in the `group_by` if you have any, and then apply the same \n+order to your `group_by` fields as configured for index sorting. \n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 4. Increase the number of shards of the destination index (index)\n+\n+<<scalability,Depending on the size of the destination index>>, you may consider \n+increasing its shard count. {transforms-cap} use one shard by default when \n+creating the destination index. To override the index settings, create the \n+destination index before starting the {transform}.\n+\n+Hint: Use the <<preview-transform>> to check the settings that the {transform} ", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYyNTkxNg==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534625916", "bodyText": "that was passed ...\n\nThis wording makes me wonder: \"Passed to where?\" or \"Passed to what?\". Is there a clearer way to state this?", "author": "lcawl", "createdAt": "2020-12-03T02:44:43Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs \n+continuously. If changes are detected, then the source data is searched and the \n+changes are applied to the destination index. Changing the frequency will change \n+the profile of the {transform} workload. Depending on your use case, you may \n+wish to reduce the frequency at which changes are applied. By setting \n+`frequency` to a higher value (maximum is one hour) workload can be spread over \n+time for the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 2. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[index-sorting-group-by-ordering]]\n+== 3. Use Index Sorting and `group_by` ordering (search, process)\n+\n+If you use more than one `group_by` field in your {transform}, then the order of \n+the fields in conjunction with the use of <<index-modules-index-sorting>> may \n+improve runtime.\n+\n+Index sorting enables you to store documents on disk in a specific order which \n+can improve query efficiency. The ideal sorting logic depends on your use case, \n+but the rule of thumb may be to sort the fields in descending order (high to low \n+cardinality) starting with the time-based fields. Then put the time-based \n+components first in the `group_by` if you have any, and then apply the same \n+order to your `group_by` fields as configured for index sorting. \n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 4. Increase the number of shards of the destination index (index)\n+\n+<<scalability,Depending on the size of the destination index>>, you may consider \n+increasing its shard count. {transforms-cap} use one shard by default when \n+creating the destination index. To override the index settings, create the \n+destination index before starting the {transform}.\n+\n+Hint: Use the <<preview-transform>> to check the settings that the {transform} \n+would use to create the destination index. You can copy and adjust these in \n+order to create the destination index prior to starting the {transform}.\n+\n+\n+[discrete]\n+[[optimize-shading-strategy]]\n+== 5. Optimize the sharding strategy for the source index (search)\n+\n+There is no one-size-fits-all sharding strategy. A strategy that works in one \n+environment may not scale in another. A good sharding strategy must account for \n+your infrastructure, use case, and performance expectations.\n+\n+Too few shards may mean that the benefits of distributing the workload cannot be \n+realised; however too many shards may impact your cluster health. To learn more \n+about sizing your shards, read this <<size-your-shards,guide>>.\n+\n+\n+[discrete]\n+[[disable-source-dest]]\n+== 6. Disable the `_source` field on the destination index (storage)\n+\n+The <<mapping-source-field>> contains the original JSON document body that was \n+passed at index time. The `_source` field itself is not indexed (and thus is not ", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYyNzM3NQ==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534627375", "bodyText": "I think it would be helpful to clarify where this is set, since we've been talking about all sorts of varied index and shard settings up til now. For example:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The `max_page_search_size` parameter defines the number of buckets that are \n          \n          \n            \n            The `max_page_search_size` transform configuration option defines the number of buckets that are", "author": "lcawl", "createdAt": "2020-12-03T02:48:59Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs \n+continuously. If changes are detected, then the source data is searched and the \n+changes are applied to the destination index. Changing the frequency will change \n+the profile of the {transform} workload. Depending on your use case, you may \n+wish to reduce the frequency at which changes are applied. By setting \n+`frequency` to a higher value (maximum is one hour) workload can be spread over \n+time for the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 2. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[index-sorting-group-by-ordering]]\n+== 3. Use Index Sorting and `group_by` ordering (search, process)\n+\n+If you use more than one `group_by` field in your {transform}, then the order of \n+the fields in conjunction with the use of <<index-modules-index-sorting>> may \n+improve runtime.\n+\n+Index sorting enables you to store documents on disk in a specific order which \n+can improve query efficiency. The ideal sorting logic depends on your use case, \n+but the rule of thumb may be to sort the fields in descending order (high to low \n+cardinality) starting with the time-based fields. Then put the time-based \n+components first in the `group_by` if you have any, and then apply the same \n+order to your `group_by` fields as configured for index sorting. \n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 4. Increase the number of shards of the destination index (index)\n+\n+<<scalability,Depending on the size of the destination index>>, you may consider \n+increasing its shard count. {transforms-cap} use one shard by default when \n+creating the destination index. To override the index settings, create the \n+destination index before starting the {transform}.\n+\n+Hint: Use the <<preview-transform>> to check the settings that the {transform} \n+would use to create the destination index. You can copy and adjust these in \n+order to create the destination index prior to starting the {transform}.\n+\n+\n+[discrete]\n+[[optimize-shading-strategy]]\n+== 5. Optimize the sharding strategy for the source index (search)\n+\n+There is no one-size-fits-all sharding strategy. A strategy that works in one \n+environment may not scale in another. A good sharding strategy must account for \n+your infrastructure, use case, and performance expectations.\n+\n+Too few shards may mean that the benefits of distributing the workload cannot be \n+realised; however too many shards may impact your cluster health. To learn more \n+about sizing your shards, read this <<size-your-shards,guide>>.\n+\n+\n+[discrete]\n+[[disable-source-dest]]\n+== 6. Disable the `_source` field on the destination index (storage)\n+\n+The <<mapping-source-field>> contains the original JSON document body that was \n+passed at index time. The `_source` field itself is not indexed (and thus is not \n+searchable), but it is still stored in the index and incurs a storage overhead. \n+Consider disabling `_source` to save storage space if you have a large \n+destination index. Disabling `_source` is only possible during index creation.\n+\n+NOTE: When the `_source` field is disabled, a number of features are not \n+supported. Consult <<disable-source-field>> to understand the consequences \n+before disabling it.\n+\n+\n+[discrete]\n+[[tune-max-page-search-size]]\n+== 7. Tune `max_page_search_size` (search)\n+\n+The `max_page_search_size` parameter defines the number of buckets that are ", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYyNzg4MQ==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534627881", "bodyText": "Minor suggestion, but I always like putting the conditionals at the beginning of the sentence:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            memory. A circuit breaker exception will occur if memory limits are exceeded.\n          \n          \n            \n            memory. If memory limits are exceeded, a circuit breaker exception occurs.", "author": "lcawl", "createdAt": "2020-12-03T02:50:21Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs \n+continuously. If changes are detected, then the source data is searched and the \n+changes are applied to the destination index. Changing the frequency will change \n+the profile of the {transform} workload. Depending on your use case, you may \n+wish to reduce the frequency at which changes are applied. By setting \n+`frequency` to a higher value (maximum is one hour) workload can be spread over \n+time for the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 2. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[index-sorting-group-by-ordering]]\n+== 3. Use Index Sorting and `group_by` ordering (search, process)\n+\n+If you use more than one `group_by` field in your {transform}, then the order of \n+the fields in conjunction with the use of <<index-modules-index-sorting>> may \n+improve runtime.\n+\n+Index sorting enables you to store documents on disk in a specific order which \n+can improve query efficiency. The ideal sorting logic depends on your use case, \n+but the rule of thumb may be to sort the fields in descending order (high to low \n+cardinality) starting with the time-based fields. Then put the time-based \n+components first in the `group_by` if you have any, and then apply the same \n+order to your `group_by` fields as configured for index sorting. \n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 4. Increase the number of shards of the destination index (index)\n+\n+<<scalability,Depending on the size of the destination index>>, you may consider \n+increasing its shard count. {transforms-cap} use one shard by default when \n+creating the destination index. To override the index settings, create the \n+destination index before starting the {transform}.\n+\n+Hint: Use the <<preview-transform>> to check the settings that the {transform} \n+would use to create the destination index. You can copy and adjust these in \n+order to create the destination index prior to starting the {transform}.\n+\n+\n+[discrete]\n+[[optimize-shading-strategy]]\n+== 5. Optimize the sharding strategy for the source index (search)\n+\n+There is no one-size-fits-all sharding strategy. A strategy that works in one \n+environment may not scale in another. A good sharding strategy must account for \n+your infrastructure, use case, and performance expectations.\n+\n+Too few shards may mean that the benefits of distributing the workload cannot be \n+realised; however too many shards may impact your cluster health. To learn more \n+about sizing your shards, read this <<size-your-shards,guide>>.\n+\n+\n+[discrete]\n+[[disable-source-dest]]\n+== 6. Disable the `_source` field on the destination index (storage)\n+\n+The <<mapping-source-field>> contains the original JSON document body that was \n+passed at index time. The `_source` field itself is not indexed (and thus is not \n+searchable), but it is still stored in the index and incurs a storage overhead. \n+Consider disabling `_source` to save storage space if you have a large \n+destination index. Disabling `_source` is only possible during index creation.\n+\n+NOTE: When the `_source` field is disabled, a number of features are not \n+supported. Consult <<disable-source-field>> to understand the consequences \n+before disabling it.\n+\n+\n+[discrete]\n+[[tune-max-page-search-size]]\n+== 7. Tune `max_page_search_size` (search)\n+\n+The `max_page_search_size` parameter defines the number of buckets that are \n+returned for each search request. The default value is 500. If you increase this \n+value, you get better throughput at the cost of higher latency and memory usage.\n+\n+The ideal value of this parameter is highly dependent on your use case. If your \n+{transform} executes memory-intensive aggregations \u2013 for example, cardinality or \n+percentiles \u2013 then increasing `max_page_search_size` requires more available \n+memory. A circuit breaker exception will occur if memory limits are exceeded.", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYyODQ3Nw==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534628477", "bodyText": "I think the first part of this sentence implies the second part so I'd not use \"and\" here:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Runtime fields and scripted fields are not indexed fields, and their values are \n          \n          \n            \n            Runtime fields and scripted fields are not indexed fields; their values are", "author": "lcawl", "createdAt": "2020-12-03T02:52:00Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs \n+continuously. If changes are detected, then the source data is searched and the \n+changes are applied to the destination index. Changing the frequency will change \n+the profile of the {transform} workload. Depending on your use case, you may \n+wish to reduce the frequency at which changes are applied. By setting \n+`frequency` to a higher value (maximum is one hour) workload can be spread over \n+time for the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 2. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[index-sorting-group-by-ordering]]\n+== 3. Use Index Sorting and `group_by` ordering (search, process)\n+\n+If you use more than one `group_by` field in your {transform}, then the order of \n+the fields in conjunction with the use of <<index-modules-index-sorting>> may \n+improve runtime.\n+\n+Index sorting enables you to store documents on disk in a specific order which \n+can improve query efficiency. The ideal sorting logic depends on your use case, \n+but the rule of thumb may be to sort the fields in descending order (high to low \n+cardinality) starting with the time-based fields. Then put the time-based \n+components first in the `group_by` if you have any, and then apply the same \n+order to your `group_by` fields as configured for index sorting. \n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 4. Increase the number of shards of the destination index (index)\n+\n+<<scalability,Depending on the size of the destination index>>, you may consider \n+increasing its shard count. {transforms-cap} use one shard by default when \n+creating the destination index. To override the index settings, create the \n+destination index before starting the {transform}.\n+\n+Hint: Use the <<preview-transform>> to check the settings that the {transform} \n+would use to create the destination index. You can copy and adjust these in \n+order to create the destination index prior to starting the {transform}.\n+\n+\n+[discrete]\n+[[optimize-shading-strategy]]\n+== 5. Optimize the sharding strategy for the source index (search)\n+\n+There is no one-size-fits-all sharding strategy. A strategy that works in one \n+environment may not scale in another. A good sharding strategy must account for \n+your infrastructure, use case, and performance expectations.\n+\n+Too few shards may mean that the benefits of distributing the workload cannot be \n+realised; however too many shards may impact your cluster health. To learn more \n+about sizing your shards, read this <<size-your-shards,guide>>.\n+\n+\n+[discrete]\n+[[disable-source-dest]]\n+== 6. Disable the `_source` field on the destination index (storage)\n+\n+The <<mapping-source-field>> contains the original JSON document body that was \n+passed at index time. The `_source` field itself is not indexed (and thus is not \n+searchable), but it is still stored in the index and incurs a storage overhead. \n+Consider disabling `_source` to save storage space if you have a large \n+destination index. Disabling `_source` is only possible during index creation.\n+\n+NOTE: When the `_source` field is disabled, a number of features are not \n+supported. Consult <<disable-source-field>> to understand the consequences \n+before disabling it.\n+\n+\n+[discrete]\n+[[tune-max-page-search-size]]\n+== 7. Tune `max_page_search_size` (search)\n+\n+The `max_page_search_size` parameter defines the number of buckets that are \n+returned for each search request. The default value is 500. If you increase this \n+value, you get better throughput at the cost of higher latency and memory usage.\n+\n+The ideal value of this parameter is highly dependent on your use case. If your \n+{transform} executes memory-intensive aggregations \u2013 for example, cardinality or \n+percentiles \u2013 then increasing `max_page_search_size` requires more available \n+memory. A circuit breaker exception will occur if memory limits are exceeded.\n+\n+\n+[discrete]\n+[[indexed-fields-in-source]]\n+== 8. Use indexed fields in your source indices (search)\n+\n+Runtime fields and scripted fields are not indexed fields, and their values are ", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYyOTk4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534629987", "bodyText": "Minor nit, but can we avoid putting \"use\" twice in this sentence? Maybe something like this:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            used for syncing a {ctransform}. \n          \n          \n            \n            that synchs a {ctransform}.", "author": "lcawl", "createdAt": "2020-12-03T02:56:18Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs \n+continuously. If changes are detected, then the source data is searched and the \n+changes are applied to the destination index. Changing the frequency will change \n+the profile of the {transform} workload. Depending on your use case, you may \n+wish to reduce the frequency at which changes are applied. By setting \n+`frequency` to a higher value (maximum is one hour) workload can be spread over \n+time for the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 2. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[index-sorting-group-by-ordering]]\n+== 3. Use Index Sorting and `group_by` ordering (search, process)\n+\n+If you use more than one `group_by` field in your {transform}, then the order of \n+the fields in conjunction with the use of <<index-modules-index-sorting>> may \n+improve runtime.\n+\n+Index sorting enables you to store documents on disk in a specific order which \n+can improve query efficiency. The ideal sorting logic depends on your use case, \n+but the rule of thumb may be to sort the fields in descending order (high to low \n+cardinality) starting with the time-based fields. Then put the time-based \n+components first in the `group_by` if you have any, and then apply the same \n+order to your `group_by` fields as configured for index sorting. \n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 4. Increase the number of shards of the destination index (index)\n+\n+<<scalability,Depending on the size of the destination index>>, you may consider \n+increasing its shard count. {transforms-cap} use one shard by default when \n+creating the destination index. To override the index settings, create the \n+destination index before starting the {transform}.\n+\n+Hint: Use the <<preview-transform>> to check the settings that the {transform} \n+would use to create the destination index. You can copy and adjust these in \n+order to create the destination index prior to starting the {transform}.\n+\n+\n+[discrete]\n+[[optimize-shading-strategy]]\n+== 5. Optimize the sharding strategy for the source index (search)\n+\n+There is no one-size-fits-all sharding strategy. A strategy that works in one \n+environment may not scale in another. A good sharding strategy must account for \n+your infrastructure, use case, and performance expectations.\n+\n+Too few shards may mean that the benefits of distributing the workload cannot be \n+realised; however too many shards may impact your cluster health. To learn more \n+about sizing your shards, read this <<size-your-shards,guide>>.\n+\n+\n+[discrete]\n+[[disable-source-dest]]\n+== 6. Disable the `_source` field on the destination index (storage)\n+\n+The <<mapping-source-field>> contains the original JSON document body that was \n+passed at index time. The `_source` field itself is not indexed (and thus is not \n+searchable), but it is still stored in the index and incurs a storage overhead. \n+Consider disabling `_source` to save storage space if you have a large \n+destination index. Disabling `_source` is only possible during index creation.\n+\n+NOTE: When the `_source` field is disabled, a number of features are not \n+supported. Consult <<disable-source-field>> to understand the consequences \n+before disabling it.\n+\n+\n+[discrete]\n+[[tune-max-page-search-size]]\n+== 7. Tune `max_page_search_size` (search)\n+\n+The `max_page_search_size` parameter defines the number of buckets that are \n+returned for each search request. The default value is 500. If you increase this \n+value, you get better throughput at the cost of higher latency and memory usage.\n+\n+The ideal value of this parameter is highly dependent on your use case. If your \n+{transform} executes memory-intensive aggregations \u2013 for example, cardinality or \n+percentiles \u2013 then increasing `max_page_search_size` requires more available \n+memory. A circuit breaker exception will occur if memory limits are exceeded.\n+\n+\n+[discrete]\n+[[indexed-fields-in-source]]\n+== 8. Use indexed fields in your source indices (search)\n+\n+Runtime fields and scripted fields are not indexed fields, and their values are \n+only extracted or computed at search time. While these fields provide \n+flexibility in how you access your data, they increase performance costs at \n+search time. If {transform} performance using runtime fields or scripted fields \n+is a concern, you may wish to consider using indexed fields instead. For \n+performance reasons, we do not recommend using a runtime field as the time field \n+used for syncing a {ctransform}. ", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYzMDYyOQ==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534630629", "bodyText": "In general, we try to stick with present tense where possible:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            will be accessed. If you use a relative time value (for example, `now-30d`) then \n          \n          \n            \n            are accessed. If you use a relative time value (for example, `now-30d`) then", "author": "lcawl", "createdAt": "2020-12-03T02:58:07Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs \n+continuously. If changes are detected, then the source data is searched and the \n+changes are applied to the destination index. Changing the frequency will change \n+the profile of the {transform} workload. Depending on your use case, you may \n+wish to reduce the frequency at which changes are applied. By setting \n+`frequency` to a higher value (maximum is one hour) workload can be spread over \n+time for the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 2. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[index-sorting-group-by-ordering]]\n+== 3. Use Index Sorting and `group_by` ordering (search, process)\n+\n+If you use more than one `group_by` field in your {transform}, then the order of \n+the fields in conjunction with the use of <<index-modules-index-sorting>> may \n+improve runtime.\n+\n+Index sorting enables you to store documents on disk in a specific order which \n+can improve query efficiency. The ideal sorting logic depends on your use case, \n+but the rule of thumb may be to sort the fields in descending order (high to low \n+cardinality) starting with the time-based fields. Then put the time-based \n+components first in the `group_by` if you have any, and then apply the same \n+order to your `group_by` fields as configured for index sorting. \n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 4. Increase the number of shards of the destination index (index)\n+\n+<<scalability,Depending on the size of the destination index>>, you may consider \n+increasing its shard count. {transforms-cap} use one shard by default when \n+creating the destination index. To override the index settings, create the \n+destination index before starting the {transform}.\n+\n+Hint: Use the <<preview-transform>> to check the settings that the {transform} \n+would use to create the destination index. You can copy and adjust these in \n+order to create the destination index prior to starting the {transform}.\n+\n+\n+[discrete]\n+[[optimize-shading-strategy]]\n+== 5. Optimize the sharding strategy for the source index (search)\n+\n+There is no one-size-fits-all sharding strategy. A strategy that works in one \n+environment may not scale in another. A good sharding strategy must account for \n+your infrastructure, use case, and performance expectations.\n+\n+Too few shards may mean that the benefits of distributing the workload cannot be \n+realised; however too many shards may impact your cluster health. To learn more \n+about sizing your shards, read this <<size-your-shards,guide>>.\n+\n+\n+[discrete]\n+[[disable-source-dest]]\n+== 6. Disable the `_source` field on the destination index (storage)\n+\n+The <<mapping-source-field>> contains the original JSON document body that was \n+passed at index time. The `_source` field itself is not indexed (and thus is not \n+searchable), but it is still stored in the index and incurs a storage overhead. \n+Consider disabling `_source` to save storage space if you have a large \n+destination index. Disabling `_source` is only possible during index creation.\n+\n+NOTE: When the `_source` field is disabled, a number of features are not \n+supported. Consult <<disable-source-field>> to understand the consequences \n+before disabling it.\n+\n+\n+[discrete]\n+[[tune-max-page-search-size]]\n+== 7. Tune `max_page_search_size` (search)\n+\n+The `max_page_search_size` parameter defines the number of buckets that are \n+returned for each search request. The default value is 500. If you increase this \n+value, you get better throughput at the cost of higher latency and memory usage.\n+\n+The ideal value of this parameter is highly dependent on your use case. If your \n+{transform} executes memory-intensive aggregations \u2013 for example, cardinality or \n+percentiles \u2013 then increasing `max_page_search_size` requires more available \n+memory. A circuit breaker exception will occur if memory limits are exceeded.\n+\n+\n+[discrete]\n+[[indexed-fields-in-source]]\n+== 8. Use indexed fields in your source indices (search)\n+\n+Runtime fields and scripted fields are not indexed fields, and their values are \n+only extracted or computed at search time. While these fields provide \n+flexibility in how you access your data, they increase performance costs at \n+search time. If {transform} performance using runtime fields or scripted fields \n+is a concern, you may wish to consider using indexed fields instead. For \n+performance reasons, we do not recommend using a runtime field as the time field \n+used for syncing a {ctransform}. \n+\n+\n+[discrete]\n+[[limit-source-query]]\n+== 9. Limit the scope of the source query (search)\n+\n+Imagine your {ctransform} is configured to group by `IP` and calculate the sum \n+of `bytes_sent`. For each checkpoint, a {ctransform} detects changes in the \n+source data since the previous checkpoint, identifying the IPs for which new \n+data has been ingested. Then it performs a second search, filtered for this \n+group of IPs, in order to calculate the total `bytes_sent`. If this second \n+search matches many shards, then this could be resource intensive. Consider \n+limiting the scope that the source index pattern and query will match.\n+\n+Use an absolute time value as a date range filter in your source query (for \n+example, greater than `2020-01-01T00:00:00`) to limit which historical indices \n+will be accessed. If you use a relative time value (for example, `now-30d`) then ", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDYzMDgwMA==", "url": "https://github.com/elastic/elasticsearch/pull/65726#discussion_r534630800", "bodyText": "Ditto re verb tense:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            this date range will be re-evaluated at the point of each checkpoint execution.\n          \n          \n            \n            this date range is re-evaluated at the point of each checkpoint execution.", "author": "lcawl", "createdAt": "2020-12-03T02:58:41Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,197 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard Elasticsearch features so \n+similar considerations for working with Elasticsearch at scale are often \n+applicable to transforms. If you experience performance issues, start by \n+identifying the bottleneck areas (search, indexing, processing, or storage) then \n+review the relevant considerations in this guide to improve performance. It also \n+helps to understand how {transforms} work as different considerations apply \n+depending on whether or not your transform is running in continuous mode or in \n+batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you\u2019re already familiar with: \n+\n+* <<transform-overview,How to create {transforms}>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the factor that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices when the {transform} runs \n+continuously. If changes are detected, then the source data is searched and the \n+changes are applied to the destination index. Changing the frequency will change \n+the profile of the {transform} workload. Depending on your use case, you may \n+wish to reduce the frequency at which changes are applied. By setting \n+`frequency` to a higher value (maximum is one hour) workload can be spread over \n+time for the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 2. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[index-sorting-group-by-ordering]]\n+== 3. Use Index Sorting and `group_by` ordering (search, process)\n+\n+If you use more than one `group_by` field in your {transform}, then the order of \n+the fields in conjunction with the use of <<index-modules-index-sorting>> may \n+improve runtime.\n+\n+Index sorting enables you to store documents on disk in a specific order which \n+can improve query efficiency. The ideal sorting logic depends on your use case, \n+but the rule of thumb may be to sort the fields in descending order (high to low \n+cardinality) starting with the time-based fields. Then put the time-based \n+components first in the `group_by` if you have any, and then apply the same \n+order to your `group_by` fields as configured for index sorting. \n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 4. Increase the number of shards of the destination index (index)\n+\n+<<scalability,Depending on the size of the destination index>>, you may consider \n+increasing its shard count. {transforms-cap} use one shard by default when \n+creating the destination index. To override the index settings, create the \n+destination index before starting the {transform}.\n+\n+Hint: Use the <<preview-transform>> to check the settings that the {transform} \n+would use to create the destination index. You can copy and adjust these in \n+order to create the destination index prior to starting the {transform}.\n+\n+\n+[discrete]\n+[[optimize-shading-strategy]]\n+== 5. Optimize the sharding strategy for the source index (search)\n+\n+There is no one-size-fits-all sharding strategy. A strategy that works in one \n+environment may not scale in another. A good sharding strategy must account for \n+your infrastructure, use case, and performance expectations.\n+\n+Too few shards may mean that the benefits of distributing the workload cannot be \n+realised; however too many shards may impact your cluster health. To learn more \n+about sizing your shards, read this <<size-your-shards,guide>>.\n+\n+\n+[discrete]\n+[[disable-source-dest]]\n+== 6. Disable the `_source` field on the destination index (storage)\n+\n+The <<mapping-source-field>> contains the original JSON document body that was \n+passed at index time. The `_source` field itself is not indexed (and thus is not \n+searchable), but it is still stored in the index and incurs a storage overhead. \n+Consider disabling `_source` to save storage space if you have a large \n+destination index. Disabling `_source` is only possible during index creation.\n+\n+NOTE: When the `_source` field is disabled, a number of features are not \n+supported. Consult <<disable-source-field>> to understand the consequences \n+before disabling it.\n+\n+\n+[discrete]\n+[[tune-max-page-search-size]]\n+== 7. Tune `max_page_search_size` (search)\n+\n+The `max_page_search_size` parameter defines the number of buckets that are \n+returned for each search request. The default value is 500. If you increase this \n+value, you get better throughput at the cost of higher latency and memory usage.\n+\n+The ideal value of this parameter is highly dependent on your use case. If your \n+{transform} executes memory-intensive aggregations \u2013 for example, cardinality or \n+percentiles \u2013 then increasing `max_page_search_size` requires more available \n+memory. A circuit breaker exception will occur if memory limits are exceeded.\n+\n+\n+[discrete]\n+[[indexed-fields-in-source]]\n+== 8. Use indexed fields in your source indices (search)\n+\n+Runtime fields and scripted fields are not indexed fields, and their values are \n+only extracted or computed at search time. While these fields provide \n+flexibility in how you access your data, they increase performance costs at \n+search time. If {transform} performance using runtime fields or scripted fields \n+is a concern, you may wish to consider using indexed fields instead. For \n+performance reasons, we do not recommend using a runtime field as the time field \n+used for syncing a {ctransform}. \n+\n+\n+[discrete]\n+[[limit-source-query]]\n+== 9. Limit the scope of the source query (search)\n+\n+Imagine your {ctransform} is configured to group by `IP` and calculate the sum \n+of `bytes_sent`. For each checkpoint, a {ctransform} detects changes in the \n+source data since the previous checkpoint, identifying the IPs for which new \n+data has been ingested. Then it performs a second search, filtered for this \n+group of IPs, in order to calculate the total `bytes_sent`. If this second \n+search matches many shards, then this could be resource intensive. Consider \n+limiting the scope that the source index pattern and query will match.\n+\n+Use an absolute time value as a date range filter in your source query (for \n+example, greater than `2020-01-01T00:00:00`) to limit which historical indices \n+will be accessed. If you use a relative time value (for example, `now-30d`) then \n+this date range will be re-evaluated at the point of each checkpoint execution.", "originalCommit": "b73686ef844425b9f86773eb41d164c435641c44", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "2f95873d1344104070628b96978163dac77e3ea0", "url": "https://github.com/elastic/elasticsearch/commit/2f95873d1344104070628b96978163dac77e3ea0", "message": "[DOCS] Addresses feedback.", "committedDate": "2020-12-03T11:44:33Z", "type": "commit"}, {"oid": "d7d67fa9c66bbfbeae56800c30e033fad49150f7", "url": "https://github.com/elastic/elasticsearch/commit/d7d67fa9c66bbfbeae56800c30e033fad49150f7", "message": "[DOCS] Reorders list.", "committedDate": "2020-12-03T11:55:30Z", "type": "commit"}]}