{"pr_number": 65966, "pr_title": "[7.10] [DOCS] Adds Working with transforms at scale to docs (#65726)", "pr_createdAt": "2020-12-07T17:09:24Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/65966", "timeline": [{"oid": "b3c28d9b8138314f64f91383e969011a7d35cfab", "url": "https://github.com/elastic/elasticsearch/commit/b3c28d9b8138314f64f91383e969011a7d35cfab", "message": "[DOCS] Adds Working with transforms at scale to docs (#65726)", "committedDate": "2020-12-07T17:09:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY5NzE3Ng==", "url": "https://github.com/elastic/elasticsearch/pull/65966#discussion_r537697176", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Runtime fields and scripted fields are not indexed fields; their values are only \n          \n          \n            \n            Scripted fields are not indexed fields; their values are only", "author": "szabosteve", "createdAt": "2020-12-07T17:38:47Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,201 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard {es} features so similar \n+considerations for working with {es} at scale are often applicable to \n+{transforms}. If you experience performance issues, start by identifying the \n+bottleneck areas (search, indexing, processing, or storage) then review the \n+relevant considerations in this guide to improve performance. It also helps to \n+understand how {transforms} work as different considerations apply depending on \n+whether or not your transform is running in continuous mode or in batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you have a {transform} you want to tune, and you\u2019re \n+already familiar with: \n+\n+* <<transform-overview,How {transforms} work>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the bottleneck area that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices. If changes are detected, then \n+the source data is searched and the changes are applied to the destination \n+index. Depending on your use case, you may wish to reduce the frequency at which \n+changes are applied. By setting `frequency` to a higher value (maximum is one \n+hour), the workload can be spread over time at the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 2. Increase the number of shards of the destination index (index)\n+\n+Depending on the size of the destination index, you may consider increasing its \n+shard count. {transforms-cap} use one shard by default when creating the \n+destination index. To override the index settings, create the destination index \n+before starting the {transform}. For more information about how the number of \n+shards affects scalability and resilience, refer to <<scalability>>\n+\n+TIP: Use the <<preview-transform>> to check the settings that the {transform} \n+would use to create the destination index. You can copy and adjust these in \n+order to create the destination index prior to starting the {transform}.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 3. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[limit-source-query]]\n+== 4. Limit the scope of the source query (search)\n+\n+Imagine your {ctransform} is configured to group by `IP` and calculate the sum \n+of `bytes_sent`. For each checkpoint, a {ctransform} detects changes in the \n+source data since the previous checkpoint, identifying the IPs for which new \n+data has been ingested. Then it performs a second search, filtered for this \n+group of IPs, in order to calculate the total `bytes_sent`. If this second \n+search matches many shards, then this could be resource intensive. Consider \n+limiting the scope that the source index pattern and query will match.\n+\n+Use an absolute time value as a date range filter in your source query (for \n+example, greater than `2020-01-01T00:00:00`) to limit which historical indices \n+are accessed. If you use a relative time value (for example, `now-30d`) then \n+this date range is re-evaluated at the point of each checkpoint execution.\n+\n+\n+[discrete]\n+[[optimize-shading-strategy]]\n+== 5. Optimize the sharding strategy for the source index (search)\n+\n+There is no one-size-fits-all sharding strategy. A strategy that works in one \n+environment may not scale in another. A good sharding strategy must account for \n+your infrastructure, use case, and performance expectations.\n+\n+Too few shards may mean that the benefits of distributing the workload cannot be \n+realised; however too many shards may impact your cluster health. To learn more \n+about sizing your shards, read this <<size-your-shards,guide>>.\n+\n+\n+[discrete]\n+[[tune-max-page-search-size]]\n+== 6. Tune `max_page_search_size` (search)\n+\n+The `max_page_search_size` {transform} configuration option defines the number \n+of buckets that are returned for each search request. The default value is 500. \n+If you increase this value, you get better throughput at the cost of higher \n+latency and memory usage.\n+\n+The ideal value of this parameter is highly dependent on your use case. If your \n+{transform} executes memory-intensive aggregations \u2013 for example, cardinality or \n+percentiles \u2013 then increasing `max_page_search_size` requires more available \n+memory. If memory limits are exceeded, a circuit breaker exception occurs.\n+\n+\n+[discrete]\n+[[indexed-fields-in-source]]\n+== 7. Use indexed fields in your source indices (search)\n+\n+Runtime fields and scripted fields are not indexed fields; their values are only ", "originalCommit": "b3c28d9b8138314f64f91383e969011a7d35cfab", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY5NzUyNA==", "url": "https://github.com/elastic/elasticsearch/pull/65966#discussion_r537697524", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            extracted or computed at search time. While these fields provide flexibility in \n          \n          \n            \n             computed at search time. While these fields provide flexibility in", "author": "szabosteve", "createdAt": "2020-12-07T17:39:17Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,201 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard {es} features so similar \n+considerations for working with {es} at scale are often applicable to \n+{transforms}. If you experience performance issues, start by identifying the \n+bottleneck areas (search, indexing, processing, or storage) then review the \n+relevant considerations in this guide to improve performance. It also helps to \n+understand how {transforms} work as different considerations apply depending on \n+whether or not your transform is running in continuous mode or in batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you have a {transform} you want to tune, and you\u2019re \n+already familiar with: \n+\n+* <<transform-overview,How {transforms} work>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the bottleneck area that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices. If changes are detected, then \n+the source data is searched and the changes are applied to the destination \n+index. Depending on your use case, you may wish to reduce the frequency at which \n+changes are applied. By setting `frequency` to a higher value (maximum is one \n+hour), the workload can be spread over time at the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 2. Increase the number of shards of the destination index (index)\n+\n+Depending on the size of the destination index, you may consider increasing its \n+shard count. {transforms-cap} use one shard by default when creating the \n+destination index. To override the index settings, create the destination index \n+before starting the {transform}. For more information about how the number of \n+shards affects scalability and resilience, refer to <<scalability>>\n+\n+TIP: Use the <<preview-transform>> to check the settings that the {transform} \n+would use to create the destination index. You can copy and adjust these in \n+order to create the destination index prior to starting the {transform}.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 3. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[limit-source-query]]\n+== 4. Limit the scope of the source query (search)\n+\n+Imagine your {ctransform} is configured to group by `IP` and calculate the sum \n+of `bytes_sent`. For each checkpoint, a {ctransform} detects changes in the \n+source data since the previous checkpoint, identifying the IPs for which new \n+data has been ingested. Then it performs a second search, filtered for this \n+group of IPs, in order to calculate the total `bytes_sent`. If this second \n+search matches many shards, then this could be resource intensive. Consider \n+limiting the scope that the source index pattern and query will match.\n+\n+Use an absolute time value as a date range filter in your source query (for \n+example, greater than `2020-01-01T00:00:00`) to limit which historical indices \n+are accessed. If you use a relative time value (for example, `now-30d`) then \n+this date range is re-evaluated at the point of each checkpoint execution.\n+\n+\n+[discrete]\n+[[optimize-shading-strategy]]\n+== 5. Optimize the sharding strategy for the source index (search)\n+\n+There is no one-size-fits-all sharding strategy. A strategy that works in one \n+environment may not scale in another. A good sharding strategy must account for \n+your infrastructure, use case, and performance expectations.\n+\n+Too few shards may mean that the benefits of distributing the workload cannot be \n+realised; however too many shards may impact your cluster health. To learn more \n+about sizing your shards, read this <<size-your-shards,guide>>.\n+\n+\n+[discrete]\n+[[tune-max-page-search-size]]\n+== 6. Tune `max_page_search_size` (search)\n+\n+The `max_page_search_size` {transform} configuration option defines the number \n+of buckets that are returned for each search request. The default value is 500. \n+If you increase this value, you get better throughput at the cost of higher \n+latency and memory usage.\n+\n+The ideal value of this parameter is highly dependent on your use case. If your \n+{transform} executes memory-intensive aggregations \u2013 for example, cardinality or \n+percentiles \u2013 then increasing `max_page_search_size` requires more available \n+memory. If memory limits are exceeded, a circuit breaker exception occurs.\n+\n+\n+[discrete]\n+[[indexed-fields-in-source]]\n+== 7. Use indexed fields in your source indices (search)\n+\n+Runtime fields and scripted fields are not indexed fields; their values are only \n+extracted or computed at search time. While these fields provide flexibility in ", "originalCommit": "b3c28d9b8138314f64f91383e969011a7d35cfab", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY5NzgzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/65966#discussion_r537697831", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            {transform} performance using runtime fields or scripted fields is a concern, \n          \n          \n            \n            {transform} performance using scripted fields is a concern,", "author": "szabosteve", "createdAt": "2020-12-07T17:39:41Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,201 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard {es} features so similar \n+considerations for working with {es} at scale are often applicable to \n+{transforms}. If you experience performance issues, start by identifying the \n+bottleneck areas (search, indexing, processing, or storage) then review the \n+relevant considerations in this guide to improve performance. It also helps to \n+understand how {transforms} work as different considerations apply depending on \n+whether or not your transform is running in continuous mode or in batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you have a {transform} you want to tune, and you\u2019re \n+already familiar with: \n+\n+* <<transform-overview,How {transforms} work>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the bottleneck area that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices. If changes are detected, then \n+the source data is searched and the changes are applied to the destination \n+index. Depending on your use case, you may wish to reduce the frequency at which \n+changes are applied. By setting `frequency` to a higher value (maximum is one \n+hour), the workload can be spread over time at the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 2. Increase the number of shards of the destination index (index)\n+\n+Depending on the size of the destination index, you may consider increasing its \n+shard count. {transforms-cap} use one shard by default when creating the \n+destination index. To override the index settings, create the destination index \n+before starting the {transform}. For more information about how the number of \n+shards affects scalability and resilience, refer to <<scalability>>\n+\n+TIP: Use the <<preview-transform>> to check the settings that the {transform} \n+would use to create the destination index. You can copy and adjust these in \n+order to create the destination index prior to starting the {transform}.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 3. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[limit-source-query]]\n+== 4. Limit the scope of the source query (search)\n+\n+Imagine your {ctransform} is configured to group by `IP` and calculate the sum \n+of `bytes_sent`. For each checkpoint, a {ctransform} detects changes in the \n+source data since the previous checkpoint, identifying the IPs for which new \n+data has been ingested. Then it performs a second search, filtered for this \n+group of IPs, in order to calculate the total `bytes_sent`. If this second \n+search matches many shards, then this could be resource intensive. Consider \n+limiting the scope that the source index pattern and query will match.\n+\n+Use an absolute time value as a date range filter in your source query (for \n+example, greater than `2020-01-01T00:00:00`) to limit which historical indices \n+are accessed. If you use a relative time value (for example, `now-30d`) then \n+this date range is re-evaluated at the point of each checkpoint execution.\n+\n+\n+[discrete]\n+[[optimize-shading-strategy]]\n+== 5. Optimize the sharding strategy for the source index (search)\n+\n+There is no one-size-fits-all sharding strategy. A strategy that works in one \n+environment may not scale in another. A good sharding strategy must account for \n+your infrastructure, use case, and performance expectations.\n+\n+Too few shards may mean that the benefits of distributing the workload cannot be \n+realised; however too many shards may impact your cluster health. To learn more \n+about sizing your shards, read this <<size-your-shards,guide>>.\n+\n+\n+[discrete]\n+[[tune-max-page-search-size]]\n+== 6. Tune `max_page_search_size` (search)\n+\n+The `max_page_search_size` {transform} configuration option defines the number \n+of buckets that are returned for each search request. The default value is 500. \n+If you increase this value, you get better throughput at the cost of higher \n+latency and memory usage.\n+\n+The ideal value of this parameter is highly dependent on your use case. If your \n+{transform} executes memory-intensive aggregations \u2013 for example, cardinality or \n+percentiles \u2013 then increasing `max_page_search_size` requires more available \n+memory. If memory limits are exceeded, a circuit breaker exception occurs.\n+\n+\n+[discrete]\n+[[indexed-fields-in-source]]\n+== 7. Use indexed fields in your source indices (search)\n+\n+Runtime fields and scripted fields are not indexed fields; their values are only \n+extracted or computed at search time. While these fields provide flexibility in \n+how you access your data, they increase performance costs at search time. If \n+{transform} performance using runtime fields or scripted fields is a concern, ", "originalCommit": "b3c28d9b8138314f64f91383e969011a7d35cfab", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY5ODEwMg==", "url": "https://github.com/elastic/elasticsearch/pull/65966#discussion_r537698102", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            you may wish to consider using indexed fields instead. For performance reasons, \n          \n          \n            \n            you may wish to consider using indexed fields instead.", "author": "szabosteve", "createdAt": "2020-12-07T17:40:05Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,201 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard {es} features so similar \n+considerations for working with {es} at scale are often applicable to \n+{transforms}. If you experience performance issues, start by identifying the \n+bottleneck areas (search, indexing, processing, or storage) then review the \n+relevant considerations in this guide to improve performance. It also helps to \n+understand how {transforms} work as different considerations apply depending on \n+whether or not your transform is running in continuous mode or in batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you have a {transform} you want to tune, and you\u2019re \n+already familiar with: \n+\n+* <<transform-overview,How {transforms} work>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the bottleneck area that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices. If changes are detected, then \n+the source data is searched and the changes are applied to the destination \n+index. Depending on your use case, you may wish to reduce the frequency at which \n+changes are applied. By setting `frequency` to a higher value (maximum is one \n+hour), the workload can be spread over time at the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 2. Increase the number of shards of the destination index (index)\n+\n+Depending on the size of the destination index, you may consider increasing its \n+shard count. {transforms-cap} use one shard by default when creating the \n+destination index. To override the index settings, create the destination index \n+before starting the {transform}. For more information about how the number of \n+shards affects scalability and resilience, refer to <<scalability>>\n+\n+TIP: Use the <<preview-transform>> to check the settings that the {transform} \n+would use to create the destination index. You can copy and adjust these in \n+order to create the destination index prior to starting the {transform}.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 3. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[limit-source-query]]\n+== 4. Limit the scope of the source query (search)\n+\n+Imagine your {ctransform} is configured to group by `IP` and calculate the sum \n+of `bytes_sent`. For each checkpoint, a {ctransform} detects changes in the \n+source data since the previous checkpoint, identifying the IPs for which new \n+data has been ingested. Then it performs a second search, filtered for this \n+group of IPs, in order to calculate the total `bytes_sent`. If this second \n+search matches many shards, then this could be resource intensive. Consider \n+limiting the scope that the source index pattern and query will match.\n+\n+Use an absolute time value as a date range filter in your source query (for \n+example, greater than `2020-01-01T00:00:00`) to limit which historical indices \n+are accessed. If you use a relative time value (for example, `now-30d`) then \n+this date range is re-evaluated at the point of each checkpoint execution.\n+\n+\n+[discrete]\n+[[optimize-shading-strategy]]\n+== 5. Optimize the sharding strategy for the source index (search)\n+\n+There is no one-size-fits-all sharding strategy. A strategy that works in one \n+environment may not scale in another. A good sharding strategy must account for \n+your infrastructure, use case, and performance expectations.\n+\n+Too few shards may mean that the benefits of distributing the workload cannot be \n+realised; however too many shards may impact your cluster health. To learn more \n+about sizing your shards, read this <<size-your-shards,guide>>.\n+\n+\n+[discrete]\n+[[tune-max-page-search-size]]\n+== 6. Tune `max_page_search_size` (search)\n+\n+The `max_page_search_size` {transform} configuration option defines the number \n+of buckets that are returned for each search request. The default value is 500. \n+If you increase this value, you get better throughput at the cost of higher \n+latency and memory usage.\n+\n+The ideal value of this parameter is highly dependent on your use case. If your \n+{transform} executes memory-intensive aggregations \u2013 for example, cardinality or \n+percentiles \u2013 then increasing `max_page_search_size` requires more available \n+memory. If memory limits are exceeded, a circuit breaker exception occurs.\n+\n+\n+[discrete]\n+[[indexed-fields-in-source]]\n+== 7. Use indexed fields in your source indices (search)\n+\n+Runtime fields and scripted fields are not indexed fields; their values are only \n+extracted or computed at search time. While these fields provide flexibility in \n+how you access your data, they increase performance costs at search time. If \n+{transform} performance using runtime fields or scripted fields is a concern, \n+you may wish to consider using indexed fields instead. For performance reasons, ", "originalCommit": "b3c28d9b8138314f64f91383e969011a7d35cfab", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzY5ODM0NQ==", "url": "https://github.com/elastic/elasticsearch/pull/65966#discussion_r537698345", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            we do not recommend using a runtime field as the time field that synchs a \n          \n          \n            \n            {ctransform}.", "author": "szabosteve", "createdAt": "2020-12-07T17:40:29Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,201 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard {es} features so similar \n+considerations for working with {es} at scale are often applicable to \n+{transforms}. If you experience performance issues, start by identifying the \n+bottleneck areas (search, indexing, processing, or storage) then review the \n+relevant considerations in this guide to improve performance. It also helps to \n+understand how {transforms} work as different considerations apply depending on \n+whether or not your transform is running in continuous mode or in batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you have a {transform} you want to tune, and you\u2019re \n+already familiar with: \n+\n+* <<transform-overview,How {transforms} work>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the bottleneck area that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices. If changes are detected, then \n+the source data is searched and the changes are applied to the destination \n+index. Depending on your use case, you may wish to reduce the frequency at which \n+changes are applied. By setting `frequency` to a higher value (maximum is one \n+hour), the workload can be spread over time at the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 2. Increase the number of shards of the destination index (index)\n+\n+Depending on the size of the destination index, you may consider increasing its \n+shard count. {transforms-cap} use one shard by default when creating the \n+destination index. To override the index settings, create the destination index \n+before starting the {transform}. For more information about how the number of \n+shards affects scalability and resilience, refer to <<scalability>>\n+\n+TIP: Use the <<preview-transform>> to check the settings that the {transform} \n+would use to create the destination index. You can copy and adjust these in \n+order to create the destination index prior to starting the {transform}.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 3. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[limit-source-query]]\n+== 4. Limit the scope of the source query (search)\n+\n+Imagine your {ctransform} is configured to group by `IP` and calculate the sum \n+of `bytes_sent`. For each checkpoint, a {ctransform} detects changes in the \n+source data since the previous checkpoint, identifying the IPs for which new \n+data has been ingested. Then it performs a second search, filtered for this \n+group of IPs, in order to calculate the total `bytes_sent`. If this second \n+search matches many shards, then this could be resource intensive. Consider \n+limiting the scope that the source index pattern and query will match.\n+\n+Use an absolute time value as a date range filter in your source query (for \n+example, greater than `2020-01-01T00:00:00`) to limit which historical indices \n+are accessed. If you use a relative time value (for example, `now-30d`) then \n+this date range is re-evaluated at the point of each checkpoint execution.\n+\n+\n+[discrete]\n+[[optimize-shading-strategy]]\n+== 5. Optimize the sharding strategy for the source index (search)\n+\n+There is no one-size-fits-all sharding strategy. A strategy that works in one \n+environment may not scale in another. A good sharding strategy must account for \n+your infrastructure, use case, and performance expectations.\n+\n+Too few shards may mean that the benefits of distributing the workload cannot be \n+realised; however too many shards may impact your cluster health. To learn more \n+about sizing your shards, read this <<size-your-shards,guide>>.\n+\n+\n+[discrete]\n+[[tune-max-page-search-size]]\n+== 6. Tune `max_page_search_size` (search)\n+\n+The `max_page_search_size` {transform} configuration option defines the number \n+of buckets that are returned for each search request. The default value is 500. \n+If you increase this value, you get better throughput at the cost of higher \n+latency and memory usage.\n+\n+The ideal value of this parameter is highly dependent on your use case. If your \n+{transform} executes memory-intensive aggregations \u2013 for example, cardinality or \n+percentiles \u2013 then increasing `max_page_search_size` requires more available \n+memory. If memory limits are exceeded, a circuit breaker exception occurs.\n+\n+\n+[discrete]\n+[[indexed-fields-in-source]]\n+== 7. Use indexed fields in your source indices (search)\n+\n+Runtime fields and scripted fields are not indexed fields; their values are only \n+extracted or computed at search time. While these fields provide flexibility in \n+how you access your data, they increase performance costs at search time. If \n+{transform} performance using runtime fields or scripted fields is a concern, \n+you may wish to consider using indexed fields instead. For performance reasons, \n+we do not recommend using a runtime field as the time field that synchs a \n+{ctransform}. ", "originalCommit": "b3c28d9b8138314f64f91383e969011a7d35cfab", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "be8dc5a99d01e13beb7d17719159077d25f16842", "url": "https://github.com/elastic/elasticsearch/commit/be8dc5a99d01e13beb7d17719159077d25f16842", "message": "Apply suggestions from code review", "committedDate": "2020-12-07T17:40:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzcwODUwNA==", "url": "https://github.com/elastic/elasticsearch/pull/65966#discussion_r537708504", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             computed at search time. While these fields provide flexibility in \n          \n          \n            \n            computed at search time. While these fields provide flexibility in", "author": "szabosteve", "createdAt": "2020-12-07T17:54:45Z", "path": "docs/reference/transform/transforms-at-scale.asciidoc", "diffHunk": "@@ -0,0 +1,199 @@\n+[role=\"xpack\"]\n+[[transform-scale]]\n+= Working with {transforms} at scale\n+++++\n+<titleabbrev>{transforms-cap} at scale</titleabbrev>\n+++++\n+\n+{transforms-cap} convert existing {es} indices into summarized indices, which \n+provide opportunities for new insights and analytics. The search and index \n+operations performed by {transforms} use standard {es} features so similar \n+considerations for working with {es} at scale are often applicable to \n+{transforms}. If you experience performance issues, start by identifying the \n+bottleneck areas (search, indexing, processing, or storage) then review the \n+relevant considerations in this guide to improve performance. It also helps to \n+understand how {transforms} work as different considerations apply depending on \n+whether or not your transform is running in continuous mode or in batch.\n+\n+In this guide, you\u2019ll learn how to:\n+\n+* Understand the impact of configuration options on the performance of \n+  {transforms}.\n+\n+**Prerequisites:**\n+\n+These guildelines assume you have a {transform} you want to tune, and you\u2019re \n+already familiar with: \n+\n+* <<transform-overview,How {transforms} work>>.\n+* <<transform-setup,How to set up {transforms}>>.\n+* <<transform-checkpoints,How {transform} checkpoints work in continuous mode>>.\n+\n+The following considerations are not sequential \u2013 the numbers help to navigate \n+between the list items; you can take action on one or more of them in any order. \n+Most of the recommendations apply to both continuous and batch {transforms}. If \n+a list item only applies to one {transform} type, this exception is highlighted \n+in the description.\n+\n+The keywords in parenthesis at the end of each recommendation title indicates \n+the bottleneck area that may be improved by following the given recommendation.\n+\n+[discrete]\n+[[measure-performance]]\n+== Measure {transforms} performance\n+\n+In order to optimize {transform} performance, start by identifying the areas \n+where most work is being done. The **Stats** interface of the \n+**{transforms-cap}** page in {kib} contains information that covers three main \n+areas: indexing, searching, and processing time (alternatively, you can use the \n+<<get-transform-stats, {transforms} stats API>>). If, for example, the results \n+show that the highest proportion of  time is spent on search, then prioritize \n+efforts on optimizing the search query of the {transform}. {transforms-cap} also \n+has https://esrally.readthedocs.io[Rally support] that makes it possible to run \n+performance checks on {transforms} configurations if it is required. If you \n+optimized the crucial factors and you still experience performance issues, you \n+may also want to consider improving your hardware.\n+\n+\n+[discrete]\n+[[frequency]]\n+== 1. Optimize `frequency` (index)\n+\n+In a {ctransform}, the `frequency` configuration option sets the interval \n+between checks for changes in the source indices. If changes are detected, then \n+the source data is searched and the changes are applied to the destination \n+index. Depending on your use case, you may wish to reduce the frequency at which \n+changes are applied. By setting `frequency` to a higher value (maximum is one \n+hour), the workload can be spread over time at the cost of less up-to-date data.\n+\n+\n+[discrete]\n+[[increase-shards-dest-index]]\n+== 2. Increase the number of shards of the destination index (index)\n+\n+Depending on the size of the destination index, you may consider increasing its \n+shard count. {transforms-cap} use one shard by default when creating the \n+destination index. To override the index settings, create the destination index \n+before starting the {transform}. For more information about how the number of \n+shards affects scalability and resilience, refer to <<scalability>>\n+\n+TIP: Use the <<preview-transform>> to check the settings that the {transform} \n+would use to create the destination index. You can copy and adjust these in \n+order to create the destination index prior to starting the {transform}.\n+\n+\n+[discrete]\n+[[search-queries]]\n+== 3. Profile and optimize your search queries (search)\n+\n+If you have defined a {transform} source index `query`, ensure it is as \n+efficient as possible. Use the **Search Profiler** under **Dev Tools** in {kib} \n+to get detailed timing information about the execution of individual components \n+in the search request. Alternatively, you can use the <<search-profile>>. The \n+results give you insight into how search requests are executed at a low level so \n+that you can understand why certain requests are slow, and take steps to improve \n+them.\n+\n+{transforms-cap} execute standard {es} search requests. There are different ways \n+to write {es} queries, and some of them are more efficient than others. Consult \n+<<tune-for-search-speed>> to learn more about {es} performance tuning.\n+\n+\n+[discrete]\n+[[limit-source-query]]\n+== 4. Limit the scope of the source query (search)\n+\n+Imagine your {ctransform} is configured to group by `IP` and calculate the sum \n+of `bytes_sent`. For each checkpoint, a {ctransform} detects changes in the \n+source data since the previous checkpoint, identifying the IPs for which new \n+data has been ingested. Then it performs a second search, filtered for this \n+group of IPs, in order to calculate the total `bytes_sent`. If this second \n+search matches many shards, then this could be resource intensive. Consider \n+limiting the scope that the source index pattern and query will match.\n+\n+Use an absolute time value as a date range filter in your source query (for \n+example, greater than `2020-01-01T00:00:00`) to limit which historical indices \n+are accessed. If you use a relative time value (for example, `now-30d`) then \n+this date range is re-evaluated at the point of each checkpoint execution.\n+\n+\n+[discrete]\n+[[optimize-shading-strategy]]\n+== 5. Optimize the sharding strategy for the source index (search)\n+\n+There is no one-size-fits-all sharding strategy. A strategy that works in one \n+environment may not scale in another. A good sharding strategy must account for \n+your infrastructure, use case, and performance expectations.\n+\n+Too few shards may mean that the benefits of distributing the workload cannot be \n+realised; however too many shards may impact your cluster health. To learn more \n+about sizing your shards, read this <<size-your-shards,guide>>.\n+\n+\n+[discrete]\n+[[tune-max-page-search-size]]\n+== 6. Tune `max_page_search_size` (search)\n+\n+The `max_page_search_size` {transform} configuration option defines the number \n+of buckets that are returned for each search request. The default value is 500. \n+If you increase this value, you get better throughput at the cost of higher \n+latency and memory usage.\n+\n+The ideal value of this parameter is highly dependent on your use case. If your \n+{transform} executes memory-intensive aggregations \u2013 for example, cardinality or \n+percentiles \u2013 then increasing `max_page_search_size` requires more available \n+memory. If memory limits are exceeded, a circuit breaker exception occurs.\n+\n+\n+[discrete]\n+[[indexed-fields-in-source]]\n+== 7. Use indexed fields in your source indices (search)\n+\n+Scripted fields are not indexed fields; their values are only \n+ computed at search time. While these fields provide flexibility in ", "originalCommit": "be8dc5a99d01e13beb7d17719159077d25f16842", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "4b903245c79993301b6010647366a05fb03d1fa6", "url": "https://github.com/elastic/elasticsearch/commit/4b903245c79993301b6010647366a05fb03d1fa6", "message": "Apply suggestions from code review", "committedDate": "2020-12-07T17:54:51Z", "type": "commit"}]}