{"pr_number": 63120, "pr_title": "Wildcard field - add normalisation of ngram tokens to reduce disk space.", "pr_createdAt": "2020-10-01T11:26:57Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/63120", "timeline": [{"oid": "ceb82a10c64b94414dee8fa8a196886f61796a28", "url": "https://github.com/elastic/elasticsearch/commit/ceb82a10c64b94414dee8fa8a196886f61796a28", "message": "Add normalisation of ngram tokens to reduce disk space.\nAll punctuation becomes / char and for A-Z0-9 chars turn even codepoints to prior odd e.g. aab becomes aaa\n\nCloses #62817", "committedDate": "2020-10-01T11:55:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxMjI3MA==", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498212270", "bodyText": "Can we generalize the block checks above with Character.isLetterOrDigit() == false ?", "author": "jimczi", "createdAt": "2020-10-01T12:40:39Z", "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -91,13 +93,98 @@\n     public static final String CONTENT_TYPE = \"wildcard\";\n     public static short MAX_CLAUSES_IN_APPROXIMATION_QUERY = 10;\n     public static final int NGRAM_SIZE = 3;\n-    static final NamedAnalyzer WILDCARD_ANALYZER = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_10 = new NamedAnalyzer(\"_wildcard_7_10\", AnalyzerScope.GLOBAL, new Analyzer() {\n         @Override\n         public TokenStreamComponents createComponents(String fieldName) {\n             Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n-            return new TokenStreamComponents(tokenizer);\n+            TokenStream tok = new NormaliseThinningFilter(tokenizer);\n+            \n+            return new TokenStreamComponents(r -> {\n+                tokenizer.setReader(r);\n+            }, tok);            \n+            \n+            \n         }\n     });\n+    \n+    // @deprecated - used for BWC with elasticsearch 7.9\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_9 = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+        @Override\n+        public TokenStreamComponents createComponents(String fieldName) {\n+            Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n+                return new TokenStreamComponents(tokenizer);\n+        }\n+    });\n+    \n+    public static class NormaliseThinningFilter extends TokenFilter {\n+        private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);\n+        \n+        /**\n+         * Create a new NormaliseThinningFilter, that normalizes token text such that even-numbered ascii values\n+         * are made odd and punctuation is replaced with /\n+         * \n+         * @param in TokenStream to filter\n+         */\n+        public NormaliseThinningFilter(TokenStream in) {\n+          super(in);\n+        }\n+        \n+        @Override\n+        public final boolean incrementToken() throws IOException {\n+          if (input.incrementToken()) {\n+              normalize(termAtt.buffer(), 0, termAtt.length());\n+            return true;\n+          } else\n+            return false;\n+        }\n+        \n+        public static String normalize(String s) {\n+            char[] chars = s.toCharArray();\n+            normalize(chars, 0, chars.length);\n+            return new String(chars);            \n+        }\n+        \n+        /**\n+         * Normalizes a token\n+         */\n+        public static void normalize(final char[] buffer, final int offset, final int limit) {\n+          assert buffer.length >= limit;\n+          assert 0 <= offset && offset <= buffer.length;\n+          for (int i = offset; i < limit;) {\n+            int codepoint = Character.codePointAt(buffer, i, limit);\n+            i += Character.toChars(\n+                    normalize(codepoint), buffer, i);\n+           }\n+        }\n+\n+        private static int normalize(int codepoint) {\n+            // Normalize  space ! \" # $ % &  ' ( } * + , - . chars to / \n+            if (codepoint >=32 && codepoint <= 47) {\n+                return 47; \n+            }\n+            // Normalize : ; < = > ? @ chars to / \n+            if (codepoint >=58 && codepoint <= 64) {\n+                return 47; \n+            }\n+            // Normalize  [ \\ ] ^ _ ` chars to / \n+            if (codepoint >=91 && codepoint <= 96) {\n+                return 47; \n+            }\n+            // Normalize  { | } ~ chars to / \n+            if (codepoint >=123 && codepoint <= 126) {\n+                return 47; \n+            }", "originalCommit": "ceb82a10c64b94414dee8fa8a196886f61796a28", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNDY1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498214653", "bodyText": "We could add the lowercase filter here instead of lowercasing outside of the analyzer ? I also wonder if putting a ASCIIFoldingFilter makes sense but that's maybe a different scope.", "author": "jimczi", "createdAt": "2020-10-01T12:44:34Z", "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -91,13 +93,98 @@\n     public static final String CONTENT_TYPE = \"wildcard\";\n     public static short MAX_CLAUSES_IN_APPROXIMATION_QUERY = 10;\n     public static final int NGRAM_SIZE = 3;\n-    static final NamedAnalyzer WILDCARD_ANALYZER = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_10 = new NamedAnalyzer(\"_wildcard_7_10\", AnalyzerScope.GLOBAL, new Analyzer() {\n         @Override\n         public TokenStreamComponents createComponents(String fieldName) {\n             Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n-            return new TokenStreamComponents(tokenizer);", "originalCommit": "ceb82a10c64b94414dee8fa8a196886f61796a28", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNjk2MQ==", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498216961", "bodyText": "This should depend on the index created version ?", "author": "jimczi", "createdAt": "2020-10-01T12:48:10Z", "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -215,13 +302,15 @@ public WildcardFieldMapper build(BuilderContext context) {\n         private WildcardFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n             super(name, true, fieldType.stored(), true,\n                 new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n-            setIndexAnalyzer(WILDCARD_ANALYZER);\n+            setIndexAnalyzer(WILDCARD_ANALYZER_7_10);", "originalCommit": "ceb82a10c64b94414dee8fa8a196886f61796a28", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNzcxMQ==", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498217711", "bodyText": "You don't need to resolve this at query-time. The correct analyzer can be picked once from the index created version when the field type is created.", "author": "jimczi", "createdAt": "2020-10-01T12:49:26Z", "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -215,13 +302,15 @@ public WildcardFieldMapper build(BuilderContext context) {\n         private WildcardFieldType(String name, FieldType fieldType, Map<String, String> meta) {\n             super(name, true, fieldType.stored(), true,\n                 new TextSearchInfo(fieldType, null, Lucene.KEYWORD_ANALYZER, Lucene.KEYWORD_ANALYZER), meta);\n-            setIndexAnalyzer(WILDCARD_ANALYZER);\n+            setIndexAnalyzer(WILDCARD_ANALYZER_7_10);\n         }\n \n         @Override\n         public Query wildcardQuery(String wildcardPattern, RewriteMethod method, boolean caseInsensitive, QueryShardContext context) {\n \n             String ngramIndexPattern = addLineEndChars(toLowerCase(wildcardPattern));\n+            \n+            Analyzer analyzer = getCorrectAnalyzerForIndexVersion(context);", "originalCommit": "ceb82a10c64b94414dee8fa8a196886f61796a28", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNzg4Mw==", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498217883", "bodyText": "same here", "author": "jimczi", "createdAt": "2020-10-01T12:49:41Z", "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -673,6 +765,7 @@ public Query rangeQuery(\n         ) {\n             BytesRef lower = lowerTerm == null ? null : BytesRefs.toBytesRef(lowerTerm);\n             BytesRef upper = upperTerm == null ? null : BytesRefs.toBytesRef(upperTerm);\n+            Analyzer analyzer = getCorrectAnalyzerForIndexVersion(context);", "originalCommit": "ceb82a10c64b94414dee8fa8a196886f61796a28", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODIxNzk2MA==", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498217960", "bodyText": "and here", "author": "jimczi", "createdAt": "2020-10-01T12:49:47Z", "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -751,6 +836,8 @@ public Query fuzzyQuery(\n         ) {\n             String searchTerm = BytesRefs.toString(value);\n             String lowerSearchTerm = toLowerCase(searchTerm);\n+            Analyzer analyzer = getCorrectAnalyzerForIndexVersion(context);", "originalCommit": "ceb82a10c64b94414dee8fa8a196886f61796a28", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODc0OTg3Nw==", "url": "https://github.com/elastic/elasticsearch/pull/63120#discussion_r498749877", "bodyText": "nit: can we rename into PunctuationFoldingFilter or something similar ?", "author": "jimczi", "createdAt": "2020-10-02T10:48:05Z", "path": "x-pack/plugin/wildcard/src/main/java/org/elasticsearch/xpack/wildcard/mapper/WildcardFieldMapper.java", "diffHunk": "@@ -91,13 +94,95 @@\n     public static final String CONTENT_TYPE = \"wildcard\";\n     public static short MAX_CLAUSES_IN_APPROXIMATION_QUERY = 10;\n     public static final int NGRAM_SIZE = 3;\n-    static final NamedAnalyzer WILDCARD_ANALYZER = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_10 = new NamedAnalyzer(\"_wildcard_7_10\", AnalyzerScope.GLOBAL, new Analyzer() {\n         @Override\n         public TokenStreamComponents createComponents(String fieldName) {\n             Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n-            return new TokenStreamComponents(tokenizer);\n+            \n+            TokenStream tok = new LowerCaseFilter(tokenizer);\n+            tok = new NormaliseThinningFilter(tok);\n+            \n+            return new TokenStreamComponents(r -> {\n+                tokenizer.setReader(r);\n+            }, tok);            \n+            \n+            \n         }\n     });\n+    \n+    // @deprecated - used for BWC with elasticsearch 7.9\n+    static final NamedAnalyzer WILDCARD_ANALYZER_7_9 = new NamedAnalyzer(\"_wildcard\", AnalyzerScope.GLOBAL, new Analyzer() {\n+        @Override\n+        public TokenStreamComponents createComponents(String fieldName) {\n+            Tokenizer tokenizer = new NGramTokenizer(NGRAM_SIZE, NGRAM_SIZE);\n+            TokenStream tok = new LowerCaseFilter(tokenizer);\n+//                return new TokenStreamComponents(tokenizer);\n+            return new TokenStreamComponents(r -> {\n+                tokenizer.setReader(r);\n+            }, tok);            \n+        }\n+    });\n+    \n+    public static class NormaliseThinningFilter extends TokenFilter {", "originalCommit": "c2e4e84800ac207379be6e1254a95e4c03833b17", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "url": "https://github.com/elastic/elasticsearch/commit/2253c70a38946b6a0efd8c88476c6b4e01f1f53b", "message": "Class rename", "committedDate": "2020-10-02T11:04:35Z", "type": "forcePushed"}, {"oid": "bb905c67fa41ba6718d9c593848c166762b8cb6a", "url": "https://github.com/elastic/elasticsearch/commit/bb905c67fa41ba6718d9c593848c166762b8cb6a", "message": "Add normalisation of ngram tokens to reduce disk space.\nAll punctuation becomes / char and for A-Z0-9 chars turn even codepoints to prior odd e.g. aab becomes aaa\n\nCloses #62817", "committedDate": "2020-10-02T13:46:53Z", "type": "commit"}, {"oid": "de6c3f6613df9806aaa7d2598bb439b27d138853", "url": "https://github.com/elastic/elasticsearch/commit/de6c3f6613df9806aaa7d2598bb439b27d138853", "message": "Addressing review comments. Made lowercaseFilter part of Analyzer and set IndexAnalyzer appropriately on FieldType construction", "committedDate": "2020-10-02T13:46:53Z", "type": "commit"}, {"oid": "4261a2aad4baffc8907bf78fc499d515233927a1", "url": "https://github.com/elastic/elasticsearch/commit/4261a2aad4baffc8907bf78fc499d515233927a1", "message": "Line length", "committedDate": "2020-10-02T13:46:53Z", "type": "commit"}, {"oid": "d6cf5dc9451d7084a6abc7ae768a502c5e6746fe", "url": "https://github.com/elastic/elasticsearch/commit/d6cf5dc9451d7084a6abc7ae768a502c5e6746fe", "message": "Remove debug", "committedDate": "2020-10-02T13:46:53Z", "type": "commit"}, {"oid": "dcbe91ffd5917d12e87216d57f9008ff60536d0d", "url": "https://github.com/elastic/elasticsearch/commit/dcbe91ffd5917d12e87216d57f9008ff60536d0d", "message": "Class rename", "committedDate": "2020-10-02T13:46:53Z", "type": "commit"}, {"oid": "3944cf6f84456624a7f87c77bbb32e110d6073db", "url": "https://github.com/elastic/elasticsearch/commit/3944cf6f84456624a7f87c77bbb32e110d6073db", "message": "Removed commented out code", "committedDate": "2020-10-02T13:46:53Z", "type": "commit"}, {"oid": "3944cf6f84456624a7f87c77bbb32e110d6073db", "url": "https://github.com/elastic/elasticsearch/commit/3944cf6f84456624a7f87c77bbb32e110d6073db", "message": "Removed commented out code", "committedDate": "2020-10-02T13:46:53Z", "type": "forcePushed"}]}