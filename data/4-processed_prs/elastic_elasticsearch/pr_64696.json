{"pr_number": 64696, "pr_title": "Allow searchable snapshot cache service to periodically fsync cache files", "pr_createdAt": "2020-11-06T12:38:02Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/64696", "timeline": [{"oid": "012eee2aa6ed7221ca25ff91c637dbc381b508e3", "url": "https://github.com/elastic/elasticsearch/commit/012eee2aa6ed7221ca25ff91c637dbc381b508e3", "message": "Periodically fsync searchable snapshots cache files", "committedDate": "2020-11-06T12:11:28Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODcyNTYxNA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r518725614", "bodyText": "\ud83e\udd26", "author": "tlrx", "createdAt": "2020-11-06T12:39:30Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/CacheFileTests.java", "diffHunk": "@@ -335,7 +335,7 @@ public void onEviction(CacheFile evictedCacheFile) {\n     public static void assertNumberOfFSyncs(final Path path, final Matcher<Long> matcher) {\n         final FSyncTrackingFileSystemProvider provider = (FSyncTrackingFileSystemProvider) path.getFileSystem().provider();\n         final AtomicLong fsyncCounter = provider.files.get(path);\n-        assertThat(\"File [\" + path + \"] was never fsynced\", notNullValue());\n+        assertThat(\"File [\" + path + \"] was never fsynced\", fsyncCounter, notNullValue());", "originalCommit": "012eee2aa6ed7221ca25ff91c637dbc381b508e3", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "499f12bf15c81235ac24f7b6915cc0264258b680", "url": "https://github.com/elastic/elasticsearch/commit/499f12bf15c81235ac24f7b6915cc0264258b680", "message": "Merge branch 'master' into periodic-fsync", "committedDate": "2020-11-09T16:58:57Z", "type": "commit"}, {"oid": "31299c1a14f827892eb97b38228f68f77baea1ce", "url": "https://github.com/elastic/elasticsearch/commit/31299c1a14f827892eb97b38228f68f77baea1ce", "message": "Fix spotless", "committedDate": "2020-11-09T17:02:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMxNjY2NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520316665", "bodyText": "I wonder if it was better to not instantiate the CacheService at all on non-data nodes? Having it support non-data nodes without the cacheSyncTask seems counter intuitive (unless there is a good reason).\nThat would allow removing the asserts/ifs on cacheSyncTask != null.", "author": "henningandersen", "createdAt": "2020-11-10T06:20:43Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -52,31 +82,63 @@\n         Setting.Property.NodeScope\n     );\n \n+    public static final TimeValue MIN_SNAPSHOT_CACHE_SYNC_INTERVAL = TimeValue.timeValueSeconds(10L);\n+    public static final Setting<TimeValue> SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING = Setting.timeSetting(\n+        SETTINGS_PREFIX + \"sync_interval\",\n+        TimeValue.timeValueSeconds(60L),                        // default\n+        MIN_SNAPSHOT_CACHE_SYNC_INTERVAL,                       // min\n+        Setting.Property.NodeScope,\n+        Setting.Property.Dynamic\n+    );\n+\n+    private static final Logger logger = LogManager.getLogger(CacheService.class);\n+\n+    private final ClusterService clusterService;\n+    private final NodeEnvironment nodeEnvironment;\n+    private final ThreadPool threadPool;\n+    private final CacheSynchronizationTask cacheSyncTask;\n     private final Cache<CacheKey, CacheFile> cache;\n     private final ByteSizeValue cacheSize;\n     private final Runnable cacheCleaner;\n     private final ByteSizeValue rangeSize;\n \n-    public CacheService(final Runnable cacheCleaner, final Settings settings) {\n-        this(cacheCleaner, SNAPSHOT_CACHE_SIZE_SETTING.get(settings), SNAPSHOT_CACHE_RANGE_SIZE_SETTING.get(settings));\n-    }\n-\n-    // exposed for tests\n-    public CacheService(final Runnable cacheCleaner, final ByteSizeValue cacheSize, final ByteSizeValue rangeSize) {\n-        this.cacheSize = Objects.requireNonNull(cacheSize);\n+    public CacheService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final ThreadPool threadPool,\n+        final NodeEnvironment nodeEnvironment,\n+        final Runnable cacheCleaner\n+    ) {\n+        this.clusterService = Objects.requireNonNull(clusterService);\n+        this.nodeEnvironment = Objects.requireNonNull(nodeEnvironment);\n+        this.threadPool = Objects.requireNonNull(threadPool);\n+        this.cacheSize = SNAPSHOT_CACHE_SIZE_SETTING.get(settings);\n         this.cacheCleaner = Objects.requireNonNull(cacheCleaner);\n-        this.rangeSize = Objects.requireNonNull(rangeSize);\n+        this.rangeSize = SNAPSHOT_CACHE_RANGE_SIZE_SETTING.get(settings);\n         this.cache = CacheBuilder.<CacheKey, CacheFile>builder()\n             .setMaximumWeight(cacheSize.getBytes())\n             .weigher((key, entry) -> entry.getLength())\n             // NORELEASE This does not immediately free space on disk, as cache file are only deleted when all index inputs\n             // are done with reading/writing the cache file\n             .removalListener(notification -> IOUtils.closeWhileHandlingException(() -> notification.getValue().startEviction()))\n             .build();\n+\n+        if (DiscoveryNode.isDataNode(settings)) {", "originalCommit": "31299c1a14f827892eb97b38228f68f77baea1ce", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQzOTkxNw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520439917", "bodyText": "++ I think not instantiating it would be nice.\nMild worry on this :) <- it might be a little cumbersome to get it right due to transport actions? (haven't checked this here in detail but I remember trying to do a similar thing elsewhere and it turned out to be tricky)", "author": "original-brownbear", "createdAt": "2020-11-10T10:07:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMxNjY2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMzMTM0MA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520331340", "bodyText": "I think the reason we need this is because cacheSyncTask.cancel does not promise to not reschedule until rescheduleIfNecessary is called again?\nI wonder if that is a bug we should fix in AbstractAsyncTask? Can certainly be done in a follow-up (or separate PR).", "author": "henningandersen", "createdAt": "2020-11-10T06:55:48Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +206,176 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    // used in tests\n+    CacheSynchronizationTask getCacheSyncTask() {\n+        return cacheSyncTask;\n+    }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        assert cacheSyncTask != null;\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    /**\n+     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     */\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        assert cacheSyncTask != null;\n+\n+        if (event.routingTableChanged()) {\n+            final ClusterState clusterState = event.state();\n+            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n+            assert localNode.isDataNode();\n+\n+            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());\n+            cacheSyncTask.allowReschedule.set(shouldSynchronize);", "originalCommit": "31299c1a14f827892eb97b38228f68f77baea1ce", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMzMjE0Ng==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520332146", "bodyText": "I think this could mean that we will not start fsync'ing during initialization/recovery of the first shard(s) on a starting node?", "author": "henningandersen", "createdAt": "2020-11-10T06:58:06Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +206,176 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    // used in tests\n+    CacheSynchronizationTask getCacheSyncTask() {\n+        return cacheSyncTask;\n+    }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        assert cacheSyncTask != null;\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    /**\n+     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     */\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        assert cacheSyncTask != null;\n+\n+        if (event.routingTableChanged()) {\n+            final ClusterState clusterState = event.state();\n+            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n+            assert localNode.isDataNode();\n+\n+            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());\n+            cacheSyncTask.allowReschedule.set(shouldSynchronize);\n+\n+            if (shouldSynchronize == false) {\n+                logger.trace(\"canceling cache synchronization task (no searchable snapshots shard(s) assigned to local node)\");\n+                cacheSyncTask.cancel();\n+\n+            } else if (cacheSyncTask.isScheduled() == false) {\n+                logger.trace(\"scheduling cache synchronization task (searchable snapshots shard(s) assigned to local node)\");\n+                cacheSyncTask.rescheduleIfNecessary();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Synchronize the cache files and dirs.\n+     *\n+     * This method iterates over all the searchable snapshot shards assigned to the local node in order to execute {@link CacheFile#fsync()}\n+     * on cache entries belonging to shards. When at least one {@link CacheFile#fsync()} call returns a non empty set of completed ranges\n+     * this method also fsync the shard's snapshot cache directory, which is the parent directory of the cache entries. Note that this\n+     * method is best effort as cache entries might be evicted during iterations and cache files/dirs removed from disk.\n+     */\n+    protected synchronized void synchronizeCache() {\n+        if (lifecycleState() != Lifecycle.State.STARTED) {\n+            return;\n+        }\n+        final ClusterState clusterState = clusterService.state();\n+        final RoutingNode routingNode = clusterState.getRoutingNodes().node(clusterState.getNodes().getLocalNodeId());\n+        assert routingNode != null;\n+\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        for (ShardRouting shardRouting : routingNode) {\n+            if (shardRouting.active()) {\n+                final IndexMetadata indexMetadata = clusterState.metadata().getIndexSafe(shardRouting.index());\n+                final Settings indexSettings = indexMetadata.getSettings();\n+                if (isSearchableSnapshotStore(indexSettings)) {\n+                    final ShardId shardId = shardRouting.shardId();\n+                    final SnapshotId snapshotId = new SnapshotId(\n+                        SNAPSHOT_SNAPSHOT_NAME_SETTING.get(indexSettings),\n+                        SNAPSHOT_SNAPSHOT_ID_SETTING.get(indexSettings)\n+                    );\n+                    final IndexId indexId = new IndexId(\n+                        SNAPSHOT_INDEX_NAME_SETTING.get(indexSettings),\n+                        SNAPSHOT_INDEX_ID_SETTING.get(indexSettings)\n+                    );\n+\n+                    boolean syncDirectory = false;\n+                    for (Tuple<CacheKey, CacheFile> entry : cache.entries()) {\n+                        final CacheKey cacheKey = entry.v1();\n+                        if (cacheKey.belongsTo(snapshotId, indexId, shardId)) {\n+                            final CacheFile cacheFile = entry.v2();\n+                            try {\n+                                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                                if (ranges.isEmpty() == false) {\n+                                    logger.trace(\n+                                        \"{} cache file [{}] synchronized with [{}] completed range(s)\",\n+                                        shardId,\n+                                        cacheFile.getFile().getFileName(),\n+                                        ranges.size()\n+                                    );\n+                                    syncDirectory = true;\n+                                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n+                                }\n+                            } catch (Exception e) {\n+                                logger.warn(\n+                                    () -> new ParameterizedMessage(\n+                                        \"{} failed to fsync cache file [{}]\",\n+                                        shardId,\n+                                        cacheFile.getFile().getFileName()\n+                                    ),\n+                                    e\n+                                );\n+                            }\n+                        }\n+                    }\n+\n+                    if (syncDirectory) {\n+                        assert IndexMetadata.INDEX_DATA_PATH_SETTING.exists(indexSettings) == false;\n+                        for (Path shardPath : nodeEnvironment.availableShardPaths(shardId)) {\n+                            final Path snapshotCacheDir = resolveSnapshotCache(shardPath).resolve(snapshotId.getUUID());\n+                            if (Files.exists(snapshotCacheDir)) {\n+                                try {\n+                                    IOUtils.fsync(snapshotCacheDir, true, false);\n+                                    logger.trace(\"{} cache directory [{}] synchronized\", shardId, snapshotCacheDir);\n+                                } catch (Exception e) {\n+                                    logger.warn(\n+                                        () -> new ParameterizedMessage(\n+                                            \"{} failed to synchronize cache directory [{}]\",\n+                                            shardId,\n+                                            snapshotCacheDir\n+                                        ),\n+                                        e\n+                                    );\n+                                }\n+                            }\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        if (logger.isDebugEnabled()) {\n+            final long elapsedNanos = threadPool.relativeTimeInNanos() - startTimeNanos;\n+            logger.debug(\"cache files synchronized in [{}]\", TimeValue.timeValueNanos(elapsedNanos));\n+        }\n+    }\n+\n+    static boolean hasSearchableSnapshotShards(final ClusterState clusterState, final String nodeId) {\n+        final RoutingNode routingNode = clusterState.getRoutingNodes().node(nodeId);\n+        if (routingNode != null) {\n+            for (ShardRouting shardRouting : routingNode) {\n+                if (shardRouting.active()) {", "originalCommit": "31299c1a14f827892eb97b38228f68f77baea1ce", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMzMjY1MA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520332650", "bodyText": "I think we also want to fsync initializing shards?", "author": "henningandersen", "createdAt": "2020-11-10T06:59:27Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +206,176 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    // used in tests\n+    CacheSynchronizationTask getCacheSyncTask() {\n+        return cacheSyncTask;\n+    }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        assert cacheSyncTask != null;\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    /**\n+     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     */\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        assert cacheSyncTask != null;\n+\n+        if (event.routingTableChanged()) {\n+            final ClusterState clusterState = event.state();\n+            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n+            assert localNode.isDataNode();\n+\n+            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());\n+            cacheSyncTask.allowReschedule.set(shouldSynchronize);\n+\n+            if (shouldSynchronize == false) {\n+                logger.trace(\"canceling cache synchronization task (no searchable snapshots shard(s) assigned to local node)\");\n+                cacheSyncTask.cancel();\n+\n+            } else if (cacheSyncTask.isScheduled() == false) {\n+                logger.trace(\"scheduling cache synchronization task (searchable snapshots shard(s) assigned to local node)\");\n+                cacheSyncTask.rescheduleIfNecessary();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Synchronize the cache files and dirs.\n+     *\n+     * This method iterates over all the searchable snapshot shards assigned to the local node in order to execute {@link CacheFile#fsync()}\n+     * on cache entries belonging to shards. When at least one {@link CacheFile#fsync()} call returns a non empty set of completed ranges\n+     * this method also fsync the shard's snapshot cache directory, which is the parent directory of the cache entries. Note that this\n+     * method is best effort as cache entries might be evicted during iterations and cache files/dirs removed from disk.\n+     */\n+    protected synchronized void synchronizeCache() {\n+        if (lifecycleState() != Lifecycle.State.STARTED) {\n+            return;\n+        }\n+        final ClusterState clusterState = clusterService.state();\n+        final RoutingNode routingNode = clusterState.getRoutingNodes().node(clusterState.getNodes().getLocalNodeId());\n+        assert routingNode != null;\n+\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        for (ShardRouting shardRouting : routingNode) {\n+            if (shardRouting.active()) {", "originalCommit": "31299c1a14f827892eb97b38228f68f77baea1ce", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMzNTQ5Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520335497", "bodyText": "This seems like an n^2 algorithm. Since we iterate the cache entries, could we not just fsync the cache files individually as long as they are in the cache?", "author": "henningandersen", "createdAt": "2020-11-10T07:07:12Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +206,176 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    // used in tests\n+    CacheSynchronizationTask getCacheSyncTask() {\n+        return cacheSyncTask;\n+    }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        assert cacheSyncTask != null;\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    /**\n+     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     */\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        assert cacheSyncTask != null;\n+\n+        if (event.routingTableChanged()) {\n+            final ClusterState clusterState = event.state();\n+            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n+            assert localNode.isDataNode();\n+\n+            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());\n+            cacheSyncTask.allowReschedule.set(shouldSynchronize);\n+\n+            if (shouldSynchronize == false) {\n+                logger.trace(\"canceling cache synchronization task (no searchable snapshots shard(s) assigned to local node)\");\n+                cacheSyncTask.cancel();\n+\n+            } else if (cacheSyncTask.isScheduled() == false) {\n+                logger.trace(\"scheduling cache synchronization task (searchable snapshots shard(s) assigned to local node)\");\n+                cacheSyncTask.rescheduleIfNecessary();\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Synchronize the cache files and dirs.\n+     *\n+     * This method iterates over all the searchable snapshot shards assigned to the local node in order to execute {@link CacheFile#fsync()}\n+     * on cache entries belonging to shards. When at least one {@link CacheFile#fsync()} call returns a non empty set of completed ranges\n+     * this method also fsync the shard's snapshot cache directory, which is the parent directory of the cache entries. Note that this\n+     * method is best effort as cache entries might be evicted during iterations and cache files/dirs removed from disk.\n+     */\n+    protected synchronized void synchronizeCache() {\n+        if (lifecycleState() != Lifecycle.State.STARTED) {\n+            return;\n+        }\n+        final ClusterState clusterState = clusterService.state();\n+        final RoutingNode routingNode = clusterState.getRoutingNodes().node(clusterState.getNodes().getLocalNodeId());\n+        assert routingNode != null;\n+\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        for (ShardRouting shardRouting : routingNode) {\n+            if (shardRouting.active()) {\n+                final IndexMetadata indexMetadata = clusterState.metadata().getIndexSafe(shardRouting.index());\n+                final Settings indexSettings = indexMetadata.getSettings();\n+                if (isSearchableSnapshotStore(indexSettings)) {\n+                    final ShardId shardId = shardRouting.shardId();\n+                    final SnapshotId snapshotId = new SnapshotId(\n+                        SNAPSHOT_SNAPSHOT_NAME_SETTING.get(indexSettings),\n+                        SNAPSHOT_SNAPSHOT_ID_SETTING.get(indexSettings)\n+                    );\n+                    final IndexId indexId = new IndexId(\n+                        SNAPSHOT_INDEX_NAME_SETTING.get(indexSettings),\n+                        SNAPSHOT_INDEX_ID_SETTING.get(indexSettings)\n+                    );\n+\n+                    boolean syncDirectory = false;\n+                    for (Tuple<CacheKey, CacheFile> entry : cache.entries()) {", "originalCommit": "31299c1a14f827892eb97b38228f68f77baea1ce", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDQ3MjgzMA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520472830", "bodyText": "++, I would also think there's no need to be tricky here. We already have all the tricky logic for handling a cache file's life-cycle in CacheFile => I think I like the idea of just iterating over all CacheFile here combined with Henning's other point of having the CacheFile register itself for fsync in some form. That seems like it wouldn't add new complexities around synchronization and life-cycle beyond what we already have in CacheFile?", "author": "original-brownbear", "createdAt": "2020-11-10T10:57:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMzNTQ5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0ODIyNA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520348224", "bodyText": "I think this is true. In fact, it looks like the lru-chain would be unsafely published with no happens-before to the reader.\nI think the iteration of the entries done in this PR is thus unsafe, at least it might skip some entries.\nI think the same applies to iterating over keys(), which we do a few places.\nTogether with other comments in this PR, this makes me think that perhaps it was easier to let CacheFile's that need fsync register with the CacheService (or a registry in between)?", "author": "henningandersen", "createdAt": "2020-11-10T07:38:30Z", "path": "server/src/main/java/org/elasticsearch/common/cache/Cache.java", "diffHunk": "@@ -650,6 +650,36 @@ public void remove() {\n         };\n     }\n \n+    /**\n+     * An LRU sequencing of the entries in the cache. This sequence is not protected from mutations\n+     * to the cache (except for {@link Iterator#remove()}. The result of iteration under any other mutation is\n+     * undefined.", "originalCommit": "31299c1a14f827892eb97b38228f68f77baea1ce", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDM0OTI2Mg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r520349262", "bodyText": "I wonder if we need to couple this to cluster state updates? Instead we could either trigger on the presence of any cache files or as proposed in another comment an explicit fsync-needed registration?", "author": "henningandersen", "createdAt": "2020-11-10T07:40:34Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +206,176 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    // used in tests\n+    CacheSynchronizationTask getCacheSyncTask() {\n+        return cacheSyncTask;\n+    }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        assert cacheSyncTask != null;\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    /**\n+     * Reschedule the {@link CacheSynchronizationTask} if the local data node is hosting searchable snapshot shards.\n+     */\n+    @Override\n+    public void clusterChanged(ClusterChangedEvent event) {\n+        assert cacheSyncTask != null;\n+\n+        if (event.routingTableChanged()) {\n+            final ClusterState clusterState = event.state();\n+            final DiscoveryNode localNode = clusterState.getNodes().getLocalNode();\n+            assert localNode.isDataNode();\n+\n+            final boolean shouldSynchronize = hasSearchableSnapshotShards(clusterState, localNode.getId());", "originalCommit": "31299c1a14f827892eb97b38228f68f77baea1ce", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "bf0e6600fc90cf1c0fbdde3e591ce53e7dcdaaa4", "url": "https://github.com/elastic/elasticsearch/commit/bf0e6600fc90cf1c0fbdde3e591ce53e7dcdaaa4", "message": "Merge branch 'master' into periodic-fsync", "committedDate": "2020-11-12T11:39:31Z", "type": "commit"}, {"oid": "9085f81a55fcb04b673705afad62a70bf54225d3", "url": "https://github.com/elastic/elasticsearch/commit/9085f81a55fcb04b673705afad62a70bf54225d3", "message": "Merge branch 'master' into periodic-fsync", "committedDate": "2020-11-13T09:20:39Z", "type": "commit"}, {"oid": "fb10c6fef5c3f6d13f1960f764212f09d9a3ea18", "url": "https://github.com/elastic/elasticsearch/commit/fb10c6fef5c3f6d13f1960f764212f09d9a3ea18", "message": "use registering mechanism to sync cache files", "committedDate": "2020-11-16T11:46:45Z", "type": "commit"}, {"oid": "f5d95597e8f27871f73cd1b9d2c83ae3f86da87d", "url": "https://github.com/elastic/elasticsearch/commit/f5d95597e8f27871f73cd1b9d2c83ae3f86da87d", "message": "Merge branch 'master' into periodic-fsync", "committedDate": "2020-11-16T11:47:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI0NzA2OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524247069", "bodyText": "This looks unused now?", "author": "henningandersen", "createdAt": "2020-11-16T12:55:09Z", "path": "server/src/main/java/org/elasticsearch/common/cache/Cache.java", "diffHunk": "@@ -650,6 +650,36 @@ public void remove() {\n         };\n     }\n \n+    /**\n+     * An LRU sequencing of the entries in the cache. This sequence is not protected from mutations\n+     * to the cache (except for {@link Iterator#remove()}. The result of iteration under any other mutation is\n+     * undefined.\n+     *\n+     * @return an LRU-ordered {@link Iterable} over the entries in the cache\n+     */\n+    public Iterable<Tuple<K,V>> entries() {", "originalCommit": "f5d95597e8f27871f73cd1b9d2c83ae3f86da87d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDM5NTQyNg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524395426", "bodyText": "Just a drive by comment @tlrx this is still unused and can probably go away, just in case you missed it :)\nI'll take a proper look at this PR in general now", "author": "original-brownbear", "createdAt": "2020-11-16T16:23:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI0NzA2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDkzODAxNg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524938016", "bodyText": "Just a drive by comment @tlrx this is still unused and can probably go away, just in case you missed it :)\n\nThanks! I'll remove it.\n\nI'll take a proper look at this PR in general now\n\nI was about to ping you once Henning approved the direction :)", "author": "tlrx", "createdAt": "2020-11-17T07:39:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI0NzA2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk2MjA1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524962059", "bodyText": "I removed the unused entries() method in 6b238d6", "author": "tlrx", "createdAt": "2020-11-17T08:19:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI0NzA2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI1MjI4Mg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524252282", "bodyText": "Looks like this might as well be a method (or inlined)?", "author": "henningandersen", "createdAt": "2020-11-16T13:04:27Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -52,40 +69,65 @@\n         Setting.Property.NodeScope\n     );\n \n+    public static final TimeValue MIN_SNAPSHOT_CACHE_SYNC_INTERVAL = TimeValue.timeValueSeconds(10L);\n+    public static final Setting<TimeValue> SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING = Setting.timeSetting(\n+        SETTINGS_PREFIX + \"sync_interval\",\n+        TimeValue.timeValueSeconds(60L),                        // default\n+        MIN_SNAPSHOT_CACHE_SYNC_INTERVAL,                       // min\n+        Setting.Property.NodeScope,\n+        Setting.Property.Dynamic\n+    );\n+\n+    private static final Supplier<Set<CacheFile>> SUPPLIER_OF_CACHE_FILES_TO_SYNC = ConcurrentCollections::newConcurrentSet;", "originalCommit": "f5d95597e8f27871f73cd1b9d2c83ae3f86da87d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDM0MjA4NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524342085", "bodyText": "I removed this when moving to a Queue implementation.", "author": "tlrx", "createdAt": "2020-11-16T15:14:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI1MjI4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI1MzcxMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524253711", "bodyText": "I think this is a leftover from last iteration? Since it is a final field initialized in constructor, I would prefer not to have this assert.", "author": "henningandersen", "createdAt": "2020-11-16T13:06:47Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +183,123 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        assert cacheSyncTask != null;", "originalCommit": "f5d95597e8f27871f73cd1b9d2c83ae3f86da87d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDM0MTg4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524341887", "bodyText": "Right, I removed it", "author": "tlrx", "createdAt": "2020-11-16T15:14:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI1MzcxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI2MDM4OA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524260388", "bodyText": "There is a race condition here, since we first get the set and then add to it. But the synchronizeCache method might read the set and check that it is empty before the add is done here, risking that we miss an fsync. Same is true for the non-empty case, in that it could start iterating over the set before the add is executed.\nMaybe we can use a queue instead? Since CacheFile ensures it is only registered once, we might not need the set semantics except when removing a cache file (where we could just iterate the queue, seems ok, could even just leave it in the queue).", "author": "henningandersen", "createdAt": "2020-11-16T13:18:09Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +183,123 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        assert cacheSyncTask != null;\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        final boolean added = cacheFilesToSyncRef.get().add(cacheFile);", "originalCommit": "f5d95597e8f27871f73cd1b9d2c83ae3f86da87d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDM0MzkwMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524343901", "bodyText": "You're perfectly right, I'm sorry I did not catch it by myself as it is obvious. I pushed 684e01e to use a ConcurrentLinkedQueue which should give us the right semantic.", "author": "tlrx", "createdAt": "2020-11-16T15:17:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI2MDM4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI2NjQwNA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524266404", "bodyText": "If the compareAndSet above does not succeed, should we then perhaps fail when running tests (using an assert)?", "author": "henningandersen", "createdAt": "2020-11-16T13:28:03Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -444,12 +461,12 @@ boolean needsFsync() {\n                         assert completedRanges != null;\n                         assert completedRanges.isEmpty() == false;\n \n-                        IOUtils.fsync(file, false, false); // TODO don't forget to fsync parent directory\n+                        IOUtils.fsync(file, false, false);\n                         success = true;\n                         return completedRanges;\n                     } finally {\n                         if (success == false) {\n-                            needsFsync.set(true);\n+                            markAsNeedsFSync();\n                         }\n                     }\n                 }", "originalCommit": "f5d95597e8f27871f73cd1b9d2c83ae3f86da87d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDM0NDYwNw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524344607", "bodyText": "I think we can but the existing tests assume that fsync can be executed at any time even when fsync is not needed. Those tests should be adapted as well, maybe in a follow up?", "author": "tlrx", "createdAt": "2020-11-16T15:18:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI2NjQwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwODI2OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525008269", "bodyText": "\ud83d\udc4d", "author": "henningandersen", "createdAt": "2020-11-17T09:31:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI2NjQwNA=="}], "type": "inlineReview"}, {"oid": "684e01ec740fa9c69b20c19d902305df8231e480", "url": "https://github.com/elastic/elasticsearch/commit/684e01ec740fa9c69b20c19d902305df8231e480", "message": "Use a queue", "committedDate": "2020-11-16T15:14:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQyNjkxNA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524426914", "bodyText": "Looks like we're only ever passing null here in tests, maybe cleaner to just pass the noop consumer in tests than having this conditional?", "author": "original-brownbear", "createdAt": "2020-11-16T17:04:41Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -117,10 +124,11 @@ protected void closeInternal() {\n     @Nullable\n     private volatile FileChannelReference channelRef;\n \n-    public CacheFile(String description, long length, Path file) {\n+    public CacheFile(String description, long length, Path file, @Nullable Consumer<CacheFile> fsyncListener) {\n         this.tracker = new SparseFileTracker(file.toString(), length);\n         this.description = Objects.requireNonNull(description);\n         this.file = Objects.requireNonNull(file);\n+        this.needsFsyncListener = fsyncListener != null ? fsyncListener : cacheFile -> {};", "originalCommit": "684e01ec740fa9c69b20c19d902305df8231e480", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk2MjI0Ng==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524962246", "bodyText": "Done in af47aaa", "author": "tlrx", "createdAt": "2020-11-17T08:19:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQyNjkxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUzMjM0OA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524532348", "bodyText": "I wonder if we should be this heroic? I guess I could see us running into an IOException here when exceeding the FD limit, but beyond that it seems there's very little valid reasons to keep going with a cache file after we fail to fsync it?\nShould we have a notion of forcefully dropping such a file from the cache since we can't trust it any longer?", "author": "original-brownbear", "createdAt": "2020-11-16T19:52:14Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +195,125 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        cacheFilesToSync.offer(cacheFile);\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n+     * queue of cache files to synchronize if the instance is referenced there.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+        cacheFilesToSync.remove(cacheFile);\n+    }\n+\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSync.contains(cacheFile);\n+    }\n+\n+    /**\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current queue of cache files to synchronize referenced by {@link #cacheFilesToSync}.\n+     *\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n+     */\n+    protected void synchronizeCache() {\n+        long count = 0L;\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        final int maxCacheFilesToSync = this.maxCacheFilesToSyncAtOnce;\n+        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+            if (lifecycleState() != Lifecycle.State.STARTED) {\n+                logger.debug(\"stopping cache synchronization (cache service is closing)\");\n+                break;\n+            }\n+            final CacheFile cacheFile = cacheFilesToSync.poll();\n+            if (cacheFile == null) {\n+                logger.debug(\"stopping cache synchronization (no more cache files to fsync)\");\n+                break;\n+            }\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);\n+                            logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n+                        } catch (Exception e) {\n+                            logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);\n+                        }\n+                    }\n+                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n+                    count += 1L;\n+                }\n+            } catch (Exception e) {\n+                logger.warn(() -> new ParameterizedMessage(\"failed to fsync cache file [{}]\", cacheFilePath.getFileName()), e);", "originalCommit": "684e01ec740fa9c69b20c19d902305df8231e480", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0MTI4NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524941285", "bodyText": "I agree, my attention was to not add the cache file to the Lucene index if the fsync failed.\n\nShould we have a notion of forcefully dropping such a file from the cache since we can't trust it any longer?\n\nI think we need such a mechanism because we should also discard a cache file in case we fail to write a range in it. I think I can try to tackle this in a follow up but I expect tests to be quite complex.", "author": "tlrx", "createdAt": "2020-11-17T07:46:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUzMjM0OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUzMzU1OA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524533558", "bodyText": "Same as the other comment, maybe even more pronounced here: what does it mean if we fail to fsync the directory? Doesn't it at least mean that we failed to fsync the file as well? (it's certainly not guaranteed to be safely persisted if it was just created on many Linux FS)", "author": "original-brownbear", "createdAt": "2020-11-16T19:54:18Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +195,125 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        cacheFilesToSync.offer(cacheFile);\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n+     * queue of cache files to synchronize if the instance is referenced there.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+        cacheFilesToSync.remove(cacheFile);\n+    }\n+\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSync.contains(cacheFile);\n+    }\n+\n+    /**\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current queue of cache files to synchronize referenced by {@link #cacheFilesToSync}.\n+     *\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n+     */\n+    protected void synchronizeCache() {\n+        long count = 0L;\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        final int maxCacheFilesToSync = this.maxCacheFilesToSyncAtOnce;\n+        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+            if (lifecycleState() != Lifecycle.State.STARTED) {\n+                logger.debug(\"stopping cache synchronization (cache service is closing)\");\n+                break;\n+            }\n+            final CacheFile cacheFile = cacheFilesToSync.poll();\n+            if (cacheFile == null) {\n+                logger.debug(\"stopping cache synchronization (no more cache files to fsync)\");\n+                break;\n+            }\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);\n+                            logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n+                        } catch (Exception e) {\n+                            logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);", "originalCommit": "684e01ec740fa9c69b20c19d902305df8231e480", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0MTYyNQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524941625", "bodyText": "Doesn't it at least mean that we failed to fsync the file as well? (it's certainly not guaranteed to be safely persisted if it was just created on many Linux FS)\n\nThat's my understanding as well, meaning that the cache file should not be added to the Lucene index.", "author": "tlrx", "createdAt": "2020-11-17T07:47:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUzMzU1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUzNTIzMw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524535233", "bodyText": "Should we first remove the file from the queue and then evict to have less of a race here with concurrent fsync runs?", "author": "original-brownbear", "createdAt": "2020-11-16T19:57:14Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +195,125 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        cacheFilesToSync.offer(cacheFile);\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n+     * queue of cache files to synchronize if the instance is referenced there.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+        cacheFilesToSync.remove(cacheFile);", "originalCommit": "684e01ec740fa9c69b20c19d902305df8231e480", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0MTk2NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524941965", "bodyText": "I saw it the other way, as startEviction() should prevent more ranges to be written and then the cache file to register itself back into the queue.", "author": "tlrx", "createdAt": "2020-11-17T07:47:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUzNTIzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk2MjYyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524962621", "bodyText": "I removed the remove() call in eabe562", "author": "tlrx", "createdAt": "2020-11-17T08:20:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUzNTIzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0MDY0OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524540649", "bodyText": "Also, calling remove (O(n)) on a ConcurrentLinkedQueue feels like it may bring trouble if we're dealing with a large number of files queued up? Do we even need to do this when we could simply skip evicted files when polling the fsync queue?", "author": "original-brownbear", "createdAt": "2020-11-16T20:07:11Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +195,125 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        cacheFilesToSync.offer(cacheFile);\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted. It also removes the instance from the current\n+     * queue of cache files to synchronize if the instance is referenced there.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+        cacheFilesToSync.remove(cacheFile);", "originalCommit": "684e01ec740fa9c69b20c19d902305df8231e480", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk0NDAxMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524944011", "bodyText": "Agree - Henning also raised this point. The CacheFile#fsync() method should return an empty set of ranges if the cache file is evicted and deleted from disk, we can rely on this to skip removed files.", "author": "tlrx", "createdAt": "2020-11-17T07:52:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0MDY0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk2MjU1MA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r524962550", "bodyText": "I removed the remove() call in eabe562", "author": "tlrx", "createdAt": "2020-11-17T08:19:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0MDY0OQ=="}], "type": "inlineReview"}, {"oid": "6b238d6e76b0ad8445feae40ef7076611d88a5c8", "url": "https://github.com/elastic/elasticsearch/commit/6b238d6e76b0ad8445feae40ef7076611d88a5c8", "message": "revert changes in Cache", "committedDate": "2020-11-17T08:13:11Z", "type": "commit"}, {"oid": "eabe56292858d6a23a4b78d77eba1b6b6bf998f9", "url": "https://github.com/elastic/elasticsearch/commit/eabe56292858d6a23a4b78d77eba1b6b6bf998f9", "message": "do not remove from queue on eviction", "committedDate": "2020-11-17T08:14:06Z", "type": "commit"}, {"oid": "af47aaa052d82b6033de699956a575ffd780ab73", "url": "https://github.com/elastic/elasticsearch/commit/af47aaa052d82b6033de699956a575ffd780ab73", "message": "noop fsyncListener", "committedDate": "2020-11-17T08:17:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwNTMzNw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525005337", "bodyText": "It would be nice to ensure we never loop further than the set of cache files already in the queue at the beginning of this method. Can we cap the number of iterations by the size of the queue before we start any fsync'ing? It is O(n) on the linked-queue implementation, but I think that is fine.\nIf we just continue looping, we risk an oscillating effect of writing another block of data and then fsync'ing it multiple times, resulting in much more fsync'ing than desired.", "author": "henningandersen", "createdAt": "2020-11-17T09:27:33Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +195,123 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        cacheFilesToSync.offer(cacheFile);\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.d\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+    }\n+\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSync.contains(cacheFile);\n+    }\n+\n+    /**\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current queue of cache files to synchronize referenced by {@link #cacheFilesToSync}.\n+     *\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n+     */\n+    protected void synchronizeCache() {\n+        long count = 0L;\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        final int maxCacheFilesToSync = this.maxCacheFilesToSyncAtOnce;\n+        for (long i = 0L; i < maxCacheFilesToSync; i++) {", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTE5OTk1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525199959", "bodyText": "This is a good suggestion, I pushed 437c8ea.", "author": "tlrx", "createdAt": "2020-11-17T14:33:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwNTMzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwNjI1OA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525206258", "bodyText": "Are you sure this is ok? The size() call isn't just O(n) it also has no accuracy guarantees. Should we maybe use org.elasticsearch.common.util.concurrent.SizeBlockingQueue here to make this a little safer?", "author": "original-brownbear", "createdAt": "2020-11-17T14:41:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwNTMzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIxMzcwMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525213701", "bodyText": "I'd prefer not using a BlockingQueue at all. An alternative could be to maintain a cacheFilesToSync atomic counter that is incremented when the cache file register itself for fsync (in onCacheFileUpdate) and decremented everytime a fsync is executed. The current size would be captured before we start any fsync'ing.", "author": "tlrx", "createdAt": "2020-11-17T14:50:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwNTMzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIxODQ4Mg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525218482", "bodyText": "Ah right, this queue isn't blocking :) -> counter sounds good to me", "author": "original-brownbear", "createdAt": "2020-11-17T14:56:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwNTMzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIyNTUzOQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525225539", "bodyText": "I pushed 395845d", "author": "tlrx", "createdAt": "2020-11-17T15:04:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwNTMzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAzOTAzOA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525039038", "bodyText": "I think we only expect IOException here. Perhaps we can assert that to ensure tests will fail?\nSimilar assert a few lines up.", "author": "henningandersen", "createdAt": "2020-11-17T10:17:32Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +195,123 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        cacheFilesToSync.offer(cacheFile);\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.d\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+    }\n+\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSync.contains(cacheFile);\n+    }\n+\n+    /**\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current queue of cache files to synchronize referenced by {@link #cacheFilesToSync}.\n+     *\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n+     */\n+    protected void synchronizeCache() {\n+        long count = 0L;\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        final int maxCacheFilesToSync = this.maxCacheFilesToSyncAtOnce;\n+        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+            if (lifecycleState() != Lifecycle.State.STARTED) {\n+                logger.debug(\"stopping cache synchronization (cache service is closing)\");\n+                break;\n+            }\n+            final CacheFile cacheFile = cacheFilesToSync.poll();\n+            if (cacheFile == null) {\n+                logger.debug(\"stopping cache synchronization (no more cache files to fsync)\");\n+                break;\n+            }\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);\n+                            logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n+                        } catch (Exception e) {\n+                            logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);\n+                        }\n+                    }\n+                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n+                    count += 1L;\n+                }\n+            } catch (Exception e) {\n+                logger.warn(() -> new ParameterizedMessage(\"failed to fsync cache file [{}]\", cacheFilePath.getFileName()), e);", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwMDAzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525200031", "bodyText": "Makes sense, I added c20bf75", "author": "tlrx", "createdAt": "2020-11-17T14:33:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAzOTAzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA1MTg1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525051853", "bodyText": "nit: I find it nicer to just pass in a Runnable here, to make it clear that a CacheFile can only request an fsync of itself.", "author": "henningandersen", "createdAt": "2020-11-17T10:37:14Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -117,10 +124,11 @@ protected void closeInternal() {\n     @Nullable\n     private volatile FileChannelReference channelRef;\n \n-    public CacheFile(String description, long length, Path file) {\n+    public CacheFile(String description, long length, Path file, Consumer<CacheFile> fsyncListener) {", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwMDA2OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525200069", "bodyText": "I pushed 74f728f to use a Runnable", "author": "tlrx", "createdAt": "2020-11-17T14:33:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA1MTg1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA1MzcxNA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525053714", "bodyText": "This will add it back on the queue, so we continually try to fsync a bad file. I saw the comments Armin made in other places about this, we can tackle this in the same follow-up.", "author": "henningandersen", "createdAt": "2020-11-17T10:40:09Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/index/store/cache/CacheFile.java", "diffHunk": "@@ -444,12 +461,12 @@ boolean needsFsync() {\n                         assert completedRanges != null;\n                         assert completedRanges.isEmpty() == false;\n \n-                        IOUtils.fsync(file, false, false); // TODO don't forget to fsync parent directory\n+                        IOUtils.fsync(file, false, false);\n                         success = true;\n                         return completedRanges;\n                     } finally {\n                         if (success == false) {\n-                            needsFsync.set(true);\n+                            markAsNeedsFSync();", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwMDEwMw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525200103", "bodyText": "Let's do that \ud83d\udc4d", "author": "tlrx", "createdAt": "2020-11-17T14:33:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA1MzcxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA1NTE0NA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525055144", "bodyText": "I wonder if we should lower this to 1 second.\nI can imagine us using this for a poor-mans rate limiter - set the interval to 1 second and number of files to sync to 10 on a spinning disk setup in case fsync'ing causes issues.", "author": "henningandersen", "createdAt": "2020-11-17T10:42:16Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -52,40 +68,78 @@\n         Setting.Property.NodeScope\n     );\n \n+    public static final TimeValue MIN_SNAPSHOT_CACHE_SYNC_INTERVAL = TimeValue.timeValueSeconds(10L);", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwMDE1NA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525200154", "bodyText": "Makes sense, I pushed 365812d", "author": "tlrx", "createdAt": "2020-11-17T14:33:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA1NTE0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA2MDU4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525060587", "bodyText": "These fields are unused. Seems like you intended the rootDir to have significance?", "author": "henningandersen", "createdAt": "2020-11-17T10:50:53Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java", "diffHunk": "@@ -245,4 +291,46 @@ public void putAsync(\n             listener.onResponse(null);\n         }\n     }\n+\n+    /**\n+     * A {@link FileSystemProvider} that counts the number of times the method {@link FileChannel#force(boolean)} is executed on every\n+     * files.\n+     */\n+    public static class FSyncTrackingFileSystemProvider extends FilterFileSystemProvider {\n+\n+        private final Map<Path, AtomicInteger> files = new ConcurrentHashMap<>();\n+        private final FileSystem delegateInstance;\n+        private final Path rootDir;", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwMDE5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525200191", "bodyText": "This should have been mutualized with some other tests, it is now in 5091a5d. Thanks for spotting this.", "author": "tlrx", "createdAt": "2020-11-17T14:33:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA2MDU4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA3MTE0Ng==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525071146", "bodyText": "Would be good to verify that once we evicted, we do not fsync these CacheFiles anymore.", "author": "henningandersen", "createdAt": "2020-11-17T11:08:14Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheServiceTests.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.searchablesnapshots.cache;\n+\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.PathUtils;\n+import org.elasticsearch.common.io.PathUtilsForTesting;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.store.cache.CacheFile;\n+import org.elasticsearch.index.store.cache.CacheKey;\n+import org.elasticsearch.index.store.cache.TestUtils.FSyncTrackingFileSystemProvider;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.xpack.searchablesnapshots.AbstractSearchableSnapshotsTestCase;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.HashMap;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.SortedSet;\n+\n+import static org.elasticsearch.index.store.cache.TestUtils.randomPopulateAndReads;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+public class CacheServiceTests extends AbstractSearchableSnapshotsTestCase {\n+\n+    private static FSyncTrackingFileSystemProvider fileSystemProvider;\n+\n+    @BeforeClass\n+    public static void installFileSystem() {\n+        fileSystemProvider = new FSyncTrackingFileSystemProvider(PathUtils.getDefaultFileSystem(), createTempDir());\n+        PathUtilsForTesting.installMock(fileSystemProvider.getFileSystem(null));\n+    }\n+\n+    @AfterClass\n+    public static void removeFileSystem() {\n+        PathUtilsForTesting.teardown();\n+    }\n+\n+    public void testCacheSynchronization() throws Exception {\n+        final int numShards = randomIntBetween(1, 3);\n+        final Index index = new Index(randomAlphaOfLength(5).toLowerCase(Locale.ROOT), UUIDs.randomBase64UUID(random()));\n+        final SnapshotId snapshotId = new SnapshotId(\"_snapshot_name\", UUIDs.randomBase64UUID(random()));\n+        final IndexId indexId = new IndexId(\"_index_name\", UUIDs.randomBase64UUID(random()));\n+\n+        logger.debug(\"--> creating shard cache directories on disk\");\n+        final Path[] shardsCacheDirs = new Path[numShards];\n+        for (int i = 0; i < numShards; i++) {\n+            final Path shardDataPath = randomFrom(nodeEnvironment.availableShardPaths(new ShardId(index, i)));\n+            assertFalse(Files.exists(shardDataPath));\n+\n+            logger.debug(\"--> creating directories [{}] for shard [{}]\", shardDataPath.toAbsolutePath(), i);\n+            shardsCacheDirs[i] = Files.createDirectories(CacheService.resolveSnapshotCache(shardDataPath).resolve(snapshotId.getUUID()));\n+        }\n+\n+        try (CacheService cacheService = defaultCacheService()) {\n+            cacheService.start();\n+\n+            logger.debug(\"--> setting large cache sync interval (explicit cache synchronization calls in test)\");\n+            cacheService.setCacheSyncInterval(TimeValue.timeValueMillis(Long.MAX_VALUE));\n+\n+            // Keep a count of the number of writes for every cache file existing in the cache\n+            final Map<CacheKey, Tuple<CacheFile, Integer>> previous = new HashMap<>();\n+\n+            for (int iteration = 0; iteration < between(1, 10); iteration++) {\n+\n+                final Map<CacheKey, Tuple<CacheFile, Integer>> updates = new HashMap<>();\n+\n+                logger.trace(\"--> more random reads/writes from existing cache files\");\n+                for (Map.Entry<CacheKey, Tuple<CacheFile, Integer>> cacheEntry : randomSubsetOf(previous.entrySet())) {\n+                    final CacheKey cacheKey = cacheEntry.getKey();\n+                    final CacheFile cacheFile = cacheEntry.getValue().v1();\n+\n+                    final CacheFile.EvictionListener listener = evictedCacheFile -> {};\n+                    cacheFile.acquire(listener);\n+\n+                    final SortedSet<Tuple<Long, Long>> newCacheRanges = randomPopulateAndReads(cacheFile);\n+                    assertThat(cacheService.isCacheFileToSync(cacheFile), is(newCacheRanges.isEmpty() == false));\n+                    if (newCacheRanges.isEmpty() == false) {\n+                        final int numberOfWrites = cacheEntry.getValue().v2() + 1;\n+                        updates.put(cacheKey, Tuple.tuple(cacheFile, numberOfWrites));\n+                    }\n+                    cacheFile.release(listener);\n+                }\n+\n+                logger.trace(\"--> creating new cache files and randomly read/write them\");\n+                for (int i = 0; i < between(1, 25); i++) {\n+                    final ShardId shardId = new ShardId(index, randomIntBetween(0, numShards - 1));\n+                    final String fileName = String.format(Locale.ROOT, \"file_%d_%d\", iteration, i);\n+                    final CacheKey cacheKey = new CacheKey(snapshotId, indexId, shardId, fileName);\n+                    final CacheFile cacheFile = cacheService.get(cacheKey, randomIntBetween(1, 10_000), shardsCacheDirs[shardId.id()]);\n+\n+                    final CacheFile.EvictionListener listener = evictedCacheFile -> {};\n+                    cacheFile.acquire(listener);\n+\n+                    final SortedSet<Tuple<Long, Long>> newRanges = randomPopulateAndReads(cacheFile);\n+                    assertThat(cacheService.isCacheFileToSync(cacheFile), is(newRanges.isEmpty() == false));\n+                    updates.put(cacheKey, Tuple.tuple(cacheFile, newRanges.isEmpty() ? 0 : 1));\n+                    cacheFile.release(listener);\n+                }\n+\n+                logger.trace(\"--> evicting random cache files\");\n+                for (CacheKey evictedCacheKey : randomSubsetOf(Sets.union(previous.keySet(), updates.keySet()))) {", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwMDI1Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525200257", "bodyText": "Right - I added f69dde9", "author": "tlrx", "createdAt": "2020-11-17T14:33:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA3MTE0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA3NDk4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525074989", "bodyText": "I think we should bias towards smaller values, perhaps using scaledRandomInt?", "author": "henningandersen", "createdAt": "2020-11-17T11:14:38Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/AbstractSearchableSnapshotsTestCase.java", "diffHunk": "@@ -63,19 +101,27 @@ protected CacheService randomCacheService() {\n         if (randomBoolean()) {\n             cacheSettings.put(CacheService.SNAPSHOT_CACHE_RANGE_SIZE_SETTING.getKey(), randomCacheRangeSize());\n         }\n-        return new CacheService(AbstractSearchableSnapshotsTestCase::noOpCacheCleaner, cacheSettings.build());\n+        if (randomBoolean()) {\n+            cacheSettings.put(\n+                CacheService.SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING.getKey(),\n+                TimeValue.timeValueSeconds(randomLongBetween(MIN_SNAPSHOT_CACHE_SYNC_INTERVAL.getSeconds(), Long.MAX_VALUE))", "originalCommit": "af47aaa052d82b6033de699956a575ffd780ab73", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTIwMDI5MA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525200290", "bodyText": "I pushed 8fe920b to randomize between 1 and 120 seconds.", "author": "tlrx", "createdAt": "2020-11-17T14:33:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTA3NDk4OQ=="}], "type": "inlineReview"}, {"oid": "437c8ea0c64f9d3777762e19f96ec2ecc7f22b4d", "url": "https://github.com/elastic/elasticsearch/commit/437c8ea0c64f9d3777762e19f96ec2ecc7f22b4d", "message": "limit iterations", "committedDate": "2020-11-17T12:21:12Z", "type": "commit"}, {"oid": "c20bf75e9f58a71cfcc624b2cb230f3167c0c6b7", "url": "https://github.com/elastic/elasticsearch/commit/c20bf75e9f58a71cfcc624b2cb230f3167c0c6b7", "message": "assert IOE", "committedDate": "2020-11-17T12:21:12Z", "type": "commit"}, {"oid": "365812d53aebf7023cdd8010f430274de0930247", "url": "https://github.com/elastic/elasticsearch/commit/365812d53aebf7023cdd8010f430274de0930247", "message": "min 1s", "committedDate": "2020-11-17T12:21:12Z", "type": "commit"}, {"oid": "8fe920be20ba2478f45e2940c688b9ab6ded559f", "url": "https://github.com/elastic/elasticsearch/commit/8fe920be20ba2478f45e2940c688b9ab6ded559f", "message": "scaledRandomIntBetween(1, 120)", "committedDate": "2020-11-17T12:23:44Z", "type": "commit"}, {"oid": "74f728f51f097f2129314ffdcc64bdc9eeebc554", "url": "https://github.com/elastic/elasticsearch/commit/74f728f51f097f2129314ffdcc64bdc9eeebc554", "message": "Use runnable", "committedDate": "2020-11-17T13:30:22Z", "type": "commit"}, {"oid": "5091a5db7dfd9a9cbb84dbbbf6ac61cc49ff97b0", "url": "https://github.com/elastic/elasticsearch/commit/5091a5db7dfd9a9cbb84dbbbf6ac61cc49ff97b0", "message": "mutualize FSyncTrackingFileSystemProvider", "committedDate": "2020-11-17T13:48:20Z", "type": "commit"}, {"oid": "f69dde9e9e911a02fbf728a378e65da8b56cba7b", "url": "https://github.com/elastic/elasticsearch/commit/f69dde9e9e911a02fbf728a378e65da8b56cba7b", "message": "check evictions", "committedDate": "2020-11-17T14:32:35Z", "type": "commit"}, {"oid": "395845dff77748e3c873d8c5e0e2d3f5e7bfec97", "url": "https://github.com/elastic/elasticsearch/commit/395845dff77748e3c873d8c5e0e2d3f5e7bfec97", "message": "use atomic long to count cache files", "committedDate": "2020-11-17T15:03:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI2MDA0OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525260049", "bodyText": "NIT: we seem to generally wrap parameters in [{}] when logging?", "author": "original-brownbear", "createdAt": "2020-11-17T15:38:16Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +202,129 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        assert cacheFile != null;\n+        cacheFilesToSync.offer(cacheFile);\n+        numberOfCacheFilesToSync.incrementAndGet();\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+    }\n+\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSync.contains(cacheFile);\n+    }\n+\n+    /**\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current queue of cache files to synchronize referenced by {@link #cacheFilesToSync}.\n+     *\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n+     */\n+    protected void synchronizeCache() {\n+        long count = 0L;\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        final long maxCacheFilesToSync = Math.min(numberOfCacheFilesToSync.get(), this.maxCacheFilesToSyncAtOnce);\n+        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+            if (lifecycleState() != Lifecycle.State.STARTED) {\n+                logger.debug(\"stopping cache synchronization (cache service is closing)\");\n+                break;\n+            }\n+            final CacheFile cacheFile = cacheFilesToSync.poll();\n+            if (cacheFile == null) {\n+                logger.debug(\"stopping cache synchronization (no more cache files to fsync)\");\n+                break;\n+            }\n+            final long value = numberOfCacheFilesToSync.decrementAndGet();\n+            assert value >= 0 : value;\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);\n+                            logger.trace(\"cache directory [{}] synchronized\", cacheDir);\n+                        } catch (Exception e) {\n+                            assert e instanceof IOException : e;\n+                            logger.warn(() -> new ParameterizedMessage(\"failed to synchronize cache directory [{}]\", cacheDir), e);\n+                        }\n+                    }\n+                    // TODO Index searchable snapshot shard information + cache file ranges in Lucene\n+                    count += 1L;\n+                }\n+            } catch (Exception e) {\n+                assert e instanceof IOException : e;\n+                logger.warn(() -> new ParameterizedMessage(\"failed to fsync cache file [{}]\", cacheFilePath.getFileName()), e);\n+            }\n+        }\n+        if (logger.isDebugEnabled()) {\n+            final long elapsedNanos = threadPool.relativeTimeInNanos() - startTimeNanos;\n+            logger.debug(\n+                \"cache files synchronization is done ({} cache files synchronized in {})\",", "originalCommit": "395845dff77748e3c873d8c5e0e2d3f5e7bfec97", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI2MTk4NA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525261984", "bodyText": "Could we theoretically assert that the service has been stopped here? (it seems the only way for the queue to be reduced is for this method to run and it should only ever run once at any point in time)", "author": "original-brownbear", "createdAt": "2020-11-17T15:40:39Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +202,129 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        assert cacheFile != null;\n+        cacheFilesToSync.offer(cacheFile);\n+        numberOfCacheFilesToSync.incrementAndGet();\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+    }\n+\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSync.contains(cacheFile);\n+    }\n+\n+    /**\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current queue of cache files to synchronize referenced by {@link #cacheFilesToSync}.\n+     *\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n+     */\n+    protected void synchronizeCache() {\n+        long count = 0L;\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        final long maxCacheFilesToSync = Math.min(numberOfCacheFilesToSync.get(), this.maxCacheFilesToSyncAtOnce);\n+        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+            if (lifecycleState() != Lifecycle.State.STARTED) {\n+                logger.debug(\"stopping cache synchronization (cache service is closing)\");\n+                break;\n+            }\n+            final CacheFile cacheFile = cacheFilesToSync.poll();\n+            if (cacheFile == null) {\n+                logger.debug(\"stopping cache synchronization (no more cache files to fsync)\");", "originalCommit": "395845dff77748e3c873d8c5e0e2d3f5e7bfec97", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTkwOTE5OA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525909198", "bodyText": "Since this method is the only place where cache files are removed from the queue I think it makes more sense to synchronized the synchronizeCache() method and asserts here that we never poll a null cacheFile", "author": "tlrx", "createdAt": "2020-11-18T08:48:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTI2MTk4NA=="}], "type": "inlineReview"}, {"oid": "082b76db40bd1076b57905433caff29247dc4859", "url": "https://github.com/elastic/elasticsearch/commit/082b76db40bd1076b57905433caff29247dc4859", "message": "[] + synchronized assert", "committedDate": "2020-11-18T09:09:09Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk3NDU1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525974553", "bodyText": "nit: I would find it more readable with an explicit lock object. It also reduces the risk of/if someone synchronizing another method in this class", "author": "henningandersen", "createdAt": "2020-11-18T10:25:29Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -251,7 +251,7 @@ boolean isCacheFileToSync(CacheFile cacheFile) {\n      * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n      * cache entry. Note that cache files might be evicted during the synchronization.\n      */\n-    protected void synchronizeCache() {\n+    protected synchronized void synchronizeCache() {", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4ODAxOA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527688018", "bodyText": "I agree, an explicit lock object would help. It also helps if we want to wait a bit for the cache sync task to terminate before shutdown, so I added such a lock.", "author": "tlrx", "createdAt": "2020-11-20T13:25:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk3NDU1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4NzIyMA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525987220", "bodyText": "Should we also wait (with timeout) for any ongoing cache sync task to complete?", "author": "henningandersen", "createdAt": "2020-11-18T10:44:59Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -52,40 +71,80 @@\n         Setting.Property.NodeScope\n     );\n \n+    public static final TimeValue MIN_SNAPSHOT_CACHE_SYNC_INTERVAL = TimeValue.timeValueSeconds(1L);\n+    public static final Setting<TimeValue> SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING = Setting.timeSetting(\n+        SETTINGS_PREFIX + \"sync_interval\",\n+        TimeValue.timeValueSeconds(60L),                        // default\n+        MIN_SNAPSHOT_CACHE_SYNC_INTERVAL,                       // min\n+        Setting.Property.NodeScope,\n+        Setting.Property.Dynamic\n+    );\n+\n+    public static final Setting<Integer> SNAPSHOT_CACHE_MAX_FILES_TO_SYNC_AT_ONCE_SETTING = Setting.intSetting(\n+        SETTINGS_PREFIX + \"max_files_to_sync\",\n+        10_000,                                                 // default\n+        0,                                                      // min\n+        Integer.MAX_VALUE,                                      // min\n+        Setting.Property.NodeScope,\n+        Setting.Property.Dynamic\n+    );\n+\n+    private static final Logger logger = LogManager.getLogger(CacheService.class);\n+\n+    private final ThreadPool threadPool;\n+    private final ConcurrentLinkedQueue<CacheFile> cacheFilesToSync;\n+    private final AtomicLong numberOfCacheFilesToSync;\n+    private final CacheSynchronizationTask cacheSyncTask;\n     private final Cache<CacheKey, CacheFile> cache;\n     private final ByteSizeValue cacheSize;\n     private final Runnable cacheCleaner;\n     private final ByteSizeValue rangeSize;\n \n-    public CacheService(final Runnable cacheCleaner, final Settings settings) {\n-        this(cacheCleaner, SNAPSHOT_CACHE_SIZE_SETTING.get(settings), SNAPSHOT_CACHE_RANGE_SIZE_SETTING.get(settings));\n-    }\n+    private volatile int maxCacheFilesToSyncAtOnce;\n \n-    // exposed for tests\n-    public CacheService(final Runnable cacheCleaner, final ByteSizeValue cacheSize, final ByteSizeValue rangeSize) {\n-        this.cacheSize = Objects.requireNonNull(cacheSize);\n+    public CacheService(\n+        final Settings settings,\n+        final ClusterService clusterService,\n+        final ThreadPool threadPool,\n+        final Runnable cacheCleaner\n+    ) {\n+        this.threadPool = Objects.requireNonNull(threadPool);\n+        this.cacheSize = SNAPSHOT_CACHE_SIZE_SETTING.get(settings);\n         this.cacheCleaner = Objects.requireNonNull(cacheCleaner);\n-        this.rangeSize = Objects.requireNonNull(rangeSize);\n+        this.rangeSize = SNAPSHOT_CACHE_RANGE_SIZE_SETTING.get(settings);\n         this.cache = CacheBuilder.<CacheKey, CacheFile>builder()\n             .setMaximumWeight(cacheSize.getBytes())\n             .weigher((key, entry) -> entry.getLength())\n             // NORELEASE This does not immediately free space on disk, as cache file are only deleted when all index inputs\n             // are done with reading/writing the cache file\n-            .removalListener(notification -> IOUtils.closeWhileHandlingException(() -> notification.getValue().startEviction()))\n+            .removalListener(notification -> onCacheFileRemoval(notification.getValue()))\n             .build();\n+        this.numberOfCacheFilesToSync = new AtomicLong();\n+        this.cacheFilesToSync = new ConcurrentLinkedQueue<>();\n+        final ClusterSettings clusterSettings = clusterService.getClusterSettings();\n+        this.maxCacheFilesToSyncAtOnce = SNAPSHOT_CACHE_MAX_FILES_TO_SYNC_AT_ONCE_SETTING.get(settings);\n+        clusterSettings.addSettingsUpdateConsumer(SNAPSHOT_CACHE_MAX_FILES_TO_SYNC_AT_ONCE_SETTING, this::setMaxCacheFilesToSyncAtOnce);\n+        this.cacheSyncTask = new CacheSynchronizationTask(threadPool, SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING.get(settings));\n+        clusterSettings.addSettingsUpdateConsumer(SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING, this::setCacheSyncInterval);\n     }\n \n     public static Path getShardCachePath(ShardPath shardPath) {\n-        return shardPath.getDataPath().resolve(\"snapshot_cache\");\n+        return resolveSnapshotCache(shardPath.getDataPath());\n+    }\n+\n+    static Path resolveSnapshotCache(Path path) {\n+        return path.resolve(\"snapshot_cache\");\n     }\n \n     @Override\n     protected void doStart() {\n+        cacheSyncTask.rescheduleIfNecessary();\n         cacheCleaner.run();\n     }\n \n     @Override\n     protected void doStop() {\n+        cacheSyncTask.close();", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4ODEyOA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527688128", "bodyText": "\ud83d\udc4d", "author": "tlrx", "createdAt": "2020-11-20T13:25:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4NzIyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4ODM3NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525988375", "bodyText": "I think this can be private?", "author": "henningandersen", "createdAt": "2020-11-18T10:46:46Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +202,127 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        assert cacheFile != null;\n+        cacheFilesToSync.offer(cacheFile);\n+        numberOfCacheFilesToSync.incrementAndGet();\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4NDgzOQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527684839", "bodyText": "I pushed ea34570", "author": "tlrx", "createdAt": "2020-11-20T13:19:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4ODM3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4ODQyNg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525988426", "bodyText": "I think this can be private?", "author": "henningandersen", "createdAt": "2020-11-18T10:46:50Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +202,127 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4NDg3Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527684877", "bodyText": "I pushed ea34570", "author": "tlrx", "createdAt": "2020-11-20T13:19:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk4ODQyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk5MDk5NQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525990995", "bodyText": "Do we need to fsync the directory except for the first time we fsync a file created in the directory? Perhaps we should do that when creating the file instead?\nThis can be handled in a follow-up if you prefer (and agree).", "author": "henningandersen", "createdAt": "2020-11-18T10:50:53Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -141,4 +202,127 @@ public void removeFromCache(final Predicate<CacheKey> predicate) {\n         }\n         cache.refresh();\n     }\n+\n+    void setCacheSyncInterval(TimeValue interval) {\n+        cacheSyncTask.setInterval(interval);\n+    }\n+\n+    private void setMaxCacheFilesToSyncAtOnce(int maxCacheFilesToSyncAtOnce) {\n+        this.maxCacheFilesToSyncAtOnce = maxCacheFilesToSyncAtOnce;\n+    }\n+\n+    /**\n+     * This method is invoked when a {@link CacheFile} notifies the current {@link CacheService} that it needs to be fsync on disk.\n+     * <p>\n+     * It adds the {@link CacheFile} instance to current set of cache files to synchronize.\n+     *\n+     * @param cacheFile the instance that needs to be fsync\n+     */\n+    void onCacheFileUpdate(CacheFile cacheFile) {\n+        assert cacheFile != null;\n+        cacheFilesToSync.offer(cacheFile);\n+        numberOfCacheFilesToSync.incrementAndGet();\n+    }\n+\n+    /**\n+     * This method is invoked after a {@link CacheFile} is evicted from the cache.\n+     * <p>\n+     * It notifies the {@link CacheFile}'s eviction listeners that the instance is evicted.\n+     *\n+     * @param cacheFile the evicted instance\n+     */\n+    void onCacheFileRemoval(CacheFile cacheFile) {\n+        IOUtils.closeWhileHandlingException(cacheFile::startEviction);\n+    }\n+\n+    // used in tests\n+    boolean isCacheFileToSync(CacheFile cacheFile) {\n+        return cacheFilesToSync.contains(cacheFile);\n+    }\n+\n+    /**\n+     * Synchronize the cache files and their parent directories on disk.\n+     *\n+     * This method synchronizes the cache files that have been updated since the last time the method was invoked. To be able to do this,\n+     * the cache files must notify the {@link CacheService} when they need to be fsync. When a {@link CacheFile} notifies the service the\n+     * {@link CacheFile} instance is added to the current queue of cache files to synchronize referenced by {@link #cacheFilesToSync}.\n+     *\n+     * Cache files are serially synchronized using the {@link CacheFile#fsync()} method. When the {@link CacheFile#fsync()} call returns a\n+     * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n+     * cache entry. Note that cache files might be evicted during the synchronization.\n+     */\n+    protected synchronized void synchronizeCache() {\n+        long count = 0L;\n+        final Set<Path> cacheDirs = new HashSet<>();\n+        final long startTimeNanos = threadPool.relativeTimeInNanos();\n+        final long maxCacheFilesToSync = Math.min(numberOfCacheFilesToSync.get(), this.maxCacheFilesToSyncAtOnce);\n+        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+            if (lifecycleState() != Lifecycle.State.STARTED) {\n+                logger.debug(\"stopping cache synchronization (cache service is closing)\");\n+                break;\n+            }\n+            final CacheFile cacheFile = cacheFilesToSync.poll();\n+            assert cacheFile != null;\n+\n+            final long value = numberOfCacheFilesToSync.decrementAndGet();\n+            assert value >= 0 : value;\n+            final Path cacheFilePath = cacheFile.getFile();\n+            try {\n+                final SortedSet<Tuple<Long, Long>> ranges = cacheFile.fsync();\n+                if (ranges.isEmpty() == false) {\n+                    logger.trace(\"cache file [{}] synchronized with [{}] completed range(s)\", cacheFilePath.getFileName(), ranges.size());\n+                    final Path cacheDir = cacheFilePath.toAbsolutePath().getParent();\n+                    if (cacheDirs.add(cacheDir)) {\n+                        try {\n+                            IOUtils.fsync(cacheDir, true, false);", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY5MzE3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527693179", "bodyText": "I found it simpler to do it here and concentrate the fsync logic at one place, but I agree it means an extra fsync per cache directory every 60s.\n\nPerhaps we should do that when creating the file instead?\n\nThat would mean to fsync the cache dir the first time a cache file is opened and have a mechanism to keep the knowledge of which cache dir was already fsync or not, since the cache file can be evicted before the cache sync task is executed. That sounds a bit more complex for a little gain to me.", "author": "tlrx", "createdAt": "2020-11-20T13:34:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk5MDk5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk5NTI5OQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r525995299", "bodyText": "Can we move this into a method on the file system provider so that it just reads:\nprovider.tearDown();\n\nhere?", "author": "henningandersen", "createdAt": "2020-11-18T10:57:31Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/CacheFileTests.java", "diffHunk": "@@ -271,23 +300,30 @@ public void testFSyncFailure() throws Exception {\n                 final SortedSet<Tuple<Long, Long>> expectedCompletedRanges = randomPopulateAndReads(cacheFile);\n                 if (expectedCompletedRanges.isEmpty() == false) {\n                     assertTrue(cacheFile.needsFsync());\n-                    expectThrows(IOException.class, cacheFile::fsync);\n+                    assertTrue(needsFSyncCalled.getAndSet(false));\n+                    IOException exception = expectThrows(IOException.class, cacheFile::fsync);\n+                    assertThat(exception.getMessage(), containsString(\"simulated\"));\n+                    assertTrue(cacheFile.needsFsync());\n+                    assertTrue(needsFSyncCalled.getAndSet(false));\n                 } else {\n                     assertFalse(cacheFile.needsFsync());\n                     final SortedSet<Tuple<Long, Long>> completedRanges = cacheFile.fsync();\n                     assertTrue(completedRanges.isEmpty());\n                 }\n-                assertNumberOfFSyncs(cacheFile.getFile(), equalTo(0L));\n+                assertNumberOfFSyncs(cacheFile.getFile(), equalTo(0));\n \n-                fileSystem.failFSyncs.set(false);\n+                fileSystem.failFSyncs(false);\n \n                 final SortedSet<Tuple<Long, Long>> completedRanges = cacheFile.fsync();\n                 assertArrayEquals(completedRanges.toArray(Tuple[]::new), expectedCompletedRanges.toArray(Tuple[]::new));\n-                assertNumberOfFSyncs(cacheFile.getFile(), equalTo(expectedCompletedRanges.isEmpty() ? 0L : 1L));\n+                assertNumberOfFSyncs(cacheFile.getFile(), equalTo(expectedCompletedRanges.isEmpty() ? 0 : 1));\n                 assertFalse(cacheFile.needsFsync());\n+                assertFalse(needsFSyncCalled.get());\n             } finally {\n                 cacheFile.release(listener);\n             }\n+        } finally {\n+            PathUtilsForTesting.installMock(fileSystem.getDelegateInstance());", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4NDk4MA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527684980", "bodyText": "+1 I pushed 54d051d", "author": "tlrx", "createdAt": "2020-11-20T13:19:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTk5NTI5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAwMDg5Mw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r526000893", "bodyText": "I think we should do this before cacheService.start() to avoid a race condition of the schedule task \"just started to run\" before we change this, which could interfere with the testing below.", "author": "henningandersen", "createdAt": "2020-11-18T11:06:23Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheServiceTests.java", "diffHunk": "@@ -0,0 +1,165 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.searchablesnapshots.cache;\n+\n+import org.elasticsearch.common.UUIDs;\n+import org.elasticsearch.common.collect.Tuple;\n+import org.elasticsearch.common.io.PathUtils;\n+import org.elasticsearch.common.io.PathUtilsForTesting;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.index.Index;\n+import org.elasticsearch.index.shard.ShardId;\n+import org.elasticsearch.index.store.cache.CacheFile;\n+import org.elasticsearch.index.store.cache.CacheKey;\n+import org.elasticsearch.index.store.cache.TestUtils.FSyncTrackingFileSystemProvider;\n+import org.elasticsearch.repositories.IndexId;\n+import org.elasticsearch.snapshots.SnapshotId;\n+import org.elasticsearch.xpack.searchablesnapshots.AbstractSearchableSnapshotsTestCase;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.HashMap;\n+import java.util.Locale;\n+import java.util.Map;\n+import java.util.SortedSet;\n+\n+import static org.elasticsearch.index.store.cache.TestUtils.randomPopulateAndReads;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+public class CacheServiceTests extends AbstractSearchableSnapshotsTestCase {\n+\n+    private static FSyncTrackingFileSystemProvider fileSystemProvider;\n+\n+    @BeforeClass\n+    public static void installFileSystem() {\n+        fileSystemProvider = new FSyncTrackingFileSystemProvider(PathUtils.getDefaultFileSystem(), createTempDir());\n+        PathUtilsForTesting.installMock(fileSystemProvider.getFileSystem(null));\n+    }\n+\n+    @AfterClass\n+    public static void removeFileSystem() {\n+        PathUtilsForTesting.teardown();\n+    }\n+\n+    public void testCacheSynchronization() throws Exception {\n+        final int numShards = randomIntBetween(1, 3);\n+        final Index index = new Index(randomAlphaOfLength(5).toLowerCase(Locale.ROOT), UUIDs.randomBase64UUID(random()));\n+        final SnapshotId snapshotId = new SnapshotId(\"_snapshot_name\", UUIDs.randomBase64UUID(random()));\n+        final IndexId indexId = new IndexId(\"_index_name\", UUIDs.randomBase64UUID(random()));\n+\n+        logger.debug(\"--> creating shard cache directories on disk\");\n+        final Path[] shardsCacheDirs = new Path[numShards];\n+        for (int i = 0; i < numShards; i++) {\n+            final Path shardDataPath = randomFrom(nodeEnvironment.availableShardPaths(new ShardId(index, i)));\n+            assertFalse(Files.exists(shardDataPath));\n+\n+            logger.debug(\"--> creating directories [{}] for shard [{}]\", shardDataPath.toAbsolutePath(), i);\n+            shardsCacheDirs[i] = Files.createDirectories(CacheService.resolveSnapshotCache(shardDataPath).resolve(snapshotId.getUUID()));\n+        }\n+\n+        try (CacheService cacheService = defaultCacheService()) {\n+            cacheService.start();\n+\n+            logger.debug(\"--> setting large cache sync interval (explicit cache synchronization calls in test)\");\n+            cacheService.setCacheSyncInterval(TimeValue.timeValueMillis(Long.MAX_VALUE));", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4NTgwMA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527685800", "bodyText": "Right - I pushed 6066924", "author": "tlrx", "createdAt": "2020-11-20T13:21:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAwMDg5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAwNDE4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r526004187", "bodyText": "This looks like it is a near identical copy from CacheFileTests, but the original method has not been removed, I think it should?", "author": "henningandersen", "createdAt": "2020-11-18T11:11:49Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java", "diffHunk": "@@ -22,20 +27,62 @@\n import java.io.FileNotFoundException;\n import java.io.IOException;\n import java.io.InputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.FileSystem;\n+import java.nio.file.OpenOption;\n+import java.nio.file.Path;\n+import java.nio.file.attribute.FileAttribute;\n+import java.nio.file.spi.FileSystemProvider;\n+import java.util.ArrayList;\n import java.util.Comparator;\n import java.util.List;\n import java.util.Map;\n+import java.util.Set;\n import java.util.SortedSet;\n import java.util.TreeSet;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n \n+import static java.util.Collections.synchronizedNavigableSet;\n+import static org.apache.lucene.util.LuceneTestCase.random;\n+import static org.elasticsearch.common.settings.Settings.builder;\n+import static org.elasticsearch.node.Node.NODE_NAME_SETTING;\n+import static org.elasticsearch.test.ESTestCase.between;\n+import static org.elasticsearch.test.ESTestCase.randomLongBetween;\n import static org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshotsConstants.toIntBytes;\n import static org.hamcrest.MatcherAssert.assertThat;\n import static org.hamcrest.Matchers.equalTo;\n+import static org.junit.Assert.assertTrue;\n import static org.mockito.Mockito.mock;\n \n public final class TestUtils {\n     private TestUtils() {}\n \n+    public static SortedSet<Tuple<Long, Long>> randomPopulateAndReads(final CacheFile cacheFile) {", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4NTQ4MQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527685481", "bodyText": "Apparently I started to mutualize utility methods but did not gone through... I pushed e8ad9be", "author": "tlrx", "createdAt": "2020-11-20T13:20:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAwNDE4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAxMDIwMg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r526010202", "bodyText": "That the tests work with this confused me for a while - but CacheFile uses deleteIfExists, which delegates to the original file system rather than going here. We need to keep the fsync counters for the check that we no longer fsync after evict to work.\nI wonder if this override of delete is at all necessary?", "author": "henningandersen", "createdAt": "2020-11-18T11:21:42Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/TestUtils.java", "diffHunk": "@@ -245,4 +292,62 @@ public void putAsync(\n             listener.onResponse(null);\n         }\n     }\n+\n+    /**\n+     * A {@link FileSystemProvider} that counts the number of times the method {@link FileChannel#force(boolean)} is executed on every\n+     * files.\n+     */\n+    public static class FSyncTrackingFileSystemProvider extends FilterFileSystemProvider {\n+\n+        private final Map<Path, AtomicInteger> files = new ConcurrentHashMap<>();\n+        private final AtomicBoolean failFSyncs = new AtomicBoolean();\n+        private final FileSystem delegateInstance;\n+        private final Path rootDir;\n+\n+        public FSyncTrackingFileSystemProvider(FileSystem delegate, Path rootDir) {\n+            super(\"fsynccounting://\", delegate);\n+            this.rootDir = new FilterPath(rootDir, this.fileSystem);\n+            this.delegateInstance = delegate;\n+        }\n+\n+        public FileSystem getDelegateInstance() {\n+            return delegateInstance;\n+        }\n+\n+        public void failFSyncs(boolean shouldFail) {\n+            failFSyncs.set(shouldFail);\n+        }\n+\n+        public Path resolve(String other) {\n+            return rootDir.resolve(other);\n+        }\n+\n+        @Nullable\n+        public Integer getNumberOfFSyncs(Path path) {\n+            final AtomicInteger counter = files.get(path);\n+            return counter != null ? counter.get() : null;\n+        }\n+\n+        @Override\n+        public FileChannel newFileChannel(Path path, Set<? extends OpenOption> options, FileAttribute<?>... attrs) throws IOException {\n+            final AtomicInteger counter = files.computeIfAbsent(path, p -> new AtomicInteger(0));\n+            return new FilterFileChannel(delegate.newFileChannel(toDelegate(path), options, attrs)) {\n+\n+                @Override\n+                public void force(boolean metaData) throws IOException {\n+                    if (failFSyncs.get()) {\n+                        throw new IOException(\"simulated\");\n+                    }\n+                    super.force(metaData);\n+                    counter.incrementAndGet();\n+                }\n+            };\n+        }\n+\n+        @Override\n+        public void delete(Path path) throws IOException {", "originalCommit": "082b76db40bd1076b57905433caff29247dc4859", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzY4Njg1Mw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r527686853", "bodyText": "That the tests work with this confused me for a while - but CacheFile uses deleteIfExists, which delegates to the original file system rather than going here.\n\nI agree this is confusing. This delete method is a left over from a previous version of a test that worked differently. I removed the method in e9721c4. I also noticed a subtility in the testFSyncOnEvictedFile() test where the file is not released until the test ends, preventing the file to be deleted from disk. I added some randomization there.", "author": "tlrx", "createdAt": "2020-11-20T13:23:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAxMDIwMg=="}], "type": "inlineReview"}, {"oid": "ea34570bfaf68a928b29187c32fa1f3686b85fd9", "url": "https://github.com/elastic/elasticsearch/commit/ea34570bfaf68a928b29187c32fa1f3686b85fd9", "message": "private", "committedDate": "2020-11-20T09:44:30Z", "type": "commit"}, {"oid": "54d051d8829b323fe7748daee37ac5ff5aefd170", "url": "https://github.com/elastic/elasticsearch/commit/54d051d8829b323fe7748daee37ac5ff5aefd170", "message": "provider.tearDown()", "committedDate": "2020-11-20T10:02:03Z", "type": "commit"}, {"oid": "e8ad9be817caba9d9f7ff4ea33d60ee56cfbae53", "url": "https://github.com/elastic/elasticsearch/commit/e8ad9be817caba9d9f7ff4ea33d60ee56cfbae53", "message": "randomPopulateAndReads", "committedDate": "2020-11-20T10:07:05Z", "type": "commit"}, {"oid": "6066924795a61fb689cf0b2740e17074019b5eeb", "url": "https://github.com/elastic/elasticsearch/commit/6066924795a61fb689cf0b2740e17074019b5eeb", "message": "set interval before start", "committedDate": "2020-11-20T10:08:50Z", "type": "commit"}, {"oid": "e9721c43b8c24cb74475e7ecbd1fb2e4f5feda38", "url": "https://github.com/elastic/elasticsearch/commit/e9721c43b8c24cb74475e7ecbd1fb2e4f5feda38", "message": "deleteIfExists", "committedDate": "2020-11-20T10:52:19Z", "type": "commit"}, {"oid": "bd1ce13f170c3482ea7d78a09f75857ce3b2bc46", "url": "https://github.com/elastic/elasticsearch/commit/bd1ce13f170c3482ea7d78a09f75857ce3b2bc46", "message": "lock & waitfor termination", "committedDate": "2020-11-20T13:16:31Z", "type": "commit"}, {"oid": "46adb3c4344e330a099a1642da31b25a668a5a34", "url": "https://github.com/elastic/elasticsearch/commit/46adb3c4344e330a099a1642da31b25a668a5a34", "message": "Merge branch 'master' into periodic-fsync", "committedDate": "2020-11-20T13:17:53Z", "type": "commit"}, {"oid": "04a4d77ed3762dd581bd8b6d57eaef88ef322af3", "url": "https://github.com/elastic/elasticsearch/commit/04a4d77ed3762dd581bd8b6d57eaef88ef322af3", "message": "missing close", "committedDate": "2020-11-20T13:24:36Z", "type": "commit"}, {"oid": "db24043323d0cd4ac10470d839ace3ea4293a7a5", "url": "https://github.com/elastic/elasticsearch/commit/db24043323d0cd4ac10470d839ace3ea4293a7a5", "message": "Merge branch 'master' into periodic-fsync", "committedDate": "2020-11-23T08:22:21Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU3MjQzMg==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r528572432", "bodyText": "Perhaps just 10 seconds default, since we only need to wait for one fsync and if it takes more than 10s to do one, we really want to continue shutting down the node anyway? The other doStop timeouts that I found (did not search thoroughly though) are in the 10-30s range.", "author": "henningandersen", "createdAt": "2020-11-23T09:39:26Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -73,28 +74,37 @@\n \n     public static final TimeValue MIN_SNAPSHOT_CACHE_SYNC_INTERVAL = TimeValue.timeValueSeconds(1L);\n     public static final Setting<TimeValue> SNAPSHOT_CACHE_SYNC_INTERVAL_SETTING = Setting.timeSetting(\n-        SETTINGS_PREFIX + \"sync_interval\",\n+        SETTINGS_PREFIX + \"sync.interval\",\n         TimeValue.timeValueSeconds(60L),                        // default\n         MIN_SNAPSHOT_CACHE_SYNC_INTERVAL,                       // min\n         Setting.Property.NodeScope,\n         Setting.Property.Dynamic\n     );\n \n     public static final Setting<Integer> SNAPSHOT_CACHE_MAX_FILES_TO_SYNC_AT_ONCE_SETTING = Setting.intSetting(\n-        SETTINGS_PREFIX + \"max_files_to_sync\",\n+        SETTINGS_PREFIX + \"sync.max_files\",\n         10_000,                                                 // default\n         0,                                                      // min\n-        Integer.MAX_VALUE,                                      // min\n+        Integer.MAX_VALUE,                                      // max\n         Setting.Property.NodeScope,\n         Setting.Property.Dynamic\n     );\n \n+    public static final Setting<TimeValue> SNAPSHOT_CACHE_SYNC_SHUTDOWN_TIMEOUT = Setting.timeSetting(\n+        SETTINGS_PREFIX + \"sync.shutdown_timeout\",\n+        TimeValue.timeValueSeconds(60L),                        // default", "originalCommit": "db24043323d0cd4ac10470d839ace3ea4293a7a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MTcwOQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r528591709", "bodyText": "Agreed.", "author": "tlrx", "createdAt": "2020-11-23T10:10:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU3MjQzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU3NTg0Nw==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r528575847", "bodyText": "I think we need to also do cacheSyncTask.close() and cache.invalidateAll() in this case? Possibly better to surround the tryLock with a separate try catch for InterruptedException.", "author": "henningandersen", "createdAt": "2020-11-23T09:44:51Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -144,8 +156,22 @@ protected void doStart() {\n \n     @Override\n     protected void doStop() {\n-        cacheSyncTask.close();\n-        cache.invalidateAll();\n+        boolean acquired = false;\n+        try {\n+            acquired = cacheSyncLock.tryLock(cacheSyncStopTimeout.duration(), cacheSyncStopTimeout.timeUnit());\n+            if (acquired == false) {\n+                logger.warn(\"failed to acquire cache sync lock in [{}], cache might be partially persisted\", cacheSyncStopTimeout);\n+            }\n+            cacheSyncTask.close();\n+            cache.invalidateAll();\n+        } catch (InterruptedException e) {\n+            Thread.currentThread().interrupt();\n+            logger.warn(\"interrupted while waiting for cache sync lock\", e);", "originalCommit": "db24043323d0cd4ac10470d839ace3ea4293a7a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MTU5MA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r528591590", "bodyText": "Oh right, I'll surround the tryLock", "author": "tlrx", "createdAt": "2020-11-23T10:10:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU3NTg0Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU3NjgwNA==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r528576804", "bodyText": "I would prefer to keep this inside the loop to ensure we break out as soon as possible when shutting down.", "author": "henningandersen", "createdAt": "2020-11-23T09:46:27Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/cache/CacheService.java", "diffHunk": "@@ -251,51 +277,62 @@ boolean isCacheFileToSync(CacheFile cacheFile) {\n      * non empty set of completed ranges this method also fsync the shard's snapshot cache directory, which is the parent directory of the\n      * cache entry. Note that cache files might be evicted during the synchronization.\n      */\n-    protected synchronized void synchronizeCache() {\n-        long count = 0L;\n-        final Set<Path> cacheDirs = new HashSet<>();\n-        final long startTimeNanos = threadPool.relativeTimeInNanos();\n-        final long maxCacheFilesToSync = Math.min(numberOfCacheFilesToSync.get(), this.maxCacheFilesToSyncAtOnce);\n-        for (long i = 0L; i < maxCacheFilesToSync; i++) {\n+    protected void synchronizeCache() {\n+        cacheSyncLock.lock();\n+        try {\n             if (lifecycleState() != Lifecycle.State.STARTED) {", "originalCommit": "db24043323d0cd4ac10470d839ace3ea4293a7a5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU5MTM3MQ==", "url": "https://github.com/elastic/elasticsearch/pull/64696#discussion_r528591371", "bodyText": "Ok", "author": "tlrx", "createdAt": "2020-11-23T10:09:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODU3NjgwNA=="}], "type": "inlineReview"}, {"oid": "10216ea40af97363b47646ffe3bcadb384f0fbde", "url": "https://github.com/elastic/elasticsearch/commit/10216ea40af97363b47646ffe3bcadb384f0fbde", "message": "nits", "committedDate": "2020-11-23T10:16:10Z", "type": "commit"}]}