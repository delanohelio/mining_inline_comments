{"pr_number": 59563, "pr_title": "Support ignore_keywords flag for word delimiter graph token filter", "pr_createdAt": "2020-07-14T19:37:29Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/59563", "timeline": [{"oid": "751dd13d215be4d1aa78944a08507ed3a00ba213", "url": "https://github.com/elastic/elasticsearch/commit/751dd13d215be4d1aa78944a08507ed3a00ba213", "message": "Add support for ignore_keywords flag in word delimiter graph token filter\n\nSupport ignore_keywords flag for word delimiter graph token filter\n\nLucene's WordDelimiterGraphFilter allows to skip processing of tokens tagged as keyword. However the Elasticsearch word delimiter graph token filter does not support this yet. I would like to update the Elasticsearch implementation to incorporate the ignore_keywords flag to enable better customization of token filters\n\nFix for https://github.com/elastic/elasticsearch/issues/59491", "committedDate": "2020-07-14T19:13:41Z", "type": "commit"}, {"oid": "751dd13d215be4d1aa78944a08507ed3a00ba213", "url": "https://github.com/elastic/elasticsearch/commit/751dd13d215be4d1aa78944a08507ed3a00ba213", "message": "Add support for ignore_keywords flag in word delimiter graph token filter\n\nSupport ignore_keywords flag for word delimiter graph token filter\n\nLucene's WordDelimiterGraphFilter allows to skip processing of tokens tagged as keyword. However the Elasticsearch word delimiter graph token filter does not support this yet. I would like to update the Elasticsearch implementation to incorporate the ignore_keywords flag to enable better customization of token filters\n\nFix for https://github.com/elastic/elasticsearch/issues/59491", "committedDate": "2020-07-14T19:13:41Z", "type": "forcePushed"}, {"oid": "5d04ff937c104525bd1066624ecd6c5bd52e6096", "url": "https://github.com/elastic/elasticsearch/commit/5d04ff937c104525bd1066624ecd6c5bd52e6096", "message": "Merge remote-tracking branch 'upstream/master'", "committedDate": "2020-07-19T07:11:56Z", "type": "commit"}, {"oid": "1a66b001266a7cb5f92917caf278132c61175811", "url": "https://github.com/elastic/elasticsearch/commit/1a66b001266a7cb5f92917caf278132c61175811", "message": "Update docs for the ignore_keywords attribute", "committedDate": "2020-07-19T07:15:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzM0NDU2MA==", "url": "https://github.com/elastic/elasticsearch/pull/59563#discussion_r457344560", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If `true`, the filter suppresses processing tokens with\n          \n          \n            \n            {lucene-core-javadoc}/org/apache/lucene/analysis/tokenattributes/KeywordAttribute.html#isKeyword()[KeywordAttribute.isKeyword()=true]\n          \n          \n            \n            If `true`, the filter skips tokens with\n          \n          \n            \n            a `keyword` attribute of `true`.", "author": "jrodewig", "createdAt": "2020-07-20T12:39:04Z", "path": "docs/reference/analysis/tokenfilters/word-delimiter-graph-tokenfilter.asciidoc", "diffHunk": "@@ -270,6 +270,12 @@ If `true`, the filter includes tokens consisting of only alphabetical characters\n in the output. If `false`, the filter excludes these tokens from the output.\n Defaults to `true`.\n \n+`ignore_keywords`::\n+(Optional, boolean)\n+If `true`, the filter suppresses processing tokens with\n+{lucene-core-javadoc}/org/apache/lucene/analysis/tokenattributes/KeywordAttribute.html#isKeyword()[KeywordAttribute.isKeyword()=true]", "originalCommit": "1a66b001266a7cb5f92917caf278132c61175811", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "4ad08cbfb44ef37d6d482f75e7e4f9e546d70937", "url": "https://github.com/elastic/elasticsearch/commit/4ad08cbfb44ef37d6d482f75e7e4f9e546d70937", "message": "Update docs/reference/analysis/tokenfilters/word-delimiter-graph-tokenfilter.asciidoc", "committedDate": "2020-07-20T12:39:35Z", "type": "commit"}]}