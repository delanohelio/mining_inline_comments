{"pr_number": 57699, "pr_title": "[DOCS] Reformat `pattern_replace` token filter", "pr_createdAt": "2020-06-04T20:44:04Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/57699", "timeline": [{"oid": "fcb119732ae274895b0dba73f4157b395a2dca17", "url": "https://github.com/elastic/elasticsearch/commit/fcb119732ae274895b0dba73f4157b395a2dca17", "message": "[DOCS] Reformat `pattern_replace` tokenfilter\n\nChanges:\n\n* Rewrites description and adds Lucene link\n* Adds analyze example\n* Adds parameter definitions\n* Adds custom analyzer example", "committedDate": "2020-06-04T20:39:57Z", "type": "commit"}, {"oid": "9ad2255136a5a3a02fa3458bd25eacad41142428", "url": "https://github.com/elastic/elasticsearch/commit/9ad2255136a5a3a02fa3458bd25eacad41142428", "message": "reword", "committedDate": "2020-06-04T20:47:05Z", "type": "commit"}, {"oid": "fce749ba65f4398999cd8e3034f5481aebb4bf0d", "url": "https://github.com/elastic/elasticsearch/commit/fce749ba65f4398999cd8e3034f5481aebb4bf0d", "message": "reword", "committedDate": "2020-06-04T20:47:38Z", "type": "commit"}, {"oid": "69d6e166267cb0dbe8d3984c5dd21645b5092c66", "url": "https://github.com/elastic/elasticsearch/commit/69d6e166267cb0dbe8d3984c5dd21645b5092c66", "message": "fix snippet", "committedDate": "2020-06-04T20:51:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU1ODI0Nw==", "url": "https://github.com/elastic/elasticsearch/pull/57699#discussion_r436558247", "bodyText": "I did not know \\\\p{Sc} was a thing so thanks for educating me :)\nWhile these more esoteric functions work in token filters they are not supported in RegExp query syntax.\nI wonder if it's worth doing one of two things here:\nA) Add a footnote to the effect of \"* note this particular expression wouldn't work with RegExp queries which use a different regex parser\" or\nB) Use a different example that works in both \"pattern_replace\" token filters and RegExp queries.", "author": "markharwood", "createdAt": "2020-06-08T09:12:10Z", "path": "docs/reference/analysis/tokenfilters/pattern_replace-tokenfilter.asciidoc", "diffHunk": "@@ -4,23 +4,157 @@\n <titleabbrev>Pattern replace</titleabbrev>\n ++++\n \n-The `pattern_replace` token filter allows to easily handle string\n-replacements based on a regular expression. The regular expression is\n-defined using the `pattern` parameter, and the replacement string can be\n-provided using the `replacement` parameter (supporting referencing the\n-original text, as explained\n-http://docs.oracle.com/javase/6/docs/api/java/util/regex/Matcher.html#appendReplacement(java.lang.StringBuffer,%20java.lang.String)[here]).\n+Uses a regular expression to match and replace token substrings.\n+\n+The `pattern_replace` filter uses\n+http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html[Java's\n+regular expression syntax]. By default, the filter replaces matching\n+substrings with an empty substring (`\"\"`).\n+\n+Regular expressions cannot be anchored to the\n+beginning or end of a token. Replacement substrings can use Java's\n+https://docs.oracle.com/javase/8/docs/api/java/util/regex/Matcher.html#appendReplacement-java.lang.StringBuffer-java.lang.String-[`$g` syntax] to reference capture groups\n+from the original token text.\n \n [WARNING]\n-.Beware of Pathological Regular Expressions\n-========================================\n+====\n+A poorly-written regular expression may run slowly or return a\n+StackOverflowError, causing the node running the expression to exit suddenly.\n+\n+Read more about\n+http://www.regular-expressions.info/catastrophic.html[pathological regular\n+expressions and how to avoid them].\n+====\n+\n+This filter uses Lucene's\n+{lucene-analysis-docs}/pattern/PatternReplaceFilter.html[PatternReplaceFilter].\n+\n+[[analysis-pattern-replace-tokenfilter-analyze-ex]]\n+==== Example\n+\n+The following <<indices-analyze,analyze API>> request uses the `pattern_replace`\n+filter to prepend `watch` to the substring `dog` in `foxes jump lazy dogs`.\n+\n+[source,console]\n+----\n+GET /_analyze\n+{\n+  \"tokenizer\": \"whitespace\",\n+  \"filter\": [\n+    {\n+      \"type\": \"pattern_replace\",\n+      \"pattern\": \"(dog)\",\n+      \"replacement\": \"watch$1\"\n+    }\n+  ],\n+  \"text\": \"foxes jump lazy dogs\"\n+}\n+----\n+\n+The filter produces the following tokens.\n+\n+[source,text]\n+----\n+[ foxes, jump, lazy, watchdogs ]\n+----\n+\n+////\n+[source,console-result]\n+----\n+{\n+  \"tokens\": [\n+    {\n+      \"token\": \"foxes\",\n+      \"start_offset\": 0,\n+      \"end_offset\": 5,\n+      \"type\": \"word\",\n+      \"position\": 0\n+    },\n+    {\n+      \"token\": \"jump\",\n+      \"start_offset\": 6,\n+      \"end_offset\": 10,\n+      \"type\": \"word\",\n+      \"position\": 1\n+    },\n+    {\n+      \"token\": \"lazy\",\n+      \"start_offset\": 11,\n+      \"end_offset\": 15,\n+      \"type\": \"word\",\n+      \"position\": 2\n+    },\n+    {\n+      \"token\": \"watchdogs\",\n+      \"start_offset\": 16,\n+      \"end_offset\": 20,\n+      \"type\": \"word\",\n+      \"position\": 3\n+    }\n+  ]\n+}\n+----\n+////\n+\n+[[analysis-pattern-replace-tokenfilter-configure-parms]]\n+==== Configurable parameters\n+\n+`all`::\n+(Optional, boolean)\n+If `true`, all substrings matching the `pattern` parameter's regular expression\n+are replaced. If `false`, the filter replaces only the first matching substring\n+in each token. Defaults to `true`.\n+\n+`pattern`::\n+(Required, string)\n+Regular expression, written in\n+http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html[Java's\n+regular expression syntax]. The filter replaces token substrings matching this\n+pattern with the substring in the `replacement` parameter.\n+\n+`replacement`::\n+(Optional, string)\n+Replacement substring. Defaults to an empty substring (`\"\"`).\n+\n+[[analysis-pattern-replace-tokenfilter-customize]]\n+==== Customize and add to an analyzer\n \n-The pattern replace token filter uses\n-http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html[Java Regular Expressions].\n+To customize the `pattern_replace` filter, duplicate it to create the basis\n+for a new custom token filter. You can modify the filter using its configurable\n+parameters.\n \n-A badly written regular expression could run very slowly or even throw a\n-StackOverflowError and cause the node it is running on to exit suddenly.\n+The following <<indices-create-index,create index API>> request\n+configures a new <<analysis-custom-analyzer,custom analyzer>> using a custom\n+`pattern_replace` filter, `my_pattern_replace_filter`.\n \n-Read more about http://www.regular-expressions.info/catastrophic.html[pathological regular expressions and how to avoid them].\n+The `my_pattern_replace_filter` filter uses the regular expression `\\\\p{Sc}` to\n+match and remove currency symbols, such as `\u00a3`, `\u20ac`, or `$`. The filter's `all`\n+parameter is `false`, meaning only the first matching symbol in each token is\n+removed.", "originalCommit": "69d6e166267cb0dbe8d3984c5dd21645b5092c66", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjY4Njc5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/57699#discussion_r436686791", "bodyText": "Thanks @markharwood. With 992ab1c, I updated the example to use a pattern that compatible with the RegExp query.", "author": "jrodewig", "createdAt": "2020-06-08T13:13:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjU1ODI0Nw=="}], "type": "inlineReview"}, {"oid": "992ab1cd8e45811044b176d58a6cf4e1910ae4a7", "url": "https://github.com/elastic/elasticsearch/commit/992ab1cd8e45811044b176d58a6cf4e1910ae4a7", "message": "update custom analyzer ex", "committedDate": "2020-06-08T13:11:49Z", "type": "commit"}]}