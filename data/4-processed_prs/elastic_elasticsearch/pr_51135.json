{"pr_number": 51135, "pr_title": "Update quantiles document in the index the document belongs to", "pr_createdAt": "2020-01-17T07:19:47Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/51135", "timeline": [{"oid": "df60ecad398de88bd4e461fac1843d203fe0c6b2", "url": "https://github.com/elastic/elasticsearch/commit/df60ecad398de88bd4e461fac1843d203fe0c6b2", "message": "Use OriginSettingClient instead of Client", "committedDate": "2020-01-17T13:05:13Z", "type": "forcePushed"}, {"oid": "86d284b16bf180d1d16711083489a9590bc33e58", "url": "https://github.com/elastic/elasticsearch/commit/86d284b16bf180d1d16711083489a9590bc33e58", "message": "Use OriginSettingClient instead of Client", "committedDate": "2020-01-21T11:09:49Z", "type": "forcePushed"}, {"oid": "c2505cf660ca7b7f81ad8c36cbb1447d84b01fbd", "url": "https://github.com/elastic/elasticsearch/commit/c2505cf660ca7b7f81ad8c36cbb1447d84b01fbd", "message": "Use OriginSettingClient instead of Client", "committedDate": "2020-01-21T11:10:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTU0MzQxOA==", "url": "https://github.com/elastic/elasticsearch/pull/51135#discussion_r369543418", "bodyText": "Minor optimizations (not super necessary).\nI am not 100% if the IdsQueryBuilder automatically is wrapped in a filter or not.\nBut, we should do something so that the docs are not scored. Possibly wrap in a constant score query?\nAlso, trackTotalHits could be false", "author": "benwtrent", "createdAt": "2020-01-22T12:57:21Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/persistence/JobResultsPersister.java", "diffHunk": "@@ -255,17 +259,50 @@ public void persistCategoryDefinition(CategoryDefinition category, Supplier<Bool\n      * Persist the quantiles (blocking)\n      */\n     public void persistQuantiles(Quantiles quantiles, Supplier<Boolean> shouldRetry) {\n-        Persistable persistable = new Persistable(quantiles.getJobId(), quantiles, Quantiles.documentId(quantiles.getJobId()));\n-        persistable.persist(AnomalyDetectorsIndex.jobStateIndexWriteAlias(), shouldRetry);\n+        String quantilesDocId = Quantiles.documentId(quantiles.getJobId());\n+\n+        SearchRequest searchRequest =\n+            new SearchRequest(AnomalyDetectorsIndex.jobStateIndexPattern())\n+                .source(new SearchSourceBuilder().size(1).query(new IdsQueryBuilder().addIds(quantilesDocId)));\n+        SearchResponse searchResponse = client.search(searchRequest).actionGet();\n+        String indexOrAlias = AnomalyDetectorsIndex.jobStateIndexWriteAlias();\n+        if (searchResponse.getHits().getHits().length > 0) {\n+            indexOrAlias = searchResponse.getHits().getHits()[0].getIndex();\n+        }\n+\n+        Persistable persistable = new Persistable(indexOrAlias, quantiles.getJobId(), quantiles, quantilesDocId);\n+        persistable.persist(shouldRetry);\n     }\n \n     /**\n      * Persist the quantiles (async)\n      */\n     public void persistQuantiles(Quantiles quantiles, WriteRequest.RefreshPolicy refreshPolicy, ActionListener<IndexResponse> listener) {\n-        Persistable persistable = new Persistable(quantiles.getJobId(), quantiles, Quantiles.documentId(quantiles.getJobId()));\n-        persistable.setRefreshPolicy(refreshPolicy);\n-        persistable.persist(AnomalyDetectorsIndex.jobStateIndexWriteAlias(), listener);\n+        String quantilesDocId = Quantiles.documentId(quantiles.getJobId());\n+\n+        // Step 2: Create or update the quantiles document:\n+        //   - if the document did not exist, create the new one in the current write index\n+        //   - if the document did exist, update it in the index where it resides (not necessarily the current write index)\n+        ActionListener<SearchResponse> searchFormerQuantilesDocListener = ActionListener.wrap(\n+            searchResponse -> {\n+                String indexOrAlias = AnomalyDetectorsIndex.jobStateIndexWriteAlias();\n+                if (searchResponse.getHits().getHits().length > 0) {\n+                    indexOrAlias = searchResponse.getHits().getHits()[0].getIndex();\n+                }\n+\n+                Persistable persistable = new Persistable(indexOrAlias, quantiles.getJobId(), quantiles, quantilesDocId);\n+                persistable.setRefreshPolicy(refreshPolicy);\n+                persistable.persist(listener);\n+            },\n+            listener::onFailure\n+        );\n+\n+        // Step 1: Search for existing quantiles document in .ml-state*\n+        SearchRequest searchRequest =\n+            new SearchRequest(AnomalyDetectorsIndex.jobStateIndexPattern())\n+                .source(new SearchSourceBuilder().size(1).query(new IdsQueryBuilder().addIds(quantilesDocId)));", "originalCommit": "c2505cf660ca7b7f81ad8c36cbb1447d84b01fbd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5ODc3Mw==", "url": "https://github.com/elastic/elasticsearch/pull/51135#discussion_r370098773", "bodyText": "Done.\nI've wrapped the ids query in a bool filter clause.", "author": "przemekwitek", "createdAt": "2020-01-23T12:51:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTU0MzQxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTU0NTA3Ng==", "url": "https://github.com/elastic/elasticsearch/pull/51135#discussion_r369545076", "bodyText": "I am not 100% sure about this.\nThis means that if we fail to search for the ID, the job will be flagged as failed immediately and stop running.\nI wonder if we should do retries on the synchronous search as we do for the persistence?", "author": "benwtrent", "createdAt": "2020-01-22T13:01:06Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/job/persistence/JobResultsPersister.java", "diffHunk": "@@ -255,17 +259,50 @@ public void persistCategoryDefinition(CategoryDefinition category, Supplier<Bool\n      * Persist the quantiles (blocking)\n      */\n     public void persistQuantiles(Quantiles quantiles, Supplier<Boolean> shouldRetry) {\n-        Persistable persistable = new Persistable(quantiles.getJobId(), quantiles, Quantiles.documentId(quantiles.getJobId()));\n-        persistable.persist(AnomalyDetectorsIndex.jobStateIndexWriteAlias(), shouldRetry);\n+        String quantilesDocId = Quantiles.documentId(quantiles.getJobId());\n+\n+        SearchRequest searchRequest =\n+            new SearchRequest(AnomalyDetectorsIndex.jobStateIndexPattern())\n+                .source(new SearchSourceBuilder().size(1).query(new IdsQueryBuilder().addIds(quantilesDocId)));\n+        SearchResponse searchResponse = client.search(searchRequest).actionGet();", "originalCommit": "c2505cf660ca7b7f81ad8c36cbb1447d84b01fbd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA5ODkxMw==", "url": "https://github.com/elastic/elasticsearch/pull/51135#discussion_r370098913", "bodyText": "Done.", "author": "przemekwitek", "createdAt": "2020-01-23T12:51:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTU0NTA3Ng=="}], "type": "inlineReview"}, {"oid": "7be3b332e3e15e5707a5f617d93d780ae11735bb", "url": "https://github.com/elastic/elasticsearch/commit/7be3b332e3e15e5707a5f617d93d780ae11735bb", "message": "Update quantiles document in the index the document belongs to", "committedDate": "2020-01-23T08:25:13Z", "type": "commit"}, {"oid": "5649ee9aa8c80b1e0d4efa64df8be8c8fb135fbb", "url": "https://github.com/elastic/elasticsearch/commit/5649ee9aa8c80b1e0d4efa64df8be8c8fb135fbb", "message": "Use OriginSettingClient instead of Client", "committedDate": "2020-01-23T08:25:13Z", "type": "commit"}, {"oid": "6f09cac6138531978b6ccd2a51a28cdaa80a3de1", "url": "https://github.com/elastic/elasticsearch/commit/6f09cac6138531978b6ccd2a51a28cdaa80a3de1", "message": "Apply review comments", "committedDate": "2020-01-23T16:06:31Z", "type": "commit"}, {"oid": "6f09cac6138531978b6ccd2a51a28cdaa80a3de1", "url": "https://github.com/elastic/elasticsearch/commit/6f09cac6138531978b6ccd2a51a28cdaa80a3de1", "message": "Apply review comments", "committedDate": "2020-01-23T16:06:31Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI2Njg3Nw==", "url": "https://github.com/elastic/elasticsearch/pull/51135#discussion_r370266877", "bodyText": "I thought that client.search threw if the search request failed.", "author": "benwtrent", "createdAt": "2020-01-23T17:53:44Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/utils/persistence/ResultsPersisterService.java", "diffHunk": "@@ -85,29 +94,77 @@ public BulkResponse bulkIndexWithRetry(BulkRequest bulkRequest,\n                                            String jobId,\n                                            Supplier<Boolean> shouldRetry,\n                                            Consumer<String> msgHandler) {\n-        int currentMin = MIN_RETRY_SLEEP_MILLIS;\n-        int currentMax = MIN_RETRY_SLEEP_MILLIS;\n-        int currentAttempt = 0;\n-        BulkResponse bulkResponse = null;\n-        final Random random = Randomness.get();\n-        while(currentAttempt <= maxFailureRetries) {\n-            bulkResponse = bulkIndex(bulkRequest);\n+        RetryContext retryContext = new RetryContext(jobId, shouldRetry, msgHandler);\n+        while (true) {\n+            BulkResponse bulkResponse = client.bulk(bulkRequest).actionGet();\n             if (bulkResponse.hasFailures() == false) {\n                 return bulkResponse;\n             }\n+\n+            retryContext.nextIteration(\"index\", bulkResponse.buildFailureMessage());\n+\n+            // We should only retry the docs that failed.\n+            bulkRequest = buildNewRequestFromFailures(bulkRequest, bulkResponse);\n+        }\n+    }\n+\n+    public SearchResponse searchWithRetry(SearchRequest searchRequest,\n+                                          String jobId,\n+                                          Supplier<Boolean> shouldRetry,\n+                                          Consumer<String> msgHandler) {\n+        RetryContext retryContext = new RetryContext(jobId, shouldRetry, msgHandler);\n+        while (true) {\n+            SearchResponse searchResponse = client.search(searchRequest).actionGet();", "originalCommit": "6f09cac6138531978b6ccd2a51a28cdaa80a3de1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDUzMDYzNQ==", "url": "https://github.com/elastic/elasticsearch/pull/51135#discussion_r370530635", "bodyText": "Done (catching ElasticsearchException).", "author": "przemekwitek", "createdAt": "2020-01-24T09:06:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI2Njg3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI2ODE5OA==", "url": "https://github.com/elastic/elasticsearch/pull/51135#discussion_r370268198", "bodyText": "given the message above, the log line is [job_id] [job_id] seems redundant.", "author": "benwtrent", "createdAt": "2020-01-23T17:56:40Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/utils/persistence/ResultsPersisterService.java", "diffHunk": "@@ -85,29 +94,77 @@ public BulkResponse bulkIndexWithRetry(BulkRequest bulkRequest,\n                                            String jobId,\n                                            Supplier<Boolean> shouldRetry,\n                                            Consumer<String> msgHandler) {\n-        int currentMin = MIN_RETRY_SLEEP_MILLIS;\n-        int currentMax = MIN_RETRY_SLEEP_MILLIS;\n-        int currentAttempt = 0;\n-        BulkResponse bulkResponse = null;\n-        final Random random = Randomness.get();\n-        while(currentAttempt <= maxFailureRetries) {\n-            bulkResponse = bulkIndex(bulkRequest);\n+        RetryContext retryContext = new RetryContext(jobId, shouldRetry, msgHandler);\n+        while (true) {\n+            BulkResponse bulkResponse = client.bulk(bulkRequest).actionGet();\n             if (bulkResponse.hasFailures() == false) {\n                 return bulkResponse;\n             }\n+\n+            retryContext.nextIteration(\"index\", bulkResponse.buildFailureMessage());\n+\n+            // We should only retry the docs that failed.\n+            bulkRequest = buildNewRequestFromFailures(bulkRequest, bulkResponse);\n+        }\n+    }\n+\n+    public SearchResponse searchWithRetry(SearchRequest searchRequest,\n+                                          String jobId,\n+                                          Supplier<Boolean> shouldRetry,\n+                                          Consumer<String> msgHandler) {\n+        RetryContext retryContext = new RetryContext(jobId, shouldRetry, msgHandler);\n+        while (true) {\n+            SearchResponse searchResponse = client.search(searchRequest).actionGet();\n+            if (searchResponse.status().getStatus() == 200) {\n+                return searchResponse;\n+            }\n+\n+            retryContext.nextIteration(\"search\", searchResponse.status().toString());\n+        }\n+    }\n+\n+    /**\n+     * {@link RetryContext} object handles logic that is executed between consecutive retries of an action.\n+     *\n+     * Note that it does not execute the action itself.\n+     */\n+    private class RetryContext {\n+\n+        final String jobId;\n+        final Supplier<Boolean> shouldRetry;\n+        final Consumer<String> msgHandler;\n+        final Random random = Randomness.get();\n+\n+        int currentAttempt = 0;\n+        int currentMin = MIN_RETRY_SLEEP_MILLIS;\n+        int currentMax = MIN_RETRY_SLEEP_MILLIS;\n+\n+        RetryContext(String jobId, Supplier<Boolean> shouldRetry, Consumer<String> msgHandler) {\n+            this.jobId = jobId;\n+            this.shouldRetry = shouldRetry;\n+            this.msgHandler = msgHandler;\n+        }\n+\n+        void nextIteration(String actionName, String failureMessage) {\n+            currentAttempt++;\n+\n+            // If the outside conditions have changed and retries are no longer needed, do not retry.\n             if (shouldRetry.get() == false) {\n-                throw new ElasticsearchException(\"[{}] failed to index all results. {}\", jobId, bulkResponse.buildFailureMessage());\n+                String msg = new ParameterizedMessage(\n+                    \"[{}] should not retry {} after [{}] attempts. {}\", jobId, actionName, currentAttempt, failureMessage)\n+                    .getFormattedMessage();\n+                LOGGER.info(() -> new ParameterizedMessage(\"[{}] {}\", jobId, msg));", "originalCommit": "6f09cac6138531978b6ccd2a51a28cdaa80a3de1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ5ODI4Ng==", "url": "https://github.com/elastic/elasticsearch/pull/51135#discussion_r370498286", "bodyText": "Done.", "author": "przemekwitek", "createdAt": "2020-01-24T07:14:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI2ODE5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI2ODM3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/51135#discussion_r370268379", "bodyText": "given the message above, the log line is [job_id] [job_id] seems redundant.", "author": "benwtrent", "createdAt": "2020-01-23T17:57:02Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/utils/persistence/ResultsPersisterService.java", "diffHunk": "@@ -85,29 +94,77 @@ public BulkResponse bulkIndexWithRetry(BulkRequest bulkRequest,\n                                            String jobId,\n                                            Supplier<Boolean> shouldRetry,\n                                            Consumer<String> msgHandler) {\n-        int currentMin = MIN_RETRY_SLEEP_MILLIS;\n-        int currentMax = MIN_RETRY_SLEEP_MILLIS;\n-        int currentAttempt = 0;\n-        BulkResponse bulkResponse = null;\n-        final Random random = Randomness.get();\n-        while(currentAttempt <= maxFailureRetries) {\n-            bulkResponse = bulkIndex(bulkRequest);\n+        RetryContext retryContext = new RetryContext(jobId, shouldRetry, msgHandler);\n+        while (true) {\n+            BulkResponse bulkResponse = client.bulk(bulkRequest).actionGet();\n             if (bulkResponse.hasFailures() == false) {\n                 return bulkResponse;\n             }\n+\n+            retryContext.nextIteration(\"index\", bulkResponse.buildFailureMessage());\n+\n+            // We should only retry the docs that failed.\n+            bulkRequest = buildNewRequestFromFailures(bulkRequest, bulkResponse);\n+        }\n+    }\n+\n+    public SearchResponse searchWithRetry(SearchRequest searchRequest,\n+                                          String jobId,\n+                                          Supplier<Boolean> shouldRetry,\n+                                          Consumer<String> msgHandler) {\n+        RetryContext retryContext = new RetryContext(jobId, shouldRetry, msgHandler);\n+        while (true) {\n+            SearchResponse searchResponse = client.search(searchRequest).actionGet();\n+            if (searchResponse.status().getStatus() == 200) {\n+                return searchResponse;\n+            }\n+\n+            retryContext.nextIteration(\"search\", searchResponse.status().toString());\n+        }\n+    }\n+\n+    /**\n+     * {@link RetryContext} object handles logic that is executed between consecutive retries of an action.\n+     *\n+     * Note that it does not execute the action itself.\n+     */\n+    private class RetryContext {\n+\n+        final String jobId;\n+        final Supplier<Boolean> shouldRetry;\n+        final Consumer<String> msgHandler;\n+        final Random random = Randomness.get();\n+\n+        int currentAttempt = 0;\n+        int currentMin = MIN_RETRY_SLEEP_MILLIS;\n+        int currentMax = MIN_RETRY_SLEEP_MILLIS;\n+\n+        RetryContext(String jobId, Supplier<Boolean> shouldRetry, Consumer<String> msgHandler) {\n+            this.jobId = jobId;\n+            this.shouldRetry = shouldRetry;\n+            this.msgHandler = msgHandler;\n+        }\n+\n+        void nextIteration(String actionName, String failureMessage) {\n+            currentAttempt++;\n+\n+            // If the outside conditions have changed and retries are no longer needed, do not retry.\n             if (shouldRetry.get() == false) {\n-                throw new ElasticsearchException(\"[{}] failed to index all results. {}\", jobId, bulkResponse.buildFailureMessage());\n+                String msg = new ParameterizedMessage(\n+                    \"[{}] should not retry {} after [{}] attempts. {}\", jobId, actionName, currentAttempt, failureMessage)\n+                    .getFormattedMessage();\n+                LOGGER.info(() -> new ParameterizedMessage(\"[{}] {}\", jobId, msg));\n+                throw new ElasticsearchException(msg);\n             }\n+\n+            // If the configured maximum number of retries has been reached, do not retry.\n             if (currentAttempt > maxFailureRetries) {\n-                LOGGER.warn(\"[{}] failed to index after [{}] attempts. Setting [xpack.ml.persist_results_max_retries] was reduced\",\n-                    jobId,\n-                    currentAttempt);\n-                throw new ElasticsearchException(\"[{}] failed to index all results after [{}] attempts. {}\",\n-                    jobId,\n-                    currentAttempt,\n-                    bulkResponse.buildFailureMessage());\n+                String msg = new ParameterizedMessage(\n+                    \"[{}] failed to {} after [{}] attempts. {}\", jobId, actionName, currentAttempt, failureMessage).getFormattedMessage();\n+                LOGGER.warn(() -> new ParameterizedMessage(\"[{}] {}\", jobId, msg));", "originalCommit": "6f09cac6138531978b6ccd2a51a28cdaa80a3de1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDQ5ODMwNA==", "url": "https://github.com/elastic/elasticsearch/pull/51135#discussion_r370498304", "bodyText": "Done.", "author": "przemekwitek", "createdAt": "2020-01-24T07:14:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDI2ODM3OQ=="}], "type": "inlineReview"}, {"oid": "af96027c0491067eaad182d1c2f57488cc7ed3fb", "url": "https://github.com/elastic/elasticsearch/commit/af96027c0491067eaad182d1c2f57488cc7ed3fb", "message": "Apply more review comments", "committedDate": "2020-01-24T09:00:53Z", "type": "commit"}]}