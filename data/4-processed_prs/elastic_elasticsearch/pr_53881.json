{"pr_number": 53881, "pr_title": "[DOCS] Adds description of analysis_stats object and its properties to GET DFA stats API docs", "pr_createdAt": "2020-03-20T15:48:12Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/53881", "timeline": [{"oid": "da1a80215f48173afcae4eb92bd29c41d3dc9519", "url": "https://github.com/elastic/elasticsearch/commit/da1a80215f48173afcae4eb92bd29c41d3dc9519", "message": "[DOCS] Adds description of analysis_stats object and its properties to GET DFA stats API docs.", "committedDate": "2020-03-20T15:46:11Z", "type": "commit"}, {"oid": "842dc3520335580dc94517f4f3a8c1ea9ddc20bb", "url": "https://github.com/elastic/elasticsearch/commit/842dc3520335580dc94517f4f3a8c1ea9ddc20bb", "message": "[DOCS] Fixes typos.", "committedDate": "2020-03-23T12:35:22Z", "type": "commit"}, {"oid": "65317aae29d90268ae01270414ac60f238472eb8", "url": "https://github.com/elastic/elasticsearch/commit/65317aae29d90268ae01270414ac60f238472eb8", "message": "[DOCS] Adds hyperparameter related properties.", "committedDate": "2020-03-25T10:02:51Z", "type": "commit"}, {"oid": "c19884971f46b1d90c5996e76d5541835623f233", "url": "https://github.com/elastic/elasticsearch/commit/c19884971f46b1d90c5996e76d5541835623f233", "message": "[DOCS] Organizes content to collapsible sections.", "committedDate": "2020-03-26T14:18:19Z", "type": "commit"}, {"oid": "a7751b67dfb3844808e74787a8d1846d61cbd267", "url": "https://github.com/elastic/elasticsearch/commit/a7751b67dfb3844808e74787a8d1846d61cbd267", "message": "[DOCS] Adjusts indentation.", "committedDate": "2020-03-26T14:57:43Z", "type": "commit"}, {"oid": "b743b35f0e6703a8e7652880f7f1d88d625ec100", "url": "https://github.com/elastic/elasticsearch/commit/b743b35f0e6703a8e7652880f7f1d88d625ec100", "message": "[DOCS] Adds child attributes role.", "committedDate": "2020-03-27T08:46:24Z", "type": "commit"}, {"oid": "bc0936d95b3678e90186ec0e9c87785a8fd35fda", "url": "https://github.com/elastic/elasticsearch/commit/bc0936d95b3678e90186ec0e9c87785a8fd35fda", "message": "[DOCS] Adds role to analysis_stats.", "committedDate": "2020-03-27T08:58:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTMyNzQxOQ==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r399327419", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            [role=\"child_attributes\"]", "author": "szabosteve", "createdAt": "2020-03-27T14:59:39Z", "path": "docs/reference/ml/df-analytics/apis/get-dfanalytics-stats.asciidoc", "diffHunk": "@@ -35,7 +35,7 @@ privileges:\n   \n For more information, see <<security-privileges>> and <<built-in-roles>>.\n \n-\n+[role=\"child_attributes\"]", "originalCommit": "bc0936d95b3678e90186ec0e9c87785a8fd35fda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5989ef03e43655c8c1105f62c4bc3f68e34a6474", "url": "https://github.com/elastic/elasticsearch/commit/5989ef03e43655c8c1105f62c4bc3f68e34a6474", "message": "Update docs/reference/ml/df-analytics/apis/get-dfanalytics-stats.asciidoc", "committedDate": "2020-03-27T15:00:24Z", "type": "commit"}, {"oid": "bbcae4be77b580d72c110d1465deb2da3de99cda", "url": "https://github.com/elastic/elasticsearch/commit/bbcae4be77b580d72c110d1465deb2da3de99cda", "message": "[DOCS] Fixes markup.", "committedDate": "2020-03-27T15:07:25Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEwNTUyMg==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400105522", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            An object containing the hyperparameters of the {classanalysis}.\n          \n          \n            \n            An object containing the parameters of the {classanalysis}.\n          \n      \n    \n    \n  \n\nAlso the section is called \"hyperparameters\" not all of these parameters are estimated in a hyperparameter  optimization procedure. Hence, I would use the word \"parameters\" here.", "author": "valeriy42", "createdAt": "2020-03-30T11:03:24Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,357 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the hyperparameters of the {classanalysis}.", "originalCommit": "bbcae4be77b580d72c110d1465deb2da3de99cda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEwNjgwMw==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400106803", "bodyText": "Since eta can be specified explicitly in the request body, maybe you can cross-reference it here?", "author": "valeriy42", "createdAt": "2020-03-30T11:05:44Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,357 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the hyperparameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `accuracy` and `minimum_recall`.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.", "originalCommit": "bbcae4be77b580d72c110d1465deb2da3de99cda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDEwNzIyNQ==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400107225", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The maximum number of trees.\n          \n          \n            \n            The maximum number of trees in the forest.", "author": "valeriy42", "createdAt": "2020-03-30T11:06:39Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,357 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the hyperparameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `accuracy` and `minimum_recall`.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies with what rate to increase `eta` for every new tree added to the \n+forest. The rate of 1.0 does not change `eta`, the rate of 1.05 increases `eta` \n+by 5%.\n+\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the bayesian optimization procedure. \n+Maximum number of steps is determined as the number of undefined hyperparameters \n+times the maximum optimization rounds per hyperparameter.\n+\n+`max_trees`::::\n+(integer)\n+The maximum number of trees.", "originalCommit": "bbcae4be77b580d72c110d1465deb2da3de99cda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDExMDg3OA==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400110878", "bodyText": "After elastic/ml-cpp#1096 is through, it will be called alpha, it can be cross-referenced with analysis config.", "author": "valeriy42", "createdAt": "2020-03-30T11:13:35Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,357 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the hyperparameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `accuracy` and `minimum_recall`.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies with what rate to increase `eta` for every new tree added to the \n+forest. The rate of 1.0 does not change `eta`, the rate of 1.05 increases `eta` \n+by 5%.\n+\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the bayesian optimization procedure. \n+Maximum number of steps is determined as the number of undefined hyperparameters \n+times the maximum optimization rounds per hyperparameter.\n+\n+`max_trees`::::\n+(integer)\n+The maximum number of trees.\n+\n+`num_folds`::::\n+(integer)\n+Maximum number of folds for the cross-validation procedure.\n+\n+`num_splits_per_feature`::::\n+(integer)\n+Determines the maximum number of splits for every feature that can occur in a \n+decision tree when the tree is trained.\n+\n+`regularization_depth_penalty_multiplier`::::", "originalCommit": "bbcae4be77b580d72c110d1465deb2da3de99cda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDExMTI3NA==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400111274", "bodyText": "This parameter will be called gamma, the same as in the analysis config.", "author": "valeriy42", "createdAt": "2020-03-30T11:14:18Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,357 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the hyperparameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `accuracy` and `minimum_recall`.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies with what rate to increase `eta` for every new tree added to the \n+forest. The rate of 1.0 does not change `eta`, the rate of 1.05 increases `eta` \n+by 5%.\n+\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the bayesian optimization procedure. \n+Maximum number of steps is determined as the number of undefined hyperparameters \n+times the maximum optimization rounds per hyperparameter.\n+\n+`max_trees`::::\n+(integer)\n+The maximum number of trees.\n+\n+`num_folds`::::\n+(integer)\n+Maximum number of folds for the cross-validation procedure.\n+\n+`num_splits_per_feature`::::\n+(integer)\n+Determines the maximum number of splits for every feature that can occur in a \n+decision tree when the tree is trained.\n+\n+`regularization_depth_penalty_multiplier`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+\n+`regularization_leaf_weight_penalty_multiplier`::::\n+(double)\n+Regularization factor to penalize large leaf weights. This parameter is also \n+referred to as `lambda`.\n+\n+`regularization_soft_tree_depth_limit`::::\n+(double)\n+Tree depth limit is used for calculating the tree depth penalty. This is a soft \n+limit, it can be exceeded.\n+\n+`regularization_soft_tree_depth_tolerance`::::\n+(double)\n+Tree depth tolerance is used for calculating the tree depth penalty. This is a \n+soft limit, it can be exceeded.\n+\n+`regularization_tree_size_penalty_multiplier`::::", "originalCommit": "bbcae4be77b580d72c110d1465deb2da3de99cda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDExMTc1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400111759", "bodyText": "This guy will be simply called lambda", "author": "valeriy42", "createdAt": "2020-03-30T11:15:17Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,357 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the hyperparameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `accuracy` and `minimum_recall`.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies with what rate to increase `eta` for every new tree added to the \n+forest. The rate of 1.0 does not change `eta`, the rate of 1.05 increases `eta` \n+by 5%.\n+\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the bayesian optimization procedure. \n+Maximum number of steps is determined as the number of undefined hyperparameters \n+times the maximum optimization rounds per hyperparameter.\n+\n+`max_trees`::::\n+(integer)\n+The maximum number of trees.\n+\n+`num_folds`::::\n+(integer)\n+Maximum number of folds for the cross-validation procedure.\n+\n+`num_splits_per_feature`::::\n+(integer)\n+Determines the maximum number of splits for every feature that can occur in a \n+decision tree when the tree is trained.\n+\n+`regularization_depth_penalty_multiplier`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+\n+`regularization_leaf_weight_penalty_multiplier`::::", "originalCommit": "bbcae4be77b580d72c110d1465deb2da3de99cda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDExMjgzMw==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400112833", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            metric. Possible values are `accuracy` and `minimum_recall`.\n          \n          \n            \n            metric. Possible values are `maximize_accuracy` and `maximize_minimum_recall`.\n          \n      \n    \n    \n  \n\nSchema will be updated.", "author": "valeriy42", "createdAt": "2020-03-30T11:17:24Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,357 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the hyperparameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `accuracy` and `minimum_recall`.", "originalCommit": "bbcae4be77b580d72c110d1465deb2da3de99cda", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "79c45a28eb468f42874294b67e49bd4bfc8fe41a", "url": "https://github.com/elastic/elasticsearch/commit/79c45a28eb468f42874294b67e49bd4bfc8fe41a", "message": "Update docs/reference/ml/ml-shared.asciidoc\n\nCo-Authored-By: Valeriy Khakhutskyy <1292899+valeriy42@users.noreply.github.com>", "committedDate": "2020-03-30T11:33:41Z", "type": "commit"}, {"oid": "6ebe5529c7045f5ed588240530d3dd89e4e185df", "url": "https://github.com/elastic/elasticsearch/commit/6ebe5529c7045f5ed588240530d3dd89e4e185df", "message": "Apply suggestions from code review\n\nCo-Authored-By: Valeriy Khakhutskyy <1292899+valeriy42@users.noreply.github.com>", "committedDate": "2020-03-30T11:35:17Z", "type": "commit"}, {"oid": "f8b05e545b9621fd9b544e737fcbdc9067727da3", "url": "https://github.com/elastic/elasticsearch/commit/f8b05e545b9621fd9b544e737fcbdc9067727da3", "message": "[DOCS] Addresses feedback.", "committedDate": "2020-03-30T13:21:40Z", "type": "commit"}, {"oid": "d4471d50fd922b1e635ce497799ac16285d9a898", "url": "https://github.com/elastic/elasticsearch/commit/d4471d50fd922b1e635ce497799ac16285d9a898", "message": "[DOCS] Modifies the name of two properties.", "committedDate": "2020-03-30T15:04:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQwOTUzNg==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400409536", "bodyText": "Minor suggestion for clarity:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Specifies with what rate to increase `eta` for every new tree added to the \n          \n          \n            \n            Specifies the rate at which the `eta` increases for each new tree that is added to the", "author": "lcawl", "createdAt": "2020-03-30T18:37:08Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,355 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the parameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `maximize_accuracy` and `maximize_minimum_recall`.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies with what rate to increase `eta` for every new tree added to the ", "originalCommit": "d4471d50fd922b1e635ce497799ac16285d9a898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxMTAzOQ==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400411039", "bodyText": "I think you can likely simplify this as follows:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            forest. The rate of 1.0 does not change `eta`, the rate of 1.05 increases `eta` \n          \n          \n            \n            forest. For example, a rate of `1.05` increases `eta`", "author": "lcawl", "createdAt": "2020-03-30T18:39:41Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,355 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the parameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `maximize_accuracy` and `maximize_minimum_recall`.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies with what rate to increase `eta` for every new tree added to the \n+forest. The rate of 1.0 does not change `eta`, the rate of 1.05 increases `eta` ", "originalCommit": "d4471d50fd922b1e635ce497799ac16285d9a898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxMjI2Mg==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400412262", "bodyText": "I think this should be capitalized:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            hyperparameter optimization steps in the bayesian optimization procedure. \n          \n          \n            \n            hyperparameter optimization steps in the Bayesian optimization procedure.", "author": "lcawl", "createdAt": "2020-03-30T18:41:51Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,355 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the parameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `maximize_accuracy` and `maximize_minimum_recall`.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies with what rate to increase `eta` for every new tree added to the \n+forest. The rate of 1.0 does not change `eta`, the rate of 1.05 increases `eta` \n+by 5%.\n+\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+\n+`gamma`::::\n+(double)\n+Regularization factor to penalize trees with large numbers of nodes.\n+\n+`lambda`::::\n+(double)\n+Regularization factor to penalize large leaf weights.\n+\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the bayesian optimization procedure. ", "originalCommit": "d4471d50fd922b1e635ce497799ac16285d9a898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxMzQyNg==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400413426", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Maximum number of steps is determined as the number of undefined hyperparameters \n          \n          \n            \n            The maximum number of steps is determined based on the number of undefined hyperparameters", "author": "lcawl", "createdAt": "2020-03-30T18:43:51Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,355 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the parameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `maximize_accuracy` and `maximize_minimum_recall`.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies with what rate to increase `eta` for every new tree added to the \n+forest. The rate of 1.0 does not change `eta`, the rate of 1.05 increases `eta` \n+by 5%.\n+\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+\n+`gamma`::::\n+(double)\n+Regularization factor to penalize trees with large numbers of nodes.\n+\n+`lambda`::::\n+(double)\n+Regularization factor to penalize large leaf weights.\n+\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the bayesian optimization procedure. \n+Maximum number of steps is determined as the number of undefined hyperparameters ", "originalCommit": "d4471d50fd922b1e635ce497799ac16285d9a898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxNDExNA==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400414114", "bodyText": "Synching with definition above this one:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Maximum number of folds for the cross-validation procedure.\n          \n          \n            \n            The maximum number of folds for the cross-validation procedure.", "author": "lcawl", "createdAt": "2020-03-30T18:45:00Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,355 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the parameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `maximize_accuracy` and `maximize_minimum_recall`.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies with what rate to increase `eta` for every new tree added to the \n+forest. The rate of 1.0 does not change `eta`, the rate of 1.05 increases `eta` \n+by 5%.\n+\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+\n+`gamma`::::\n+(double)\n+Regularization factor to penalize trees with large numbers of nodes.\n+\n+`lambda`::::\n+(double)\n+Regularization factor to penalize large leaf weights.\n+\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the bayesian optimization procedure. \n+Maximum number of steps is determined as the number of undefined hyperparameters \n+times the maximum optimization rounds per hyperparameter.\n+\n+`max_trees`::::\n+(integer)\n+The maximum number of trees in the forest.\n+\n+`num_folds`::::\n+(integer)\n+Maximum number of folds for the cross-validation procedure.", "originalCommit": "d4471d50fd922b1e635ce497799ac16285d9a898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxNTMxOQ==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400415319", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            An object containing the paramters of the {reganalysis}.\n          \n          \n            \n            An object containing the parameters of the {reganalysis}.", "author": "lcawl", "createdAt": "2020-03-30T18:47:08Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,355 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the parameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `maximize_accuracy` and `maximize_minimum_recall`.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies with what rate to increase `eta` for every new tree added to the \n+forest. The rate of 1.0 does not change `eta`, the rate of 1.05 increases `eta` \n+by 5%.\n+\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+\n+`gamma`::::\n+(double)\n+Regularization factor to penalize trees with large numbers of nodes.\n+\n+`lambda`::::\n+(double)\n+Regularization factor to penalize large leaf weights.\n+\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the bayesian optimization procedure. \n+Maximum number of steps is determined as the number of undefined hyperparameters \n+times the maximum optimization rounds per hyperparameter.\n+\n+`max_trees`::::\n+(integer)\n+The maximum number of trees in the forest.\n+\n+`num_folds`::::\n+(integer)\n+Maximum number of folds for the cross-validation procedure.\n+\n+`num_splits_per_feature`::::\n+(integer)\n+Determines the maximum number of splits for every feature that can occur in a \n+decision tree when the tree is trained.\n+\n+`soft_tree_depth_limit`::::\n+(double)\n+Tree depth limit is used for calculating the tree depth penalty. This is a soft \n+limit, it can be exceeded.\n+\n+`soft_tree_depth_tolerance`::::\n+(double)\n+Tree depth tolerance is used for calculating the tree depth penalty. This is a \n+soft limit, it can be exceeded.\n+======\n+//End class_hyperparameters\n+\n+`iteration`::::\n+(integer)\n+The number of iterations on the {dfanalytics-job}.\n+\n+`timestamp`::::\n+(date)\n+The timestamp when the statistics returned in milliseconds since the epoch.\n+\n+//Begin class_timing_stats\n+`timing_stats`::::\n+(object)\n+An object containing time statistics about the {dfanalytics-job}.\n++\n+.Properties of `timing_stats`\n+[%collapsible%open]\n+======\n+`elapsed_time`::::\n+(integer)\n+Runtime of the {dfanalytics-job} in milliseconds.\n+\n+`iteration_time`::::\n+(integer)\n+Runtime of the {dfanalytics-job} since the last iteration in milliseconds.\n+======\n+//End class_timing_stats\n+\n+//Begin class_validation_loss\n+`validation_loss`::::\n+(object)\n+An object containing information about validation loss.\n++\n+.Properties of `validation_loss`\n+[%collapsible%open]\n+======\n+`loss_type`::::\n+(string)\n+The name of the loss metric. For example, `binomial_logistic`.\n+\n+`fold_values`::::\n+(array of strings)\n+Validation loss values for every added decision tree during the forest growing \n+procedure.\n+======\n+//End class_validation_loss\n+=====\n+//End classification_stats\n+\n+//Begin outlier_detection_stats\n+`outlier_detection_stats`:::\n+(object)\n+An object containing statistical data about the {oldetection} job.\n++\n+.Properties of `outlier_detection_stats`\n+[%collapsible%open]\n+=====\n+//Begin parameters\n+`parameters`::::\n+(object)\n+The list of job parameters specified by the user or determined by algorithmic \n+heuristics.\n++\n+.Properties of `parameters`\n+[%collapsible%open]\n+======\n+`compute_feature_influence`::::\n+(boolean)\n+If true, feature influence calculation is enabled.\n+\n+`feature_influence_threshold`::::\n+(double)\n+The minimum {olscore} that a document needs to have to calculate its feature \n+influence score.\n+\n+`method`::::\n+(string)\n+The method that {oldetection} uses. Possible values are `lof`, `ldof`, \n+`distance_kth_nn`, `distance_knn`, and `ensemble`.\n+\n+`n_neighbors`::::\n+(integer)\n+The value for how many nearest neighbors each method of {oldetection} uses to \n+calculate its outlier score.\n+\n+`outlier_fraction`::::\n+(double)\n+The proportion of the data set that is assumed to be outlying prior to \n+{oldetection}.\n+\n+`standardization_enabled`::::\n+(boolean)\n+If true, then the following operation is performed on the columns before \n+computing {olscores}: (x_i - mean(x_i)) / sd(x_i).\n+======\n+//End parameters\n+\n+`timestamp`::::\n+(date)\n+The timestamp when the statistics returned in milliseconds since the epoch.\n+\n+//Begin od_timing_stats\n+`timing_stats`::::\n+(object)\n+An object containing time statistics about the {dfanalytics-job}.\n++\n+.Property of `timing_stats`\n+[%collapsible%open]\n+======\n+`elapsed_time`::::\n+(integer)\n+Runtime of the {dfanalytics-job} in milliseconds.\n+======\n+//End od_timing_stats\n+=====\n+//End outlier_detection_stats\n+\n+//Begin regression_stats\n+`regression_stats`:::\n+(object)\n+An object containing statistical data about the {reganalysis}.\n++\n+.Properties of `regression_stats`\n+[%collapsible%open]\n+=====\n+//Begin reg_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the paramters of the {reganalysis}.", "originalCommit": "d4471d50fd922b1e635ce497799ac16285d9a898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxNjI1OA==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400416258", "bodyText": "Clarifying to match earlier similar definition:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Specifies with what rate to increase `eta` for every new tree added to the \n          \n          \n            \n            Specifies the rate at which the `eta` increases for every new tree that is added to the", "author": "lcawl", "createdAt": "2020-03-30T18:48:42Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,355 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the parameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `maximize_accuracy` and `maximize_minimum_recall`.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies with what rate to increase `eta` for every new tree added to the \n+forest. The rate of 1.0 does not change `eta`, the rate of 1.05 increases `eta` \n+by 5%.\n+\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+\n+`gamma`::::\n+(double)\n+Regularization factor to penalize trees with large numbers of nodes.\n+\n+`lambda`::::\n+(double)\n+Regularization factor to penalize large leaf weights.\n+\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the bayesian optimization procedure. \n+Maximum number of steps is determined as the number of undefined hyperparameters \n+times the maximum optimization rounds per hyperparameter.\n+\n+`max_trees`::::\n+(integer)\n+The maximum number of trees in the forest.\n+\n+`num_folds`::::\n+(integer)\n+Maximum number of folds for the cross-validation procedure.\n+\n+`num_splits_per_feature`::::\n+(integer)\n+Determines the maximum number of splits for every feature that can occur in a \n+decision tree when the tree is trained.\n+\n+`soft_tree_depth_limit`::::\n+(double)\n+Tree depth limit is used for calculating the tree depth penalty. This is a soft \n+limit, it can be exceeded.\n+\n+`soft_tree_depth_tolerance`::::\n+(double)\n+Tree depth tolerance is used for calculating the tree depth penalty. This is a \n+soft limit, it can be exceeded.\n+======\n+//End class_hyperparameters\n+\n+`iteration`::::\n+(integer)\n+The number of iterations on the {dfanalytics-job}.\n+\n+`timestamp`::::\n+(date)\n+The timestamp when the statistics returned in milliseconds since the epoch.\n+\n+//Begin class_timing_stats\n+`timing_stats`::::\n+(object)\n+An object containing time statistics about the {dfanalytics-job}.\n++\n+.Properties of `timing_stats`\n+[%collapsible%open]\n+======\n+`elapsed_time`::::\n+(integer)\n+Runtime of the {dfanalytics-job} in milliseconds.\n+\n+`iteration_time`::::\n+(integer)\n+Runtime of the {dfanalytics-job} since the last iteration in milliseconds.\n+======\n+//End class_timing_stats\n+\n+//Begin class_validation_loss\n+`validation_loss`::::\n+(object)\n+An object containing information about validation loss.\n++\n+.Properties of `validation_loss`\n+[%collapsible%open]\n+======\n+`loss_type`::::\n+(string)\n+The name of the loss metric. For example, `binomial_logistic`.\n+\n+`fold_values`::::\n+(array of strings)\n+Validation loss values for every added decision tree during the forest growing \n+procedure.\n+======\n+//End class_validation_loss\n+=====\n+//End classification_stats\n+\n+//Begin outlier_detection_stats\n+`outlier_detection_stats`:::\n+(object)\n+An object containing statistical data about the {oldetection} job.\n++\n+.Properties of `outlier_detection_stats`\n+[%collapsible%open]\n+=====\n+//Begin parameters\n+`parameters`::::\n+(object)\n+The list of job parameters specified by the user or determined by algorithmic \n+heuristics.\n++\n+.Properties of `parameters`\n+[%collapsible%open]\n+======\n+`compute_feature_influence`::::\n+(boolean)\n+If true, feature influence calculation is enabled.\n+\n+`feature_influence_threshold`::::\n+(double)\n+The minimum {olscore} that a document needs to have to calculate its feature \n+influence score.\n+\n+`method`::::\n+(string)\n+The method that {oldetection} uses. Possible values are `lof`, `ldof`, \n+`distance_kth_nn`, `distance_knn`, and `ensemble`.\n+\n+`n_neighbors`::::\n+(integer)\n+The value for how many nearest neighbors each method of {oldetection} uses to \n+calculate its outlier score.\n+\n+`outlier_fraction`::::\n+(double)\n+The proportion of the data set that is assumed to be outlying prior to \n+{oldetection}.\n+\n+`standardization_enabled`::::\n+(boolean)\n+If true, then the following operation is performed on the columns before \n+computing {olscores}: (x_i - mean(x_i)) / sd(x_i).\n+======\n+//End parameters\n+\n+`timestamp`::::\n+(date)\n+The timestamp when the statistics returned in milliseconds since the epoch.\n+\n+//Begin od_timing_stats\n+`timing_stats`::::\n+(object)\n+An object containing time statistics about the {dfanalytics-job}.\n++\n+.Property of `timing_stats`\n+[%collapsible%open]\n+======\n+`elapsed_time`::::\n+(integer)\n+Runtime of the {dfanalytics-job} in milliseconds.\n+======\n+//End od_timing_stats\n+=====\n+//End outlier_detection_stats\n+\n+//Begin regression_stats\n+`regression_stats`:::\n+(object)\n+An object containing statistical data about the {reganalysis}.\n++\n+.Properties of `regression_stats`\n+[%collapsible%open]\n+=====\n+//Begin reg_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the paramters of the {reganalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies with what rate to increase `eta` for every new tree added to the ", "originalCommit": "d4471d50fd922b1e635ce497799ac16285d9a898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxNzQxOQ==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400417419", "bodyText": "A multiplier responsible ...\n\nThis content seems to duplicate an earlier definition.  Can the content be re-used?", "author": "lcawl", "createdAt": "2020-03-30T18:50:35Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,355 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the parameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `maximize_accuracy` and `maximize_minimum_recall`.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies with what rate to increase `eta` for every new tree added to the \n+forest. The rate of 1.0 does not change `eta`, the rate of 1.05 increases `eta` \n+by 5%.\n+\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+\n+`gamma`::::\n+(double)\n+Regularization factor to penalize trees with large numbers of nodes.\n+\n+`lambda`::::\n+(double)\n+Regularization factor to penalize large leaf weights.\n+\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the bayesian optimization procedure. \n+Maximum number of steps is determined as the number of undefined hyperparameters \n+times the maximum optimization rounds per hyperparameter.\n+\n+`max_trees`::::\n+(integer)\n+The maximum number of trees in the forest.\n+\n+`num_folds`::::\n+(integer)\n+Maximum number of folds for the cross-validation procedure.\n+\n+`num_splits_per_feature`::::\n+(integer)\n+Determines the maximum number of splits for every feature that can occur in a \n+decision tree when the tree is trained.\n+\n+`soft_tree_depth_limit`::::\n+(double)\n+Tree depth limit is used for calculating the tree depth penalty. This is a soft \n+limit, it can be exceeded.\n+\n+`soft_tree_depth_tolerance`::::\n+(double)\n+Tree depth tolerance is used for calculating the tree depth penalty. This is a \n+soft limit, it can be exceeded.\n+======\n+//End class_hyperparameters\n+\n+`iteration`::::\n+(integer)\n+The number of iterations on the {dfanalytics-job}.\n+\n+`timestamp`::::\n+(date)\n+The timestamp when the statistics returned in milliseconds since the epoch.\n+\n+//Begin class_timing_stats\n+`timing_stats`::::\n+(object)\n+An object containing time statistics about the {dfanalytics-job}.\n++\n+.Properties of `timing_stats`\n+[%collapsible%open]\n+======\n+`elapsed_time`::::\n+(integer)\n+Runtime of the {dfanalytics-job} in milliseconds.\n+\n+`iteration_time`::::\n+(integer)\n+Runtime of the {dfanalytics-job} since the last iteration in milliseconds.\n+======\n+//End class_timing_stats\n+\n+//Begin class_validation_loss\n+`validation_loss`::::\n+(object)\n+An object containing information about validation loss.\n++\n+.Properties of `validation_loss`\n+[%collapsible%open]\n+======\n+`loss_type`::::\n+(string)\n+The name of the loss metric. For example, `binomial_logistic`.\n+\n+`fold_values`::::\n+(array of strings)\n+Validation loss values for every added decision tree during the forest growing \n+procedure.\n+======\n+//End class_validation_loss\n+=====\n+//End classification_stats\n+\n+//Begin outlier_detection_stats\n+`outlier_detection_stats`:::\n+(object)\n+An object containing statistical data about the {oldetection} job.\n++\n+.Properties of `outlier_detection_stats`\n+[%collapsible%open]\n+=====\n+//Begin parameters\n+`parameters`::::\n+(object)\n+The list of job parameters specified by the user or determined by algorithmic \n+heuristics.\n++\n+.Properties of `parameters`\n+[%collapsible%open]\n+======\n+`compute_feature_influence`::::\n+(boolean)\n+If true, feature influence calculation is enabled.\n+\n+`feature_influence_threshold`::::\n+(double)\n+The minimum {olscore} that a document needs to have to calculate its feature \n+influence score.\n+\n+`method`::::\n+(string)\n+The method that {oldetection} uses. Possible values are `lof`, `ldof`, \n+`distance_kth_nn`, `distance_knn`, and `ensemble`.\n+\n+`n_neighbors`::::\n+(integer)\n+The value for how many nearest neighbors each method of {oldetection} uses to \n+calculate its outlier score.\n+\n+`outlier_fraction`::::\n+(double)\n+The proportion of the data set that is assumed to be outlying prior to \n+{oldetection}.\n+\n+`standardization_enabled`::::\n+(boolean)\n+If true, then the following operation is performed on the columns before \n+computing {olscores}: (x_i - mean(x_i)) / sd(x_i).\n+======\n+//End parameters\n+\n+`timestamp`::::\n+(date)\n+The timestamp when the statistics returned in milliseconds since the epoch.\n+\n+//Begin od_timing_stats\n+`timing_stats`::::\n+(object)\n+An object containing time statistics about the {dfanalytics-job}.\n++\n+.Property of `timing_stats`\n+[%collapsible%open]\n+======\n+`elapsed_time`::::\n+(integer)\n+Runtime of the {dfanalytics-job} in milliseconds.\n+======\n+//End od_timing_stats\n+=====\n+//End outlier_detection_stats\n+\n+//Begin regression_stats\n+`regression_stats`:::\n+(object)\n+An object containing statistical data about the {reganalysis}.\n++\n+.Properties of `regression_stats`\n+[%collapsible%open]\n+=====\n+//Begin reg_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the paramters of the {reganalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies with what rate to increase `eta` for every new tree added to the \n+forest. The rate of 1.0 does not change `eta`, the rate of 1.05 increases `eta` \n+by 5%.\n+\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+\n+`gamma`::::\n+(double)\n+Regularization factor to penalize trees with large numbers of nodes.\n+\n+`lambda`::::\n+(double)\n+Regularization factor to penalize large leaf weights.\n+\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of ", "originalCommit": "d4471d50fd922b1e635ce497799ac16285d9a898", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc2OTkzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400769931", "bodyText": "@lcawl Yes, it can be. I single-sourced all the possible shared properties in a7bec16.", "author": "szabosteve", "createdAt": "2020-03-31T09:29:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQxNzQxOQ=="}], "type": "inlineReview"}, {"oid": "7281a69776182cfc3581af07572c549841167187", "url": "https://github.com/elastic/elasticsearch/commit/7281a69776182cfc3581af07572c549841167187", "message": "Apply suggestions from code review\n\nCo-Authored-By: Lisa Cawley <lcawley@elastic.co>", "committedDate": "2020-03-31T06:11:55Z", "type": "commit"}, {"oid": "a7bec16545e994f52234222a7304327e960024cc", "url": "https://github.com/elastic/elasticsearch/commit/a7bec16545e994f52234222a7304327e960024cc", "message": "[DOCS] Single-sources shared parameters.", "committedDate": "2020-03-31T09:27:52Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc3NTM0MQ==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400775341", "bodyText": "I wonder if we could substitue returned with a more suitable verb here. Perhaps ... when the statistics were reported?", "author": "dimitris-athanasiou", "createdAt": "2020-03-31T09:37:52Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,335 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the parameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+tag::dfas-alpha[]\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+end::dfas-alpha[]\n+\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `maximize_accuracy` and `maximize_minimum_recall`.\n+\n+tag::dfas-downsample-factor[]\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+end::dfas-downsample-factor[]\n+\n+tag::dfas-eta[]\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+end::dfas-eta[]\n+\n+tag::dfas-eta-growth[]\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies the rate at which the `eta` increases for each new tree that is added to the \n+forest. For example, a rate of `1.05` increases `eta` by 5%.\n+end::dfas-eta-growth[]\n+\n+tag::dfas-feature-bag-fraction[]\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+end::dfas-feature-bag-fraction[]\n+\n+tag::dfas-gamma[]\n+`gamma`::::\n+(double)\n+Regularization factor to penalize trees with large numbers of nodes.\n+end::dfas-gamma[]\n+\n+tag::dfas-lambda[]\n+`lambda`::::\n+(double)\n+Regularization factor to penalize large leaf weights.\n+end::dfas-lambda[]\n+\n+tag::dfas-max-attempts[]\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+end::dfas-max-attempts[]\n+\n+tag::dfas-max-optimization-rounds[]\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the Bayesian optimization procedure. \n+The maximum number of steps is determined based on the number of undefined hyperparameters \n+times the maximum optimization rounds per hyperparameter.\n+end::dfas-max-optimization-rounds[]\n+\n+tag::dfas-max-trees[]\n+`max_trees`::::\n+(integer)\n+The maximum number of trees in the forest.\n+end::dfas-max-trees[]\n+\n+tag::dfas-num-folds[]\n+`num_folds`::::\n+(integer)\n+The maximum number of folds for the cross-validation procedure.\n+end::dfas-num-folds[]\n+\n+tag::dfas-num-splits[]\n+`num_splits_per_feature`::::\n+(integer)\n+Determines the maximum number of splits for every feature that can occur in a \n+decision tree when the tree is trained.\n+end::dfas-num-splits[]\n+\n+tag::dfas-soft-limit[]\n+`soft_tree_depth_limit`::::\n+(double)\n+Tree depth limit is used for calculating the tree depth penalty. This is a soft \n+limit, it can be exceeded.\n+end::dfas-soft-limit[]\n+\n+tag::dfas-soft-tolerance[]\n+`soft_tree_depth_tolerance`::::\n+(double)\n+Tree depth tolerance is used for calculating the tree depth penalty. This is a \n+soft limit, it can be exceeded.\n+end::dfas-soft-tolerance[]\n+======\n+//End class_hyperparameters\n+\n+tag::dfas-iteration[]\n+`iteration`::::\n+(integer)\n+The number of iterations on the {dfanalytics-job}.\n+end::dfas-iteration[]\n+\n+tag::dfas-timestamp[]\n+`timestamp`::::\n+(date)\n+The timestamp when the statistics returned in milliseconds since the epoch.", "originalCommit": "a7bec16545e994f52234222a7304327e960024cc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc3NjgyNg==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400776826", "bodyText": "I would rather say here \"number of iterations in the classification analysis\" instead of the DFA job, as iterations is not a concept that is relevant for all analyses.", "author": "dimitris-athanasiou", "createdAt": "2020-03-31T09:40:13Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,335 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the parameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+tag::dfas-alpha[]\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+end::dfas-alpha[]\n+\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `maximize_accuracy` and `maximize_minimum_recall`.\n+\n+tag::dfas-downsample-factor[]\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+end::dfas-downsample-factor[]\n+\n+tag::dfas-eta[]\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+end::dfas-eta[]\n+\n+tag::dfas-eta-growth[]\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies the rate at which the `eta` increases for each new tree that is added to the \n+forest. For example, a rate of `1.05` increases `eta` by 5%.\n+end::dfas-eta-growth[]\n+\n+tag::dfas-feature-bag-fraction[]\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+end::dfas-feature-bag-fraction[]\n+\n+tag::dfas-gamma[]\n+`gamma`::::\n+(double)\n+Regularization factor to penalize trees with large numbers of nodes.\n+end::dfas-gamma[]\n+\n+tag::dfas-lambda[]\n+`lambda`::::\n+(double)\n+Regularization factor to penalize large leaf weights.\n+end::dfas-lambda[]\n+\n+tag::dfas-max-attempts[]\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+end::dfas-max-attempts[]\n+\n+tag::dfas-max-optimization-rounds[]\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the Bayesian optimization procedure. \n+The maximum number of steps is determined based on the number of undefined hyperparameters \n+times the maximum optimization rounds per hyperparameter.\n+end::dfas-max-optimization-rounds[]\n+\n+tag::dfas-max-trees[]\n+`max_trees`::::\n+(integer)\n+The maximum number of trees in the forest.\n+end::dfas-max-trees[]\n+\n+tag::dfas-num-folds[]\n+`num_folds`::::\n+(integer)\n+The maximum number of folds for the cross-validation procedure.\n+end::dfas-num-folds[]\n+\n+tag::dfas-num-splits[]\n+`num_splits_per_feature`::::\n+(integer)\n+Determines the maximum number of splits for every feature that can occur in a \n+decision tree when the tree is trained.\n+end::dfas-num-splits[]\n+\n+tag::dfas-soft-limit[]\n+`soft_tree_depth_limit`::::\n+(double)\n+Tree depth limit is used for calculating the tree depth penalty. This is a soft \n+limit, it can be exceeded.\n+end::dfas-soft-limit[]\n+\n+tag::dfas-soft-tolerance[]\n+`soft_tree_depth_tolerance`::::\n+(double)\n+Tree depth tolerance is used for calculating the tree depth penalty. This is a \n+soft limit, it can be exceeded.\n+end::dfas-soft-tolerance[]\n+======\n+//End class_hyperparameters\n+\n+tag::dfas-iteration[]\n+`iteration`::::\n+(integer)\n+The number of iterations on the {dfanalytics-job}.", "originalCommit": "a7bec16545e994f52234222a7304327e960024cc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc3NzYwOQ==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400777609", "bodyText": "This should explain this is the runtime of the analysis itself, not the whole job's. Note the job involves other steps that take time (e.g. reindexing, etc.) that are not accounted for by this measurement.", "author": "dimitris-athanasiou", "createdAt": "2020-03-31T09:41:33Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,335 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the parameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+tag::dfas-alpha[]\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+end::dfas-alpha[]\n+\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `maximize_accuracy` and `maximize_minimum_recall`.\n+\n+tag::dfas-downsample-factor[]\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+end::dfas-downsample-factor[]\n+\n+tag::dfas-eta[]\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+end::dfas-eta[]\n+\n+tag::dfas-eta-growth[]\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies the rate at which the `eta` increases for each new tree that is added to the \n+forest. For example, a rate of `1.05` increases `eta` by 5%.\n+end::dfas-eta-growth[]\n+\n+tag::dfas-feature-bag-fraction[]\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+end::dfas-feature-bag-fraction[]\n+\n+tag::dfas-gamma[]\n+`gamma`::::\n+(double)\n+Regularization factor to penalize trees with large numbers of nodes.\n+end::dfas-gamma[]\n+\n+tag::dfas-lambda[]\n+`lambda`::::\n+(double)\n+Regularization factor to penalize large leaf weights.\n+end::dfas-lambda[]\n+\n+tag::dfas-max-attempts[]\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+end::dfas-max-attempts[]\n+\n+tag::dfas-max-optimization-rounds[]\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the Bayesian optimization procedure. \n+The maximum number of steps is determined based on the number of undefined hyperparameters \n+times the maximum optimization rounds per hyperparameter.\n+end::dfas-max-optimization-rounds[]\n+\n+tag::dfas-max-trees[]\n+`max_trees`::::\n+(integer)\n+The maximum number of trees in the forest.\n+end::dfas-max-trees[]\n+\n+tag::dfas-num-folds[]\n+`num_folds`::::\n+(integer)\n+The maximum number of folds for the cross-validation procedure.\n+end::dfas-num-folds[]\n+\n+tag::dfas-num-splits[]\n+`num_splits_per_feature`::::\n+(integer)\n+Determines the maximum number of splits for every feature that can occur in a \n+decision tree when the tree is trained.\n+end::dfas-num-splits[]\n+\n+tag::dfas-soft-limit[]\n+`soft_tree_depth_limit`::::\n+(double)\n+Tree depth limit is used for calculating the tree depth penalty. This is a soft \n+limit, it can be exceeded.\n+end::dfas-soft-limit[]\n+\n+tag::dfas-soft-tolerance[]\n+`soft_tree_depth_tolerance`::::\n+(double)\n+Tree depth tolerance is used for calculating the tree depth penalty. This is a \n+soft limit, it can be exceeded.\n+end::dfas-soft-tolerance[]\n+======\n+//End class_hyperparameters\n+\n+tag::dfas-iteration[]\n+`iteration`::::\n+(integer)\n+The number of iterations on the {dfanalytics-job}.\n+end::dfas-iteration[]\n+\n+tag::dfas-timestamp[]\n+`timestamp`::::\n+(date)\n+The timestamp when the statistics returned in milliseconds since the epoch.\n+end::dfas-timestamp[]\n+\n+//Begin class_timing_stats\n+tag::dfas-timing-stats[]\n+`timing_stats`::::\n+(object)\n+An object containing time statistics about the {dfanalytics-job}.\n+end::dfas-timing-stats[]\n++\n+.Properties of `timing_stats`\n+[%collapsible%open]\n+======\n+tag::dfas-timing-stats-elapsed[]\n+`elapsed_time`::::\n+(integer)\n+Runtime of the {dfanalytics-job} in milliseconds.", "originalCommit": "a7bec16545e994f52234222a7304327e960024cc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc3ODE5NQ==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400778195", "bodyText": "It might be simpler to explain this as \"Runtime of the latest iteration of the classification analysis in milliseconds\"", "author": "dimitris-athanasiou", "createdAt": "2020-03-31T09:42:26Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,335 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the parameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+tag::dfas-alpha[]\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+end::dfas-alpha[]\n+\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `maximize_accuracy` and `maximize_minimum_recall`.\n+\n+tag::dfas-downsample-factor[]\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+end::dfas-downsample-factor[]\n+\n+tag::dfas-eta[]\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+end::dfas-eta[]\n+\n+tag::dfas-eta-growth[]\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies the rate at which the `eta` increases for each new tree that is added to the \n+forest. For example, a rate of `1.05` increases `eta` by 5%.\n+end::dfas-eta-growth[]\n+\n+tag::dfas-feature-bag-fraction[]\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+end::dfas-feature-bag-fraction[]\n+\n+tag::dfas-gamma[]\n+`gamma`::::\n+(double)\n+Regularization factor to penalize trees with large numbers of nodes.\n+end::dfas-gamma[]\n+\n+tag::dfas-lambda[]\n+`lambda`::::\n+(double)\n+Regularization factor to penalize large leaf weights.\n+end::dfas-lambda[]\n+\n+tag::dfas-max-attempts[]\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+end::dfas-max-attempts[]\n+\n+tag::dfas-max-optimization-rounds[]\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the Bayesian optimization procedure. \n+The maximum number of steps is determined based on the number of undefined hyperparameters \n+times the maximum optimization rounds per hyperparameter.\n+end::dfas-max-optimization-rounds[]\n+\n+tag::dfas-max-trees[]\n+`max_trees`::::\n+(integer)\n+The maximum number of trees in the forest.\n+end::dfas-max-trees[]\n+\n+tag::dfas-num-folds[]\n+`num_folds`::::\n+(integer)\n+The maximum number of folds for the cross-validation procedure.\n+end::dfas-num-folds[]\n+\n+tag::dfas-num-splits[]\n+`num_splits_per_feature`::::\n+(integer)\n+Determines the maximum number of splits for every feature that can occur in a \n+decision tree when the tree is trained.\n+end::dfas-num-splits[]\n+\n+tag::dfas-soft-limit[]\n+`soft_tree_depth_limit`::::\n+(double)\n+Tree depth limit is used for calculating the tree depth penalty. This is a soft \n+limit, it can be exceeded.\n+end::dfas-soft-limit[]\n+\n+tag::dfas-soft-tolerance[]\n+`soft_tree_depth_tolerance`::::\n+(double)\n+Tree depth tolerance is used for calculating the tree depth penalty. This is a \n+soft limit, it can be exceeded.\n+end::dfas-soft-tolerance[]\n+======\n+//End class_hyperparameters\n+\n+tag::dfas-iteration[]\n+`iteration`::::\n+(integer)\n+The number of iterations on the {dfanalytics-job}.\n+end::dfas-iteration[]\n+\n+tag::dfas-timestamp[]\n+`timestamp`::::\n+(date)\n+The timestamp when the statistics returned in milliseconds since the epoch.\n+end::dfas-timestamp[]\n+\n+//Begin class_timing_stats\n+tag::dfas-timing-stats[]\n+`timing_stats`::::\n+(object)\n+An object containing time statistics about the {dfanalytics-job}.\n+end::dfas-timing-stats[]\n++\n+.Properties of `timing_stats`\n+[%collapsible%open]\n+======\n+tag::dfas-timing-stats-elapsed[]\n+`elapsed_time`::::\n+(integer)\n+Runtime of the {dfanalytics-job} in milliseconds.\n+end::dfas-timing-stats-elapsed[]\n+\n+tag::dfas-timing-stats-iteration[]\n+`iteration_time`::::\n+(integer)\n+Runtime of the {dfanalytics-job} since the last iteration in milliseconds.", "originalCommit": "a7bec16545e994f52234222a7304327e960024cc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc3ODUxMA==", "url": "https://github.com/elastic/elasticsearch/pull/53881#discussion_r400778510", "bodyText": "name -> type ?", "author": "dimitris-athanasiou", "createdAt": "2020-03-31T09:42:54Z", "path": "docs/reference/ml/ml-shared.asciidoc", "diffHunk": "@@ -507,6 +507,335 @@ tag::data-frame-analytics-stats[]\n An array of statistics objects for {dfanalytics-jobs}, which are\n sorted by the `id` value in ascending order.\n \n+//Begin analysis_stats\n+`analysis_stats`::\n+(object)\n+An object containing statistical data about the analysis.\n++\n+.Properties of `analysis_stats`\n+[%collapsible%open]\n+====\n+//Begin classification_stats\n+`classification_stats`:::\n+(object)\n+An object containing statistical data about the {classanalysis}.\n++\n+.Properties of `classification_stats`\n+[%collapsible%open]\n+=====\n+//Begin class_hyperparameters\n+`hyperparameters`::::\n+(object)\n+An object containing the parameters of the {classanalysis}.\n++\n+.Properties of `hyperparameters`\n+[%collapsible%open]\n+======\n+tag::dfas-alpha[]\n+`alpha`::::\n+(double)\n+Regularization factor to penalize deeper trees when training decision trees.\n+end::dfas-alpha[]\n+\n+`class_assignment_objective`::::\n+(string)\n+Defines whether class assignment maximizes the accuracy or the minimum recall \n+metric. Possible values are `maximize_accuracy` and `maximize_minimum_recall`.\n+\n+tag::dfas-downsample-factor[]\n+`downsample_factor`::::\n+(double)\n+The value of the downsample factor.\n+end::dfas-downsample-factor[]\n+\n+tag::dfas-eta[]\n+`eta`::::\n+(double)\n+The value of the eta hyperparameter.\n+end::dfas-eta[]\n+\n+tag::dfas-eta-growth[]\n+`eta_growth_rate_per_tree`::::\n+(double)\n+Specifies the rate at which the `eta` increases for each new tree that is added to the \n+forest. For example, a rate of `1.05` increases `eta` by 5%.\n+end::dfas-eta-growth[]\n+\n+tag::dfas-feature-bag-fraction[]\n+`feature_bag_fraction`::::\n+(double)\n+The fraction of features that is used when selecting a random bag for each \n+candidate split.\n+end::dfas-feature-bag-fraction[]\n+\n+tag::dfas-gamma[]\n+`gamma`::::\n+(double)\n+Regularization factor to penalize trees with large numbers of nodes.\n+end::dfas-gamma[]\n+\n+tag::dfas-lambda[]\n+`lambda`::::\n+(double)\n+Regularization factor to penalize large leaf weights.\n+end::dfas-lambda[]\n+\n+tag::dfas-max-attempts[]\n+`max_attempts_to_add_tree`::::\n+(integer)\n+If the algorithm fails to determine a non-trivial tree (more than a single \n+leaf), this parameter determines how many of such consecutive failures are \n+tolerated. Once the number of attempts exceeds the threshold, the forest \n+training stops.\n+end::dfas-max-attempts[]\n+\n+tag::dfas-max-optimization-rounds[]\n+`max_optimization_rounds_per_hyperparameter`::::\n+(integer)\n+A multiplier responsible for determining the maximum number of \n+hyperparameter optimization steps in the Bayesian optimization procedure. \n+The maximum number of steps is determined based on the number of undefined hyperparameters \n+times the maximum optimization rounds per hyperparameter.\n+end::dfas-max-optimization-rounds[]\n+\n+tag::dfas-max-trees[]\n+`max_trees`::::\n+(integer)\n+The maximum number of trees in the forest.\n+end::dfas-max-trees[]\n+\n+tag::dfas-num-folds[]\n+`num_folds`::::\n+(integer)\n+The maximum number of folds for the cross-validation procedure.\n+end::dfas-num-folds[]\n+\n+tag::dfas-num-splits[]\n+`num_splits_per_feature`::::\n+(integer)\n+Determines the maximum number of splits for every feature that can occur in a \n+decision tree when the tree is trained.\n+end::dfas-num-splits[]\n+\n+tag::dfas-soft-limit[]\n+`soft_tree_depth_limit`::::\n+(double)\n+Tree depth limit is used for calculating the tree depth penalty. This is a soft \n+limit, it can be exceeded.\n+end::dfas-soft-limit[]\n+\n+tag::dfas-soft-tolerance[]\n+`soft_tree_depth_tolerance`::::\n+(double)\n+Tree depth tolerance is used for calculating the tree depth penalty. This is a \n+soft limit, it can be exceeded.\n+end::dfas-soft-tolerance[]\n+======\n+//End class_hyperparameters\n+\n+tag::dfas-iteration[]\n+`iteration`::::\n+(integer)\n+The number of iterations on the {dfanalytics-job}.\n+end::dfas-iteration[]\n+\n+tag::dfas-timestamp[]\n+`timestamp`::::\n+(date)\n+The timestamp when the statistics returned in milliseconds since the epoch.\n+end::dfas-timestamp[]\n+\n+//Begin class_timing_stats\n+tag::dfas-timing-stats[]\n+`timing_stats`::::\n+(object)\n+An object containing time statistics about the {dfanalytics-job}.\n+end::dfas-timing-stats[]\n++\n+.Properties of `timing_stats`\n+[%collapsible%open]\n+======\n+tag::dfas-timing-stats-elapsed[]\n+`elapsed_time`::::\n+(integer)\n+Runtime of the {dfanalytics-job} in milliseconds.\n+end::dfas-timing-stats-elapsed[]\n+\n+tag::dfas-timing-stats-iteration[]\n+`iteration_time`::::\n+(integer)\n+Runtime of the {dfanalytics-job} since the last iteration in milliseconds.\n+end::dfas-timing-stats-iteration[]\n+======\n+//End class_timing_stats\n+\n+//Begin class_validation_loss\n+tag::dfas-validation-loss[]\n+`validation_loss`::::\n+(object)\n+An object containing information about validation loss.\n+end::dfas-validation-loss[]\n++\n+.Properties of `validation_loss`\n+[%collapsible%open]\n+======\n+tag::dfas-validation-loss-type[]\n+`loss_type`::::\n+(string)\n+The name of the loss metric. For example, `binomial_logistic`.", "originalCommit": "a7bec16545e994f52234222a7304327e960024cc", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1e2461f86a684a819ec11f78c9bb4af4a8dfa296", "url": "https://github.com/elastic/elasticsearch/commit/1e2461f86a684a819ec11f78c9bb4af4a8dfa296", "message": "[DOCS] Addresses feedback.", "committedDate": "2020-03-31T09:58:59Z", "type": "commit"}]}