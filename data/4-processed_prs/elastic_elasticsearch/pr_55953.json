{"pr_number": 55953, "pr_title": "[DOCS] Align with ILM changes.", "pr_createdAt": "2020-04-29T16:28:55Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/55953", "timeline": [{"oid": "f3fcb830fa37f44d6f305316b4aed03877a8fb4f", "url": "https://github.com/elastic/elasticsearch/commit/f3fcb830fa37f44d6f305316b4aed03877a8fb4f", "message": "[DOCS] Align with ILM changes.", "committedDate": "2020-05-05T01:07:10Z", "type": "commit"}, {"oid": "f3fcb830fa37f44d6f305316b4aed03877a8fb4f", "url": "https://github.com/elastic/elasticsearch/commit/f3fcb830fa37f44d6f305316b4aed03877a8fb4f", "message": "[DOCS] Align with ILM changes.", "committedDate": "2020-05-05T01:07:10Z", "type": "forcePushed"}, {"oid": "0d22121134aa4c84bac2f03d85d3e4c695c56597", "url": "https://github.com/elastic/elasticsearch/commit/0d22121134aa4c84bac2f03d85d3e4c695c56597", "message": "Edit retention", "committedDate": "2020-05-05T03:13:42Z", "type": "commit"}, {"oid": "6f87aca5189d507385f1ff9cbdadd6c928ed904b", "url": "https://github.com/elastic/elasticsearch/commit/6f87aca5189d507385f1ff9cbdadd6c928ed904b", "message": "Add test setup", "committedDate": "2020-05-05T22:21:45Z", "type": "commit"}, {"oid": "9d884f130535eac8719ed1f2f202bd30b95f6c0c", "url": "https://github.com/elastic/elasticsearch/commit/9d884f130535eac8719ed1f2f202bd30b95f6c0c", "message": "Split off SLM settings.", "committedDate": "2020-05-05T23:27:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU4MTE2NQ==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421581165", "bodyText": "The below example is 2:30am\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            to back up all of your indices daily at 1:30AM UTC.\n          \n          \n            \n            to back up all of your indices daily at 2:30AM UTC.", "author": "dakrone", "createdAt": "2020-05-07T15:10:14Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -34,15 +42,22 @@ PUT /_snapshot/my_repository\n [[slm-gs-create-policy]]\n ==== Setting up a snapshot policy\n \n-Now that we have a repository in place, we can create a policy to automatically\n-take snapshots. Policies are written in JSON and will define when to take\n-snapshots, what the snapshots should be named, and which indices should be\n-included, among other things.  We'll use the <<slm-api-put-policy>> API\n-to create the policy.\n+Once you have a repository in place, you can define an {slm-init} policy to automate your backups. \n+The policy defines when to take snapshots, which indices should be included, \n+and what to name the snapshots. \n+A policy can also specify a <<slm-retention,retention policy>> and \n+automatically delete snapshots when they are no longer needed.\n+\n+TIP: Don't be afraid to configure a policy that takes frequent snapshots.\n+Snapshots are incremental and make efficient use of storage.\n+\n+You can define and manage policies through the {kibana} Management UI, \n+which invokes the {slm-init} put policy API to create policies according to the options you specify.\n \n-When configurating a policy, retention can also optionally be configured. See\n-the <<slm-retention,SLM retention>> documentation for the full documentation of\n-how retention works.\n+For example, you could define a nightly-snapshots policy \n+to back up all of your indices daily at 1:30AM UTC.", "originalCommit": "9d884f130535eac8719ed1f2f202bd30b95f6c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU4MTMzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421581331", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                <<schedule-cron,Cron syntax>>: daily at 1:30AM UTC\n          \n          \n            \n                <<schedule-cron,Cron syntax>>: daily at 2:30AM UTC", "author": "dakrone", "createdAt": "2020-05-07T15:10:29Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -62,66 +77,56 @@ PUT /_slm/policy/nightly-snapshots\n }\n --------------------------------------------------\n // TEST[continued]\n-<1> when the snapshot should be taken, using \n-    <<schedule-cron,Cron syntax>>, in this \n-    case at 1:30AM each day\n-<2> whe name each snapshot should be given, using \n-    <<date-math-index-names,date math>> to include the current date in the name\n-    of the snapshot\n-<3> the repository the snapshot should be stored in\n-<4> the configuration to be used for the snapshot requests (see below)\n-<5> which indices should be included in the snapshot, in this case, every index\n-<6> Optional retention configuration\n-<7> Keep snapshots for 30 days\n-<8> Always keep at least 5 successful snapshots\n-<9> Keep no more than 50 successful snapshots, even if they're less than 30 days old\n-\n-This policy will take a snapshot of every index each day at 1:30AM UTC.\n-Snapshots are incremental, allowing frequent snapshots to be stored efficiently,\n-so don't be afraid to configure a policy to take frequent snapshots.\n-\n-In addition to specifying the indices that should be included in the snapshot,\n-the `config` field can be used to customize other aspects of the snapshot. You\n-can use any option allowed in <<snapshots-take-snapshot,a regular snapshot \n-request>>, so you can specify, for example, whether the snapshot should fail in\n-special cases, such as if one of the specified indices cannot be found.\n+<1> When the snapshot should be taken in\n+    <<schedule-cron,Cron syntax>>: daily at 1:30AM UTC", "originalCommit": "9d884f130535eac8719ed1f2f202bd30b95f6c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU4MzA3Mw==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421583073", "bodyText": "It's strange to call .slm-history* a single index, since it's a collection of indices behind an alias named .slm-history, we could either change this to \"indices\" or only mention the alias?", "author": "dakrone", "createdAt": "2020-05-07T15:12:51Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -143,44 +148,33 @@ next time the policy will be executed.\n         \"max_count\": 50\n       }\n     },\n-    \"last_success\": { <1>\n-      \"snapshot_name\": \"nightly-snap-2019.04.24-tmtnyjtrsxkhbrrdcgg18a\", <2>\n-      \"time_string\": \"2019-04-24T16:43:49.316Z\",\n+    \"last_success\": { \n+      \"snapshot_name\": \"nightly-snap-2019.04.24-tmtnyjtrsxkhbrrdcgg18a\", <1>\n+      \"time_string\": \"2019-04-24T16:43:49.316Z\", <2>\n       \"time\": 1556124229316\n     } ,\n-    \"last_failure\": { <3>\n-      \"snapshot_name\": \"nightly-snap-2019.04.02-lohisb5ith2n8hxacaq3mw\",\n-      \"time_string\": \"2019-04-02T01:30:00.000Z\",\n-      \"time\": 1556042030000,\n-      \"details\": \"{\\\"type\\\":\\\"index_not_found_exception\\\",\\\"reason\\\":\\\"no such index [important]\\\",\\\"resource.type\\\":\\\"index_or_alias\\\",\\\"resource.id\\\":\\\"important\\\",\\\"index_uuid\\\":\\\"_na_\\\",\\\"index\\\":\\\"important\\\",\\\"stack_trace\\\":\\\"[important] IndexNotFoundException[no such index [important]]\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.indexNotFoundException(IndexNameExpressionResolver.java:762)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.innerResolve(IndexNameExpressionResolver.java:714)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.resolve(IndexNameExpressionResolver.java:670)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:163)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndexNames(IndexNameExpressionResolver.java:142)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndexNames(IndexNameExpressionResolver.java:102)\\\\n\\\\tat org.elasticsearch.snapshots.SnapshotsService$1.execute(SnapshotsService.java:280)\\\\n\\\\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\\\\n\\\\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\\\\n\\\\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\\\\n\\\\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\\\\n\\\\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\\\\n\\\\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\\\\n\\\\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\\\\n\\\\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:688)\\\\n\\\\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\\\\n\\\\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\\\\n\\\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\\\n\\\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\\\n\\\\tat java.base/java.lang.Thread.run(Thread.java:834)\\\\n\\\"}\"\n-    } ,\n-    \"next_execution\": \"2019-04-24T01:30:00.000Z\", <4>\n-    \"next_execution_millis\": 1556048160000\n+    \"next_execution\": \"2019-04-24T01:30:00.000Z\", <3>\n+    \"next_execution_millis\": 1556048160000 \n   }\n }\n --------------------------------------------------\n // TESTRESPONSE[skip:the presence of last_failure and last_success is asynchronous and will be present for users, but is untestable]\n \n-<1> information about the last time the policy successfully initated a snapshot\n-<2> the name of the snapshot that was successfully initiated\n-<3> information about the last time the policy failed to initiate a snapshot\n-<4> the next time the policy will execute\n+<1> The name of the last snapshot that was succesfully initiated by the policy\n+<2> When the snapshot was initiated\n+<3> When the policy will initiate the next snapshot\n \n-NOTE: This metadata only indicates whether the request to initiate the snapshot was\n-made successfully or not - after the snapshot has been successfully started, it\n-is possible for the snapshot to fail if, for example, the connection to a remote\n+The response shows if the policy succeeded in _initiating_ a snapshot.\n+However, that does not guarantee that the snapshot completed successfully. \n+It is possible for the initiated snapshot to fail if, for example, the connection to a remote\n repository is lost while copying files.\n \n-If you're following along, the returned SLM policy shouldn't have a `last_failure`\n-field - it's included above only as an example. You should, however, see a \n-`last_success` field and a snapshot name. If you do, you've successfully taken\n-your first snapshot using SLM!\n-\n-While only the most recent sucess and failure are available through the Get Policy \n-API, all policy executions are recorded to a history index, which may be queried\n-by searching the index pattern `.slm-history*`.\n+Only the most recent success and failure are returned, \n+but all policy executions are recorded in the `.slm-history*` index.", "originalCommit": "9d884f130535eac8719ed1f2f202bd30b95f6c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU4MzU3OA==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421583578", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To control when the retention task runs, you configure \n          \n          \n            \n            To control when the retention task runs, configure", "author": "dakrone", "createdAt": "2020-05-07T15:13:37Z", "path": "docs/reference/slm/slm-retention.asciidoc", "diffHunk": "@@ -3,30 +3,31 @@\n [[slm-retention]]\n === Snapshot retention\n \n-Automatic deletion of older snapshots is an optional feature of snapshot lifecycle management.\n-Retention is run as a cluster level task that is not associated with a particular policy's schedule\n-(though the configuration of which snapshots to keep is done on a per-policy basis). Retention\n-configuration consists of two parts\u2014The first a cluster-level configuration for when retention is\n-run and for how long, the second configured on a policy for which snapshots should be eligible for\n-retention.\n+You can include a retention policy in an {slm-init} policy to automatically delete old snapshots. \n+Retention runs as a cluster level task and is not associated with a particular policy's schedule.\n+The retention criteria are evaluated as part of the retention task, not when the policy executes.\n+For the retention task to automatically delete snapshots, \n+you need to include a  <<slm-api-put-retention,`retention`>> object in your {slm-init} policy.\n \n-The cluster level settings for retention are shown below, and can be changed dynamically using the\n-<<cluster-update-settings>> API:\n+To control when the retention task runs, you configure ", "originalCommit": "9d884f130535eac8719ed1f2f202bd30b95f6c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU4NDk1Mg==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421584952", "bodyText": "We're removing the description of these options, but I don't see them documented anywhere else now other than once in the example API request. I think we still need to document these configuration options somewhere", "author": "dakrone", "createdAt": "2020-05-07T15:15:30Z", "path": "docs/reference/slm/slm-retention.asciidoc", "diffHunk": "@@ -46,35 +47,7 @@ PUT /_slm/policy/daily-snapshots\n <2> Keep snapshots for 30 days\n <3> Always keep at least 5 successful snapshots\n <4> Keep no more than 50 successful snapshots\n-\n-Supported configuration for retention from within a policy are as follows. The default value for\n-each is unset unless specified by the user in the policy configuration.\n-\n-NOTE: The oldest snapshots are always deleted first, in the case of a `max_count` of 5 for a policy\n-with 6 snapshots, the oldest snapshot will be deleted.\n-\n-|=====================================\n-| Setting | Description\n-| `expire_after` | A timevalue for how old a snapshot must be in order to be eligible for deletion.\n-| `min_count` | A minimum number of snapshots to keep, regardless of age.\n-| `max_count` | The maximum number of snapshots to keep, regardless of age.", "originalCommit": "9d884f130535eac8719ed1f2f202bd30b95f6c0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTg2MjEwNw==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421862107", "bodyText": "They are in the API reference: https://github.com/elastic/elasticsearch/pull/55953/files#diff-3e796bf77f9921d05504be8c3e5a9349", "author": "debadair", "createdAt": "2020-05-08T00:04:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU4NDk1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU5MDM4NA==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421590384", "bodyText": "Double periods. I'd also spell out ILM on first mention.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            These are the settings available for configuring <<index-lifecycle-management, {ilm-init}>>..\n          \n          \n            \n            These are the settings available for configuring <<index-lifecycle-management, {ilm} ({ilm-init})>>.", "author": "jrodewig", "createdAt": "2020-05-07T15:23:05Z", "path": "docs/reference/settings/ilm-settings.asciidoc", "diffHunk": "@@ -1,8 +1,12 @@\n [role=\"xpack\"]\n [[ilm-settings]]\n-=== {ilm-cap} settings\n+=== {ilm-cap} settings in {es}\n+[subs=\"attributes\"]\n+++++\n+<titleabbrev>{ilm-cap} settings</titleabbrev>\n+++++\n \n-These are the settings available for configuring Index Lifecycle Management\n+These are the settings available for configuring <<index-lifecycle-management, {ilm-init}>>..", "originalCommit": "9d884f130535eac8719ed1f2f202bd30b95f6c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU5MDQzNA==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421590434", "bodyText": "I'm not sure in {es} is adding much here, but it's not a big deal. I would assume users know they're in the ES docs.", "author": "jrodewig", "createdAt": "2020-05-07T15:23:08Z", "path": "docs/reference/settings/ilm-settings.asciidoc", "diffHunk": "@@ -1,8 +1,12 @@\n [role=\"xpack\"]\n [[ilm-settings]]\n-=== {ilm-cap} settings\n+=== {ilm-cap} settings in {es}", "originalCommit": "9d884f130535eac8719ed1f2f202bd30b95f6c0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc2NjY0Mg==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421766642", "bodyText": "I was following the pattern in some of the other settings topics. I don't feel strongly one way or the other. It's possibly helpful from an SEO perspective, but with elasticsearch in the URL, it's likely negligible.  I'll open a follow on to make them all consistent.", "author": "debadair", "createdAt": "2020-05-07T20:14:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU5MDQzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU5MDU2MQ==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421590561", "bodyText": "Same comment as above.", "author": "jrodewig", "createdAt": "2020-05-07T15:23:21Z", "path": "docs/reference/settings/slm-settings.asciidoc", "diffHunk": "@@ -0,0 +1,23 @@\n+[role=\"xpack\"]\n+[[slm-settings]]\n+=== {slm-cap} settings in {es}", "originalCommit": "9d884f130535eac8719ed1f2f202bd30b95f6c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU5MDc4OA==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421590788", "bodyText": "If we spell out ILM on first mention, I'd do the same here.", "author": "jrodewig", "createdAt": "2020-05-07T15:23:39Z", "path": "docs/reference/settings/slm-settings.asciidoc", "diffHunk": "@@ -0,0 +1,23 @@\n+[role=\"xpack\"]\n+[[slm-settings]]\n+=== {slm-cap} settings in {es}\n+[subs=\"attributes\"]\n+++++\n+<titleabbrev>{slm-cap} settings</titleabbrev>\n+++++\n+\n+These are the settings available for configuring <<snapshot-lifecycle-management, {slm-init}>>.", "originalCommit": "9d884f130535eac8719ed1f2f202bd30b95f6c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU5MDk3OA==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421590978", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            ==== Cluster level settings\n          \n          \n            \n            ==== Cluster-level settings", "author": "jrodewig", "createdAt": "2020-05-07T15:23:53Z", "path": "docs/reference/settings/slm-settings.asciidoc", "diffHunk": "@@ -0,0 +1,23 @@\n+[role=\"xpack\"]\n+[[slm-settings]]\n+=== {slm-cap} settings in {es}\n+[subs=\"attributes\"]\n+++++\n+<titleabbrev>{slm-cap} settings</titleabbrev>\n+++++\n+\n+These are the settings available for configuring <<snapshot-lifecycle-management, {slm-init}>>.\n+\n+==== Cluster level settings", "originalCommit": "9d884f130535eac8719ed1f2f202bd30b95f6c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU5MTkwNQ==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421591905", "bodyText": "retention task\n\nA link here would be good. Maybe <<slm-retention,retention task>>", "author": "jrodewig", "createdAt": "2020-05-07T15:25:00Z", "path": "docs/reference/settings/slm-settings.asciidoc", "diffHunk": "@@ -0,0 +1,23 @@\n+[role=\"xpack\"]\n+[[slm-settings]]\n+=== {slm-cap} settings in {es}\n+[subs=\"attributes\"]\n+++++\n+<titleabbrev>{slm-cap} settings</titleabbrev>\n+++++\n+\n+These are the settings available for configuring <<snapshot-lifecycle-management, {slm-init}>>.\n+\n+==== Cluster level settings\n+\n+[[slm-retention-schedule]]\n+`slm.retention_schedule`::\n+Controls when the retention task runs.", "originalCommit": "9d884f130535eac8719ed1f2f202bd30b95f6c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "3907f824e1bb9f7360971166403ed5bdb4349567", "url": "https://github.com/elastic/elasticsearch/commit/3907f824e1bb9f7360971166403ed5bdb4349567", "message": "Update docs/reference/slm/slm-retention.asciidoc\n\nCo-authored-by: Lee Hinman <dakrone@users.noreply.github.com>", "committedDate": "2020-05-07T15:27:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU5Mzg4Mw==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421593883", "bodyText": "We don't have a good convention for settings yet, but I think it's helpful to add a dynamic indicator and the data type here.\nSo expand this to something like:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            `slm.retention_schedule`::\n          \n          \n            \n            `slm.retention_schedule`::\n          \n          \n            \n            (<<cluster-update-settings,Dynamic>>, <<time-units,time value>> or <<schedule-cron,cron scheduler value>>) \n          \n      \n    \n    \n  \n\nNo biggie if we want to do this later though.", "author": "jrodewig", "createdAt": "2020-05-07T15:27:37Z", "path": "docs/reference/settings/slm-settings.asciidoc", "diffHunk": "@@ -0,0 +1,23 @@\n+[role=\"xpack\"]\n+[[slm-settings]]\n+=== {slm-cap} settings in {es}\n+[subs=\"attributes\"]\n+++++\n+<titleabbrev>{slm-cap} settings</titleabbrev>\n+++++\n+\n+These are the settings available for configuring <<snapshot-lifecycle-management, {slm-init}>>.\n+\n+==== Cluster level settings\n+\n+[[slm-retention-schedule]]\n+`slm.retention_schedule`::", "originalCommit": "9d884f130535eac8719ed1f2f202bd30b95f6c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU5NDQwMg==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421594402", "bodyText": "See https://github.com/elastic/elasticsearch/pull/55953/files#r421593883", "author": "jrodewig", "createdAt": "2020-05-07T15:28:16Z", "path": "docs/reference/settings/slm-settings.asciidoc", "diffHunk": "@@ -0,0 +1,23 @@\n+[role=\"xpack\"]\n+[[slm-settings]]\n+=== {slm-cap} settings in {es}\n+[subs=\"attributes\"]\n+++++\n+<titleabbrev>{slm-cap} settings</titleabbrev>\n+++++\n+\n+These are the settings available for configuring <<snapshot-lifecycle-management, {slm-init}>>.\n+\n+==== Cluster level settings\n+\n+[[slm-retention-schedule]]\n+`slm.retention_schedule`::\n+Controls when the retention task runs.\n+Can be a periodic or absolute time schedule.\n+Supports all values supported by the <<schedule-cron,cron scheduler>>.\n+Defaults to daily at 1:30am UTC: `0 30 1 * * ?`.\n+\n+[[slm-retention-duration]]\n+`slm.retention_duration`::\n+Limits how long {slm-init} should spend deleting old snapshots.", "originalCommit": "9d884f130535eac8719ed1f2f202bd30b95f6c0c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU5NzY4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421597689", "bodyText": "When rendered this title is Shard request cache settings. We may want to move it after Security settings.", "author": "jrodewig", "createdAt": "2020-05-07T15:32:53Z", "path": "docs/reference/setup.asciidoc", "diffHunk": "@@ -67,13 +69,13 @@ include::settings/monitoring-settings.asciidoc[]\n \n include::modules/indices/query_cache.asciidoc[]\n \n-include::modules/indices/request_cache.asciidoc[]\n-\n include::modules/indices/search-settings.asciidoc[]\n \n+include::modules/indices/request_cache.asciidoc[]", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTU5OTkyMg==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421599922", "bodyText": "This is sorta unrelated to your changes but Field data cache settings should come first.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            include::settings/ilm-settings.asciidoc[]\n          \n          \n            \n            include::modules/indices/fielddata.asciidoc[]\n          \n          \n            \n            \n          \n          \n            \n            include::settings/ilm-settings.asciidoc[]", "author": "jrodewig", "createdAt": "2020-05-07T15:36:05Z", "path": "docs/reference/setup.asciidoc", "diffHunk": "@@ -45,18 +45,20 @@ include::setup/jvm-options.asciidoc[]\n \n include::setup/secure-settings.asciidoc[]\n \n-include::settings/ccr-settings.asciidoc[]\n+include::settings/audit-settings.asciidoc[]\n \n include::modules/indices/circuit_breaker.asciidoc[]\n \n+include::settings/ccr-settings.asciidoc[]\n+\n+include::settings/ilm-settings.asciidoc[]", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwMDE0Mw==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421600143", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            include::modules/indices/fielddata.asciidoc[]", "author": "jrodewig", "createdAt": "2020-05-07T15:36:22Z", "path": "docs/reference/setup.asciidoc", "diffHunk": "@@ -45,18 +45,20 @@ include::setup/jvm-options.asciidoc[]\n \n include::setup/secure-settings.asciidoc[]\n \n-include::settings/ccr-settings.asciidoc[]\n+include::settings/audit-settings.asciidoc[]\n \n include::modules/indices/circuit_breaker.asciidoc[]\n \n+include::settings/ccr-settings.asciidoc[]\n+\n+include::settings/ilm-settings.asciidoc[]\n+\n include::modules/indices/recovery.asciidoc[]\n \n include::modules/indices/indexing_buffer.asciidoc[]\n \n include::modules/indices/fielddata.asciidoc[]", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwMzAzNA==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421603034", "bodyText": "This tutorial demonstrates how to\n\nI thought we typically strayed away form this type of meta language. We could probably rephrase to something like You can use an {slim-init} policy to ...", "author": "jrodewig", "createdAt": "2020-05-07T15:40:20Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -1,23 +1,31 @@\n [role=\"xpack\"]\n [testenv=\"basic\"]\n [[getting-started-snapshot-lifecycle-management]]\n-=== Configure snapshot lifecycle policies\n+=== Tutorial: Automate back ups with {slm-init}\n \n-Let's get started with {slm} ({slm-init}) by working through a\n-hands-on scenario. The goal of this example is to automatically back up {es}\n-indices using the <<snapshot-restore,snapshots>> every day at a particular\n-time. Once these snapshots have been created, they are kept for a configured\n-amount of time and then deleted per a configured retention policy.\n+This tutorial demonstrates how to automate daily back ups of {es} indices using an {slm-init} policy.", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc3MTI4MQ==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421771281", "bodyText": "Tutorials are the one place the meta-info doesn't really bother me. I'm going to leave it for now & look at the language we use in other places. I'll open another PR to be consistent, one way or another. (With tutorial in the titles, it's not really necessary to repeat \"tutorial\" in the text for SEO purposes.)", "author": "debadair", "createdAt": "2020-05-07T20:23:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwMzAzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwMzI1Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421603257", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The policy also defines a retention policy and automatically deletes the snapshots when they\n          \n          \n            \n            The policy also defines a retention policy and automatically deletes snapshots when they", "author": "jrodewig", "createdAt": "2020-05-07T15:40:37Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -1,23 +1,31 @@\n [role=\"xpack\"]\n [testenv=\"basic\"]\n [[getting-started-snapshot-lifecycle-management]]\n-=== Configure snapshot lifecycle policies\n+=== Tutorial: Automate back ups with {slm-init}\n \n-Let's get started with {slm} ({slm-init}) by working through a\n-hands-on scenario. The goal of this example is to automatically back up {es}\n-indices using the <<snapshot-restore,snapshots>> every day at a particular\n-time. Once these snapshots have been created, they are kept for a configured\n-amount of time and then deleted per a configured retention policy.\n+This tutorial demonstrates how to automate daily back ups of {es} indices using an {slm-init} policy.\n+The policy also defines a retention policy and automatically deletes the snapshots when they", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwMzYwMw==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421603603", "bodyText": "We should probably connect backup = snapshot before the following para.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            This tutorial demonstrates how to automate daily back ups of {es} indices using an {slm-init} policy.\n          \n          \n            \n            This tutorial demonstrates how to automate daily backups of {es} indices using an {slm-init} policy.", "author": "jrodewig", "createdAt": "2020-05-07T15:41:07Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -1,23 +1,31 @@\n [role=\"xpack\"]\n [testenv=\"basic\"]\n [[getting-started-snapshot-lifecycle-management]]\n-=== Configure snapshot lifecycle policies\n+=== Tutorial: Automate back ups with {slm-init}\n \n-Let's get started with {slm} ({slm-init}) by working through a\n-hands-on scenario. The goal of this example is to automatically back up {es}\n-indices using the <<snapshot-restore,snapshots>> every day at a particular\n-time. Once these snapshots have been created, they are kept for a configured\n-amount of time and then deleted per a configured retention policy.\n+This tutorial demonstrates how to automate daily back ups of {es} indices using an {slm-init} policy.", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwNDEzOQ==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421604139", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            You can manually trigger the policy to test the policy and take an initial snapshot. \n          \n          \n            \n            To test the policy, you can manually trigger it to take an initial snapshot.", "author": "jrodewig", "createdAt": "2020-05-07T15:41:50Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -1,23 +1,31 @@\n [role=\"xpack\"]\n [testenv=\"basic\"]\n [[getting-started-snapshot-lifecycle-management]]\n-=== Configure snapshot lifecycle policies\n+=== Tutorial: Automate back ups with {slm-init}\n \n-Let's get started with {slm} ({slm-init}) by working through a\n-hands-on scenario. The goal of this example is to automatically back up {es}\n-indices using the <<snapshot-restore,snapshots>> every day at a particular\n-time. Once these snapshots have been created, they are kept for a configured\n-amount of time and then deleted per a configured retention policy.\n+This tutorial demonstrates how to automate daily back ups of {es} indices using an {slm-init} policy.\n+The policy also defines a retention policy and automatically deletes the snapshots when they\n+are no longer needed.\n+\n+To manage snapshots with {slm-init}, you:\n+\n+. <<slm-gs-register-repository, Register a repository>>.\n+. <<slm-gs-create-policy, Create an {slm-init} policy>>.\n+\n+You can manually trigger the policy to test the policy and take an initial snapshot. ", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwNDI5Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421604297", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To take snapshots and use {slm-init}, you must have a snapshot repository configured. \n          \n          \n            \n            To use {slm-init}, you must have a snapshot repository configured.", "author": "jrodewig", "createdAt": "2020-05-07T15:42:02Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -1,23 +1,31 @@\n [role=\"xpack\"]\n [testenv=\"basic\"]\n [[getting-started-snapshot-lifecycle-management]]\n-=== Configure snapshot lifecycle policies\n+=== Tutorial: Automate back ups with {slm-init}\n \n-Let's get started with {slm} ({slm-init}) by working through a\n-hands-on scenario. The goal of this example is to automatically back up {es}\n-indices using the <<snapshot-restore,snapshots>> every day at a particular\n-time. Once these snapshots have been created, they are kept for a configured\n-amount of time and then deleted per a configured retention policy.\n+This tutorial demonstrates how to automate daily back ups of {es} indices using an {slm-init} policy.\n+The policy also defines a retention policy and automatically deletes the snapshots when they\n+are no longer needed.\n+\n+To manage snapshots with {slm-init}, you:\n+\n+. <<slm-gs-register-repository, Register a repository>>.\n+. <<slm-gs-create-policy, Create an {slm-init} policy>>.\n+\n+You can manually trigger the policy to test the policy and take an initial snapshot. \n \n [float]\n [[slm-gs-register-repository]]\n ==== Register a repository\n \n-Before we can set up an SLM policy, we'll need to set up a\n-snapshot repository where the snapshots will be\n-stored. Repositories can use {plugins}/repository.html[many different backends],\n-including cloud storage providers. You'll probably want to use one of these in\n-production, but for this example we'll use a shared file system repository:\n+To take snapshots and use {slm-init}, you must have a snapshot repository configured. ", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwNDU1NQ==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421604555", "bodyText": "Plugin links?\n\nRemote repositories can reside on S3, HDFS, Azure, Google Cloud Storage,\nor any other platform supported by a repository plugin.", "author": "jrodewig", "createdAt": "2020-05-07T15:42:27Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -1,23 +1,31 @@\n [role=\"xpack\"]\n [testenv=\"basic\"]\n [[getting-started-snapshot-lifecycle-management]]\n-=== Configure snapshot lifecycle policies\n+=== Tutorial: Automate back ups with {slm-init}\n \n-Let's get started with {slm} ({slm-init}) by working through a\n-hands-on scenario. The goal of this example is to automatically back up {es}\n-indices using the <<snapshot-restore,snapshots>> every day at a particular\n-time. Once these snapshots have been created, they are kept for a configured\n-amount of time and then deleted per a configured retention policy.\n+This tutorial demonstrates how to automate daily back ups of {es} indices using an {slm-init} policy.\n+The policy also defines a retention policy and automatically deletes the snapshots when they\n+are no longer needed.\n+\n+To manage snapshots with {slm-init}, you:\n+\n+. <<slm-gs-register-repository, Register a repository>>.\n+. <<slm-gs-create-policy, Create an {slm-init} policy>>.\n+\n+You can manually trigger the policy to test the policy and take an initial snapshot. \n \n [float]\n [[slm-gs-register-repository]]\n ==== Register a repository\n \n-Before we can set up an SLM policy, we'll need to set up a\n-snapshot repository where the snapshots will be\n-stored. Repositories can use {plugins}/repository.html[many different backends],\n-including cloud storage providers. You'll probably want to use one of these in\n-production, but for this example we'll use a shared file system repository:\n+To take snapshots and use {slm-init}, you must have a snapshot repository configured. \n+The repository can be local (shared filesystem) or remote (cloud storage).  \n+Remote repositories can reside on S3, HDFS, Azure, Google Cloud Storage, \n+or any other platform supported by a repository plugin.", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwNjM2OA==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421606368", "bodyText": "No comma needed. Also not a big fan of \"call directly.\"\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            For this tutorial, you can register a local repository from the {kib} Management UI, \n          \n          \n            \n            or call the put repository API directly:\n          \n          \n            \n            For this tutorial, you can register a local repository from the {kib} Management UI\n          \n          \n            \n            or use the put repository API:", "author": "jrodewig", "createdAt": "2020-05-07T15:45:05Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -1,23 +1,31 @@\n [role=\"xpack\"]\n [testenv=\"basic\"]\n [[getting-started-snapshot-lifecycle-management]]\n-=== Configure snapshot lifecycle policies\n+=== Tutorial: Automate back ups with {slm-init}\n \n-Let's get started with {slm} ({slm-init}) by working through a\n-hands-on scenario. The goal of this example is to automatically back up {es}\n-indices using the <<snapshot-restore,snapshots>> every day at a particular\n-time. Once these snapshots have been created, they are kept for a configured\n-amount of time and then deleted per a configured retention policy.\n+This tutorial demonstrates how to automate daily back ups of {es} indices using an {slm-init} policy.\n+The policy also defines a retention policy and automatically deletes the snapshots when they\n+are no longer needed.\n+\n+To manage snapshots with {slm-init}, you:\n+\n+. <<slm-gs-register-repository, Register a repository>>.\n+. <<slm-gs-create-policy, Create an {slm-init} policy>>.\n+\n+You can manually trigger the policy to test the policy and take an initial snapshot. \n \n [float]\n [[slm-gs-register-repository]]\n ==== Register a repository\n \n-Before we can set up an SLM policy, we'll need to set up a\n-snapshot repository where the snapshots will be\n-stored. Repositories can use {plugins}/repository.html[many different backends],\n-including cloud storage providers. You'll probably want to use one of these in\n-production, but for this example we'll use a shared file system repository:\n+To take snapshots and use {slm-init}, you must have a snapshot repository configured. \n+The repository can be local (shared filesystem) or remote (cloud storage).  \n+Remote repositories can reside on S3, HDFS, Azure, Google Cloud Storage, \n+or any other platform supported by a repository plugin.\n+Remote repositories are generally used for production deployments.\n+\n+For this tutorial, you can register a local repository from the {kib} Management UI, \n+or call the put repository API directly:", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwNjc3Ng==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421606776", "bodyText": "We kinda jump between backups and snapshots. I'd establish backup = snapshot upfront and just use one.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Once you have a repository in place, you can define an {slm-init} policy to automate your backups. \n          \n          \n            \n            Once you have a repository in place, you can define a {slm-init} policy to automate your backups.", "author": "jrodewig", "createdAt": "2020-05-07T15:45:41Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -34,15 +42,22 @@ PUT /_snapshot/my_repository\n [[slm-gs-create-policy]]\n ==== Setting up a snapshot policy\n \n-Now that we have a repository in place, we can create a policy to automatically\n-take snapshots. Policies are written in JSON and will define when to take\n-snapshots, what the snapshots should be named, and which indices should be\n-included, among other things.  We'll use the <<slm-api-put-policy>> API\n-to create the policy.\n+Once you have a repository in place, you can define an {slm-init} policy to automate your backups. ", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTgwODgzOQ==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421808839", "bodyText": "Oops. Bad suggestion on my part. Please ignore.", "author": "jrodewig", "createdAt": "2020-05-07T21:36:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwNjc3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwODE0Mw==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421608143", "bodyText": "Not sure how useful it is to peel back the hood here. I'd just tell people they can use the UI or the API.\nDon't think it matters that they know the UI invokes the API.\n\nYou can define and manage policies through the {kibana} Management UI,\nwhich invokes the {slm-init} put policy API to create policies according to the options you specify.", "author": "jrodewig", "createdAt": "2020-05-07T15:47:37Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -34,15 +42,22 @@ PUT /_snapshot/my_repository\n [[slm-gs-create-policy]]\n ==== Setting up a snapshot policy\n \n-Now that we have a repository in place, we can create a policy to automatically\n-take snapshots. Policies are written in JSON and will define when to take\n-snapshots, what the snapshots should be named, and which indices should be\n-included, among other things.  We'll use the <<slm-api-put-policy>> API\n-to create the policy.\n+Once you have a repository in place, you can define an {slm-init} policy to automate your backups. \n+The policy defines when to take snapshots, which indices should be included, \n+and what to name the snapshots. \n+A policy can also specify a <<slm-retention,retention policy>> and \n+automatically delete snapshots when they are no longer needed.\n+\n+TIP: Don't be afraid to configure a policy that takes frequent snapshots.\n+Snapshots are incremental and make efficient use of storage.\n+\n+You can define and manage policies through the {kibana} Management UI, \n+which invokes the {slm-init} put policy API to create policies according to the options you specify.", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwODQ3Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421608477", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            For example, you could define a nightly-snapshots policy \n          \n          \n            \n            For example, you could define a `nightly-snapshots` policy", "author": "jrodewig", "createdAt": "2020-05-07T15:48:02Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -34,15 +42,22 @@ PUT /_snapshot/my_repository\n [[slm-gs-create-policy]]\n ==== Setting up a snapshot policy\n \n-Now that we have a repository in place, we can create a policy to automatically\n-take snapshots. Policies are written in JSON and will define when to take\n-snapshots, what the snapshots should be named, and which indices should be\n-included, among other things.  We'll use the <<slm-api-put-policy>> API\n-to create the policy.\n+Once you have a repository in place, you can define an {slm-init} policy to automate your backups. \n+The policy defines when to take snapshots, which indices should be included, \n+and what to name the snapshots. \n+A policy can also specify a <<slm-retention,retention policy>> and \n+automatically delete snapshots when they are no longer needed.\n+\n+TIP: Don't be afraid to configure a policy that takes frequent snapshots.\n+Snapshots are incremental and make efficient use of storage.\n+\n+You can define and manage policies through the {kibana} Management UI, \n+which invokes the {slm-init} put policy API to create policies according to the options you specify.\n \n-When configurating a policy, retention can also optionally be configured. See\n-the <<slm-retention,SLM retention>> documentation for the full documentation of\n-how retention works.\n+For example, you could define a nightly-snapshots policy ", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwOTI0Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421609247", "bodyText": "Links?\n\nYou can view information about snapshots in {kib} or get info with the snapshot APIs.", "author": "jrodewig", "createdAt": "2020-05-07T15:49:02Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -62,66 +77,56 @@ PUT /_slm/policy/nightly-snapshots\n }\n --------------------------------------------------\n // TEST[continued]\n-<1> when the snapshot should be taken, using \n-    <<schedule-cron,Cron syntax>>, in this \n-    case at 1:30AM each day\n-<2> whe name each snapshot should be given, using \n-    <<date-math-index-names,date math>> to include the current date in the name\n-    of the snapshot\n-<3> the repository the snapshot should be stored in\n-<4> the configuration to be used for the snapshot requests (see below)\n-<5> which indices should be included in the snapshot, in this case, every index\n-<6> Optional retention configuration\n-<7> Keep snapshots for 30 days\n-<8> Always keep at least 5 successful snapshots\n-<9> Keep no more than 50 successful snapshots, even if they're less than 30 days old\n-\n-This policy will take a snapshot of every index each day at 1:30AM UTC.\n-Snapshots are incremental, allowing frequent snapshots to be stored efficiently,\n-so don't be afraid to configure a policy to take frequent snapshots.\n-\n-In addition to specifying the indices that should be included in the snapshot,\n-the `config` field can be used to customize other aspects of the snapshot. You\n-can use any option allowed in <<snapshots-take-snapshot,a regular snapshot \n-request>>, so you can specify, for example, whether the snapshot should fail in\n-special cases, such as if one of the specified indices cannot be found.\n+<1> When the snapshot should be taken in\n+    <<schedule-cron,Cron syntax>>: daily at 1:30AM UTC\n+<2> How to name the snapshot: use  \n+    <<date-math-index-names,date math>> to include the current date in the snapshot name\n+<3> Where to store the snapshot\n+<4> The configuration to be used for the snapshot requests (see below)\n+<5> Which indices to include in the snapshot: all indices\n+<6> Optional retention policy: keep snapshots for 30 days, \n+retaining at least 5 and no more than 50 snapshots regardless of age. \n+\n+You can specify additional snapshot configuration options to customize how snapshots are taken.\n+For example, you could configure the policy to fail the snapshot \n+if one of the specified indices is missing. \n+For more information about snapshot options, see <<snapshots-take-snapshot,snapshot requests>>.\n \n [float]\n [[slm-gs-test-policy]]\n ==== Test the snapshot policy\n \n-While snapshots taken by SLM policies can be viewed through the standard snapshot\n-API, SLM also keeps track of policy successes and failures in ways that are a bit\n-easier to use to make sure the policy is working.  Once a policy has executed at\n-least once, when you view the policy using the <<slm-api-get-policy>>, \n-some metadata will be returned indicating whether the snapshot was sucessfully \n-initiated or not.\n+A snapshot taken by {slm-init} is just like any other snapshot. \n+You can view information about snapshots in {kib} or get info with the snapshot APIs. ", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwOTM1MA==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421609350", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            In addition, {slm-init } keeps track of policy successes and failures so you \n          \n          \n            \n            In addition, {slm-init} keeps track of policy successes and failures so you", "author": "jrodewig", "createdAt": "2020-05-07T15:49:11Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -62,66 +77,56 @@ PUT /_slm/policy/nightly-snapshots\n }\n --------------------------------------------------\n // TEST[continued]\n-<1> when the snapshot should be taken, using \n-    <<schedule-cron,Cron syntax>>, in this \n-    case at 1:30AM each day\n-<2> whe name each snapshot should be given, using \n-    <<date-math-index-names,date math>> to include the current date in the name\n-    of the snapshot\n-<3> the repository the snapshot should be stored in\n-<4> the configuration to be used for the snapshot requests (see below)\n-<5> which indices should be included in the snapshot, in this case, every index\n-<6> Optional retention configuration\n-<7> Keep snapshots for 30 days\n-<8> Always keep at least 5 successful snapshots\n-<9> Keep no more than 50 successful snapshots, even if they're less than 30 days old\n-\n-This policy will take a snapshot of every index each day at 1:30AM UTC.\n-Snapshots are incremental, allowing frequent snapshots to be stored efficiently,\n-so don't be afraid to configure a policy to take frequent snapshots.\n-\n-In addition to specifying the indices that should be included in the snapshot,\n-the `config` field can be used to customize other aspects of the snapshot. You\n-can use any option allowed in <<snapshots-take-snapshot,a regular snapshot \n-request>>, so you can specify, for example, whether the snapshot should fail in\n-special cases, such as if one of the specified indices cannot be found.\n+<1> When the snapshot should be taken in\n+    <<schedule-cron,Cron syntax>>: daily at 1:30AM UTC\n+<2> How to name the snapshot: use  \n+    <<date-math-index-names,date math>> to include the current date in the snapshot name\n+<3> Where to store the snapshot\n+<4> The configuration to be used for the snapshot requests (see below)\n+<5> Which indices to include in the snapshot: all indices\n+<6> Optional retention policy: keep snapshots for 30 days, \n+retaining at least 5 and no more than 50 snapshots regardless of age. \n+\n+You can specify additional snapshot configuration options to customize how snapshots are taken.\n+For example, you could configure the policy to fail the snapshot \n+if one of the specified indices is missing. \n+For more information about snapshot options, see <<snapshots-take-snapshot,snapshot requests>>.\n \n [float]\n [[slm-gs-test-policy]]\n ==== Test the snapshot policy\n \n-While snapshots taken by SLM policies can be viewed through the standard snapshot\n-API, SLM also keeps track of policy successes and failures in ways that are a bit\n-easier to use to make sure the policy is working.  Once a policy has executed at\n-least once, when you view the policy using the <<slm-api-get-policy>>, \n-some metadata will be returned indicating whether the snapshot was sucessfully \n-initiated or not.\n+A snapshot taken by {slm-init} is just like any other snapshot. \n+You can view information about snapshots in {kib} or get info with the snapshot APIs. \n+In addition, {slm-init } keeps track of policy successes and failures so you ", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYwOTg0OA==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421609848", "bodyText": "I typically define anchor text. You may want to see how this renders to ensure its not italicized.", "author": "jrodewig", "createdAt": "2020-05-07T15:49:52Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -62,66 +77,56 @@ PUT /_slm/policy/nightly-snapshots\n }\n --------------------------------------------------\n // TEST[continued]\n-<1> when the snapshot should be taken, using \n-    <<schedule-cron,Cron syntax>>, in this \n-    case at 1:30AM each day\n-<2> whe name each snapshot should be given, using \n-    <<date-math-index-names,date math>> to include the current date in the name\n-    of the snapshot\n-<3> the repository the snapshot should be stored in\n-<4> the configuration to be used for the snapshot requests (see below)\n-<5> which indices should be included in the snapshot, in this case, every index\n-<6> Optional retention configuration\n-<7> Keep snapshots for 30 days\n-<8> Always keep at least 5 successful snapshots\n-<9> Keep no more than 50 successful snapshots, even if they're less than 30 days old\n-\n-This policy will take a snapshot of every index each day at 1:30AM UTC.\n-Snapshots are incremental, allowing frequent snapshots to be stored efficiently,\n-so don't be afraid to configure a policy to take frequent snapshots.\n-\n-In addition to specifying the indices that should be included in the snapshot,\n-the `config` field can be used to customize other aspects of the snapshot. You\n-can use any option allowed in <<snapshots-take-snapshot,a regular snapshot \n-request>>, so you can specify, for example, whether the snapshot should fail in\n-special cases, such as if one of the specified indices cannot be found.\n+<1> When the snapshot should be taken in\n+    <<schedule-cron,Cron syntax>>: daily at 1:30AM UTC\n+<2> How to name the snapshot: use  \n+    <<date-math-index-names,date math>> to include the current date in the snapshot name\n+<3> Where to store the snapshot\n+<4> The configuration to be used for the snapshot requests (see below)\n+<5> Which indices to include in the snapshot: all indices\n+<6> Optional retention policy: keep snapshots for 30 days, \n+retaining at least 5 and no more than 50 snapshots regardless of age. \n+\n+You can specify additional snapshot configuration options to customize how snapshots are taken.\n+For example, you could configure the policy to fail the snapshot \n+if one of the specified indices is missing. \n+For more information about snapshot options, see <<snapshots-take-snapshot,snapshot requests>>.\n \n [float]\n [[slm-gs-test-policy]]\n ==== Test the snapshot policy\n \n-While snapshots taken by SLM policies can be viewed through the standard snapshot\n-API, SLM also keeps track of policy successes and failures in ways that are a bit\n-easier to use to make sure the policy is working.  Once a policy has executed at\n-least once, when you view the policy using the <<slm-api-get-policy>>, \n-some metadata will be returned indicating whether the snapshot was sucessfully \n-initiated or not.\n+A snapshot taken by {slm-init} is just like any other snapshot. \n+You can view information about snapshots in {kib} or get info with the snapshot APIs. \n+In addition, {slm-init } keeps track of policy successes and failures so you \n+have insight into how the policy is working. If the policy has executed at\n+least once, the <<slm-api-get-policy>> API returns additional metadata", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYxMDU4MA==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421610580", "bodyText": "I try to avoid using see for accessibility reasons.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            you will see the sucess or failure information if you retrieve the policy.\n          \n          \n            \n            you can retrieve the policy to get success or failure information.", "author": "jrodewig", "createdAt": "2020-05-07T15:50:56Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -62,66 +77,56 @@ PUT /_slm/policy/nightly-snapshots\n }\n --------------------------------------------------\n // TEST[continued]\n-<1> when the snapshot should be taken, using \n-    <<schedule-cron,Cron syntax>>, in this \n-    case at 1:30AM each day\n-<2> whe name each snapshot should be given, using \n-    <<date-math-index-names,date math>> to include the current date in the name\n-    of the snapshot\n-<3> the repository the snapshot should be stored in\n-<4> the configuration to be used for the snapshot requests (see below)\n-<5> which indices should be included in the snapshot, in this case, every index\n-<6> Optional retention configuration\n-<7> Keep snapshots for 30 days\n-<8> Always keep at least 5 successful snapshots\n-<9> Keep no more than 50 successful snapshots, even if they're less than 30 days old\n-\n-This policy will take a snapshot of every index each day at 1:30AM UTC.\n-Snapshots are incremental, allowing frequent snapshots to be stored efficiently,\n-so don't be afraid to configure a policy to take frequent snapshots.\n-\n-In addition to specifying the indices that should be included in the snapshot,\n-the `config` field can be used to customize other aspects of the snapshot. You\n-can use any option allowed in <<snapshots-take-snapshot,a regular snapshot \n-request>>, so you can specify, for example, whether the snapshot should fail in\n-special cases, such as if one of the specified indices cannot be found.\n+<1> When the snapshot should be taken in\n+    <<schedule-cron,Cron syntax>>: daily at 1:30AM UTC\n+<2> How to name the snapshot: use  \n+    <<date-math-index-names,date math>> to include the current date in the snapshot name\n+<3> Where to store the snapshot\n+<4> The configuration to be used for the snapshot requests (see below)\n+<5> Which indices to include in the snapshot: all indices\n+<6> Optional retention policy: keep snapshots for 30 days, \n+retaining at least 5 and no more than 50 snapshots regardless of age. \n+\n+You can specify additional snapshot configuration options to customize how snapshots are taken.\n+For example, you could configure the policy to fail the snapshot \n+if one of the specified indices is missing. \n+For more information about snapshot options, see <<snapshots-take-snapshot,snapshot requests>>.\n \n [float]\n [[slm-gs-test-policy]]\n ==== Test the snapshot policy\n \n-While snapshots taken by SLM policies can be viewed through the standard snapshot\n-API, SLM also keeps track of policy successes and failures in ways that are a bit\n-easier to use to make sure the policy is working.  Once a policy has executed at\n-least once, when you view the policy using the <<slm-api-get-policy>>, \n-some metadata will be returned indicating whether the snapshot was sucessfully \n-initiated or not.\n+A snapshot taken by {slm-init} is just like any other snapshot. \n+You can view information about snapshots in {kib} or get info with the snapshot APIs. \n+In addition, {slm-init } keeps track of policy successes and failures so you \n+have insight into how the policy is working. If the policy has executed at\n+least once, the <<slm-api-get-policy>> API returns additional metadata\n+that shows if the snapshot succeeded.\n+\n+You can manually execute a snapshot policy to take a snapshot immediately. \n+This is useful for taking snapshots before making a configuration change, \n+upgrading, or to test a new policy. \n+Manually executing a policy does not affect its configured schedule. \n \n-Instead of waiting for our policy to run, let's tell SLM to take a snapshot\n-as using the configuration from our policy right now instead of waiting for\n-1:30AM.\n+For example, the following request manually triggers the `nightly-snapshots` policy:\n \n [source,console]\n --------------------------------------------------\n POST /_slm/policy/nightly-snapshots/_execute\n --------------------------------------------------\n // TEST[skip:we can't easily handle snapshots from docs tests]\n \n-This request will kick off a snapshot for our policy right now, regardless of\n-the schedule in the policy. This is useful for taking snapshots before making \n-a configuration change, upgrading, or for our purposes, making sure our policy\n-is going to work successfully. The policy will continue to run on its configured\n-schedule after this execution of the policy.\n+\n+After forcing the `nightly-snapshots` policy to run, \n+you will see the sucess or failure information if you retrieve the policy.", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYxMDg5NA==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421610894", "bodyText": "I'd incorporate this with the above para. Kinda odd to have the info split over two paras with a snippet between.", "author": "jrodewig", "createdAt": "2020-05-07T15:51:24Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -62,66 +77,56 @@ PUT /_slm/policy/nightly-snapshots\n }\n --------------------------------------------------\n // TEST[continued]\n-<1> when the snapshot should be taken, using \n-    <<schedule-cron,Cron syntax>>, in this \n-    case at 1:30AM each day\n-<2> whe name each snapshot should be given, using \n-    <<date-math-index-names,date math>> to include the current date in the name\n-    of the snapshot\n-<3> the repository the snapshot should be stored in\n-<4> the configuration to be used for the snapshot requests (see below)\n-<5> which indices should be included in the snapshot, in this case, every index\n-<6> Optional retention configuration\n-<7> Keep snapshots for 30 days\n-<8> Always keep at least 5 successful snapshots\n-<9> Keep no more than 50 successful snapshots, even if they're less than 30 days old\n-\n-This policy will take a snapshot of every index each day at 1:30AM UTC.\n-Snapshots are incremental, allowing frequent snapshots to be stored efficiently,\n-so don't be afraid to configure a policy to take frequent snapshots.\n-\n-In addition to specifying the indices that should be included in the snapshot,\n-the `config` field can be used to customize other aspects of the snapshot. You\n-can use any option allowed in <<snapshots-take-snapshot,a regular snapshot \n-request>>, so you can specify, for example, whether the snapshot should fail in\n-special cases, such as if one of the specified indices cannot be found.\n+<1> When the snapshot should be taken in\n+    <<schedule-cron,Cron syntax>>: daily at 1:30AM UTC\n+<2> How to name the snapshot: use  \n+    <<date-math-index-names,date math>> to include the current date in the snapshot name\n+<3> Where to store the snapshot\n+<4> The configuration to be used for the snapshot requests (see below)\n+<5> Which indices to include in the snapshot: all indices\n+<6> Optional retention policy: keep snapshots for 30 days, \n+retaining at least 5 and no more than 50 snapshots regardless of age. \n+\n+You can specify additional snapshot configuration options to customize how snapshots are taken.\n+For example, you could configure the policy to fail the snapshot \n+if one of the specified indices is missing. \n+For more information about snapshot options, see <<snapshots-take-snapshot,snapshot requests>>.\n \n [float]\n [[slm-gs-test-policy]]\n ==== Test the snapshot policy\n \n-While snapshots taken by SLM policies can be viewed through the standard snapshot\n-API, SLM also keeps track of policy successes and failures in ways that are a bit\n-easier to use to make sure the policy is working.  Once a policy has executed at\n-least once, when you view the policy using the <<slm-api-get-policy>>, \n-some metadata will be returned indicating whether the snapshot was sucessfully \n-initiated or not.\n+A snapshot taken by {slm-init} is just like any other snapshot. \n+You can view information about snapshots in {kib} or get info with the snapshot APIs. \n+In addition, {slm-init } keeps track of policy successes and failures so you \n+have insight into how the policy is working. If the policy has executed at\n+least once, the <<slm-api-get-policy>> API returns additional metadata\n+that shows if the snapshot succeeded.\n+\n+You can manually execute a snapshot policy to take a snapshot immediately. \n+This is useful for taking snapshots before making a configuration change, \n+upgrading, or to test a new policy. \n+Manually executing a policy does not affect its configured schedule. \n \n-Instead of waiting for our policy to run, let's tell SLM to take a snapshot\n-as using the configuration from our policy right now instead of waiting for\n-1:30AM.\n+For example, the following request manually triggers the `nightly-snapshots` policy:\n \n [source,console]\n --------------------------------------------------\n POST /_slm/policy/nightly-snapshots/_execute\n --------------------------------------------------\n // TEST[skip:we can't easily handle snapshots from docs tests]\n \n-This request will kick off a snapshot for our policy right now, regardless of\n-the schedule in the policy. This is useful for taking snapshots before making \n-a configuration change, upgrading, or for our purposes, making sure our policy\n-is going to work successfully. The policy will continue to run on its configured\n-schedule after this execution of the policy.\n+\n+After forcing the `nightly-snapshots` policy to run, \n+you will see the sucess or failure information if you retrieve the policy.\n \n [source,console]\n --------------------------------------------------\n GET /_slm/policy/nightly-snapshots?human\n --------------------------------------------------\n // TEST[continued]\n \n-This request will return a response that includes the policy, as well as\n-information about the last time the policy succeeded and failed, as well as the\n-next time the policy will be executed.\n+The response also shows when the policy is scheduled to execute next:", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYxMTU3Ng==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421611576", "bodyText": "I don't think this is needed if we link the APIs inline.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            For more information about using the APIs directly, \n          \n          \n            \n            see the <<snapshot-lifecycle-management-api,{slm-init] API documentation>>.", "author": "jrodewig", "createdAt": "2020-05-07T15:52:23Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -143,44 +148,33 @@ next time the policy will be executed.\n         \"max_count\": 50\n       }\n     },\n-    \"last_success\": { <1>\n-      \"snapshot_name\": \"nightly-snap-2019.04.24-tmtnyjtrsxkhbrrdcgg18a\", <2>\n-      \"time_string\": \"2019-04-24T16:43:49.316Z\",\n+    \"last_success\": { \n+      \"snapshot_name\": \"nightly-snap-2019.04.24-tmtnyjtrsxkhbrrdcgg18a\", <1>\n+      \"time_string\": \"2019-04-24T16:43:49.316Z\", <2>\n       \"time\": 1556124229316\n     } ,\n-    \"last_failure\": { <3>\n-      \"snapshot_name\": \"nightly-snap-2019.04.02-lohisb5ith2n8hxacaq3mw\",\n-      \"time_string\": \"2019-04-02T01:30:00.000Z\",\n-      \"time\": 1556042030000,\n-      \"details\": \"{\\\"type\\\":\\\"index_not_found_exception\\\",\\\"reason\\\":\\\"no such index [important]\\\",\\\"resource.type\\\":\\\"index_or_alias\\\",\\\"resource.id\\\":\\\"important\\\",\\\"index_uuid\\\":\\\"_na_\\\",\\\"index\\\":\\\"important\\\",\\\"stack_trace\\\":\\\"[important] IndexNotFoundException[no such index [important]]\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.indexNotFoundException(IndexNameExpressionResolver.java:762)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.innerResolve(IndexNameExpressionResolver.java:714)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.resolve(IndexNameExpressionResolver.java:670)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:163)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndexNames(IndexNameExpressionResolver.java:142)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndexNames(IndexNameExpressionResolver.java:102)\\\\n\\\\tat org.elasticsearch.snapshots.SnapshotsService$1.execute(SnapshotsService.java:280)\\\\n\\\\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\\\\n\\\\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\\\\n\\\\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\\\\n\\\\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\\\\n\\\\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\\\\n\\\\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\\\\n\\\\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\\\\n\\\\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:688)\\\\n\\\\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\\\\n\\\\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\\\\n\\\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\\\n\\\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\\\n\\\\tat java.base/java.lang.Thread.run(Thread.java:834)\\\\n\\\"}\"\n-    } ,\n-    \"next_execution\": \"2019-04-24T01:30:00.000Z\", <4>\n-    \"next_execution_millis\": 1556048160000\n+    \"next_execution\": \"2019-04-24T01:30:00.000Z\", <3>\n+    \"next_execution_millis\": 1556048160000 \n   }\n }\n --------------------------------------------------\n // TESTRESPONSE[skip:the presence of last_failure and last_success is asynchronous and will be present for users, but is untestable]\n \n-<1> information about the last time the policy successfully initated a snapshot\n-<2> the name of the snapshot that was successfully initiated\n-<3> information about the last time the policy failed to initiate a snapshot\n-<4> the next time the policy will execute\n+<1> The name of the last snapshot that was succesfully initiated by the policy\n+<2> When the snapshot was initiated\n+<3> When the policy will initiate the next snapshot\n \n-NOTE: This metadata only indicates whether the request to initiate the snapshot was\n-made successfully or not - after the snapshot has been successfully started, it\n-is possible for the snapshot to fail if, for example, the connection to a remote\n+The response shows if the policy succeeded in _initiating_ a snapshot.\n+However, that does not guarantee that the snapshot completed successfully. \n+It is possible for the initiated snapshot to fail if, for example, the connection to a remote\n repository is lost while copying files.\n \n-If you're following along, the returned SLM policy shouldn't have a `last_failure`\n-field - it's included above only as an example. You should, however, see a \n-`last_success` field and a snapshot name. If you do, you've successfully taken\n-your first snapshot using SLM!\n-\n-While only the most recent sucess and failure are available through the Get Policy \n-API, all policy executions are recorded to a history index, which may be queried\n-by searching the index pattern `.slm-history*`.\n+Only the most recent success and failure are returned, \n+but all policy executions are recorded in the `.slm-history*` index.\n \n-That's it! We have our first SLM policy set up to periodically take snapshots\n-so that our backups are always up to date. You can read more details in the \n-<<snapshot-lifecycle-management-api,SLM API documentation>> and the\n-<<modules-snapshots,general snapshot documentation.>>\n+For more information about using {kib} to set up and manage snapshot policies, \n+see {kibana-ref}/snapshot-repositories.html[Snapshot and Restore]. \n+For more information about using the APIs directly, \n+see the <<snapshot-lifecycle-management-api,{slm-init] API documentation>>.", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYxMTgzMA==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421611830", "bodyText": "I'd probably move this up higher. Maybe a tip at the beginning?", "author": "jrodewig", "createdAt": "2020-05-07T15:52:41Z", "path": "docs/reference/slm/getting-started-slm.asciidoc", "diffHunk": "@@ -143,44 +148,33 @@ next time the policy will be executed.\n         \"max_count\": 50\n       }\n     },\n-    \"last_success\": { <1>\n-      \"snapshot_name\": \"nightly-snap-2019.04.24-tmtnyjtrsxkhbrrdcgg18a\", <2>\n-      \"time_string\": \"2019-04-24T16:43:49.316Z\",\n+    \"last_success\": { \n+      \"snapshot_name\": \"nightly-snap-2019.04.24-tmtnyjtrsxkhbrrdcgg18a\", <1>\n+      \"time_string\": \"2019-04-24T16:43:49.316Z\", <2>\n       \"time\": 1556124229316\n     } ,\n-    \"last_failure\": { <3>\n-      \"snapshot_name\": \"nightly-snap-2019.04.02-lohisb5ith2n8hxacaq3mw\",\n-      \"time_string\": \"2019-04-02T01:30:00.000Z\",\n-      \"time\": 1556042030000,\n-      \"details\": \"{\\\"type\\\":\\\"index_not_found_exception\\\",\\\"reason\\\":\\\"no such index [important]\\\",\\\"resource.type\\\":\\\"index_or_alias\\\",\\\"resource.id\\\":\\\"important\\\",\\\"index_uuid\\\":\\\"_na_\\\",\\\"index\\\":\\\"important\\\",\\\"stack_trace\\\":\\\"[important] IndexNotFoundException[no such index [important]]\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.indexNotFoundException(IndexNameExpressionResolver.java:762)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.innerResolve(IndexNameExpressionResolver.java:714)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver$WildcardExpressionResolver.resolve(IndexNameExpressionResolver.java:670)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndices(IndexNameExpressionResolver.java:163)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndexNames(IndexNameExpressionResolver.java:142)\\\\n\\\\tat org.elasticsearch.cluster.metadata.IndexNameExpressionResolver.concreteIndexNames(IndexNameExpressionResolver.java:102)\\\\n\\\\tat org.elasticsearch.snapshots.SnapshotsService$1.execute(SnapshotsService.java:280)\\\\n\\\\tat org.elasticsearch.cluster.ClusterStateUpdateTask.execute(ClusterStateUpdateTask.java:47)\\\\n\\\\tat org.elasticsearch.cluster.service.MasterService.executeTasks(MasterService.java:687)\\\\n\\\\tat org.elasticsearch.cluster.service.MasterService.calculateTaskOutputs(MasterService.java:310)\\\\n\\\\tat org.elasticsearch.cluster.service.MasterService.runTasks(MasterService.java:210)\\\\n\\\\tat org.elasticsearch.cluster.service.MasterService$Batcher.run(MasterService.java:142)\\\\n\\\\tat org.elasticsearch.cluster.service.TaskBatcher.runIfNotProcessed(TaskBatcher.java:150)\\\\n\\\\tat org.elasticsearch.cluster.service.TaskBatcher$BatchedTask.run(TaskBatcher.java:188)\\\\n\\\\tat org.elasticsearch.common.util.concurrent.ThreadContext$ContextPreservingRunnable.run(ThreadContext.java:688)\\\\n\\\\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:252)\\\\n\\\\tat org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:215)\\\\n\\\\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\\\\n\\\\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\\\\n\\\\tat java.base/java.lang.Thread.run(Thread.java:834)\\\\n\\\"}\"\n-    } ,\n-    \"next_execution\": \"2019-04-24T01:30:00.000Z\", <4>\n-    \"next_execution_millis\": 1556048160000\n+    \"next_execution\": \"2019-04-24T01:30:00.000Z\", <3>\n+    \"next_execution_millis\": 1556048160000 \n   }\n }\n --------------------------------------------------\n // TESTRESPONSE[skip:the presence of last_failure and last_success is asynchronous and will be present for users, but is untestable]\n \n-<1> information about the last time the policy successfully initated a snapshot\n-<2> the name of the snapshot that was successfully initiated\n-<3> information about the last time the policy failed to initiate a snapshot\n-<4> the next time the policy will execute\n+<1> The name of the last snapshot that was succesfully initiated by the policy\n+<2> When the snapshot was initiated\n+<3> When the policy will initiate the next snapshot\n \n-NOTE: This metadata only indicates whether the request to initiate the snapshot was\n-made successfully or not - after the snapshot has been successfully started, it\n-is possible for the snapshot to fail if, for example, the connection to a remote\n+The response shows if the policy succeeded in _initiating_ a snapshot.\n+However, that does not guarantee that the snapshot completed successfully. \n+It is possible for the initiated snapshot to fail if, for example, the connection to a remote\n repository is lost while copying files.\n \n-If you're following along, the returned SLM policy shouldn't have a `last_failure`\n-field - it's included above only as an example. You should, however, see a \n-`last_success` field and a snapshot name. If you do, you've successfully taken\n-your first snapshot using SLM!\n-\n-While only the most recent sucess and failure are available through the Get Policy \n-API, all policy executions are recorded to a history index, which may be queried\n-by searching the index pattern `.slm-history*`.\n+Only the most recent success and failure are returned, \n+but all policy executions are recorded in the `.slm-history*` index.\n \n-That's it! We have our first SLM policy set up to periodically take snapshots\n-so that our backups are always up to date. You can read more details in the \n-<<snapshot-lifecycle-management-api,SLM API documentation>> and the\n-<<modules-snapshots,general snapshot documentation.>>\n+For more information about using {kib} to set up and manage snapshot policies, \n+see {kibana-ref}/snapshot-repositories.html[Snapshot and Restore]. ", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYxMjQwNQ==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421612405", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Retention runs as a cluster level task and is not associated with a particular policy's schedule.\n          \n          \n            \n            Retention runs as a cluster-level task and is not associated with a particular policy's schedule.", "author": "jrodewig", "createdAt": "2020-05-07T15:53:30Z", "path": "docs/reference/slm/slm-retention.asciidoc", "diffHunk": "@@ -3,30 +3,31 @@\n [[slm-retention]]\n === Snapshot retention\n \n-Automatic deletion of older snapshots is an optional feature of snapshot lifecycle management.\n-Retention is run as a cluster level task that is not associated with a particular policy's schedule\n-(though the configuration of which snapshots to keep is done on a per-policy basis). Retention\n-configuration consists of two parts\u2014The first a cluster-level configuration for when retention is\n-run and for how long, the second configured on a policy for which snapshots should be eligible for\n-retention.\n+You can include a retention policy in an {slm-init} policy to automatically delete old snapshots. \n+Retention runs as a cluster level task and is not associated with a particular policy's schedule.", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYxMjY1MA==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421612650", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            you need to include a  <<slm-api-put-retention,`retention`>> object in your {slm-init} policy.\n          \n          \n            \n            you need to include a <<slm-api-put-retention,`retention`>> object in your {slm-init} policy.", "author": "jrodewig", "createdAt": "2020-05-07T15:53:50Z", "path": "docs/reference/slm/slm-retention.asciidoc", "diffHunk": "@@ -3,30 +3,31 @@\n [[slm-retention]]\n === Snapshot retention\n \n-Automatic deletion of older snapshots is an optional feature of snapshot lifecycle management.\n-Retention is run as a cluster level task that is not associated with a particular policy's schedule\n-(though the configuration of which snapshots to keep is done on a per-policy basis). Retention\n-configuration consists of two parts\u2014The first a cluster-level configuration for when retention is\n-run and for how long, the second configured on a policy for which snapshots should be eligible for\n-retention.\n+You can include a retention policy in an {slm-init} policy to automatically delete old snapshots. \n+Retention runs as a cluster level task and is not associated with a particular policy's schedule.\n+The retention criteria are evaluated as part of the retention task, not when the policy executes.\n+For the retention task to automatically delete snapshots, \n+you need to include a  <<slm-api-put-retention,`retention`>> object in your {slm-init} policy.", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYxMzAyMw==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421613023", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The <<slm-retention-duration>>`slm.retention_duration`>> setting limits how long \n          \n          \n            \n            The <<slm-retention-duration,`slm.retention_duration`>> setting limits how long", "author": "jrodewig", "createdAt": "2020-05-07T15:54:20Z", "path": "docs/reference/slm/slm-retention.asciidoc", "diffHunk": "@@ -3,30 +3,31 @@\n [[slm-retention]]\n === Snapshot retention\n \n-Automatic deletion of older snapshots is an optional feature of snapshot lifecycle management.\n-Retention is run as a cluster level task that is not associated with a particular policy's schedule\n-(though the configuration of which snapshots to keep is done on a per-policy basis). Retention\n-configuration consists of two parts\u2014The first a cluster-level configuration for when retention is\n-run and for how long, the second configured on a policy for which snapshots should be eligible for\n-retention.\n+You can include a retention policy in an {slm-init} policy to automatically delete old snapshots. \n+Retention runs as a cluster level task and is not associated with a particular policy's schedule.\n+The retention criteria are evaluated as part of the retention task, not when the policy executes.\n+For the retention task to automatically delete snapshots, \n+you need to include a  <<slm-api-put-retention,`retention`>> object in your {slm-init} policy.\n \n-The cluster level settings for retention are shown below, and can be changed dynamically using the\n-<<cluster-update-settings>> API:\n+To control when the retention task runs, configure \n+<<slm-retention-schedule,`slm.retention_schedule`>> in the cluster settings.\n+You can define the schedule as a periodic or absolute <<schedule-cron,cron schedule>.\n+The <<slm-retention-duration>>`slm.retention_duration`>> setting limits how long ", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYxMzMyNg==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421613326", "bodyText": "Same note here about checking for italicized rendering.", "author": "jrodewig", "createdAt": "2020-05-07T15:54:44Z", "path": "docs/reference/slm/slm-retention.asciidoc", "diffHunk": "@@ -3,30 +3,31 @@\n [[slm-retention]]\n === Snapshot retention\n \n-Automatic deletion of older snapshots is an optional feature of snapshot lifecycle management.\n-Retention is run as a cluster level task that is not associated with a particular policy's schedule\n-(though the configuration of which snapshots to keep is done on a per-policy basis). Retention\n-configuration consists of two parts\u2014The first a cluster-level configuration for when retention is\n-run and for how long, the second configured on a policy for which snapshots should be eligible for\n-retention.\n+You can include a retention policy in an {slm-init} policy to automatically delete old snapshots. \n+Retention runs as a cluster level task and is not associated with a particular policy's schedule.\n+The retention criteria are evaluated as part of the retention task, not when the policy executes.\n+For the retention task to automatically delete snapshots, \n+you need to include a  <<slm-api-put-retention,`retention`>> object in your {slm-init} policy.\n \n-The cluster level settings for retention are shown below, and can be changed dynamically using the\n-<<cluster-update-settings>> API:\n+To control when the retention task runs, configure \n+<<slm-retention-schedule,`slm.retention_schedule`>> in the cluster settings.\n+You can define the schedule as a periodic or absolute <<schedule-cron,cron schedule>.\n+The <<slm-retention-duration>>`slm.retention_duration`>> setting limits how long \n+{slm-init} should spend deleting old snapshots.\n \n-|=====================================\n-| Setting | Default value | Description\n+You can update the schedule and duration dynamically with the <<cluster-update-settings>> API.\n+You can run the retention task manually with the <<slm-api-execute-retention>> API. ", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTYxMzU4MQ==", "url": "https://github.com/elastic/elasticsearch/pull/55953#discussion_r421613581", "bodyText": "Check for italicized rendering.", "author": "jrodewig", "createdAt": "2020-05-07T15:55:06Z", "path": "docs/reference/slm/slm-retention.asciidoc", "diffHunk": "@@ -3,30 +3,31 @@\n [[slm-retention]]\n === Snapshot retention\n \n-Automatic deletion of older snapshots is an optional feature of snapshot lifecycle management.\n-Retention is run as a cluster level task that is not associated with a particular policy's schedule\n-(though the configuration of which snapshots to keep is done on a per-policy basis). Retention\n-configuration consists of two parts\u2014The first a cluster-level configuration for when retention is\n-run and for how long, the second configured on a policy for which snapshots should be eligible for\n-retention.\n+You can include a retention policy in an {slm-init} policy to automatically delete old snapshots. \n+Retention runs as a cluster level task and is not associated with a particular policy's schedule.\n+The retention criteria are evaluated as part of the retention task, not when the policy executes.\n+For the retention task to automatically delete snapshots, \n+you need to include a  <<slm-api-put-retention,`retention`>> object in your {slm-init} policy.\n \n-The cluster level settings for retention are shown below, and can be changed dynamically using the\n-<<cluster-update-settings>> API:\n+To control when the retention task runs, configure \n+<<slm-retention-schedule,`slm.retention_schedule`>> in the cluster settings.\n+You can define the schedule as a periodic or absolute <<schedule-cron,cron schedule>.\n+The <<slm-retention-duration>>`slm.retention_duration`>> setting limits how long \n+{slm-init} should spend deleting old snapshots.\n \n-|=====================================\n-| Setting | Default value | Description\n+You can update the schedule and duration dynamically with the <<cluster-update-settings>> API.\n+You can run the retention task manually with the <<slm-api-execute-retention>> API. \n \n-| `slm.retention_schedule` | `0 30 1 * * ?` | A periodic or absolute time schedule for when\n-  retention should be run. Supports all values supported by the cron scheduler: <<schedule-cron,Cron\n-  scheduler configuration>>. Retention can also be manually run using the\n-  <<slm-api-execute-retention>> API. Defaults to daily at 1:30am UTC.\n+The retention task only considers snapshots initiated through {slm-init} policies,  \n+either according to the policy schedule or through the <<slm-api-execute-lifecycle>> API. ", "originalCommit": "3907f824e1bb9f7360971166403ed5bdb4349567", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "6b2b6fed925843cdf82f9584237a74ef9c4fbb28", "url": "https://github.com/elastic/elasticsearch/commit/6b2b6fed925843cdf82f9584237a74ef9c4fbb28", "message": "Apply suggestions from code review\n\nCo-authored-by: James Rodewig <james.rodewig@elastic.co>\nCo-authored-by: Lee Hinman <dakrone@users.noreply.github.com>", "committedDate": "2020-05-07T20:43:24Z", "type": "commit"}, {"oid": "71ad5153f34a609624df749e9aab9dee30440f0c", "url": "https://github.com/elastic/elasticsearch/commit/71ad5153f34a609624df749e9aab9dee30440f0c", "message": "Incorporated review comments.", "committedDate": "2020-05-07T22:20:01Z", "type": "commit"}, {"oid": "6133d07d4949ca10acf5f2d91747127ae8844387", "url": "https://github.com/elastic/elasticsearch/commit/6133d07d4949ca10acf5f2d91747127ae8844387", "message": "Fixed plugins xref", "committedDate": "2020-05-07T23:13:31Z", "type": "commit"}, {"oid": "1b0f976947c1e637fbee01dc655d052296489334", "url": "https://github.com/elastic/elasticsearch/commit/1b0f976947c1e637fbee01dc655d052296489334", "message": "Final cleanup", "committedDate": "2020-05-08T00:32:58Z", "type": "commit"}, {"oid": "34387abc0a8d4738fdb57c06105eeffd720a10a2", "url": "https://github.com/elastic/elasticsearch/commit/34387abc0a8d4738fdb57c06105eeffd720a10a2", "message": "edit", "committedDate": "2020-05-08T00:53:48Z", "type": "commit"}]}