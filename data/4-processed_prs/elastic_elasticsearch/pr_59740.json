{"pr_number": 59740, "pr_title": "Allocate slightly less per bucket", "pr_createdAt": "2020-07-16T23:35:37Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/59740", "timeline": [{"oid": "d92157c4fbe61309599374e9ed57bafb5373859d", "url": "https://github.com/elastic/elasticsearch/commit/d92157c4fbe61309599374e9ed57bafb5373859d", "message": "Replace legoed data structure", "committedDate": "2020-07-16T21:13:01Z", "type": "commit"}, {"oid": "3a40a47ab37f22d2ca17cb67eac09ca03a367843", "url": "https://github.com/elastic/elasticsearch/commit/3a40a47ab37f22d2ca17cb67eac09ca03a367843", "message": "Try compacting keys", "committedDate": "2020-07-16T21:23:39Z", "type": "commit"}, {"oid": "8ccc652ae6d1c70b525c5cac2d950f664decefad", "url": "https://github.com/elastic/elasticsearch/commit/8ccc652ae6d1c70b525c5cac2d950f664decefad", "message": "Reverse", "committedDate": "2020-07-16T22:43:01Z", "type": "commit"}, {"oid": "0cbe92fc4134008c4922bc808b139804345bdde8", "url": "https://github.com/elastic/elasticsearch/commit/0cbe92fc4134008c4922bc808b139804345bdde8", "message": "Nope", "committedDate": "2020-07-16T23:25:10Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyMTE5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/59740#discussion_r456521191", "bodyText": "is this meant to be used?", "author": "talevy", "createdAt": "2020-07-17T15:39:43Z", "path": "server/src/main/java/org/elasticsearch/common/util/LongLongHash.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.common.util;\n+\n+import com.carrotsearch.hppc.BitMixer;\n+\n+import org.elasticsearch.common.lease.Releasables;\n+\n+/**\n+ * Specialized hash table implementation similar to BytesRefHash that maps\n+ * two long values to ids. Collisions are resolved with open addressing and\n+ * linear probing, growth is smooth thanks to {@link BigArrays} and capacity\n+ * is always a multiple of 2 for faster identification of buckets.\n+ * This class is not thread-safe.\n+ */\n+// IDs are internally stored as id + 1 so that 0 encodes for an empty slot\n+public final class LongLongHash extends AbstractHash {\n+    /**\n+     * The keys of the hash, stored one after another. So the keys for an id\n+     * are stored in {@code 2 * id} and {@code 2 * id + 1}. This arrangement\n+     * makes {@link #add(long, long)} about 17% faster which seems worth it\n+     * because it is in the critical path for aggregations.\n+     */\n+    private LongArray keys;\n+\n+    // Constructor with configurable capacity and default maximum load factor.\n+    public LongLongHash(long capacity, BigArrays bigArrays) {\n+        this(capacity, DEFAULT_MAX_LOAD_FACTOR, bigArrays);\n+    }\n+\n+    //Constructor with configurable capacity and load factor.\n+    public LongLongHash(long capacity, float maxLoadFactor, BigArrays bigArrays) {\n+        super(capacity, maxLoadFactor, bigArrays);\n+        keys = bigArrays.newLongArray(2 * capacity, false);\n+    }\n+\n+    /**\n+     * Return the first key at {@code 0 &lt;= index &lt;= capacity()}. The\n+     * result is undefined if the slot is unused.\n+     */\n+    public long getKey1(long id) {\n+        return keys.get(2 * id);\n+    }\n+\n+    /**\n+     * Return the second key at {@code 0 &lt;= index &lt;= capacity()}. The\n+     * result is undefined if the slot is unused.\n+     */\n+    public long getKey2(long id) {\n+        return keys.get(2 * id + 1);\n+    }\n+\n+    /**\n+     * Get the id associated with <code>key</code> or -1 if the key is not contained in the hash.\n+     */\n+    public long find(long key1, long key2) {\n+        final long slot = slot(hash(key1, key2), mask);\n+        for (long index = slot; ; index = nextSlot(index, mask)) {\n+            final long id = id(index);\n+            long keyOffset = 2 * id;\n+            if (id == -1 || (keys.get(keyOffset) == key1 && keys.get(keyOffset + 1) == key2)) {\n+                return id;\n+            }\n+        }\n+    }\n+\n+    private long set(long key1, long key2, long id) {\n+        assert size < maxSize;\n+        final long slot = slot(hash(key1, key2), mask);\n+        for (long index = slot; ; index = nextSlot(index, mask)) {\n+            final long curId = id(index);\n+            if (curId == -1) { // means unset\n+                id(index, id);\n+                append(id, key1, key2);\n+                ++size;\n+                return id;\n+            } else {\n+                long keyOffset = 2 * curId;\n+                if (keys.get(keyOffset) == key1 && keys.get(keyOffset + 1) == key2) {\n+                    return -1 - curId;\n+                }\n+            }\n+        }\n+    }\n+\n+    private void append(long id, long key1, long key2) {\n+        long keyOffset = 2 * id;\n+        keys = bigArrays.grow(keys, keyOffset + 2);\n+        keys.set(keyOffset, key1);\n+        keys.set(keyOffset + 1, key2);\n+    }\n+\n+    private void reset(long key1, long key2, long id) {\n+        final long slot = slot(hash(key1, key2), mask);\n+        for (long index = slot; ; index = nextSlot(index, mask)) {\n+            final long curId = id(index);\n+            if (curId == -1) { // means unset\n+                id(index, id);\n+                append(id, key1, key2);\n+                break;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Try to add {@code key}. Return its newly allocated id if it wasn't in\n+     * the hash table yet, or {@code -1-id} if it was already present in\n+     * the hash table.\n+     */\n+    public long add(long key1, long key2) {\n+        if (size >= maxSize) {\n+            assert size == maxSize;\n+            grow();\n+        }\n+        assert size < maxSize;\n+        return set(key1, key2, size);\n+    }\n+\n+    @Override\n+    protected void removeAndAdd(long index) {", "originalCommit": "0cbe92fc4134008c4922bc808b139804345bdde8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyODk4NA==", "url": "https://github.com/elastic/elasticsearch/pull/59740#discussion_r456528984", "bodyText": "woops. this is a part of the overriding. nevermind!", "author": "talevy", "createdAt": "2020-07-17T15:53:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyMTE5MQ=="}], "type": "inlineReview"}]}