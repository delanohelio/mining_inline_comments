{"pr_number": 63040, "pr_title": "[DOCS] Add searchable snapshots topic.", "pr_createdAt": "2020-09-30T01:03:57Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/63040", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQyNjkzNA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r497426934", "bodyText": "I believe this option is part of our future plans, but not yet available.", "author": "henningandersen", "createdAt": "2020-09-30T11:10:27Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,31 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+{search-snaps-cap} enable you to significantly reduce costs by \n+leveraging external storage for read-only data. \n+Searchable snapshots can be used in two ways:\n+\n+* Snapshot-backed indices: Instead of maintaining replicas of your data within the cluster, \n+a snapshot-backed index relies on a searchable snapshot for redundancy. \n+You can perform all regular data retrieval operations, but cannot write to the index. \n+In the event of a failure, data is recovered from the snapshot. \n+Latency increases during recovery, but you can continue to query your data.\n+\n+* Fully-remote storage: Data is only brought into the cluster from the snapshot \n+when it is needed to service a query. \n+Because of the additional overhead, querying your data takes significantly longer \n+and it\u2019s only accessible via asynchronous search.", "originalCommit": "9e4b6e447da4b7220936c64b02a0ceac09be272d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzQyODQyOQ==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r497428429", "bodyText": "Maybe add that searchable snapshots are eagerly downloaded and once fully downloaded, search performance against searchable snapshots will be similar to search performance against a regular index.", "author": "henningandersen", "createdAt": "2020-09-30T11:13:28Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,31 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+{search-snaps-cap} enable you to significantly reduce costs by \n+leveraging external storage for read-only data. \n+Searchable snapshots can be used in two ways:\n+\n+* Snapshot-backed indices: Instead of maintaining replicas of your data within the cluster, \n+a snapshot-backed index relies on a searchable snapshot for redundancy. \n+You can perform all regular data retrieval operations, but cannot write to the index. \n+In the event of a failure, data is recovered from the snapshot. \n+Latency increases during recovery, but you can continue to query your data.", "originalCommit": "9e4b6e447da4b7220936c64b02a0ceac09be272d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "fef25ccd03172e7892f736efb6159a6dd57dc4df", "url": "https://github.com/elastic/elasticsearch/commit/fef25ccd03172e7892f736efb6159a6dd57dc4df", "message": "[DOCS] Add searchable snapshots topic.", "committedDate": "2020-10-02T00:52:48Z", "type": "commit"}, {"oid": "b12246894f9b11b7634b26732b0bfa571090b95e", "url": "https://github.com/elastic/elasticsearch/commit/b12246894f9b11b7634b26732b0bfa571090b95e", "message": "[DOCS] Add definitions & remove fully-remote storage.", "committedDate": "2020-10-02T00:52:48Z", "type": "commit"}, {"oid": "df1d881e9390e91b9df9f5b334d4984a948565ae", "url": "https://github.com/elastic/elasticsearch/commit/df1d881e9390e91b9df9f5b334d4984a948565ae", "message": "[DOCS] Fixed duplicate anchor.", "committedDate": "2020-10-02T00:52:48Z", "type": "commit"}, {"oid": "df1d881e9390e91b9df9f5b334d4984a948565ae", "url": "https://github.com/elastic/elasticsearch/commit/df1d881e9390e91b9df9f5b334d4984a948565ae", "message": "[DOCS] Fixed duplicate anchor.", "committedDate": "2020-10-02T00:52:48Z", "type": "forcePushed"}, {"oid": "d4292ecd073d2fd387b7b7765e9e083684c500e7", "url": "https://github.com/elastic/elasticsearch/commit/d4292ecd073d2fd387b7b7765e9e083684c500e7", "message": "Expand conceptual docs for searchable snapshots", "committedDate": "2020-10-16T09:41:40Z", "type": "commit"}, {"oid": "003bb24ffbd547ed37d86e9a8d41442727010385", "url": "https://github.com/elastic/elasticsearch/commit/003bb24ffbd547ed37d86e9a8d41442727010385", "message": "Rewordings", "committedDate": "2020-10-16T10:11:37Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzYyNTEzNw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r507625137", "bodyText": "This looks like it is only referenced from the glossary itself and I wonder if introducing this terminology is necessary? I think I would prefer to only have \"snapshot\" and perhaps explain the explanation there a little.", "author": "henningandersen", "createdAt": "2020-10-19T10:03:29Z", "path": "docs/reference/glossary.asciidoc", "diffHunk": "@@ -39,6 +39,12 @@ An <<glossary-index-pattern,index pattern>> that automatically configures new in\n For more information, see {ref}/ccr-auto-follow.html[Managing auto follow patterns].\n // end::auto-follow-pattern-def[]\n \n+[[glossary-backup-snapshot]] backup snapshot ::", "originalCommit": "003bb24ffbd547ed37d86e9a8d41442727010385", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODMyNzMyMw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508327323", "bodyText": "++ I removed this in c026c9f.", "author": "DaveCTurner", "createdAt": "2020-10-20T08:56:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzYyNTEzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY3MDk4Mw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r507670983", "bodyText": "their seems wrong, did you mean the?", "author": "henningandersen", "createdAt": "2020-10-19T11:26:28Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,108 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore,snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of their data in", "originalCommit": "003bb24ffbd547ed37d86e9a8d41442727010385", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODMyODczNA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508328734", "bodyText": "I meant their (as in \"belonging to the indices\") but it's awkward. Reworded in 29402a5", "author": "DaveCTurner", "createdAt": "2020-10-20T08:58:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY3MDk4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY3MjQ3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r507672479", "bodyText": "I wonder if we are here framing searchable snapshots as being slow, which is not necessarily the case. I think I get that the time span of the search will be large and this adds to query time, hence async search is necessary, but I would like to move that to the meat of the section more than this introducing paragraph.", "author": "henningandersen", "createdAt": "2020-10-19T11:29:18Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,108 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore,snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of their data in\n+your cluster purely for resiliency. {es} makes a copy of a searchable snapshot\n+on the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps-cap} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps-cap} may allow you to expose twice as\n+much data to searches for a given cluster size.\n+\n+=== Using searchable snapshots\n+\n+A searchable snapshot can be searched just like any other index.\n+{search-snaps-cap} are often used to access a large archive of historical data,\n+for which searches may sometimes be complex and time-consuming.", "originalCommit": "003bb24ffbd547ed37d86e9a8d41442727010385", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODMzMDc1Nw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508330757", "bodyText": "I was trying not to, but yes it still suggests slowness. I moved this to a TIP in 8beb64b and replaced this sentence with one indicating that performance should be similar to a regular index.", "author": "DaveCTurner", "createdAt": "2020-10-20T09:01:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY3MjQ3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY3MzA4Mg==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r507673082", "bodyText": "\"use\" implies \"search\" in my head, I would prefer to say \"create\" or \"mount\" here?", "author": "henningandersen", "createdAt": "2020-10-19T11:30:19Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,108 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore,snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of their data in\n+your cluster purely for resiliency. {es} makes a copy of a searchable snapshot\n+on the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps-cap} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps-cap} may allow you to expose twice as\n+much data to searches for a given cluster size.\n+\n+=== Using searchable snapshots\n+\n+A searchable snapshot can be searched just like any other index.\n+{search-snaps-cap} are often used to access a large archive of historical data,\n+for which searches may sometimes be complex and time-consuming.\n+<<async-search>> is particularly useful for these long-running searches.\n+\n+The shards of searchable snapshots are also allocated just like shards of any\n+other index. You can, for instance, use <<shard-allocation-filtering>> to\n+restrict these shards to a subset of your nodes.\n+\n+Normally you will use {search-snaps-cap} via the", "originalCommit": "003bb24ffbd547ed37d86e9a8d41442727010385", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODMzMTU0Mw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508331543", "bodyText": "I wanted to talk about something more general than just creating them -- after all ILM does also take care of aliases which lets you search them too. How about manage? 90a2184", "author": "DaveCTurner", "createdAt": "2020-10-20T09:02:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY3MzA4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY3NDU3OA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r507674578", "bodyText": "I believe the cluster will currently only be yellow unless we worked on this recently?", "author": "henningandersen", "createdAt": "2020-10-19T11:33:10Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,108 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore,snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of their data in\n+your cluster purely for resiliency. {es} makes a copy of a searchable snapshot\n+on the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps-cap} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps-cap} may allow you to expose twice as\n+much data to searches for a given cluster size.\n+\n+=== Using searchable snapshots\n+\n+A searchable snapshot can be searched just like any other index.\n+{search-snaps-cap} are often used to access a large archive of historical data,\n+for which searches may sometimes be complex and time-consuming.\n+<<async-search>> is particularly useful for these long-running searches.\n+\n+The shards of searchable snapshots are also allocated just like shards of any\n+other index. You can, for instance, use <<shard-allocation-filtering>> to\n+restrict these shards to a subset of your nodes.\n+\n+Normally you will use {search-snaps-cap} via the\n+<<ilm-searchable-snapshot,searchable snapshots ILM action>> which automatically\n+and transparently converts your index into a searchable snapshot when it\n+reaches the `cold` ILM phase. If you already have some snapshots that you want\n+to search, you can also use the <<searchable-snapshots-api-mount-snapshot>> to\n+manually mount them as searchable snapshots.\n+\n+You must not delete a snapshot while any of its indices are mounted as a\n+searchable snapshot. However, most snapshots are taken as a backup and contain\n+a large number of indices, most of which will not be mounted as searchable\n+snapshots. If you mount just one of these indices then you may not delete that\n+snapshot. Therefore we recommend that you use the <<clone-snapshot-api>> to\n+cheaply create a clone of a snapshot where the clone contains just the index\n+you want to mount. This will mean you can delete the multiple-index snapshot,\n+reducing the size of your snapshot repository, without losing access to any\n+mounted indices.\n+\n+We recommend that you <<indices-forcemerge,force-merge>> indices to a single\n+segment per shard before mounting them as searchable snapshots. Each read from\n+a snapshot repository takes time and costs money, and the fewer segments there\n+are the fewer reads are needed to restore the snapshot.\n+\n+By default a searchable snapshot has `number_of_replicas` set to `0`. You can\n+increase the number of replicas if desired, for instance if you want to perform\n+more concurrent searches of these shards.\n+\n+If a node fails while holding some zero-replica searchable snapshot then there\n+will be a brief window of time before {es} allocates these shards elsewhere.\n+During this window of time the cluster health will be `red` and searches that", "originalCommit": "003bb24ffbd547ed37d86e9a8d41442727010385", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODMzMjUwOA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508332508", "bodyText": "Ah yes now that the recovery source is always \"snapshot\" this should be the case. Hedging my bets in c43841d by saying \"not green\".", "author": "DaveCTurner", "createdAt": "2020-10-20T09:03:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY3NDU3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY3NjgzNg==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r507676836", "bodyText": "Add beta[] here?", "author": "henningandersen", "createdAt": "2020-10-19T11:37:24Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,108 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+", "originalCommit": "003bb24ffbd547ed37d86e9a8d41442727010385", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODMyODAyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508328021", "bodyText": "++ 05b95fe.", "author": "DaveCTurner", "createdAt": "2020-10-20T08:57:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY3NjgzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY4MzA1MQ==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r507683051", "bodyText": "I wonder if the \"searchable snapshot\" object is the index or the snapshot? We talked about \"snapshot-backed index\", which is clearly the index. I think of it as the index that makes the snapshot searchable.\nWe could also define \"searchable snapshot index/indices\" here instead.\nI find the current definition here slightly confusing in that any snapshot can be made searchable.", "author": "henningandersen", "createdAt": "2020-10-19T11:49:13Z", "path": "docs/reference/glossary.asciidoc", "diffHunk": "@@ -450,6 +456,12 @@ in the <<glossary-mapping,mapping>>.\n // end::routing-def[]\n --\n \n+[[glossary-searchable-snapshot]] searchable snapshot ::\n+// tag::searchable-snapshot-def[]\n+A <<glossary-snapshot, snapshot>> of an index or data stream that resides in a remote data store ", "originalCommit": "003bb24ffbd547ed37d86e9a8d41442727010385", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODMyNzgyNA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508327824", "bodyText": "I have reworked the glossary entries in c026c9f.", "author": "DaveCTurner", "createdAt": "2020-10-20T08:57:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNzY4MzA1MQ=="}], "type": "inlineReview"}, {"oid": "b15c0e7ff29d9e77330f95007d14402eac23bdf4", "url": "https://github.com/elastic/elasticsearch/commit/b15c0e7ff29d9e77330f95007d14402eac23bdf4", "message": "Merge branch 'master' into searchable-snapshots", "committedDate": "2020-10-20T08:02:07Z", "type": "commit"}, {"oid": "c026c9f30cd320cdcb7c85e8c21e7e1f2ae8d68b", "url": "https://github.com/elastic/elasticsearch/commit/c026c9f30cd320cdcb7c85e8c21e7e1f2ae8d68b", "message": "Glossary tidy-up", "committedDate": "2020-10-20T08:16:39Z", "type": "commit"}, {"oid": "05b95fe0d19296d1733696bca177b3044deafb57", "url": "https://github.com/elastic/elasticsearch/commit/05b95fe0d19296d1733696bca177b3044deafb57", "message": "Beta", "committedDate": "2020-10-20T08:17:50Z", "type": "commit"}, {"oid": "29402a58eea9b513170628df241d6aa70a2474c0", "url": "https://github.com/elastic/elasticsearch/commit/29402a58eea9b513170628df241d6aa70a2474c0", "message": "Reword", "committedDate": "2020-10-20T08:19:31Z", "type": "commit"}, {"oid": "8beb64bc81451f5953bdb8c1a2626857e23ac8e3", "url": "https://github.com/elastic/elasticsearch/commit/8beb64bc81451f5953bdb8c1a2626857e23ac8e3", "message": "More performance idea to a TIP", "committedDate": "2020-10-20T08:53:43Z", "type": "commit"}, {"oid": "90a2184f94fb078b0db8858fd593b4829a349266", "url": "https://github.com/elastic/elasticsearch/commit/90a2184f94fb078b0db8858fd593b4829a349266", "message": "use -> manage", "committedDate": "2020-10-20T08:54:33Z", "type": "commit"}, {"oid": "c43841dc1d59ac7dd814a3332818501619996617", "url": "https://github.com/elastic/elasticsearch/commit/c43841dc1d59ac7dd814a3332818501619996617", "message": "red -> not green", "committedDate": "2020-10-20T08:55:45Z", "type": "commit"}, {"oid": "c1e672a14e5e0ed0b13e496a7680933cd1f07106", "url": "https://github.com/elastic/elasticsearch/commit/c1e672a14e5e0ed0b13e496a7680933cd1f07106", "message": "Missing space?", "committedDate": "2020-10-20T09:10:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODQ2MjQ4Ng==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508462486", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            You can also mount snapshots as <<glossary-searchable-snapshot-index,\n          \n          \n            \n            searchable snapshot indices>>.\n          \n          \n            \n            You can also mount snapshots as\n          \n          \n            \n            {ref}/glossary.html#glossary-searchable-snapshot-index[searchable snapshot\n          \n          \n            \n            indices].", "author": "jrodewig", "createdAt": "2020-10-20T12:35:13Z", "path": "docs/reference/glossary.asciidoc", "diffHunk": "@@ -486,9 +502,11 @@ See the {ref}/indices-shrink-index.html[shrink index API].\n \n [[glossary-snapshot]] snapshot ::\n // tag::snapshot-def[]\n-A backup taken from a running {es} cluster.\n-A snapshot can include backups of an entire cluster or only data streams and\n-indices you specify.\n+Captures the state of the whole cluster, or of some of its indices or data\n+streams, at a particular point in time.  Snapshots are useful for backups since\n+you can restore the cluster to its state at the time the snapshot was taken.\n+You can also mount snapshots as <<glossary-searchable-snapshot-index,\n+searchable snapshot indices>>.", "originalCommit": "c1e672a14e5e0ed0b13e496a7680933cd1f07106", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "a1e130a7c392b770afbdd6f4c7ece28006af9c47", "url": "https://github.com/elastic/elasticsearch/commit/a1e130a7c392b770afbdd6f4c7ece28006af9c47", "message": "Update docs/reference/glossary.asciidoc", "committedDate": "2020-10-20T12:35:23Z", "type": "commit"}, {"oid": "221dcd133151848d56226e7adad8ea86cf4e2aa2", "url": "https://github.com/elastic/elasticsearch/commit/221dcd133151848d56226e7adad8ea86cf4e2aa2", "message": "Fix beta label", "committedDate": "2020-10-20T12:51:05Z", "type": "commit"}, {"oid": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "url": "https://github.com/elastic/elasticsearch/commit/fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "message": "Use more attributes, fix link titles", "committedDate": "2020-10-20T12:58:30Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODg4MDgxNw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508880817", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Captures the state of the whole cluster, or of some of its indices or data\n          \n          \n            \n            streams, at a particular point in time.  Snapshots are useful for backups since\n          \n          \n            \n            you can restore the cluster to its state at the time the snapshot was taken.\n          \n          \n            \n            You can also mount snapshots as\n          \n          \n            \n            {ref}/glossary.html#glossary-searchable-snapshot-index[searchable snapshot\n          \n          \n            \n            indices].\n          \n          \n            \n            Captures the state of the whole cluster or of particular indices or data\n          \n          \n            \n            streams at a particular point in time. Snapshots provide a back up of a running cluster, ensuring you can restore your data in the event of a failure. You can also mount indices or datastreams from snapshots as read-only\n          \n          \n            \n            {ref}/glossary.html#glossary-searchable-snapshot-index[searchable snapshots].", "author": "debadair", "createdAt": "2020-10-20T22:36:58Z", "path": "docs/reference/glossary.asciidoc", "diffHunk": "@@ -486,9 +502,12 @@ See the {ref}/indices-shrink-index.html[shrink index API].\n \n [[glossary-snapshot]] snapshot ::\n // tag::snapshot-def[]\n-A backup taken from a running {es} cluster.\n-A snapshot can include backups of an entire cluster or only data streams and\n-indices you specify.\n+Captures the state of the whole cluster, or of some of its indices or data\n+streams, at a particular point in time.  Snapshots are useful for backups since\n+you can restore the cluster to its state at the time the snapshot was taken.\n+You can also mount snapshots as\n+{ref}/glossary.html#glossary-searchable-snapshot-index[searchable snapshot\n+indices].", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODg4OTA4Mw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508889083", "bodyText": "I think we're still not quite there with these definitions. If a \"searchable snapshot\" is an index mounted from snapshot, do we even need the notion of the searchable snapshot index? As written, these definitions don't make the distinction between them clear.", "author": "debadair", "createdAt": "2020-10-20T22:59:30Z", "path": "docs/reference/glossary.asciidoc", "diffHunk": "@@ -450,6 +450,22 @@ in the <<glossary-mapping,mapping>>.\n // end::routing-def[]\n --\n \n+[[glossary-searchable-snapshot]] searchable snapshot ::\n+// tag::searchable-snapshot-def[]", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTk0MDE1MQ==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r509940151", "bodyText": "I'd like us to be able to distinguish the index-in-the-snapshot from the index-in-the-cluster. In principle we are searching the index-in-the-snapshot, hence \"searchable snapshot\", and we implement this today by creating a corresponding index-in-the-cluster. I think the distinction is important since we may in future support searches directly against snapshots too. I've changed the wording slightly: \"index in a snapshot\" -> \"snapshot of an index\" -- does that help?", "author": "DaveCTurner", "createdAt": "2020-10-22T07:32:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODg4OTA4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAyMjA0Ng==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r510022046", "bodyText": "I think of it more like \"searchable snapshot\" is the concept, whereas a \"searchable snapshot index\" is a concrete index backed by a searchable snapshot. I.e., there is no object anywhere that is a \"searchable snapshot\", since all snapshots can be made searchable (through a \"searchable snapshot index\"). But I am also ok with the current text.\n\ndo we even need the notion of the searchable snapshot index\n\nI think referring to an index as just a \"searchable snapshot\" is unintuitive, since it is an index, not a snapshot.", "author": "henningandersen", "createdAt": "2020-10-22T09:38:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODg4OTA4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODg5MzgxMw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508893813", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            An index in a <<glossary-snapshot, snapshot>> that is mounted as a\n          \n          \n            \n            <<glossary-searchable-snapshot-index, searchable snapshot index>> and can be\n          \n          \n            \n            searched as if it were a regular index.\n          \n          \n            \n            A read-only index mounted from a <<glossary-snapshot, snapshot>> that can be searched like any other index.  Searchable snapshots do not need\n          \n          \n            \n            <<glossary-replica-shard,replica shards>> for resilience, since their data is\n          \n          \n            \n            reliably stored in the snapshot repository.", "author": "debadair", "createdAt": "2020-10-20T23:14:03Z", "path": "docs/reference/glossary.asciidoc", "diffHunk": "@@ -450,6 +450,22 @@ in the <<glossary-mapping,mapping>>.\n // end::routing-def[]\n --\n \n+[[glossary-searchable-snapshot]] searchable snapshot ::\n+// tag::searchable-snapshot-def[]\n+An index in a <<glossary-snapshot, snapshot>> that is mounted as a\n+<<glossary-searchable-snapshot-index, searchable snapshot index>> and can be\n+searched as if it were a regular index.", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODg5Mzk2MA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508893960", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            [[glossary-searchable-snapshot-index]] searchable snapshot index ::\n          \n          \n            \n            // tag::searchable-snapshot-index-def[]\n          \n          \n            \n            An <<glossary-index, index>> whose data is stored in a <<glossary-snapshot,\n          \n          \n            \n            snapshot>> that resides in a separate <<glossary-snapshot-repository,snapshot\n          \n          \n            \n            repository>> such as AWS S3. Searchable snapshot indices do not need\n          \n          \n            \n            <<glossary-replica-shard,replica>> shards for resilience, since their data is\n          \n          \n            \n            reliably stored outside the cluster.\n          \n          \n            \n            // end::searchable-snapshot-index-def[]", "author": "debadair", "createdAt": "2020-10-20T23:14:25Z", "path": "docs/reference/glossary.asciidoc", "diffHunk": "@@ -450,6 +450,22 @@ in the <<glossary-mapping,mapping>>.\n // end::routing-def[]\n --\n \n+[[glossary-searchable-snapshot]] searchable snapshot ::\n+// tag::searchable-snapshot-def[]\n+An index in a <<glossary-snapshot, snapshot>> that is mounted as a\n+<<glossary-searchable-snapshot-index, searchable snapshot index>> and can be\n+searched as if it were a regular index.\n+// end::searchable-snapshot-def[]\n+\n+[[glossary-searchable-snapshot-index]] searchable snapshot index ::\n+// tag::searchable-snapshot-index-def[]\n+An <<glossary-index, index>> whose data is stored in a <<glossary-snapshot,\n+snapshot>> that resides in a separate <<glossary-snapshot-repository,snapshot\n+repository>> such as AWS S3. Searchable snapshot indices do not need\n+<<glossary-replica-shard,replica>> shards for resilience, since their data is\n+reliably stored outside the cluster.\n+// end::searchable-snapshot-index-def[]", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODg5NTQyOQ==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508895429", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            === Using {search-snaps}\n          \n          \n            \n            [discrete]\n          \n          \n            \n            [[using-searchable-snapshots]]\n          \n          \n            \n            === Using {search-snaps}", "author": "debadair", "createdAt": "2020-10-20T23:18:39Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of each shard in\n+your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n+the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps} may allow you to expose twice as much\n+data to searches for a given cluster size.\n+\n+=== Using {search-snaps}", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODg5NTYwNA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508895604", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n            === How {search-snaps} work\n          \n          \n            \n            [discrete]\n          \n          \n            \n            [[how-searchable-snapshots-work]]\n          \n          \n            \n            === How {search-snaps} work", "author": "debadair", "createdAt": "2020-10-20T23:19:11Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of each shard in\n+your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n+the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps} may allow you to expose twice as much\n+data to searches for a given cluster size.\n+\n+=== Using {search-snaps}\n+\n+A {search-snap} can be searched just like any other index. Since there is a\n+copy of the {search-snap} on the nodes in the cluster its searches will perform\n+similarly to searches on a regular index.\n+\n+The shards of {search-snaps} are allocated just like shards of any other index.\n+You can, for instance, use <<shard-allocation-filtering>> to restrict these\n+shards to a subset of your nodes.\n+\n+Normally you will manage {search-snaps} via the <<ilm-searchable-snapshot,\n+searchable snapshots ILM action>> which automatically and transparently\n+converts your index into a {search-snap} when it reaches the `cold` ILM phase.\n+If you already have some snapshots that you want to search, you can also use\n+the <<searchable-snapshots-api-mount-snapshot, mount snapshot API>> to manually\n+mount them as {search-snaps}.\n+\n+You must not delete a snapshot while any of its indices are mounted as a\n+{search-snap}. However, most snapshots are taken as a backup and contain a\n+large number of indices, most of which will not be mounted as searchable\n+snapshots. If you mount just one of these indices then you may not delete that\n+snapshot. Therefore we recommend that you use the <<clone-snapshot-api, clone\n+snapshot API>> to cheaply create a clone of a snapshot where the clone contains\n+just the index you want to mount. This will mean you can delete the\n+multiple-index snapshot, reducing the size of your snapshot repository, without\n+losing access to any mounted indices.\n+\n+We recommend that you <<indices-forcemerge, force-merge>> indices to a single\n+segment per shard before mounting them as {search-snaps}. Each read from a\n+snapshot repository takes time and costs money, and the fewer segments there\n+are the fewer reads are needed to restore the snapshot.\n+\n+By default a {search-snap} index has `number_of_replicas` set to `0`. You can\n+increase the number of replicas if desired, for instance if you want to perform\n+more concurrent searches of these shards.\n+\n+If a node fails while holding some shards of a zero-replica {search-snap} then\n+there will be a brief window of time before {es} allocates these shards\n+elsewhere.  During this window of time the cluster health will not be `green`\n+and searches that hit these shards will fail or return partial results.\n+\n+[TIP]\n+====\n+{search-snaps-cap} are ideal for managing a large archive of historical data.\n+Historical information is typically searched less frequently than recent data\n+and therefore may not need replicas for their performance benefits.\n+\n+You can use <<async-search>> with {search-snaps}, which is especially useful\n+for more complex or time-consuming searches.\n+====\n+\n+=== How {search-snaps} work", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODkwNDY5Mw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508904693", "bodyText": "I think we need to lead with a focus on searchable snapshots, rather than the justification for them.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n            {search-snaps-cap} let you reduce your operating costs by using \n          \n          \n            \n            <<snapshot-restore, snapshots>> for resiliency \n          \n          \n            \n            rather than maintaining <<scalability,replica shards>> within a cluster. \n          \n          \n            \n            When you mount an index from a snapshot as a {search-snap}, \n          \n          \n            \n            {es} copies the index shards to the cluster. \n          \n          \n            \n            This ensures that query performance is comparable to any other index,\n          \n          \n            \n            and minimizes the need to access the snapshot repository.\n          \n          \n            \n            Should a node fail, shards for the {search-snap}\n          \n          \n            \n            are recovered from the snapshot repository. \n          \n          \n            \n            \n          \n          \n            \n            This can result in a significant cost savings. With {search-snaps}, \n          \n          \n            \n            you may be able to halve your cluster size without increasing the risk \n          \n          \n            \n            of data loss or reducing the amount of data you can search. \n          \n          \n            \n            Because {search-snaps} rely on the same snapshot mechanism \n          \n          \n            \n            you use for back ups, they have a minimal impact on your snapshot \n          \n          \n            \n            repository storage costs.", "author": "debadair", "createdAt": "2020-10-20T23:47:50Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODkyMjQ3NA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508922474", "bodyText": "I think this info needs to be at the beginning.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            {search-snaps-cap} let you reduce your operating costs by treating the snapshot\n          \n          \n            \n            as the authoritative copy of some of your indices. The high reliability of the\n          \n          \n            \n            snapshot repository removes the need to keep multiple copies of each shard in\n          \n          \n            \n            your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n          \n          \n            \n            the nodes in the cluster to reduce the performance impact and costs of\n          \n          \n            \n            accessing the snapshot repository.\n          \n          \n            \n            \n          \n          \n            \n            With {search-snaps} you may be able to halve your cluster size without\n          \n          \n            \n            increasing the risk of data loss or reducing the amount of data exposed to\n          \n          \n            \n            searches. Put differently, {search-snaps} may allow you to expose twice as much\n          \n          \n            \n            data to searches for a given cluster size.", "author": "debadair", "createdAt": "2020-10-21T00:40:41Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of each shard in\n+your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n+the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps} may allow you to expose twice as much\n+data to searches for a given cluster size.", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODkyMzE2Nw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508923167", "bodyText": "I don't think we need the background on the performance characteristics and can assume a basic understanding of resiliency.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Nodes in a distributed system like {es} will inevitably fail from time to time.\n          \n          \n            \n            To protect your data against node failures, by default when you index a\n          \n          \n            \n            document into {es} it is stored on two or more nodes. You also take periodic\n          \n          \n            \n            <<snapshot-restore, snapshots>> of your data so that you can recover from more\n          \n          \n            \n            serious failures. This means that each document is stored in at least three\n          \n          \n            \n            places. These extra copies are important for resiliency, but the storage they\n          \n          \n            \n            consume has an impact on your cluster's operating costs. The two storage\n          \n          \n            \n            mechanisms have different, but complementary, performance characteristics:\n          \n          \n            \n            \n          \n          \n            \n            * Snapshot repositories are much more reliable than local storage on individual\n          \n          \n            \n              nodes.\n          \n          \n            \n            \n          \n          \n            \n            * The monetary cost per GB stored in a snapshot repository is usually lower\n          \n          \n            \n              than on a node.\n          \n          \n            \n            \n          \n          \n            \n            * The monetary cost per read or write operation on a snapshot repository is\n          \n          \n            \n              usually much higher.\n          \n          \n            \n            \n          \n          \n            \n            * Reading or writing data in a snapshot repository usually takes much more time\n          \n          \n            \n              compared with accessing a node's local storage.", "author": "debadair", "createdAt": "2020-10-21T00:43:22Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODkzMTkxNg==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508931916", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            A {search-snap} can be searched just like any other index. Since there is a\n          \n          \n            \n            copy of the {search-snap} on the nodes in the cluster its searches will perform\n          \n          \n            \n            similarly to searches on a regular index.\n          \n          \n            \n            Searching a {search-snap} is the same as searching any other index. \n          \n          \n            \n            Query performance is comparable to regular indices because the index shards \n          \n          \n            \n            are allocated to nodes in the cluster when the {search-snap} is mounted. \n          \n          \n            \n            \n          \n          \n            \n            You can control allocation using the standard mechanisms. \n          \n          \n            \n            For example, you could use  <<shard-allocation-filtering>> to restrict \n          \n          \n            \n            {search-snap}  shards to a subset of your nodes.\n          \n          \n            \n            \n          \n          \n            \n            By default, {search-snaps} have no replicas. \n          \n          \n            \n            The snapshots provide the necessary resilience and \n          \n          \n            \n            queries are expected to be less frequent and query performance less important. \n          \n          \n            \n            However, if you need to support a higher query volume or faster queries, \n          \n          \n            \n            you can increase the number of replicas. \n          \n          \n            \n            \n          \n          \n            \n            If a node fails and {search-snap} shards need to be restored from the snapshot,  \n          \n          \n            \n            there is a brief window of time while  {es} allocates the shards\n          \n          \n            \n            to other nodes where the cluster health will not be `green`. \n          \n          \n            \n            Searches that hit these shards will fail or return partial results until they are reallocated.", "author": "debadair", "createdAt": "2020-10-21T01:16:23Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of each shard in\n+your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n+the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps} may allow you to expose twice as much\n+data to searches for a given cluster size.\n+\n+=== Using {search-snaps}\n+\n+A {search-snap} can be searched just like any other index. Since there is a\n+copy of the {search-snap} on the nodes in the cluster its searches will perform\n+similarly to searches on a regular index.", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODkzMjMwOA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508932308", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n            The shards of {search-snaps} are allocated just like shards of any other index.\n          \n          \n            \n            You can, for instance, use <<shard-allocation-filtering>> to restrict these\n          \n          \n            \n            shards to a subset of your nodes.", "author": "debadair", "createdAt": "2020-10-21T01:17:48Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of each shard in\n+your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n+the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps} may allow you to expose twice as much\n+data to searches for a given cluster size.\n+\n+=== Using {search-snaps}\n+\n+A {search-snap} can be searched just like any other index. Since there is a\n+copy of the {search-snap} on the nodes in the cluster its searches will perform\n+similarly to searches on a regular index.\n+\n+The shards of {search-snaps} are allocated just like shards of any other index.\n+You can, for instance, use <<shard-allocation-filtering>> to restrict these\n+shards to a subset of your nodes.", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODkzMzA1NA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508933054", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Normally you will manage {search-snaps} via the <<ilm-searchable-snapshot,\n          \n          \n            \n            searchable snapshots ILM action>> which automatically and transparently\n          \n          \n            \n            converts your index into a {search-snap} when it reaches the `cold` ILM phase.\n          \n          \n            \n            You typically manage {search-snaps} through {ilm-init}. The <<ilm-searchable-snapshot,\n          \n          \n            \n            searchable snapshots>>  action automatically converts an index to a {search-snap} when it reaches the `cold` phase.", "author": "debadair", "createdAt": "2020-10-21T01:20:48Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of each shard in\n+your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n+the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps} may allow you to expose twice as much\n+data to searches for a given cluster size.\n+\n+=== Using {search-snaps}\n+\n+A {search-snap} can be searched just like any other index. Since there is a\n+copy of the {search-snap} on the nodes in the cluster its searches will perform\n+similarly to searches on a regular index.\n+\n+The shards of {search-snaps} are allocated just like shards of any other index.\n+You can, for instance, use <<shard-allocation-filtering>> to restrict these\n+shards to a subset of your nodes.\n+\n+Normally you will manage {search-snaps} via the <<ilm-searchable-snapshot,\n+searchable snapshots ILM action>> which automatically and transparently\n+converts your index into a {search-snap} when it reaches the `cold` ILM phase.", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODkzNDI2Mw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508934263", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If you already have some snapshots that you want to search, you can also use\n          \n          \n            \n            the <<searchable-snapshots-api-mount-snapshot, mount snapshot API>> to manually\n          \n          \n            \n            mount them as {search-snaps}.\n          \n          \n            \n            You can also make indices in existing snapshots searchable by manually \n          \n          \n            \n            mounting them as {search-snaps} with the \n          \n          \n            \n            <<searchable-snapshots-api-mount-snapshot, mount snapshot>> API. \n          \n          \n            \n            To minimize reads from the snapshot repository, you should \n          \n          \n            \n            <<indices-forcemerge, force-merge>> an index to a single segment per shard \n          \n          \n            \n            before mounting it as a {search-snap}. The fewer segments there are \n          \n          \n            \n            the fewer reads are needed to restore the snapshot.", "author": "debadair", "createdAt": "2020-10-21T01:25:26Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of each shard in\n+your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n+the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps} may allow you to expose twice as much\n+data to searches for a given cluster size.\n+\n+=== Using {search-snaps}\n+\n+A {search-snap} can be searched just like any other index. Since there is a\n+copy of the {search-snap} on the nodes in the cluster its searches will perform\n+similarly to searches on a regular index.\n+\n+The shards of {search-snaps} are allocated just like shards of any other index.\n+You can, for instance, use <<shard-allocation-filtering>> to restrict these\n+shards to a subset of your nodes.\n+\n+Normally you will manage {search-snaps} via the <<ilm-searchable-snapshot,\n+searchable snapshots ILM action>> which automatically and transparently\n+converts your index into a {search-snap} when it reaches the `cold` ILM phase.\n+If you already have some snapshots that you want to search, you can also use\n+the <<searchable-snapshots-api-mount-snapshot, mount snapshot API>> to manually\n+mount them as {search-snaps}.", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODkzNDU4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508934589", "bodyText": "Is it possible to delete a snapshot while it has indices mounted?", "author": "debadair", "createdAt": "2020-10-21T01:26:48Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of each shard in\n+your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n+the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps} may allow you to expose twice as much\n+data to searches for a given cluster size.\n+\n+=== Using {search-snaps}\n+\n+A {search-snap} can be searched just like any other index. Since there is a\n+copy of the {search-snap} on the nodes in the cluster its searches will perform\n+similarly to searches on a regular index.\n+\n+The shards of {search-snaps} are allocated just like shards of any other index.\n+You can, for instance, use <<shard-allocation-filtering>> to restrict these\n+shards to a subset of your nodes.\n+\n+Normally you will manage {search-snaps} via the <<ilm-searchable-snapshot,\n+searchable snapshots ILM action>> which automatically and transparently\n+converts your index into a {search-snap} when it reaches the `cold` ILM phase.\n+If you already have some snapshots that you want to search, you can also use\n+the <<searchable-snapshots-api-mount-snapshot, mount snapshot API>> to manually\n+mount them as {search-snaps}.\n+", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODkzOTU3NA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508939574", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            You must not delete a snapshot while any of its indices are mounted as a\n          \n          \n            \n            {search-snap}. However, most snapshots are taken as a backup and contain a\n          \n          \n            \n            large number of indices, most of which will not be mounted as searchable\n          \n          \n            \n            snapshots. If you mount just one of these indices then you may not delete that\n          \n          \n            \n            snapshot. Therefore we recommend that you use the <<clone-snapshot-api, clone\n          \n          \n            \n            snapshot API>> to cheaply create a clone of a snapshot where the clone contains\n          \n          \n            \n            just the index you want to mount. This will mean you can delete the\n          \n          \n            \n            multiple-index snapshot, reducing the size of your snapshot repository, without\n          \n          \n            \n            losing access to any mounted indices.\n          \n          \n            \n            To mount an index from a backup snapshot that contains multiple indices, \n          \n          \n            \n            we recommend creating a <<clone-snapshot-api, clone>> of the snapshot \n          \n          \n            \n            that contains only the index you want to search, and mounting the clone. \n          \n          \n            \n            You cannot delete a snapshot if it has any mounted indices,\n          \n          \n            \n             so creating a clone enables you to manage the lifecycle of the backup \n          \n          \n            \n             snapshot independent of any {search-snaps}.", "author": "debadair", "createdAt": "2020-10-21T01:45:20Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of each shard in\n+your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n+the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps} may allow you to expose twice as much\n+data to searches for a given cluster size.\n+\n+=== Using {search-snaps}\n+\n+A {search-snap} can be searched just like any other index. Since there is a\n+copy of the {search-snap} on the nodes in the cluster its searches will perform\n+similarly to searches on a regular index.\n+\n+The shards of {search-snaps} are allocated just like shards of any other index.\n+You can, for instance, use <<shard-allocation-filtering>> to restrict these\n+shards to a subset of your nodes.\n+\n+Normally you will manage {search-snaps} via the <<ilm-searchable-snapshot,\n+searchable snapshots ILM action>> which automatically and transparently\n+converts your index into a {search-snap} when it reaches the `cold` ILM phase.\n+If you already have some snapshots that you want to search, you can also use\n+the <<searchable-snapshots-api-mount-snapshot, mount snapshot API>> to manually\n+mount them as {search-snaps}.\n+\n+You must not delete a snapshot while any of its indices are mounted as a\n+{search-snap}. However, most snapshots are taken as a backup and contain a\n+large number of indices, most of which will not be mounted as searchable\n+snapshots. If you mount just one of these indices then you may not delete that\n+snapshot. Therefore we recommend that you use the <<clone-snapshot-api, clone\n+snapshot API>> to cheaply create a clone of a snapshot where the clone contains\n+just the index you want to mount. This will mean you can delete the\n+multiple-index snapshot, reducing the size of your snapshot repository, without\n+losing access to any mounted indices.", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk0MDgzNw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508940837", "bodyText": "Moved up\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            We recommend that you <<indices-forcemerge, force-merge>> indices to a single\n          \n          \n            \n            segment per shard before mounting them as {search-snaps}. Each read from a\n          \n          \n            \n            snapshot repository takes time and costs money, and the fewer segments there\n          \n          \n            \n            are the fewer reads are needed to restore the snapshot.", "author": "debadair", "createdAt": "2020-10-21T01:50:05Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of each shard in\n+your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n+the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps} may allow you to expose twice as much\n+data to searches for a given cluster size.\n+\n+=== Using {search-snaps}\n+\n+A {search-snap} can be searched just like any other index. Since there is a\n+copy of the {search-snap} on the nodes in the cluster its searches will perform\n+similarly to searches on a regular index.\n+\n+The shards of {search-snaps} are allocated just like shards of any other index.\n+You can, for instance, use <<shard-allocation-filtering>> to restrict these\n+shards to a subset of your nodes.\n+\n+Normally you will manage {search-snaps} via the <<ilm-searchable-snapshot,\n+searchable snapshots ILM action>> which automatically and transparently\n+converts your index into a {search-snap} when it reaches the `cold` ILM phase.\n+If you already have some snapshots that you want to search, you can also use\n+the <<searchable-snapshots-api-mount-snapshot, mount snapshot API>> to manually\n+mount them as {search-snaps}.\n+\n+You must not delete a snapshot while any of its indices are mounted as a\n+{search-snap}. However, most snapshots are taken as a backup and contain a\n+large number of indices, most of which will not be mounted as searchable\n+snapshots. If you mount just one of these indices then you may not delete that\n+snapshot. Therefore we recommend that you use the <<clone-snapshot-api, clone\n+snapshot API>> to cheaply create a clone of a snapshot where the clone contains\n+just the index you want to mount. This will mean you can delete the\n+multiple-index snapshot, reducing the size of your snapshot repository, without\n+losing access to any mounted indices.\n+\n+We recommend that you <<indices-forcemerge, force-merge>> indices to a single\n+segment per shard before mounting them as {search-snaps}. Each read from a\n+snapshot repository takes time and costs money, and the fewer segments there\n+are the fewer reads are needed to restore the snapshot.", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTkyNjY4MA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r509926680", "bodyText": "I'd rather this was down here. It's not very important to force-merge things before mounting them, and if you're mounting an existing snapshot you basically have no choice since you can't do anything about the segment count without restoring each index, merging it and re-snapshotting it.", "author": "DaveCTurner", "createdAt": "2020-10-22T07:07:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk0MDgzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk0NzExNQ==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508947115", "bodyText": "Moved up\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            By default a {search-snap} index has `number_of_replicas` set to `0`. You can\n          \n          \n            \n            increase the number of replicas if desired, for instance if you want to perform\n          \n          \n            \n            more concurrent searches of these shards.\n          \n          \n            \n            \n          \n          \n            \n            If a node fails while holding some shards of a zero-replica {search-snap} then\n          \n          \n            \n            there will be a brief window of time before {es} allocates these shards\n          \n          \n            \n            elsewhere.  During this window of time the cluster health will not be `green`\n          \n          \n            \n            and searches that hit these shards will fail or return partial results.", "author": "debadair", "createdAt": "2020-10-21T02:13:41Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of each shard in\n+your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n+the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps} may allow you to expose twice as much\n+data to searches for a given cluster size.\n+\n+=== Using {search-snaps}\n+\n+A {search-snap} can be searched just like any other index. Since there is a\n+copy of the {search-snap} on the nodes in the cluster its searches will perform\n+similarly to searches on a regular index.\n+\n+The shards of {search-snaps} are allocated just like shards of any other index.\n+You can, for instance, use <<shard-allocation-filtering>> to restrict these\n+shards to a subset of your nodes.\n+\n+Normally you will manage {search-snaps} via the <<ilm-searchable-snapshot,\n+searchable snapshots ILM action>> which automatically and transparently\n+converts your index into a {search-snap} when it reaches the `cold` ILM phase.\n+If you already have some snapshots that you want to search, you can also use\n+the <<searchable-snapshots-api-mount-snapshot, mount snapshot API>> to manually\n+mount them as {search-snaps}.\n+\n+You must not delete a snapshot while any of its indices are mounted as a\n+{search-snap}. However, most snapshots are taken as a backup and contain a\n+large number of indices, most of which will not be mounted as searchable\n+snapshots. If you mount just one of these indices then you may not delete that\n+snapshot. Therefore we recommend that you use the <<clone-snapshot-api, clone\n+snapshot API>> to cheaply create a clone of a snapshot where the clone contains\n+just the index you want to mount. This will mean you can delete the\n+multiple-index snapshot, reducing the size of your snapshot repository, without\n+losing access to any mounted indices.\n+\n+We recommend that you <<indices-forcemerge, force-merge>> indices to a single\n+segment per shard before mounting them as {search-snaps}. Each read from a\n+snapshot repository takes time and costs money, and the fewer segments there\n+are the fewer reads are needed to restore the snapshot.\n+\n+By default a {search-snap} index has `number_of_replicas` set to `0`. You can\n+increase the number of replicas if desired, for instance if you want to perform\n+more concurrent searches of these shards.\n+\n+If a node fails while holding some shards of a zero-replica {search-snap} then\n+there will be a brief window of time before {es} allocates these shards\n+elsewhere.  During this window of time the cluster health will not be `green`\n+and searches that hit these shards will fail or return partial results.", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk0ODQ5Mw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508948493", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            {search-snaps-cap} are ideal for managing a large archive of historical data.\n          \n          \n            \n            Historical information is typically searched less frequently than recent data\n          \n          \n            \n            and therefore may not need replicas for their performance benefits.\n          \n          \n            \n            \n          \n          \n            \n            You can use <<async-search>> with {search-snaps}, which is especially useful\n          \n          \n            \n            for more complex or time-consuming searches.\n          \n          \n            \n            {search-snaps-cap} are ideal for managing large archives of historical data.\n          \n          \n            \n            Historical information is typically searched less frequently than recent data\n          \n          \n            \n            and performance is less important.\n          \n          \n            \n            \n          \n          \n            \n            For more complex or time-consuming searches, you can use <<async-search>> with {search-snaps}.", "author": "debadair", "createdAt": "2020-10-21T02:18:50Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of each shard in\n+your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n+the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps} may allow you to expose twice as much\n+data to searches for a given cluster size.\n+\n+=== Using {search-snaps}\n+\n+A {search-snap} can be searched just like any other index. Since there is a\n+copy of the {search-snap} on the nodes in the cluster its searches will perform\n+similarly to searches on a regular index.\n+\n+The shards of {search-snaps} are allocated just like shards of any other index.\n+You can, for instance, use <<shard-allocation-filtering>> to restrict these\n+shards to a subset of your nodes.\n+\n+Normally you will manage {search-snaps} via the <<ilm-searchable-snapshot,\n+searchable snapshots ILM action>> which automatically and transparently\n+converts your index into a {search-snap} when it reaches the `cold` ILM phase.\n+If you already have some snapshots that you want to search, you can also use\n+the <<searchable-snapshots-api-mount-snapshot, mount snapshot API>> to manually\n+mount them as {search-snaps}.\n+\n+You must not delete a snapshot while any of its indices are mounted as a\n+{search-snap}. However, most snapshots are taken as a backup and contain a\n+large number of indices, most of which will not be mounted as searchable\n+snapshots. If you mount just one of these indices then you may not delete that\n+snapshot. Therefore we recommend that you use the <<clone-snapshot-api, clone\n+snapshot API>> to cheaply create a clone of a snapshot where the clone contains\n+just the index you want to mount. This will mean you can delete the\n+multiple-index snapshot, reducing the size of your snapshot repository, without\n+losing access to any mounted indices.\n+\n+We recommend that you <<indices-forcemerge, force-merge>> indices to a single\n+segment per shard before mounting them as {search-snaps}. Each read from a\n+snapshot repository takes time and costs money, and the fewer segments there\n+are the fewer reads are needed to restore the snapshot.\n+\n+By default a {search-snap} index has `number_of_replicas` set to `0`. You can\n+increase the number of replicas if desired, for instance if you want to perform\n+more concurrent searches of these shards.\n+\n+If a node fails while holding some shards of a zero-replica {search-snap} then\n+there will be a brief window of time before {es} allocates these shards\n+elsewhere.  During this window of time the cluster health will not be `green`\n+and searches that hit these shards will fail or return partial results.\n+\n+[TIP]\n+====\n+{search-snaps-cap} are ideal for managing a large archive of historical data.\n+Historical information is typically searched less frequently than recent data\n+and therefore may not need replicas for their performance benefits.\n+\n+You can use <<async-search>> with {search-snaps}, which is especially useful\n+for more complex or time-consuming searches.", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTkyNTQ3OA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r509925478", "bodyText": "I'd rather keep this wording as-is: \"performance is less important\" suggests to me that there's a general performance penalty for using searchable snapshots -- in fact the only drawback most of the time is the lack of replicas.\nI'll apply the change to the wording re. async searches separately.", "author": "DaveCTurner", "createdAt": "2020-10-22T07:04:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk0ODQ5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk1MTMxMQ==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508951311", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n            When you mount a {search-snap} index, {es} allocates its shards onto the data\n          \n          \n            \n            nodes in your cluster similarly to shards of regular indices. When a shard of a\n          \n          \n            \n            {search-snap} index is allocated to a data node, that node automatically\n          \n          \n            \n            restores the shard data from the repository into its local storage. When the\n          \n          \n            \n            restore process has completed these shards will respond to searches using the\n          \n          \n            \n            data held in local storage and will not need to access the repository. This\n          \n          \n            \n            avoids incurring the monetary cost or performance penalty associated with\n          \n          \n            \n            reading data from the repository. However, if the node holding one of these\n          \n          \n            \n            shards fails then {es} will automatically allocate the shards onto the other\n          \n          \n            \n            nodes in the cluster and restore the shard data from the repository again. This\n          \n          \n            \n            means you can safely run these indices without replicas, and yet you do not\n          \n          \n            \n            need to perform any complicated monitoring or orchestration to restore lost\n          \n          \n            \n            shards yourself.\n          \n          \n            \n            When an index is mounted from a snapshot, {es} allocates its shards to data\n          \n          \n            \n            nodes within the cluster. The data nodes then automatically restore the shard data from the repository into local storage. \n          \n          \n            \n            Once the restore process completes, these shards respond to searches using the\n          \n          \n            \n            data held in local storage and do not need to access the repository. This\n          \n          \n            \n            avoids incurring the cost or performance penalty associated with\n          \n          \n            \n            reading data from the repository. \n          \n          \n            \n            \n          \n          \n            \n            If a node holding one of these shards fails, {es} automatically allocates it to another node,\n          \n          \n            \n            and that node restores the shard data from the repository. No replicas are needed, and \n          \n          \n            \n            no complicated monitoring or orchestration is necessary to  restore lost shards.", "author": "debadair", "createdAt": "2020-10-21T02:29:02Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of each shard in\n+your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n+the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps} may allow you to expose twice as much\n+data to searches for a given cluster size.\n+\n+=== Using {search-snaps}\n+\n+A {search-snap} can be searched just like any other index. Since there is a\n+copy of the {search-snap} on the nodes in the cluster its searches will perform\n+similarly to searches on a regular index.\n+\n+The shards of {search-snaps} are allocated just like shards of any other index.\n+You can, for instance, use <<shard-allocation-filtering>> to restrict these\n+shards to a subset of your nodes.\n+\n+Normally you will manage {search-snaps} via the <<ilm-searchable-snapshot,\n+searchable snapshots ILM action>> which automatically and transparently\n+converts your index into a {search-snap} when it reaches the `cold` ILM phase.\n+If you already have some snapshots that you want to search, you can also use\n+the <<searchable-snapshots-api-mount-snapshot, mount snapshot API>> to manually\n+mount them as {search-snaps}.\n+\n+You must not delete a snapshot while any of its indices are mounted as a\n+{search-snap}. However, most snapshots are taken as a backup and contain a\n+large number of indices, most of which will not be mounted as searchable\n+snapshots. If you mount just one of these indices then you may not delete that\n+snapshot. Therefore we recommend that you use the <<clone-snapshot-api, clone\n+snapshot API>> to cheaply create a clone of a snapshot where the clone contains\n+just the index you want to mount. This will mean you can delete the\n+multiple-index snapshot, reducing the size of your snapshot repository, without\n+losing access to any mounted indices.\n+\n+We recommend that you <<indices-forcemerge, force-merge>> indices to a single\n+segment per shard before mounting them as {search-snaps}. Each read from a\n+snapshot repository takes time and costs money, and the fewer segments there\n+are the fewer reads are needed to restore the snapshot.\n+\n+By default a {search-snap} index has `number_of_replicas` set to `0`. You can\n+increase the number of replicas if desired, for instance if you want to perform\n+more concurrent searches of these shards.\n+\n+If a node fails while holding some shards of a zero-replica {search-snap} then\n+there will be a brief window of time before {es} allocates these shards\n+elsewhere.  During this window of time the cluster health will not be `green`\n+and searches that hit these shards will fail or return partial results.\n+\n+[TIP]\n+====\n+{search-snaps-cap} are ideal for managing a large archive of historical data.\n+Historical information is typically searched less frequently than recent data\n+and therefore may not need replicas for their performance benefits.\n+\n+You can use <<async-search>> with {search-snaps}, which is especially useful\n+for more complex or time-consuming searches.\n+====\n+\n+=== How {search-snaps} work\n+\n+When you mount a {search-snap} index, {es} allocates its shards onto the data\n+nodes in your cluster similarly to shards of regular indices. When a shard of a\n+{search-snap} index is allocated to a data node, that node automatically\n+restores the shard data from the repository into its local storage. When the\n+restore process has completed these shards will respond to searches using the\n+data held in local storage and will not need to access the repository. This\n+avoids incurring the monetary cost or performance penalty associated with\n+reading data from the repository. However, if the node holding one of these\n+shards fails then {es} will automatically allocate the shards onto the other\n+nodes in the cluster and restore the shard data from the repository again. This\n+means you can safely run these indices without replicas, and yet you do not\n+need to perform any complicated monitoring or orchestration to restore lost\n+shards yourself.", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODk1MjQ3Mg==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r508952472", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Restoring a shard of a {search-snap} index happens in the background, which\n          \n          \n            \n            means that you can search these shards even if they have not been fully\n          \n          \n            \n            restored. If you attempt to search a shard of a {search-snap} index before it\n          \n          \n            \n            has been fully restored then {es} will eagerly retrieve just the data needed\n          \n          \n            \n            for the search. This means that some searches will be slower if the shard is\n          \n          \n            \n            freshly allocated to a node and still warming up. Searches usually only need to\n          \n          \n            \n            access a very small fraction of the total shard data so the performance penalty\n          \n          \n            \n            on searches during the background restore process is often very small.\n          \n          \n            \n            {es] restores {search-snap} shards in the background and you can search them \n          \n          \n            \n            even if they have not been fully restored. If a search hits a {search-snap} shard before it\n          \n          \n            \n            has been fully restored, {es} eagerly retrieves the data needed for the search. \n          \n          \n            \n            If a shard is freshly allocated to a node and still warming up, some searches will be slower. However, searches typically access a very small fraction of the total shard data so the performance penalty is typically very small.", "author": "debadair", "createdAt": "2020-10-21T02:33:30Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,118 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+Nodes in a distributed system like {es} will inevitably fail from time to time.\n+To protect your data against node failures, by default when you index a\n+document into {es} it is stored on two or more nodes. You also take periodic\n+<<snapshot-restore, snapshots>> of your data so that you can recover from more\n+serious failures. This means that each document is stored in at least three\n+places. These extra copies are important for resiliency, but the storage they\n+consume has an impact on your cluster's operating costs. The two storage\n+mechanisms have different, but complementary, performance characteristics:\n+\n+* Snapshot repositories are much more reliable than local storage on individual\n+  nodes.\n+\n+* The monetary cost per GB stored in a snapshot repository is usually lower\n+  than on a node.\n+\n+* The monetary cost per read or write operation on a snapshot repository is\n+  usually much higher.\n+\n+* Reading or writing data in a snapshot repository usually takes much more time\n+  compared with accessing a node's local storage.\n+\n+{search-snaps-cap} let you reduce your operating costs by treating the snapshot\n+as the authoritative copy of some of your indices. The high reliability of the\n+snapshot repository removes the need to keep multiple copies of each shard in\n+your cluster purely for resiliency. {es} makes a copy of a {search-snap} onto\n+the nodes in the cluster to reduce the performance impact and costs of\n+accessing the snapshot repository.\n+\n+With {search-snaps} you may be able to halve your cluster size without\n+increasing the risk of data loss or reducing the amount of data exposed to\n+searches. Put differently, {search-snaps} may allow you to expose twice as much\n+data to searches for a given cluster size.\n+\n+=== Using {search-snaps}\n+\n+A {search-snap} can be searched just like any other index. Since there is a\n+copy of the {search-snap} on the nodes in the cluster its searches will perform\n+similarly to searches on a regular index.\n+\n+The shards of {search-snaps} are allocated just like shards of any other index.\n+You can, for instance, use <<shard-allocation-filtering>> to restrict these\n+shards to a subset of your nodes.\n+\n+Normally you will manage {search-snaps} via the <<ilm-searchable-snapshot,\n+searchable snapshots ILM action>> which automatically and transparently\n+converts your index into a {search-snap} when it reaches the `cold` ILM phase.\n+If you already have some snapshots that you want to search, you can also use\n+the <<searchable-snapshots-api-mount-snapshot, mount snapshot API>> to manually\n+mount them as {search-snaps}.\n+\n+You must not delete a snapshot while any of its indices are mounted as a\n+{search-snap}. However, most snapshots are taken as a backup and contain a\n+large number of indices, most of which will not be mounted as searchable\n+snapshots. If you mount just one of these indices then you may not delete that\n+snapshot. Therefore we recommend that you use the <<clone-snapshot-api, clone\n+snapshot API>> to cheaply create a clone of a snapshot where the clone contains\n+just the index you want to mount. This will mean you can delete the\n+multiple-index snapshot, reducing the size of your snapshot repository, without\n+losing access to any mounted indices.\n+\n+We recommend that you <<indices-forcemerge, force-merge>> indices to a single\n+segment per shard before mounting them as {search-snaps}. Each read from a\n+snapshot repository takes time and costs money, and the fewer segments there\n+are the fewer reads are needed to restore the snapshot.\n+\n+By default a {search-snap} index has `number_of_replicas` set to `0`. You can\n+increase the number of replicas if desired, for instance if you want to perform\n+more concurrent searches of these shards.\n+\n+If a node fails while holding some shards of a zero-replica {search-snap} then\n+there will be a brief window of time before {es} allocates these shards\n+elsewhere.  During this window of time the cluster health will not be `green`\n+and searches that hit these shards will fail or return partial results.\n+\n+[TIP]\n+====\n+{search-snaps-cap} are ideal for managing a large archive of historical data.\n+Historical information is typically searched less frequently than recent data\n+and therefore may not need replicas for their performance benefits.\n+\n+You can use <<async-search>> with {search-snaps}, which is especially useful\n+for more complex or time-consuming searches.\n+====\n+\n+=== How {search-snaps} work\n+\n+When you mount a {search-snap} index, {es} allocates its shards onto the data\n+nodes in your cluster similarly to shards of regular indices. When a shard of a\n+{search-snap} index is allocated to a data node, that node automatically\n+restores the shard data from the repository into its local storage. When the\n+restore process has completed these shards will respond to searches using the\n+data held in local storage and will not need to access the repository. This\n+avoids incurring the monetary cost or performance penalty associated with\n+reading data from the repository. However, if the node holding one of these\n+shards fails then {es} will automatically allocate the shards onto the other\n+nodes in the cluster and restore the shard data from the repository again. This\n+means you can safely run these indices without replicas, and yet you do not\n+need to perform any complicated monitoring or orchestration to restore lost\n+shards yourself.\n+\n+Restoring a shard of a {search-snap} index happens in the background, which\n+means that you can search these shards even if they have not been fully\n+restored. If you attempt to search a shard of a {search-snap} index before it\n+has been fully restored then {es} will eagerly retrieve just the data needed\n+for the search. This means that some searches will be slower if the shard is\n+freshly allocated to a node and still warming up. Searches usually only need to\n+access a very small fraction of the total shard data so the performance penalty\n+on searches during the background restore process is often very small.", "originalCommit": "fd9652b15c5e004d0bf77a4f0809bc5728febd7a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "fb0ccd0948145c879c62fb9dbc6e524dcade7af8", "url": "https://github.com/elastic/elasticsearch/commit/fb0ccd0948145c879c62fb9dbc6e524dcade7af8", "message": "Apply suggestions from code review\n\nCo-authored-by: debadair <debadair@elastic.co>", "committedDate": "2020-10-22T06:59:03Z", "type": "commit"}, {"oid": "4929f8b5a92ca00f60d86f1485361ac4d1fe874e", "url": "https://github.com/elastic/elasticsearch/commit/4929f8b5a92ca00f60d86f1485361ac4d1fe874e", "message": "Merge branch 'master' into searchable-snapshots", "committedDate": "2020-10-22T07:10:59Z", "type": "commit"}, {"oid": "644eccd2a7523ee2ba392a461082a02f42d0e0b4", "url": "https://github.com/elastic/elasticsearch/commit/644eccd2a7523ee2ba392a461082a02f42d0e0b4", "message": "Reformat", "committedDate": "2020-10-22T07:13:36Z", "type": "commit"}, {"oid": "de75da95f3146cd1a1e6ce897f29c0fb747a040c", "url": "https://github.com/elastic/elasticsearch/commit/de75da95f3146cd1a1e6ce897f29c0fb747a040c", "message": "Minor rewordings", "committedDate": "2020-10-22T07:28:15Z", "type": "commit"}, {"oid": "26706d8a793a76a56a4d5bfed5327b46632d4bc1", "url": "https://github.com/elastic/elasticsearch/commit/26706d8a793a76a56a4d5bfed5327b46632d4bc1", "message": "More minor rewordings", "committedDate": "2020-10-22T07:41:39Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTk3ODA4OA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r509978088", "bodyText": "I wonder if this should go below the ILM section in the interest of explaining the \"easy/normal\" option first and then the more advanced option afterwards?", "author": "henningandersen", "createdAt": "2020-10-22T08:33:05Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,99 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+{search-snaps-cap} let you reduce your operating costs by using\n+<<snapshot-restore, snapshots>> for resiliency rather than maintaining\n+<<scalability,replica shards>> within a cluster. When you mount an index from a\n+snapshot as a {search-snap}, {es} copies the index shards to local storage\n+within the cluster. This ensures that search performance is comparable to\n+searching any other index, and minimizes the need to access the snapshot\n+repository. Should a node fail, shards of a {search-snap} are automatically\n+recovered from the snapshot repository.\n+\n+This can result in significant cost savings. With {search-snaps}, you may be\n+able to halve your cluster size without increasing the risk of data loss or\n+reducing the amount of data you can search. Because {search-snaps} rely on the\n+same snapshot mechanism you use for backups, they have a minimal impact on your\n+snapshot repository storage costs.\n+\n+[discrete]\n+[[using-searchable-snapshots]]\n+=== Using {search-snaps}\n+\n+Searching a {search-snap} is the same as searching any other index. Search\n+performance is comparable to regular indices because the shard data is copied\n+onto nodes in the cluster when the {search-snap} is mounted.\n+\n+You can control the allocation of the shards of {search-snap} indices using the\n+same mechanisms as for regular indices. For example, you could use\n+<<shard-allocation-filtering>> to restrict {search-snap} shards to a subset of\n+your nodes.", "originalCommit": "26706d8a793a76a56a4d5bfed5327b46632d4bc1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA4NDI5Mw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r510084293", "bodyText": "I'm ambivalent -- I put it here since we're starting off by talking about how these indices are mostly maniuplated (searched & allocated) as if they were normal indices, but I've moved it in 990707b.", "author": "DaveCTurner", "createdAt": "2020-10-22T11:26:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTk3ODA4OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAxMjU4Nw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r510012587", "bodyText": "nit: I think \"very\" is unnecessary here.", "author": "henningandersen", "createdAt": "2020-10-22T09:24:01Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,99 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+{search-snaps-cap} let you reduce your operating costs by using\n+<<snapshot-restore, snapshots>> for resiliency rather than maintaining\n+<<scalability,replica shards>> within a cluster. When you mount an index from a\n+snapshot as a {search-snap}, {es} copies the index shards to local storage\n+within the cluster. This ensures that search performance is comparable to\n+searching any other index, and minimizes the need to access the snapshot\n+repository. Should a node fail, shards of a {search-snap} are automatically\n+recovered from the snapshot repository.\n+\n+This can result in significant cost savings. With {search-snaps}, you may be\n+able to halve your cluster size without increasing the risk of data loss or\n+reducing the amount of data you can search. Because {search-snaps} rely on the\n+same snapshot mechanism you use for backups, they have a minimal impact on your\n+snapshot repository storage costs.\n+\n+[discrete]\n+[[using-searchable-snapshots]]\n+=== Using {search-snaps}\n+\n+Searching a {search-snap} is the same as searching any other index. Search\n+performance is comparable to regular indices because the shard data is copied\n+onto nodes in the cluster when the {search-snap} is mounted.\n+\n+You can control the allocation of the shards of {search-snap} indices using the\n+same mechanisms as for regular indices. For example, you could use\n+<<shard-allocation-filtering>> to restrict {search-snap} shards to a subset of\n+your nodes.\n+\n+By default, {search-snaps} have no replicas. The underlying snapshot provides\n+resilience and the query volume is expected to be low enough that a single\n+shard copy will be sufficient. However, if you need to support a higher query\n+volume, you can add replicas by adjusting the `index.number_of_replicas` index\n+setting.\n+\n+If a node fails and {search-snap} shards need to be restored from the snapshot,\n+there is a brief window of time while {es} allocates the shards to other nodes\n+where the cluster health will not be `green`. Searches that hit these shards\n+will fail or return partial results until they are reallocated.\n+\n+You typically manage {search-snaps} through {ilm-init}. The\n+<<ilm-searchable-snapshot, searchable snapshots>> action automatically converts\n+an index to a {search-snap} when it reaches the `cold` phase. You can also make\n+indices in existing snapshots searchable by manually mounting them as\n+{search-snaps} with the <<searchable-snapshots-api-mount-snapshot, mount\n+snapshot>> API.\n+\n+To mount an index from a snapshot that contains multiple indices, we recommend\n+creating a <<clone-snapshot-api, clone>> of the snapshot that contains only the\n+index you want to search, and mounting the clone. You cannot delete a snapshot\n+if it has any mounted indices, so creating a clone enables you to manage the\n+lifecycle of the backup snapshot independently of any {search-snaps}.\n+\n+We recommend that you <<indices-forcemerge, force-merge>> indices to a single\n+segment per shard before mounting them as {search-snaps}. Each read from a\n+snapshot repository takes time and costs money, and the fewer segments there\n+are the fewer reads are needed to restore the snapshot.\n+\n+[TIP]\n+====\n+{search-snaps-cap} are ideal for managing a large archive of historical data.\n+Historical information is typically searched less frequently than recent data\n+and therefore may not need replicas for their performance benefits.\n+\n+For more complex or time-consuming searches, you can use <<async-search>> with\n+{search-snaps}.\n+====\n+\n+[discrete]\n+[[how-searchable-snapshots-work]]\n+=== How {search-snaps} work\n+\n+When an index is mounted from a snapshot, {es} allocates its shards to data\n+nodes within the cluster. The data nodes then automatically restore the shard\n+data from the repository onto local storage. Once the restore process\n+completes, these shards respond to searches using the data held in local\n+storage and do not need to access the repository. This avoids incurring the\n+cost or performance penalty associated with reading data from the repository.\n+\n+If a node holding one of these shards fails, {es} automatically allocates it to\n+another node, and that node restores the shard data from the repository. No\n+replicas are needed, and no complicated monitoring or orchestration is\n+necessary to restore lost shards.\n+\n+{es} restores {search-snap} shards in the background and you can search them\n+even if they have not been fully restored. If a search hits a {search-snap}\n+shard before it has been fully restored, {es} eagerly retrieves the data needed\n+for the search. If a shard is freshly allocated to a node and still warming up,\n+some searches will be slower. However, searches typically access a very small\n+fraction of the total shard data so the performance penalty is typically very", "originalCommit": "26706d8a793a76a56a4d5bfed5327b46632d4bc1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA4MzI5Nw==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r510083297", "bodyText": "Very well ;) Addressed in 990707b", "author": "DaveCTurner", "createdAt": "2020-10-22T11:24:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAxMjU4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAxODUzOA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r510018538", "bodyText": "Should this be \"Searching a searchable snapshot index\" to be consistent with glossary. I think it reads better too.\nSame comment goes for a number of the \"{search-snap}\" mentions throughout.", "author": "henningandersen", "createdAt": "2020-10-22T09:32:52Z", "path": "docs/reference/searchable-snapshots/index.asciidoc", "diffHunk": "@@ -0,0 +1,99 @@\n+[[searchable-snapshots]]\n+== {search-snaps-cap}\n+\n+beta::[]\n+\n+{search-snaps-cap} let you reduce your operating costs by using\n+<<snapshot-restore, snapshots>> for resiliency rather than maintaining\n+<<scalability,replica shards>> within a cluster. When you mount an index from a\n+snapshot as a {search-snap}, {es} copies the index shards to local storage\n+within the cluster. This ensures that search performance is comparable to\n+searching any other index, and minimizes the need to access the snapshot\n+repository. Should a node fail, shards of a {search-snap} are automatically\n+recovered from the snapshot repository.\n+\n+This can result in significant cost savings. With {search-snaps}, you may be\n+able to halve your cluster size without increasing the risk of data loss or\n+reducing the amount of data you can search. Because {search-snaps} rely on the\n+same snapshot mechanism you use for backups, they have a minimal impact on your\n+snapshot repository storage costs.\n+\n+[discrete]\n+[[using-searchable-snapshots]]\n+=== Using {search-snaps}\n+\n+Searching a {search-snap} is the same as searching any other index. Search", "originalCommit": "26706d8a793a76a56a4d5bfed5327b46632d4bc1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDA4MzIxMA==", "url": "https://github.com/elastic/elasticsearch/pull/63040#discussion_r510083210", "bodyText": "Good point, I've added a few \"index\" or \"shard\" nouns throughout in 990707b.", "author": "DaveCTurner", "createdAt": "2020-10-22T11:24:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDAxODUzOA=="}], "type": "inlineReview"}, {"oid": "990707b6758d4c82243aec92cb582e34daa828ca", "url": "https://github.com/elastic/elasticsearch/commit/990707b6758d4c82243aec92cb582e34daa828ca", "message": "Address Henning's comments", "committedDate": "2020-10-22T11:23:09Z", "type": "commit"}]}