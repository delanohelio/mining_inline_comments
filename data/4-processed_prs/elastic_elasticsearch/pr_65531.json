{"pr_number": 65531, "pr_title": "Wait for prewarm when relocating searchable snapshot shards", "pr_createdAt": "2020-11-26T08:49:17Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/65531", "timeline": [{"oid": "74eae5cbbd7a7780e66f20da3b47d6d5883c974d", "url": "https://github.com/elastic/elasticsearch/commit/74eae5cbbd7a7780e66f20da3b47d6d5883c974d", "message": "Wait for Prewarm when Relocating Searchable Snapshot Shards\n\nAdd hooks to enable waiting for a condition before relocation handoff.\nMake timeout on relocation unbounded and add ability to disable recovery\nliveness checker temporarily while running prewarm.", "committedDate": "2020-11-26T08:42:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkwOTYwNA==", "url": "https://github.com/elastic/elasticsearch/pull/65531#discussion_r530909604", "bodyText": "This is a bit of a BwC issue I guess. If the hand-off request comes from 7.10 and doesn't wait indefinitely yet then it could timeout on the primary I guess but maybe we can just ignore it since it's so fringe?", "author": "original-brownbear", "createdAt": "2020-11-26T10:01:25Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/PeerRecoveryTargetService.java", "diffHunk": "@@ -312,16 +316,23 @@ public void messageReceived(RecoveryFinalizeRecoveryRequest request, TransportCh\n         public void messageReceived(final RecoveryHandoffPrimaryContextRequest request, final TransportChannel channel,\n                                     Task task) throws Exception {\n             final RecoveryRef recoveryRef = onGoingRecoveries.getRecoverySafe(request.recoveryId(), request.shardId());\n+            final List<Releasable> toRelease = new ArrayList<>(2);\n+            toRelease.add(recoveryRef::close);\n             boolean success = false;\n             try {\n+                // Due to relocation conditions on the shard it could take a while for the hand-off to complete so we disable the recovery\n+                // monitor since we don't expect any transport messages from master for the duration of the handoff and activate it again\n+                // after the handoff.\n+                final Releasable disabledMonitor = recoveryRef.target().disableRecoveryMonitor();", "originalCommit": "74eae5cbbd7a7780e66f20da3b47d6d5883c974d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDkxMzkzNg==", "url": "https://github.com/elastic/elasticsearch/pull/65531#discussion_r530913936", "bodyText": "This is a little low-tech relative to the tricky ref-counting in the IndexShard.  I figured this was ok here since the hand-off request only comes in once (at least judging by the assertions we have in IndexShard) while the other API has a more \"feel\" to it and there are no hard guarantees on the index shard state listener only being invoked once (though the \"loaded\" flag on the directory effectively guarantees we only add one condition for now) and it wasn't that much extra effort since the API was supposed to be non-blocking anyway.", "author": "original-brownbear", "createdAt": "2020-11-26T10:08:15Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/RecoveryTarget.java", "diffHunk": "@@ -161,6 +164,26 @@ public void setLastAccessTime() {\n         lastAccessTime = System.nanoTime();\n     }\n \n+    /**\n+     * Set flag to signal to {@link org.elasticsearch.indices.recovery.RecoveriesCollection.RecoveryMonitor} that it must not cancel this\n+     * recovery temporarily. This is used by the primary relocation mechanism to avoid recovery failure in case a long running relocation\n+     * condition was added to the shard via {@link IndexShard#createRelocationDependency()}.\n+     *\n+     * @return releasable that once closed will re-enable liveness checks by the recovery monitor\n+     */\n+    public Releasable disableRecoveryMonitor() {\n+        assert recoveryMonitorEnabled : \"recovery monitor already disabled\";\n+        recoveryMonitorEnabled = false;\n+        return () -> {\n+            setLastAccessTime();\n+            recoveryMonitorEnabled = true;", "originalCommit": "74eae5cbbd7a7780e66f20da3b47d6d5883c974d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e688e7431340b2cd66ad69b9b8fb58c3da1fe619", "url": "https://github.com/elastic/elasticsearch/commit/e688e7431340b2cd66ad69b9b8fb58c3da1fe619", "message": "Merge remote-tracking branch 'elastic/master' into wait-for-prewarm", "committedDate": "2020-11-29T20:36:04Z", "type": "commit"}, {"oid": "e57db0733f93b1537a8cea1f9e636972bd14215c", "url": "https://github.com/elastic/elasticsearch/commit/e57db0733f93b1537a8cea1f9e636972bd14215c", "message": "Merge remote-tracking branch 'elastic/master' into wait-for-prewarm", "committedDate": "2020-11-30T03:16:07Z", "type": "commit"}, {"oid": "f489058c5ca37e8291937644e2bf574c9390c7e2", "url": "https://github.com/elastic/elasticsearch/commit/f489058c5ca37e8291937644e2bf574c9390c7e2", "message": "add test", "committedDate": "2020-11-30T04:07:47Z", "type": "commit"}, {"oid": "95dadb200f9e39cbcb146c05e4877ec1c632755d", "url": "https://github.com/elastic/elasticsearch/commit/95dadb200f9e39cbcb146c05e4877ec1c632755d", "message": "better test", "committedDate": "2020-11-30T05:25:56Z", "type": "commit"}, {"oid": "d5ee3f3e632fcdd8d7b46acb3acf1e78c4523100", "url": "https://github.com/elastic/elasticsearch/commit/d5ee3f3e632fcdd8d7b46acb3acf1e78c4523100", "message": "way better test", "committedDate": "2020-11-30T05:36:08Z", "type": "commit"}, {"oid": "fa8dea685d6e4d5ac5d566e5ffafb20918e01a53", "url": "https://github.com/elastic/elasticsearch/commit/fa8dea685d6e4d5ac5d566e5ffafb20918e01a53", "message": "reformat nicer", "committedDate": "2020-11-30T05:47:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjQ3NjkyMQ==", "url": "https://github.com/elastic/elasticsearch/pull/65531#discussion_r532476921", "bodyText": "Could we do this outside the synchronized block? Not sure it is important, but simplifies reading the code.", "author": "henningandersen", "createdAt": "2020-11-30T10:04:46Z", "path": "server/src/main/java/org/elasticsearch/index/shard/IndexShard.java", "diffHunk": "@@ -457,6 +461,38 @@ public QueryCachingPolicy getQueryCachingPolicy() {\n         return cachingPolicy;\n     }\n \n+    /**\n+     * A ref counter that can be used to delay primary relocation handoff via {@link #createRelocationDependency()}.\n+     */\n+    private final class RelocationCondition extends AbstractRefCounted {\n+\n+        private Runnable asyncActivation;\n+\n+        RelocationCondition(ShardRouting routing) {\n+            super(\"relocation condition for [\" + routing.shardId() + \"][\" + routing.allocationId() + \"]\");\n+        }\n+\n+        @Override\n+        protected void closeInternal() {\n+            synchronized (this) {\n+                if (asyncActivation != null) {\n+                    threadPool.generic().execute(asyncActivation);\n+                }\n+            }\n+        }\n+\n+        // Set the relocation context when receiving it and execute the handoff right away if no more conditions are waiting or create a\n+        // Runnable to execute once all conditions have finished\n+        void receivePrimaryContext(ReplicationTracker.PrimaryContext primaryContext, ActionListener<Void> listener) {\n+            synchronized (this) {\n+                if (decRef()) {\n+                    doActivateWithPrimaryContext(primaryContext, listener);", "originalCommit": "fa8dea685d6e4d5ac5d566e5ffafb20918e01a53", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjQ3OTc0Mw==", "url": "https://github.com/elastic/elasticsearch/pull/65531#discussion_r532479743", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * {@link #activateThrottling()}.\n          \n          \n            \n                 * {@link #activateWithPrimaryContext()}.", "author": "henningandersen", "createdAt": "2020-11-30T10:09:24Z", "path": "server/src/main/java/org/elasticsearch/index/shard/IndexShard.java", "diffHunk": "@@ -2409,23 +2453,62 @@ assert state() != IndexShardState.POST_RECOVERY && state() != IndexShardState.ST\n         replicationTracker.updateGlobalCheckpointOnReplica(globalCheckpoint, reason);\n     }\n \n+    private RelocationCondition relocationCondition;\n+\n+    /**\n+     * Creates a {@link Runnable} that must be executed before primary relocation to this shard can complete by a call to\n+     * {@link #activateThrottling()}.", "originalCommit": "fa8dea685d6e4d5ac5d566e5ffafb20918e01a53", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjUwNDU4NA==", "url": "https://github.com/elastic/elasticsearch/pull/65531#discussion_r532504584", "bodyText": "I think it might be simpler to just fake the progress inside RecoveryTarget by returning System.nanoTime()?", "author": "henningandersen", "createdAt": "2020-11-30T10:48:01Z", "path": "server/src/main/java/org/elasticsearch/indices/recovery/RecoveriesCollection.java", "diffHunk": "@@ -275,16 +275,20 @@ protected void doRun() throws Exception {\n                 logger.trace(\"[monitor] no status found for [{}], shutting down\", recoveryId);\n                 return;\n             }\n-            long accessTime = status.lastAccessTime();\n-            if (accessTime == lastSeenAccessTime) {\n-                String message = \"no activity after [\" + checkInterval + \"]\";\n-                failRecovery(recoveryId,\n-                        new RecoveryFailedException(status.state(), message, new ElasticsearchTimeoutException(message)),\n-                        true // to be safe, we don't know what go stuck\n-                );\n-                return;\n+            if (status.isRecoveryMonitorEnabled()) {\n+                long accessTime = status.lastAccessTime();\n+                if (accessTime == lastSeenAccessTime) {\n+                    String message = \"no activity after [\" + checkInterval + \"]\";\n+                    failRecovery(recoveryId,\n+                            new RecoveryFailedException(status.state(), message, new ElasticsearchTimeoutException(message)),\n+                            true // to be safe, we don't know what go stuck\n+                    );\n+                    return;\n+                }\n+                lastSeenAccessTime = accessTime;\n+            } else {\n+                lastSeenAccessTime = System.nanoTime();", "originalCommit": "fa8dea685d6e4d5ac5d566e5ffafb20918e01a53", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "eccb1b4d85edf751996d555a39a6b6adf62d86b5", "url": "https://github.com/elastic/elasticsearch/commit/eccb1b4d85edf751996d555a39a6b6adf62d86b5", "message": "Merge remote-tracking branch 'elastic/master' into wait-for-prewarm", "committedDate": "2020-11-30T12:03:55Z", "type": "commit"}, {"oid": "a428a8b1556b94a7b34d9228cc577d3a5b564948", "url": "https://github.com/elastic/elasticsearch/commit/a428a8b1556b94a7b34d9228cc577d3a5b564948", "message": "start", "committedDate": "2020-11-30T14:41:08Z", "type": "commit"}, {"oid": "472fa1e26dba7a856fcf3ce9141a109e922ce921", "url": "https://github.com/elastic/elasticsearch/commit/472fa1e26dba7a856fcf3ce9141a109e922ce921", "message": "Merge remote-tracking branch 'elastic/master' into wait-for-prewarm-on-finalize", "committedDate": "2020-11-30T16:11:25Z", "type": "commit"}, {"oid": "fc01ad49ce00ac575690936dc519385b84659fa3", "url": "https://github.com/elastic/elasticsearch/commit/fc01ad49ce00ac575690936dc519385b84659fa3", "message": "Merge remote-tracking branch 'elastic/master' into wait-for-prewarm-on-finalize", "committedDate": "2020-12-01T12:44:32Z", "type": "commit"}, {"oid": "48c55f54a45299eae08ca2a0a7ce83f23f2cd9a1", "url": "https://github.com/elastic/elasticsearch/commit/48c55f54a45299eae08ca2a0a7ce83f23f2cd9a1", "message": "bck", "committedDate": "2020-12-01T15:28:41Z", "type": "commit"}, {"oid": "40e18cd23a1263c9bf0ecf812d32f9414b712b0a", "url": "https://github.com/elastic/elasticsearch/commit/40e18cd23a1263c9bf0ecf812d32f9414b712b0a", "message": "works nicely", "committedDate": "2020-12-01T17:04:24Z", "type": "commit"}, {"oid": "9427179ba57bd0f3490ca3f87396b4c48657f056", "url": "https://github.com/elastic/elasticsearch/commit/9427179ba57bd0f3490ca3f87396b4c48657f056", "message": "Merge remote-tracking branch 'elastic/master' into wait-for-prewarm-on-finalize", "committedDate": "2020-12-02T08:10:18Z", "type": "commit"}, {"oid": "ed4e8c91bc1d8164afd335f258cebbacd97241a3", "url": "https://github.com/elastic/elasticsearch/commit/ed4e8c91bc1d8164afd335f258cebbacd97241a3", "message": "fixes", "committedDate": "2020-12-02T08:13:47Z", "type": "commit"}, {"oid": "59ab566d06212d84768a3b6f22ee8751ff1454bc", "url": "https://github.com/elastic/elasticsearch/commit/59ab566d06212d84768a3b6f22ee8751ff1454bc", "message": "fix liveness check disabling", "committedDate": "2020-12-02T08:49:53Z", "type": "commit"}, {"oid": "566884e9bd713b1ddaeddd6dd789b9caf800d5b0", "url": "https://github.com/elastic/elasticsearch/commit/566884e9bd713b1ddaeddd6dd789b9caf800d5b0", "message": "fix comment", "committedDate": "2020-12-02T08:55:35Z", "type": "commit"}, {"oid": "3b41f9313c131a6f11d44c0dd6614174bae511ea", "url": "https://github.com/elastic/elasticsearch/commit/3b41f9313c131a6f11d44c0dd6614174bae511ea", "message": "much simpler", "committedDate": "2020-12-02T10:18:11Z", "type": "commit"}, {"oid": "43816f5535e1c99d7062465af4b7192e2754e10b", "url": "https://github.com/elastic/elasticsearch/commit/43816f5535e1c99d7062465af4b7192e2754e10b", "message": "cs", "committedDate": "2020-12-02T10:20:43Z", "type": "commit"}, {"oid": "714e6c1bbf7a1fc53f69fc01a432d95959378a71", "url": "https://github.com/elastic/elasticsearch/commit/714e6c1bbf7a1fc53f69fc01a432d95959378a71", "message": "Merge remote-tracking branch 'elastic/master' into wait-for-prewarm", "committedDate": "2020-12-02T10:22:00Z", "type": "commit"}, {"oid": "86e9ebb01e6bcf714144bd61a3155b87143ab803", "url": "https://github.com/elastic/elasticsearch/commit/86e9ebb01e6bcf714144bd61a3155b87143ab803", "message": "adjust broken test", "committedDate": "2020-12-02T10:29:28Z", "type": "commit"}, {"oid": "d44b1202f71c204e0e4775e6e463871a20a29f59", "url": "https://github.com/elastic/elasticsearch/commit/d44b1202f71c204e0e4775e6e463871a20a29f59", "message": "shorter", "committedDate": "2020-12-02T10:39:21Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTA2NzYyNQ==", "url": "https://github.com/elastic/elasticsearch/pull/65531#discussion_r539067625", "bodyText": "Could we instead find the shard using internalCluster().getInstance(IndicesService.class, node) and assertBusy that it has a pending after cleanup action?", "author": "henningandersen", "createdAt": "2020-12-09T07:26:11Z", "path": "x-pack/plugin/searchable-snapshots/src/internalClusterTest/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsRelocationIntegTests.java", "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+package org.elasticsearch.xpack.searchablesnapshots;\n+\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.metadata.IndexMetadata;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.common.Priority;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.indices.recovery.RecoveryState;\n+import org.elasticsearch.plugins.Plugin;\n+import org.elasticsearch.snapshots.mockstore.MockRepository;\n+import org.elasticsearch.test.ESIntegTestCase;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.hamcrest.Matchers;\n+\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.CyclicBarrier;\n+import java.util.concurrent.Executor;\n+import java.util.concurrent.TimeUnit;\n+\n+import static org.elasticsearch.test.hamcrest.ElasticsearchAssertions.assertAcked;\n+\n+@ESIntegTestCase.ClusterScope(scope = ESIntegTestCase.Scope.TEST, numDataNodes = 0)\n+public class SearchableSnapshotsRelocationIntegTests extends BaseSearchableSnapshotsIntegTestCase {\n+\n+    @Override\n+    protected Collection<Class<? extends Plugin>> nodePlugins() {\n+        return List.of(LocalStateSearchableSnapshots.class, MockRepository.Plugin.class);\n+    }\n+\n+    public void testRelocationWaitsForPreWarm() throws Exception {\n+        internalCluster().startMasterOnlyNode();\n+        final String firstDataNode = internalCluster().startDataOnlyNode();\n+        final String index = \"test-idx\";\n+        createIndexWithContent(index, indexSettingsNoReplicas(1).build());\n+        final String repoName = \"test-repo\";\n+        createRepository(repoName, \"mock\");\n+        final String snapshotName = \"test-snapshot\";\n+        createSnapshot(repoName, snapshotName, List.of(index));\n+        assertAcked(client().admin().indices().prepareDelete(index));\n+        final String restoredIndex = mountSnapshot(repoName, snapshotName, index, Settings.EMPTY);\n+        ensureGreen(restoredIndex);\n+        final String secondDataNode = internalCluster().startDataOnlyNode();\n+\n+        final ThreadPool threadPool = internalCluster().getInstance(ThreadPool.class, secondDataNode);\n+        final int preWarmThreads = threadPool.info(SearchableSnapshotsConstants.CACHE_PREWARMING_THREAD_POOL_NAME).getMax();\n+        final Executor executor = threadPool.executor(SearchableSnapshotsConstants.CACHE_PREWARMING_THREAD_POOL_NAME);\n+        final CyclicBarrier barrier = new CyclicBarrier(preWarmThreads + 1);\n+        final CountDownLatch latch = new CountDownLatch(1);\n+        for (int i = 0; i < preWarmThreads; i++) {\n+            executor.execute(() -> {\n+                try {\n+                    barrier.await();\n+                    latch.await();\n+                } catch (Exception e) {\n+                    throw new AssertionError(e);\n+                }\n+            });\n+        }\n+        logger.info(\"--> waiting for prewarm threads to all become blocked\");\n+        barrier.await();\n+\n+        logger.info(\"--> force index [{}] to relocate to [{}]\", index, secondDataNode);\n+        assertAcked(\n+            client().admin()\n+                .indices()\n+                .prepareUpdateSettings(restoredIndex)\n+                .setSettings(\n+                    Settings.builder()\n+                        .put(\n+                            IndexMetadata.INDEX_ROUTING_REQUIRE_GROUP_SETTING.getConcreteSettingForNamespace(\"_name\").getKey(),\n+                            secondDataNode\n+                        )\n+                )\n+        );\n+        assertBusy(() -> {\n+            final List<RecoveryState> recoveryStates = getActiveRestores(restoredIndex);\n+            assertThat(recoveryStates, Matchers.hasSize(1));\n+            final RecoveryState shardRecoveryState = recoveryStates.get(0);\n+            assertEquals(firstDataNode, shardRecoveryState.getSourceNode().getName());\n+            assertEquals(secondDataNode, shardRecoveryState.getTargetNode().getName());\n+        });\n+\n+        logger.info(\"--> sleep for 5s to ensure we are actually stuck at the FINALIZE stage and that the primary has not yet relocated\");\n+        TimeUnit.SECONDS.sleep(5L);", "originalCommit": "d44b1202f71c204e0e4775e6e463871a20a29f59", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTE2Nzk2NQ==", "url": "https://github.com/elastic/elasticsearch/pull/65531#discussion_r539167965", "bodyText": "++ thanks, you actually prevented a likely test failure here as well :) I moved the check for translog stage to a busy assert and then added the check for one clean files condition after. Otherwise we'd only have had 5s to arrive at TRANSLOG now at least we have 10 which should be a little safer.", "author": "original-brownbear", "createdAt": "2020-12-09T09:59:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTA2NzYyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTA3MjI2NA==", "url": "https://github.com/elastic/elasticsearch/pull/65531#discussion_r539072264", "bodyText": "Maybe only do this line randomly to avoid waiting for prewarming before doing all the reads below?", "author": "henningandersen", "createdAt": "2020-12-09T07:35:49Z", "path": "x-pack/plugin/searchable-snapshots/src/test/java/org/elasticsearch/index/store/cache/CachedBlobContainerIndexInputTests.java", "diffHunk": "@@ -114,7 +117,9 @@ public void testRandomReads() throws Exception {\n                     )\n                 ) {\n                     RecoveryState recoveryState = createRecoveryState();\n-                    final boolean loaded = directory.loadSnapshot(recoveryState);\n+                    final PlainActionFuture<Void> future = PlainActionFuture.newFuture();\n+                    final boolean loaded = directory.loadSnapshot(recoveryState, future);\n+                    future.get();", "originalCommit": "d44b1202f71c204e0e4775e6e463871a20a29f59", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTE2ODA0NQ==", "url": "https://github.com/elastic/elasticsearch/pull/65531#discussion_r539168045", "bodyText": "sure done :)", "author": "original-brownbear", "createdAt": "2020-12-09T09:59:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTA3MjI2NA=="}], "type": "inlineReview"}, {"oid": "ef5032e1234ee5380dd1249ca11276eb223ccee3", "url": "https://github.com/elastic/elasticsearch/commit/ef5032e1234ee5380dd1249ca11276eb223ccee3", "message": "Merge remote-tracking branch 'elastic/master' into wait-for-prewarm", "committedDate": "2020-12-09T08:51:40Z", "type": "commit"}, {"oid": "b9063b59ead269aff21929e2e74479c60a213f9b", "url": "https://github.com/elastic/elasticsearch/commit/b9063b59ead269aff21929e2e74479c60a213f9b", "message": "adjust tests", "committedDate": "2020-12-09T09:57:48Z", "type": "commit"}]}