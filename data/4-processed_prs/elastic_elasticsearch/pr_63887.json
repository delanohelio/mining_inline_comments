{"pr_number": 63887, "pr_title": "[ML] add new setting xpack.ml.use_auto_machine_memory_percent for auto calculating native memory percentage allowed for machine learning jobs", "pr_createdAt": "2020-10-19T15:24:39Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/63887", "timeline": [{"oid": "e9386bcb6352f6e01b7163ac399c545d7003f7a8", "url": "https://github.com/elastic/elasticsearch/commit/e9386bcb6352f6e01b7163ac399c545d7003f7a8", "message": "[ML] add new setting for allowing specialized dynamic native memory percentage allowed for ML\n\nWhen running ML, sometimes it is best to automatically adjust the\nmemory allotted for machine learning based on the nodesize\nand how much space is given to the JVM\n\nThis commit adds an optional flag for allowing this dynamic\ncalculation. The old setting remains as a backup\njust in case the dynamic limit cannot be determined due to\nlack of information.", "committedDate": "2020-10-19T15:21:18Z", "type": "commit"}, {"oid": "4b8bc94f634c67a7769076e967ad0e5a2fe838db", "url": "https://github.com/elastic/elasticsearch/commit/4b8bc94f634c67a7769076e967ad0e5a2fe838db", "message": "Merge branch 'master' into feature/ml-add-dynamic-setting-for-job-memory-percent", "committedDate": "2020-10-19T15:39:30Z", "type": "commit"}, {"oid": "88ed9e570eb7efd9a058e1b13b527b35c6480bc2", "url": "https://github.com/elastic/elasticsearch/commit/88ed9e570eb7efd9a058e1b13b527b35c6480bc2", "message": "[DOCS] Add advanced setting", "committedDate": "2020-10-19T18:47:33Z", "type": "commit"}, {"oid": "1d7c90c799fa59148e00b883d261ef3f12ac025e", "url": "https://github.com/elastic/elasticsearch/commit/1d7c90c799fa59148e00b883d261ef3f12ac025e", "message": "[DOCS] Adds tip for dedicated ML nodes", "committedDate": "2020-10-19T19:07:35Z", "type": "commit"}, {"oid": "4a8356e9141a22117f5537772f2565b2b274da15", "url": "https://github.com/elastic/elasticsearch/commit/4a8356e9141a22117f5537772f2565b2b274da15", "message": "undoing unnecessray changes", "committedDate": "2020-10-20T15:43:41Z", "type": "commit"}, {"oid": "d7fad1ef9a462d8ccc678b60a3d6b4e0a890a989", "url": "https://github.com/elastic/elasticsearch/commit/d7fad1ef9a462d8ccc678b60a3d6b4e0a890a989", "message": "Merge remote-tracking branch 'upstream/master' into feature/ml-add-dynamic-setting-for-job-memory-percent", "committedDate": "2020-10-20T15:43:46Z", "type": "commit"}, {"oid": "1b77b0bbd80f021ae579bdf801e274f33766f8eb", "url": "https://github.com/elastic/elasticsearch/commit/1b77b0bbd80f021ae579bdf801e274f33766f8eb", "message": "Merge branch 'feature/ml-add-dynamic-setting-for-job-memory-percent' of github.com:benwtrent/elasticsearch into feature/ml-add-dynamic-setting-for-job-memory-percent", "committedDate": "2020-10-20T15:43:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODYzNjM0Ng==", "url": "https://github.com/elastic/elasticsearch/pull/63887#discussion_r508636346", "bodyText": "The reasons for adding a new setting instead of expanding xpack.ml.max_machine_memory_percent to allow a special -1 value are:\n\nAn old node joining the cluster would not be able to deserialize the setting and would throw errors\nWhen calculating the memory possible on an old node, we would fail to gather the JVM attribute (as it wouldn't be available). So, we need a sane fallback. Which is the other static calculated value xpack.ml.max_machine_memory_percent\n\nDefaulting to false keeps users from having things change unexpectedly during a rolling upgrade.\nIn the scenario where the administrator does not want to bother setting the max memory percent, they can simply set this value true. The assumption is that the ml nodes are focused to only run ML.", "author": "benwtrent", "createdAt": "2020-10-20T15:50:16Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/MachineLearning.java", "diffHunk": "@@ -421,6 +422,22 @@\n     // can handle.\n     public static final Setting<Integer> MAX_MACHINE_MEMORY_PERCENT =\n             Setting.intSetting(\"xpack.ml.max_machine_memory_percent\", 30, 5, 200, Property.Dynamic, Property.NodeScope);\n+    /**\n+     * This boolean value indicates if `max_machine_memory_percent` should be ignored and a automatic calculation is used instead.\n+     *\n+     * This calculation takes into account total node size and the size of the JVM on that node.\n+     *\n+     * If the calculation fails, we fall back to `max_machine_memory_percent`.\n+     *\n+     * This setting is NOT dynamic. This allows the cluster administrator to set it on startup without worry of it\n+     * being edited accidentally later.\n+     * Consequently, it could be that this setting differs between nodes. But, we only ever pay attention to the value\n+     * that is set on the current master. As master nodes are responsible for persistent task assignments.\n+     */\n+    public static final Setting<Boolean> USE_AUTO_MACHINE_MEMORY_PERCENT = Setting.boolSetting(\n+        \"xpack.ml.use_auto_machine_memory_percent\",\n+        false,\n+        Property.NodeScope);", "originalCommit": "1b77b0bbd80f021ae579bdf801e274f33766f8eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODYzNzEyOQ==", "url": "https://github.com/elastic/elasticsearch/pull/63887#discussion_r508637129", "bodyText": "We need this information for each node. This way we can calculate the total native memory that is allowed in on the node and then calculate our percentage from that.", "author": "benwtrent", "createdAt": "2020-10-20T15:50:56Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/MachineLearning.java", "diffHunk": "@@ -531,6 +550,7 @@ public Settings additionalSettings() {\n                     String.valueOf(MAX_OPEN_JOBS_PER_NODE.get(settings)));\n             addMlNodeAttribute(additionalSettings, machineMemoryAttrName,\n                     Long.toString(machineMemoryFromStats(OsProbe.getInstance().osStats())));\n+            addMlNodeAttribute(additionalSettings, jvmSizeAttrName, Long.toString(Runtime.getRuntime().maxMemory()));", "originalCommit": "1b77b0bbd80f021ae579bdf801e274f33766f8eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTEzNzYzMg==", "url": "https://github.com/elastic/elasticsearch/pull/63887#discussion_r509137632", "bodyText": "I don't think the try/catch here is really necessary.  The cluster applier service already wraps each callback to a listener in a try/catch, so an exception here wouldn't stop other listeners being called.  And asyncRefresh itself already catches the most likely exception it could throw.  So any exception caught here would be really strange.  So I would just avoid the clutter and call asyncRefresh() outside a try block after the trace logging.", "author": "droberts195", "createdAt": "2020-10-21T09:40:52Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/process/MlMemoryTracker.java", "diffHunk": "@@ -101,6 +101,11 @@ private void setReassignmentRecheckInterval(TimeValue recheckInterval) {\n     @Override\n     public void onMaster() {\n         isMaster = true;\n+        try {\n+            asyncRefresh();\n+        } catch (Exception ex) {", "originalCommit": "1b77b0bbd80f021ae579bdf801e274f33766f8eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTE0Mjc2OA==", "url": "https://github.com/elastic/elasticsearch/pull/63887#discussion_r509142768", "bodyText": "When this formula was originally used in Cloud we knew the node size would never be less than 200MB.  However, in theory this could now produce a negative number if the node was really small, e.g. in a very constrained Docker container.\nSome options would be:\n\nWrap the formula in a Math.max(1, ...)\nPrevent the node starting up if useAuto is true and node size is less than some value greater than 200MB, e.g. 256MB, and document this as a requirement (I don't think it would be that controversial to demand that a dedicated ML node run on a machine with that much memory available)", "author": "droberts195", "createdAt": "2020-10-21T09:48:41Z", "path": "x-pack/plugin/ml/src/main/java/org/elasticsearch/xpack/ml/utils/NativeMemoryCalculator.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.utils;\n+\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.common.Strings;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+\n+import java.util.OptionalLong;\n+\n+import static org.elasticsearch.xpack.ml.MachineLearning.MACHINE_MEMORY_NODE_ATTR;\n+import static org.elasticsearch.xpack.ml.MachineLearning.MAX_JVM_SIZE_NODE_ATTR;\n+import static org.elasticsearch.xpack.ml.MachineLearning.MAX_MACHINE_MEMORY_PERCENT;\n+import static org.elasticsearch.xpack.ml.MachineLearning.USE_AUTO_MACHINE_MEMORY_PERCENT;\n+\n+public final class NativeMemoryCalculator {\n+\n+    private static final long OS_OVERHEAD = ByteSizeValue.ofMb(200L).getBytes();\n+\n+    private NativeMemoryCalculator() { }\n+\n+    public static OptionalLong allowedBytesForMl(DiscoveryNode node, Settings settings) {\n+        return allowedBytesForMl(\n+            node.getAttributes().get(MACHINE_MEMORY_NODE_ATTR),\n+            node.getAttributes().get(MAX_JVM_SIZE_NODE_ATTR),\n+            MAX_MACHINE_MEMORY_PERCENT.get(settings),\n+            USE_AUTO_MACHINE_MEMORY_PERCENT.get(settings));\n+    }\n+\n+    public static OptionalLong allowedBytesForMl(DiscoveryNode node, ClusterSettings settings) {\n+        return allowedBytesForMl(\n+            node.getAttributes().get(MACHINE_MEMORY_NODE_ATTR),\n+            node.getAttributes().get(MAX_JVM_SIZE_NODE_ATTR),\n+            settings.get(MAX_MACHINE_MEMORY_PERCENT),\n+            settings.get(USE_AUTO_MACHINE_MEMORY_PERCENT));\n+    }\n+\n+    public static OptionalLong allowedBytesForMl(DiscoveryNode node, int maxMemoryPercent, boolean useAuto) {\n+        return allowedBytesForMl(\n+            node.getAttributes().get(MACHINE_MEMORY_NODE_ATTR),\n+            node.getAttributes().get(MAX_JVM_SIZE_NODE_ATTR),\n+            maxMemoryPercent,\n+            useAuto);\n+    }\n+\n+    private static OptionalLong allowedBytesForMl(String nodeBytes, String jvmBytes, int maxMemoryPercent, boolean useAuto) {\n+        if (nodeBytes == null) {\n+            return OptionalLong.empty();\n+        }\n+        final long machineMemory;\n+        try {\n+            machineMemory = Long.parseLong(nodeBytes);\n+        } catch (NumberFormatException e) {\n+            return OptionalLong.empty();\n+        }\n+        Long jvmMemory = null;\n+        try {\n+            if (Strings.isNullOrEmpty(jvmBytes) == false) {\n+                jvmMemory = Long.parseLong(jvmBytes);\n+            }\n+        } catch (NumberFormatException e) {\n+            return OptionalLong.empty();\n+        }\n+        return OptionalLong.of(allowedBytesForMl(machineMemory, jvmMemory, maxMemoryPercent, useAuto));\n+    }\n+\n+    private static long allowedBytesForMl(long machineMemory, Long jvmSize, int maxMemoryPercent, boolean useAuto) {\n+        if (useAuto && jvmSize != null) {\n+            // This calculation is dynamic and designed to maximally take advantage of the underlying machine for machine learning\n+            // We only allow 200MB for the Operating system itself and take up to 90% of the underlying native memory left\n+            // Example calculations:\n+            // 1GB node -> 41%\n+            // 2GB node -> 66%\n+            // 16GB node -> 87%\n+            // 64GB node -> 90%\n+            long memoryPercent = Math.min(90, (int)Math.ceil(((machineMemory - jvmSize - OS_OVERHEAD) / (double)machineMemory) * 100.0D));", "originalCommit": "1b77b0bbd80f021ae579bdf801e274f33766f8eb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTIxNDcwMw==", "url": "https://github.com/elastic/elasticsearch/pull/63887#discussion_r509214703", "bodyText": "@droberts195\n\nPrevent the node starting up ... node size < 256MB.\n\nI am not sure this is going to be possible.\nIt is completely valid to only have this setting set to true on master nodes. Master nodes don't have to be ML nodes, so our size requirements don't apply to them. It follows that valid ML nodes could have this assigned to false and be small, but the master node is set to calculate dynamically.\nI see two valid options:\n\ndo a max calculation as you indicate\nFall back to the statically set percentage when the node is too small.\n\nOption 2 might be unexpected, but I don't know of a nice way to come up with some magic \"OS overhead\" calculation for exceptionally small nodes. I think exceptionally small nodes just sort of break this calculation.\nI am thinking we should fall back to the static percentage.", "author": "benwtrent", "createdAt": "2020-10-21T11:53:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTE0Mjc2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTIyMDYyOA==", "url": "https://github.com/elastic/elasticsearch/pull/63887#discussion_r509220628", "bodyText": "I am thinking we should fall back to the static percentage.\n\nI think falling back to 1% would be more reasonable.  Basically we're saying that either there will be an OOM or that significant amounts of swap will need to be used to run a job.  Neither is a very good experience, so if the user specifically asked us to automatically determine how much ML native memory to use then it's reasonable for us to choose an amount that will mean no jobs can get assigned but also nothing will crash or grind to a halt.  The reason for non-assignment will indicate that more memory is needed.", "author": "droberts195", "createdAt": "2020-10-21T12:03:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTE0Mjc2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTE0NTUzMQ==", "url": "https://github.com/elastic/elasticsearch/pull/63887#discussion_r509145531", "bodyText": "These are bytes, not megabytes.  The test would be testing more realistic size ranges if this was multiplied by 1024 * 1024.", "author": "droberts195", "createdAt": "2020-10-21T09:53:03Z", "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/utils/NativeMemoryCalculatorTests.java", "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.utils;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.test.ESTestCase;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.OptionalLong;\n+\n+import static org.elasticsearch.xpack.ml.MachineLearning.MACHINE_MEMORY_NODE_ATTR;\n+import static org.elasticsearch.xpack.ml.MachineLearning.MAX_JVM_SIZE_NODE_ATTR;\n+import static org.elasticsearch.xpack.ml.MachineLearning.MAX_MACHINE_MEMORY_PERCENT;\n+import static org.elasticsearch.xpack.ml.MachineLearning.USE_AUTO_MACHINE_MEMORY_PERCENT;\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class NativeMemoryCalculatorTests extends ESTestCase{\n+\n+    private static final int NUM_TEST_RUNS = 10;\n+    public void testAllowedBytesForMLWhenAutoIsFalse() {\n+        for (int i = 0; i < NUM_TEST_RUNS; i++) {\n+            long nodeSize = randomLongBetween(100, 10_000);", "originalCommit": "1b77b0bbd80f021ae579bdf801e274f33766f8eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTE0NTY0OQ==", "url": "https://github.com/elastic/elasticsearch/pull/63887#discussion_r509145649", "bodyText": "These are bytes, not megabytes.  The test would be testing more realistic size ranges if this was multiplied by 1024 * 1024.", "author": "droberts195", "createdAt": "2020-10-21T09:53:14Z", "path": "x-pack/plugin/ml/src/test/java/org/elasticsearch/xpack/ml/utils/NativeMemoryCalculatorTests.java", "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.ml.utils;\n+\n+import org.elasticsearch.Version;\n+import org.elasticsearch.cluster.node.DiscoveryNode;\n+import org.elasticsearch.cluster.node.DiscoveryNodeRole;\n+import org.elasticsearch.common.settings.ClusterSettings;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.ByteSizeValue;\n+import org.elasticsearch.common.util.set.Sets;\n+import org.elasticsearch.test.ESTestCase;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.OptionalLong;\n+\n+import static org.elasticsearch.xpack.ml.MachineLearning.MACHINE_MEMORY_NODE_ATTR;\n+import static org.elasticsearch.xpack.ml.MachineLearning.MAX_JVM_SIZE_NODE_ATTR;\n+import static org.elasticsearch.xpack.ml.MachineLearning.MAX_MACHINE_MEMORY_PERCENT;\n+import static org.elasticsearch.xpack.ml.MachineLearning.USE_AUTO_MACHINE_MEMORY_PERCENT;\n+import static org.hamcrest.Matchers.equalTo;\n+\n+public class NativeMemoryCalculatorTests extends ESTestCase{\n+\n+    private static final int NUM_TEST_RUNS = 10;\n+    public void testAllowedBytesForMLWhenAutoIsFalse() {\n+        for (int i = 0; i < NUM_TEST_RUNS; i++) {\n+            long nodeSize = randomLongBetween(100, 10_000);\n+            int percent = randomIntBetween(5, 200);\n+            DiscoveryNode node = newNode(randomBoolean() ? null : randomNonNegativeLong(), nodeSize);\n+            Settings settings = newSettings(percent, false);\n+            ClusterSettings clusterSettings = newClusterSettings(percent, false);\n+\n+            long expected = nodeSize * percent / 100;\n+\n+            assertThat(NativeMemoryCalculator.allowedBytesForMl(node, settings).getAsLong(), equalTo(expected));\n+            assertThat(NativeMemoryCalculator.allowedBytesForMl(node, clusterSettings).getAsLong(), equalTo(expected));\n+            assertThat(NativeMemoryCalculator.allowedBytesForMl(node, percent, false).getAsLong(), equalTo(expected));\n+        }\n+    }\n+\n+    public void testAllowedBytesForMlWhenAutoIsTrue() {\n+        for (int i = 0; i < NUM_TEST_RUNS; i++) {\n+            long nodeSize = randomLongBetween(ByteSizeValue.ofMb(500).getBytes(), ByteSizeValue.ofGb(64).getBytes());\n+            long jvmSize = randomLongBetween(ByteSizeValue.ofMb(250).getBytes(), nodeSize - ByteSizeValue.ofMb(200).getBytes());\n+            int percent = randomIntBetween(5, 200);\n+            DiscoveryNode node = newNode(jvmSize, nodeSize);\n+            Settings settings = newSettings(percent, true);\n+            ClusterSettings clusterSettings = newClusterSettings(percent, true);\n+\n+            int truePercent = Math.min(\n+                90,\n+                (int)Math.ceil(((nodeSize - jvmSize - ByteSizeValue.ofMb(200).getBytes()) / (double)nodeSize) * 100.0D));\n+            long expected = nodeSize * truePercent / 100;\n+\n+            assertThat(NativeMemoryCalculator.allowedBytesForMl(node, settings).getAsLong(), equalTo(expected));\n+            assertThat(NativeMemoryCalculator.allowedBytesForMl(node, clusterSettings).getAsLong(), equalTo(expected));\n+            assertThat(NativeMemoryCalculator.allowedBytesForMl(node, percent, true).getAsLong(), equalTo(expected));\n+        }\n+    }\n+\n+    public void testAllowedBytesForMlWhenAutoIsTrueButJVMSizeIsUnknown() {\n+        long nodeSize = randomLongBetween(100, 10_000);", "originalCommit": "1b77b0bbd80f021ae579bdf801e274f33766f8eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d9590baf2ce4d6797008c1ba9b92cf4c57af44f8", "url": "https://github.com/elastic/elasticsearch/commit/d9590baf2ce4d6797008c1ba9b92cf4c57af44f8", "message": "protect against tiny nodes", "committedDate": "2020-10-21T12:43:55Z", "type": "commit"}]}