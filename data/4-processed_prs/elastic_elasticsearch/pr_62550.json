{"pr_number": 62550, "pr_title": "Add test for snapshot incrementality of snapshot-backed indices", "pr_createdAt": "2020-09-17T14:02:08Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/62550", "timeline": [{"oid": "c84210cd7748d59a405544826421f98c398d5f0c", "url": "https://github.com/elastic/elasticsearch/commit/c84210cd7748d59a405544826421f98c398d5f0c", "message": "Add test", "committedDate": "2020-09-17T13:46:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDI4MzExOQ==", "url": "https://github.com/elastic/elasticsearch/pull/62550#discussion_r490283119", "bodyText": "I think you can have this check in a more straight-forward manner and just use the snapshot status API.\nSee for example org.elasticsearch.snapshots.BlobStoreIncrementalityIT#assertTwoIdenticalShardSnapshots. I think I'd prefer that over adding yet another test that manually inspects the exact file structure on disk and has to be adjusted if and when we change the repo format.\nIn a sense this is also more correct since we already store some blobs straight in the shard snapshot metadata where the approach would catch changes while the data files don't change.", "author": "original-brownbear", "createdAt": "2020-09-17T14:16:53Z", "path": "x-pack/plugin/searchable-snapshots/src/internalClusterTest/java/org/elasticsearch/xpack/searchablesnapshots/SearchableSnapshotsIntegTests.java", "diffHunk": "@@ -660,6 +671,52 @@ public void testMountedSnapshotHasNoReplicasByDefault() throws Exception {\n         }\n     }\n \n+    public void testSnapshotMountedIndexLeavesBlobsUntouched() throws Exception {\n+        final String indexName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        createAndPopulateIndex(\n+            indexName,\n+            Settings.builder()\n+                .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, between(1, 3))\n+                .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n+                .put(INDEX_SOFT_DELETES_SETTING.getKey(), true)\n+        );\n+        ensureGreen(indexName);\n+        forceMerge();\n+\n+        final String repositoryName = randomAlphaOfLength(10).toLowerCase(Locale.ROOT);\n+        final Path repositoryLocation = randomRepoPath();\n+        createFsRepository(repositoryName, repositoryLocation);\n+\n+        final SnapshotId snapshotOne = createSnapshot(repositoryName, List.of(indexName));\n+        final Set<Tuple<String, Long>> snapshotOneDataBlobs = listDataBlobsInRepository(repositoryLocation);\n+        assertThat(snapshotOneDataBlobs, hasSize(greaterThan(0)));\n+        assertAcked(client().admin().indices().prepareDelete(indexName));\n+\n+        mountSnapshot(repositoryName, snapshotOne.getName(), indexName, indexName, Settings.EMPTY);\n+        ensureGreen(indexName);\n+\n+        createSnapshot(repositoryName, List.of(indexName));\n+        final Set<Tuple<String, Long>> snapshotTwoDataBlobs = listDataBlobsInRepository(repositoryLocation);\n+        assertThat(snapshotTwoDataBlobs.containsAll(snapshotOneDataBlobs), is(true));\n+        assertThat(snapshotTwoDataBlobs, hasSize(snapshotOneDataBlobs.size()));", "originalCommit": "c84210cd7748d59a405544826421f98c398d5f0c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDkzMDUzNA==", "url": "https://github.com/elastic/elasticsearch/pull/62550#discussion_r490930534", "bodyText": "I hadn't even thought about it, thanks for the suggestion", "author": "tlrx", "createdAt": "2020-09-18T12:57:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDI4MzExOQ=="}], "type": "inlineReview"}, {"oid": "9dd966ded4f311bfcdc13790d8371323d8297665", "url": "https://github.com/elastic/elasticsearch/commit/9dd966ded4f311bfcdc13790d8371323d8297665", "message": "feedback", "committedDate": "2020-09-18T08:49:38Z", "type": "commit"}, {"oid": "12972fb157b86718936f395acfd0259e9829f229", "url": "https://github.com/elastic/elasticsearch/commit/12972fb157b86718936f395acfd0259e9829f229", "message": "Merge branch 'master' into test-snapshot-of-mounted-index", "committedDate": "2020-09-18T12:06:04Z", "type": "commit"}]}