{"pr_number": 55051, "pr_title": "Provide repository-level stats for searchable snapshots", "pr_createdAt": "2020-04-10T12:10:01Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/55051", "timeline": [{"oid": "444955d21014f0a8f6992b11f35d67535f4e1444", "url": "https://github.com/elastic/elasticsearch/commit/444955d21014f0a8f6992b11f35d67535f4e1444", "message": "Provide repository-level stats for searchable snapshots", "committedDate": "2020-04-10T12:04:13Z", "type": "commit"}, {"oid": "d060429f92dc2938e0c800f8bfd6bd497579c1d6", "url": "https://github.com/elastic/elasticsearch/commit/d060429f92dc2938e0c800f8bfd6bd497579c1d6", "message": "Merge remote-tracking branch 'elastic/master' into record-list-get-calls", "committedDate": "2020-04-10T12:04:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc0OTEwMw==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r406749103", "bodyText": "Just a general question (will try to review properly shortly):  Should this maybe live in x-pack core since this isn't just a searchable snapshots related piece of functionality and we have plans to use it elsewhere also?", "author": "original-brownbear", "createdAt": "2020-04-10T13:07:01Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/rest/RestRepositoryStatsAction.java", "diffHunk": "@@ -0,0 +1,39 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.searchablesnapshots.rest;\n+\n+import org.elasticsearch.client.node.NodeClient;\n+import org.elasticsearch.rest.BaseRestHandler;\n+import org.elasticsearch.rest.RestHandler;\n+import org.elasticsearch.rest.RestRequest;\n+import org.elasticsearch.rest.action.RestToXContentListener;\n+import org.elasticsearch.xpack.searchablesnapshots.action.RepositoryStatsAction;\n+import org.elasticsearch.xpack.searchablesnapshots.action.RepositoryStatsRequest;\n+\n+import java.util.Collections;\n+import java.util.List;\n+\n+import static org.elasticsearch.rest.RestRequest.Method.GET;\n+\n+public class RestRepositoryStatsAction extends BaseRestHandler {", "originalCommit": "d060429f92dc2938e0c800f8bfd6bd497579c1d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1MjA2MQ==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r406752061", "bodyText": "I wanted to keep the scope small here so that we can iterate more quickly on this API. For now, the scope of this is only targeting searchable snapshot investigations. We can at a later stage discuss whether this change is more broadly usable. The main issue with the stats reported here are that they're reset as soon as a repository is updated or a node is restarted, which might make this a confusing API. The core functionality for tracing, that might be useful in the context of Cloud, is in the respective blobstore implementation, and might be exposed differently (e.g. periodic logging)", "author": "ywelsch", "createdAt": "2020-04-10T13:15:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc0OTEwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc1NzI3NA==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r406757274", "bodyText": "This fails reproducibly for me with  -Dtests.seed=73DAD8B23C19870D", "author": "original-brownbear", "createdAt": "2020-04-10T13:28:46Z", "path": "plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java", "diffHunk": "@@ -176,6 +187,82 @@ public void testEnforcedCooldownPeriod() throws IOException {\n         assertThat(repository.threadPool().relativeTimeInNanos() - beforeFastDelete, lessThan(TEST_COOLDOWN_PERIOD.getNanos()));\n     }\n \n+    public void testRequestStats() throws Exception {", "originalCommit": "d060429f92dc2938e0c800f8bfd6bd497579c1d6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc2MTk4OQ==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r406761989", "bodyText": "You probably don't want this filter because it prevents you from seeing the erroneous handlers below in the mapping.", "author": "original-brownbear", "createdAt": "2020-04-10T13:40:37Z", "path": "plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java", "diffHunk": "@@ -176,6 +187,82 @@ public void testEnforcedCooldownPeriod() throws IOException {\n         assertThat(repository.threadPool().relativeTimeInNanos() - beforeFastDelete, lessThan(TEST_COOLDOWN_PERIOD.getNanos()));\n     }\n \n+    public void testRequestStats() throws Exception {\n+        final String repository = createRepository(randomName());\n+        final String index = \"index-no-merges\";\n+        createIndex(index, Settings.builder()\n+            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)\n+            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n+            .build());\n+\n+        final long nbDocs = randomLongBetween(100, 1000);\n+        try (BackgroundIndexer indexer = new BackgroundIndexer(index, \"_doc\", client(), (int) nbDocs)) {\n+            waitForDocs(nbDocs, indexer);\n+        }\n+\n+        flushAndRefresh(index);\n+        ForceMergeResponse forceMerge = client().admin().indices().prepareForceMerge(index).setFlush(true).setMaxNumSegments(1).get();\n+        assertThat(forceMerge.getSuccessfulShards(), equalTo(1));\n+        assertHitCount(client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get(), nbDocs);\n+\n+        final String snapshot = \"snapshot\";\n+        assertSuccessfulSnapshot(client().admin().cluster().prepareCreateSnapshot(repository, snapshot)\n+            .setWaitForCompletion(true).setIndices(index));\n+\n+        assertAcked(client().admin().indices().prepareDelete(index));\n+\n+        assertSuccessfulRestore(client().admin().cluster().prepareRestoreSnapshot(repository, snapshot).setWaitForCompletion(true));\n+        ensureGreen(index);\n+        assertHitCount(client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get(), nbDocs);\n+\n+        assertAcked(client().admin().cluster().prepareDeleteSnapshot(repository, snapshot).get());\n+\n+        final RepositoryStats repositoryStats = StreamSupport.stream(\n+            internalCluster().getInstances(RepositoriesService.class).spliterator(), false)\n+            .map(repositoriesService -> {\n+                try {\n+                    return repositoriesService.repository(repository);\n+                } catch (RepositoryMissingException e) {\n+                    return null;\n+                }\n+            })\n+            .filter(r -> r != null)\n+            .map(r -> r.stats())\n+            .reduce((s1, s2) -> s1.combine(s2))\n+            .get();\n+        final long sdkGetCalls = repositoryStats.requestCounts.get(\"GET\");\n+        final long sdkListCalls = repositoryStats.requestCounts.get(\"LIST\");\n+\n+        final long getCalls = handlers.values().stream()\n+            .mapToLong(h -> {\n+                if (h instanceof S3HttpHandler) {\n+                    return ((S3HttpHandler) h).getCalls.get();\n+                } else if (h instanceof S3ErroneousHttpHandler) {\n+                    return ((S3ErroneousHttpHandler) h).getCalls.get();\n+                } else {\n+                    return 0L;\n+                }\n+            })\n+            .sum();\n+        final long listCalls = handlers.values().stream().filter(h -> h instanceof S3HttpHandler)", "originalCommit": "d060429f92dc2938e0c800f8bfd6bd497579c1d6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc2MzQ5Nw==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r406763497", "bodyText": "This won't work (I think that's the reason for the test failure I mentioned). The handlers field does not contain the erroneous handler wrappers.See org.elasticsearch.repositories.blobstore.ESMockAPIBasedRepositoryIntegTestCase#setUpHttpServer:\n    @Before\n    public void setUpHttpServer() {\n        handlers = createHttpHandlers();\n        handlers.forEach((c, h) -> httpServer.createContext(c, wrap(randomBoolean() ? createErroneousHttpHandler(h) : h, logger)));\n    }\n\nyou'll have to put the erroneous handlers into another map (so you get the counts from both the normal and the erroneous wrappers by going over both maps) or similar.", "author": "original-brownbear", "createdAt": "2020-04-10T13:44:24Z", "path": "plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java", "diffHunk": "@@ -176,6 +187,82 @@ public void testEnforcedCooldownPeriod() throws IOException {\n         assertThat(repository.threadPool().relativeTimeInNanos() - beforeFastDelete, lessThan(TEST_COOLDOWN_PERIOD.getNanos()));\n     }\n \n+    public void testRequestStats() throws Exception {\n+        final String repository = createRepository(randomName());\n+        final String index = \"index-no-merges\";\n+        createIndex(index, Settings.builder()\n+            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)\n+            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n+            .build());\n+\n+        final long nbDocs = randomLongBetween(100, 1000);\n+        try (BackgroundIndexer indexer = new BackgroundIndexer(index, \"_doc\", client(), (int) nbDocs)) {\n+            waitForDocs(nbDocs, indexer);\n+        }\n+\n+        flushAndRefresh(index);\n+        ForceMergeResponse forceMerge = client().admin().indices().prepareForceMerge(index).setFlush(true).setMaxNumSegments(1).get();\n+        assertThat(forceMerge.getSuccessfulShards(), equalTo(1));\n+        assertHitCount(client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get(), nbDocs);\n+\n+        final String snapshot = \"snapshot\";\n+        assertSuccessfulSnapshot(client().admin().cluster().prepareCreateSnapshot(repository, snapshot)\n+            .setWaitForCompletion(true).setIndices(index));\n+\n+        assertAcked(client().admin().indices().prepareDelete(index));\n+\n+        assertSuccessfulRestore(client().admin().cluster().prepareRestoreSnapshot(repository, snapshot).setWaitForCompletion(true));\n+        ensureGreen(index);\n+        assertHitCount(client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get(), nbDocs);\n+\n+        assertAcked(client().admin().cluster().prepareDeleteSnapshot(repository, snapshot).get());\n+\n+        final RepositoryStats repositoryStats = StreamSupport.stream(\n+            internalCluster().getInstances(RepositoriesService.class).spliterator(), false)\n+            .map(repositoriesService -> {\n+                try {\n+                    return repositoriesService.repository(repository);\n+                } catch (RepositoryMissingException e) {\n+                    return null;\n+                }\n+            })\n+            .filter(r -> r != null)\n+            .map(r -> r.stats())\n+            .reduce((s1, s2) -> s1.combine(s2))\n+            .get();\n+        final long sdkGetCalls = repositoryStats.requestCounts.get(\"GET\");\n+        final long sdkListCalls = repositoryStats.requestCounts.get(\"LIST\");\n+\n+        final long getCalls = handlers.values().stream()", "originalCommit": "d060429f92dc2938e0c800f8bfd6bd497579c1d6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2NzI2MA==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r407967260", "bodyText": "I think we could add a counting http handler that would wrap the handlers (similarly to what ExceptionCatchingHttpHandler does) and that would update counters when receiving an HttpExchange.\nI think we're interesting in couting all GETs including the retries?", "author": "tlrx", "createdAt": "2020-04-14T08:44:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc2MzQ5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc2NDUwNA==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r406764504", "bodyText": "NIT: Revert", "author": "original-brownbear", "createdAt": "2020-04-10T13:47:01Z", "path": "plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobStore.java", "diffHunk": "@@ -135,4 +151,5 @@ public static CannedAccessControlList initCannedACL(String cannedACL) {\n \n         throw new BlobStoreException(\"cannedACL is not valid: [\" + cannedACL + \"]\");\n     }\n+", "originalCommit": "d060429f92dc2938e0c800f8bfd6bd497579c1d6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjc2NjAwNA==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r406766004", "bodyText": "You could just keep these collectors as fields on S3BlobStore and have getters for them on it?\nThen you save adding new fields to the retrying input stream and containers and don't have to create a new instance for every container + get request.", "author": "original-brownbear", "createdAt": "2020-04-10T13:50:24Z", "path": "plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobContainer.java", "diffHunk": "@@ -78,10 +82,22 @@\n     private final S3BlobStore blobStore;\n     private final String keyPath;\n \n+    private final RequestMetricCollector listMetricCollector;\n+\n     S3BlobContainer(BlobPath path, S3BlobStore blobStore) {\n         super(path);\n         this.blobStore = blobStore;\n         this.keyPath = path.buildAsString();\n+        this.listMetricCollector = new RequestMetricCollector() {", "originalCommit": "d060429f92dc2938e0c800f8bfd6bd497579c1d6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "6c48c0735f75c156dfd4f76ad912c64b76bf5f2a", "url": "https://github.com/elastic/elasticsearch/commit/6c48c0735f75c156dfd4f76ad912c64b76bf5f2a", "message": "Armin's feedback", "committedDate": "2020-04-14T07:01:31Z", "type": "commit"}, {"oid": "af17d17ea8cab8976be6c4e695775a7c9006e10e", "url": "https://github.com/elastic/elasticsearch/commit/af17d17ea8cab8976be6c4e695775a7c9006e10e", "message": "Merge remote-tracking branch 'elastic/master' into record-list-get-calls", "committedDate": "2020-04-14T07:02:04Z", "type": "commit"}, {"oid": "fe1288bcac06bbe0ddca61bd922f08d4412ea39b", "url": "https://github.com/elastic/elasticsearch/commit/fe1288bcac06bbe0ddca61bd922f08d4412ea39b", "message": "forbiddenAPIs", "committedDate": "2020-04-14T07:48:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk1OTAzMA==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r407959030", "bodyText": "Since it's an inner class, maybe just call it Stats", "author": "tlrx", "createdAt": "2020-04-14T08:31:16Z", "path": "plugins/repository-s3/src/main/java/org/elasticsearch/repositories/s3/S3BlobStore.java", "diffHunk": "@@ -135,4 +173,18 @@ public static CannedAccessControlList initCannedACL(String cannedACL) {\n \n         throw new BlobStoreException(\"cannedACL is not valid: [\" + cannedACL + \"]\");\n     }\n+\n+    static class S3Stats {", "originalCommit": "fe1288bcac06bbe0ddca61bd922f08d4412ea39b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2MzU2OA==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r407963568", "bodyText": "Can you remove the log message and add them to the assertEquals() methods instead?", "author": "tlrx", "createdAt": "2020-04-14T08:38:48Z", "path": "plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java", "diffHunk": "@@ -176,6 +187,94 @@ public void testEnforcedCooldownPeriod() throws IOException {\n         assertThat(repository.threadPool().relativeTimeInNanos() - beforeFastDelete, lessThan(TEST_COOLDOWN_PERIOD.getNanos()));\n     }\n \n+    public void testRequestStats() throws Exception {\n+        final String repository = createRepository(randomName());\n+        final String index = \"index-no-merges\";\n+        createIndex(index, Settings.builder()\n+            .put(IndexMetadata.SETTING_NUMBER_OF_SHARDS, 1)\n+            .put(IndexMetadata.SETTING_NUMBER_OF_REPLICAS, 0)\n+            .build());\n+\n+        final long nbDocs = randomLongBetween(100, 1000);\n+        try (BackgroundIndexer indexer = new BackgroundIndexer(index, \"_doc\", client(), (int) nbDocs)) {\n+            waitForDocs(nbDocs, indexer);\n+        }\n+\n+        flushAndRefresh(index);\n+        ForceMergeResponse forceMerge = client().admin().indices().prepareForceMerge(index).setFlush(true).setMaxNumSegments(1).get();\n+        assertThat(forceMerge.getSuccessfulShards(), equalTo(1));\n+        assertHitCount(client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get(), nbDocs);\n+\n+        final String snapshot = \"snapshot\";\n+        assertSuccessfulSnapshot(client().admin().cluster().prepareCreateSnapshot(repository, snapshot)\n+            .setWaitForCompletion(true).setIndices(index));\n+\n+        assertAcked(client().admin().indices().prepareDelete(index));\n+\n+        assertSuccessfulRestore(client().admin().cluster().prepareRestoreSnapshot(repository, snapshot).setWaitForCompletion(true));\n+        ensureGreen(index);\n+        assertHitCount(client().prepareSearch(index).setSize(0).setTrackTotalHits(true).get(), nbDocs);\n+\n+        assertAcked(client().admin().cluster().prepareDeleteSnapshot(repository, snapshot).get());\n+\n+        final RepositoryStats repositoryStats = StreamSupport.stream(\n+            internalCluster().getInstances(RepositoriesService.class).spliterator(), false)\n+            .map(repositoriesService -> {\n+                try {\n+                    return repositoriesService.repository(repository);\n+                } catch (RepositoryMissingException e) {\n+                    return null;\n+                }\n+            })\n+            .filter(r -> r != null)\n+            .map(r -> r.stats())\n+            .reduce((s1, s2) -> s1.combine(s2))\n+            .get();\n+        final long sdkGetCalls = repositoryStats.requestCounts.get(\"GET\");\n+        final long sdkListCalls = repositoryStats.requestCounts.get(\"LIST\");\n+\n+        final long getCalls = handlers.values().stream()\n+            .mapToLong(h -> {\n+                long count = 0;\n+                while (h instanceof DelegatingHttpHandler) {\n+                    if (h instanceof S3ErroneousHttpHandler) {\n+                        count += ((S3ErroneousHttpHandler) h).getCalls.get();\n+                    }\n+                    h = ((DelegatingHttpHandler) h).getDelegate();\n+                }\n+                if (h instanceof S3HttpHandler) {\n+                    return count + ((S3HttpHandler) h).getCalls.get();\n+                } else {\n+                    assert false;\n+                    return count;\n+                }\n+            })\n+            .sum();\n+        final long listCalls = handlers.values().stream()\n+            .mapToLong(h -> {\n+                long count = 0;\n+                while (h instanceof DelegatingHttpHandler) {\n+                    if (h instanceof S3ErroneousHttpHandler) {\n+                        count += ((S3ErroneousHttpHandler) h).listCalls.get();\n+                    }\n+                    h = ((DelegatingHttpHandler) h).getDelegate();\n+                }\n+                if (h instanceof S3HttpHandler) {\n+                    return count + ((S3HttpHandler) h).listCalls.get();\n+                } else {\n+                    assert false;\n+                    return count;\n+                }\n+            })\n+            .sum();\n+\n+        logger.info(\"SDK sent {} GET calls and handler measured {} GET calls\", sdkGetCalls, getCalls);", "originalCommit": "fe1288bcac06bbe0ddca61bd922f08d4412ea39b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2NzU2Ng==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r407967566", "bodyText": "I'd move this in a dedicated HttpHandler that would wrap other handlers", "author": "tlrx", "createdAt": "2020-04-14T08:45:06Z", "path": "plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/S3BlobStoreRepositoryTests.java", "diffHunk": "@@ -256,10 +355,24 @@ private void validateAuthHeader(HttpExchange exchange) {\n     @SuppressForbidden(reason = \"this test uses a HttpServer to emulate an S3 endpoint\")\n     private static class S3ErroneousHttpHandler extends ErroneousHttpHandler {\n \n+        public final AtomicLong getCalls = new AtomicLong();", "originalCommit": "fe1288bcac06bbe0ddca61bd922f08d4412ea39b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2OTI1NA==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r407969254", "bodyText": "Maybe rename this method to merge? (to be consistent with other Stats classes that have similar methods like ForecastStats, SnapshotPolicyStats etc)", "author": "tlrx", "createdAt": "2020-04-14T08:47:54Z", "path": "server/src/main/java/org/elasticsearch/repositories/RepositoryStats.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.repositories;\n+\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.common.io.stream.StreamOutput;\n+import org.elasticsearch.common.io.stream.Writeable;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class RepositoryStats implements Writeable {\n+\n+    public static final RepositoryStats EMPTY_STATS = new RepositoryStats(Collections.emptyMap());\n+\n+    public final Map<String, Long> requestCounts;\n+\n+    public RepositoryStats(Map<String, Long> requestCounts) {\n+        this.requestCounts = Collections.unmodifiableMap(requestCounts);\n+    }\n+\n+    public RepositoryStats(StreamInput in) throws IOException {\n+        this.requestCounts = in.readMap(StreamInput::readString, StreamInput::readLong);\n+    }\n+\n+    public RepositoryStats combine(RepositoryStats otherStats) {", "originalCommit": "fe1288bcac06bbe0ddca61bd922f08d4412ea39b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3NDg0MQ==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r407974841", "bodyText": "Should we catch the repository missing exception here - in case the repository is not yet known by this node - and return empty stats too?", "author": "tlrx", "createdAt": "2020-04-14T08:56:30Z", "path": "x-pack/plugin/searchable-snapshots/src/main/java/org/elasticsearch/xpack/searchablesnapshots/action/TransportRepositoryStatsAction.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Copyright Elasticsearch B.V. and/or licensed to Elasticsearch B.V. under one\n+ * or more contributor license agreements. Licensed under the Elastic License;\n+ * you may not use this file except in compliance with the Elastic License.\n+ */\n+\n+package org.elasticsearch.xpack.searchablesnapshots.action;\n+\n+import org.elasticsearch.action.FailedNodeException;\n+import org.elasticsearch.action.support.ActionFilters;\n+import org.elasticsearch.action.support.nodes.TransportNodesAction;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.inject.Inject;\n+import org.elasticsearch.common.io.stream.StreamInput;\n+import org.elasticsearch.license.XPackLicenseState;\n+import org.elasticsearch.repositories.RepositoriesService;\n+import org.elasticsearch.repositories.Repository;\n+import org.elasticsearch.repositories.RepositoryStats;\n+import org.elasticsearch.tasks.Task;\n+import org.elasticsearch.threadpool.ThreadPool;\n+import org.elasticsearch.transport.TransportService;\n+import org.elasticsearch.xpack.searchablesnapshots.SearchableSnapshots;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Objects;\n+\n+public class TransportRepositoryStatsAction extends TransportNodesAction<\n+    RepositoryStatsRequest,\n+    RepositoryStatsResponse,\n+    RepositoryStatsNodeRequest,\n+    RepositoryStatsNodeResponse> {\n+\n+    private final RepositoriesService repositoriesService;\n+    private final XPackLicenseState licenseState;\n+\n+    @Inject\n+    public TransportRepositoryStatsAction(\n+        ThreadPool threadPool,\n+        ClusterService clusterService,\n+        TransportService transportService,\n+        ActionFilters actionFilters,\n+        RepositoriesService repositoriesService,\n+        XPackLicenseState licenseState\n+    ) {\n+        super(\n+            RepositoryStatsAction.NAME,\n+            threadPool,\n+            clusterService,\n+            transportService,\n+            actionFilters,\n+            RepositoryStatsRequest::new,\n+            RepositoryStatsNodeRequest::new,\n+            ThreadPool.Names.SAME,\n+            RepositoryStatsNodeResponse.class\n+        );\n+        this.repositoriesService = repositoriesService;\n+        this.licenseState = Objects.requireNonNull(licenseState);\n+    }\n+\n+    @Override\n+    protected RepositoryStatsResponse newResponse(\n+        RepositoryStatsRequest request,\n+        List<RepositoryStatsNodeResponse> nodes,\n+        List<FailedNodeException> failures\n+    ) {\n+        return new RepositoryStatsResponse(clusterService.getClusterName(), nodes, failures);\n+    }\n+\n+    @Override\n+    protected RepositoryStatsNodeRequest newNodeRequest(RepositoryStatsRequest request) {\n+        return new RepositoryStatsNodeRequest(request.getRepository());\n+    }\n+\n+    @Override\n+    protected RepositoryStatsNodeResponse newNodeResponse(StreamInput in) throws IOException {\n+        return new RepositoryStatsNodeResponse(in);\n+    }\n+\n+    @Override\n+    protected RepositoryStatsNodeResponse nodeOperation(RepositoryStatsNodeRequest request, Task task) {\n+        SearchableSnapshots.ensureValidLicense(licenseState);\n+        if (clusterService.localNode().isMasterNode() == false && clusterService.localNode().isDataNode() == false) {\n+            return new RepositoryStatsNodeResponse(clusterService.localNode(), RepositoryStats.EMPTY_STATS);\n+        }\n+        final Repository repository = repositoriesService.repository(request.getRepository());", "originalCommit": "fe1288bcac06bbe0ddca61bd922f08d4412ea39b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODAxMDExNg==", "url": "https://github.com/elastic/elasticsearch/pull/55051#discussion_r408010116", "bodyText": "I would like to avoid that as it would then silently provide partial stats", "author": "ywelsch", "createdAt": "2020-04-14T09:51:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3NDg0MQ=="}], "type": "inlineReview"}, {"oid": "08ce54c2a45499436defb023b1f3d68a6ed075a2", "url": "https://github.com/elastic/elasticsearch/commit/08ce54c2a45499436defb023b1f3d68a6ed075a2", "message": "Tanguy feedback", "committedDate": "2020-04-14T10:03:38Z", "type": "commit"}]}