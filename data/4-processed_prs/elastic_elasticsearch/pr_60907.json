{"pr_number": 60907, "pr_title": "Merge FetchSubPhase hitsExecute and hitExecute methods", "pr_createdAt": "2020-08-10T14:43:59Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/60907", "timeline": [{"oid": "b7557b5a14b7c9203e4bfe1a5bd84a97fe3b9457", "url": "https://github.com/elastic/elasticsearch/commit/b7557b5a14b7c9203e4bfe1a5bd84a97fe3b9457", "message": "Merge FetchSubPhase hitsExecute and hitExecute methods", "committedDate": "2020-08-10T14:35:31Z", "type": "commit"}, {"oid": "72a1cd70bffbf8bd12e57a5aa92af2486ae0d94e", "url": "https://github.com/elastic/elasticsearch/commit/72a1cd70bffbf8bd12e57a5aa92af2486ae0d94e", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute", "committedDate": "2020-08-10T21:06:38Z", "type": "commit"}, {"oid": "220724300e534d77094978fe402d0290f90104be", "url": "https://github.com/elastic/elasticsearch/commit/220724300e534d77094978fe402d0290f90104be", "message": "WIP: percolator needs work to compile", "committedDate": "2020-08-11T14:49:44Z", "type": "commit"}, {"oid": "22edcdcc2f0604cee27a30de8f2eaaddd0ed47e1", "url": "https://github.com/elastic/elasticsearch/commit/22edcdcc2f0604cee27a30de8f2eaaddd0ed47e1", "message": "still some compilation failures in percolator tests", "committedDate": "2020-08-12T11:08:03Z", "type": "commit"}, {"oid": "43d93d7a3c9ecd9db82995c189b08759b2cf7778", "url": "https://github.com/elastic/elasticsearch/commit/43d93d7a3c9ecd9db82995c189b08759b2cf7778", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute", "committedDate": "2020-08-17T08:45:54Z", "type": "commit"}, {"oid": "06495cf076e0d1705410b48bf769a776be3b7620", "url": "https://github.com/elastic/elasticsearch/commit/06495cf076e0d1705410b48bf769a776be3b7620", "message": "fix percolator", "committedDate": "2020-08-17T15:04:04Z", "type": "commit"}, {"oid": "8ced182b104367084fcef7a1846a0734f0cabc0d", "url": "https://github.com/elastic/elasticsearch/commit/8ced182b104367084fcef7a1846a0734f0cabc0d", "message": "checkstyle", "committedDate": "2020-08-17T15:26:41Z", "type": "commit"}, {"oid": "5b913ef5768877a0a08d64c72008bb48c01e11d5", "url": "https://github.com/elastic/elasticsearch/commit/5b913ef5768877a0a08d64c72008bb48c01e11d5", "message": "checkstyle", "committedDate": "2020-08-17T15:33:15Z", "type": "commit"}, {"oid": "da36dfc2b6ac38b46abe58da898db87fd21ecece", "url": "https://github.com/elastic/elasticsearch/commit/da36dfc2b6ac38b46abe58da898db87fd21ecece", "message": "javadocs; use unrewritten query in highlight", "committedDate": "2020-08-19T15:04:26Z", "type": "commit"}, {"oid": "4f574db14f528b8287dddc95762ecf2b815267be", "url": "https://github.com/elastic/elasticsearch/commit/4f574db14f528b8287dddc95762ecf2b815267be", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute", "committedDate": "2020-08-19T15:20:26Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQxMDQzNw==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473410437", "bodyText": "Just a personal preference, but I don't think this class FetchPhaseExecutor adds much in terms of clarity + modularity. We could easily inline these loops in FetchPhase#execute.", "author": "jtibshirani", "createdAt": "2020-08-19T22:58:47Z", "path": "server/src/main/java/org/elasticsearch/search/fetch/FetchPhaseExecutor.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.fetch;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.search.internal.SearchContext;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+public class FetchPhaseExecutor {", "originalCommit": "4f574db14f528b8287dddc95762ecf2b815267be", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQxODYyNw==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473418627", "bodyText": "Small comment, it would be nice move the root doc lookup into this method too:\n      int rootDocId = findRootDocumentIfNested(context, readerContext, subDocId);", "author": "jtibshirani", "createdAt": "2020-08-19T23:10:11Z", "path": "server/src/main/java/org/elasticsearch/search/fetch/FetchPhase.java", "diffHunk": "@@ -223,23 +217,34 @@ private int findRootDocumentIfNested(SearchContext context, LeafReaderContext su\n         return -1;\n     }\n \n+    private HitContext prepareHitContext(SearchContext context, FieldsVisitor fieldsVisitor, int docId,\n+                                         int subDocId, int rootDocId, Map<String, Set<String>> storedToRequestedFields,\n+                                         LeafReaderContext subReaderContext, Map<String, Object> sharedCache) throws IOException {\n+        if (rootDocId == -1) {", "originalCommit": "4f574db14f528b8287dddc95762ecf2b815267be", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQyMTI2NA==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473421264", "bodyText": "Small clarification: 'doc ID order' ?", "author": "jtibshirani", "createdAt": "2020-08-19T23:14:07Z", "path": "server/src/main/java/org/elasticsearch/search/fetch/FetchSubPhaseExecutor.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.fetch;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.search.fetch.FetchSubPhase.HitContext;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Executes the logic for a {@link FetchSubPhase} against a particular leaf reader and hit\n+ */\n+public interface FetchSubPhaseExecutor {\n+\n+    /**\n+     * Called when moving to the next {@link LeafReaderContext} for a set of hits\n+     */\n+    void setNextReader(LeafReaderContext readerContext) throws IOException;\n+\n+    /**\n+     * Called in doc order for each hit in a leaf reader", "originalCommit": "4f574db14f528b8287dddc95762ecf2b815267be", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQyMjM2OA==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473422368", "bodyText": "Is it okay to remove these catch and finally blocks?", "author": "jtibshirani", "createdAt": "2020-08-19T23:15:40Z", "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/ExplainPhase.java", "diffHunk": "@@ -32,24 +33,27 @@\n public final class ExplainPhase implements FetchSubPhase {\n \n     @Override\n-    public void hitExecute(SearchContext context, HitContext hitContext) {\n+    public FetchSubPhaseExecutor getExecutor(SearchContext context) {\n         if (context.explain() == false || context.hasOnlySuggest()) {\n-            return;\n+            return null;\n         }\n-        try {\n-            final int topLevelDocId = hitContext.hit().docId();\n-            Explanation explanation = context.searcher().explain(context.query(), topLevelDocId);\n+        return new FetchSubPhaseExecutor() {\n+            @Override\n+            public void setNextReader(LeafReaderContext readerContext) {\n \n-            for (RescoreContext rescore : context.rescore()) {\n-                explanation = rescore.rescorer().explain(topLevelDocId, context.searcher(), rescore, explanation);\n             }\n-            // we use the top level doc id, since we work with the top level searcher\n-            hitContext.hit().explanation(explanation);\n-        } catch (IOException e) {", "originalCommit": "4f574db14f528b8287dddc95762ecf2b815267be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzg4Njc5MA==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473886790", "bodyText": "The finally block is a no-op (nowhere in the code do we add a releasable for Lifetime.COLLECTION and it will be removed entirely by the ReaderContext refactor) so it's safe to remove.  Given that execute is declared as throws IOException it seems weird to catch IOException and rethrow as something else; but perhaps FetchPhase itself should throw a FetchPhaseExecutionException?", "author": "romseygeek", "createdAt": "2020-08-20T11:02:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQyMjM2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc2ODg0Mg==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r476768842", "bodyText": "Maybe we could revert to the old behavior for now to be really safe and scope down the change? My impression is that the fetch code hasn't been refactored in a while and isn't extensively tested.", "author": "jtibshirani", "createdAt": "2020-08-25T21:47:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQyMjM2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQyODUxNw==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473428517", "bodyText": "Should we assert or throw if scorerSupplier is null here? It looks like previously we threw an IllegalStateException. The same question holds for the advance call below.", "author": "jtibshirani", "createdAt": "2020-08-19T23:24:29Z", "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/FetchScorePhase.java", "diffHunk": "@@ -25,48 +25,44 @@\n import org.apache.lucene.search.Scorer;\n import org.apache.lucene.search.ScorerSupplier;\n import org.apache.lucene.search.Weight;\n-import org.elasticsearch.search.SearchHit;\n import org.elasticsearch.search.fetch.FetchSubPhase;\n+import org.elasticsearch.search.fetch.FetchSubPhaseExecutor;\n import org.elasticsearch.search.internal.SearchContext;\n \n import java.io.IOException;\n-import java.util.Iterator;\n \n public class FetchScorePhase implements FetchSubPhase {\n \n     @Override\n-    public void hitsExecute(SearchContext context, SearchHit[] hits) throws IOException {\n-        if (context.trackScores() == false || hits.length == 0 ||\n-                // scores were already computed since they are needed on the coordinated node to merge top hits\n-                context.sort() == null) {\n-            return;\n+    public FetchSubPhaseExecutor getExecutor(SearchContext context) throws IOException {\n+        if (context.trackScores() == false || context.docIdsToLoadSize() == 0 ||\n+            // scores were already computed since they are needed on the coordinated node to merge top hits\n+            context.sort() == null) {\n+            return null;\n         }\n-\n         final IndexSearcher searcher = context.searcher();\n         final Weight weight = searcher.createWeight(searcher.rewrite(context.query()), ScoreMode.COMPLETE, 1);\n-        Iterator<LeafReaderContext> leafContextIterator = searcher.getIndexReader().leaves().iterator();\n-        LeafReaderContext leafContext = null;\n-        Scorer scorer = null;\n-        for (SearchHit hit : hits) {\n-            if (leafContext == null || leafContext.docBase + leafContext.reader().maxDoc() <= hit.docId()) {\n-                do {\n-                    leafContext = leafContextIterator.next();\n-                } while (leafContext == null || leafContext.docBase + leafContext.reader().maxDoc() <= hit.docId());\n-                ScorerSupplier scorerSupplier = weight.scorerSupplier(leafContext);\n+        return new FetchSubPhaseExecutor() {\n+\n+            Scorer scorer;\n+\n+            @Override\n+            public void setNextReader(LeafReaderContext readerContext) throws IOException {\n+                ScorerSupplier scorerSupplier = weight.scorerSupplier(readerContext);\n                 if (scorerSupplier == null) {\n-                    throw new IllegalStateException(\"Can't compute score on document \" + hit + \" as it doesn't match the query\");\n+                    scorer = null;", "originalCommit": "4f574db14f528b8287dddc95762ecf2b815267be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzkxOTA0MQ==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473919041", "bodyText": "I think this can safely be turned into an assertion once the ReaderContext branch has merged, but should probably stay an Exception for now - I will reinstate it.", "author": "romseygeek", "createdAt": "2020-08-20T12:04:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQyODUxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQ3NTM1MQ==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473475351", "bodyText": "I assume this is okay, but wanted to check -- before we looped over fields then hits, but now we loop over hits then fields. This means that we hold onto a (potentially large) number of doc values iterators for the duration of the fetch phase. Are there any concerns around this change?", "author": "jtibshirani", "createdAt": "2020-08-20T00:33:12Z", "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/FetchDocValuesPhase.java", "diffHunk": "@@ -51,103 +48,191 @@\n public final class FetchDocValuesPhase implements FetchSubPhase {\n \n     @Override\n-    public void hitsExecute(SearchContext context, SearchHit[] hits) throws IOException {\n-\n+    public FetchSubPhaseExecutor getExecutor(SearchContext context) throws IOException {\n         if (context.collapse() != null) {\n             // retrieve the `doc_value` associated with the collapse field\n             String name = context.collapse().getFieldName();\n             if (context.docValuesContext() == null) {\n                 context.docValuesContext(new FetchDocValuesContext(\n-                        Collections.singletonList(new FieldAndFormat(name, null))));\n+                    Collections.singletonList(new FieldAndFormat(name, null))));\n             } else if (context.docValuesContext().fields().stream().map(ff -> ff.field).anyMatch(name::equals) == false) {\n                 context.docValuesContext().fields().add(new FieldAndFormat(name, null));\n             }\n         }\n \n         if (context.docValuesContext() == null) {\n-            return;\n+            return null;\n         }\n \n+        List<DocValueField> fields = new ArrayList<>();\n         for (FieldAndFormat fieldAndFormat : context.docValuesContext().fields()) {\n-            String field = fieldAndFormat.field;\n-            MappedFieldType fieldType = context.mapperService().fieldType(field);\n-            if (fieldType != null) {\n-                final IndexFieldData<?> indexFieldData = context.getForField(fieldType);\n-                final boolean isNanosecond;\n-                if (indexFieldData instanceof IndexNumericFieldData) {\n-                    isNanosecond = ((IndexNumericFieldData) indexFieldData).getNumericType() == NumericType.DATE_NANOSECONDS;\n-                } else {\n-                    isNanosecond = false;\n-                }\n-                final DocValueFormat format;\n-                String formatDesc = fieldAndFormat.format;\n-                if (isNanosecond) {\n-                    format = withNanosecondResolution(fieldType.docValueFormat(formatDesc, null));\n-                } else {\n-                    format = fieldType.docValueFormat(formatDesc, null);\n+            DocValueField f = buildField(context, fieldAndFormat);", "originalCommit": "4f574db14f528b8287dddc95762ecf2b815267be", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzg4NzYzMw==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r473887633", "bodyText": "I can see that it may cause memory spikes, but I think DV iterators are generally low-impact.  I'll try and run some benchmarks to see if there's an appreciable difference", "author": "romseygeek", "createdAt": "2020-08-20T11:03:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQ3NTM1MQ=="}], "type": "inlineReview"}, {"oid": "2cc3fa4667881ed8ad26c9ed44d48944d1c69a7b", "url": "https://github.com/elastic/elasticsearch/commit/2cc3fa4667881ed8ad26c9ed44d48944d1c69a7b", "message": "feedback", "committedDate": "2020-08-20T12:12:38Z", "type": "commit"}, {"oid": "fbb22456d8af2f548318bcdf13dc4ed489b4075e", "url": "https://github.com/elastic/elasticsearch/commit/fbb22456d8af2f548318bcdf13dc4ed489b4075e", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute", "committedDate": "2020-08-20T12:12:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU2Mjc3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r474562779", "bodyText": "Is it still needed ? From what I understand this is now a global cache for the sub phases but I don't see where it is used as such. Do you have specific plans for this cache, maybe we can remove it now that sub phases can have a state ?", "author": "jimczi", "createdAt": "2020-08-21T09:15:40Z", "path": "server/src/main/java/org/elasticsearch/search/fetch/FetchSubPhase.java", "diffHunk": "@@ -36,19 +35,21 @@\n public interface FetchSubPhase {\n \n     class HitContext {\n-        private SearchHit hit;\n-        private IndexSearcher searcher;\n-        private LeafReaderContext readerContext;\n-        private int docId;\n+        private final SearchHit hit;\n+        private final IndexSearcher searcher;\n+        private final LeafReaderContext readerContext;\n+        private final int docId;\n         private final SourceLookup sourceLookup = new SourceLookup();\n-        private Map<String, Object> cache;\n+        private final Map<String, Object> cache;", "originalCommit": "fbb22456d8af2f548318bcdf13dc4ed489b4075e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ1MTA3Mg==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r475451072", "bodyText": "Some of the highlighter impls use it; I agree we should be able to remove it but I think it will need some changes to the Highlighter API (HighlightPhase can have state, but highlighters themselves don't) so I'll add a TODO and we can do it in a followup.", "author": "romseygeek", "createdAt": "2020-08-24T09:12:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU2Mjc3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ1Mzc4NQ==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r475453785", "bodyText": "yes I know, what I was trying to understand is whether that will be an issue to change the behavior of this map. If I understand correctly, we don't clear the map after each document, so I have no idea if this is acceptable for the usage that we have.", "author": "jimczi", "createdAt": "2020-08-24T09:17:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU2Mjc3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ3MTQwOA==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r475471408", "bodyText": "OIC, yes, this is actually preserving previous behaviour - we used to call HitContext.reset() which would change alter everything except the cache, so that things put there would be re-used across different hits.", "author": "romseygeek", "createdAt": "2020-08-24T09:36:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU2Mjc3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU2NTQ1MA==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r474565450", "bodyText": "Maybe FetchSubPhaseCollector since it \"collects\" top hits ?", "author": "jimczi", "createdAt": "2020-08-21T09:18:47Z", "path": "server/src/main/java/org/elasticsearch/search/fetch/FetchSubPhaseExecutor.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to Elasticsearch under one or more contributor\n+ * license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright\n+ * ownership. Elasticsearch licenses this file to you under\n+ * the Apache License, Version 2.0 (the \"License\"); you may\n+ * not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.elasticsearch.search.fetch;\n+\n+import org.apache.lucene.index.LeafReaderContext;\n+import org.elasticsearch.search.fetch.FetchSubPhase.HitContext;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Executes the logic for a {@link FetchSubPhase} against a particular leaf reader and hit\n+ */\n+public interface FetchSubPhaseExecutor {", "originalCommit": "fbb22456d8af2f548318bcdf13dc4ed489b4075e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ1MTE5MQ==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r475451191", "bodyText": "++", "author": "romseygeek", "createdAt": "2020-08-24T09:12:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU2NTQ1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTcyODU4OA==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r475728588", "bodyText": "I ended up going with FetchSubPhaseProcessor, as we're processing hits rather than collecting them I think...", "author": "romseygeek", "createdAt": "2020-08-24T16:10:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDU2NTQ1MA=="}], "type": "inlineReview"}, {"oid": "a7457ac466f40b15247159671b4e27f9083a6dba", "url": "https://github.com/elastic/elasticsearch/commit/a7457ac466f40b15247159671b4e27f9083a6dba", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute", "committedDate": "2020-08-24T09:13:48Z", "type": "commit"}, {"oid": "453277799ee694829dedad23fe53f57217c2eb7f", "url": "https://github.com/elastic/elasticsearch/commit/453277799ee694829dedad23fe53f57217c2eb7f", "message": "rename; fix nested source reads", "committedDate": "2020-08-24T16:02:34Z", "type": "commit"}, {"oid": "82803f11d7d1f7271e541f03e54d670c40a63713", "url": "https://github.com/elastic/elasticsearch/commit/82803f11d7d1f7271e541f03e54d670c40a63713", "message": "highlight through aliases", "committedDate": "2020-08-24T17:26:06Z", "type": "commit"}, {"oid": "ec6fef29c344eac67c7d63906335efb616697763", "url": "https://github.com/elastic/elasticsearch/commit/ec6fef29c344eac67c7d63906335efb616697763", "message": "preserve highlight fields ordering", "committedDate": "2020-08-25T09:59:42Z", "type": "commit"}, {"oid": "9c747bdbacb9ce9ad8bedad57dd1b8dabf5a7a0e", "url": "https://github.com/elastic/elasticsearch/commit/9c747bdbacb9ce9ad8bedad57dd1b8dabf5a7a0e", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute", "committedDate": "2020-08-25T10:04:44Z", "type": "commit"}, {"oid": "6d4a5b24ab2593197bf433a3d74745f0f3ee3ea1", "url": "https://github.com/elastic/elasticsearch/commit/6d4a5b24ab2593197bf433a3d74745f0f3ee3ea1", "message": "getCollector -> getProcessor", "committedDate": "2020-08-25T10:16:32Z", "type": "commit"}, {"oid": "218a15a4b1168d111a4d1e7a7a40e02074c886eb", "url": "https://github.com/elastic/elasticsearch/commit/218a15a4b1168d111a4d1e7a7a40e02074c886eb", "message": "matching queries", "committedDate": "2020-08-25T11:29:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc0Mzc1OQ==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r476743759", "bodyText": "Small comment, this could be private (or we could just inline it).", "author": "jtibshirani", "createdAt": "2020-08-25T21:19:14Z", "path": "server/src/internalClusterTest/java/org/elasticsearch/search/fetch/FetchSubPhasePluginIT.java", "diffHunk": "@@ -113,6 +114,20 @@ public void testPlugin() throws Exception {\n         private static final String NAME = \"term_vectors_fetch\";\n \n         @Override\n+        public FetchSubPhaseProcessor getProcessor(SearchContext searchContext) {\n+            return new FetchSubPhaseProcessor() {\n+                @Override\n+                public void setNextReader(LeafReaderContext readerContext) {\n+\n+                }\n+\n+                @Override\n+                public void process(HitContext hitContext) {\n+                    hitExecute(searchContext, hitContext);\n+                }\n+            };\n+        }\n+\n         public void hitExecute(SearchContext context, HitContext hitContext) {", "originalCommit": "218a15a4b1168d111a4d1e7a7a40e02074c886eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc1MDA4Ng==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r476750086", "bodyText": "Very small comment, it's a bit unusual to have an else after a throw ?", "author": "jtibshirani", "createdAt": "2020-08-25T21:26:07Z", "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/FetchScorePhase.java", "diffHunk": "@@ -25,48 +25,44 @@\n import org.apache.lucene.search.Scorer;\n import org.apache.lucene.search.ScorerSupplier;\n import org.apache.lucene.search.Weight;\n-import org.elasticsearch.search.SearchHit;\n import org.elasticsearch.search.fetch.FetchSubPhase;\n+import org.elasticsearch.search.fetch.FetchSubPhaseProcessor;\n import org.elasticsearch.search.internal.SearchContext;\n \n import java.io.IOException;\n-import java.util.Iterator;\n \n public class FetchScorePhase implements FetchSubPhase {\n \n     @Override\n-    public void hitsExecute(SearchContext context, SearchHit[] hits) throws IOException {\n-        if (context.trackScores() == false || hits.length == 0 ||\n-                // scores were already computed since they are needed on the coordinated node to merge top hits\n-                context.sort() == null) {\n-            return;\n+    public FetchSubPhaseProcessor getProcessor(SearchContext context) throws IOException {\n+        if (context.trackScores() == false || context.docIdsToLoadSize() == 0 ||\n+            // scores were already computed since they are needed on the coordinated node to merge top hits\n+            context.sort() == null) {\n+            return null;\n         }\n-\n         final IndexSearcher searcher = context.searcher();\n         final Weight weight = searcher.createWeight(searcher.rewrite(context.query()), ScoreMode.COMPLETE, 1);\n-        Iterator<LeafReaderContext> leafContextIterator = searcher.getIndexReader().leaves().iterator();\n-        LeafReaderContext leafContext = null;\n-        Scorer scorer = null;\n-        for (SearchHit hit : hits) {\n-            if (leafContext == null || leafContext.docBase + leafContext.reader().maxDoc() <= hit.docId()) {\n-                do {\n-                    leafContext = leafContextIterator.next();\n-                } while (leafContext == null || leafContext.docBase + leafContext.reader().maxDoc() <= hit.docId());\n-                ScorerSupplier scorerSupplier = weight.scorerSupplier(leafContext);\n+        return new FetchSubPhaseProcessor() {\n+\n+            Scorer scorer;\n+\n+            @Override\n+            public void setNextReader(LeafReaderContext readerContext) throws IOException {\n+                ScorerSupplier scorerSupplier = weight.scorerSupplier(readerContext);\n                 if (scorerSupplier == null) {\n-                    throw new IllegalStateException(\"Can't compute score on document \" + hit + \" as it doesn't match the query\");\n+                    throw new IllegalStateException(\"Can't compute score on document as it doesn't match the query\");\n+                } else {", "originalCommit": "218a15a4b1168d111a4d1e7a7a40e02074c886eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc2MzU3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r476763579", "bodyText": "It's great how these subphases become more readable.", "author": "jtibshirani", "createdAt": "2020-08-25T21:41:38Z", "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/MatchedQueriesPhase.java", "diffHunk": "@@ -41,53 +38,52 @@\n public final class MatchedQueriesPhase implements FetchSubPhase {\n \n     @Override\n-    public void hitsExecute(SearchContext context, SearchHit[] hits) {\n-        if (hits.length == 0 ||\n+    public FetchSubPhaseProcessor getProcessor(SearchContext context) throws IOException {\n+        if (context.docIdsToLoadSize() == 0 ||\n             // in case the request has only suggest, parsed query is null\n             context.parsedQuery() == null) {\n-            return;\n+            return null;\n         }\n-        @SuppressWarnings(\"unchecked\")\n-        List<String>[] matchedQueries = new List[hits.length];\n-        for (int i = 0; i < matchedQueries.length; ++i) {\n-            matchedQueries[i] = new ArrayList<>();\n-        }\n-\n         Map<String, Query> namedQueries = new HashMap<>(context.parsedQuery().namedFilters());\n         if (context.parsedPostFilter() != null) {\n             namedQueries.putAll(context.parsedPostFilter().namedFilters());\n         }\n+        if (namedQueries.isEmpty()) {\n+            return null;\n+        }\n+        Map<String, Weight> weights = new HashMap<>();\n+        for (Map.Entry<String, Query> entry : namedQueries.entrySet()) {\n+            weights.put(entry.getKey(),\n+                context.searcher().createWeight(context.searcher().rewrite(entry.getValue()), ScoreMode.COMPLETE_NO_SCORES, 1));\n+        }\n+        return new FetchSubPhaseProcessor() {\n \n-        try {\n-            for (Map.Entry<String, Query> entry : namedQueries.entrySet()) {\n-                String name = entry.getKey();\n-                Query query = entry.getValue();\n-                int readerIndex = -1;\n-                int docBase = -1;\n-                Weight weight = context.searcher().createWeight(context.searcher().rewrite(query), ScoreMode.COMPLETE_NO_SCORES, 1f);\n-                Bits matchingDocs = null;\n-                final IndexReader indexReader = context.searcher().getIndexReader();\n-                for (int i = 0; i < hits.length; ++i) {\n-                    SearchHit hit = hits[i];\n-                    int hitReaderIndex = ReaderUtil.subIndex(hit.docId(), indexReader.leaves());\n-                    if (readerIndex != hitReaderIndex) {\n-                        readerIndex = hitReaderIndex;\n-                        LeafReaderContext ctx = indexReader.leaves().get(readerIndex);\n-                        docBase = ctx.docBase;\n-                        // scorers can be costly to create, so reuse them across docs of the same segment\n-                        ScorerSupplier scorerSupplier = weight.scorerSupplier(ctx);\n-                        matchingDocs = Lucene.asSequentialAccessBits(ctx.reader().maxDoc(), scorerSupplier);\n-                    }\n-                    if (matchingDocs.get(hit.docId() - docBase)) {\n-                        matchedQueries[i].add(name);\n+            final Map<String, Bits> matchingIterators = new HashMap<>();\n+\n+            @Override\n+            public void setNextReader(LeafReaderContext readerContext) throws IOException {\n+                matchingIterators.clear();", "originalCommit": "218a15a4b1168d111a4d1e7a7a40e02074c886eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc4MDA2MA==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r476780060", "bodyText": "Could we perform this check only once for the whole subphase (maybe by reworking the contextBuilders method)? That would let us avoid adding the fieldNameContainsWildcards field to FieldHighlightContext.", "author": "jtibshirani", "createdAt": "2020-08-25T22:01:33Z", "path": "server/src/main/java/org/elasticsearch/search/fetch/subphase/highlight/HighlightPhase.java", "diffHunk": "@@ -28,34 +29,83 @@\n import org.elasticsearch.index.query.QueryShardContext;\n import org.elasticsearch.search.SearchShardTarget;\n import org.elasticsearch.search.fetch.FetchSubPhase;\n+import org.elasticsearch.search.fetch.FetchSubPhaseProcessor;\n import org.elasticsearch.search.internal.SearchContext;\n \n import java.util.Collection;\n import java.util.Collections;\n import java.util.HashMap;\n+import java.util.LinkedHashMap;\n import java.util.Map;\n+import java.util.function.Function;\n \n public class HighlightPhase implements FetchSubPhase {\n+\n     private final Map<String, Highlighter> highlighters;\n \n     public HighlightPhase(Map<String, Highlighter> highlighters) {\n         this.highlighters = highlighters;\n     }\n \n     @Override\n-    public void hitExecute(SearchContext context, HitContext hitContext) {\n+    public FetchSubPhaseProcessor getProcessor(SearchContext context) {\n         if (context.highlight() == null) {\n-            return;\n+            return null;\n         }\n-        hitExecute(context.shardTarget(), context.getQueryShardContext(), context.parsedQuery().query(), context.highlight(), hitContext);\n+\n+        return getProcessor(context.getQueryShardContext(), context.shardTarget(), context.highlight(), context.parsedQuery().query());\n+    }\n+\n+    public FetchSubPhaseProcessor getProcessor(QueryShardContext qsc, SearchShardTarget target, SearchHighlightContext hc, Query query) {\n+        Map<String, Function<HitContext, FieldHighlightContext>> contextBuilders = contextBuilders(qsc, target, hc, query);\n+        return new FetchSubPhaseProcessor() {\n+            @Override\n+            public void setNextReader(LeafReaderContext readerContext) {\n+\n+            }\n+\n+            @Override\n+            public void process(HitContext hitContext) {\n+                Map<String, HighlightField> highlightFields = new HashMap<>();\n+                for (String field : contextBuilders.keySet()) {\n+                    FieldHighlightContext fieldContext = contextBuilders.get(field).apply(hitContext);\n+                    Highlighter highlighter = getHighlighter(fieldContext.field);\n+                    if ((highlighter.canHighlight(fieldContext.fieldType) == false) && fieldContext.fromWildcard) {", "originalCommit": "218a15a4b1168d111a4d1e7a7a40e02074c886eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc4ODk0Mw==", "url": "https://github.com/elastic/elasticsearch/pull/60907#discussion_r476788943", "bodyText": "Small comment, we could pass this into the PercolateContext constructor to avoid always having to pass it into PercolateContext#fieldName.", "author": "jtibshirani", "createdAt": "2020-08-25T22:13:01Z", "path": "modules/percolator/src/main/java/org/elasticsearch/percolator/PercolatorMatchedSlotSubFetchPhase.java", "diffHunk": "@@ -56,62 +56,86 @@\n     static final String FIELD_NAME_PREFIX = \"_percolator_document_slot\";\n \n     @Override\n-    public void hitsExecute(SearchContext context, SearchHit[] hits) throws IOException {\n-        innerHitsExecute(context.query(), context.searcher(), hits);\n-    }\n+    public FetchSubPhaseProcessor getProcessor(SearchContext searchContext) throws IOException {\n \n-    static void innerHitsExecute(Query mainQuery,\n-                                 IndexSearcher indexSearcher,\n-                                 SearchHit[] hits) throws IOException {\n-        List<PercolateQuery> percolateQueries = locatePercolatorQuery(mainQuery);\n-        if (percolateQueries.isEmpty()) {\n-            return;\n+        List<PercolateContext> percolateContexts = new ArrayList<>();\n+        for (PercolateQuery pq : locatePercolatorQuery(searchContext.query())) {\n+            percolateContexts.add(new PercolateContext(pq));\n+        }\n+        if (percolateContexts.isEmpty()) {\n+            return null;\n         }\n+        boolean singlePercolateQuery = percolateContexts.size() == 1;", "originalCommit": "218a15a4b1168d111a4d1e7a7a40e02074c886eb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "08c859defd935db3e4416156c7329510d563b06b", "url": "https://github.com/elastic/elasticsearch/commit/08c859defd935db3e4416156c7329510d563b06b", "message": "feedback", "committedDate": "2020-08-26T09:25:50Z", "type": "commit"}, {"oid": "a76d6b07ee2679af13625c038dd1dd426aa32ce9", "url": "https://github.com/elastic/elasticsearch/commit/a76d6b07ee2679af13625c038dd1dd426aa32ce9", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute", "committedDate": "2020-08-26T10:13:34Z", "type": "commit"}, {"oid": "ca849f8451474ea7346a4e0d1b448e61a163ff06", "url": "https://github.com/elastic/elasticsearch/commit/ca849f8451474ea7346a4e0d1b448e61a163ff06", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute", "committedDate": "2020-08-27T15:38:47Z", "type": "commit"}, {"oid": "f880d94415df66431213f95859a5a238a17892d8", "url": "https://github.com/elastic/elasticsearch/commit/f880d94415df66431213f95859a5a238a17892d8", "message": "Merge remote-tracking branch 'origin/master' into fetch/hitexecute", "committedDate": "2020-09-01T16:01:35Z", "type": "commit"}, {"oid": "b541593f98418d7130fd771500a41a6c94a94b48", "url": "https://github.com/elastic/elasticsearch/commit/b541593f98418d7130fd771500a41a6c94a94b48", "message": "Merge branch 'master' into fetch/hitexecute", "committedDate": "2020-09-02T16:12:11Z", "type": "commit"}, {"oid": "897e78b1c42540d83fd7bb85226af46ea9660295", "url": "https://github.com/elastic/elasticsearch/commit/897e78b1c42540d83fd7bb85226af46ea9660295", "message": "Merge branch 'master' into fetch/hitexecute", "committedDate": "2020-09-03T08:21:11Z", "type": "commit"}]}