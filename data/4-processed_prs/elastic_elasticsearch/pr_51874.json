{"pr_number": 51874, "pr_title": "[DOCS] Streamline `analyzer` mapping parm def", "pr_createdAt": "2020-02-04T16:38:48Z", "pr_url": "https://github.com/elastic/elasticsearch/pull/51874", "timeline": [{"oid": "1f64083a78fa2002fbbec8d25e66005199d16f4e", "url": "https://github.com/elastic/elasticsearch/commit/1f64083a78fa2002fbbec8d25e66005199d16f4e", "message": "[DOCS] Streamline `analyzer` mapping parm def\n\nSimplifies the `analyzer` mapping parameter definition to remove\nduplicated analysis content and examples.", "committedDate": "2020-02-04T16:34:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDc4Njc3OQ==", "url": "https://github.com/elastic/elasticsearch/pull/51874#discussion_r374786779", "bodyText": "This is now covered in the Analysis overview. I think we should avoid repeating it here.", "author": "jrodewig", "createdAt": "2020-02-04T16:40:14Z", "path": "docs/reference/mapping/params/analyzer.asciidoc", "diffHunk": "@@ -1,81 +1,17 @@\n [[analyzer]]\n === `analyzer`\n \n-The values of <<mapping-index,`analyzed`>> string fields are passed through an\n-<<analysis,analyzer>> to convert the string into a stream of _tokens_ or\n-_terms_.  For instance, the string `\"The quick Brown Foxes.\"` may, depending\n-on which analyzer is used,  be analyzed to the tokens: `quick`, `brown`,\n-`fox`.  These are the actual terms that are indexed for the field, which makes\n-it possible to search efficiently for individual words _within_  big blobs of\n-text.", "originalCommit": "1f64083a78fa2002fbbec8d25e66005199d16f4e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDc4NzI2Nw==", "url": "https://github.com/elastic/elasticsearch/pull/51874#discussion_r374787267", "bodyText": "Covered in Index and search analysis.", "author": "jrodewig", "createdAt": "2020-02-04T16:40:58Z", "path": "docs/reference/mapping/params/analyzer.asciidoc", "diffHunk": "@@ -1,81 +1,17 @@\n [[analyzer]]\n === `analyzer`\n \n-The values of <<mapping-index,`analyzed`>> string fields are passed through an\n-<<analysis,analyzer>> to convert the string into a stream of _tokens_ or\n-_terms_.  For instance, the string `\"The quick Brown Foxes.\"` may, depending\n-on which analyzer is used,  be analyzed to the tokens: `quick`, `brown`,\n-`fox`.  These are the actual terms that are indexed for the field, which makes\n-it possible to search efficiently for individual words _within_  big blobs of\n-text.\n+[IMPORTANT]\n+====\n+Only <<text,`text`>> fields support the `analyzer` mapping parameter.\n+====\n \n-This analysis process needs to happen not just at index time, but also at\n-query time: the query string needs to be passed through the same (or a\n-similar) analyzer so that the terms that it tries to find are in the same\n-format as those that exist in the index.", "originalCommit": "1f64083a78fa2002fbbec8d25e66005199d16f4e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzMTcxNQ==", "url": "https://github.com/elastic/elasticsearch/pull/51874#discussion_r394231715", "bodyText": "Maybe it would it make sense to include some small text snippet that links to this broader overview article? I always find it useful to be able to click through from some small, concise parameter description to the more general explanation of the concepts, I might miss them otherwise.", "author": "cbuescher", "createdAt": "2020-03-18T10:06:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDc4NzI2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMyMjA1OA==", "url": "https://github.com/elastic/elasticsearch/pull/51874#discussion_r394322058", "bodyText": "There is a link to this section in line 12:\nUnless overridden with the <<search-analyzer,`search_analyzer`>> mapping\nparameter, this analyzer is used for both <<analysis-index-search-time,index and\nsearch analysis>>. See <<specify-analyzer>>.", "author": "jrodewig", "createdAt": "2020-03-18T12:51:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDc4NzI2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDc4NzcxOQ==", "url": "https://github.com/elastic/elasticsearch/pull/51874#discussion_r374787719", "bodyText": "Covered in Anatomy of an analyzer.", "author": "jrodewig", "createdAt": "2020-02-04T16:41:42Z", "path": "docs/reference/mapping/params/analyzer.asciidoc", "diffHunk": "@@ -1,81 +1,17 @@\n [[analyzer]]\n === `analyzer`\n \n-The values of <<mapping-index,`analyzed`>> string fields are passed through an\n-<<analysis,analyzer>> to convert the string into a stream of _tokens_ or\n-_terms_.  For instance, the string `\"The quick Brown Foxes.\"` may, depending\n-on which analyzer is used,  be analyzed to the tokens: `quick`, `brown`,\n-`fox`.  These are the actual terms that are indexed for the field, which makes\n-it possible to search efficiently for individual words _within_  big blobs of\n-text.\n+[IMPORTANT]\n+====\n+Only <<text,`text`>> fields support the `analyzer` mapping parameter.\n+====\n \n-This analysis process needs to happen not just at index time, but also at\n-query time: the query string needs to be passed through the same (or a\n-similar) analyzer so that the terms that it tries to find are in the same\n-format as those that exist in the index.\n-\n-Elasticsearch ships with a number of <<analysis-analyzers,pre-defined analyzers>>,\n-which can be used without further configuration.  It also ships with many\n-<<analysis-charfilters,character filters>>, <<analysis-tokenizers,tokenizers>>,\n-and <<analysis-tokenfilters>> which can be combined to configure\n-custom analyzers per index.", "originalCommit": "1f64083a78fa2002fbbec8d25e66005199d16f4e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzMTk4MA==", "url": "https://github.com/elastic/elasticsearch/pull/51874#discussion_r394231980", "bodyText": "Same here, maybe this can be linked in some way?", "author": "cbuescher", "createdAt": "2020-03-18T10:07:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDc4NzcxOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMyMzYxOA==", "url": "https://github.com/elastic/elasticsearch/pull/51874#discussion_r394323618", "bodyText": "I added a link with 5460b11.", "author": "jrodewig", "createdAt": "2020-03-18T12:54:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDc4NzcxOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDc4ODI2Nw==", "url": "https://github.com/elastic/elasticsearch/pull/51874#discussion_r374788267", "bodyText": "Covered in Specify an analyzer.\nThe example is not exactly the same, but I feel they cover the same ground.", "author": "jrodewig", "createdAt": "2020-02-04T16:42:33Z", "path": "docs/reference/mapping/params/analyzer.asciidoc", "diffHunk": "@@ -1,81 +1,17 @@\n [[analyzer]]\n === `analyzer`\n \n-The values of <<mapping-index,`analyzed`>> string fields are passed through an\n-<<analysis,analyzer>> to convert the string into a stream of _tokens_ or\n-_terms_.  For instance, the string `\"The quick Brown Foxes.\"` may, depending\n-on which analyzer is used,  be analyzed to the tokens: `quick`, `brown`,\n-`fox`.  These are the actual terms that are indexed for the field, which makes\n-it possible to search efficiently for individual words _within_  big blobs of\n-text.\n+[IMPORTANT]\n+====\n+Only <<text,`text`>> fields support the `analyzer` mapping parameter.\n+====\n \n-This analysis process needs to happen not just at index time, but also at\n-query time: the query string needs to be passed through the same (or a\n-similar) analyzer so that the terms that it tries to find are in the same\n-format as those that exist in the index.\n-\n-Elasticsearch ships with a number of <<analysis-analyzers,pre-defined analyzers>>,\n-which can be used without further configuration.  It also ships with many\n-<<analysis-charfilters,character filters>>, <<analysis-tokenizers,tokenizers>>,\n-and <<analysis-tokenfilters>> which can be combined to configure\n-custom analyzers per index.\n-\n-Analyzers can be specified per-query, per-field or per-index. At index time,\n-Elasticsearch will look for an analyzer in this order:\n-\n-* The `analyzer` defined in the field mapping.\n-* An analyzer named `default` in the index settings.\n-* The <<analysis-standard-analyzer,`standard`>> analyzer.\n-\n-At query time, there are a few more layers:\n-\n-* The `analyzer` defined in a <<full-text-queries,full-text query>>.\n-* The `search_analyzer` defined in the field mapping.\n-* The `analyzer` defined in the field mapping.\n-* An analyzer named `default_search` in the index settings.\n-* An analyzer named `default` in the index settings.\n-* The <<analysis-standard-analyzer,`standard`>> analyzer.\n-\n-The easiest way to specify an analyzer for a particular field is to define it\n-in the field mapping, as follows:\n-\n-[source,console]\n---------------------------------------------------\n-PUT /my_index\n-{\n-  \"mappings\": {\n-    \"properties\": {\n-      \"text\": { <1>\n-        \"type\": \"text\",\n-        \"fields\": {\n-          \"english\": { <2>\n-            \"type\":     \"text\",\n-            \"analyzer\": \"english\"\n-          }\n-        }\n-      }\n-    }\n-  }\n-}\n-\n-GET my_index/_analyze <3>\n-{\n-  \"field\": \"text\",\n-  \"text\": \"The quick Brown Foxes.\"\n-}\n-\n-GET my_index/_analyze <4>\n-{\n-  \"field\": \"text.english\",\n-  \"text\": \"The quick Brown Foxes.\"\n-}\n---------------------------------------------------\n-\n-<1> The `text` field uses the default `standard` analyzer`.\n-<2> The `text.english` <<multi-fields,multi-field>> uses the `english` analyzer, which removes stop words and applies stemming.\n-<3> This returns the tokens: [ `the`, `quick`, `brown`, `foxes` ].\n-<4> This returns the tokens: [ `quick`, `brown`, `fox` ].", "originalCommit": "1f64083a78fa2002fbbec8d25e66005199d16f4e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "4d2f48ecd4217401b1529480f3df4385f4ced70e", "url": "https://github.com/elastic/elasticsearch/commit/4d2f48ecd4217401b1529480f3df4385f4ced70e", "message": "Merge branch 'master' into docs__streamline-analyzer-parm", "committedDate": "2020-02-14T18:12:11Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzMTc2OA==", "url": "https://github.com/elastic/elasticsearch/pull/51874#discussion_r394231768", "bodyText": "Looks like there might be something missing here. Should this maybe be \"Analyzers are used\" or something like that?", "author": "cbuescher", "createdAt": "2020-03-18T10:06:58Z", "path": "docs/reference/mapping/params/analyzer.asciidoc", "diffHunk": "@@ -1,81 +1,17 @@\n [[analyzer]]\n === `analyzer`\n \n-The values of <<text,`text`>> fields are passed through an\n-<<analysis,analyzer>> to convert the string into a stream of _tokens_ or\n-_terms_.  For instance, the string `\"The quick Brown Foxes.\"` may, depending\n-on which analyzer is used,  be analyzed to the tokens: `quick`, `brown`,\n-`fox`.  These are the actual terms that are indexed for the field, which makes\n-it possible to search efficiently for individual words _within_  big blobs of\n-text.\n+[IMPORTANT]\n+====\n+Only <<text,`text`>> fields support the `analyzer` mapping parameter.\n+====\n \n-This analysis process needs to happen not just at index time, but also at\n-query time: the query string needs to be passed through the same (or a\n-similar) analyzer so that the terms that it tries to find are in the same\n-format as those that exist in the index.\n-\n-Elasticsearch ships with a number of <<analysis-analyzers,pre-defined analyzers>>,\n-which can be used without further configuration.  It also ships with many\n-<<analysis-charfilters,character filters>>, <<analysis-tokenizers,tokenizers>>,\n-and <<analysis-tokenfilters>> which can be combined to configure\n-custom analyzers per index.\n-\n-Analyzers can be specified per-query, per-field or per-index. At index time,\n-Elasticsearch will look for an analyzer in this order:\n-\n-* The `analyzer` defined in the field mapping.\n-* An analyzer named `default` in the index settings.\n-* The <<analysis-standard-analyzer,`standard`>> analyzer.\n-\n-At query time, there are a few more layers:\n-\n-* The `analyzer` defined in a <<full-text-queries,full-text query>>.\n-* The `search_analyzer` defined in the field mapping.\n-* The `analyzer` defined in the field mapping.\n-* An analyzer named `default_search` in the index settings.\n-* An analyzer named `default` in the index settings.\n-* The <<analysis-standard-analyzer,`standard`>> analyzer.\n-\n-The easiest way to specify an analyzer for a particular field is to define it\n-in the field mapping, as follows:\n-\n-[source,console]\n---------------------------------------------------\n-PUT /my_index\n-{\n-  \"mappings\": {\n-    \"properties\": {\n-      \"text\": { <1>\n-        \"type\": \"text\",\n-        \"fields\": {\n-          \"english\": { <2>\n-            \"type\":     \"text\",\n-            \"analyzer\": \"english\"\n-          }\n-        }\n-      }\n-    }\n-  }\n-}\n-\n-GET my_index/_analyze <3>\n-{\n-  \"field\": \"text\",\n-  \"text\": \"The quick Brown Foxes.\"\n-}\n-\n-GET my_index/_analyze <4>\n-{\n-  \"field\": \"text.english\",\n-  \"text\": \"The quick Brown Foxes.\"\n-}\n---------------------------------------------------\n-\n-<1> The `text` field uses the default `standard` analyzer`.\n-<2> The `text.english` <<multi-fields,multi-field>> uses the `english` analyzer, which removes stop words and applies stemming.\n-<3> This returns the tokens: [ `the`, `quick`, `brown`, `foxes` ].\n-<4> This returns the tokens: [ `quick`, `brown`, `fox` ].\n+Analyzer used for <<analysis,text analysis>> when indexing or searching", "originalCommit": "4d2f48ecd4217401b1529480f3df4385f4ced70e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMyMDYyNA==", "url": "https://github.com/elastic/elasticsearch/pull/51874#discussion_r394320624", "bodyText": "Thanks for catching this. Fixed with 7043d43.", "author": "jrodewig", "createdAt": "2020-03-18T12:49:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzMTc2OA=="}], "type": "inlineReview"}, {"oid": "048ef29a25e891fbc3940529496f5fd6af1ad556", "url": "https://github.com/elastic/elasticsearch/commit/048ef29a25e891fbc3940529496f5fd6af1ad556", "message": "fix typo", "committedDate": "2020-03-18T12:48:51Z", "type": "commit"}, {"oid": "7043d43c77cd8d1f9dffffe5f6227bb446ff27cd", "url": "https://github.com/elastic/elasticsearch/commit/7043d43c77cd8d1f9dffffe5f6227bb446ff27cd", "message": "reword", "committedDate": "2020-03-18T12:50:37Z", "type": "commit"}, {"oid": "5460b11c8025574e52a1a0c4ac8f8e25f63bb834", "url": "https://github.com/elastic/elasticsearch/commit/5460b11c8025574e52a1a0c4ac8f8e25f63bb834", "message": "Add link for analyzer anatomy", "committedDate": "2020-03-18T12:54:05Z", "type": "commit"}, {"oid": "fe9c3436a99f4a608108065209b8d2af150bc34e", "url": "https://github.com/elastic/elasticsearch/commit/fe9c3436a99f4a608108065209b8d2af150bc34e", "message": "Add tip for testing analyzers", "committedDate": "2020-03-18T13:04:40Z", "type": "commit"}, {"oid": "920e9e985ec1ea4abc6e1d563777efacf5a89518", "url": "https://github.com/elastic/elasticsearch/commit/920e9e985ec1ea4abc6e1d563777efacf5a89518", "message": "reword", "committedDate": "2020-03-18T13:16:19Z", "type": "commit"}]}