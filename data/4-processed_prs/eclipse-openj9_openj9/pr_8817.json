{"pr_number": 8817, "pr_title": "Support uploading to multiple Artifactory servers", "pr_createdAt": "2020-03-10T17:56:16Z", "pr_url": "https://github.com/eclipse-openj9/openj9/pull/8817", "timeline": [{"oid": "a57760821920f49026a8b66e4431bdce4826abff", "url": "https://github.com/eclipse-openj9/openj9/commit/a57760821920f49026a8b66e4431bdce4826abff", "message": "Revert to original osu server name\n\nSigned-off-by: Adam Brousseau <adam.brousseau88@gmail.com>", "committedDate": "2020-03-11T14:24:06Z", "type": "forcePushed"}, {"oid": "4548c5227736f7f9f2a7569e23e7de3318ac1e80", "url": "https://github.com/eclipse-openj9/openj9/commit/4548c5227736f7f9f2a7569e23e7de3318ac1e80", "message": "Artifactory readme\n\nSigned-off-by: Adam Brousseau <adam.brousseau88@gmail.com>", "committedDate": "2020-03-17T01:12:16Z", "type": "forcePushed"}, {"oid": "8b1ece8e86005aee27258c772264b6045075d7b9", "url": "https://github.com/eclipse-openj9/openj9/commit/8b1ece8e86005aee27258c772264b6045075d7b9", "message": "Temp rename unb server\n\nSigned-off-by: Adam Brousseau <adam.brousseau88@gmail.com>", "committedDate": "2020-03-21T23:29:11Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYyNzg0OQ==", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396627849", "bodyText": "Please combine the two if statements into one statement:\nif (ARTIFACTORY_CONFIG && ARTIFACTORY_CONFIG['stashed']) {...}", "author": "vsebe", "createdAt": "2020-03-23T17:29:25Z", "path": "buildenv/jenkins/common/build.groovy", "diffHunk": "@@ -432,44 +435,93 @@ def archive_diagnostics() {\n     } else {\n         sh \"find . -name 'core.*.dmp' -o -name 'javacore.*.txt' -o -name 'Snap.*.trc' -o -name 'jitdump.*.dmp' | sed 's#^./##' | tar -zcvf ${DIAGNOSTICS_FILENAME} -T -\"\n     }\n-    if (ARTIFACTORY_SERVER) {\n+    if (ARTIFACTORY_CONFIG) {\n         def uploadSpec = \"\"\"{\n             \"files\":[\n                 {\n                     \"pattern\": \"${DIAGNOSTICS_FILENAME}\",\n-                    \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                    \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                     \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"\n                 }\n             ]\n         }\"\"\"\n-        upload_artifactory(uploadSpec)\n-        DIAGNOSTICS_FILE_URL = \"${ARTIFACTORY_URL}/${ARTIFACTORY_UPLOAD_DIR}${DIAGNOSTICS_FILENAME}\"\n+        upload_artifactory_core(ARTIFACTORY_CONFIG['defaultGeo'], uploadSpec)\n+        DIAGNOSTICS_FILE_URL = \"${ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['url']}/${ARTIFACTORY_CONFIG['uploadDir']}${DIAGNOSTICS_FILENAME}\"\n         currentBuild.description += \"<br><a href=${DIAGNOSTICS_FILE_URL}>${DIAGNOSTICS_FILENAME}</a>\"\n     } else {\n         archiveArtifacts artifacts: \"${DIAGNOSTICS_FILENAME}\", fingerprint: false\n     }\n }\n \n def upload_artifactory(uploadSpec) {\n-    def server = Artifactory.server ARTIFACTORY_SERVER\n+    // Loop all the servers and upload if we've determined we should do so\n+    for (geo in ARTIFACTORY_CONFIG['geos']) {\n+        if (ARTIFACTORY_CONFIG[geo]['uploadBool']) {\n+            /*\n+            * If the server is behind a vpn and we aren't on a node behind the vpn,\n+            * save the sdk and upload it later on a machine behind the vpn\n+            */\n+            if (ARTIFACTORY_CONFIG[geo]['vpn'] == 'true' && !NODE_LABELS.contains(\"ci.geo.${geo}\")) {\n+                if (!ARTIFACTORY_CONFIG['stashed']) {\n+                    stash includes: \"**/${SDK_FILENAME},**/${TEST_FILENAME}\", name: 'sdk'\n+                    ARTIFACTORY_CONFIG['stashed'] = true\n+                    ARTIFACTORY_CONFIG['uploadSpec'] = uploadSpec\n+                }\n+                ARTIFACTORY_CONFIG[geo]['uploaded'] = false\n+            } else {\n+                upload_artifactory_core(geo, uploadSpec)\n+                ARTIFACTORY_CONFIG[geo]['uploaded'] = true\n+            }\n+        }\n+    }\n+}\n+\n+def upload_artifactory_core(geo, uploadSpec) {\n+    echo \"Uploading to '${geo}'...\"\n+    def server = Artifactory.server ARTIFACTORY_CONFIG[geo]['server']\n     // set connection timeout to 10 mins to avoid timeout on slow platforms\n     server.connection.timeout = 600\n \n     def buildInfo = Artifactory.newBuildInfo()\n-    buildInfo.retention maxBuilds: ARTIFACTORY_NUM_ARTIFACTS, maxDays: ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS, deleteBuildArtifacts: true\n+    buildInfo.retention maxBuilds: ARTIFACTORY_CONFIG[geo]['numArtifacts'], maxDays: ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts'], deleteBuildArtifacts: true\n     // Add BUILD_IDENTIFIER to the buildInfo. The UploadSpec adds it to the Artifact info\n     buildInfo.env.filter.addInclude(\"BUILD_IDENTIFIER\")\n     buildInfo.env.capture = true\n \n     //Retry uploading to Artifactory if errors occur\n     pipelineFunctions.retry_and_delay({\n         server.upload spec: uploadSpec, buildInfo: buildInfo;\n-        server.publishBuildInfo buildInfo},\n+        if (!ARTIFACTORY_CONFIG[geo]['vpn']){server.publishBuildInfo buildInfo}},\n         3, 300)\n \n-    // Write URL to env so that we can pull it from the upstream pipeline job\n-    env.ARTIFACTORY_URL = server.getUrl()\n-    env.ARTIFACTORY_CREDS = server.getCredentialsId()\n+    ARTIFACTORY_CONFIG[geo]['url'] = server.getUrl()\n+    ARTIFACTORY_CONFIG[geo]['creds'] = server.getCredentialsId()\n+    // If this is the default server, save the creds to pass to test\n+    if (geo == ARTIFACTORY_CONFIG['defaultGeo']) {\n+        env.ARTIFACTORY_CREDS = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']].creds\n+    }\n+}\n+\n+def upload_artifactory_post() {\n+    // Determine if we didn't do any artifactory uploads because of vpn.\n+    // At the time of writing this code, we would only hit this case if we compiled at OSU on plinux and needed to upload to UNB.\n+    if (ARTIFACTORY_CONFIG) {", "originalCommit": "4e8f6dfeae82a243d335430a476796b609ef1637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg1MTAxNQ==", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396851015", "bodyText": "Done", "author": "AdamBrousseau", "createdAt": "2020-03-24T01:17:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYyNzg0OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYyOTk1OA==", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396629958", "bodyText": "Is this hard-coded value for development only?", "author": "vsebe", "createdAt": "2020-03-23T17:32:25Z", "path": "buildenv/jenkins/common/pipeline-functions.groovy", "diffHunk": "@@ -223,7 +223,7 @@ def build(BUILD_JOB_NAME, OPENJDK_REPO, OPENJDK_BRANCH, OPENJDK_SHA, OPENJ9_REPO\n def test(JOB_NAME, UPSTREAM_JOB_NAME, UPSTREAM_JOB_NUMBER, NODE, OPENJ9_REPO, OPENJ9_BRANCH, OPENJ9_SHA, VENDOR_TEST_REPOS, VENDOR_TEST_BRANCHES, VENDOR_TEST_SHAS, VENDOR_TEST_DIRS, USER_CREDENTIALS_ID, CUSTOMIZED_SDK_URL, ARTIFACTORY_CREDS, TEST_FLAG, BUILD_IDENTIFIER, ghprbGhRepository, ghprbActualCommit, GITHUB_SERVER, ADOPTOPENJDK_REPO, ADOPTOPENJDK_BRANCH, IS_PARALLEL, extraTestLabels, keepReportDir) {\n     stage (\"${JOB_NAME}\") {\n         def testParams = []\n-        testParams.addAll([string(name: 'LABEL', value: NODE),\n+        testParams.addAll([string(name: 'LABEL', value: 'ub16p8j96'),", "originalCommit": "4e8f6dfeae82a243d335430a476796b609ef1637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg1MDk0OA==", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396850948", "bodyText": "Yes", "author": "AdamBrousseau", "createdAt": "2020-03-24T01:17:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYyOTk1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYzMTY2NA==", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396631664", "bodyText": "Could get_value(VARIABLES.artifactory.numArtifacts, geo) = null ?", "author": "vsebe", "createdAt": "2020-03-23T17:34:52Z", "path": "buildenv/jenkins/common/variables-functions.groovy", "diffHunk": "@@ -702,19 +702,151 @@ def set_slack_channel() {\n }\n \n def set_artifactory_config() {\n-    ARTIFACTORY_SERVER = VARIABLES.artifactory_server\n-    if (ARTIFACTORY_SERVER) {\n-        env.ARTIFACTORY_SERVER = ARTIFACTORY_SERVER\n-        env.ARTIFACTORY_REPO = VARIABLES.artifactory_repo\n-        env.ARTIFACTORY_NUM_ARTIFACTS = VARIABLES.artifactory_num_artifacts\n-        env.ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS = VARIABLES.artifactory_days_to_keep_artifacts\n-        env.ARTIFACTORY_MANUAL_CLEANUP = VARIABLES.artifactory_manual_cleanup // This is being used by the cleanup script\n-        env.ARTIFACTORY_UPLOAD_DIR = \"${ARTIFACTORY_REPO}/${JOB_NAME}/${BUILD_ID}/\"\n-        echo \"Using artifactory server/repo: ${ARTIFACTORY_SERVER} / ${ARTIFACTORY_REPO}\"\n-        echo \"Keeping '${ARTIFACTORY_NUM_ARTIFACTS}' artifacts\"\n-        echo \"Keeping artifacts for '${ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS}' days\"\n-        echo \"Artifactory Manual Cleanup: ${env.ARTIFACTORY_MANUAL_CLEANUP}\"\n+    ARTIFACTORY_CONFIG = [:]\n+    echo \"Configure Artifactory...\"\n+\n+    if (VARIABLES.artifactory.defaultGeo) {\n+        // Allow default geo to be overridden with a param. Used by the Clenaup script to target a specific server.\n+        ARTIFACTORY_CONFIG['defaultGeo'] = (params.ARTIFACTORY_GEO) ? params.ARTIFACTORY_GEO : VARIABLES.artifactory.defaultGeo\n+        ARTIFACTORY_CONFIG['geos'] = VARIABLES.artifactory.server.keySet()\n+        ARTIFACTORY_CONFIG['repo'] = VARIABLES.artifactory.repo\n+        ARTIFACTORY_CONFIG['uploadDir'] = \"${ARTIFACTORY_CONFIG['repo']}/${JOB_NAME}/${BUILD_ID}/\"\n+        //println VARIABLES.artifactory\n+        //println ARTIFACTORY_CONFIG['defaultServerGeo']\n+        //println ARTIFACTORY_CONFIG['geos']\n+        //println ARTIFACTORY_CONFIG['repo']\n+        //println ARTIFACTORY_CONFIG['manualCleanup']\n+\n+        for (geo in ARTIFACTORY_CONFIG['geos']) {\n+            ARTIFACTORY_CONFIG[geo] = [:]\n+            ARTIFACTORY_CONFIG[geo]['server'] = get_value(VARIABLES.artifactory.server, geo)\n+            ARTIFACTORY_CONFIG[geo]['numArtifacts'] = get_value(VARIABLES.artifactory.numArtifacts, geo).toInteger()", "originalCommit": "4e8f6dfeae82a243d335430a476796b609ef1637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg1MTI1Nw==", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396851257", "bodyText": "It's possible but there is no valid use case for it to not be set. Ie. if it's not set then it's a user problem.", "author": "AdamBrousseau", "createdAt": "2020-03-24T01:18:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYzMTY2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY1MjgwNQ==", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396652805", "bodyText": "There are multiple nodes per geo. It should set the flag only once (and skip the other nodes with same geo):\nif (!ARTIFACTORY_CONFIG[nodeGeo].contains('uploadBool') {\n    ARTIFACTORY_CONFIG[nodeGeo]['uploadBool'] = true\n}", "author": "vsebe", "createdAt": "2020-03-23T18:06:35Z", "path": "buildenv/jenkins/common/variables-functions.groovy", "diffHunk": "@@ -702,19 +702,151 @@ def set_slack_channel() {\n }\n \n def set_artifactory_config() {\n-    ARTIFACTORY_SERVER = VARIABLES.artifactory_server\n-    if (ARTIFACTORY_SERVER) {\n-        env.ARTIFACTORY_SERVER = ARTIFACTORY_SERVER\n-        env.ARTIFACTORY_REPO = VARIABLES.artifactory_repo\n-        env.ARTIFACTORY_NUM_ARTIFACTS = VARIABLES.artifactory_num_artifacts\n-        env.ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS = VARIABLES.artifactory_days_to_keep_artifacts\n-        env.ARTIFACTORY_MANUAL_CLEANUP = VARIABLES.artifactory_manual_cleanup // This is being used by the cleanup script\n-        env.ARTIFACTORY_UPLOAD_DIR = \"${ARTIFACTORY_REPO}/${JOB_NAME}/${BUILD_ID}/\"\n-        echo \"Using artifactory server/repo: ${ARTIFACTORY_SERVER} / ${ARTIFACTORY_REPO}\"\n-        echo \"Keeping '${ARTIFACTORY_NUM_ARTIFACTS}' artifacts\"\n-        echo \"Keeping artifacts for '${ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS}' days\"\n-        echo \"Artifactory Manual Cleanup: ${env.ARTIFACTORY_MANUAL_CLEANUP}\"\n+    ARTIFACTORY_CONFIG = [:]\n+    echo \"Configure Artifactory...\"\n+\n+    if (VARIABLES.artifactory.defaultGeo) {\n+        // Allow default geo to be overridden with a param. Used by the Clenaup script to target a specific server.\n+        ARTIFACTORY_CONFIG['defaultGeo'] = (params.ARTIFACTORY_GEO) ? params.ARTIFACTORY_GEO : VARIABLES.artifactory.defaultGeo\n+        ARTIFACTORY_CONFIG['geos'] = VARIABLES.artifactory.server.keySet()\n+        ARTIFACTORY_CONFIG['repo'] = VARIABLES.artifactory.repo\n+        ARTIFACTORY_CONFIG['uploadDir'] = \"${ARTIFACTORY_CONFIG['repo']}/${JOB_NAME}/${BUILD_ID}/\"\n+        //println VARIABLES.artifactory\n+        //println ARTIFACTORY_CONFIG['defaultServerGeo']\n+        //println ARTIFACTORY_CONFIG['geos']\n+        //println ARTIFACTORY_CONFIG['repo']\n+        //println ARTIFACTORY_CONFIG['manualCleanup']\n+\n+        for (geo in ARTIFACTORY_CONFIG['geos']) {\n+            ARTIFACTORY_CONFIG[geo] = [:]\n+            ARTIFACTORY_CONFIG[geo]['server'] = get_value(VARIABLES.artifactory.server, geo)\n+            ARTIFACTORY_CONFIG[geo]['numArtifacts'] = get_value(VARIABLES.artifactory.numArtifacts, geo).toInteger()\n+            ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts'] = get_value(VARIABLES.artifactory.daysToKeepArtifacts, geo).toInteger()\n+            ARTIFACTORY_CONFIG[geo]['manualCleanup'] = get_value(VARIABLES.artifactory.manualCleanup, geo)\n+            ARTIFACTORY_CONFIG[geo]['vpn'] = get_value(VARIABLES.artifactory.vpn, geo)\n+            //println geo\n+            //println ARTIFACTORY_CONFIG[geo]['server']\n+            //println ARTIFACTORY_CONFIG[geo]['numArtifacts']\n+            //println ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts']\n+        }\n+        ARTIFACTORY_CONFIG[VARIABLES.artifactory.defaultGeo]['uploadBool'] = true\n+\n+        // Determine if we need to upload more than the default server\n+        if (ARTIFACTORY_CONFIG['geos'].size() > 1) {\n+            // What platform did we build on\n+            compilePlatform = get_node_platform(NODE_LABELS)\n+\n+            // See if there are servers with colocated nodes of matching platform\n+            def testNodes = jenkins.model.Jenkins.instance.getLabel('ci.role.test').getNodes()\n+            //println testNodes\n+            for (node in testNodes) {\n+                def nodeGeo = get_node_geo(node.getLabelString())\n+                def nodePlatform = get_node_platform(node.getLabelString())\n+                //println nodeGeo\n+                //println nodePlatform\n+                // Upload if there is a server at geo where there are machines matching our platform.\n+                if (nodePlatform == compilePlatform && ARTIFACTORY_CONFIG['geos'].contains(nodeGeo)) {\n+                    ARTIFACTORY_CONFIG[nodeGeo]['uploadBool'] = true\n+                    //println ARTIFACTORY_CONFIG[nodeGeo]['uploadBool']", "originalCommit": "4e8f6dfeae82a243d335430a476796b609ef1637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg1MTM0Mw==", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396851343", "bodyText": "Agree. Added an if higher up.", "author": "AdamBrousseau", "createdAt": "2020-03-24T01:19:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY1MjgwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY2MzQzNg==", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396663436", "bodyText": "Could you please simplify the switch statement below, maybe use an array for all the matching cases sharing the same code, for example:\ndef nodePlatform\nswitch(baseOS) {\n    case ['aix, 'windows',  'osx', 'zos'] :\n        nodePlatform  = baseOS\n        break\n    case ['linux', 'ubuntu', 'rhel', 'cent', 'sles']:\n        ...\n        break\n    default:\n        echo \"WARNING: Unknown baseOS:'${baseOS}'\"\n        nodePlatform  = ''\n        break\n    }\nreturn nodePlatform", "author": "vsebe", "createdAt": "2020-03-23T18:22:15Z", "path": "buildenv/jenkins/common/variables-functions.groovy", "diffHunk": "@@ -702,19 +702,151 @@ def set_slack_channel() {\n }\n \n def set_artifactory_config() {\n-    ARTIFACTORY_SERVER = VARIABLES.artifactory_server\n-    if (ARTIFACTORY_SERVER) {\n-        env.ARTIFACTORY_SERVER = ARTIFACTORY_SERVER\n-        env.ARTIFACTORY_REPO = VARIABLES.artifactory_repo\n-        env.ARTIFACTORY_NUM_ARTIFACTS = VARIABLES.artifactory_num_artifacts\n-        env.ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS = VARIABLES.artifactory_days_to_keep_artifacts\n-        env.ARTIFACTORY_MANUAL_CLEANUP = VARIABLES.artifactory_manual_cleanup // This is being used by the cleanup script\n-        env.ARTIFACTORY_UPLOAD_DIR = \"${ARTIFACTORY_REPO}/${JOB_NAME}/${BUILD_ID}/\"\n-        echo \"Using artifactory server/repo: ${ARTIFACTORY_SERVER} / ${ARTIFACTORY_REPO}\"\n-        echo \"Keeping '${ARTIFACTORY_NUM_ARTIFACTS}' artifacts\"\n-        echo \"Keeping artifacts for '${ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS}' days\"\n-        echo \"Artifactory Manual Cleanup: ${env.ARTIFACTORY_MANUAL_CLEANUP}\"\n+    ARTIFACTORY_CONFIG = [:]\n+    echo \"Configure Artifactory...\"\n+\n+    if (VARIABLES.artifactory.defaultGeo) {\n+        // Allow default geo to be overridden with a param. Used by the Clenaup script to target a specific server.\n+        ARTIFACTORY_CONFIG['defaultGeo'] = (params.ARTIFACTORY_GEO) ? params.ARTIFACTORY_GEO : VARIABLES.artifactory.defaultGeo\n+        ARTIFACTORY_CONFIG['geos'] = VARIABLES.artifactory.server.keySet()\n+        ARTIFACTORY_CONFIG['repo'] = VARIABLES.artifactory.repo\n+        ARTIFACTORY_CONFIG['uploadDir'] = \"${ARTIFACTORY_CONFIG['repo']}/${JOB_NAME}/${BUILD_ID}/\"\n+        //println VARIABLES.artifactory\n+        //println ARTIFACTORY_CONFIG['defaultServerGeo']\n+        //println ARTIFACTORY_CONFIG['geos']\n+        //println ARTIFACTORY_CONFIG['repo']\n+        //println ARTIFACTORY_CONFIG['manualCleanup']\n+\n+        for (geo in ARTIFACTORY_CONFIG['geos']) {\n+            ARTIFACTORY_CONFIG[geo] = [:]\n+            ARTIFACTORY_CONFIG[geo]['server'] = get_value(VARIABLES.artifactory.server, geo)\n+            ARTIFACTORY_CONFIG[geo]['numArtifacts'] = get_value(VARIABLES.artifactory.numArtifacts, geo).toInteger()\n+            ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts'] = get_value(VARIABLES.artifactory.daysToKeepArtifacts, geo).toInteger()\n+            ARTIFACTORY_CONFIG[geo]['manualCleanup'] = get_value(VARIABLES.artifactory.manualCleanup, geo)\n+            ARTIFACTORY_CONFIG[geo]['vpn'] = get_value(VARIABLES.artifactory.vpn, geo)\n+            //println geo\n+            //println ARTIFACTORY_CONFIG[geo]['server']\n+            //println ARTIFACTORY_CONFIG[geo]['numArtifacts']\n+            //println ARTIFACTORY_CONFIG[geo]['daysToKeepArtifacts']\n+        }\n+        ARTIFACTORY_CONFIG[VARIABLES.artifactory.defaultGeo]['uploadBool'] = true\n+\n+        // Determine if we need to upload more than the default server\n+        if (ARTIFACTORY_CONFIG['geos'].size() > 1) {\n+            // What platform did we build on\n+            compilePlatform = get_node_platform(NODE_LABELS)\n+\n+            // See if there are servers with colocated nodes of matching platform\n+            def testNodes = jenkins.model.Jenkins.instance.getLabel('ci.role.test').getNodes()\n+            //println testNodes\n+            for (node in testNodes) {\n+                def nodeGeo = get_node_geo(node.getLabelString())\n+                def nodePlatform = get_node_platform(node.getLabelString())\n+                //println nodeGeo\n+                //println nodePlatform\n+                // Upload if there is a server at geo where there are machines matching our platform.\n+                if (nodePlatform == compilePlatform && ARTIFACTORY_CONFIG['geos'].contains(nodeGeo)) {\n+                    ARTIFACTORY_CONFIG[nodeGeo]['uploadBool'] = true\n+                    //println ARTIFACTORY_CONFIG[nodeGeo]['uploadBool']\n+                }\n+            }\n+        }\n+\n+        echo \"ARTIFACTORY_CONFIG:'${ARTIFACTORY_CONFIG}'\"\n+        /*\n+        * Write out default server values to string variables.\n+        * The upstream job calls job.getBuildVariables() which only returns strings.\n+        * Rather than parsing out the ARTIFACTORY_CONFIG map that is stored as a string,\n+        * we'll write out the values to env here as strings to save work later.\n+        */\n+        env.ARTIFACTORY_SERVER = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['server']\n+        env.ARTIFACTORY_REPO = ARTIFACTORY_CONFIG['repo']\n+        env.ARTIFACTORY_NUM_ARTIFACTS = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['numArtifacts']\n+        env.ARTIFACTORY_DAYS_TO_KEEP_ARTIFACTS = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['daysToKeepArtifacts']\n+        env.ARTIFACTORY_MANUAL_CLEANUP = ARTIFACTORY_CONFIG[ARTIFACTORY_CONFIG['defaultGeo']]['manualCleanup']\n+    }\n+}\n+\n+def get_node_geo(nodeLabels) {\n+    if (nodeLabels.contains('ci.geo.')) {\n+        labelArray = nodeLabels.tokenize()\n+        for (label in labelArray) {\n+            if (label ==~ /ci\\.geo\\..*/) {\n+                return label.substring(7)\n+            }\n+        }\n     }\n+    return ''\n+}\n+\n+def get_node_platform(nodeLabels) {\n+    /*\n+    * xlinux -> arch=x86 && baseOS=linux\n+    * plinux -> arch=ppc64le && baseOS=linux\n+    * zlinux -> arch=s390x && baseOS=linux\n+    * aix -> baseOS=aix\n+    * windows -> baseOS=windows\n+    * osx -> baseOS=osx\n+    * zos -> baseOS=zos\n+    * aarch64 -> arch=aarch64\n+    */\n+    def arch = ''\n+    def baseOS = ''\n+    if (nodeLabels.contains('hw.arch.') && nodeLabels.contains('sw.os.')) {\n+        labelArray = nodeLabels.tokenize()\n+        for (label in labelArray) {\n+            switch(label) {\n+                case ~/hw\\.arch\\.[a-z0-9]+/:\n+                    arch = label.substring(8)\n+                    //println arch\n+                    break\n+                case ~/sw\\.os\\.[a-z]+/:\n+                    baseOS = label.substring(6)\n+                    //println baseOS\n+                    break\n+            }\n+        }\n+    }\n+    if (!arch || !baseOS) {\n+        echo \"WARNING: Unable to determine node arch/os:'${nodeLabels}'\"\n+        return ''\n+    }\n+    switch(baseOS) {\n+        case 'aix':", "originalCommit": "4e8f6dfeae82a243d335430a476796b609ef1637", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg1MzA2NA==", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r396853064", "bodyText": "Added arrays for multi-cases.", "author": "AdamBrousseau", "createdAt": "2020-03-24T01:25:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjY2MzQzNg=="}], "type": "inlineReview"}, {"oid": "7e0c08dcf542f72ae5fec3b226f4b6522bd0dbe9", "url": "https://github.com/eclipse-openj9/openj9/commit/7e0c08dcf542f72ae5fec3b226f4b6522bd0dbe9", "message": "trying to figure out condition syntax for null var\n\nSigned-off-by: Adam Brousseau <adam.brousseau88@gmail.com>", "committedDate": "2020-03-24T01:58:40Z", "type": "forcePushed"}, {"oid": "17c6d872077bb5154814a058b22b68ec98189225", "url": "https://github.com/eclipse-openj9/openj9/commit/17c6d872077bb5154814a058b22b68ec98189225", "message": "Art readme update curl wrapper\n\nSigned-off-by: Adam Brousseau <adam.brousseau88@gmail.com>", "committedDate": "2020-03-24T03:07:51Z", "type": "forcePushed"}, {"oid": "f7923c481748d40ecab0af6714d239ff4d119394", "url": "https://github.com/eclipse-openj9/openj9/commit/f7923c481748d40ecab0af6714d239ff4d119394", "message": "Add support for multiple Artifactory servers\n\nArtifactory bandwidth has become an issue in the CI builds.\nThis has caused issues with upload and download times, as well\nas failing downloads due to infrastructure inadequacy.\nParticularily for UNB machines, where a large portion of the\nfarm is located, combined with the pipe into UNB being small.\n\nBeing able to setup multiple Artifactory servers spread across\ngeographies and colocated with pools of machines will allow us\nto push and more importantly pull from a nearby server.\n\nThe design leaves one site as the main (default) server (OSU). We\nwill always upload to the default server. We will only upload\nto a secondary server(s) if there are machines with a matching\nplatform, colocated with another (non-default) server. The design\nis layed out so it will scale with more servers without any code\nchange other than adding to the defaults.yml config.\n\nSince we cannot determine where a test will land (geographically),\nwe need to upload to any/all servers that are colocated with machines\nof matching platform. We also will always pass the default SDK URL.\nWe will add a curl wrapper on the nodes which have colocated servers.\nThis wrapper will redirect requests from one server to another. In\nthis case redirect OSU requests to UNB. We will also strip off\nthe user/password since a) The servers allow anonymous access and\nb) The user's api key will be different for every server.\n\nChanges introduced:\n- Redesign the Artifactory config in defaults.yml to support multiple\n  servers. Identify servers based on geo(graphy) and identify one\n  geo as default.\n- Redesign the Artifactory variables as a single hashmap. This keeps\n  all the config together. Continue to write out the default server\n  values to env, in order for the parent job to continue as-is.\n- Move Artifactory setup onto the compile node. This is needed\n  in order to determine where we are compiling and where we need\n  to upload.\n- Add support for uploading to a server behind a vpn. If we aren't\n  compiling behind the vpn, stash the SDK for later when we can\n  grap a node in the same geo as the server we need to push to.\n  Note: We cannot publish buildInfo to vpn'd servers. Artifacts\n  come from nodes but buildInfo comes from Master, so Master needs\n  to see the server.\n- Add some more details to the Artifacotry README. Also add more\n  info specific to the UNB setup.\n\nAlso:\n- Unrelated change to stop adding JAVADOC_LIB_URL to the CUSTOMIZED_SDK_URL.\n  CUSTOMIZED_SDK_URL is for test and test doesn't need JAVADOC.\n\n[skip ci]\nIssue #8425\n\nSigned-off-by: Adam Brousseau <adam.brousseau88@gmail.com>", "committedDate": "2020-03-24T03:32:33Z", "type": "forcePushed"}, {"oid": "1171d18619087dcd05fd6bbc40b50b02feafac72", "url": "https://github.com/eclipse-openj9/openj9/commit/1171d18619087dcd05fd6bbc40b50b02feafac72", "message": "Add support for multiple Artifactory servers\n\nArtifactory bandwidth has become an issue in the CI builds.\nThis has caused issues with upload and download times, as well\nas failing downloads due to infrastructure inadequacy.\nParticularly for UNB machines, where a large portion of the\nfarm is located, combined with the pipe into UNB being small.\n\nBeing able to setup multiple Artifactory servers spread across\ngeographies and colocated with pools of machines will allow us\nto push and more importantly pull from a nearby server.\n\nThe design leaves one site as the main (default) server (OSU). We\nwill always upload to the default server. We will only upload\nto a secondary server(s) if there are machines with a matching\nplatform, colocated with another (non-default) server. The design\nis laid out so it will scale with more servers without any code\nchange other than adding to the defaults.yml config.\n\nSince we cannot determine where a test will land (geographically),\nwe need to upload to any/all servers that are colocated with machines\nof matching platform. We also will always pass the default SDK URL.\nWe will add a curl wrapper on the nodes which have colocated servers.\nThis wrapper will redirect requests from one server to another. In\nthis case redirect OSU requests to UNB. We will also strip off\nthe user/password since a) The servers allow anonymous access and\nb) The user's api key will be different for every server.\n\nChanges introduced:\n- Redesign the Artifactory config in defaults.yml to support multiple\n  servers. Identify servers based on geo(graphy) and identify one\n  geo as default.\n- Redesign the Artifactory variables as a single hashmap. This keeps\n  all the config together. Continue to write out the default server\n  values to env, in order for the parent job to continue as-is.\n- Move Artifactory setup onto the compile node. This is needed\n  in order to determine where we are compiling and where we need\n  to upload.\n- Add support for uploading to a server behind a vpn. If we aren't\n  compiling behind the vpn, stash the SDK for later when we can\n  grab a node in the same geo as the server we need to push to.\n  Note: We cannot publish buildInfo to vpn'd servers. Artifacts\n  come from nodes but buildInfo comes from Master, so Master needs\n  to see the server.\n- Add some more details to the Artifacotry README. Also add more\n  info specific to the UNB setup.\n\nAlso:\n- Unrelated change to stop adding JAVADOC_LIB_URL to the CUSTOMIZED_SDK_URL.\n  CUSTOMIZED_SDK_URL is for test and test doesn't need JAVADOC.\n\n[skip ci]\nIssue #8425\n\nSigned-off-by: Adam Brousseau <adam.brousseau88@gmail.com>", "committedDate": "2020-03-24T04:06:29Z", "type": "forcePushed"}, {"oid": "0829b3610b96c0c61b435bb86280e959829bb89a", "url": "https://github.com/eclipse-openj9/openj9/commit/0829b3610b96c0c61b435bb86280e959829bb89a", "message": "Add support for multiple Artifactory servers\n\nArtifactory bandwidth has become an issue in the CI builds.\nThis has caused issues with upload and download times, as well\nas failing downloads due to infrastructure inadequacy.\nParticularly for UNB machines, where a large portion of the\nfarm is located, combined with the pipe into UNB being small.\n\nBeing able to setup multiple Artifactory servers spread across\ngeographies and colocated with pools of machines will allow us\nto push and more importantly pull from a nearby server.\n\nThe design leaves one site as the main (default) server (OSU). We\nwill always upload to the default server. We will only upload\nto a secondary server(s) if there are machines with a matching\nplatform, colocated with another (non-default) server. The design\nis laid out so it will scale with more servers without any code\nchange other than adding to the defaults.yml config.\n\nSince we cannot determine where a test will land (geographically),\nwe need to upload to any/all servers that are colocated with machines\nof matching platform. We also will always pass the default SDK URL.\nWe will add a curl wrapper on the nodes which have colocated servers.\nThis wrapper will redirect requests from one server to another. In\nthis case redirect OSU requests to UNB. We will also strip off\nthe user/password since a) The servers allow anonymous access and\nb) The user's api key will be different for every server.\n\nChanges introduced:\n- Redesign the Artifactory config in defaults.yml to support multiple\n  servers. Identify servers based on geo(graphy) and identify one\n  geo as default.\n- Redesign the Artifactory variables as a single hashmap. This keeps\n  all the config together. Continue to write out the default server\n  values to env, in order for the parent job to continue as-is.\n- Move Artifactory setup onto the compile node. This is needed\n  in order to determine where we are compiling and where we need\n  to upload.\n- Add support for uploading to a server behind a vpn. If we aren't\n  compiling behind the vpn, stash the SDK for later when we can\n  grab a node in the same geo as the server we need to push to.\n  Note: We cannot publish buildInfo to vpn'd servers. Artifacts\n  come from nodes but buildInfo comes from Master, so Master needs\n  to see the server.\n- Add some more details to the Artifacotry README. Also add more\n  info specific to the UNB setup.\n\nAlso:\n- Unrelated change to stop adding JAVADOC_LIB_URL to the CUSTOMIZED_SDK_URL.\n  CUSTOMIZED_SDK_URL is for test and test doesn't need JAVADOC.\n\n[skip ci]\nIssue #8425\n\nSigned-off-by: Adam Brousseau <adam.brousseau88@gmail.com>", "committedDate": "2020-03-24T04:16:53Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzExMDc3Nw==", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r397110777", "bodyText": "type here descirption", "author": "pshipton", "createdAt": "2020-03-24T12:22:02Z", "path": "buildenv/jenkins/common/build.groovy", "diffHunk": "@@ -325,45 +325,48 @@ def archive_sdk() {\n                     }\n                 }\n             }\n-            if (ARTIFACTORY_SERVER) {\n+            if (ARTIFACTORY_CONFIG) {\n                 def specs = []\n                 def sdkSpec = [\"pattern\": \"${OPENJDK_CLONE_DIR}/${SDK_FILENAME}\",\n-                               \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                               \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                                \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"]\n                 specs.add(sdkSpec)\n                 def testSpec = [\"pattern\": \"${OPENJDK_CLONE_DIR}/${TEST_FILENAME}\",\n-                                \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                                \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                                 \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"]\n                 specs.add(testSpec)\n                 def debugImageSpec = [\"pattern\": \"${OPENJDK_CLONE_DIR}/${DEBUG_IMAGE_FILENAME}\",\n-                                \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                                \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                                 \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"]\n                 specs.add(debugImageSpec)\n                 if (params.ARCHIVE_JAVADOC) {\n                     def javadocSpec = [\"pattern\": \"${OPENJDK_CLONE_DIR}/${JAVADOC_FILENAME}\",\n-                                       \"target\": \"${ARTIFACTORY_UPLOAD_DIR}\",\n+                                       \"target\": \"${ARTIFACTORY_CONFIG['uploadDir']}\",\n                                        \"props\": \"build.buildIdentifier=${BUILD_IDENTIFIER}\"]\n                     specs.add(javadocSpec)\n                 }\n                 def uploadFiles = [files : specs]\n                 def uploadSpec = JsonOutput.toJson(uploadFiles)\n                 upload_artifactory(uploadSpec)\n-                env.CUSTOMIZED_SDK_URL = \"${ARTIFACTORY_URL}/${ARTIFACTORY_UPLOAD_DIR}${SDK_FILENAME}\"\n+\n+                // Always use the default server link for the descirption and for test.", "originalCommit": "0829b3610b96c0c61b435bb86280e959829bb89a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzYwNTA1MQ==", "url": "https://github.com/eclipse-openj9/openj9/pull/8817#discussion_r397605051", "bodyText": "fixed", "author": "AdamBrousseau", "createdAt": "2020-03-25T04:36:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzExMDc3Nw=="}], "type": "inlineReview"}, {"oid": "15ffa6add821efd8c203fbd3f0df993074363762", "url": "https://github.com/eclipse-openj9/openj9/commit/15ffa6add821efd8c203fbd3f0df993074363762", "message": "Add support for multiple Artifactory servers\n\nArtifactory bandwidth has become an issue in the CI builds.\nThis has caused issues with upload and download times, as well\nas failing downloads due to infrastructure inadequacy.\nParticularly for UNB machines, where a large portion of the\nfarm is located, combined with the pipe into UNB being small.\n\nBeing able to setup multiple Artifactory servers spread across\ngeographies and colocated with pools of machines will allow us\nto push and more importantly pull from a nearby server.\n\nThe design leaves one site as the main (default) server (OSU). We\nwill always upload to the default server. We will only upload\nto a secondary server(s) if there are machines with a matching\nplatform, colocated with another (non-default) server. The design\nis laid out so it will scale with more servers without any code\nchange other than adding to the defaults.yml config.\n\nSince we cannot determine where a test will land (geographically),\nwe need to upload to any/all servers that are colocated with machines\nof matching platform. We also will always pass the default SDK URL.\nWe will add a curl wrapper on the nodes which have colocated servers.\nThis wrapper will redirect requests from one server to another. In\nthis case redirect OSU requests to UNB. We will also strip off\nthe user/password since a) The servers allow anonymous access and\nb) The user's api key will be different for every server.\n\nChanges introduced:\n- Redesign the Artifactory config in defaults.yml to support multiple\n  servers. Identify servers based on geo(graphy) and identify one\n  geo as default.\n- Redesign the Artifactory variables as a single hashmap. This keeps\n  all the config together. Continue to write out the default server\n  values to env, in order for the parent job to continue as-is.\n- Move Artifactory setup onto the compile node. This is needed\n  in order to determine where we are compiling and where we need\n  to upload.\n- Add support for uploading to a server behind a vpn. If we aren't\n  compiling behind the vpn, stash the SDK for later when we can\n  grab a node in the same geo as the server we need to push to.\n  Note: We cannot publish buildInfo to vpn'd servers. Artifacts\n  come from nodes but buildInfo comes from Master, so Master needs\n  to see the server.\n- Add some more details to the Artifacotry README. Also add more\n  info specific to the UNB setup.\n\nAlso:\n- Unrelated change to stop adding JAVADOC_LIB_URL to the CUSTOMIZED_SDK_URL.\n  CUSTOMIZED_SDK_URL is for test and test doesn't need JAVADOC.\n\n[skip ci]\nIssue #8425\n\nSigned-off-by: Adam Brousseau <adam.brousseau88@gmail.com>", "committedDate": "2020-03-25T04:36:01Z", "type": "commit"}, {"oid": "15ffa6add821efd8c203fbd3f0df993074363762", "url": "https://github.com/eclipse-openj9/openj9/commit/15ffa6add821efd8c203fbd3f0df993074363762", "message": "Add support for multiple Artifactory servers\n\nArtifactory bandwidth has become an issue in the CI builds.\nThis has caused issues with upload and download times, as well\nas failing downloads due to infrastructure inadequacy.\nParticularly for UNB machines, where a large portion of the\nfarm is located, combined with the pipe into UNB being small.\n\nBeing able to setup multiple Artifactory servers spread across\ngeographies and colocated with pools of machines will allow us\nto push and more importantly pull from a nearby server.\n\nThe design leaves one site as the main (default) server (OSU). We\nwill always upload to the default server. We will only upload\nto a secondary server(s) if there are machines with a matching\nplatform, colocated with another (non-default) server. The design\nis laid out so it will scale with more servers without any code\nchange other than adding to the defaults.yml config.\n\nSince we cannot determine where a test will land (geographically),\nwe need to upload to any/all servers that are colocated with machines\nof matching platform. We also will always pass the default SDK URL.\nWe will add a curl wrapper on the nodes which have colocated servers.\nThis wrapper will redirect requests from one server to another. In\nthis case redirect OSU requests to UNB. We will also strip off\nthe user/password since a) The servers allow anonymous access and\nb) The user's api key will be different for every server.\n\nChanges introduced:\n- Redesign the Artifactory config in defaults.yml to support multiple\n  servers. Identify servers based on geo(graphy) and identify one\n  geo as default.\n- Redesign the Artifactory variables as a single hashmap. This keeps\n  all the config together. Continue to write out the default server\n  values to env, in order for the parent job to continue as-is.\n- Move Artifactory setup onto the compile node. This is needed\n  in order to determine where we are compiling and where we need\n  to upload.\n- Add support for uploading to a server behind a vpn. If we aren't\n  compiling behind the vpn, stash the SDK for later when we can\n  grab a node in the same geo as the server we need to push to.\n  Note: We cannot publish buildInfo to vpn'd servers. Artifacts\n  come from nodes but buildInfo comes from Master, so Master needs\n  to see the server.\n- Add some more details to the Artifacotry README. Also add more\n  info specific to the UNB setup.\n\nAlso:\n- Unrelated change to stop adding JAVADOC_LIB_URL to the CUSTOMIZED_SDK_URL.\n  CUSTOMIZED_SDK_URL is for test and test doesn't need JAVADOC.\n\n[skip ci]\nIssue #8425\n\nSigned-off-by: Adam Brousseau <adam.brousseau88@gmail.com>", "committedDate": "2020-03-25T04:36:01Z", "type": "forcePushed"}, {"oid": "7caada9461d1ea8a8cd10d920728da2975c54c21", "url": "https://github.com/eclipse-openj9/openj9/commit/7caada9461d1ea8a8cd10d920728da2975c54c21", "message": "Temporarily disable UNB Artifactory\n\n- We will hold off on enabling until we\n  have physical access to UNB again. If we\n  take down the p host we will be stuck.\n\n[skip ci]\nIssue #8425\n\nSigned-off-by: Adam Brousseau <adam.brousseau88@gmail.com>", "committedDate": "2020-03-26T04:33:48Z", "type": "commit"}, {"oid": "7caada9461d1ea8a8cd10d920728da2975c54c21", "url": "https://github.com/eclipse-openj9/openj9/commit/7caada9461d1ea8a8cd10d920728da2975c54c21", "message": "Temporarily disable UNB Artifactory\n\n- We will hold off on enabling until we\n  have physical access to UNB again. If we\n  take down the p host we will be stuck.\n\n[skip ci]\nIssue #8425\n\nSigned-off-by: Adam Brousseau <adam.brousseau88@gmail.com>", "committedDate": "2020-03-26T04:33:48Z", "type": "forcePushed"}]}