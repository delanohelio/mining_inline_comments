{"pr_number": 138, "pr_title": "SQL Classifier: Added SQL classification", "pr_createdAt": "2020-08-05T23:25:07Z", "pr_url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/138", "timeline": [{"oid": "0a17e4a834f54b9140355f1be5e1e3280ba42eef", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/0a17e4a834f54b9140355f1be5e1e3280ba42eef", "message": "Added pom and parser classifier files", "committedDate": "2020-08-05T23:17:16Z", "type": "commit"}, {"oid": "f289def6268887bfe7582a0debcd5140a189f91d", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/f289def6268887bfe7582a0debcd5140a189f91d", "message": "Added test files", "committedDate": "2020-08-05T23:17:28Z", "type": "commit"}, {"oid": "69a2e43317c6066d2c7c29731bffeab9ec2f3155", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/69a2e43317c6066d2c7c29731bffeab9ec2f3155", "message": "Added dialect parser jars", "committedDate": "2020-08-05T23:19:12Z", "type": "commit"}, {"oid": "8523b45c397cf1120c9bf380ebeb532c9836f40e", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/8523b45c397cf1120c9bf380ebeb532c9836f40e", "message": "Updated README", "committedDate": "2020-08-05T23:23:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjUzNDE0Mw==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/138#discussion_r466534143", "bodyText": "Why it's called like this? Should be Classifier or something similar?", "author": "yzhvictor", "createdAt": "2020-08-06T16:25:47Z", "path": "tools/unsupervised_dataset/sql_classifier/parserc/src/main/java/Parserc.java", "diffHunk": "@@ -0,0 +1,156 @@\n+import com.opencsv.*;\n+import org.apache.calcite.sql.parser.SqlParseException;\n+import org.apache.calcite.sql.parser.SqlParser;\n+\n+import org.apache.calcite.sql.parser.dialect1.Dialect1ParserImpl;\n+import org.apache.calcite.sql.parser.bigquery.BigQueryParserImpl;\n+import org.apache.calcite.sql.parser.defaultdialect.DefaultDialectParserImpl;\n+import org.apache.calcite.sql.parser.postgresql.PostgreSQLParserImpl;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.FileWriter;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.Date;\n+\n+public class Parserc {", "originalCommit": "8523b45c397cf1120c9bf380ebeb532c9836f40e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjUzNjc2NQ==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/138#discussion_r466536765", "bodyText": "Instead of adding it one by one, is it possible to do it in a loop to add all dialects Calcite has. Therefore, when Calcite has new dialect, it will be automatically included?", "author": "yzhvictor", "createdAt": "2020-08-06T16:30:17Z", "path": "tools/unsupervised_dataset/sql_classifier/parserc/src/main/java/Parserc.java", "diffHunk": "@@ -0,0 +1,156 @@\n+import com.opencsv.*;\n+import org.apache.calcite.sql.parser.SqlParseException;\n+import org.apache.calcite.sql.parser.SqlParser;\n+\n+import org.apache.calcite.sql.parser.dialect1.Dialect1ParserImpl;\n+import org.apache.calcite.sql.parser.bigquery.BigQueryParserImpl;\n+import org.apache.calcite.sql.parser.defaultdialect.DefaultDialectParserImpl;\n+import org.apache.calcite.sql.parser.postgresql.PostgreSQLParserImpl;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.FileWriter;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.Date;\n+\n+public class Parserc {\n+    /*\n+     * Runs the classification tool. Takes a CSV file of queries, classifies queries based on dialect, and creates\n+     * several subdirectories to store the queries by dialect.\n+     *\n+     * @param args Command line arguments\n+     */\n+    public static void main(String[] args) {\n+        if (args.length == 0) {\n+            System.out.println(\"Please provide a CSV file.\");\n+            return;\n+        }\n+        List<String[]> allData = readCSV(args[0]);\n+        if (allData == null) {\n+            return;\n+        }\n+        SqlParser.Config[] parserConfigs = new SqlParser.Config[4];\n+        parserConfigs[0] = SqlParser.configBuilder().setParserFactory(DefaultDialectParserImpl.FACTORY).build();", "originalCommit": "8523b45c397cf1120c9bf380ebeb532c9836f40e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcwNDk4MA==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/138#discussion_r466704980", "bodyText": "I'm not sure if this is possible, especially with the workaround we are using since we cannot get some of the dependencies online yet? I think this would definitely make the most sense when we have the capabilities, so this can be a change once it is available.", "author": "noah-kuo", "createdAt": "2020-08-06T21:49:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjUzNjc2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjUzNzI5Ng==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/138#discussion_r466537296", "bodyText": "consider using logger instead of system.out.print", "author": "yzhvictor", "createdAt": "2020-08-06T16:31:12Z", "path": "tools/unsupervised_dataset/sql_classifier/parserc/src/main/java/Parserc.java", "diffHunk": "@@ -0,0 +1,156 @@\n+import com.opencsv.*;\n+import org.apache.calcite.sql.parser.SqlParseException;\n+import org.apache.calcite.sql.parser.SqlParser;\n+\n+import org.apache.calcite.sql.parser.dialect1.Dialect1ParserImpl;\n+import org.apache.calcite.sql.parser.bigquery.BigQueryParserImpl;\n+import org.apache.calcite.sql.parser.defaultdialect.DefaultDialectParserImpl;\n+import org.apache.calcite.sql.parser.postgresql.PostgreSQLParserImpl;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.FileWriter;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.Date;\n+\n+public class Parserc {\n+    /*\n+     * Runs the classification tool. Takes a CSV file of queries, classifies queries based on dialect, and creates\n+     * several subdirectories to store the queries by dialect.\n+     *\n+     * @param args Command line arguments\n+     */\n+    public static void main(String[] args) {\n+        if (args.length == 0) {\n+            System.out.println(\"Please provide a CSV file.\");\n+            return;\n+        }\n+        List<String[]> allData = readCSV(args[0]);\n+        if (allData == null) {\n+            return;\n+        }\n+        SqlParser.Config[] parserConfigs = new SqlParser.Config[4];\n+        parserConfigs[0] = SqlParser.configBuilder().setParserFactory(DefaultDialectParserImpl.FACTORY).build();\n+        parserConfigs[1] = SqlParser.configBuilder().setParserFactory(Dialect1ParserImpl.FACTORY).build();\n+        parserConfigs[2] = SqlParser.configBuilder().setParserFactory(BigQueryParserImpl.FACTORY).build();\n+        parserConfigs[3] = SqlParser.configBuilder().setParserFactory(PostgreSQLParserImpl.FACTORY).build();\n+\n+        CSVWriter[] writers = setupOutput();\n+\n+        for (String[] data : allData) {\n+            boolean[] results = classifyQuery(cleanQuery(data[0]), parserConfigs);\n+            boolean unclassified = true;\n+            String[] nextLine = {data[0], data[1]};\n+            for (int i = 0; i < results.length; i++) {\n+                if (results[i]) {\n+                    unclassified = false;\n+                    writers[i].writeNext(nextLine);\n+                }\n+            }\n+            if (unclassified) {\n+                writers[writers.length-1].writeNext(nextLine);\n+            }\n+        }\n+        try {\n+            for (CSVWriter writer : writers) {\n+                writer.close();\n+            }\n+        } catch (Exception e) {\n+            e.printStackTrace();\n+        }\n+\n+    }\n+\n+    /*\n+     * Reads a CSV file and returns the data as a list of String arrays.\n+     *\n+     * @param filename Path to a CSV file\n+     * @return Contents of the CSV file\n+     */\n+    static List<String[]> readCSV(String filename) {\n+        try {\n+            FileReader filereader = new FileReader(filename);\n+            CSVReader csvReader = new CSVReaderBuilder(filereader).withSkipLines(1).build();\n+            return csvReader.readAll();\n+        }\n+        catch (Exception e) {\n+            System.out.println(e);", "originalCommit": "8523b45c397cf1120c9bf380ebeb532c9836f40e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjUzNzk3MQ==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/138#discussion_r466537971", "bodyText": "null may cause issues if other parts didn't handle correctly, consider using Optional<List<String[]>> as return type.", "author": "yzhvictor", "createdAt": "2020-08-06T16:32:26Z", "path": "tools/unsupervised_dataset/sql_classifier/parserc/src/main/java/Parserc.java", "diffHunk": "@@ -0,0 +1,156 @@\n+import com.opencsv.*;\n+import org.apache.calcite.sql.parser.SqlParseException;\n+import org.apache.calcite.sql.parser.SqlParser;\n+\n+import org.apache.calcite.sql.parser.dialect1.Dialect1ParserImpl;\n+import org.apache.calcite.sql.parser.bigquery.BigQueryParserImpl;\n+import org.apache.calcite.sql.parser.defaultdialect.DefaultDialectParserImpl;\n+import org.apache.calcite.sql.parser.postgresql.PostgreSQLParserImpl;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.FileWriter;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.Date;\n+\n+public class Parserc {\n+    /*\n+     * Runs the classification tool. Takes a CSV file of queries, classifies queries based on dialect, and creates\n+     * several subdirectories to store the queries by dialect.\n+     *\n+     * @param args Command line arguments\n+     */\n+    public static void main(String[] args) {\n+        if (args.length == 0) {\n+            System.out.println(\"Please provide a CSV file.\");\n+            return;\n+        }\n+        List<String[]> allData = readCSV(args[0]);\n+        if (allData == null) {\n+            return;\n+        }\n+        SqlParser.Config[] parserConfigs = new SqlParser.Config[4];\n+        parserConfigs[0] = SqlParser.configBuilder().setParserFactory(DefaultDialectParserImpl.FACTORY).build();\n+        parserConfigs[1] = SqlParser.configBuilder().setParserFactory(Dialect1ParserImpl.FACTORY).build();\n+        parserConfigs[2] = SqlParser.configBuilder().setParserFactory(BigQueryParserImpl.FACTORY).build();\n+        parserConfigs[3] = SqlParser.configBuilder().setParserFactory(PostgreSQLParserImpl.FACTORY).build();\n+\n+        CSVWriter[] writers = setupOutput();\n+\n+        for (String[] data : allData) {\n+            boolean[] results = classifyQuery(cleanQuery(data[0]), parserConfigs);\n+            boolean unclassified = true;\n+            String[] nextLine = {data[0], data[1]};\n+            for (int i = 0; i < results.length; i++) {\n+                if (results[i]) {\n+                    unclassified = false;\n+                    writers[i].writeNext(nextLine);\n+                }\n+            }\n+            if (unclassified) {\n+                writers[writers.length-1].writeNext(nextLine);\n+            }\n+        }\n+        try {\n+            for (CSVWriter writer : writers) {\n+                writer.close();\n+            }\n+        } catch (Exception e) {\n+            e.printStackTrace();\n+        }\n+\n+    }\n+\n+    /*\n+     * Reads a CSV file and returns the data as a list of String arrays.\n+     *\n+     * @param filename Path to a CSV file\n+     * @return Contents of the CSV file\n+     */\n+    static List<String[]> readCSV(String filename) {\n+        try {\n+            FileReader filereader = new FileReader(filename);\n+            CSVReader csvReader = new CSVReaderBuilder(filereader).withSkipLines(1).build();\n+            return csvReader.readAll();\n+        }\n+        catch (Exception e) {\n+            System.out.println(e);\n+            return null;", "originalCommit": "8523b45c397cf1120c9bf380ebeb532c9836f40e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjUzODM3Ng==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/138#discussion_r466538376", "bodyText": "will a map be more explicit? key can be dialect, value is true or false?", "author": "yzhvictor", "createdAt": "2020-08-06T16:33:11Z", "path": "tools/unsupervised_dataset/sql_classifier/parserc/src/main/java/Parserc.java", "diffHunk": "@@ -0,0 +1,156 @@\n+import com.opencsv.*;\n+import org.apache.calcite.sql.parser.SqlParseException;\n+import org.apache.calcite.sql.parser.SqlParser;\n+\n+import org.apache.calcite.sql.parser.dialect1.Dialect1ParserImpl;\n+import org.apache.calcite.sql.parser.bigquery.BigQueryParserImpl;\n+import org.apache.calcite.sql.parser.defaultdialect.DefaultDialectParserImpl;\n+import org.apache.calcite.sql.parser.postgresql.PostgreSQLParserImpl;\n+\n+import java.io.File;\n+import java.io.FileReader;\n+import java.io.FileWriter;\n+import java.text.SimpleDateFormat;\n+import java.util.List;\n+import java.util.Date;\n+\n+public class Parserc {\n+    /*\n+     * Runs the classification tool. Takes a CSV file of queries, classifies queries based on dialect, and creates\n+     * several subdirectories to store the queries by dialect.\n+     *\n+     * @param args Command line arguments\n+     */\n+    public static void main(String[] args) {\n+        if (args.length == 0) {\n+            System.out.println(\"Please provide a CSV file.\");\n+            return;\n+        }\n+        List<String[]> allData = readCSV(args[0]);\n+        if (allData == null) {\n+            return;\n+        }\n+        SqlParser.Config[] parserConfigs = new SqlParser.Config[4];\n+        parserConfigs[0] = SqlParser.configBuilder().setParserFactory(DefaultDialectParserImpl.FACTORY).build();\n+        parserConfigs[1] = SqlParser.configBuilder().setParserFactory(Dialect1ParserImpl.FACTORY).build();\n+        parserConfigs[2] = SqlParser.configBuilder().setParserFactory(BigQueryParserImpl.FACTORY).build();\n+        parserConfigs[3] = SqlParser.configBuilder().setParserFactory(PostgreSQLParserImpl.FACTORY).build();\n+\n+        CSVWriter[] writers = setupOutput();\n+\n+        for (String[] data : allData) {\n+            boolean[] results = classifyQuery(cleanQuery(data[0]), parserConfigs);\n+            boolean unclassified = true;\n+            String[] nextLine = {data[0], data[1]};\n+            for (int i = 0; i < results.length; i++) {\n+                if (results[i]) {\n+                    unclassified = false;\n+                    writers[i].writeNext(nextLine);\n+                }\n+            }\n+            if (unclassified) {\n+                writers[writers.length-1].writeNext(nextLine);\n+            }\n+        }\n+        try {\n+            for (CSVWriter writer : writers) {\n+                writer.close();\n+            }\n+        } catch (Exception e) {\n+            e.printStackTrace();\n+        }\n+\n+    }\n+\n+    /*\n+     * Reads a CSV file and returns the data as a list of String arrays.\n+     *\n+     * @param filename Path to a CSV file\n+     * @return Contents of the CSV file\n+     */\n+    static List<String[]> readCSV(String filename) {\n+        try {\n+            FileReader filereader = new FileReader(filename);\n+            CSVReader csvReader = new CSVReaderBuilder(filereader).withSkipLines(1).build();\n+            return csvReader.readAll();\n+        }\n+        catch (Exception e) {\n+            System.out.println(e);\n+            return null;\n+        }\n+    }\n+\n+    /*\n+     * Classifies a single query using different SQL parsers.\n+     *\n+     * @param query The query to be classified\n+     * @param parserConfigs The parsers for each of the different dialects\n+     * @return A boolean array, with true values if the query can be classified in a dialect and false otherwise\n+     */\n+    static boolean[] classifyQuery(String query, SqlParser.Config[] parserConfigs) {", "originalCommit": "8523b45c397cf1120c9bf380ebeb532c9836f40e", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "00c12982caceaadeb6906b13f36e3a8c52541e96", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/00c12982caceaadeb6906b13f36e3a8c52541e96", "message": "Updated file and class names", "committedDate": "2020-08-06T19:30:00Z", "type": "commit"}, {"oid": "1c67d962de0583d487cfcd5ec91168e834551fd5", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/1c67d962de0583d487cfcd5ec91168e834551fd5", "message": "Edited some method signatures and changed some variable types to improve readability and clarity", "committedDate": "2020-08-06T22:41:30Z", "type": "commit"}, {"oid": "bc27d4c2eefddb7d4bb3a10c6ee683b4e38bb407", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/bc27d4c2eefddb7d4bb3a10c6ee683b4e38bb407", "message": "Merge branch 'master' into classifier", "committedDate": "2020-08-10T18:08:53Z", "type": "commit"}]}