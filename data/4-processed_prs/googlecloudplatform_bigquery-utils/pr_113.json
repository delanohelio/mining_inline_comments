{"pr_number": 113, "pr_title": "Query Verification: Populate tables in bq and get query results", "pr_createdAt": "2020-07-21T23:24:05Z", "pr_url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/113", "timeline": [{"oid": "a02071e61075470959c0faec496fe2bb2f487902", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/a02071e61075470959c0faec496fe2bb2f487902", "message": "Populate tables in bq and get query results", "committedDate": "2020-07-21T22:39:16Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ2OTQwMw==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/113#discussion_r458469403", "bodyText": "Maybe we should log that the file is being skipped.", "author": "Luminarys", "createdAt": "2020-07-22T00:46:59Z", "path": "tools/query_verification/src/main/java/com/google/bigquery/Main.java", "diffHunk": "@@ -82,9 +89,22 @@ public static void main(String[] args) {\n \n         // Data input handling\n         if (command.hasOption(\"d\")) {\n-            // TODO Data input for data aware verification\n+            String[] dataOptionValues = command.getOptionValues(\"d\");\n+\n+            for (String dataFilePath : dataOptionValues) {\n+                String dataFileName = new File(dataFilePath).getName();\n+                String dataContents = getContentsOfFile(dataFilePath);\n+\n+                // Check file format\n+                if (dataFileName.substring(dataFileName.lastIndexOf(\".\") + 1).toLowerCase().equals(\"csv\")) {", "originalCommit": "a02071e61075470959c0faec496fe2bb2f487902", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODQ3NTQ5OA==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/113#discussion_r458475498", "bodyText": "Can we get more context from this than just the fact it was interrupted", "author": "Luminarys", "createdAt": "2020-07-22T01:10:00Z", "path": "tools/query_verification/src/main/java/com/google/bigquery/QueryVerifier.java", "diffHunk": "@@ -113,11 +93,122 @@ public void verifyDataFree() {\n      * Verifies migrated query by sending query jobs to BQ and TD to check for differences in the query results.\n      */\n     public void verifyDataAware() {\n-        boolean verificationResult = false;\n+        List<Table> tables = getBigQueryTablesFromSchema();\n+        populateBigQueryTablesFromData(tables);\n+\n+        // Create query jobs\n+        List<JobInfo> jobInfos = getJobInfosFromQuery(migratedQuery, false);\n+\n+        // Store results from every job\n+        List<QueryJobResults<TableResult>> bigQueryJobResults = new ArrayList<QueryJobResults<TableResult>>();\n+\n+        for (int i = 0; i < jobInfos.size(); i++) {\n+            JobInfo jobInfo = jobInfos.get(i);\n+\n+            // Retrieve query\n+            QueryJobConfiguration queryJobConfiguration = jobInfo.getConfiguration();\n+            String query = queryJobConfiguration.getQuery();\n+\n+            QueryJobResults results = null;\n+            try {\n+                // Run query job\n+                Job queryJob = bigQuery.create(jobInfo);\n+\n+                results = QueryJobResults.create(query, queryJob.getQueryResults());\n+            } catch (BigQueryException | InterruptedException e) {\n+                // Print out syntax/semantic errors returned from BQ\n+                System.out.printf(\"Error in Query #%d from %s\\n%s\\n\\n\", i, migratedQuery.path(), e.getMessage());\n+            } finally {\n+                // Store results\n+                bigQueryJobResults.add(results);\n+            }\n+        }\n+\n+        // Clear tables created\n+        tables.forEach(table -> BigQueryOptions.getDefaultInstance().getService().delete(table.getTableId()));\n+\n+        // TODO Run queries in TD\n \n-        // TODO Implement data aware verification\n+        // TODO Compare results\n \n-        System.out.printf(\"Data-Aware Verification %s\\n\", verificationResult ? \"Succeeded\" : \"Failed\");\n+        bigQueryJobResults.removeIf(Objects::isNull);\n+\n+        System.out.println();\n+        System.out.printf(\"%d/%d (%.2f%%) Queries Verified\\n\", bigQueryJobResults.size(), jobInfos.size(), bigQueryJobResults.size() * 100.0f / jobInfos.size());\n+        System.out.printf(\"Data-Aware Verification %s\\n\", bigQueryJobResults.size() == jobInfos.size() ? \"Succeeded\" : \"Failed\");\n+    }\n+\n+    /**\n+     * Creates BQ tables based on the provided schema\n+     * @return List of newly created tables\n+     */\n+    public List<Table> getBigQueryTablesFromSchema() {\n+        List<Table> tables = new ArrayList<Table>();\n+\n+        if (migratedSchema != null) {\n+            if (migratedSchema.isInJsonFormat()) {\n+                // Schema is JSON\n+                List<TableInfo> tableInfos = QueryVerifier.getTableInfoFromJsonSchema(migratedSchema);\n+                if (tableInfos != null) {\n+                    tableInfos.forEach(tableInfo -> tables.add(bigQuery.create(tableInfo)));\n+                }\n+            } else {\n+                // Schema is DDL\n+                JobInfo jobInfo = configureJob(migratedSchema.schema(), false);\n+                Job schemaJob = bigQuery.create(jobInfo);\n+                try {\n+                    schemaJob.waitFor();\n+                } catch (InterruptedException e) {\n+                    System.out.println(e.getMessage());\n+                }\n+\n+                List<TableId> tableIds = QueryVerifier.getTableIdsFromDdlSchema(migratedSchema);\n+                tableIds.forEach(tableId -> tables.add(bigQuery.getTable(tableId)));\n+            }\n+\n+            if (tables.isEmpty()) {\n+                System.out.println(migratedSchema.path() + \" is not correctly formatted.\");\n+            }\n+        }\n+\n+        return tables;\n+    }\n+\n+    /**\n+     * Populates BQ tables based on the provided table data\n+     * @param tables\n+     */\n+    public void populateBigQueryTablesFromData(List<Table> tables) {\n+        for (QueryVerificationData queryVerificationData : data) {\n+            Table table = bigQuery.getTable(queryVerificationData.datasetName(), queryVerificationData.tableName());\n+\n+            // Check if no schema was provided for this table\n+            if (table == null) {\n+                System.out.println(queryVerificationData.tableName() + \" has no provided schema.\");\n+\n+                // Try to continue verification\n+                continue;\n+            }\n+\n+            TableId tableId = table.getTableId();\n+\n+            // Copy contents of CSV file\n+            WriteChannelConfiguration writeChannelConfiguration = WriteChannelConfiguration.newBuilder(tableId).setFormatOptions(FormatOptions.csv()).build();\n+            TableDataWriteChannel writer = bigQuery.writer(writeChannelConfiguration);\n+            try {\n+                writer.write(ByteBuffer.wrap(queryVerificationData.contents().getBytes()));\n+                writer.close();\n+            } catch (IOException e) {\n+                System.out.println(\"I/O Exception: \" + e.getMessage());\n+            }\n+\n+            // Run table data writing job\n+            try {\n+                writer.getJob().waitFor();\n+            } catch (InterruptedException e) {", "originalCommit": "a02071e61075470959c0faec496fe2bb2f487902", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODUzNjQyNA==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/113#discussion_r458536424", "bodyText": "Do we really want to check the extension. I feel sometimes although the files are csv format, they don't necessary have .csv extension. I think maybe we can just assume people are providing valid files?", "author": "yzhvictor", "createdAt": "2020-07-22T05:05:35Z", "path": "tools/query_verification/src/main/java/com/google/bigquery/Main.java", "diffHunk": "@@ -82,9 +89,22 @@ public static void main(String[] args) {\n \n         // Data input handling\n         if (command.hasOption(\"d\")) {\n-            // TODO Data input for data aware verification\n+            String[] dataOptionValues = command.getOptionValues(\"d\");\n+\n+            for (String dataFilePath : dataOptionValues) {\n+                String dataFileName = new File(dataFilePath).getName();\n+                String dataContents = getContentsOfFile(dataFilePath);\n+\n+                // Check file format\n+                if (dataFileName.substring(dataFileName.lastIndexOf(\".\") + 1).toLowerCase().equals(\"csv\")) {", "originalCommit": "a02071e61075470959c0faec496fe2bb2f487902", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODUzNjk3MA==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/113#discussion_r458536970", "bodyText": "consider using logger library instead of system.out", "author": "yzhvictor", "createdAt": "2020-07-22T05:07:40Z", "path": "tools/query_verification/src/main/java/com/google/bigquery/QueryVerifier.java", "diffHunk": "@@ -113,11 +93,122 @@ public void verifyDataFree() {\n      * Verifies migrated query by sending query jobs to BQ and TD to check for differences in the query results.\n      */\n     public void verifyDataAware() {\n-        boolean verificationResult = false;\n+        List<Table> tables = getBigQueryTablesFromSchema();\n+        populateBigQueryTablesFromData(tables);\n+\n+        // Create query jobs\n+        List<JobInfo> jobInfos = getJobInfosFromQuery(migratedQuery, false);\n+\n+        // Store results from every job\n+        List<QueryJobResults<TableResult>> bigQueryJobResults = new ArrayList<QueryJobResults<TableResult>>();\n+\n+        for (int i = 0; i < jobInfos.size(); i++) {\n+            JobInfo jobInfo = jobInfos.get(i);\n+\n+            // Retrieve query\n+            QueryJobConfiguration queryJobConfiguration = jobInfo.getConfiguration();\n+            String query = queryJobConfiguration.getQuery();\n+\n+            QueryJobResults results = null;\n+            try {\n+                // Run query job\n+                Job queryJob = bigQuery.create(jobInfo);\n+\n+                results = QueryJobResults.create(query, queryJob.getQueryResults());\n+            } catch (BigQueryException | InterruptedException e) {\n+                // Print out syntax/semantic errors returned from BQ\n+                System.out.printf(\"Error in Query #%d from %s\\n%s\\n\\n\", i, migratedQuery.path(), e.getMessage());", "originalCommit": "a02071e61075470959c0faec496fe2bb2f487902", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTU3ODU1MQ==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/113#discussion_r459578551", "bodyText": "As discussed, we'll have a follow up pr to handle logging.", "author": "yzhvictor", "createdAt": "2020-07-23T16:32:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODUzNjk3MA=="}], "type": "inlineReview"}, {"oid": "dfcb059dd14a3f87e89cd8cacd1fe11e3caf7ad3", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/dfcb059dd14a3f87e89cd8cacd1fe11e3caf7ad3", "message": "Updated data input handling", "committedDate": "2020-07-23T15:44:43Z", "type": "commit"}, {"oid": "d32c68594921ff188d62b66af3ee9c16f3cd440d", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/d32c68594921ff188d62b66af3ee9c16f3cd440d", "message": "Improved error handling", "committedDate": "2020-07-23T15:47:24Z", "type": "commit"}, {"oid": "63e4caabdc8dc25f71503dea3cd901d4f8275548", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/63e4caabdc8dc25f71503dea3cd901d4f8275548", "message": "Merge branch 'master' into createTablesBq", "committedDate": "2020-07-24T12:28:15Z", "type": "commit"}]}