{"pr_number": 36, "pr_title": "Adding UDF Testing Framework", "pr_createdAt": "2020-02-08T02:05:15Z", "pr_url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36", "timeline": [{"oid": "d2d81c4abcd88972f4791309578d5286b1db6ef1", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/d2d81c4abcd88972f4791309578d5286b1db6ef1", "message": "Adding UDF Unit Testing Framework", "committedDate": "2019-11-07T19:40:46Z", "type": "commit"}, {"oid": "7ea3ae4a6dffa80348ff46b2168b9498b35eda16", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/7ea3ae4a6dffa80348ff46b2168b9498b35eda16", "message": "Adding test cases yaml files", "committedDate": "2019-11-07T20:04:28Z", "type": "commit"}, {"oid": "284e61df60d36668d7281311e4363af35d1dd293", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/284e61df60d36668d7281311e4363af35d1dd293", "message": "Adding test cases yaml files", "committedDate": "2019-11-07T20:24:28Z", "type": "commit"}, {"oid": "d0b2fa6ec3f7e3b06e99ff3e086784d5f62ba46d", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/d0b2fa6ec3f7e3b06e99ff3e086784d5f62ba46d", "message": "initial commit of contributing and readme docs in udfs", "committedDate": "2019-11-07T20:34:43Z", "type": "commit"}, {"oid": "3ae2882192c985aaa213d4e80ca95f56a3e59138", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/3ae2882192c985aaa213d4e80ca95f56a3e59138", "message": "Merge branch 'master' of https://github.com/danieldeleo/bigquery-utils", "committedDate": "2019-11-07T20:41:14Z", "type": "commit"}, {"oid": "42171455f65d1e709adf15679a78af39cbc513bb", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/42171455f65d1e709adf15679a78af39cbc513bb", "message": "Adding dataset back into function name", "committedDate": "2019-11-07T20:53:58Z", "type": "commit"}, {"oid": "ba840159fa656d18fad2fdb351dd5cefa2d0b1c5", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/ba840159fa656d18fad2fdb351dd5cefa2d0b1c5", "message": "Removing dataset from function name to allow deployment of UDF to a dynamic dataset which is set using the default_dataset parameter when executing queries.", "committedDate": "2019-11-07T21:27:09Z", "type": "commit"}, {"oid": "c474aa36fb50820ca9d71f588072b381657268c8", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/c474aa36fb50820ca9d71f588072b381657268c8", "message": "Escaping reserved SQL keywords \"left\" and \"right\" with backticks in UDFs", "committedDate": "2019-11-07T21:40:35Z", "type": "commit"}, {"oid": "d810e2388962e889d2149798e0cbeae98485e5e5", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/d810e2388962e889d2149798e0cbeae98485e5e5", "message": "Fixing bug in nullifzero teradata function", "committedDate": "2019-11-07T22:43:18Z", "type": "commit"}, {"oid": "8dfc10479e8e9fb0e6c4149791bf08b77ea92699", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/8dfc10479e8e9fb0e6c4149791bf08b77ea92699", "message": "Adding more test cases for int UDF", "committedDate": "2019-11-07T22:47:00Z", "type": "commit"}, {"oid": "2da0dfc916ce7a756e00ecc15bd223ced8dde11b", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/2da0dfc916ce7a756e00ecc15bd223ced8dde11b", "message": "Merge branch 'master' of https://github.com/danieldeleo/bigquery-utils", "committedDate": "2019-11-07T22:58:03Z", "type": "commit"}, {"oid": "b7381eeb3cb252391d6f6c63c945105bcfe05bf4", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/b7381eeb3cb252391d6f6c63c945105bcfe05bf4", "message": "Fixing Vertica test name", "committedDate": "2019-11-20T04:52:39Z", "type": "commit"}, {"oid": "b248af9cdab3f274c258c01e63c1d6e1b07159dd", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/b248af9cdab3f274c258c01e63c1d6e1b07159dd", "message": "Merge branch 'master' of https://github.com/danieldeleo/bigquery-utils", "committedDate": "2019-12-02T21:06:47Z", "type": "commit"}, {"oid": "4e86fc6ffc193b4ad6b6f1072a6d290c29e034b2", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/4e86fc6ffc193b4ad6b6f1072a6d290c29e034b2", "message": "Updating dev branch to be current with master (#28)", "committedDate": "2019-12-02T21:11:48Z", "type": "commit"}, {"oid": "80eca9ee7120fae0606dc358a1b56988eeb15e1f", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/80eca9ee7120fae0606dc358a1b56988eeb15e1f", "message": "Merge branch 'dev' into master", "committedDate": "2019-12-02T23:58:47Z", "type": "commit"}, {"oid": "3db074473f376d6e1ed5f40a49486964bbb91e0b", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/3db074473f376d6e1ed5f40a49486964bbb91e0b", "message": "Unify tests (#1)\n\nRestructuring to only use one test class with parameterized parallel test methods", "committedDate": "2019-12-12T23:47:25Z", "type": "commit"}, {"oid": "34495491b3b07dc9f5f7c19baf286e5c01e135ee", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/34495491b3b07dc9f5f7c19baf286e5c01e135ee", "message": "Merge branch 'master' of https://github.com/GoogleCloudPlatform/bigquery-utils", "committedDate": "2019-12-13T16:47:02Z", "type": "commit"}, {"oid": "e24cb0bbd03fd9ac90033e224004afc4b7fa90a3", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/e24cb0bbd03fd9ac90033e224004afc4b7fa90a3", "message": "Fixes to allow calling functions within functions", "committedDate": "2019-12-13T23:11:18Z", "type": "commit"}, {"oid": "b2157c7161ac39abf86976fc254fe3956736d5de", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/b2157c7161ac39abf86976fc254fe3956736d5de", "message": "Fixes to allow calling functions within functions", "committedDate": "2019-12-16T20:34:25Z", "type": "commit"}, {"oid": "f164efdb62b06a6dc8a88030b5990372e638f1d5", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/f164efdb62b06a6dc8a88030b5990372e638f1d5", "message": "Fixes to allow calling functions within functions", "committedDate": "2019-12-16T20:43:00Z", "type": "commit"}, {"oid": "0be92a4fcdf0f919cf46dc67c75bb418bdb376e4", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/0be92a4fcdf0f919cf46dc67c75bb418bdb376e4", "message": "Fixes to allow calling functions within functions", "committedDate": "2019-12-16T20:47:39Z", "type": "commit"}, {"oid": "1fc2dc12d62ad36ddef3e3a68201bdb7d8893369", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/1fc2dc12d62ad36ddef3e3a68201bdb7d8893369", "message": "Fixes to allow calling functions within functions", "committedDate": "2019-12-16T20:52:01Z", "type": "commit"}, {"oid": "0f2cf9a12e4b21f8e8b41d44ea6437bf1a7d08a4", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/0f2cf9a12e4b21f8e8b41d44ea6437bf1a7d08a4", "message": "Merge remote-tracking branch 'origin/master'", "committedDate": "2019-12-16T22:15:55Z", "type": "commit"}, {"oid": "251527cf2dc2bf7bd602d1b3fd04ad8e931f35f6", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/251527cf2dc2bf7bd602d1b3fd04ad8e931f35f6", "message": "Merge branch 'master' into master", "committedDate": "2019-12-16T22:20:18Z", "type": "commit"}, {"oid": "2e3e79d513de308955bdd8f23de2ae12e9c885b9", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/2e3e79d513de308955bdd8f23de2ae12e9c885b9", "message": "Merge branch 'master' of https://github.com/danieldeleo/bigquery-utils", "committedDate": "2019-12-16T22:33:48Z", "type": "commit"}, {"oid": "67143b87a24bbbde684aa5ff061f80ffc27c71ed", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/67143b87a24bbbde684aa5ff061f80ffc27c71ed", "message": "Merge remote-tracking branch 'origin/master'\n\n# Conflicts:\n#\tudfs/community/README.md\n#\tudfs/migration/redshift/README.md", "committedDate": "2019-12-16T22:36:12Z", "type": "commit"}, {"oid": "6f259d9396e0e6b7546fc4ab9fad182f4fd8a153", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/6f259d9396e0e6b7546fc4ab9fad182f4fd8a153", "message": "Updates to address code review comments", "committedDate": "2020-01-10T22:54:53Z", "type": "commit"}, {"oid": "cc7a90c004f803ba15ac148299a5a56701f81463", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/cc7a90c004f803ba15ac148299a5a56701f81463", "message": "Updates to address code review comments", "committedDate": "2020-01-13T19:01:11Z", "type": "commit"}, {"oid": "ce8711558784fffaf51624d97a35d6c6972fadd7", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/ce8711558784fffaf51624d97a35d6c6972fadd7", "message": "Merge branch 'master' of https://github.com/GoogleCloudPlatform/bigquery-utils\n\n\u0001 Conflicts:\n\u0001\tudfs/community/README.md", "committedDate": "2020-01-13T19:02:56Z", "type": "commit"}, {"oid": "90a907827718a58fae0b40f17fdc819422d0f5fd", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/90a907827718a58fae0b40f17fdc819422d0f5fd", "message": "Updates to address code review comments", "committedDate": "2020-01-13T19:44:36Z", "type": "commit"}, {"oid": "f5385c64bf6b30ac4bc18358220c2d41e056e48b", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/f5385c64bf6b30ac4bc18358220c2d41e056e48b", "message": "Updates to address code review comments", "committedDate": "2020-01-28T15:21:57Z", "type": "commit"}, {"oid": "84b61419678cf00552e07ebd52030563cc228b17", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/84b61419678cf00552e07ebd52030563cc228b17", "message": "Updates to address code review comments", "committedDate": "2020-01-31T18:52:19Z", "type": "commit"}, {"oid": "ad40620277c8347ad01a0b087a34dd10a15065aa", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/ad40620277c8347ad01a0b087a34dd10a15065aa", "message": "Reformatting markdown", "committedDate": "2020-02-07T23:12:04Z", "type": "commit"}, {"oid": "4affdcdf949e2d844d4d3574d252a503c6931626", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/4affdcdf949e2d844d4d3574d252a503c6931626", "message": "Merge branch 'master' of https://github.com/GoogleCloudPlatform/bigquery-utils", "committedDate": "2020-02-07T23:20:04Z", "type": "commit"}, {"oid": "53650c983cd676f0ddd7123a80cace9467d9ba91", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/53650c983cd676f0ddd7123a80cace9467d9ba91", "message": "Updates to address code review", "committedDate": "2020-02-08T00:56:05Z", "type": "commit"}, {"oid": "03b3cb33a545965607fe23919a8651b61a0f58e3", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/03b3cb33a545965607fe23919a8651b61a0f58e3", "message": "Updates to address code review", "committedDate": "2020-02-08T01:36:29Z", "type": "commit"}, {"oid": "e956336cd2d28fc87cb9c4b53c92daf66b99fa6b", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/e956336cd2d28fc87cb9c4b53c92daf66b99fa6b", "message": "Updates to address code review", "committedDate": "2020-02-08T01:59:23Z", "type": "commit"}, {"oid": "3b057d8310fe4de6f8020e3ef77f6659581a8858", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/3b057d8310fe4de6f8020e3ef77f6659581a8858", "message": "Updates to address code review", "committedDate": "2020-02-11T21:15:18Z", "type": "commit"}, {"oid": "340d5753a6adfd86590356e81336b5d1f0c62c1a", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/340d5753a6adfd86590356e81336b5d1f0c62c1a", "message": "Updates to address code review", "committedDate": "2020-02-12T17:38:29Z", "type": "commit"}, {"oid": "13da329c81a4c42024a90943a6ec055e58264b4d", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/13da329c81a4c42024a90943a6ec055e58264b4d", "message": "Updates to address code review", "committedDate": "2020-02-12T20:43:11Z", "type": "commit"}, {"oid": "f1c035c7d8f27a29d66b691c65123f62d60bec3c", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/f1c035c7d8f27a29d66b691c65123f62d60bec3c", "message": "Updates to address code review", "committedDate": "2020-02-12T20:52:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU0MTIzNw==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r378541237", "bodyText": "This venv is bare. Are you missing a step to pip install dependencies?", "author": "jaketf", "createdAt": "2020-02-12T22:08:04Z", "path": "udfs/CONTRIBUTING.md", "diffHunk": "@@ -0,0 +1,92 @@\n+# Contributing UDFs\n+\n+Thank you for taking the time to contribute to this repository of user-defined\n+functions (UDFs) for BigQuery.\n+\n+The following is a set of guidelines for contributing a UDF to this repository.\n+\n+## UDF Contribution Guidelines\n+\n+### Add your UDF\n+\n+1.  Add your UDFs (**one** UDF per file) and a\n+    [Contributor License Agreement](#contributor-license-agreement) to the\n+    appropriate directory.\n+    *   If your function replicates logic from some other data warehouse UDF,\n+        place it in the relevant sub-directory in the\n+        [migration](/udfs/migration) directory. Otherwise, place it in the\n+        [community](/udfs/community) directory.\n+1.  Add test cases for your UDFs.\n+    *   Edit the `test_cases.yaml` file to include test inputs and expected\n+        outputs for the function.\n+    *   Make sure test cases provide full coverage of the function's expected\n+        behavior. For example, if integers are the expected input, please\n+        provide test cases with the following inputs: negative numbers, zero,\n+        positive numbers, and null values.\n+1.  Describe what your UDF does.\n+    *   Edit the `README.md` in the associated sub-directory to include a\n+        description of the function and make sure your function is listed in\n+        alphabetical order amongst the other functions in the `README.md`.\n+    *   Make sure the same description is placed as a comment in your UDF file.\n+\n+### Test your UDF\n+\n+1.  Test your UDF locally using the test cases you added to the\n+    `test_cases.yaml` file. Please follow the instructions in the\n+    [Testing UDFs Locally section](#testing-udfs-locally) to automatically test\n+    all inputs for the expected outputs using the function.\n+\n+### Submit a Pull Request\n+\n+1.  Submit a pull request and we will review the code as soon as possible.\n+    Please see the section on [Code Reviews](#code-reviews) for more\n+    information.\n+\n+Note: Your pull request, and any following commits, will trigger a testing\n+pipeline that will run unit tests on your submitted function as well as all the\n+other existing functions. This is done by a Cloud Build Trigger which runs a\n+Bash script. This Bash script unit tests the functions, running the contributed\n+UDFs in BigQuery with the given input to check that it results in the expected\n+output. If these tests pass, this will indicate to the reviewer that the\n+functions work as expected. So testing these functions locally before submitting\n+the pull request can ensure a successful review process.\n+\n+## Testing UDFs Locally\n+\n+Please follow these instructions to confirm that the test cases being provided\n+in your pull request work as expected.\n+\n+1.  Change into the bigquery_utils top-level directory.\n+1.  Create a Python virtual environment and activate it:", "originalCommit": "f1c035c7d8f27a29d66b691c65123f62d60bec3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU0MTczNQ==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r378541735", "bodyText": "nit: can we relative link to this file?", "author": "jaketf", "createdAt": "2020-02-12T22:09:06Z", "path": "udfs/CONTRIBUTING.md", "diffHunk": "@@ -0,0 +1,92 @@\n+# Contributing UDFs\n+\n+Thank you for taking the time to contribute to this repository of user-defined\n+functions (UDFs) for BigQuery.\n+\n+The following is a set of guidelines for contributing a UDF to this repository.\n+\n+## UDF Contribution Guidelines\n+\n+### Add your UDF\n+\n+1.  Add your UDFs (**one** UDF per file) and a\n+    [Contributor License Agreement](#contributor-license-agreement) to the\n+    appropriate directory.\n+    *   If your function replicates logic from some other data warehouse UDF,\n+        place it in the relevant sub-directory in the\n+        [migration](/udfs/migration) directory. Otherwise, place it in the\n+        [community](/udfs/community) directory.\n+1.  Add test cases for your UDFs.\n+    *   Edit the `test_cases.yaml` file to include test inputs and expected", "originalCommit": "f1c035c7d8f27a29d66b691c65123f62d60bec3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU0Mzg5MQ==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r378543891", "bodyText": "nit / nice to have in future PR:\n\nalphabetizing is annoying and error prone (speaking for dyslexic experience)\nKeeping comments / README in sync is also annoying / error prone.\n\nSolution:\nDRY up documentation by auto-generate these READMEs instead of having this burden on contributor.\nMuch like javadoc or sphinx or terraform-docs These udf  READMEs should generated from the the comment in the UDF SQL files.", "author": "jaketf", "createdAt": "2020-02-12T22:14:01Z", "path": "udfs/CONTRIBUTING.md", "diffHunk": "@@ -0,0 +1,92 @@\n+# Contributing UDFs\n+\n+Thank you for taking the time to contribute to this repository of user-defined\n+functions (UDFs) for BigQuery.\n+\n+The following is a set of guidelines for contributing a UDF to this repository.\n+\n+## UDF Contribution Guidelines\n+\n+### Add your UDF\n+\n+1.  Add your UDFs (**one** UDF per file) and a\n+    [Contributor License Agreement](#contributor-license-agreement) to the\n+    appropriate directory.\n+    *   If your function replicates logic from some other data warehouse UDF,\n+        place it in the relevant sub-directory in the\n+        [migration](/udfs/migration) directory. Otherwise, place it in the\n+        [community](/udfs/community) directory.\n+1.  Add test cases for your UDFs.\n+    *   Edit the `test_cases.yaml` file to include test inputs and expected\n+        outputs for the function.\n+    *   Make sure test cases provide full coverage of the function's expected\n+        behavior. For example, if integers are the expected input, please\n+        provide test cases with the following inputs: negative numbers, zero,\n+        positive numbers, and null values.\n+1.  Describe what your UDF does.\n+    *   Edit the `README.md` in the associated sub-directory to include a\n+        description of the function and make sure your function is listed in\n+        alphabetical order amongst the other functions in the `README.md`.\n+    *   Make sure the same description is placed as a comment in your UDF file.", "originalCommit": "f1c035c7d8f27a29d66b691c65123f62d60bec3c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU5NDA2Nw==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r388594067", "bodyText": "I'll leave this as a v2", "author": "danieldeleo", "createdAt": "2020-03-05T22:04:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU0Mzg5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU0NTExNg==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r378545116", "bodyText": "Should this file be split up per function?\nSeems like this could get very long as number of UDFs grows.", "author": "jaketf", "createdAt": "2020-02-12T22:16:58Z", "path": "udfs/community/test_cases.yaml", "diffHunk": "@@ -0,0 +1,62 @@\n+int:", "originalCommit": "f1c035c7d8f27a29d66b691c65123f62d60bec3c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU5NDY1OQ==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r388594659", "bodyText": "single file is intentional to prevent having many files. Ctrl-f will be the worn out keys on keyboard", "author": "danieldeleo", "createdAt": "2020-03-05T22:05:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU0NTExNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU0Nzg0MQ==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r378547841", "bodyText": "nit: test-ception\nThis logic in your testing framework utilities could use unittests.", "author": "jaketf", "createdAt": "2020-02-12T22:23:21Z", "path": "udfs/tests/udf_test_utils.py", "diffHunk": "@@ -0,0 +1,122 @@\n+# Copyright 2019 Google LLC\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import glob\n+from os import path\n+from os.path import dirname\n+import re\n+import argparse\n+from google.cloud import bigquery\n+\n+from yaml import SafeLoader\n+from yaml import load\n+\n+BIGQUERY_TEST_DATASET_MAPPINGS = {\n+    'netezza': 'nz_test',\n+    'oracle': 'or_test',\n+    'redshift': 'rs_test',\n+    'teradata': 'td_test',\n+    'vertica': 've_test',\n+    'community': 'fn_test',\n+}\n+\n+UDF_PARENT_DIR = 'udfs/'\n+\n+\n+def get_all_udf_paths():\n+    return glob.glob(UDF_PARENT_DIR + '/**/*.sql', recursive=True)\n+\n+\n+def load_test_cases(udf_path):\n+    udf_dir = '/'.join(udf_path.split('/')[:-1])\n+    yaml_test_data_path = f'{udf_dir}/test_cases.yaml'\n+    if path.isfile(yaml_test_data_path):\n+        with open(yaml_test_data_path, 'r') as yaml_file:\n+            return load(yaml_file, Loader=SafeLoader)\n+    else:\n+        return None\n+\n+\n+def extract_udf_name(udf_path):", "originalCommit": "f1c035c7d8f27a29d66b691c65123f62d60bec3c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU4MDgyNw==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r388580827", "bodyText": "Addressed implicitly by adding a test to ensure that extract_udf_name is equivalent to the file name", "author": "danieldeleo", "createdAt": "2020-03-05T21:37:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU0Nzg0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU0OTU5Mg==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r378549592", "bodyText": "This should mention the aruments --[create/delete]_datasets arguments.\nWe should call out that testing \"locally\" requires creating BQ datasets in your own project to facilitate the tests.", "author": "jaketf", "createdAt": "2020-02-12T22:27:30Z", "path": "udfs/CONTRIBUTING.md", "diffHunk": "@@ -0,0 +1,92 @@\n+# Contributing UDFs\n+\n+Thank you for taking the time to contribute to this repository of user-defined\n+functions (UDFs) for BigQuery.\n+\n+The following is a set of guidelines for contributing a UDF to this repository.\n+\n+## UDF Contribution Guidelines\n+\n+### Add your UDF\n+\n+1.  Add your UDFs (**one** UDF per file) and a\n+    [Contributor License Agreement](#contributor-license-agreement) to the\n+    appropriate directory.\n+    *   If your function replicates logic from some other data warehouse UDF,\n+        place it in the relevant sub-directory in the\n+        [migration](/udfs/migration) directory. Otherwise, place it in the\n+        [community](/udfs/community) directory.\n+1.  Add test cases for your UDFs.\n+    *   Edit the `test_cases.yaml` file to include test inputs and expected\n+        outputs for the function.\n+    *   Make sure test cases provide full coverage of the function's expected\n+        behavior. For example, if integers are the expected input, please\n+        provide test cases with the following inputs: negative numbers, zero,\n+        positive numbers, and null values.\n+1.  Describe what your UDF does.\n+    *   Edit the `README.md` in the associated sub-directory to include a\n+        description of the function and make sure your function is listed in\n+        alphabetical order amongst the other functions in the `README.md`.\n+    *   Make sure the same description is placed as a comment in your UDF file.\n+\n+### Test your UDF\n+\n+1.  Test your UDF locally using the test cases you added to the\n+    `test_cases.yaml` file. Please follow the instructions in the\n+    [Testing UDFs Locally section](#testing-udfs-locally) to automatically test\n+    all inputs for the expected outputs using the function.\n+\n+### Submit a Pull Request\n+\n+1.  Submit a pull request and we will review the code as soon as possible.\n+    Please see the section on [Code Reviews](#code-reviews) for more\n+    information.\n+\n+Note: Your pull request, and any following commits, will trigger a testing\n+pipeline that will run unit tests on your submitted function as well as all the\n+other existing functions. This is done by a Cloud Build Trigger which runs a\n+Bash script. This Bash script unit tests the functions, running the contributed\n+UDFs in BigQuery with the given input to check that it results in the expected\n+output. If these tests pass, this will indicate to the reviewer that the\n+functions work as expected. So testing these functions locally before submitting\n+the pull request can ensure a successful review process.\n+\n+## Testing UDFs Locally\n+\n+Please follow these instructions to confirm that the test cases being provided\n+in your pull request work as expected.\n+\n+1.  Change into the bigquery_utils top-level directory.\n+1.  Create a Python virtual environment and activate it:\n+    *   `python3 -m venv venv`\n+    *   `source venv/bin/activate``\n+1.  Run all tests by invoking the `run.sh` script\n+    *   `bash udfs/tests/run.sh`", "originalCommit": "f1c035c7d8f27a29d66b691c65123f62d60bec3c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU1ODQ0MQ==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r378558441", "bodyText": "Installation of dependencies should happen outside of this script so the installation of dependencies doesn't happen on every test run.\nlocally I shouldn't have to run this pip step every time I want to run the tests just to functionally no-op.\nI think you did this so you can just use the python slim image directly.\nIt would be ideal to use the Docker cloud builder to build an image (Dockerfile base image python slim + this pip install line) or pull from cache in gcr that has these deps installed and the cloud build should just use this as your base image. We could make this publicly available gcr image for the purpose of contributing to this repo. This example from professional-services might be helpful\nIf you don't want to manage the container in GCR or want to be lazy for the purposes of this PR, then at least move this line into the cloud build.\nFor Example\n- name: python:3.8.0-slim\n  entrypoint: 'bash'\n args: [\"python3 -m pip install -r udfs/tests/requirements.txt && udfs/tests/run.sh\"]\n\nRegardless we should add to contributing a step to install the dependencies in the virtualenv so for local testing.", "author": "jaketf", "createdAt": "2020-02-12T22:49:32Z", "path": "udfs/tests/run.sh", "diffHunk": "@@ -0,0 +1,29 @@\n+#!/usr/bin/env bash\n+\n+# Copyright 2019 Google LLC\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+#########################################################################\n+# Call run.sh locally with an optional parameter specifying the test name\n+# if you want to run only that test and no others\n+#\n+# e.g. bash udfs/tests/run.sh test_community_udf\n+#\n+#########################################################################\n+python3 -m pip install -r udfs/tests/requirements.txt", "originalCommit": "f1c035c7d8f27a29d66b691c65123f62d60bec3c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODU5NTYzMg==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r388595632", "bodyText": "addressed via bash script argument to explicitly install dependencies", "author": "danieldeleo", "createdAt": "2020-03-05T22:07:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU1ODQ0MQ=="}], "type": "inlineReview"}, {"oid": "a30225072c47e8043cd449366007a8cf4b264614", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/a30225072c47e8043cd449366007a8cf4b264614", "message": "Updates to address code review", "committedDate": "2020-02-13T02:26:40Z", "type": "commit"}, {"oid": "d4bf8011117de7e7af18388ff9c2e97101b01b79", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/d4bf8011117de7e7af18388ff9c2e97101b01b79", "message": "Updates to address code review", "committedDate": "2020-02-13T02:27:35Z", "type": "commit"}, {"oid": "7b99fec40d745e4030017560679637484beb1962", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/7b99fec40d745e4030017560679637484beb1962", "message": "Fix mismatching function/file name and add implicit test for extract_udf_name", "committedDate": "2020-03-05T21:40:53Z", "type": "commit"}, {"oid": "cc541544529199fc0f16f57b71f5ddeb97034c6a", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/cc541544529199fc0f16f57b71f5ddeb97034c6a", "message": "Fix mismatching function/file name and add implicit test for extract_udf_name", "committedDate": "2020-03-05T22:12:15Z", "type": "commit"}, {"oid": "797784008c91742a5ed79791e5362bd4f8d5fbf4", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/797784008c91742a5ed79791e5362bd4f8d5fbf4", "message": "Documentation clarifications", "committedDate": "2020-03-06T16:16:49Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM5NzYxNA==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r403397614", "bodyText": "is this intentional?", "author": "jaketf", "createdAt": "2020-04-04T00:41:52Z", "path": "udfs/migration/teradata/otranslate.sql", "diffHunk": "@@ -14,7 +14,7 @@\n  * limitations under the License.\n  */\n \n-CREATE OR REPLACE FUNCTION td.translate(\n+CREATE OR REPLACE FUNCTION td.otranslate(", "originalCommit": "797784008c91742a5ed79791e5362bd4f8d5fbf4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE5MTI4Ng==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r404191286", "bodyText": "yes intentional. I'm fixing the name since this function is supposed to be otranslate as the author wrote in README https://github.com/GoogleCloudPlatform/bigquery-utils/tree/master/udfs/migration/teradata#otranslatesource_string-string-from_string-string-to_string-string", "author": "danieldeleo", "createdAt": "2020-04-06T15:40:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM5NzYxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM5OTAwNw==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r403399007", "bodyText": "TIL the cool kids use pathlib in python3 for these sorts of things.\nQuick example:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                parent_dir_name = str(dirname(udf_path).split('/')[-1])\n          \n          \n            \n                parent_dir_name = pathlib.Path(udf_path).absolute().parent.name\n          \n      \n    \n    \n  \n\nfrom pathlib import Path\np = Path('.')\np.absolute()  # PosixPath('/home/jferriero/VersionControl/ci-cd-for-data-processing-workflow')\np.absolute().parent  # PosixPath('/home/jferriero/VersionControl')\np.absolute().parent.name  # 'VersionControl'", "author": "jaketf", "createdAt": "2020-04-04T00:50:06Z", "path": "udfs/tests/udf_test_utils.py", "diffHunk": "@@ -0,0 +1,122 @@\n+# Copyright 2019 Google LLC\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import glob\n+from os import path\n+from os.path import dirname\n+import re\n+import argparse\n+from google.cloud import bigquery\n+\n+from yaml import SafeLoader\n+from yaml import load\n+\n+BIGQUERY_TEST_DATASET_MAPPINGS = {\n+    'netezza': 'nz_test',\n+    'oracle': 'or_test',\n+    'redshift': 'rs_test',\n+    'teradata': 'td_test',\n+    'vertica': 've_test',\n+    'community': 'fn_test',\n+}\n+\n+UDF_PARENT_DIR = 'udfs/'\n+\n+\n+def get_all_udf_paths():\n+    return glob.glob(UDF_PARENT_DIR + '/**/*.sql', recursive=True)\n+\n+\n+def load_test_cases(udf_path):\n+    udf_dir = '/'.join(udf_path.split('/')[:-1])\n+    yaml_test_data_path = f'{udf_dir}/test_cases.yaml'\n+    if path.isfile(yaml_test_data_path):\n+        with open(yaml_test_data_path, 'r') as yaml_file:\n+            return load(yaml_file, Loader=SafeLoader)\n+    else:\n+        return None\n+\n+\n+def extract_udf_name(udf_path):\n+    with open(udf_path) as udf_file:\n+        udf_sql = udf_file.read()\n+    udf_sql = udf_sql.replace('\\n', ' ')\n+    pattern = re.compile(r'FUNCTION\\s*`?(\\w+.)?(\\w+)`?\\s*\\(')\n+    match = pattern.search(udf_sql)\n+    if match:\n+        udf_name = match[2]\n+        return udf_name\n+    else:\n+        return None\n+\n+\n+def extract_udf_signature(udf_path):\n+    with open(udf_path) as udf_file:\n+        udf_sql = udf_file.read()\n+    udf_sql = udf_sql.replace('\\n', ' ')\n+    pattern = re.compile(r'FUNCTION\\s+(`?.+?`?.*?\\).*?\\s+)AS')\n+    match = pattern.search(udf_sql)\n+    if match:\n+        udf_name = match[1].replace('LANGUAGE', '').replace('js', '')\n+        return udf_name\n+    else:\n+        return udf_path\n+\n+\n+def replace_with_test_datasets(udf_path=None, project_id=None, udf_sql=None):\n+    if udf_path:\n+        with open(udf_path) as udf_file:\n+            udf_sql = udf_file.read()\n+    udf_length_before_replacement = len(udf_sql)\n+    udf_sql = re.sub(\n+        r'(\\w+\\.)?(?P<bq_dataset>\\w+)(?P<udf_name>\\.\\w+)\\(',\n+        f'`{project_id}.\\\\g<bq_dataset>_test\\\\g<udf_name>`(',\n+        udf_sql)\n+    if udf_length_before_replacement == len(udf_sql):\n+        return None\n+    else:\n+        return udf_sql\n+\n+\n+def get_target_bq_dataset(udf_path):\n+    parent_dir_name = str(dirname(udf_path).split('/')[-1])", "originalCommit": "797784008c91742a5ed79791e5362bd4f8d5fbf4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE5OTgxOA==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r404199818", "bodyText": "REALLY excited to join the cool kids, awesome tip, thanks!", "author": "danieldeleo", "createdAt": "2020-04-06T15:51:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM5OTAwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzM5OTQwMQ==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r403399401", "bodyText": "see other comment on pathlib\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                udf_dir = '/'.join(udf_path.split('/')[:-1])\n          \n          \n            \n                udf_dir = pathlib.Path(udf_path).parent", "author": "jaketf", "createdAt": "2020-04-04T00:51:50Z", "path": "udfs/tests/udf_test_utils.py", "diffHunk": "@@ -0,0 +1,122 @@\n+# Copyright 2019 Google LLC\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import glob\n+from os import path\n+from os.path import dirname\n+import re\n+import argparse\n+from google.cloud import bigquery\n+\n+from yaml import SafeLoader\n+from yaml import load\n+\n+BIGQUERY_TEST_DATASET_MAPPINGS = {\n+    'netezza': 'nz_test',\n+    'oracle': 'or_test',\n+    'redshift': 'rs_test',\n+    'teradata': 'td_test',\n+    'vertica': 've_test',\n+    'community': 'fn_test',\n+}\n+\n+UDF_PARENT_DIR = 'udfs/'\n+\n+\n+def get_all_udf_paths():\n+    return glob.glob(UDF_PARENT_DIR + '/**/*.sql', recursive=True)\n+\n+\n+def load_test_cases(udf_path):\n+    udf_dir = '/'.join(udf_path.split('/')[:-1])", "originalCommit": "797784008c91742a5ed79791e5362bd4f8d5fbf4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzQwMDQ3NQ==", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/pull/36#discussion_r403400475", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    file_name = splitext(basename(udf_path))[0]\n          \n          \n            \n                    file_name = pathlib.Path(udf_path).stem", "author": "jaketf", "createdAt": "2020-04-04T00:58:04Z", "path": "udfs/tests/test_run_udfs.py", "diffHunk": "@@ -0,0 +1,75 @@\n+# Copyright 2019 Google LLC\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import unittest\n+\n+from os.path import splitext\n+from os.path import basename\n+from parameterized import parameterized\n+from google.cloud import bigquery\n+from google.api_core.exceptions import GoogleAPICallError\n+\n+import udf_test_utils as utils\n+\n+\n+class TestRunUDFs(unittest.TestCase):\n+    \"\"\"\n+    This class uses the parameterized python package (https://pypi.org/project/parameterized/) to programmatically\n+    create multiple python test function definitions (based off `test_run_udf_and_verify_expected_result`).\n+    It will effectively create a python test function for each UDF that it encounters as it walks through the\n+    udfs/ directory. This class tests each UDF by running it in BigQuery with the inputs given in the test_cases.yaml\n+    file, and then asserting that the results equal the expected outputs given in the test_cases.yaml file.\n+    \"\"\"\n+\n+    @classmethod\n+    def setUpClass(cls):\n+        cls._client = bigquery.Client()\n+\n+    @parameterized.expand(utils.get_all_udf_paths())\n+    def test_run_udf_and_verify_expected_result(self, udf_path):\n+        client = self._client\n+        bq_test_dataset = utils.get_target_bq_dataset(udf_path)\n+        file_name = splitext(basename(udf_path))[0]", "originalCommit": "797784008c91742a5ed79791e5362bd4f8d5fbf4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d21a74bbe5213da461ad498b3f1760022173caef", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/d21a74bbe5213da461ad498b3f1760022173caef", "message": "Adding pathlib for cleaner file handling", "committedDate": "2020-04-07T03:06:14Z", "type": "commit"}, {"oid": "d2a14174db01db019c0a7113027758d58808831f", "url": "https://github.com/GoogleCloudPlatform/bigquery-utils/commit/d2a14174db01db019c0a7113027758d58808831f", "message": "python linter and one more pathlib change", "committedDate": "2020-04-07T03:18:22Z", "type": "commit"}]}