{"pr_number": 6902, "pr_title": "Moving extract wdls from variantstore repo", "pr_createdAt": "2020-10-20T12:43:22Z", "pr_url": "https://github.com/broadinstitute/gatk/pull/6902", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODY4MzMwNQ==", "url": "https://github.com/broadinstitute/gatk/pull/6902#discussion_r508683305", "bodyText": "FYI, my PR with the sample map change will also change this argument to be --read-project-id. Maybe we can make that change with this PR?", "author": "ericsong", "createdAt": "2020-10-20T16:45:51Z", "path": "scripts/variantstore_wdl/raw_array_cohort_extract.wdl", "diffHunk": "@@ -0,0 +1,242 @@\n+version 1.0\n+\n+workflow RawArrayCohortExtract {\n+   input {\n+        Int number_of_partitions = 2\n+        Int max_probe_id = 1914822\n+        \n+        Int probes_per_partition = ceil ( max_probe_id / number_of_partitions)\n+        \n+        File reference\n+        File reference_index\n+        File reference_dict\n+    \n+        String? fq_probe_info_table\n+        File? probe_info_file\n+        \n+        String fq_dataset\n+        Int max_tables\n+        String fq_destination_dataset\n+        String query_project\n+        String fq_cohort_mapping_table\n+        File cohort_sample_names_file\n+        Int ttl = 24\n+        \n+        String output_file_base_name\n+        String? gatk_override\n+    }\n+    \n+    call CreateExtractTable {\n+        input:\n+            fq_dataset                = fq_dataset,\n+            max_tables                = max_tables,\n+            fq_destination_dataset    = fq_destination_dataset,\n+            query_project             = query_project,\n+            fq_sample_mapping_table   = fq_cohort_mapping_table,\n+            cohort_sample_names_file  = cohort_sample_names_file,\n+            ttl                       = ttl,\n+            number_of_partitions      = number_of_partitions,\n+            probes_per_partition      = probes_per_partition\n+    }\n+  \n+    \n+    scatter(i in range(number_of_partitions)) {\n+        call ExtractTask {\n+            input:\n+                gatk_override         = gatk_override,\n+                reference             = reference,\n+                reference_index       = reference_index,\n+                reference_dict        = reference_dict,\n+                fq_probe_info_table   = fq_probe_info_table,\n+                probe_info_file       = probe_info_file,\n+                min_probe_id          = 1 + i * probes_per_partition,\n+                max_probe_id          = (i+1) * probes_per_partition,\n+                fq_cohort_mapping_table     = fq_cohort_mapping_table,\n+                cohort_extract_table  = CreateExtractTable.cohort_extract_table,\n+                project_id            = query_project,\n+                output_file           = \"${output_file_base_name}_${i}.vcf.gz\"\n+        }\n+    }\n+\n+    call MergeVCFs { \n+       input:\n+           input_vcfs = ExtractTask.output_vcf,\n+           input_vcfs_indexes = ExtractTask.output_vcf_index,\n+           output_vcf_name = \"${output_file_base_name}.vcf.gz\",\n+           preemptible_tries = 3\n+    }\n+    \n+    output {\n+        File output_vcf = MergeVCFs.output_vcf\n+        File output_vcf_idx = MergeVCFs.output_vcf_index\n+    }\n+}\n+\n+################################################################################\n+task CreateExtractTable {\n+    # indicates that this task should NOT be call cached\n+    meta {\n+       volatile: true\n+    }\n+\n+    # ------------------------------------------------\n+    # Input args:\n+    input {\n+        String fq_dataset\n+        Int max_tables\n+        String fq_destination_dataset\n+        String query_project\n+        String fq_sample_mapping_table\n+        File cohort_sample_names_file\n+        Int ttl\n+        Int number_of_partitions\n+        Int probes_per_partition\n+    }\n+\n+    # ------------------------------------------------\n+    # Run our command:\n+    command <<<\n+        set -e\n+\n+        uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\n+        export_table=\"~{fq_destination_dataset}.${uuid}\"\n+        echo \"Exporting to ${export_table}\"\n+        \n+        python /app/raw_array_cohort_extract.py \\\n+          --dataset ~{fq_dataset} \\\n+          --max_tables ~{max_tables} \\\n+          --fq_destination_table ${export_table} \\\n+          --query_project ~{query_project} \\\n+          --fq_sample_mapping_table ~{fq_sample_mapping_table} \\\n+          --cohort_sample_names_file ~{cohort_sample_names_file} \\\n+          --ttl ~{ttl} \\\n+          --number_of_partitions ~{number_of_partitions} \\\n+          --probes_per_partition ~{probes_per_partition}\n+          \n+        echo ${export_table} > cohort_extract_table.txt\n+\n+    >>>\n+\n+    # ------------------------------------------------\n+    # Runtime settings:\n+    runtime {\n+        docker: \"us.gcr.io/broad-dsde-methods/variantstore-export:091920\"\n+        memory: \"3 GB\"\n+        disks: \"local-disk 10 HDD\"\n+        bootDiskSizeGb: 15\n+        preemptible: 3\n+        cpu: 1\n+    }\n+\n+    # Outputs:\n+    output {\n+        String cohort_extract_table = read_string(\"cohort_extract_table.txt\")\n+    }    \n+}\n+\n+task ExtractTask {\n+    # indicates that this task should NOT be call cached\n+    meta {\n+       volatile: true\n+    }\n+\n+    input {\n+        # ------------------------------------------------\n+        # Input args:\n+        File reference\n+        File reference_index\n+        File reference_dict\n+    \n+        String? fq_probe_info_table \n+        File? probe_info_file\n+        String probe_info_clause = if defined(probe_info_file) then \"--probe-info-csv ${probe_info_file}\" else \"--probe-info-table ${fq_probe_info_table}\"\n+\n+        Int min_probe_id\n+        Int max_probe_id\n+        String fq_cohort_mapping_table\n+        String cohort_extract_table\n+        String project_id\n+        String output_file\n+        \n+        # Runtime Options:\n+        File? gatk_override\n+    }\n+\n+\n+    # ------------------------------------------------\n+    # Run our command:\n+    command <<<\n+        set -e\n+        export GATK_LOCAL_JAR=~{default=\"/root/gatk.jar\" gatk_override}\n+\n+        df -h\n+\n+        gatk --java-options \"-Xmx4g\" \\\n+            ArrayExtractCohort \\\n+                -R \"~{reference}\" \\\n+                -O \"~{output_file}\" \\\n+                ~{probe_info_clause} \\\n+                --project-id \"~{project_id}\" \\", "originalCommit": "81cad0ea4781805ab2af869c94480c911b6a5f48", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODcyODg0Mw==", "url": "https://github.com/broadinstitute/gatk/pull/6902#discussion_r508728843", "bodyText": "Great, yeah I'll update it here.", "author": "meganshand", "createdAt": "2020-10-20T17:58:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODY4MzMwNQ=="}], "type": "inlineReview"}, {"oid": "a6ffaf0416b13a90af33d044ae2f270b4f66ca7a", "url": "https://github.com/broadinstitute/gatk/commit/a6ffaf0416b13a90af33d044ae2f270b4f66ca7a", "message": "add files", "committedDate": "2020-10-20T19:15:46Z", "type": "commit"}, {"oid": "4a4a54b18c9ca8e0cee9add92a841d397bfb1b8b", "url": "https://github.com/broadinstitute/gatk/commit/4a4a54b18c9ca8e0cee9add92a841d397bfb1b8b", "message": "turn off testing", "committedDate": "2020-10-20T19:19:32Z", "type": "commit"}, {"oid": "e268d9497bddf17023bb20941692d7a12ef461e3", "url": "https://github.com/broadinstitute/gatk/commit/e268d9497bddf17023bb20941692d7a12ef461e3", "message": "updating readme", "committedDate": "2020-10-20T19:19:32Z", "type": "commit"}, {"oid": "6f0d76c3db4465792f70c6da13f0222e038495e0", "url": "https://github.com/broadinstitute/gatk/commit/6f0d76c3db4465792f70c6da13f0222e038495e0", "message": "updating parameter name", "committedDate": "2020-10-20T19:19:32Z", "type": "commit"}, {"oid": "6f0d76c3db4465792f70c6da13f0222e038495e0", "url": "https://github.com/broadinstitute/gatk/commit/6f0d76c3db4465792f70c6da13f0222e038495e0", "message": "updating parameter name", "committedDate": "2020-10-20T19:19:32Z", "type": "forcePushed"}]}