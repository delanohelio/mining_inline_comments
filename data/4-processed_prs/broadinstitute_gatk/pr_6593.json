{"pr_number": 6593, "pr_title": "Fixed bugs and simplified AlleleLikelihoods evidence-to-index cache", "pr_createdAt": "2020-05-11T03:25:15Z", "pr_url": "https://github.com/broadinstitute/gatk/pull/6593", "timeline": [{"oid": "fb006fd9fc2e8ce9ee549fdafa07622f05310765", "url": "https://github.com/broadinstitute/gatk/commit/fb006fd9fc2e8ce9ee549fdafa07622f05310765", "message": "Fixed bugs and simplified implementation of AlleleLikelihoods evidence-to-index cache", "committedDate": "2020-05-11T03:02:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzE3MDkxMg==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r423170912", "bodyText": "Make a method .invalidateCache() that gets called here and everywhere else we edit the evidences lists.", "author": "jamesemery", "createdAt": "2020-05-11T16:38:55Z", "path": "src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java", "diffHunk": "@@ -1129,60 +1129,45 @@ private void removeEvidence(final int sampleIndex, final Collection<EVIDENCE> ev\n         removeEvidenceByIndex(sampleIndex, indexesToRemove);\n     }\n \n+    // remove evidence and unset the {@code evidenceIndexBySampleIndex} Map for this sample\n     // assumes that evidencesToRemove is sorted and without duplicates.\n     private void removeEvidenceByIndex(final int sampleIndex, final int[] evidencesToRemove) {\n-        if (evidencesToRemove.length == 0) {\n+        final int numToRemove = evidencesToRemove.length;\n+        if (numToRemove == 0) {\n             return;\n-        } else {\n-            final Object2IntMap<EVIDENCE> evidenceIndex = evidenceIndexBySampleIndex(sampleIndex);\n-            final int oldEvidenceCount = numberOfEvidences[sampleIndex];\n-            final int newEvidenceCount = oldEvidenceCount - evidencesToRemove.length;\n-            if (newEvidenceCount < 0) {\n-                throw new IllegalStateException(\"attempt to remove non-existent evidence or repeated evidence\");\n-            } else if (newEvidenceCount == 0) { // taking in consideration the assumption we simply remove\n-                // all evidence.\n-                evidenceIndex.clear();\n-                numberOfEvidences[sampleIndex] = 0;\n+        }\n+        final int oldEvidenceCount = numberOfEvidences[sampleIndex];\n+        final int newEvidenceCount = oldEvidenceCount - evidencesToRemove.length;\n+        Utils.validate(newEvidenceCount >= 0, \"attempted to remove non-existent evidence or repeated evidence\");\n+\n+        // update the list of evidence and evidence count\n+        final List<EVIDENCE> oldEvidence = evidenceBySampleIndex.get(sampleIndex);\n+        final List<EVIDENCE> newEvidence = new ArrayList<>(newEvidenceCount);\n+        for (int n = 0, numRemoved = 0; n < oldEvidenceCount; n++) {\n+            if (numRemoved < numToRemove && n == evidencesToRemove[numRemoved]) {\n+                numRemoved++;\n             } else {\n-                final List<EVIDENCE> evidences = evidenceBySampleIndex.get(sampleIndex);\n-                final double[][] values = valuesBySampleIndex[sampleIndex];\n-\n-                int nextIndexToRemove = evidencesToRemove[0];\n-                if (nextIndexToRemove < 0) {\n-                    throw new IllegalStateException(\"invalid input index array as it contains negatives\");\n-                }\n-                evidenceIndex.remove(evidences.get(nextIndexToRemove));\n-                for (int etrIndex = 1, to = nextIndexToRemove, from = to + 1; to < newEvidenceCount; etrIndex++, from++) {\n-                    if (etrIndex < evidencesToRemove.length) {\n-                        nextIndexToRemove = evidencesToRemove[etrIndex];\n-                        if (nextIndexToRemove < from) {\n-                            throw new IllegalStateException(\"invalid input index array contains indexes out of order\");\n-                        } else if (nextIndexToRemove >= oldEvidenceCount) {\n-                            throw new IllegalStateException(\"invalid input index array contains indexes out of order\");\n-                        }\n-                        evidenceIndex.remove(evidences.get(nextIndexToRemove));\n-                    } else {\n-                        nextIndexToRemove = oldEvidenceCount;\n-                    }\n-                    for (; from < nextIndexToRemove; from++) {\n-                        final EVIDENCE evidence = evidences.get(from);\n-                        evidences.set(to, evidence);\n-                        evidenceIndex.put(evidence, to++);\n-                    }\n-                }\n-                Utils.truncate(evidences, newEvidenceCount);\n-                // now we do the likelihood values, we save ourselves all the checks:\n-                for (final double[] alleleValues : values) {\n-                    for (int etrIndex = 1, to = evidencesToRemove[0], from = to + 1; to < newEvidenceCount; from++, etrIndex++) {\n-                        nextIndexToRemove = etrIndex < evidencesToRemove.length ? evidencesToRemove[etrIndex] : oldEvidenceCount;\n-                        for (; from < nextIndexToRemove; from++) {\n-                            alleleValues[to++] = alleleValues[from];\n-                        }\n-                    }\n+                newEvidence.add(oldEvidence.get(n));\n+            }\n+        }\n+        Utils.validate(newEvidence.size() == newEvidenceCount, \"Indices to remove contained duplicates, was not ordered, or contained out-of-range indices.\");\n+        evidenceBySampleIndex.set(sampleIndex, newEvidence);\n+        numberOfEvidences[sampleIndex] = newEvidenceCount;\n+\n+        //  invalidate the cached evidence to index map\n+        evidenceIndexBySampleIndex.set(sampleIndex, null);", "originalCommit": "fb006fd9fc2e8ce9ee549fdafa07622f05310765", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzI3MTU3NQ==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r423271575", "bodyText": "Furthermore we should call invalidateCache() for all operations that mutate the sample arrays (so for adding samples and removing samples)", "author": "jamesemery", "createdAt": "2020-05-11T19:34:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzE3MDkxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU5OTI3Ng==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r429599276", "bodyText": "Done, but I didn't call the invalidate method for the case of adding evidence, for which updating the cache on the fly is easy.\nAnd I could just be really tired but I don't think there are any methods to add or remove samples.", "author": "davidbenjamin", "createdAt": "2020-05-24T04:59:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzE3MDkxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzI3MjAxMg==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r423272012", "bodyText": "Add some comments to evidenceIndexBySampleIndex.set(sampleIndex, null); and the class javadocs explaining how this cache works and what it accomplishes.", "author": "jamesemery", "createdAt": "2020-05-11T19:35:39Z", "path": "src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java", "diffHunk": "@@ -1129,60 +1129,45 @@ private void removeEvidence(final int sampleIndex, final Collection<EVIDENCE> ev\n         removeEvidenceByIndex(sampleIndex, indexesToRemove);\n     }\n \n+    // remove evidence and unset the {@code evidenceIndexBySampleIndex} Map for this sample", "originalCommit": "fb006fd9fc2e8ce9ee549fdafa07622f05310765", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTU5OTYzNQ==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r429599635", "bodyText": "done", "author": "davidbenjamin", "createdAt": "2020-05-24T05:07:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzI3MjAxMg=="}], "type": "inlineReview"}, {"oid": "72f6f4fe5fd3b91a6a097fa1931ce9f7d18c7432", "url": "https://github.com/broadinstitute/gatk/commit/72f6f4fe5fd3b91a6a097fa1931ce9f7d18c7432", "message": "Review edits", "committedDate": "2020-05-25T02:54:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyMzU3Mw==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r429723573", "bodyText": "You just calculated that values when initializing previousEvidenceCount why not simply reuse it here:\nint nextIndex = previousEvidenceCount;", "author": "vruano", "createdAt": "2020-05-25T04:09:25Z", "path": "src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java", "diffHunk": "@@ -758,46 +759,28 @@ private void extendsLikelihoodArrays(final double initialLikelihood, final int s\n         }\n     }\n \n-    // Append the new evidence reference into the structure per-sample.\n-    private List<EVIDENCE> appendEvidence(final List<EVIDENCE> newSampleEvidence, final int sampleIndex) {\n+    // Append the new evidence reference into the structure per-sample, returning the count of evidence actually added (duplicates are not added)\n+    // NOTE: the evidence-to-index cache is updated in place and not invalidated via {@link #invalidateEvidenceToIndexCache(int)} because adding new evidence\n+    // to the cache, as opposed to removing evidence, is just a matter of appending entries\n+    private int appendEvidence(final List<EVIDENCE> newSampleEvidence, final int sampleIndex) {\n \n         final List<EVIDENCE> sampleEvidence = evidenceBySampleIndex.get(sampleIndex);\n         final Object2IntMap<EVIDENCE> sampleEvidenceIndex = evidenceIndexBySampleIndex(sampleIndex);\n+        final int previousEvidenceCount = sampleEvidence.size();\n \n-        // actually-added will have the list of evidence added at the end of this method.\n-        // this won't include those that were already in the table.\n-        // being optimistic we assume that there is no repeats in the input new evidence so we set it to\n-        // the input list but if we found something we then start a new list.\n-        List<EVIDENCE> actuallyAdded = newSampleEvidence;\n-\n-        int i, nextIndex = sampleEvidence.size();\n-        final int stop = newSampleEvidence.size();\n-        for (i = 0; i < stop; i++) {\n-            final EVIDENCE newEvidence = newSampleEvidence.get(i);\n-            final int previousValue = sampleEvidenceIndex.put(newEvidence, nextIndex);\n-            if (previousValue == MISSING_INDEX) {\n-                nextIndex++;\n-                sampleEvidence.add(newEvidence);\n-            } else {\n-                actuallyAdded = new ArrayList<>(newSampleEvidence.subList(0, i));\n-                i++; // skip the repeated element.\n-                break;\n-            }\n-        }\n-        // second for below only use if we encounter some evidence that is already in the table:\n-        for (; i < stop; i++) {\n-            final EVIDENCE newEvidence = newSampleEvidence.get(i);\n+        int nextIndex = sampleEvidence.size();", "originalCommit": "72f6f4fe5fd3b91a6a097fa1931ce9f7d18c7432", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE1Mjc2MQ==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r430152761", "bodyText": "done", "author": "davidbenjamin", "createdAt": "2020-05-26T04:44:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyMzU3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyMzg1OQ==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r429723859", "bodyText": "nextIndex contains the value you need here.\nperhaps it would be better to call this variable currentSize", "author": "vruano", "createdAt": "2020-05-25T04:11:29Z", "path": "src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java", "diffHunk": "@@ -758,46 +759,28 @@ private void extendsLikelihoodArrays(final double initialLikelihood, final int s\n         }\n     }\n \n-    // Append the new evidence reference into the structure per-sample.\n-    private List<EVIDENCE> appendEvidence(final List<EVIDENCE> newSampleEvidence, final int sampleIndex) {\n+    // Append the new evidence reference into the structure per-sample, returning the count of evidence actually added (duplicates are not added)\n+    // NOTE: the evidence-to-index cache is updated in place and not invalidated via {@link #invalidateEvidenceToIndexCache(int)} because adding new evidence\n+    // to the cache, as opposed to removing evidence, is just a matter of appending entries\n+    private int appendEvidence(final List<EVIDENCE> newSampleEvidence, final int sampleIndex) {\n \n         final List<EVIDENCE> sampleEvidence = evidenceBySampleIndex.get(sampleIndex);\n         final Object2IntMap<EVIDENCE> sampleEvidenceIndex = evidenceIndexBySampleIndex(sampleIndex);\n+        final int previousEvidenceCount = sampleEvidence.size();\n \n-        // actually-added will have the list of evidence added at the end of this method.\n-        // this won't include those that were already in the table.\n-        // being optimistic we assume that there is no repeats in the input new evidence so we set it to\n-        // the input list but if we found something we then start a new list.\n-        List<EVIDENCE> actuallyAdded = newSampleEvidence;\n-\n-        int i, nextIndex = sampleEvidence.size();\n-        final int stop = newSampleEvidence.size();\n-        for (i = 0; i < stop; i++) {\n-            final EVIDENCE newEvidence = newSampleEvidence.get(i);\n-            final int previousValue = sampleEvidenceIndex.put(newEvidence, nextIndex);\n-            if (previousValue == MISSING_INDEX) {\n-                nextIndex++;\n-                sampleEvidence.add(newEvidence);\n-            } else {\n-                actuallyAdded = new ArrayList<>(newSampleEvidence.subList(0, i));\n-                i++; // skip the repeated element.\n-                break;\n-            }\n-        }\n-        // second for below only use if we encounter some evidence that is already in the table:\n-        for (; i < stop; i++) {\n-            final EVIDENCE newEvidence = newSampleEvidence.get(i);\n+        int nextIndex = sampleEvidence.size();\n+        for (final EVIDENCE newEvidence : newSampleEvidence) {\n             final int previousValue = sampleEvidenceIndex.put(newEvidence, nextIndex);\n             if (previousValue == MISSING_INDEX) {\n                 nextIndex++;\n                 sampleEvidence.add(newEvidence);\n-                actuallyAdded.add(newEvidence);\n             } else {\n                 sampleEvidenceIndex.put(newEvidence, previousValue); // revert\n             }\n         }\n+\n         numberOfEvidences[sampleIndex] = sampleEvidence.size();", "originalCommit": "72f6f4fe5fd3b91a6a097fa1931ce9f7d18c7432", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE1NDAzNw==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r430154037", "bodyText": "I agree, but now that you mention it I think it's even better to drop nextIndex entirely and replace it with sampleEvidence.size().", "author": "davidbenjamin", "createdAt": "2020-05-26T04:50:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyMzg1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyMzk2NQ==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r429723965", "bodyText": "return nextIndex - previousEvidenceCount;", "author": "vruano", "createdAt": "2020-05-25T04:12:17Z", "path": "src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java", "diffHunk": "@@ -758,46 +759,28 @@ private void extendsLikelihoodArrays(final double initialLikelihood, final int s\n         }\n     }\n \n-    // Append the new evidence reference into the structure per-sample.\n-    private List<EVIDENCE> appendEvidence(final List<EVIDENCE> newSampleEvidence, final int sampleIndex) {\n+    // Append the new evidence reference into the structure per-sample, returning the count of evidence actually added (duplicates are not added)\n+    // NOTE: the evidence-to-index cache is updated in place and not invalidated via {@link #invalidateEvidenceToIndexCache(int)} because adding new evidence\n+    // to the cache, as opposed to removing evidence, is just a matter of appending entries\n+    private int appendEvidence(final List<EVIDENCE> newSampleEvidence, final int sampleIndex) {\n \n         final List<EVIDENCE> sampleEvidence = evidenceBySampleIndex.get(sampleIndex);\n         final Object2IntMap<EVIDENCE> sampleEvidenceIndex = evidenceIndexBySampleIndex(sampleIndex);\n+        final int previousEvidenceCount = sampleEvidence.size();\n \n-        // actually-added will have the list of evidence added at the end of this method.\n-        // this won't include those that were already in the table.\n-        // being optimistic we assume that there is no repeats in the input new evidence so we set it to\n-        // the input list but if we found something we then start a new list.\n-        List<EVIDENCE> actuallyAdded = newSampleEvidence;\n-\n-        int i, nextIndex = sampleEvidence.size();\n-        final int stop = newSampleEvidence.size();\n-        for (i = 0; i < stop; i++) {\n-            final EVIDENCE newEvidence = newSampleEvidence.get(i);\n-            final int previousValue = sampleEvidenceIndex.put(newEvidence, nextIndex);\n-            if (previousValue == MISSING_INDEX) {\n-                nextIndex++;\n-                sampleEvidence.add(newEvidence);\n-            } else {\n-                actuallyAdded = new ArrayList<>(newSampleEvidence.subList(0, i));\n-                i++; // skip the repeated element.\n-                break;\n-            }\n-        }\n-        // second for below only use if we encounter some evidence that is already in the table:\n-        for (; i < stop; i++) {\n-            final EVIDENCE newEvidence = newSampleEvidence.get(i);\n+        int nextIndex = sampleEvidence.size();\n+        for (final EVIDENCE newEvidence : newSampleEvidence) {\n             final int previousValue = sampleEvidenceIndex.put(newEvidence, nextIndex);\n             if (previousValue == MISSING_INDEX) {\n                 nextIndex++;\n                 sampleEvidence.add(newEvidence);\n-                actuallyAdded.add(newEvidence);\n             } else {\n                 sampleEvidenceIndex.put(newEvidence, previousValue); // revert\n             }\n         }\n+\n         numberOfEvidences[sampleIndex] = sampleEvidence.size();\n-        return actuallyAdded;\n+        return sampleEvidence.size() - previousEvidenceCount;", "originalCommit": "72f6f4fe5fd3b91a6a097fa1931ce9f7d18c7432", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE1NTAzNg==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r430155036", "bodyText": "True, but upon further thought I realized this method should be void because its return value is not really needed.", "author": "davidbenjamin", "createdAt": "2020-05-26T04:54:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyMzk2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyNDkwOQ==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r429724909", "bodyText": "This method is private do we really need to check this, can we simply assume the input is correct?", "author": "vruano", "createdAt": "2020-05-25T04:17:23Z", "path": "src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java", "diffHunk": "@@ -1129,60 +1112,50 @@ private void removeEvidence(final int sampleIndex, final Collection<EVIDENCE> ev\n         removeEvidenceByIndex(sampleIndex, indexesToRemove);\n     }\n \n+    // remove evidence and unset the {@code evidenceIndexBySampleIndex} cache for this sample\n     // assumes that evidencesToRemove is sorted and without duplicates.\n     private void removeEvidenceByIndex(final int sampleIndex, final int[] evidencesToRemove) {\n-        if (evidencesToRemove.length == 0) {\n+        final int numToRemove = evidencesToRemove.length;\n+        if (numToRemove == 0) {\n             return;\n-        } else {\n-            final Object2IntMap<EVIDENCE> evidenceIndex = evidenceIndexBySampleIndex(sampleIndex);\n-            final int oldEvidenceCount = numberOfEvidences[sampleIndex];\n-            final int newEvidenceCount = oldEvidenceCount - evidencesToRemove.length;\n-            if (newEvidenceCount < 0) {\n-                throw new IllegalStateException(\"attempt to remove non-existent evidence or repeated evidence\");\n-            } else if (newEvidenceCount == 0) { // taking in consideration the assumption we simply remove\n-                // all evidence.\n-                evidenceIndex.clear();\n-                numberOfEvidences[sampleIndex] = 0;\n+        }\n+        final int oldEvidenceCount = numberOfEvidences[sampleIndex];\n+        final int newEvidenceCount = oldEvidenceCount - evidencesToRemove.length;\n+        Utils.validate(newEvidenceCount >= 0, \"attempted to remove non-existent evidence or repeated evidence\");", "originalCommit": "72f6f4fe5fd3b91a6a097fa1931ce9f7d18c7432", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE1NTM5MA==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r430155390", "bodyText": "Works for me.  Done.", "author": "davidbenjamin", "createdAt": "2020-05-26T04:56:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyNDkwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyNjU0Mw==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r429726543", "bodyText": "You can be a bit more efficient by putting the next to skip \"on-deck\":\nfor (int n = 0, numRemoved = 0, nextToRemove = evidencesToRemove[0]; n < oldEvidenceCount; n++) {\n     if (n == nextToRemove) {\n         nextToRemove = ++numRemoved < evidencesToRemove.length ? evidencesToRemove[numRemoved] : -1;\n     } else {\n         newEvidence.add(oldEvidence.get(n));\n     }\n}", "author": "vruano", "createdAt": "2020-05-25T04:27:38Z", "path": "src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java", "diffHunk": "@@ -1129,60 +1112,50 @@ private void removeEvidence(final int sampleIndex, final Collection<EVIDENCE> ev\n         removeEvidenceByIndex(sampleIndex, indexesToRemove);\n     }\n \n+    // remove evidence and unset the {@code evidenceIndexBySampleIndex} cache for this sample\n     // assumes that evidencesToRemove is sorted and without duplicates.\n     private void removeEvidenceByIndex(final int sampleIndex, final int[] evidencesToRemove) {\n-        if (evidencesToRemove.length == 0) {\n+        final int numToRemove = evidencesToRemove.length;\n+        if (numToRemove == 0) {\n             return;\n-        } else {\n-            final Object2IntMap<EVIDENCE> evidenceIndex = evidenceIndexBySampleIndex(sampleIndex);\n-            final int oldEvidenceCount = numberOfEvidences[sampleIndex];\n-            final int newEvidenceCount = oldEvidenceCount - evidencesToRemove.length;\n-            if (newEvidenceCount < 0) {\n-                throw new IllegalStateException(\"attempt to remove non-existent evidence or repeated evidence\");\n-            } else if (newEvidenceCount == 0) { // taking in consideration the assumption we simply remove\n-                // all evidence.\n-                evidenceIndex.clear();\n-                numberOfEvidences[sampleIndex] = 0;\n+        }\n+        final int oldEvidenceCount = numberOfEvidences[sampleIndex];\n+        final int newEvidenceCount = oldEvidenceCount - evidencesToRemove.length;\n+        Utils.validate(newEvidenceCount >= 0, \"attempted to remove non-existent evidence or repeated evidence\");\n+\n+        // update the list of evidence and evidence count\n+        final List<EVIDENCE> oldEvidence = evidenceBySampleIndex.get(sampleIndex);\n+        final List<EVIDENCE> newEvidence = new ArrayList<>(newEvidenceCount);\n+        for (int n = 0, numRemoved = 0; n < oldEvidenceCount; n++) {", "originalCommit": "72f6f4fe5fd3b91a6a097fa1931ce9f7d18c7432", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE1OTk0OA==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r430159948", "bodyText": "That's pretty neat but I think I'll keep the loop simpler as-is.", "author": "davidbenjamin", "createdAt": "2020-05-26T05:15:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyNjU0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyNjgyNQ==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r429726825", "bodyText": "Again a private does not need to perform this checks... This is something that must be cached by unit tests, perhaps you should increase testing coverage if you are worried that this is a real issue.", "author": "vruano", "createdAt": "2020-05-25T04:29:36Z", "path": "src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java", "diffHunk": "@@ -1129,60 +1112,50 @@ private void removeEvidence(final int sampleIndex, final Collection<EVIDENCE> ev\n         removeEvidenceByIndex(sampleIndex, indexesToRemove);\n     }\n \n+    // remove evidence and unset the {@code evidenceIndexBySampleIndex} cache for this sample\n     // assumes that evidencesToRemove is sorted and without duplicates.\n     private void removeEvidenceByIndex(final int sampleIndex, final int[] evidencesToRemove) {\n-        if (evidencesToRemove.length == 0) {\n+        final int numToRemove = evidencesToRemove.length;\n+        if (numToRemove == 0) {\n             return;\n-        } else {\n-            final Object2IntMap<EVIDENCE> evidenceIndex = evidenceIndexBySampleIndex(sampleIndex);\n-            final int oldEvidenceCount = numberOfEvidences[sampleIndex];\n-            final int newEvidenceCount = oldEvidenceCount - evidencesToRemove.length;\n-            if (newEvidenceCount < 0) {\n-                throw new IllegalStateException(\"attempt to remove non-existent evidence or repeated evidence\");\n-            } else if (newEvidenceCount == 0) { // taking in consideration the assumption we simply remove\n-                // all evidence.\n-                evidenceIndex.clear();\n-                numberOfEvidences[sampleIndex] = 0;\n+        }\n+        final int oldEvidenceCount = numberOfEvidences[sampleIndex];\n+        final int newEvidenceCount = oldEvidenceCount - evidencesToRemove.length;\n+        Utils.validate(newEvidenceCount >= 0, \"attempted to remove non-existent evidence or repeated evidence\");\n+\n+        // update the list of evidence and evidence count\n+        final List<EVIDENCE> oldEvidence = evidenceBySampleIndex.get(sampleIndex);\n+        final List<EVIDENCE> newEvidence = new ArrayList<>(newEvidenceCount);\n+        for (int n = 0, numRemoved = 0; n < oldEvidenceCount; n++) {\n+            if (numRemoved < numToRemove && n == evidencesToRemove[numRemoved]) {\n+                numRemoved++;\n             } else {\n-                final List<EVIDENCE> evidences = evidenceBySampleIndex.get(sampleIndex);\n-                final double[][] values = valuesBySampleIndex[sampleIndex];\n-\n-                int nextIndexToRemove = evidencesToRemove[0];\n-                if (nextIndexToRemove < 0) {\n-                    throw new IllegalStateException(\"invalid input index array as it contains negatives\");\n-                }\n-                evidenceIndex.remove(evidences.get(nextIndexToRemove));\n-                for (int etrIndex = 1, to = nextIndexToRemove, from = to + 1; to < newEvidenceCount; etrIndex++, from++) {\n-                    if (etrIndex < evidencesToRemove.length) {\n-                        nextIndexToRemove = evidencesToRemove[etrIndex];\n-                        if (nextIndexToRemove < from) {\n-                            throw new IllegalStateException(\"invalid input index array contains indexes out of order\");\n-                        } else if (nextIndexToRemove >= oldEvidenceCount) {\n-                            throw new IllegalStateException(\"invalid input index array contains indexes out of order\");\n-                        }\n-                        evidenceIndex.remove(evidences.get(nextIndexToRemove));\n-                    } else {\n-                        nextIndexToRemove = oldEvidenceCount;\n-                    }\n-                    for (; from < nextIndexToRemove; from++) {\n-                        final EVIDENCE evidence = evidences.get(from);\n-                        evidences.set(to, evidence);\n-                        evidenceIndex.put(evidence, to++);\n-                    }\n-                }\n-                Utils.truncate(evidences, newEvidenceCount);\n-                // now we do the likelihood values, we save ourselves all the checks:\n-                for (final double[] alleleValues : values) {\n-                    for (int etrIndex = 1, to = evidencesToRemove[0], from = to + 1; to < newEvidenceCount; from++, etrIndex++) {\n-                        nextIndexToRemove = etrIndex < evidencesToRemove.length ? evidencesToRemove[etrIndex] : oldEvidenceCount;\n-                        for (; from < nextIndexToRemove; from++) {\n-                            alleleValues[to++] = alleleValues[from];\n-                        }\n-                    }\n+                newEvidence.add(oldEvidence.get(n));\n+            }\n+        }\n+        Utils.validate(newEvidence.size() == newEvidenceCount, \"Indices to remove contained duplicates, was not ordered, or contained out-of-range indices.\");", "originalCommit": "72f6f4fe5fd3b91a6a097fa1931ce9f7d18c7432", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE1NTg1NQ==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r430155855", "bodyText": "I wasn't worried, just preserving a check from before the PR.  Deleting validating code from private methods always makes me happy.  Done.", "author": "davidbenjamin", "createdAt": "2020-05-26T04:58:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyNjgyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyNzg2OQ==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r429727869", "bodyText": "why we have two for loops that seem to do pretty much the same. Can we simply move this line of code to the for loop above?... I mean:\nfor (...) {\n   if (n == nextToRemove) {\n     ...\n   } else {\n     ...\n     for (final double[] alleleValues : valuesBySampleIndex[sampleIndex]) {\n          alleleValues[n - numRemoved] = alleleValues[n];\n     }\n   }\n\nOtherwise if you want to keep it this way, you could start the loop on the first removed-index:\n   for (int n = evidencesToRemove[0] + 1, ...; n < oldEvidenceCount; n++) {\n       ...\n   }", "author": "vruano", "createdAt": "2020-05-25T04:36:26Z", "path": "src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java", "diffHunk": "@@ -1129,60 +1112,50 @@ private void removeEvidence(final int sampleIndex, final Collection<EVIDENCE> ev\n         removeEvidenceByIndex(sampleIndex, indexesToRemove);\n     }\n \n+    // remove evidence and unset the {@code evidenceIndexBySampleIndex} cache for this sample\n     // assumes that evidencesToRemove is sorted and without duplicates.\n     private void removeEvidenceByIndex(final int sampleIndex, final int[] evidencesToRemove) {\n-        if (evidencesToRemove.length == 0) {\n+        final int numToRemove = evidencesToRemove.length;\n+        if (numToRemove == 0) {\n             return;\n-        } else {\n-            final Object2IntMap<EVIDENCE> evidenceIndex = evidenceIndexBySampleIndex(sampleIndex);\n-            final int oldEvidenceCount = numberOfEvidences[sampleIndex];\n-            final int newEvidenceCount = oldEvidenceCount - evidencesToRemove.length;\n-            if (newEvidenceCount < 0) {\n-                throw new IllegalStateException(\"attempt to remove non-existent evidence or repeated evidence\");\n-            } else if (newEvidenceCount == 0) { // taking in consideration the assumption we simply remove\n-                // all evidence.\n-                evidenceIndex.clear();\n-                numberOfEvidences[sampleIndex] = 0;\n+        }\n+        final int oldEvidenceCount = numberOfEvidences[sampleIndex];\n+        final int newEvidenceCount = oldEvidenceCount - evidencesToRemove.length;\n+        Utils.validate(newEvidenceCount >= 0, \"attempted to remove non-existent evidence or repeated evidence\");\n+\n+        // update the list of evidence and evidence count\n+        final List<EVIDENCE> oldEvidence = evidenceBySampleIndex.get(sampleIndex);\n+        final List<EVIDENCE> newEvidence = new ArrayList<>(newEvidenceCount);\n+        for (int n = 0, numRemoved = 0; n < oldEvidenceCount; n++) {\n+            if (numRemoved < numToRemove && n == evidencesToRemove[numRemoved]) {\n+                numRemoved++;\n             } else {\n-                final List<EVIDENCE> evidences = evidenceBySampleIndex.get(sampleIndex);\n-                final double[][] values = valuesBySampleIndex[sampleIndex];\n-\n-                int nextIndexToRemove = evidencesToRemove[0];\n-                if (nextIndexToRemove < 0) {\n-                    throw new IllegalStateException(\"invalid input index array as it contains negatives\");\n-                }\n-                evidenceIndex.remove(evidences.get(nextIndexToRemove));\n-                for (int etrIndex = 1, to = nextIndexToRemove, from = to + 1; to < newEvidenceCount; etrIndex++, from++) {\n-                    if (etrIndex < evidencesToRemove.length) {\n-                        nextIndexToRemove = evidencesToRemove[etrIndex];\n-                        if (nextIndexToRemove < from) {\n-                            throw new IllegalStateException(\"invalid input index array contains indexes out of order\");\n-                        } else if (nextIndexToRemove >= oldEvidenceCount) {\n-                            throw new IllegalStateException(\"invalid input index array contains indexes out of order\");\n-                        }\n-                        evidenceIndex.remove(evidences.get(nextIndexToRemove));\n-                    } else {\n-                        nextIndexToRemove = oldEvidenceCount;\n-                    }\n-                    for (; from < nextIndexToRemove; from++) {\n-                        final EVIDENCE evidence = evidences.get(from);\n-                        evidences.set(to, evidence);\n-                        evidenceIndex.put(evidence, to++);\n-                    }\n-                }\n-                Utils.truncate(evidences, newEvidenceCount);\n-                // now we do the likelihood values, we save ourselves all the checks:\n-                for (final double[] alleleValues : values) {\n-                    for (int etrIndex = 1, to = evidencesToRemove[0], from = to + 1; to < newEvidenceCount; from++, etrIndex++) {\n-                        nextIndexToRemove = etrIndex < evidencesToRemove.length ? evidencesToRemove[etrIndex] : oldEvidenceCount;\n-                        for (; from < nextIndexToRemove; from++) {\n-                            alleleValues[to++] = alleleValues[from];\n-                        }\n-                    }\n+                newEvidence.add(oldEvidence.get(n));\n+            }\n+        }\n+        Utils.validate(newEvidence.size() == newEvidenceCount, \"Indices to remove contained duplicates, was not ordered, or contained out-of-range indices.\");\n+        evidenceBySampleIndex.set(sampleIndex, newEvidence);\n+        numberOfEvidences[sampleIndex] = newEvidenceCount;\n+\n+        invalidateEvidenceToIndexCache(sampleIndex);\n+\n+        // update the likelihoods arrays in place\n+        for (final double[] alleleValues : valuesBySampleIndex[sampleIndex]) {\n+            for (int n = 0, numRemoved = 0; n < oldEvidenceCount; n++) {\n+                if (numRemoved < numToRemove && n == evidencesToRemove[numRemoved]) {\n+                    numRemoved++;\n+                } else {\n+                    alleleValues[n - numRemoved] = alleleValues[n];", "originalCommit": "72f6f4fe5fd3b91a6a097fa1931ce9f7d18c7432", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE2MjAyMQ==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r430162021", "bodyText": "Your way is better.  Done.", "author": "davidbenjamin", "createdAt": "2020-05-26T05:23:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyNzg2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyODU2MA==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r429728560", "bodyText": "You can avoid the double get if the index map is not null, but is just a direct get acces to an array-list so perhaps not worth the trouble.", "author": "vruano", "createdAt": "2020-05-25T04:40:55Z", "path": "src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java", "diffHunk": "@@ -1216,18 +1189,26 @@ public void filterPoorlyModeledEvidence(final ToDoubleFunction<EVIDENCE> log10Mi\n \n     private Object2IntMap<EVIDENCE> evidenceIndexBySampleIndex(final int sampleIndex) {\n         if (evidenceIndexBySampleIndex.get(sampleIndex) == null) {\n-            final List<EVIDENCE> sampleEvidence = evidenceBySampleIndex.get(sampleIndex);\n-            final int sampleEvidenceCount = sampleEvidence.size();\n-            final Object2IntMap<EVIDENCE> index = new Object2IntOpenHashMap<>(sampleEvidenceCount);\n-            index.defaultReturnValue(MISSING_INDEX);\n-            evidenceIndexBySampleIndex.set(sampleIndex, index);\n-            for (int r = 0; r < sampleEvidenceCount; r++) {\n-                index.put(sampleEvidence.get(r), r);\n-            }\n-            return index;\n-        } else {\n-            return evidenceIndexBySampleIndex.get(sampleIndex);\n+            fillEvidenceToIndexCache(sampleIndex);", "originalCommit": "72f6f4fe5fd3b91a6a097fa1931ce9f7d18c7432", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE2Mjc5Nw==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r430162797", "bodyText": "done", "author": "davidbenjamin", "createdAt": "2020-05-26T05:26:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyODU2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyODkwMg==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r429728902", "bodyText": "We are not multithread safe in general but as a matter of principle I think you should only set the list once the map is filled and not before.", "author": "vruano", "createdAt": "2020-05-25T04:43:12Z", "path": "src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java", "diffHunk": "@@ -1216,18 +1189,26 @@ public void filterPoorlyModeledEvidence(final ToDoubleFunction<EVIDENCE> log10Mi\n \n     private Object2IntMap<EVIDENCE> evidenceIndexBySampleIndex(final int sampleIndex) {\n         if (evidenceIndexBySampleIndex.get(sampleIndex) == null) {\n-            final List<EVIDENCE> sampleEvidence = evidenceBySampleIndex.get(sampleIndex);\n-            final int sampleEvidenceCount = sampleEvidence.size();\n-            final Object2IntMap<EVIDENCE> index = new Object2IntOpenHashMap<>(sampleEvidenceCount);\n-            index.defaultReturnValue(MISSING_INDEX);\n-            evidenceIndexBySampleIndex.set(sampleIndex, index);\n-            for (int r = 0; r < sampleEvidenceCount; r++) {\n-                index.put(sampleEvidence.get(r), r);\n-            }\n-            return index;\n-        } else {\n-            return evidenceIndexBySampleIndex.get(sampleIndex);\n+            fillEvidenceToIndexCache(sampleIndex);\n         }\n+        return evidenceIndexBySampleIndex.get(sampleIndex);\n+    }\n+\n+    @VisibleForTesting\n+    void fillEvidenceToIndexCache(int sampleIndex) {\n+        final List<EVIDENCE> sampleEvidence = evidenceBySampleIndex.get(sampleIndex);\n+        final int sampleEvidenceCount = sampleEvidence.size();\n+        final Object2IntMap<EVIDENCE> index = new Object2IntOpenHashMap<>(sampleEvidenceCount);\n+        index.defaultReturnValue(MISSING_INDEX);\n+        evidenceIndexBySampleIndex.set(sampleIndex, index);", "originalCommit": "72f6f4fe5fd3b91a6a097fa1931ce9f7d18c7432", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE1NzQxOQ==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r430157419", "bodyText": "Can't argue with principle.  Done.", "author": "davidbenjamin", "createdAt": "2020-05-26T05:05:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyODkwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyOTI4MQ==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r429729281", "bodyText": "what about using a foreach:\nint nextIdx = 0;\nfor( final EVIDENCE evi : sampleEvidence) {\n    index.put(evi, nextIdx++);\n}", "author": "vruano", "createdAt": "2020-05-25T04:45:39Z", "path": "src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java", "diffHunk": "@@ -1216,18 +1189,26 @@ public void filterPoorlyModeledEvidence(final ToDoubleFunction<EVIDENCE> log10Mi\n \n     private Object2IntMap<EVIDENCE> evidenceIndexBySampleIndex(final int sampleIndex) {\n         if (evidenceIndexBySampleIndex.get(sampleIndex) == null) {\n-            final List<EVIDENCE> sampleEvidence = evidenceBySampleIndex.get(sampleIndex);\n-            final int sampleEvidenceCount = sampleEvidence.size();\n-            final Object2IntMap<EVIDENCE> index = new Object2IntOpenHashMap<>(sampleEvidenceCount);\n-            index.defaultReturnValue(MISSING_INDEX);\n-            evidenceIndexBySampleIndex.set(sampleIndex, index);\n-            for (int r = 0; r < sampleEvidenceCount; r++) {\n-                index.put(sampleEvidence.get(r), r);\n-            }\n-            return index;\n-        } else {\n-            return evidenceIndexBySampleIndex.get(sampleIndex);\n+            fillEvidenceToIndexCache(sampleIndex);\n         }\n+        return evidenceIndexBySampleIndex.get(sampleIndex);\n+    }\n+\n+    @VisibleForTesting\n+    void fillEvidenceToIndexCache(int sampleIndex) {\n+        final List<EVIDENCE> sampleEvidence = evidenceBySampleIndex.get(sampleIndex);\n+        final int sampleEvidenceCount = sampleEvidence.size();\n+        final Object2IntMap<EVIDENCE> index = new Object2IntOpenHashMap<>(sampleEvidenceCount);\n+        index.defaultReturnValue(MISSING_INDEX);\n+        evidenceIndexBySampleIndex.set(sampleIndex, index);\n+        for (int r = 0; r < sampleEvidenceCount; r++) {", "originalCommit": "72f6f4fe5fd3b91a6a097fa1931ce9f7d18c7432", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE1NjY3Mw==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r430156673", "bodyText": "I like the foreach but my distaste for introducing a variable outside the scope of the for loop is stronger.", "author": "davidbenjamin", "createdAt": "2020-05-26T05:01:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyOTI4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTcyOTYzOQ==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r429729639", "bodyText": "I like more ...IsPresent rather than ...isFilled, but my mother's tongle is not English.", "author": "vruano", "createdAt": "2020-05-25T04:47:48Z", "path": "src/main/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoods.java", "diffHunk": "@@ -1216,18 +1189,26 @@ public void filterPoorlyModeledEvidence(final ToDoubleFunction<EVIDENCE> log10Mi\n \n     private Object2IntMap<EVIDENCE> evidenceIndexBySampleIndex(final int sampleIndex) {\n         if (evidenceIndexBySampleIndex.get(sampleIndex) == null) {\n-            final List<EVIDENCE> sampleEvidence = evidenceBySampleIndex.get(sampleIndex);\n-            final int sampleEvidenceCount = sampleEvidence.size();\n-            final Object2IntMap<EVIDENCE> index = new Object2IntOpenHashMap<>(sampleEvidenceCount);\n-            index.defaultReturnValue(MISSING_INDEX);\n-            evidenceIndexBySampleIndex.set(sampleIndex, index);\n-            for (int r = 0; r < sampleEvidenceCount; r++) {\n-                index.put(sampleEvidence.get(r), r);\n-            }\n-            return index;\n-        } else {\n-            return evidenceIndexBySampleIndex.get(sampleIndex);\n+            fillEvidenceToIndexCache(sampleIndex);\n         }\n+        return evidenceIndexBySampleIndex.get(sampleIndex);\n+    }\n+\n+    @VisibleForTesting\n+    void fillEvidenceToIndexCache(int sampleIndex) {\n+        final List<EVIDENCE> sampleEvidence = evidenceBySampleIndex.get(sampleIndex);\n+        final int sampleEvidenceCount = sampleEvidence.size();\n+        final Object2IntMap<EVIDENCE> index = new Object2IntOpenHashMap<>(sampleEvidenceCount);\n+        index.defaultReturnValue(MISSING_INDEX);\n+        evidenceIndexBySampleIndex.set(sampleIndex, index);\n+        for (int r = 0; r < sampleEvidenceCount; r++) {\n+            index.put(sampleEvidence.get(r), r);\n+        }\n+    }\n+\n+    @VisibleForTesting\n+    boolean evidenceToIndexCacheIsFilled(final int sampleIndex) {", "originalCommit": "72f6f4fe5fd3b91a6a097fa1931ce9f7d18c7432", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTczMDU3Nw==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r429730577", "bodyText": "IMO this cache is a implementation business and the using code is not supposed to know or care about it. I don't think there is the need to check the inner state of the likelihood collection this way which results in exposing its workings for the sake of this testing.\nInstead you could focus that the index are consistent after several mutating operations.", "author": "vruano", "createdAt": "2020-05-25T04:54:01Z", "path": "src/test/java/org/broadinstitute/hellbender/utils/genotyper/AlleleLikelihoodsUnitTest.java", "diffHunk": "@@ -174,11 +174,19 @@ public void testFilterPoorlyModeledReads(final String[] samples, final Allele[]\n         final AlleleLikelihoods<GATKRead, Allele> original = makeGoodAndBadLikelihoods(samples, alleles, reads);\n \n         final AlleleLikelihoods<GATKRead, Allele> result = makeGoodAndBadLikelihoods(samples, alleles, reads);\n+\n+        // fill the evidence-to-index cache now to check that it is invalidated below", "originalCommit": "72f6f4fe5fd3b91a6a097fa1931ce9f7d18c7432", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE3MTEyMw==", "url": "https://github.com/broadinstitute/gatk/pull/6593#discussion_r430171123", "bodyText": "done", "author": "davidbenjamin", "createdAt": "2020-05-26T05:56:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTczMDU3Nw=="}], "type": "inlineReview"}, {"oid": "9494c4ea231f5f8feef18679bcc6de2eba12145d", "url": "https://github.com/broadinstitute/gatk/commit/9494c4ea231f5f8feef18679bcc6de2eba12145d", "message": "Valentin edits", "committedDate": "2020-05-26T05:56:39Z", "type": "commit"}]}