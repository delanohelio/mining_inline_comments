{"pr_number": 741, "pr_title": "Fix ConcurrentModification exception in Workflow Garbage Collection", "pr_createdAt": "2020-02-10T21:47:09Z", "pr_url": "https://github.com/apache/helix/pull/741", "timeline": [{"oid": "0848259a68fc77dbd23b88442e8daee1819dc522", "url": "https://github.com/apache/helix/commit/0848259a68fc77dbd23b88442e8daee1819dc522", "message": "Fix the possibile ConcurrentMod exception in Workflow Garbage Collection\n\nIn workflow Garbage collection, there is possbility that we see ConcurrentMod exception\nwhile looping through the context. This commit fixes this issue.", "committedDate": "2020-02-10T22:04:57Z", "type": "commit"}, {"oid": "0848259a68fc77dbd23b88442e8daee1819dc522", "url": "https://github.com/apache/helix/commit/0848259a68fc77dbd23b88442e8daee1819dc522", "message": "Fix the possibile ConcurrentMod exception in Workflow Garbage Collection\n\nIn workflow Garbage collection, there is possbility that we see ConcurrentMod exception\nwhile looping through the context. This commit fixes this issue.", "committedDate": "2020-02-10T22:04:57Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM1MDY1Nw==", "url": "https://github.com/apache/helix/pull/741#discussion_r377350657", "bodyText": "Can you merge these two if's?", "author": "narendly", "createdAt": "2020-02-10T22:18:40Z", "path": "helix-core/src/main/java/org/apache/helix/task/TaskUtil.java", "diffHunk": "@@ -1043,23 +1043,35 @@ public static void purgeExpiredJobs(String workflow, WorkflowConfig workflowConf\n    * @param dataProvider\n    * @param manager\n    */\n-  public static void workflowGarbageCollection(WorkflowControllerDataProvider dataProvider,\n+  public static void workflowGarbageCollection(final WorkflowControllerDataProvider dataProvider,\n       final HelixManager manager) {\n     // Garbage collections for conditions where workflow context exists but config is missing.\n-    Map<String, ZNRecord> contexts = dataProvider.getContexts();\n-    HelixDataAccessor accessor = manager.getHelixDataAccessor();\n-    HelixPropertyStore<ZNRecord> propertyStore = manager.getHelixPropertyStore();\n \n+    // toBeDeletedWorkflows is a set that contains the name of the workflows that their contexts\n+    // should be deleted.\n     Set<String> toBeDeletedWorkflows = new HashSet<>();\n-    for (Map.Entry<String, ZNRecord> entry : contexts.entrySet()) {\n-      if (entry.getValue() != null\n-          && entry.getValue().getId().equals(TaskUtil.WORKFLOW_CONTEXT_KW)) {\n-        if (dataProvider.getWorkflowConfig(entry.getKey()) == null) {\n-          toBeDeletedWorkflows.add(entry.getKey());\n+    try {\n+      Set<String> existingWorkflowContexts = new HashSet<>(dataProvider.getContexts().keySet());\n+      for (String entry : existingWorkflowContexts) {\n+        if (entry != null) {\n+          WorkflowConfig cfg = dataProvider.getWorkflowConfig(entry);\n+          WorkflowContext ctx = dataProvider.getWorkflowContext(entry);\n+          if (ctx != null && ctx.getId().equals(TaskUtil.WORKFLOW_CONTEXT_KW)) {\n+            if (cfg == null) {", "originalCommit": "0848259a68fc77dbd23b88442e8daee1819dc522", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQxODE5NA==", "url": "https://github.com/apache/helix/pull/741#discussion_r377418194", "bodyText": "Done.", "author": "alirezazamani", "createdAt": "2020-02-11T02:04:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM1MDY1Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM1MTE0MQ==", "url": "https://github.com/apache/helix/pull/741#discussion_r377351141", "bodyText": "Use {}\nYou can input the exception as the second parameter. You don't have to do e.getMessage().", "author": "narendly", "createdAt": "2020-02-10T22:19:41Z", "path": "helix-core/src/main/java/org/apache/helix/task/TaskUtil.java", "diffHunk": "@@ -1043,23 +1043,35 @@ public static void purgeExpiredJobs(String workflow, WorkflowConfig workflowConf\n    * @param dataProvider\n    * @param manager\n    */\n-  public static void workflowGarbageCollection(WorkflowControllerDataProvider dataProvider,\n+  public static void workflowGarbageCollection(final WorkflowControllerDataProvider dataProvider,\n       final HelixManager manager) {\n     // Garbage collections for conditions where workflow context exists but config is missing.\n-    Map<String, ZNRecord> contexts = dataProvider.getContexts();\n-    HelixDataAccessor accessor = manager.getHelixDataAccessor();\n-    HelixPropertyStore<ZNRecord> propertyStore = manager.getHelixPropertyStore();\n \n+    // toBeDeletedWorkflows is a set that contains the name of the workflows that their contexts\n+    // should be deleted.\n     Set<String> toBeDeletedWorkflows = new HashSet<>();\n-    for (Map.Entry<String, ZNRecord> entry : contexts.entrySet()) {\n-      if (entry.getValue() != null\n-          && entry.getValue().getId().equals(TaskUtil.WORKFLOW_CONTEXT_KW)) {\n-        if (dataProvider.getWorkflowConfig(entry.getKey()) == null) {\n-          toBeDeletedWorkflows.add(entry.getKey());\n+    try {\n+      Set<String> existingWorkflowContexts = new HashSet<>(dataProvider.getContexts().keySet());\n+      for (String entry : existingWorkflowContexts) {\n+        if (entry != null) {\n+          WorkflowConfig cfg = dataProvider.getWorkflowConfig(entry);\n+          WorkflowContext ctx = dataProvider.getWorkflowContext(entry);\n+          if (ctx != null && ctx.getId().equals(TaskUtil.WORKFLOW_CONTEXT_KW)) {\n+            if (cfg == null) {\n+              toBeDeletedWorkflows.add(entry);\n+            }\n+          }\n         }\n       }\n+    } catch (Exception e) {\n+      LOG.warn(String.format(\n+          \"Exception occurred while creating a list of all existing contexts with missing config!! Reason: %s\"),", "originalCommit": "0848259a68fc77dbd23b88442e8daee1819dc522", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQxODI2Mw==", "url": "https://github.com/apache/helix/pull/741#discussion_r377418263", "bodyText": "Done.", "author": "alirezazamani", "createdAt": "2020-02-11T02:04:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM1MTE0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM1MTgzNw==", "url": "https://github.com/apache/helix/pull/741#discussion_r377351837", "bodyText": "Use one \"!'.", "author": "narendly", "createdAt": "2020-02-10T22:21:13Z", "path": "helix-core/src/main/java/org/apache/helix/task/TaskUtil.java", "diffHunk": "@@ -1043,23 +1043,35 @@ public static void purgeExpiredJobs(String workflow, WorkflowConfig workflowConf\n    * @param dataProvider\n    * @param manager\n    */\n-  public static void workflowGarbageCollection(WorkflowControllerDataProvider dataProvider,\n+  public static void workflowGarbageCollection(final WorkflowControllerDataProvider dataProvider,\n       final HelixManager manager) {\n     // Garbage collections for conditions where workflow context exists but config is missing.\n-    Map<String, ZNRecord> contexts = dataProvider.getContexts();\n-    HelixDataAccessor accessor = manager.getHelixDataAccessor();\n-    HelixPropertyStore<ZNRecord> propertyStore = manager.getHelixPropertyStore();\n \n+    // toBeDeletedWorkflows is a set that contains the name of the workflows that their contexts\n+    // should be deleted.\n     Set<String> toBeDeletedWorkflows = new HashSet<>();\n-    for (Map.Entry<String, ZNRecord> entry : contexts.entrySet()) {\n-      if (entry.getValue() != null\n-          && entry.getValue().getId().equals(TaskUtil.WORKFLOW_CONTEXT_KW)) {\n-        if (dataProvider.getWorkflowConfig(entry.getKey()) == null) {\n-          toBeDeletedWorkflows.add(entry.getKey());\n+    try {\n+      Set<String> existingWorkflowContexts = new HashSet<>(dataProvider.getContexts().keySet());\n+      for (String entry : existingWorkflowContexts) {\n+        if (entry != null) {\n+          WorkflowConfig cfg = dataProvider.getWorkflowConfig(entry);\n+          WorkflowContext ctx = dataProvider.getWorkflowContext(entry);\n+          if (ctx != null && ctx.getId().equals(TaskUtil.WORKFLOW_CONTEXT_KW)) {\n+            if (cfg == null) {\n+              toBeDeletedWorkflows.add(entry);\n+            }\n+          }\n         }\n       }\n+    } catch (Exception e) {\n+      LOG.warn(String.format(\n+          \"Exception occurred while creating a list of all existing contexts with missing config!! Reason: %s\"),", "originalCommit": "0848259a68fc77dbd23b88442e8daee1819dc522", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQxODIzNw==", "url": "https://github.com/apache/helix/pull/741#discussion_r377418237", "bodyText": "Done.", "author": "alirezazamani", "createdAt": "2020-02-11T02:04:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM1MTgzNw=="}], "type": "inlineReview"}, {"oid": "9694b81f701ac2ab8b2b43b8a6325fcf636697ea", "url": "https://github.com/apache/helix/commit/9694b81f701ac2ab8b2b43b8a6325fcf636697ea", "message": "fix comments", "committedDate": "2020-02-11T02:03:25Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQyMzU3NA==", "url": "https://github.com/apache/helix/pull/741#discussion_r377423574", "bodyText": "Do you clearly understand why and where ConcurrentModificationException is happening? This looks like we're just masking it with a try-catch. I don't think that's a fix. Could we identify why and where clearly first and could you please update the description with your findings? Then this try-catch shouldn't be necessary.", "author": "narendly", "createdAt": "2020-02-11T02:33:02Z", "path": "helix-core/src/main/java/org/apache/helix/task/TaskUtil.java", "diffHunk": "@@ -1043,23 +1043,33 @@ public static void purgeExpiredJobs(String workflow, WorkflowConfig workflowConf\n    * @param dataProvider\n    * @param manager\n    */\n-  public static void workflowGarbageCollection(WorkflowControllerDataProvider dataProvider,\n+  public static void workflowGarbageCollection(final WorkflowControllerDataProvider dataProvider,\n       final HelixManager manager) {\n     // Garbage collections for conditions where workflow context exists but config is missing.\n-    Map<String, ZNRecord> contexts = dataProvider.getContexts();\n-    HelixDataAccessor accessor = manager.getHelixDataAccessor();\n-    HelixPropertyStore<ZNRecord> propertyStore = manager.getHelixPropertyStore();\n \n+    // toBeDeletedWorkflows is a set that contains the name of the workflows that their contexts\n+    // should be deleted.\n     Set<String> toBeDeletedWorkflows = new HashSet<>();\n-    for (Map.Entry<String, ZNRecord> entry : contexts.entrySet()) {\n-      if (entry.getValue() != null\n-          && entry.getValue().getId().equals(TaskUtil.WORKFLOW_CONTEXT_KW)) {\n-        if (dataProvider.getWorkflowConfig(entry.getKey()) == null) {\n-          toBeDeletedWorkflows.add(entry.getKey());\n+    try {\n+      Set<String> existingWorkflowContexts = new HashSet<>(dataProvider.getContexts().keySet());\n+      for (String entry : existingWorkflowContexts) {\n+        if (entry != null) {\n+          WorkflowConfig cfg = dataProvider.getWorkflowConfig(entry);\n+          WorkflowContext ctx = dataProvider.getWorkflowContext(entry);\n+          if (ctx != null && ctx.getId().equals(TaskUtil.WORKFLOW_CONTEXT_KW) && cfg == null) {\n+            toBeDeletedWorkflows.add(entry);\n+          }\n         }\n       }\n+    } catch (Exception e) {\n+      LOG.warn(\n+          \"Exception occurred while creating a list of all existing contexts with missing config!\",\n+          e);\n     }", "originalCommit": "9694b81f701ac2ab8b2b43b8a6325fcf636697ea", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQzMzAyNg==", "url": "https://github.com/apache/helix/pull/741#discussion_r377433026", "bodyText": "Yes. I tried several scenarios and for each scenario I used Jiajun's scripts which runs the test for 50 time. The most effective solution is the one that I proposed in this PR. Please have a look at this line:\n\nSet existingWorkflowContexts = new HashSet<>(dataProvider.getContexts().keySet());\n\nIn some minor cases (about 2 out of 50 runs) above line is the only line that can generate concurrent modification exception which I eliminated it with try-catch. The reason behind this is because while we want to get all of the existing contexts, the contextMap can be modified in the cache by other threads. As a result we will get concurrentMod exception. Please note that this part of the code runs asynchronously.\n@narendly I don't have strong preference about this method and using try-catch and I would be happy if you can propose new way to get all of the context without hitting concurrent modification exception.", "author": "alirezazamani", "createdAt": "2020-02-11T03:27:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQyMzU3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQzNDM5MA==", "url": "https://github.com/apache/helix/pull/741#discussion_r377434390", "bodyText": "If you make a deep copy of the set, you shouldn't need to wrap it with a try-catch since your async thread would be the only thread iterating over the data structure, correct? What I'm not understanding is why we need the try-catch.", "author": "narendly", "createdAt": "2020-02-11T03:36:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQyMzU3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQzNjcyNQ==", "url": "https://github.com/apache/helix/pull/741#discussion_r377436725", "bodyText": "I don't believe deep copy by itself helps. The code generate concurrent modification in this function: map.keySet(). We cannot avoid this. How you are proposing to get the keys in the map in this scenario? We need to get the keys no matter what (even for doing deep copy). Even the implementation of deep copying involves to loop over the elements and copy them one by one to the new map. A deep copy is merely done by iterating through the elements (keys and values) and cloning those too. Right? In this case if original map has been changed while copy operation is happening, we might still get concurrent modification exception.", "author": "alirezazamani", "createdAt": "2020-02-11T03:51:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQyMzU3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzc5MzcwMQ==", "url": "https://github.com/apache/helix/pull/741#discussion_r377793701", "bodyText": "@alirezazamani  thanks for the explanation :) Now that makes a lot more sense.\nOne structural improvement I'd suggest:\n\nPlease only wrap the copy constructor with a the try-catch to make your intentions clear.\nIt would be good to explain this in the code as a javadoc comment (as to why it needs to be wrapped with a try-catch).\nYour catch should return the function early.", "author": "narendly", "createdAt": "2020-02-11T17:44:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQyMzU3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzg4MDgyMg==", "url": "https://github.com/apache/helix/pull/741#discussion_r377880822", "bodyText": "Done. Thanks @narendly for the comments.", "author": "alirezazamani", "createdAt": "2020-02-11T20:30:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzQyMzU3NA=="}], "type": "inlineReview"}, {"oid": "de0f8fb4506a2891b326542657b1e72576e97d31", "url": "https://github.com/apache/helix/commit/de0f8fb4506a2891b326542657b1e72576e97d31", "message": "fix reviewer comments", "committedDate": "2020-02-11T18:10:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk1NDE0Mw==", "url": "https://github.com/apache/helix/pull/741#discussion_r377954143", "bodyText": "move this to where try-catch is?\nExplain why Map.keySet() throws CME w regards to copy constructor?", "author": "narendly", "createdAt": "2020-02-11T23:08:45Z", "path": "helix-core/src/main/java/org/apache/helix/task/TaskUtil.java", "diffHunk": "@@ -1040,26 +1040,39 @@ public static void purgeExpiredJobs(String workflow, WorkflowConfig workflowConf\n   /**\n    * The function that loops through the all existing workflow contexts and removes IdealState and\n    * workflow context of the workflow whose workflow config does not exist.\n+   * Try-catch has been used to avoid concurrent modification exception while doing deep copy. Since\n+   * Map.keySet() can produce concurrent modification exception.", "originalCommit": "de0f8fb4506a2891b326542657b1e72576e97d31", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk4NjMxOA==", "url": "https://github.com/apache/helix/pull/741#discussion_r377986318", "bodyText": "Done. Please let me know if it is still not clear.", "author": "alirezazamani", "createdAt": "2020-02-12T00:51:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk1NDE0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk1NDMxMA==", "url": "https://github.com/apache/helix/pull/741#discussion_r377954310", "bodyText": "\"workflow context names\"", "author": "narendly", "createdAt": "2020-02-11T23:09:10Z", "path": "helix-core/src/main/java/org/apache/helix/task/TaskUtil.java", "diffHunk": "@@ -1040,26 +1040,39 @@ public static void purgeExpiredJobs(String workflow, WorkflowConfig workflowConf\n   /**\n    * The function that loops through the all existing workflow contexts and removes IdealState and\n    * workflow context of the workflow whose workflow config does not exist.\n+   * Try-catch has been used to avoid concurrent modification exception while doing deep copy. Since\n+   * Map.keySet() can produce concurrent modification exception.\n    * @param dataProvider\n    * @param manager\n    */\n-  public static void workflowGarbageCollection(WorkflowControllerDataProvider dataProvider,\n+  public static void workflowGarbageCollection(final WorkflowControllerDataProvider dataProvider,\n       final HelixManager manager) {\n     // Garbage collections for conditions where workflow context exists but config is missing.\n-    Map<String, ZNRecord> contexts = dataProvider.getContexts();\n-    HelixDataAccessor accessor = manager.getHelixDataAccessor();\n-    HelixPropertyStore<ZNRecord> propertyStore = manager.getHelixPropertyStore();\n \n+    Set<String> existingWorkflowContexts;\n+    try {\n+      existingWorkflowContexts = new HashSet<>(dataProvider.getContexts().keySet());\n+    } catch (Exception e) {\n+      LOG.warn(\n+          \"Exception occurred while creating a list of all existing contexts with missing config!\",\n+          e);", "originalCommit": "de0f8fb4506a2891b326542657b1e72576e97d31", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk4NjM2MQ==", "url": "https://github.com/apache/helix/pull/741#discussion_r377986361", "bodyText": "Done.", "author": "alirezazamani", "createdAt": "2020-02-12T00:52:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk1NDMxMA=="}], "type": "inlineReview"}, {"oid": "db44ab0ca83b1cf79b9dd378f9937f9d14a221d9", "url": "https://github.com/apache/helix/commit/db44ab0ca83b1cf79b9dd378f9937f9d14a221d9", "message": "Comment fixes", "committedDate": "2020-02-12T00:54:14Z", "type": "forcePushed"}, {"oid": "0c4f575e376e509e57e0d1bc617500449e5be047", "url": "https://github.com/apache/helix/commit/0c4f575e376e509e57e0d1bc617500449e5be047", "message": "Comment fixes", "committedDate": "2020-02-12T00:56:42Z", "type": "commit"}, {"oid": "0c4f575e376e509e57e0d1bc617500449e5be047", "url": "https://github.com/apache/helix/commit/0c4f575e376e509e57e0d1bc617500449e5be047", "message": "Comment fixes", "committedDate": "2020-02-12T00:56:42Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5NTM4Mg==", "url": "https://github.com/apache/helix/pull/741#discussion_r383095382", "bodyText": "@alirezazamani Is there a specific reason why we don't change the contexts map below to a concurrent hash map and make it thread safe?\n  private Map<String, ZNRecord> _contextMap = new HashMap<>();\n\nWhat I can only see is performance concern when contexts modification is blocked by this copying. If performance is not that bad, I believe changing the contextMap to a concurrent hash map is the right fix.", "author": "huizhilu", "createdAt": "2020-02-24T06:00:42Z", "path": "helix-core/src/main/java/org/apache/helix/task/TaskUtil.java", "diffHunk": "@@ -1043,23 +1043,40 @@ public static void purgeExpiredJobs(String workflow, WorkflowConfig workflowConf\n    * @param dataProvider\n    * @param manager\n    */\n-  public static void workflowGarbageCollection(WorkflowControllerDataProvider dataProvider,\n+  public static void workflowGarbageCollection(final WorkflowControllerDataProvider dataProvider,\n       final HelixManager manager) {\n     // Garbage collections for conditions where workflow context exists but config is missing.\n-    Map<String, ZNRecord> contexts = dataProvider.getContexts();\n-    HelixDataAccessor accessor = manager.getHelixDataAccessor();\n-    HelixPropertyStore<ZNRecord> propertyStore = manager.getHelixPropertyStore();\n \n+    Set<String> existingContexts;\n+    /*\n+     * Here try-catch is used to avoid concurrent modification exception while doing deep copy.\n+     * Map.keySet() can produce concurrent modification exception.\n+     * Reason: If the map is modified while an iteration over the set is in progress, concurrent\n+     * modification exception will be thrown.\n+     */\n+    try {\n+      existingContexts = new HashSet<>(dataProvider.getContexts().keySet());", "originalCommit": "0c4f575e376e509e57e0d1bc617500449e5be047", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5NzQ1OA==", "url": "https://github.com/apache/helix/pull/741#discussion_r383097458", "bodyText": "dataProvider.getContexts() is outside the scope of this class and perhaps there are performance concerns regarding this. Maybe we can consider this in next design of TF.", "author": "alirezazamani", "createdAt": "2020-02-24T06:13:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA5NTM4Mg=="}], "type": "inlineReview"}]}