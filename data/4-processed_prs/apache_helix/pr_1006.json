{"pr_number": 1006, "pr_title": "Fix the RuntimeJobDag issue for queues", "pr_createdAt": "2020-05-13T17:23:35Z", "pr_url": "https://github.com/apache/helix/pull/1006", "timeline": [{"oid": "75c285a5e587335c3ea4a2da1270aa8f189845aa", "url": "https://github.com/apache/helix/commit/75c285a5e587335c3ea4a2da1270aa8f189845aa", "message": "Fix the RuntimeJobDag issue for queues with ParallelJob set to more than 1\n\nIn this commit, a fix has been implemented to avoid\n _readyJobList in RuntimeJobDag to contain multiple\nentries of the same job.", "committedDate": "2020-05-13T17:26:38Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDY5NDA4Mw==", "url": "https://github.com/apache/helix/pull/1006#discussion_r424694083", "bodyText": "Better to have some comments here. I think this is an optimization instead of fix. Even if you add the scheduled one as next job. It will be skipped in schedule job part in WorkflowDispatcher.\nWould that cause problem for get another next job?", "author": "junkaixue", "createdAt": "2020-05-13T19:55:18Z", "path": "helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java", "diffHunk": "@@ -146,8 +146,13 @@ public boolean finishJob(String job) {\n     }\n     // Add finished job's successors to ready-list\n     if (_isJobQueue) {\n-      if (_lastJob != null && _parentsToChildren.containsKey(_lastJob)) {\n-        _readyJobList.offer(_parentsToChildren.get(_lastJob).iterator().next());\n+      while (_lastJob != null && _parentsToChildren.containsKey(_lastJob)) {", "originalCommit": "75c285a5e587335c3ea4a2da1270aa8f189845aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDY5OTI2NQ==", "url": "https://github.com/apache/helix/pull/1006#discussion_r424699265", "bodyText": "Thanks for the feedback. I will add the comments. Actually this is a fix. If you look at the test I added, it is failing without this fix. If you run the newly added test, you will notice that the jobs are not running in parallel because of this issue. This specifically causes problems for the ParallelJobs in the queue. If ParallelJobs is set to one, then we won't notice the issue.", "author": "alirezazamani", "createdAt": "2020-05-13T20:05:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDY5NDA4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc1NjMyMw==", "url": "https://github.com/apache/helix/pull/1006#discussion_r424756323", "bodyText": "+1. I believe we're making this improvement because we've seen an issue in production. Could you add a block comment here what the issue was and why this would fix the issue to give more context?", "author": "narendly", "createdAt": "2020-05-13T22:01:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDY5NDA4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkwOTUxNQ==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426909515", "bodyText": "Sure. Added comments about it. I will change the PR for master branch.", "author": "alirezazamani", "createdAt": "2020-05-18T21:43:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDY5NDA4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc1NTEzNg==", "url": "https://github.com/apache/helix/pull/1006#discussion_r424755136", "bodyText": "Could nextJob be null?", "author": "narendly", "createdAt": "2020-05-13T21:58:52Z", "path": "helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java", "diffHunk": "@@ -146,8 +146,13 @@ public boolean finishJob(String job) {\n     }\n     // Add finished job's successors to ready-list\n     if (_isJobQueue) {\n-      if (_lastJob != null && _parentsToChildren.containsKey(_lastJob)) {\n-        _readyJobList.offer(_parentsToChildren.get(_lastJob).iterator().next());\n+      while (_lastJob != null && _parentsToChildren.containsKey(_lastJob)) {\n+        String nextJob = _parentsToChildren.get(_lastJob).iterator().next();", "originalCommit": "75c285a5e587335c3ea4a2da1270aa8f189845aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkwOTU1OQ==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426909559", "bodyText": "Since _parentsToChildren.containsKey(_lastJob) is only added if there is actually a children for that job, as long as we are in the while loop, it means that nextJob is not null.", "author": "alirezazamani", "createdAt": "2020-05-18T21:43:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc1NTEzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyMzk5MA==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426923990", "bodyText": "could you add that explanation in the code?", "author": "narendly", "createdAt": "2020-05-18T22:21:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc1NTEzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk0MTgxOQ==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426941819", "bodyText": "Sure. I will add that now.", "author": "alirezazamani", "createdAt": "2020-05-18T23:14:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc1NTEzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc1NTM5MA==", "url": "https://github.com/apache/helix/pull/1006#discussion_r424755390", "bodyText": "Let's make these magic numbers descriptive variables?", "author": "narendly", "createdAt": "2020-05-13T21:59:27Z", "path": "helix-core/src/test/java/org/apache/helix/integration/task/TestEnqueueJobs.java", "diffHunk": "@@ -96,4 +102,60 @@ public void testJobSubmitGenericWorkflows() throws InterruptedException {\n \n     _driver.pollForWorkflowState(workflowName, TaskState.COMPLETED);\n   }\n-}\n\\ No newline at end of file\n+\n+  @Test\n+  public void testQueueParallelJobs() throws InterruptedException {\n+    String queueName = TestHelper.getTestMethodName();\n+    JobQueue.Builder builder = TaskTestUtil.buildJobQueue(queueName);\n+    WorkflowConfig.Builder workflowCfgBuilder = new WorkflowConfig.Builder()\n+        .setWorkflowId(queueName).setParallelJobs(3).setAllowOverlapJobAssignment(true);\n+    _driver.start(builder.setWorkflowConfig(workflowCfgBuilder.build()).build());\n+    JobConfig.Builder jobBuilder =\n+        new JobConfig.Builder().setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+            .setCommand(MockTask.TASK_COMMAND).setMaxAttemptsPerTask(2)\n+            .setJobCommandConfigMap(Collections.singletonMap(MockTask.JOB_DELAY, \"10000\"));\n+\n+    // Add 4 jobs to the queue\n+    for (int i = 0; i <= 3; i++) {", "originalCommit": "75c285a5e587335c3ea4a2da1270aa8f189845aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkwOTYzNg==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426909636", "bodyText": "Done.", "author": "alirezazamani", "createdAt": "2020-05-18T21:44:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDc1NTM5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg0MjIwOQ==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426842209", "bodyText": "Could you help understand: If you are only checking one: maxEndtime > maxStartime, why are HashSets necessary?", "author": "huizhilu", "createdAt": "2020-05-18T19:18:31Z", "path": "helix-core/src/test/java/org/apache/helix/integration/task/TestEnqueueJobs.java", "diffHunk": "@@ -96,4 +102,60 @@ public void testJobSubmitGenericWorkflows() throws InterruptedException {\n \n     _driver.pollForWorkflowState(workflowName, TaskState.COMPLETED);\n   }\n-}\n\\ No newline at end of file\n+\n+  @Test\n+  public void testQueueParallelJobs() throws InterruptedException {\n+    String queueName = TestHelper.getTestMethodName();\n+    JobQueue.Builder builder = TaskTestUtil.buildJobQueue(queueName);\n+    WorkflowConfig.Builder workflowCfgBuilder = new WorkflowConfig.Builder()\n+        .setWorkflowId(queueName).setParallelJobs(3).setAllowOverlapJobAssignment(true);\n+    _driver.start(builder.setWorkflowConfig(workflowCfgBuilder.build()).build());\n+    JobConfig.Builder jobBuilder =\n+        new JobConfig.Builder().setTargetResource(WorkflowGenerator.DEFAULT_TGT_DB)\n+            .setCommand(MockTask.TASK_COMMAND).setMaxAttemptsPerTask(2)\n+            .setJobCommandConfigMap(Collections.singletonMap(MockTask.JOB_DELAY, \"10000\"));\n+\n+    // Add 4 jobs to the queue\n+    for (int i = 0; i <= 3; i++) {\n+      _driver.enqueueJob(queueName, \"JOB\" + i, jobBuilder);\n+    }\n+\n+    // Wait until all of the enqueued jobs (Job0 to Job3) are finished\n+    for (int i = 0; i <= 3; i++) {\n+      _driver.pollForJobState(queueName, TaskUtil.getNamespacedJobName(queueName, \"JOB\" + i),\n+          TaskState.COMPLETED);\n+    }\n+\n+    // Stop the Controller\n+    _controller.syncStop();\n+\n+    // Add 3 more jobs to the queue which should run in parallel after the Controller is started\n+    for (int i = 4; i <= 6; i++) {\n+      _driver.enqueueJob(queueName, \"JOB\" + i, jobBuilder);\n+    }\n+\n+    // Start the Controller\n+    String controllerName = CONTROLLER_PREFIX + \"_0\";\n+    _controller = new ClusterControllerManager(ZK_ADDR, CLUSTER_NAME, controllerName);\n+    _controller.syncStart();\n+\n+    // Wait until all of the newly added jobs (Job4 to Job6) are finished\n+    for (int i = 4; i <= 6; i++) {\n+      _driver.pollForJobState(queueName, TaskUtil.getNamespacedJobName(queueName, \"JOB\" + i),\n+          TaskState.COMPLETED);\n+    }\n+\n+    // Make sure the jobs have been running in parallel by checking the jobs start time and finish\n+    // time\n+    Set<Long> startTimes = new HashSet<>();\n+    Set<Long> endTime = new HashSet<>();\n+\n+    for (int i = 4; i <= 6; i++) {\n+      JobContext jobContext =\n+          _driver.getJobContext(TaskUtil.getNamespacedJobName(queueName, \"JOB\" + i));\n+      startTimes.add(jobContext.getStartTime());\n+      endTime.add(jobContext.getFinishTime());\n+    }\n+    Assert.assertTrue(Collections.min(endTime) > Collections.max(startTimes));", "originalCommit": "75c285a5e587335c3ea4a2da1270aa8f189845aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkwOTY5NQ==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426909695", "bodyText": "Changed it to one long and get minimum/maximum in every loop.", "author": "alirezazamani", "createdAt": "2020-05-18T21:44:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg0MjIwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg0NTgyNQ==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426845825", "bodyText": "What's the time complexity of this operation?", "author": "huizhilu", "createdAt": "2020-05-18T19:25:45Z", "path": "helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java", "diffHunk": "@@ -146,8 +146,13 @@ public boolean finishJob(String job) {\n     }\n     // Add finished job's successors to ready-list\n     if (_isJobQueue) {\n-      if (_lastJob != null && _parentsToChildren.containsKey(_lastJob)) {\n-        _readyJobList.offer(_parentsToChildren.get(_lastJob).iterator().next());\n+      while (_lastJob != null && _parentsToChildren.containsKey(_lastJob)) {\n+        String nextJob = _parentsToChildren.get(_lastJob).iterator().next();\n+        if (!_readyJobList.contains(nextJob)) {", "originalCommit": "75c285a5e587335c3ea4a2da1270aa8f189845aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkwOTY3MA==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426909670", "bodyText": "I understand you concern about time complexity. However, if you look at the whole structure of the code, finish job is only called once and only if the job is finished. Also parallel jobs is not usually set to a large value, I think we are safe here. Also note that we need that for correctness of TF.", "author": "alirezazamani", "createdAt": "2020-05-18T21:44:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg0NTgyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNzQ3Mg==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426927472", "bodyText": "This is within a while loop. How many times this check will be run?", "author": "huizhilu", "createdAt": "2020-05-18T22:31:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg0NTgyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk0NDQzMQ==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426944431", "bodyText": "Usually in normal cases where we do not have controller switch we don't run this loop multiple times because _lastJob is keeping us at the end for the list. Also if we have controller switch, it will help us in the long run because we do not need to loop through the jobs that has been scheduled before multiple times.", "author": "alirezazamani", "createdAt": "2020-05-18T23:22:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg0NTgyNQ=="}], "type": "inlineReview"}, {"oid": "2531e22d3544919a695c41bbd978c5f679c9d093", "url": "https://github.com/apache/helix/commit/2531e22d3544919a695c41bbd978c5f679c9d093", "message": "Fix the RuntimeJobDag issue for queues with ParallelJob set to more than 1\n\nIn this commit, a fix has been implemented to avoid\n _readyJobList in RuntimeJobDag to contain multiple\nentries of the same job.", "committedDate": "2020-05-18T19:55:03Z", "type": "commit"}, {"oid": "5fdad13a156e31af745d70bc58c04104b3dfca95", "url": "https://github.com/apache/helix/commit/5fdad13a156e31af745d70bc58c04104b3dfca95", "message": "Address the comments", "committedDate": "2020-05-18T21:43:01Z", "type": "commit"}, {"oid": "5fdad13a156e31af745d70bc58c04104b3dfca95", "url": "https://github.com/apache/helix/commit/5fdad13a156e31af745d70bc58c04104b3dfca95", "message": "Address the comments", "committedDate": "2020-05-18T21:43:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNTY5Nw==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426925697", "bodyText": "Have a follow up question. What do you mean the job gets added several times to the readyJobList?\nIf there's a controller switch, we'll be creating readyJobList/inflightJobList from scratch, and add everything from the beginning (or the first available job from the step-by-step topological sort). Then as long as the controller doesn't switch, it only gets added once, right?\nIn other words, for each controller should add a job exactly once. Is that correct?\nAlso even though a job might get added to readyJobList multiple times (exactly once in different controllers), our scheduling logic just skips it I believe (if jobState is complete/progress we just skip?). Could you help me understand how this could help? It seems that although this wouldn't hurt to do...", "author": "narendly", "createdAt": "2020-05-18T22:26:17Z", "path": "helix-core/src/main/java/org/apache/helix/task/RuntimeJobDag.java", "diffHunk": "@@ -145,9 +145,21 @@ public boolean finishJob(String job) {\n           String.format(\"Job: %s has either finished already, never been scheduled, or been removed from DAG\", job));\n     }\n     // Add finished job's successors to ready-list\n+\n+    // If it is a jobQueue, there should be a check to make sure that the a job has not been added\n+    // to the _readyJobList multiple times. This check is necessary because once the controller\n+    // switch happens, the _readyJobList and _inflightJobList will be created from scratch. In this\n+    // case, since there might be many jobs that have been finished before, we do not want to have a\n+    // job several times to the _readyJobList. If _readyJobList has multiple instances of the same\n+    // job, it can compromise the functionality of the parallel jobs.", "originalCommit": "5fdad13a156e31af745d70bc58c04104b3dfca95", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk0MDc0OQ==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426940749", "bodyText": "It is very hard to explain. I will do my best to explain it here. (If it is still not clear, I suggest you to just run the test I added to this PR and it will be very clear to you.)\nExplanation:\nHere is the _readyJobList contents after the controller switch in my test (without this fix):\n\n[testQueueParallelJobs_JOB0, testQueueParallelJobs_JOB1, testQueueParallelJobs_JOB2]\n[testQueueParallelJobs_JOB1, testQueueParallelJobs_JOB2, testQueueParallelJobs_JOB1]\n[testQueueParallelJobs_JOB2, testQueueParallelJobs_JOB1, testQueueParallelJobs_JOB2]\n[testQueueParallelJobs_JOB1, testQueueParallelJobs_JOB2, testQueueParallelJobs_JOB3]\n[testQueueParallelJobs_JOB2, testQueueParallelJobs_JOB3, testQueueParallelJobs_JOB2]\n[testQueueParallelJobs_JOB3, testQueueParallelJobs_JOB2, testQueueParallelJobs_JOB3]\n[testQueueParallelJobs_JOB2, testQueueParallelJobs_JOB3, testQueueParallelJobs_JOB4]\n[testQueueParallelJobs_JOB3, testQueueParallelJobs_JOB4, testQueueParallelJobs_JOB3]\n[testQueueParallelJobs_JOB4, testQueueParallelJobs_JOB3, testQueueParallelJobs_JOB4]\n[testQueueParallelJobs_JOB3, testQueueParallelJobs_JOB4]\n[testQueueParallelJobs_JOB4, testQueueParallelJobs_JOB4]\n[testQueueParallelJobs_JOB4]\n[testQueueParallelJobs_JOB5]\n[testQueueParallelJobs_JOB6]\n\nWe end up having just JOB4 in the DAG and the reason is because once each job is finished, we add new job to the _readyList (_readyList is updated in finishJob method). If there is only one Job in the _readyList, we will wait until 4 is finished and add JOB5 and so on. In this case, we will not run the whole queue in parallel.\nAlso interesting to note here that even before controller switch here is _readyList which is also wrong (and can potentially causes problems) and we see two JOBs with the same name in the queue. However, this is not as critical as the the one I explained above:\n\n[testQueueParallelJobs_JOB0, testQueueParallelJobs_JOB1]\n[testQueueParallelJobs_JOB1]\n[testQueueParallelJobs_JOB0, testQueueParallelJobs_JOB1, testQueueParallelJobs_JOB2]\n[testQueueParallelJobs_JOB1, testQueueParallelJobs_JOB2]\n[testQueueParallelJobs_JOB2]\n[testQueueParallelJobs_JOB3, testQueueParallelJobs_JOB3]\n[testQueueParallelJobs_JOB3]", "author": "alirezazamani", "createdAt": "2020-05-18T23:10:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNTY5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk0NTE2OA==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426945168", "bodyText": "Please note that if we have a lot of jobs in the queue and restart the controller, if we have for example 1000 jobs already in the queue and completed, we will loop through each job several times for the first pipelines after the switch. It will make the controller very slow (for the fist pipelines) because each job will go to _readyList multiple times.", "author": "alirezazamani", "createdAt": "2020-05-18T23:25:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNTY5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODkwOTU4NA==", "url": "https://github.com/apache/helix/pull/1006#discussion_r428909584", "bodyText": "With this fix, this is the _readyList after controller switch:\n[testQueueParallelJobs_JOB0, testQueueParallelJobs_JOB1, testQueueParallelJobs_JOB2]\n[testQueueParallelJobs_JOB1, testQueueParallelJobs_JOB2, testQueueParallelJobs_JOB3]\n[testQueueParallelJobs_JOB2, testQueueParallelJobs_JOB3, testQueueParallelJobs_JOB4]\n[testQueueParallelJobs_JOB3, testQueueParallelJobs_JOB4, testQueueParallelJobs_JOB5]\n[testQueueParallelJobs_JOB4, testQueueParallelJobs_JOB5, testQueueParallelJobs_JOB6]\n[testQueueParallelJobs_JOB5, testQueueParallelJobs_JOB6]\n[testQueueParallelJobs_JOB6]", "author": "alirezazamani", "createdAt": "2020-05-21T20:55:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNTY5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTM2NzQ3NA==", "url": "https://github.com/apache/helix/pull/1006#discussion_r429367474", "bodyText": "Without the fix:\nPlease note the we add job to the _readyJob list once we call finishJob (e.g. once a job is completed).\nLet's say controller switch happened and we started from scratch.\nWe have [Job0, Job1 , Job2] in the _readyList.\nTo schedule the jobs, we get next job from readyList (Job0), see that this job is completed, we add the children of Job0 which is Job1. Hence the _readyList will be [Job1, Job2, Job1]. That is why we have same job added to the _readyList.\nIn conclusion, if a job is finished and controller adds a wrong job, the _readyJobList will fall behind. For example in my test, we add Job4 multiple times. Since Job4 goes to in-progress state and it takes some time to finish, we do not add new job (i.e. job5) until Job4 is finished and hence we do not run jobs in parallel if this happens.", "author": "alirezazamani", "createdAt": "2020-05-22T17:23:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNTY5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDA0NjA3MA==", "url": "https://github.com/apache/helix/pull/1006#discussion_r430046070", "bodyText": "@alirezazamani Thank for explaining with concrete examples. So the root cause seems to be that we do not do if (!_readyJobList.contains(nextJob)) when we add the jobs to the ready list.\nGood find and good fix! :)", "author": "narendly", "createdAt": "2020-05-25T18:48:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNTY5Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNTc5Nw==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426925797", "bodyText": "Don't forget to remove unused imports.", "author": "huizhilu", "createdAt": "2020-05-18T22:26:36Z", "path": "helix-core/src/test/java/org/apache/helix/integration/task/TestEnqueueJobs.java", "diffHunk": "@@ -1,12 +1,18 @@\n package org.apache.helix.integration.task;\n \n+import java.util.Collections;\n+import java.util.HashSet;", "originalCommit": "5fdad13a156e31af745d70bc58c04104b3dfca95", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk0MzcxMA==", "url": "https://github.com/apache/helix/pull/1006#discussion_r426943710", "bodyText": "Done.", "author": "alirezazamani", "createdAt": "2020-05-18T23:20:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNTc5Nw=="}], "type": "inlineReview"}, {"oid": "9325b3b948b998733d56e3fb7f329c6fdc26431c", "url": "https://github.com/apache/helix/commit/9325b3b948b998733d56e3fb7f329c6fdc26431c", "message": "Address new comments", "committedDate": "2020-05-18T23:18:16Z", "type": "commit"}]}