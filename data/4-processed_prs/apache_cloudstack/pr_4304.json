{"pr_number": 4304, "pr_title": "Storage plugin for Dell EMC PowerFlex/ScaleIO (formerly VxFlexOS)", "pr_createdAt": "2020-09-03T17:47:30Z", "pr_url": "https://github.com/apache/cloudstack/pull/4304", "timeline": [{"oid": "4e77f6870c194c7beee396e877686a7a082e4ec3", "url": "https://github.com/apache/cloudstack/commit/4e77f6870c194c7beee396e877686a7a082e4ec3", "message": "Storage plugin for Dell EMC PowerFlex/ScaleIO (formerly VxFlexOS)", "committedDate": "2020-09-09T10:28:07Z", "type": "forcePushed"}, {"oid": "aa3b9bcb3d0f91dd055df4c5149aaf53e1a2b1aa", "url": "https://github.com/apache/cloudstack/commit/aa3b9bcb3d0f91dd055df4c5149aaf53e1a2b1aa", "message": "Storage plugin for Dell EMC PowerFlex/ScaleIO (formerly VxFlexOS)", "committedDate": "2020-10-15T23:58:58Z", "type": "forcePushed"}, {"oid": "0129ddeb153ce57c08c54d409e2ee7cafc9a4008", "url": "https://github.com/apache/cloudstack/commit/0129ddeb153ce57c08c54d409e2ee7cafc9a4008", "message": "Storage plugin for Dell EMC PowerFlex/ScaleIO (formerly VxFlexOS)", "committedDate": "2020-10-16T04:15:42Z", "type": "forcePushed"}, {"oid": "02e5647f2e63ccc6b360502ada224d695b26c1af", "url": "https://github.com/apache/cloudstack/commit/02e5647f2e63ccc6b360502ada224d695b26c1af", "message": "Storage plugin for Dell EMC PowerFlex/ScaleIO (formerly VxFlexOS)", "committedDate": "2020-10-19T20:40:55Z", "type": "forcePushed"}, {"oid": "3b061e8054d8256ec8fdc606057ded982de21804", "url": "https://github.com/apache/cloudstack/commit/3b061e8054d8256ec8fdc606057ded982de21804", "message": "Storage plugin for Dell EMC PowerFlex/ScaleIO (formerly VxFlexOS)", "committedDate": "2020-10-29T12:06:40Z", "type": "forcePushed"}, {"oid": "ad50a8de67a6737579bdd9f249ed010d15820229", "url": "https://github.com/apache/cloudstack/commit/ad50a8de67a6737579bdd9f249ed010d15820229", "message": "Storage plugin for Dell EMC PowerFlex/ScaleIO (formerly VxFlexOS)", "committedDate": "2020-11-02T18:43:14Z", "type": "forcePushed"}, {"oid": "0185a0f3f4464e741e21f16f46fc7f951250e8a1", "url": "https://github.com/apache/cloudstack/commit/0185a0f3f4464e741e21f16f46fc7f951250e8a1", "message": "Storage plugin for Dell EMC PowerFlex/ScaleIO (formerly VxFlexOS)", "committedDate": "2020-11-03T10:39:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI5NTk5MQ==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r521295991", "bodyText": "will be good to add a since tag here\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @Parameter(name = ApiConstants.DETAILS, type = CommandType.MAP, description = \"details to specify disk offering parameters\")\n          \n          \n            \n                @Parameter(name = ApiConstants.DETAILS, type = CommandType.MAP, description = \"details to specify disk offering parameters\", since=\"4.16)", "author": "shwstppr", "createdAt": "2020-11-11T11:33:43Z", "path": "api/src/main/java/org/apache/cloudstack/api/command/admin/offering/CreateDiskOfferingCmd.java", "diffHunk": "@@ -152,6 +156,9 @@\n             since = \"4.14\")\n     private String cacheMode;\n \n+    @Parameter(name = ApiConstants.DETAILS, type = CommandType.MAP, description = \"details to specify disk offering parameters\")", "originalCommit": "0185a0f3f4464e741e21f16f46fc7f951250e8a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI5Njc4Mg==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r521296782", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @Param(description = \"the pool type of the virtual machine\")\n          \n          \n            \n                @Param(description = \"the pool type of the virtual machine\", since=\"4.16)", "author": "shwstppr", "createdAt": "2020-11-11T11:35:17Z", "path": "api/src/main/java/org/apache/cloudstack/api/response/UserVmResponse.java", "diffHunk": "@@ -310,6 +310,10 @@\n     @Param(description = \"Guest vm Boot Type\")\n     private String bootType;\n \n+    @SerializedName(ApiConstants.POOL_TYPE)\n+    @Param(description = \"the pool type of the virtual machine\")", "originalCommit": "0185a0f3f4464e741e21f16f46fc7f951250e8a1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTMxMjU2NQ==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r521312565", "bodyText": "@sureshanaparti this config is changed from global scope to zone. Will that affect the existing setup in any way?", "author": "shwstppr", "createdAt": "2020-11-11T12:06:48Z", "path": "engine/api/src/main/java/com/cloud/vm/VirtualMachineManager.java", "diffHunk": "@@ -59,7 +59,13 @@\n             \"The default label name for the config drive\", false);\n \n     ConfigKey<Boolean> VmConfigDriveOnPrimaryPool = new ConfigKey<>(\"Advanced\", Boolean.class, \"vm.configdrive.primarypool.enabled\", \"false\",\n-            \"If config drive need to be created and hosted on primary storage pool. Currently only supported for KVM.\", true);\n+            \"If config drive need to be created and hosted on primary storage pool. Currently only supported for KVM.\", true, ConfigKey.Scope.Zone);", "originalCommit": "0185a0f3f4464e741e21f16f46fc7f951250e8a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI1NDc4OQ==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r524254789", "bodyText": "@sureshanaparti this config is changed from global scope to zone. Will that affect the existing setup in any way?\n\n@shwstppr no, the existing config would always fallback to the global scope, as zone scope setting is not defined initially.", "author": "sureshanaparti", "createdAt": "2020-11-16T13:08:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTMxMjU2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2MDA5NQ==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r521360095", "bodyText": "Curious, why we need to catch all Exception here? And we are not even logging it then", "author": "shwstppr", "createdAt": "2020-11-11T13:32:59Z", "path": "engine/orchestration/src/main/java/org/apache/cloudstack/engine/orchestration/VolumeOrchestrator.java", "diffHunk": "@@ -1465,11 +1543,17 @@ public void prepareForMigration(VirtualMachineProfile vm, DeployDestination dest\n                     long hostId = vm.getVirtualMachine().getHostId();\n                     Host host = _hostDao.findById(hostId);\n \n-                    volService.grantAccess(volFactory.getVolume(newVol.getId()), host, destPool);\n+                    try {\n+                        volService.grantAccess(volFactory.getVolume(newVol.getId()), host, destPool);\n+                    } catch (Exception e) {\n+                        throw new StorageAccessException(\"Unable to grant access to volume: \" + newVol.getId() + \" on host: \" + host.getId());\n+                    }", "originalCommit": "0185a0f3f4464e741e21f16f46fc7f951250e8a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI2MDAzNg==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r524260036", "bodyText": "Curious, why we need to catch all Exception here? And we are not even logging it then\n\n@shwstppr in order to retry the deployment, whenever granting access to a disk fails in any case (chances are storage temporarily inaccessible, failure, etc); and this is being logged in \"VirtualMachineManagerImpl orchestrateStart()\"", "author": "sureshanaparti", "createdAt": "2020-11-16T13:17:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2MDA5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2MTU5Mg==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r521361592", "bodyText": "Is this message in-line with the fact that we support PowerFlex only for KVM right now?", "author": "shwstppr", "createdAt": "2020-11-11T13:35:31Z", "path": "engine/storage/datamotion/src/main/java/org/apache/cloudstack/storage/motion/StorageSystemDataMotionStrategy.java", "diffHunk": "@@ -574,6 +574,14 @@ private void handleVolumeMigrationFromManagedStorageToNonManagedStorage(VolumeIn\n         }\n     }\n \n+    private void verifyFormatWithPoolType(ImageFormat imageFormat, StoragePoolType poolType) {\n+        if (imageFormat != ImageFormat.VHD && imageFormat != ImageFormat.OVA && imageFormat != ImageFormat.QCOW2 &&\n+                !(imageFormat == ImageFormat.RAW && StoragePoolType.PowerFlex == poolType)) {\n+            throw new CloudRuntimeException(\"Only the following image types are currently supported: \" +\n+                    ImageFormat.VHD.toString() + \", \" + ImageFormat.OVA.toString() + \", \" + ImageFormat.QCOW2.toString() + \", and \" + ImageFormat.RAW.toString() + \"(for PowerFlex)\");", "originalCommit": "0185a0f3f4464e741e21f16f46fc7f951250e8a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI2MTI1Ng==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r524261256", "bodyText": "Is this message in-line with the fact that we support PowerFlex only for KVM right now?\n\nyes, in-line with the RAW disk support with PowerFlex storage, for KVM.", "author": "sureshanaparti", "createdAt": "2020-11-16T13:19:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2MTU5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2Mjk1Mg==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r521362952", "bodyText": "We listed couple of more image formats with powerflex support", "author": "shwstppr", "createdAt": "2020-11-11T13:37:49Z", "path": "engine/storage/datamotion/src/main/java/org/apache/cloudstack/storage/motion/StorageSystemDataMotionStrategy.java", "diffHunk": "@@ -2301,7 +2325,9 @@ private void handleCreateTemplateFromManagedVolume(VolumeInfo volumeInfo, Templa\n         CopyCmdAnswer copyCmdAnswer = null;\n \n         try {\n-            if (!ImageFormat.QCOW2.equals(volumeInfo.getFormat())) {\n+            StoragePoolVO storagePoolVO = _storagePoolDao.findById(volumeInfo.getPoolId());\n+\n+            if (!ImageFormat.QCOW2.equals(volumeInfo.getFormat()) && !(ImageFormat.RAW.equals(volumeInfo.getFormat()) && StoragePoolType.PowerFlex == storagePoolVO.getPoolType())) {", "originalCommit": "0185a0f3f4464e741e21f16f46fc7f951250e8a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDI2MjgzMA==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r524262830", "bodyText": "We listed couple of more image formats with powerflex support\n\nRAW format is the only supported disk format with PowerFlex storage", "author": "sureshanaparti", "createdAt": "2020-11-16T13:22:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2Mjk1Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2NDA2NQ==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r521364065", "bodyText": "@sureshanaparti do we need a Primate change for this or is it already handled there?", "author": "shwstppr", "createdAt": "2020-11-11T13:39:39Z", "path": "ui/scripts/instances.js", "diffHunk": "@@ -4189,6 +4189,10 @@\n                 allowedActions.push(\"storageSnapshot\");\n             }\n \n+            if (jsonObj.hypervisor == 'KVM' && jsonObj.pooltype == 'PowerFlex') {\n+                allowedActions.push(\"snapshot\");\n+            }\n+", "originalCommit": "0185a0f3f4464e741e21f16f46fc7f951250e8a1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjAxNzcyMg==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r526017722", "bodyText": "@sureshanaparti do we need a Primate change for this or is it already handled there?\n\n@shwstppr Updated this change in primate. PR: apache/cloudstack-primate#863.", "author": "sureshanaparti", "createdAt": "2020-11-18T11:34:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTM2NDA2NQ=="}], "type": "inlineReview"}, {"oid": "62c918d1121d22ba5bb6310180c1b7a146ef7120", "url": "https://github.com/apache/cloudstack/commit/62c918d1121d22ba5bb6310180c1b7a146ef7120", "message": "Storage plugin for Dell EMC PowerFlex/ScaleIO (formerly VxFlexOS)\n\nThis enables support for PowerFlex/ScaleIO (v3.5 onwards) storage pool as a primary storage in CloudStack\n\nOther improvements addressed in addition to PowerFlex/ScaleIO support:\n\n- Added support for config drives in host cache for KVM\n\t=> Changed configuration \"vm.configdrive.primarypool.enabled\" scope from Global to Zone level\n\t=> Introduced new zone level configuration \"vm.configdrive.force.host.cache.use\" (default: false) to force host cache for config drives\n\t=> Introduced new zone level configuration \"vm.configdrive.use.host.cache.on.unsupported.pool\" (default: true) to use host cache for config drives when storage pool doesn't support config drive\n\t=> Added new parameter \"host.cache.location\" (default: /var/cache/cloud) in KVM agent.properties for specifying the host cache path and create config drives on the \"/config\" directory on the host cache path\n\t=> Maintain the config drive location and use it when required on any config drive operation (migrate, delete)\n\n- Detect virtual size from the template URL while registering direct download qcow2 (of KVM hypervisor) templates\n\n- Updated full deployment destination for preparing the network(s) on VM start\n\n- Propagate the direct download certificates uploaded to the newly added KVM hosts\n\n- Discover the template size for direct download templates using any available host from the zones specified on template registration\n\t=> When zones are not specified while registering template, template size discovery is performed using any available host, which is picked up randomly from one of the available zones\n\n- Release the VM resources when VM is sync-ed to Stopped state on PowerReportMissing (after graceful period)\n\n- Retry VM deployment/start when the host cannot grant access to volume/template\n\n- Mark never-used or downloaded templates as Destroyed on deletion, without sending any DeleteCommand\n\t=> Do not trigger any DeleteCommand for never-used or downloaded templates as these doesn't exist and cannot be deleted from the datastore\n\n- Check the router filesystem is writable or not, before performing health checks\n\t=> Introduce a new test \"filesystem.writable.test\" to check the filesystem is writable or not\n\t=> The router health checks keeps the config info at \"/var/cache/cloud\" and updates the monitor results at \"/root\" for health checks, both are different partitions. So, test at both the locations.\n\t=> Added new script: \"filesystem_writable_check.py\" at /opt/cloud/bin/ to check the filesystem is writable or not\n\n- Fixed NPE issue, template is null for DATA disks. Copy template to target storage for ROOT disk (with template id), skip DATA disk(s)", "committedDate": "2020-11-23T07:24:37Z", "type": "forcePushed"}, {"oid": "0628aaf9d63d6dbf1c90f35552e10d8a77f7befa", "url": "https://github.com/apache/cloudstack/commit/0628aaf9d63d6dbf1c90f35552e10d8a77f7befa", "message": "Addressed some issues for few operations on PowerFlex storage pool.\n\n- Updated migration volume operation to sync the status and wait for migration to complete.\n\n- Updated VM Snapshot naming, for uniqueness in ScaleIO volume name when more than one volume exists in the VM.\n\n- Added sync lock while spooling managed storage template before volume creation from the template (non-direct download).\n\n- Updated resize volume error message string.\n\n- Blocked the below operations on PowerFlex storage pool:\n  -> Extract Volume\n  -> Create Snapshot for VMSnapshot", "committedDate": "2020-12-15T16:24:35Z", "type": "forcePushed"}, {"oid": "dbaa2e70e342ad6a7c45edfef6715cc7029055d5", "url": "https://github.com/apache/cloudstack/commit/dbaa2e70e342ad6a7c45edfef6715cc7029055d5", "message": "Added the PowerFlex/ScaleIO client connection pool to manage the ScaleIO gateway clients, which uses a single gateway client per Powerflex/ScaleIO storage pool and renews it when the session token expires.\n\n- The token is valid for 8 hours from the time it was created, unless there has been no activity for 10 minutes.\n  Reference: https://cpsdocs.dellemc.com/bundle/PF_REST_API_RG/page/GUID-92430F19-9F44-42B6-B898-87D5307AE59B.html\n\nOther fixes included:\n\n- Fail the VM deployment when the host specified in the deployVirtualMachine cmd is not in the right state (i.e. either Resource State is not Enabled or Status is not Up)\n\n- Use the physical file size of the template to check the free space availability on the host, while downloading the direct download templates.\n\n- Perform basic tests (for connectivity and file system) on router before updating the health check config data\n\t=> Validate the basic tests (connectivity and file system check) on router\n\t=> Cleanup the health check results when router is destroyed", "committedDate": "2021-01-12T13:06:14Z", "type": "forcePushed"}, {"oid": "a7e1e9e2ddd8b419924f696a6614a5ec39f7280e", "url": "https://github.com/apache/cloudstack/commit/a7e1e9e2ddd8b419924f696a6614a5ec39f7280e", "message": "Added support for PowerFlex/ScaleIO volume migration across different PowerFlex storage instances.\n\n- findStoragePoolsForMigration API returns PowerFlex pool(s) of different instance as suitable pool(s), for volume(s) on PowerFlex storage pool.\n- Volume(s) with snapshots are not allowed to migrate to different PowerFlex instance.\n- Volume(s) of running VM are not allowed to migrate to other PowerFlex storage pools.\n- Volume migration from PowerFlex pool to Non-PowerFlex pool, and vice versa are not supported.", "committedDate": "2021-01-25T12:15:19Z", "type": "forcePushed"}, {"oid": "76986b71a7740a4b3a1d31190eb9896b5ea195e3", "url": "https://github.com/apache/cloudstack/commit/76986b71a7740a4b3a1d31190eb9896b5ea195e3", "message": "Added support for PowerFlex/ScaleIO volume migration across different PowerFlex storage instances.\n\n- findStoragePoolsForMigration API returns PowerFlex pool(s) of different instance as suitable pool(s), for volume(s) on PowerFlex storage pool.\n- Volume(s) with snapshots are not allowed to migrate to different PowerFlex instance.\n- Volume(s) of running VM are not allowed to migrate to other PowerFlex storage pools.\n- Volume migration from PowerFlex pool to Non-PowerFlex pool, and vice versa are not supported.", "committedDate": "2021-02-01T07:15:14Z", "type": "forcePushed"}, {"oid": "a0a793dea03ea61cd7ea8d38e06c22aef1d63aaa", "url": "https://github.com/apache/cloudstack/commit/a0a793dea03ea61cd7ea8d38e06c22aef1d63aaa", "message": "Added support for PowerFlex/ScaleIO volume migration across different PowerFlex storage instances.\n\n- findStoragePoolsForMigration API returns PowerFlex pool(s) of different instance as suitable pool(s), for volume(s) on PowerFlex storage pool.\n- Volume(s) with snapshots are not allowed to migrate to different PowerFlex instance.\n- Volume(s) of running VM are not allowed to migrate to other PowerFlex storage pools.\n- Volume migration from PowerFlex pool to Non-PowerFlex pool, and vice versa are not supported.", "committedDate": "2021-02-02T05:39:52Z", "type": "forcePushed"}, {"oid": "2d05a143207843103f4384bc9e497c19b58eae58", "url": "https://github.com/apache/cloudstack/commit/2d05a143207843103f4384bc9e497c19b58eae58", "message": "Added support for PowerFlex/ScaleIO volume migration across different PowerFlex storage instances.\n\n- findStoragePoolsForMigration API returns PowerFlex pool(s) of different instance as suitable pool(s), for volume(s) on PowerFlex storage pool.\n- Volume(s) with snapshots are not allowed to migrate to different PowerFlex instance.\n- Volume(s) of running VM are not allowed to migrate to other PowerFlex storage pools.\n- Volume migration from PowerFlex pool to Non-PowerFlex pool, and vice versa are not supported.", "committedDate": "2021-02-02T13:11:11Z", "type": "forcePushed"}, {"oid": "455b0b6e034334afa5996c05e7cf109dbf311e74", "url": "https://github.com/apache/cloudstack/commit/455b0b6e034334afa5996c05e7cf109dbf311e74", "message": "Fixed change service offering smoke tests in test_service_offerings.py, test_vm_snapshots.py", "committedDate": "2021-02-05T08:46:50Z", "type": "forcePushed"}, {"oid": "24a0261c8cc909d4a0a517b0cfebaf106fb35830", "url": "https://github.com/apache/cloudstack/commit/24a0261c8cc909d4a0a517b0cfebaf106fb35830", "message": "Added new response parameter \u201csupportsStorageSnapshot\u201d (true/false) to volume response, and Updated UI to hide the async backup option while taking snapshot for volume(s) with storage snapshot support.", "committedDate": "2021-02-10T04:37:42Z", "type": "forcePushed"}, {"oid": "bc4bce2737ee97e91c5e0fc478e85c6cbe925e3b", "url": "https://github.com/apache/cloudstack/commit/bc4bce2737ee97e91c5e0fc478e85c6cbe925e3b", "message": "Fix to remove the duplicate zone wide pools listed while finding storage pools for migration", "committedDate": "2021-02-12T12:44:54Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NTY0ODEzOQ==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r575648139", "bodyText": "Hi @sureshanaparti, may I suggest here to get the VMSnapshotStrategy instead of checking which is the storage pool type? If it's an instance of DefaultVMSnapshotStrategy to get into the statement. In this case, the other storage plugins could implement their own VM snapshot strategy, without checking here which is the storage pool type. I saw that Solidfire's API has a group snapshot (maybe and others have it). We at StorPool also have this functionality (but for now we have a workaround for this). I guess someday it will be easier for the plugins to adopt this functionality", "author": "slavkap", "createdAt": "2021-02-13T10:01:47Z", "path": "server/src/main/java/com/cloud/vm/snapshot/VMSnapshotManagerImpl.java", "diffHunk": "@@ -358,9 +363,33 @@ public VMSnapshot allocVMSnapshot(Long vmId, String vsDisplayName, String vsDesc\n             throw new InvalidParameterValueException(\"Can not snapshot memory when VM is not in Running state\");\n         }\n \n+        List<VolumeVO> rootVolumes = _volumeDao.findReadyRootVolumesByInstance(userVmVo.getId());\n+        if (rootVolumes == null || rootVolumes.isEmpty()) {\n+            throw new CloudRuntimeException(\"Unable to find root volume for the user vm:\" + userVmVo.getUuid());\n+        }\n+\n+        VolumeVO rootVolume = rootVolumes.get(0);\n+        StoragePoolVO rootVolumePool = _storagePoolDao.findById(rootVolume.getPoolId());\n+        if (rootVolumePool == null) {\n+            throw new CloudRuntimeException(\"Unable to find root volume storage pool for the user vm:\" + userVmVo.getUuid());\n+        }\n+\n         // for KVM, only allow snapshot with memory when VM is in running state\n-        if (userVmVo.getHypervisorType() == HypervisorType.KVM && userVmVo.getState() == State.Running && !snapshotMemory) {\n-            throw new InvalidParameterValueException(\"KVM VM does not allow to take a disk-only snapshot when VM is in running state\");\n+        if (userVmVo.getHypervisorType() == HypervisorType.KVM) {\n+            if (rootVolumePool.getPoolType() != Storage.StoragePoolType.PowerFlex) {", "originalCommit": "bc4bce2737ee97e91c5e0fc478e85c6cbe925e3b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTA5MDI3OA==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r579090278", "bodyText": "@slavkap Thanks for the review and suggestions. Can not get the VMSnapshotStrategy to use here, as VMSnapshot object is not yet created. The check here is a pre-creation phase check, and  VMSnapshot object is not created when it is not supported. VMSnapshotStrategy is currently being used to check (canHandle(VMSnapshot)) and perform the operations (take VM snapshot, revert VM snapshots, delete VM snapshot) allowed, on the VMSnapshot object.", "author": "sureshanaparti", "createdAt": "2021-02-19T10:40:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NTY0ODEzOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTExNTEyOA==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r579115128", "bodyText": "Thanks, @sureshanaparti, for the reply! My bad that I didn't look below in the code, where the VMSnapshot object is created. My suggestion about this functionality was to be more general for the rest of the plugins if somebody wants to integrate with it. I will try to find a solution in our PR", "author": "slavkap", "createdAt": "2021-02-19T11:24:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NTY0ODEzOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NTY3NzA1MA==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r575677050", "bodyText": "If you consider using VMSnapshotStrategy, this check won't be needed because you're checking in ScaleIOVMSnapshotStrategy.canHandle() that all volumes are on PowerFlex. Also, this PR #3724 (if it gets in someday) will handle snapshots of the volumes with different storage pool types", "author": "slavkap", "createdAt": "2021-02-13T15:09:48Z", "path": "server/src/main/java/com/cloud/vm/snapshot/VMSnapshotManagerImpl.java", "diffHunk": "@@ -358,9 +363,33 @@ public VMSnapshot allocVMSnapshot(Long vmId, String vsDisplayName, String vsDesc\n             throw new InvalidParameterValueException(\"Can not snapshot memory when VM is not in Running state\");\n         }\n \n+        List<VolumeVO> rootVolumes = _volumeDao.findReadyRootVolumesByInstance(userVmVo.getId());\n+        if (rootVolumes == null || rootVolumes.isEmpty()) {\n+            throw new CloudRuntimeException(\"Unable to find root volume for the user vm:\" + userVmVo.getUuid());\n+        }\n+\n+        VolumeVO rootVolume = rootVolumes.get(0);\n+        StoragePoolVO rootVolumePool = _storagePoolDao.findById(rootVolume.getPoolId());\n+        if (rootVolumePool == null) {\n+            throw new CloudRuntimeException(\"Unable to find root volume storage pool for the user vm:\" + userVmVo.getUuid());\n+        }\n+\n         // for KVM, only allow snapshot with memory when VM is in running state\n-        if (userVmVo.getHypervisorType() == HypervisorType.KVM && userVmVo.getState() == State.Running && !snapshotMemory) {\n-            throw new InvalidParameterValueException(\"KVM VM does not allow to take a disk-only snapshot when VM is in running state\");\n+        if (userVmVo.getHypervisorType() == HypervisorType.KVM) {\n+            if (rootVolumePool.getPoolType() != Storage.StoragePoolType.PowerFlex) {\n+                if (userVmVo.getState() == State.Running && !snapshotMemory) {\n+                    throw new InvalidParameterValueException(\"KVM VM does not allow to take a disk-only snapshot when VM is in running state\");\n+                }\n+            } else {\n+                if (snapshotMemory) {\n+                    throw new InvalidParameterValueException(\"Can not snapshot memory for PowerFlex storage pool\");\n+                }\n+\n+                // All volumes should be on the same PowerFlex storage pool for VM Snapshot\n+                if (!isVolumesOfUserVmOnSameStoragePool(userVmVo.getId(), rootVolumePool.getId())) {", "originalCommit": "bc4bce2737ee97e91c5e0fc478e85c6cbe925e3b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3OTA5MDQwNA==", "url": "https://github.com/apache/cloudstack/pull/4304#discussion_r579090404", "bodyText": "The check here does't allow to create a VMSnapshot object when all the volumes are not on the PowerFlex/ScaleIO pool. ScaleIOVMSnapshotStrategy.canHandle() re-confirms and allows the VM Snapshot operations that are supported by ScaleIOVMSnapshotStrategy.", "author": "sureshanaparti", "createdAt": "2021-02-19T10:40:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NTY3NzA1MA=="}], "type": "inlineReview"}, {"oid": "11c81b09a49d45136c342accc28c50ca279ce5a5", "url": "https://github.com/apache/cloudstack/commit/11c81b09a49d45136c342accc28c50ca279ce5a5", "message": "Storage plugin for Dell EMC PowerFlex/ScaleIO (formerly VxFlexOS)\n\nThis enables support for PowerFlex/ScaleIO (v3.5 onwards) storage pool as a primary storage in CloudStack\n\nOther improvements addressed in addition to PowerFlex/ScaleIO support:\n\n- Added support for config drives in host cache for KVM\n\t=> Changed configuration \"vm.configdrive.primarypool.enabled\" scope from Global to Zone level\n\t=> Introduced new zone level configuration \"vm.configdrive.force.host.cache.use\" (default: false) to force host cache for config drives\n\t=> Introduced new zone level configuration \"vm.configdrive.use.host.cache.on.unsupported.pool\" (default: true) to use host cache for config drives when storage pool doesn't support config drive\n\t=> Added new parameter \"host.cache.location\" (default: /var/cache/cloud) in KVM agent.properties for specifying the host cache path and create config drives on the \"/config\" directory on the host cache path\n\t=> Maintain the config drive location and use it when required on any config drive operation (migrate, delete)\n\n- Detect virtual size from the template URL while registering direct download qcow2 (of KVM hypervisor) templates\n\n- Updated full deployment destination for preparing the network(s) on VM start\n\n- Propagate the direct download certificates uploaded to the newly added KVM hosts\n\n- Discover the template size for direct download templates using any available host from the zones specified on template registration\n\t=> When zones are not specified while registering template, template size discovery is performed using any available host, which is picked up randomly from one of the available zones\n\n- Release the VM resources when VM is sync-ed to Stopped state on PowerReportMissing (after graceful period)\n\n- Retry VM deployment/start when the host cannot grant access to volume/template\n\n- Mark never-used or downloaded templates as Destroyed on deletion, without sending any DeleteCommand\n\t=> Do not trigger any DeleteCommand for never-used or downloaded templates as these doesn't exist and cannot be deleted from the datastore\n\n- Check the router filesystem is writable or not, before performing health checks\n\t=> Introduce a new test \"filesystem.writable.test\" to check the filesystem is writable or not\n\t=> The router health checks keeps the config info at \"/var/cache/cloud\" and updates the monitor results at \"/root\" for health checks, both are different partitions. So, test at both the locations.\n\t=> Added new script: \"filesystem_writable_check.py\" at /opt/cloud/bin/ to check the filesystem is writable or not\n\n- Fixed NPE issue, template is null for DATA disks. Copy template to target storage for ROOT disk (with template id), skip DATA disk(s)", "committedDate": "2021-02-18T16:02:51Z", "type": "commit"}, {"oid": "6085c064c1f6dbf5f5d828fc2d5ca166ed2e2a9e", "url": "https://github.com/apache/cloudstack/commit/6085c064c1f6dbf5f5d828fc2d5ca166ed2e2a9e", "message": "Addressed some issues for few operations on PowerFlex storage pool.\n\n- Updated migration volume operation to sync the status and wait for migration to complete.\n\n- Updated VM Snapshot naming, for uniqueness in ScaleIO volume name when more than one volume exists in the VM.\n\n- Added sync lock while spooling managed storage template before volume creation from the template (non-direct download).\n\n- Updated resize volume error message string.\n\n- Blocked the below operations on PowerFlex storage pool:\n  -> Extract Volume\n  -> Create Snapshot for VMSnapshot", "committedDate": "2021-02-18T16:02:51Z", "type": "commit"}, {"oid": "5cce9623e7f352f018a351eef1c744ac753709ef", "url": "https://github.com/apache/cloudstack/commit/5cce9623e7f352f018a351eef1c744ac753709ef", "message": "Added the PowerFlex/ScaleIO client connection pool to manage the ScaleIO gateway clients, which uses a single gateway client per Powerflex/ScaleIO storage pool and renews it when the session token expires.\n\n- The token is valid for 8 hours from the time it was created, unless there has been no activity for 10 minutes.\n  Reference: https://cpsdocs.dellemc.com/bundle/PF_REST_API_RG/page/GUID-92430F19-9F44-42B6-B898-87D5307AE59B.html\n\nOther fixes included:\n\n- Fail the VM deployment when the host specified in the deployVirtualMachine cmd is not in the right state (i.e. either Resource State is not Enabled or Status is not Up)\n\n- Use the physical file size of the template to check the free space availability on the host, while downloading the direct download templates.\n\n- Perform basic tests (for connectivity and file system) on router before updating the health check config data\n\t=> Validate the basic tests (connectivity and file system check) on router\n\t=> Cleanup the health check results when router is destroyed", "committedDate": "2021-02-18T16:07:15Z", "type": "commit"}, {"oid": "2de8944bc31f907c85527b5bfbec3616cf1f67cf", "url": "https://github.com/apache/cloudstack/commit/2de8944bc31f907c85527b5bfbec3616cf1f67cf", "message": "Updated PowerFlex/ScaleIO storage plugin version to 4.16.0.0", "committedDate": "2021-02-18T16:07:15Z", "type": "commit"}, {"oid": "3a7c3db72fa49fd3b78a65581452dd9062639c85", "url": "https://github.com/apache/cloudstack/commit/3a7c3db72fa49fd3b78a65581452dd9062639c85", "message": "UI Changes to support storage plugin for PowerFlex/ScaleIO storage pool.\n- PowerFlex pool URL generated from the UI inputs(Gateway, Username, Password, Storage Pool) when adding \"PowerFlex\" Primary Storage\n- Updated protocol to \"custom\" for PowerFlex provider\n- Allow VM Snapshot for stopped VM on KVM hypervisor and PowerFlex/ScaleIO storage pool\n\nand Minor improvements in PowerFlex/ScaleIO storage plugin code", "committedDate": "2021-02-18T16:07:15Z", "type": "commit"}, {"oid": "71252ea387914d3d917ba72f30fb0ad25e0d38f1", "url": "https://github.com/apache/cloudstack/commit/71252ea387914d3d917ba72f30fb0ad25e0d38f1", "message": "Added support for PowerFlex/ScaleIO volume migration across different PowerFlex storage instances.\n\n- findStoragePoolsForMigration API returns PowerFlex pool(s) of different instance as suitable pool(s), for volume(s) on PowerFlex storage pool.\n- Volume(s) with snapshots are not allowed to migrate to different PowerFlex instance.\n- Volume(s) of running VM are not allowed to migrate to other PowerFlex storage pools.\n- Volume migration from PowerFlex pool to Non-PowerFlex pool, and vice versa are not supported.", "committedDate": "2021-02-18T16:07:16Z", "type": "commit"}, {"oid": "602a708662f2ab50aa633cbd122df5098d491eba", "url": "https://github.com/apache/cloudstack/commit/602a708662f2ab50aa633cbd122df5098d491eba", "message": "Fixed change service offering smoke tests in test_service_offerings.py, test_vm_snapshots.py", "committedDate": "2021-02-18T16:07:16Z", "type": "commit"}, {"oid": "9e92647210268c21ec2f1769816da28505f718f4", "url": "https://github.com/apache/cloudstack/commit/9e92647210268c21ec2f1769816da28505f718f4", "message": "Added the PowerFlex/ScaleIO volume/snapshot name to the paths of respective CloudStack resources (Templates, Volumes, Snapshots and VM Snapshots)", "committedDate": "2021-02-18T16:07:16Z", "type": "commit"}, {"oid": "1c16a1f97e499def2c50ba63aaaad3b867d8fbc2", "url": "https://github.com/apache/cloudstack/commit/1c16a1f97e499def2c50ba63aaaad3b867d8fbc2", "message": "Added new response parameter \u201csupportsStorageSnapshot\u201d (true/false) to volume response, and Updated UI to hide the async backup option while taking snapshot for volume(s) with storage snapshot support.", "committedDate": "2021-02-18T16:07:16Z", "type": "commit"}, {"oid": "ea6f7f1f4affa5419fbb57a2e084656e83fa74bc", "url": "https://github.com/apache/cloudstack/commit/ea6f7f1f4affa5419fbb57a2e084656e83fa74bc", "message": "Fix to remove the duplicate zone wide pools listed while finding storage pools for migration", "committedDate": "2021-02-18T16:07:16Z", "type": "commit"}, {"oid": "dc91003e987b3c9a89db99792f54758608ac44c3", "url": "https://github.com/apache/cloudstack/commit/dc91003e987b3c9a89db99792f54758608ac44c3", "message": "Updated PowerFlex/ScaleIO volume migration checks and rollback migration on failure", "committedDate": "2021-02-18T16:07:16Z", "type": "commit"}, {"oid": "010dfeef1bfd6f26e58724d998833f7657b29e6e", "url": "https://github.com/apache/cloudstack/commit/010dfeef1bfd6f26e58724d998833f7657b29e6e", "message": "Fixed the PowerFlex/ScaleIO volume name inconsistency issue in the volume path after migration, due to rename failure", "committedDate": "2021-02-18T16:07:16Z", "type": "commit"}, {"oid": "010dfeef1bfd6f26e58724d998833f7657b29e6e", "url": "https://github.com/apache/cloudstack/commit/010dfeef1bfd6f26e58724d998833f7657b29e6e", "message": "Fixed the PowerFlex/ScaleIO volume name inconsistency issue in the volume path after migration, due to rename failure", "committedDate": "2021-02-18T16:07:16Z", "type": "forcePushed"}]}