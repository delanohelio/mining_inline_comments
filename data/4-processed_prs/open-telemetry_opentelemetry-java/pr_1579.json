{"pr_number": 1579, "pr_title": "More aggresive version of BatchSpanProcessor", "pr_createdAt": "2020-08-23T15:30:41Z", "pr_url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579", "timeline": [{"oid": "15260bdd59bdcdf60819d5e414080c557c8904e8", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/15260bdd59bdcdf60819d5e414080c557c8904e8", "message": "More aggresive version of BatchSpanProcessor", "committedDate": "2020-08-23T15:32:59Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTI5MjY3Nw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475292677", "bodyText": "Yeah if we block between exports the code gets cut down a lot. I think it's nice to keep things async though if we can to reduce context switches.", "author": "anuraaga", "createdAt": "2020-08-24T00:58:19Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -164,146 +152,121 @@ public void forceFlush() {\n \n     private static final BoundLongCounter droppedSpans;\n \n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n     private static final Logger logger = Logger.getLogger(Worker.class.getName());\n     private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n+    private final long scheduleDelayNanos;\n     private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n     private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n \n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n+    private long nextExportTime;\n+\n+    private final BlockingQueue<ReadableSpan> queue;\n+\n+    @Nullable private volatile CompletableResultCode flushRequested = null;\n+    private volatile boolean continueWork = true;\n+    private final ArrayList<SpanData> batch;\n \n     private Worker(\n         SpanExporter spanExporter,\n         long scheduleDelayMillis,\n-        int maxQueueSize,\n         int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n+        int exporterTimeoutMillis,\n+        BlockingQueue<ReadableSpan> queue) {\n       this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n+      this.scheduleDelayNanos = TimeUnit.MILLISECONDS.toNanos(scheduleDelayMillis);\n       this.maxExportBatchSize = maxExportBatchSize;\n       this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+      this.queue = queue;\n+      this.batch = new ArrayList<>(this.maxExportBatchSize);\n     }\n \n     private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n+      if (!queue.offer(span)) {\n+        droppedSpans.add(1);\n       }\n     }\n \n     @Override\n     public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+      updateNextExportTime();\n+\n+      while (continueWork) {\n+        try {\n+          if (flushRequested != null) {\n+            flush();\n+          }\n+\n+          ReadableSpan lastElement = queue.poll(100, TimeUnit.MILLISECONDS);\n+          if (lastElement != null) {\n+            batch.add(lastElement.toSpanData());\n+          }\n+\n+          if (batch.size() >= maxExportBatchSize || System.nanoTime() >= nextExportTime) {\n+            exportCurrentBatch();\n+            updateNextExportTime();\n           }\n-          spansCopy = new ArrayList<>(spansList);\n-          spansList.clear();\n+\n+        } catch (InterruptedException e) {\n+          Thread.currentThread().interrupt();\n+          return;\n+        }\n+      }\n+    }\n+\n+    private void flush() {\n+      int spansToFlush = queue.size();\n+      while (spansToFlush > 0) {\n+        ReadableSpan span = queue.poll();\n+        assert span != null;\n+        batch.add(span.toSpanData());\n+        spansToFlush--;\n+        if (batch.size() >= maxExportBatchSize) {\n+          exportCurrentBatch();\n         }\n-        // Execute the batch export outside the synchronized to not block all producers.\n-        exportBatches(spansCopy);\n       }\n+      exportCurrentBatch();\n+      Objects.requireNonNull(flushRequested).succeed();\n+      flushRequested = null;\n+    }\n+\n+    private void updateNextExportTime() {\n+      nextExportTime = System.nanoTime() + scheduleDelayNanos;\n     }\n \n     private void shutdown() {\n       forceFlush();\n-      timer.cancel();\n       spanExporter.shutdown();\n+      continueWork = false;\n     }\n \n     private void forceFlush() {\n-      ArrayList<ReadableSpan> spansCopy;\n-      synchronized (monitor) {\n-        spansCopy = new ArrayList<>(spansList);\n-        spansList.clear();\n+      CompletableResultCode flushResult = new CompletableResultCode();\n+      this.flushRequested = flushResult;\n+      try {\n+        flushResult.join();\n+      } catch (InterruptedException e) {\n+        Thread.currentThread().interrupt();\n       }\n-      // Execute the batch export outside the synchronized to not block all producers.\n-      exportBatches(spansCopy);\n     }\n \n-    private void exportBatches(ArrayList<ReadableSpan> spanList) {\n-      // TODO: Record a counter for pushed spans.\n-      for (int i = 0; i < spanList.size(); ) {\n-        int lastIndexToTake = Math.min(i + maxExportBatchSize, spanList.size());\n-        onBatchExport(createSpanDataForExport(spanList, i, lastIndexToTake));\n-        i = lastIndexToTake;\n+    private void exportCurrentBatch() {\n+      if (batch.isEmpty()) {\n+        return;\n       }\n-    }\n \n-    private static List<SpanData> createSpanDataForExport(\n-        List<ReadableSpan> spanList, int startIndex, int endIndex) {\n-      List<SpanData> spanDataBuffer = new ArrayList<>(endIndex - startIndex);\n-      for (int i = startIndex; i < endIndex; i++) {\n-        spanDataBuffer.add(spanList.get(i).toSpanData());\n-        // Remove the reference to the ReadableSpan to allow GC to free the memory.\n-        spanList.set(i, null);\n-      }\n-      return Collections.unmodifiableList(spanDataBuffer);\n-    }\n-\n-    // Exports the list of SpanData to the SpanExporter.\n-    @SuppressWarnings(\"BooleanParameter\")\n-    private void onBatchExport(final List<SpanData> spans) {\n-      if (exportAvailable.compareAndSet(true, false)) {\n-        try {\n-          final CompletableResultCode result = spanExporter.export(spans);\n-          result.whenComplete(\n-              new Runnable() {\n-                @Override\n-                public void run() {\n-                  if (!result.isSuccess()) {\n-                    logger.log(Level.FINE, \"Exporter failed\");\n-                  }\n-                  exportAvailable.set(true);\n-                }\n-              });\n-          timer.schedule(\n-              new TimerTask() {\n-                @Override\n-                public void run() {\n-                  result.fail();\n-                }\n-              },\n-              exporterTimeoutMillis);\n-        } catch (Exception e) {\n-          logger.log(Level.WARNING, \"Exporter threw an Exception\", e);\n+      try {\n+        final CompletableResultCode result = spanExporter.export(batch);\n+        result.join(exporterTimeoutMillis, TimeUnit.MILLISECONDS);", "originalCommit": "5bde48dd459a26be6cdcc5e775e43d73971b7e81", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMzNTkxNA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475335914", "bodyText": "I am not sure about that. We have to prevent concurrent calls to export and we have to have timeouts. IMO timed joins is the easiest way to achieve this. At least until benchmarking shows that this is too expensive.", "author": "iNikem", "createdAt": "2020-08-24T04:29:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTI5MjY3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzU4OTMwMQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r477589301", "bodyText": "Join shouldn\u2019t have a timeout. There\u2019s nothing you can really do if you can\u2019t join. This is why CompleteableFuture and even back to pthreads has no join.\nIf an exporter doesn\u2019t return then there is nothing that can be done here other than fail it\u2019s result. Exporters can then act on a result failure and halt their activity.", "author": "huntc", "createdAt": "2020-08-26T21:06:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTI5MjY3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxMzM3MQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475313371", "bodyText": "CompletableFuture.join doesn't throw interrupted exception so I think it's ok to squash that here too (don't know if it's best practice for interruptions but may as well copy the JDK)", "author": "anuraaga", "createdAt": "2020-08-24T02:43:02Z", "path": "sdk/common/src/main/java/io/opentelemetry/sdk/common/export/CompletableResultCode.java", "diffHunk": "@@ -107,4 +109,33 @@ public CompletableResultCode whenComplete(Runnable action) {\n     }\n     return this;\n   }\n+\n+  /** Waits until this instances completes, regardless of the result. */\n+  public void join() throws InterruptedException {\n+    final CountDownLatch latch = new CountDownLatch(1);\n+    whenComplete(\n+        new Runnable() {\n+          @Override\n+          public void run() {\n+            latch.countDown();\n+          }\n+        });\n+    latch.await();\n+  }\n+\n+  /** Calls {@link #fail()} if times out. */\n+  public void join(long timeout, TimeUnit unit) throws InterruptedException {", "originalCommit": "5bde48dd459a26be6cdcc5e775e43d73971b7e81", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMzNjIyNQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475336225", "bodyText": "You mean catch that inside the method?", "author": "iNikem", "createdAt": "2020-08-24T04:31:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxMzM3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMzNzc5Mw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475337793", "bodyText": "Yeah - presumably that's what CompletableFuture does since it doesn't declare throwing InterruptedException", "author": "anuraaga", "createdAt": "2020-08-24T04:36:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxMzM3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxMzQzOA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475313438", "bodyText": "I think we can leave out this method, joining without timeout is rarely a good idea.", "author": "anuraaga", "createdAt": "2020-08-24T02:43:22Z", "path": "sdk/common/src/main/java/io/opentelemetry/sdk/common/export/CompletableResultCode.java", "diffHunk": "@@ -107,4 +109,33 @@ public CompletableResultCode whenComplete(Runnable action) {\n     }\n     return this;\n   }\n+\n+  /** Waits until this instances completes, regardless of the result. */\n+  public void join() throws InterruptedException {", "originalCommit": "5bde48dd459a26be6cdcc5e775e43d73971b7e81", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMzNjYzOQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475336639", "bodyText": "I use it forceFlush. There is no good option how long should I wait there. And if you say that forceFlush should be async, I will just change my argument to shutdown :)", "author": "iNikem", "createdAt": "2020-08-24T04:32:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxMzQzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMzNzkzNw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475337937", "bodyText": "Well there must be some value better than infinity right? My goto timeout is 10 seconds when lacking any other options, I think even shutdown shouldn't block forever. Apps that accept SIGTERM but may stay stuck until an explicit SIGKILL are frowned upon from what I understand we should probably use something.", "author": "anuraaga", "createdAt": "2020-08-24T04:37:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxMzQzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxMzc5MA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475313790", "bodyText": "Is there a reason to wait for a constant here instead of until the next export time?", "author": "anuraaga", "createdAt": "2020-08-24T02:45:07Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -164,146 +152,121 @@ public void forceFlush() {\n \n     private static final BoundLongCounter droppedSpans;\n \n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n     private static final Logger logger = Logger.getLogger(Worker.class.getName());\n     private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n+    private final long scheduleDelayNanos;\n     private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n     private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n \n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n+    private long nextExportTime;\n+\n+    private final BlockingQueue<ReadableSpan> queue;\n+\n+    @Nullable private volatile CompletableResultCode flushRequested = null;\n+    private volatile boolean continueWork = true;\n+    private final ArrayList<SpanData> batch;\n \n     private Worker(\n         SpanExporter spanExporter,\n         long scheduleDelayMillis,\n-        int maxQueueSize,\n         int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n+        int exporterTimeoutMillis,\n+        BlockingQueue<ReadableSpan> queue) {\n       this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n+      this.scheduleDelayNanos = TimeUnit.MILLISECONDS.toNanos(scheduleDelayMillis);\n       this.maxExportBatchSize = maxExportBatchSize;\n       this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+      this.queue = queue;\n+      this.batch = new ArrayList<>(this.maxExportBatchSize);\n     }\n \n     private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n+      if (!queue.offer(span)) {\n+        droppedSpans.add(1);\n       }\n     }\n \n     @Override\n     public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+      updateNextExportTime();\n+\n+      while (continueWork) {\n+        try {\n+          if (flushRequested != null) {\n+            flush();\n+          }\n+\n+          ReadableSpan lastElement = queue.poll(100, TimeUnit.MILLISECONDS);", "originalCommit": "5bde48dd459a26be6cdcc5e775e43d73971b7e81", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMzNzExMQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475337111", "bodyText": "Hm... I will think about that. My first concern is the introduction of System.nanoTime on essentially every poll.", "author": "iNikem", "createdAt": "2020-08-24T04:34:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxMzc5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMzODQ2MQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475338461", "bodyText": "Ah I think I meant scheduleDelayMillis not next export time, sorry. But now I realize it's because we need to respond to the flush sooner than scheduleDelayMillis", "author": "anuraaga", "createdAt": "2020-08-24T04:39:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxMzc5MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTM1OTA0OA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475359048", "bodyText": "Poll certainly cannot block for scheduleDelayMillis if it is already almost time to export, but we have partial batch.", "author": "iNikem", "createdAt": "2020-08-24T05:59:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxMzc5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxMzkzNg==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475313936", "bodyText": "It's probably a nice win to add a drainTo here to get as many elements as possible. In the case where there are constantly spans, we'll be able to handle them with less queue lock acquisitions and tighter loop. drainTo has this very tight loop inside the lock which JVM should deal well with.\nwhile (i < n) {\n                    @SuppressWarnings(\"unchecked\")\n                    E e = (E) items[take];\n                    c.add(e);\n                    items[take] = null;\n                    if (++take == items.length) take = 0;\n                    i++;\n                }", "author": "anuraaga", "createdAt": "2020-08-24T02:45:55Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -164,146 +152,121 @@ public void forceFlush() {\n \n     private static final BoundLongCounter droppedSpans;\n \n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n     private static final Logger logger = Logger.getLogger(Worker.class.getName());\n     private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n+    private final long scheduleDelayNanos;\n     private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n     private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n \n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n+    private long nextExportTime;\n+\n+    private final BlockingQueue<ReadableSpan> queue;\n+\n+    @Nullable private volatile CompletableResultCode flushRequested = null;\n+    private volatile boolean continueWork = true;\n+    private final ArrayList<SpanData> batch;\n \n     private Worker(\n         SpanExporter spanExporter,\n         long scheduleDelayMillis,\n-        int maxQueueSize,\n         int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n+        int exporterTimeoutMillis,\n+        BlockingQueue<ReadableSpan> queue) {\n       this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n+      this.scheduleDelayNanos = TimeUnit.MILLISECONDS.toNanos(scheduleDelayMillis);\n       this.maxExportBatchSize = maxExportBatchSize;\n       this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+      this.queue = queue;\n+      this.batch = new ArrayList<>(this.maxExportBatchSize);\n     }\n \n     private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n+      if (!queue.offer(span)) {\n+        droppedSpans.add(1);\n       }\n     }\n \n     @Override\n     public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+      updateNextExportTime();\n+\n+      while (continueWork) {\n+        try {\n+          if (flushRequested != null) {\n+            flush();\n+          }\n+\n+          ReadableSpan lastElement = queue.poll(100, TimeUnit.MILLISECONDS);\n+          if (lastElement != null) {\n+            batch.add(lastElement.toSpanData());\n+          }", "originalCommit": "5bde48dd459a26be6cdcc5e775e43d73971b7e81", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTcxMzgwNQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475713805", "bodyText": "A, main reason I cannot use drain here is that I immediately convert to SpanData. And I don't want to drain to one collection, then iterate and convert element by element into another collection.", "author": "iNikem", "createdAt": "2020-08-24T15:48:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxMzkzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxNTMxNg==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475315316", "bodyText": "Similar to above, it might be better if we can structure this to take advantage of drainTo. I guess you can consecutively drainTo and subtract the number drained from spansToFlush instead of individual poll without a huge change in structure.", "author": "anuraaga", "createdAt": "2020-08-24T02:52:57Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -164,146 +152,121 @@ public void forceFlush() {\n \n     private static final BoundLongCounter droppedSpans;\n \n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n-\n     private static final Logger logger = Logger.getLogger(Worker.class.getName());\n     private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n+    private final long scheduleDelayNanos;\n     private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n     private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n \n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n+    private long nextExportTime;\n+\n+    private final BlockingQueue<ReadableSpan> queue;\n+\n+    @Nullable private volatile CompletableResultCode flushRequested = null;\n+    private volatile boolean continueWork = true;\n+    private final ArrayList<SpanData> batch;\n \n     private Worker(\n         SpanExporter spanExporter,\n         long scheduleDelayMillis,\n-        int maxQueueSize,\n         int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n+        int exporterTimeoutMillis,\n+        BlockingQueue<ReadableSpan> queue) {\n       this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n+      this.scheduleDelayNanos = TimeUnit.MILLISECONDS.toNanos(scheduleDelayMillis);\n       this.maxExportBatchSize = maxExportBatchSize;\n       this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+      this.queue = queue;\n+      this.batch = new ArrayList<>(this.maxExportBatchSize);\n     }\n \n     private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n+      if (!queue.offer(span)) {\n+        droppedSpans.add(1);\n       }\n     }\n \n     @Override\n     public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+      updateNextExportTime();\n+\n+      while (continueWork) {\n+        try {\n+          if (flushRequested != null) {\n+            flush();\n+          }\n+\n+          ReadableSpan lastElement = queue.poll(100, TimeUnit.MILLISECONDS);\n+          if (lastElement != null) {\n+            batch.add(lastElement.toSpanData());\n+          }\n+\n+          if (batch.size() >= maxExportBatchSize || System.nanoTime() >= nextExportTime) {\n+            exportCurrentBatch();\n+            updateNextExportTime();\n           }\n-          spansCopy = new ArrayList<>(spansList);\n-          spansList.clear();\n+\n+        } catch (InterruptedException e) {\n+          Thread.currentThread().interrupt();\n+          return;\n+        }\n+      }\n+    }\n+\n+    private void flush() {\n+      int spansToFlush = queue.size();\n+      while (spansToFlush > 0) {\n+        ReadableSpan span = queue.poll();", "originalCommit": "5bde48dd459a26be6cdcc5e775e43d73971b7e81", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMzNzYwMw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475337603", "bodyText": "I will try to benchmark this class today", "author": "iNikem", "createdAt": "2020-08-24T04:36:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxNTMxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc2NDM2MA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475764360", "bodyText": "See #1579 (comment)", "author": "iNikem", "createdAt": "2020-08-24T17:06:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTMxNTMxNg=="}], "type": "inlineReview"}, {"oid": "dc44d2803b1897d753230a7fc652d3ae7dab3834", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/dc44d2803b1897d753230a7fc652d3ae7dab3834", "message": "Polish", "committedDate": "2020-08-24T16:02:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc2MjYwOA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475762608", "bodyText": "what is the use-case for an unused nested class that we wouldn't want to warn about it?", "author": "jkwatson", "createdAt": "2020-08-24T17:02:56Z", "path": "build.gradle", "diffHunk": "@@ -70,6 +70,8 @@ configure(opentelemetryProjects) {\n         it.options.errorprone.disable(\"UnnecessaryAnonymousClass\")\n         // \"-Xep:UnnecessaryAnonymousClass:OFF\"\n \n+        it.options.errorprone.disable(\"UnusedNestedClass\")", "originalCommit": "dc44d2803b1897d753230a7fc652d3ae7dab3834", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc2NDA2OQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475764069", "bodyText": "Damn... My benchmark class has a ThreadState inner class that error prone disliked. I will take a look if I can remove this.", "author": "iNikem", "createdAt": "2020-08-24T17:05:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc2MjYwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc2NTI1OA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475765258", "bodyText": "Removed this line", "author": "iNikem", "createdAt": "2020-08-24T17:07:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc2MjYwOA=="}], "type": "inlineReview"}, {"oid": "fedb811fc2ef29d90dec3016f813d35d26301a71", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/fedb811fc2ef29d90dec3016f813d35d26301a71", "message": "Polish", "committedDate": "2020-08-24T17:08:03Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc3MDU1Mw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r475770553", "bodyText": "this is very similar to what I did when I took a swing at this class 6 months ago, so obviously I think it's a great approach. ;)", "author": "jkwatson", "createdAt": "2020-08-24T17:17:47Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -160,150 +147,135 @@ public void forceFlush() {\n       droppedSpans =\n           droppedSpansCounter.bind(\n               Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n+      LongCounter exportedSpansCounter =\n+          meter\n+              .longCounterBuilder(\"exportedSpans\")\n+              .setUnit(\"1\")\n+              .setDescription(\"The number of spans exported by the BatchSpanProcessor.\")\n+              .build();\n+      exportedSpans =\n+          exportedSpansCounter.bind(\n+              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n     }\n \n     private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n+    private static final BoundLongCounter exportedSpans;\n \n     private static final Logger logger = Logger.getLogger(Worker.class.getName());\n     private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n+    private final long scheduleDelayNanos;\n     private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n     private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n \n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n+    private long nextExportTime;\n+\n+    private final BlockingQueue<ReadableSpan> queue;\n+\n+    private final AtomicReference<CompletableResultCode> flushRequested = new AtomicReference<>();\n+    private volatile boolean continueWork = true;\n+    private final ArrayList<SpanData> batch;\n \n     private Worker(\n         SpanExporter spanExporter,\n         long scheduleDelayMillis,\n-        int maxQueueSize,\n         int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n+        int exporterTimeoutMillis,\n+        BlockingQueue<ReadableSpan> queue) {\n       this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n+      this.scheduleDelayNanos = TimeUnit.MILLISECONDS.toNanos(scheduleDelayMillis);\n       this.maxExportBatchSize = maxExportBatchSize;\n       this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+      this.queue = queue;\n+      this.batch = new ArrayList<>(this.maxExportBatchSize);\n     }\n \n     private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n+      if (!queue.offer(span)) {\n+        droppedSpans.add(1);\n       }\n     }\n \n     @Override\n     public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+      updateNextExportTime();\n+\n+      while (continueWork) {\n+        try {\n+          if (flushRequested.get() != null) {\n+            flush();\n+          }\n+\n+          ReadableSpan lastElement = queue.poll(100, TimeUnit.MILLISECONDS);\n+          if (lastElement != null) {\n+            batch.add(lastElement.toSpanData());\n           }\n-          spansCopy = new ArrayList<>(spansList);\n-          spansList.clear();\n+\n+          if (batch.size() >= maxExportBatchSize || System.nanoTime() >= nextExportTime) {", "originalCommit": "dc44d2803b1897d753230a7fc652d3ae7dab3834", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ5NDM5Ng==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r476494396", "bodyText": "If you don't mind copying in #1583 that'd be cool, I think the synchronous case optimization and less branching (same lines of code to just all fail() twice) is worth it. Then no worries closing that PR in favor of this one", "author": "anuraaga", "createdAt": "2020-08-25T14:29:59Z", "path": "sdk/common/src/main/java/io/opentelemetry/sdk/common/export/CompletableResultCode.java", "diffHunk": "@@ -107,4 +109,33 @@ public CompletableResultCode whenComplete(Runnable action) {\n     }\n     return this;\n   }\n+\n+  /** Returns whether this {@link CompletableResultCode} has completed. */\n+  public boolean isDone() {\n+    synchronized (lock) {\n+      return succeeded != null;\n+    }\n+  }\n+\n+  /** Calls {@link #fail()} if times out. */\n+  public CompletableResultCode join(long timeout, TimeUnit unit) {\n+    final CountDownLatch latch = new CountDownLatch(1);", "originalCommit": "57deb41ac1fdc73f9e9dc86668520195134310bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjU1NjM0NA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r476556344", "bodyText": "Will do.", "author": "iNikem", "createdAt": "2020-08-25T15:54:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ5NDM5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ5NTYzNQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r476495635", "bodyText": "AINTD, we still have the issue that a flush can be delayed by a long 100ms. Do you mind filing an issue for it? Flush is mostly used on FaaS so they pay $$ for the time they use, we should put in the effort to save that even if it adds some complexity.", "author": "anuraaga", "createdAt": "2020-08-25T14:31:40Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -160,150 +153,135 @@ public void forceFlush() {\n       droppedSpans =\n           droppedSpansCounter.bind(\n               Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n+      LongCounter exportedSpansCounter =\n+          meter\n+              .longCounterBuilder(\"exportedSpans\")\n+              .setUnit(\"1\")\n+              .setDescription(\"The number of spans exported by the BatchSpanProcessor.\")\n+              .build();\n+      exportedSpans =\n+          exportedSpansCounter.bind(\n+              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n     }\n \n     private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n+    private static final BoundLongCounter exportedSpans;\n \n     private static final Logger logger = Logger.getLogger(Worker.class.getName());\n     private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n+    private final long scheduleDelayNanos;\n     private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n     private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n \n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n+    private long nextExportTime;\n+\n+    private final BlockingQueue<ReadableSpan> queue;\n+\n+    private final AtomicReference<CompletableResultCode> flushRequested = new AtomicReference<>();\n+    private volatile boolean continueWork = true;\n+    private final ArrayList<SpanData> batch;\n \n     private Worker(\n         SpanExporter spanExporter,\n         long scheduleDelayMillis,\n-        int maxQueueSize,\n         int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n+        int exporterTimeoutMillis,\n+        BlockingQueue<ReadableSpan> queue) {\n       this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n+      this.scheduleDelayNanos = TimeUnit.MILLISECONDS.toNanos(scheduleDelayMillis);\n       this.maxExportBatchSize = maxExportBatchSize;\n       this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+      this.queue = queue;\n+      this.batch = new ArrayList<>(this.maxExportBatchSize);\n     }\n \n     private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n+      if (!queue.offer(span)) {\n+        droppedSpans.add(1);\n       }\n     }\n \n     @Override\n     public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+      updateNextExportTime();\n+\n+      while (continueWork) {\n+        try {\n+          if (flushRequested.get() != null) {", "originalCommit": "57deb41ac1fdc73f9e9dc86668520195134310bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjU1NjE2OA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r476556168", "bodyText": "I will do that after this PR is merged. It will be easier to refer to the code concerned.", "author": "iNikem", "createdAt": "2020-08-25T15:54:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ5NTYzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ5NzM4Nw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r476497387", "bodyText": "I think it's only this line that can produce a InterruptedException, can you narrow down the scope of the try / catch to make that more obvious?", "author": "anuraaga", "createdAt": "2020-08-25T14:33:55Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -160,150 +153,135 @@ public void forceFlush() {\n       droppedSpans =\n           droppedSpansCounter.bind(\n               Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n+      LongCounter exportedSpansCounter =\n+          meter\n+              .longCounterBuilder(\"exportedSpans\")\n+              .setUnit(\"1\")\n+              .setDescription(\"The number of spans exported by the BatchSpanProcessor.\")\n+              .build();\n+      exportedSpans =\n+          exportedSpansCounter.bind(\n+              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n     }\n \n     private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n+    private static final BoundLongCounter exportedSpans;\n \n     private static final Logger logger = Logger.getLogger(Worker.class.getName());\n     private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n+    private final long scheduleDelayNanos;\n     private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n     private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n \n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n+    private long nextExportTime;\n+\n+    private final BlockingQueue<ReadableSpan> queue;\n+\n+    private final AtomicReference<CompletableResultCode> flushRequested = new AtomicReference<>();\n+    private volatile boolean continueWork = true;\n+    private final ArrayList<SpanData> batch;\n \n     private Worker(\n         SpanExporter spanExporter,\n         long scheduleDelayMillis,\n-        int maxQueueSize,\n         int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n+        int exporterTimeoutMillis,\n+        BlockingQueue<ReadableSpan> queue) {\n       this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n+      this.scheduleDelayNanos = TimeUnit.MILLISECONDS.toNanos(scheduleDelayMillis);\n       this.maxExportBatchSize = maxExportBatchSize;\n       this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+      this.queue = queue;\n+      this.batch = new ArrayList<>(this.maxExportBatchSize);\n     }\n \n     private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n+      if (!queue.offer(span)) {\n+        droppedSpans.add(1);\n       }\n     }\n \n     @Override\n     public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+      updateNextExportTime();\n+\n+      while (continueWork) {\n+        try {\n+          if (flushRequested.get() != null) {\n+            flush();\n+          }\n+\n+          ReadableSpan lastElement = queue.poll(100, TimeUnit.MILLISECONDS);", "originalCommit": "57deb41ac1fdc73f9e9dc86668520195134310bb", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjUwMDUyMQ==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r476500521", "bodyText": "As we discussed in chat, I still have reservations about the lock contention between .poll and .offer. It'd be nice if we can file an issue about performance benchmarking / optimization of BSP. If I understood correctly, we're ok with adding complexity if we start with numbers and show the numbers with it, which makes sense to me.", "author": "anuraaga", "createdAt": "2020-08-25T14:37:59Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -160,150 +153,135 @@ public void forceFlush() {\n       droppedSpans =\n           droppedSpansCounter.bind(\n               Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n+      LongCounter exportedSpansCounter =\n+          meter\n+              .longCounterBuilder(\"exportedSpans\")\n+              .setUnit(\"1\")\n+              .setDescription(\"The number of spans exported by the BatchSpanProcessor.\")\n+              .build();\n+      exportedSpans =\n+          exportedSpansCounter.bind(\n+              Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n     }\n \n     private static final BoundLongCounter droppedSpans;\n-\n-    private final Timer timer = new Timer(TIMER_THREAD_NAME, /* isDaemon= */ true);\n+    private static final BoundLongCounter exportedSpans;\n \n     private static final Logger logger = Logger.getLogger(Worker.class.getName());\n     private final SpanExporter spanExporter;\n-    private final long scheduleDelayMillis;\n-    private final int maxQueueSize;\n+    private final long scheduleDelayNanos;\n     private final int maxExportBatchSize;\n-    private final int halfMaxQueueSize;\n-    private final Object monitor = new Object();\n     private final int exporterTimeoutMillis;\n-    private final AtomicBoolean exportAvailable = new AtomicBoolean(true);\n \n-    @GuardedBy(\"monitor\")\n-    private final List<ReadableSpan> spansList;\n+    private long nextExportTime;\n+\n+    private final BlockingQueue<ReadableSpan> queue;\n+\n+    private final AtomicReference<CompletableResultCode> flushRequested = new AtomicReference<>();\n+    private volatile boolean continueWork = true;\n+    private final ArrayList<SpanData> batch;\n \n     private Worker(\n         SpanExporter spanExporter,\n         long scheduleDelayMillis,\n-        int maxQueueSize,\n         int maxExportBatchSize,\n-        int exporterTimeoutMillis) {\n+        int exporterTimeoutMillis,\n+        BlockingQueue<ReadableSpan> queue) {\n       this.spanExporter = spanExporter;\n-      this.scheduleDelayMillis = scheduleDelayMillis;\n-      this.maxQueueSize = maxQueueSize;\n-      this.halfMaxQueueSize = maxQueueSize >> 1;\n+      this.scheduleDelayNanos = TimeUnit.MILLISECONDS.toNanos(scheduleDelayMillis);\n       this.maxExportBatchSize = maxExportBatchSize;\n       this.exporterTimeoutMillis = exporterTimeoutMillis;\n-      this.spansList = new ArrayList<>(maxQueueSize);\n+      this.queue = queue;\n+      this.batch = new ArrayList<>(this.maxExportBatchSize);\n     }\n \n     private void addSpan(ReadableSpan span) {\n-      synchronized (monitor) {\n-        if (spansList.size() == maxQueueSize) {\n-          droppedSpans.add(1);\n-          return;\n-        }\n-        // TODO: Record a gauge for referenced spans.\n-        spansList.add(span);\n-        // Notify the worker thread that at half of the queue is available. It will take\n-        // time anyway for the thread to wake up.\n-        if (spansList.size() >= halfMaxQueueSize) {\n-          monitor.notifyAll();\n-        }\n+      if (!queue.offer(span)) {\n+        droppedSpans.add(1);\n       }\n     }\n \n     @Override\n     public void run() {\n-      while (!Thread.currentThread().isInterrupted()) {\n-        // Copy all the batched spans in a separate list to release the monitor lock asap to\n-        // avoid blocking the producer thread.\n-        ArrayList<ReadableSpan> spansCopy;\n-        synchronized (monitor) {\n-          // If still maxExportBatchSize elements in the queue better to execute an extra\n-          if (spansList.size() < maxExportBatchSize) {\n-            do {\n-              // In the case of a spurious wakeup we export only if we have at least one span in\n-              // the batch. It is acceptable because batching is a best effort mechanism here.\n-              try {\n-                monitor.wait(scheduleDelayMillis);\n-              } catch (InterruptedException ie) {\n-                // Preserve the interruption status as per guidance and stop doing any work.\n-                Thread.currentThread().interrupt();\n-                return;\n-              }\n-            } while (spansList.isEmpty());\n+      updateNextExportTime();\n+\n+      while (continueWork) {\n+        try {\n+          if (flushRequested.get() != null) {\n+            flush();\n+          }\n+\n+          ReadableSpan lastElement = queue.poll(100, TimeUnit.MILLISECONDS);\n+          if (lastElement != null) {\n+            batch.add(lastElement.toSpanData());\n           }\n-          spansCopy = new ArrayList<>(spansList);\n-          spansList.clear();\n+\n+          if (batch.size() >= maxExportBatchSize || System.nanoTime() >= nextExportTime) {\n+            exportCurrentBatch();\n+            updateNextExportTime();\n+          }\n+\n+        } catch (InterruptedException e) {\n+          Thread.currentThread().interrupt();\n+          return;\n         }\n-        // Execute the batch export outside the synchronized to not block all producers.\n-        exportBatches(spansCopy);\n       }\n     }\n \n-    private void shutdown() {\n-      forceFlush();\n-      timer.cancel();\n-      spanExporter.shutdown();\n+    private void flush() {\n+      int spansToFlush = queue.size();\n+      while (spansToFlush > 0) {\n+        ReadableSpan span = queue.poll();", "originalCommit": "57deb41ac1fdc73f9e9dc86668520195134310bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjU2MDU4NA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r476560584", "bodyText": "#1587", "author": "iNikem", "createdAt": "2020-08-25T16:00:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjUwMDUyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjYwMTkzMA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r476601930", "bodyText": "\ud83d\ude02", "author": "jkwatson", "createdAt": "2020-08-25T17:04:33Z", "path": "sdk/all/src/jmh/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessorDroppedSpansBenchmark.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Copyright 2020, OpenTelemetry Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package io.opentelemetry.sdk.trace.export;\n+\n+import io.opentelemetry.OpenTelemetry;\n+import io.opentelemetry.sdk.OpenTelemetrySdk;\n+import io.opentelemetry.sdk.common.export.CompletableResultCode;\n+import io.opentelemetry.sdk.metrics.data.MetricData;\n+import io.opentelemetry.sdk.metrics.data.MetricData.LongPoint;\n+import io.opentelemetry.sdk.metrics.data.MetricData.Point;\n+import io.opentelemetry.sdk.metrics.export.MetricProducer;\n+import io.opentelemetry.sdk.trace.ReadableSpan;\n+import io.opentelemetry.sdk.trace.data.SpanData;\n+import io.opentelemetry.trace.Tracer;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import org.openjdk.jmh.annotations.AuxCounters;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Level;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.TearDown;\n+import org.openjdk.jmh.annotations.Threads;\n+import org.openjdk.jmh.annotations.Warmup;\n+\n+public class BatchSpanProcessorDroppedSpansBenchmark {\n+\n+  private static class DelayingSpanExporter implements SpanExporter {\n+    @SuppressWarnings(\"FutureReturnValueIgnored\")\n+    @Override\n+    public CompletableResultCode export(Collection<SpanData> spans) {\n+      return CompletableResultCode.ofSuccess();\n+    }\n+\n+    @Override\n+    public CompletableResultCode flush() {\n+      return CompletableResultCode.ofSuccess();\n+    }\n+\n+    @Override\n+    public void shutdown() {}\n+  }\n+\n+  @State(Scope.Benchmark)\n+  public static class BenchmarkState {\n+    private final MetricProducer metricProducer =\n+        OpenTelemetrySdk.getMeterProvider().getMetricProducer();\n+    private BatchSpanProcessor processor;\n+    private Tracer tracer;\n+    private Collection<MetricData> allMetrics;\n+\n+    @Setup(Level.Trial)\n+    public final void setup() {\n+      SpanExporter exporter = new DelayingSpanExporter();\n+      processor = BatchSpanProcessor.newBuilder(exporter).build();\n+\n+      tracer = OpenTelemetry.getTracerProvider().get(\"benchmarkTracer\");\n+    }\n+\n+    @TearDown(Level.Trial)\n+    public final void tearDown() {\n+      processor.shutdown();\n+    }\n+\n+    @TearDown(Level.Iteration)\n+    public final void recordMetrics() {\n+      allMetrics = metricProducer.collectAllMetrics();\n+    }\n+  }\n+\n+  @State(Scope.Thread)\n+  @AuxCounters(AuxCounters.Type.EVENTS)\n+  public static class ThreadState {\n+    private Collection<MetricData> allMetrics;\n+\n+    @TearDown(Level.Iteration)\n+    public final void recordMetrics(BenchmarkState benchmarkState) {\n+      allMetrics = benchmarkState.allMetrics;\n+    }\n+\n+    /** Burn, checkstyle, burn. */", "originalCommit": "ea358f020a4ef5cc80939ea51caa0c843c9f1cef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjYwNTg2Mw==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r476605863", "bodyText": "same comment as on @anuraaga 's PR: can we just do if (isDone()) return this;  instead of duplicating the code?", "author": "jkwatson", "createdAt": "2020-08-25T17:11:05Z", "path": "sdk/common/src/main/java/io/opentelemetry/sdk/common/export/CompletableResultCode.java", "diffHunk": "@@ -107,4 +109,42 @@ public CompletableResultCode whenComplete(Runnable action) {\n     }\n     return this;\n   }\n+\n+  /** Returns whether this {@link CompletableResultCode} has completed. */\n+  public boolean isDone() {\n+    synchronized (lock) {\n+      return succeeded != null;\n+    }\n+  }\n+\n+  /**\n+   * Waits for the specified amount of time for this {@link CompletableResultCode} to complete. If\n+   * it times out or is interrupted, the {@link CompletableResultCode} is failed.\n+   *\n+   * @return this {@link CompletableResultCode}\n+   */\n+  public CompletableResultCode join(long timeout, TimeUnit unit) {\n+    synchronized (lock) {\n+      if (succeeded != null) {\n+        return this;\n+      }\n+    }", "originalCommit": "ea358f020a4ef5cc80939ea51caa0c843c9f1cef", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzExODE4Mg==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r477118182", "bodyText": "Rebased and took all changes from Anuraag PR", "author": "iNikem", "createdAt": "2020-08-26T08:15:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjYwNTg2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjYwODA4OA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r476608088", "bodyText": "what would you think about having only one counter called \"processedSpans\", with a boolean label for dropped or not?", "author": "jkwatson", "createdAt": "2020-08-25T17:14:40Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -160,150 +153,134 @@ public void forceFlush() {\n       droppedSpans =\n           droppedSpansCounter.bind(\n               Labels.of(\"spanProcessorType\", BatchSpanProcessor.class.getSimpleName()));\n+      LongCounter exportedSpansCounter =\n+          meter\n+              .longCounterBuilder(\"exportedSpans\")", "originalCommit": "ea358f020a4ef5cc80939ea51caa0c843c9f1cef", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b25396b33b867e358ea6b3f94425f72092d0b860", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/b25396b33b867e358ea6b3f94425f72092d0b860", "message": "More aggresive version of BatchSpanProcessor", "committedDate": "2020-08-26T08:02:01Z", "type": "commit"}, {"oid": "b60e51dea8e567bf5682daba95a271437cfa35ee", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/b60e51dea8e567bf5682daba95a271437cfa35ee", "message": "Add benchmark", "committedDate": "2020-08-26T08:03:03Z", "type": "commit"}, {"oid": "0fae55441d08ffecfec361f1f5b064c931b69fa3", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/0fae55441d08ffecfec361f1f5b064c931b69fa3", "message": "Polish", "committedDate": "2020-08-26T08:03:31Z", "type": "commit"}, {"oid": "43f1b08bf991a4a288f1c2d2492ea20901309f15", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/43f1b08bf991a4a288f1c2d2492ea20901309f15", "message": "Polish", "committedDate": "2020-08-26T08:03:31Z", "type": "commit"}, {"oid": "e71634d6b2a7acc479c0224f8b3b18534e810998", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/e71634d6b2a7acc479c0224f8b3b18534e810998", "message": "Incorporated some changes from #1571", "committedDate": "2020-08-26T08:03:51Z", "type": "commit"}, {"oid": "ec593503191102fffe0080301215c5e82071925b", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/ec593503191102fffe0080301215c5e82071925b", "message": "Rollback one test change", "committedDate": "2020-08-26T08:03:51Z", "type": "commit"}, {"oid": "b964ba13399001e2120638d191ad168e2e0ddd70", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/b964ba13399001e2120638d191ad168e2e0ddd70", "message": "Polish", "committedDate": "2020-08-26T08:03:59Z", "type": "commit"}, {"oid": "2634ff9282e621b23d2d8845a5d56f8fe86d22b2", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/2634ff9282e621b23d2d8845a5d56f8fe86d22b2", "message": "Polish", "committedDate": "2020-08-26T09:03:42Z", "type": "commit"}, {"oid": "2634ff9282e621b23d2d8845a5d56f8fe86d22b2", "url": "https://github.com/open-telemetry/opentelemetry-java/commit/2634ff9282e621b23d2d8845a5d56f8fe86d22b2", "message": "Polish", "committedDate": "2020-08-26T09:03:42Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM4NTcwNA==", "url": "https://github.com/open-telemetry/opentelemetry-java/pull/1579#discussion_r477385704", "bodyText": "this description isn't quite right any more. Can be fixed in a follow-on PR, to get you unblocked.", "author": "jkwatson", "createdAt": "2020-08-26T15:22:04Z", "path": "sdk/tracing/src/main/java/io/opentelemetry/sdk/trace/export/BatchSpanProcessor.java", "diffHunk": "@@ -142,169 +132,148 @@ public void forceFlush() {\n     worker.forceFlush();\n   }\n \n+  // TODO remove this when this.forceFlush returns CompletableResultCode\n+  @VisibleForTesting\n+  CompletableResultCode flush() {\n+    return worker.forceFlush();\n+  }\n+\n   // Worker is a thread that batches multiple spans and calls the registered SpanExporter to export\n   // the data.\n-  //\n-  // The list of batched data is protected by an explicit monitor object which ensures full\n-  // concurrency.\n   private static final class Worker implements Runnable {\n \n     static {\n       Meter meter = OpenTelemetry.getMeter(\"io.opentelemetry.sdk.trace\");\n-      LongCounter droppedSpansCounter =\n+      LongCounter processedSpansCounter =\n           meter\n-              .longCounterBuilder(\"droppedSpans\")\n+              .longCounterBuilder(\"processedSpans\")\n               .setUnit(\"1\")\n               .setDescription(\n                   \"The number of spans dropped by the BatchSpanProcessor due to high throughput.\")", "originalCommit": "2634ff9282e621b23d2d8845a5d56f8fe86d22b2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}