{"pr_number": 11596, "pr_title": "[BEAM-9856] Optimization/hl7v2 io list messages", "pr_createdAt": "2020-05-02T02:22:19Z", "pr_url": "https://github.com/apache/beam/pull/11596", "timeline": [{"oid": "011154d5168f1b6e8c8c38b79680a58fadd2e657", "url": "https://github.com/apache/beam/commit/011154d5168f1b6e8c8c38b79680a58fadd2e657", "message": "pre-work send time bound convenience functions for\n\nBEAM-9856", "committedDate": "2020-04-30T22:53:24Z", "type": "commit"}, {"oid": "209b6191b6d1e64c15e0a3c9d2f67cb1a3c51ee8", "url": "https://github.com/apache/beam/commit/209b6191b6d1e64c15e0a3c9d2f67cb1a3c51ee8", "message": "WIP splitable DoFn for message listing", "committedDate": "2020-05-02T01:44:15Z", "type": "commit"}, {"oid": "b2051f24d92601c5bcfbcc23e7f8b1ec8e554880", "url": "https://github.com/apache/beam/commit/b2051f24d92601c5bcfbcc23e7f8b1ec8e554880", "message": "wip HL7v2IO.ListMessages splittable dofn POC", "committedDate": "2020-05-02T02:20:31Z", "type": "commit"}, {"oid": "3289835d2c841e18a92c898da9fa8f3401bbf006", "url": "https://github.com/apache/beam/commit/3289835d2c841e18a92c898da9fa8f3401bbf006", "message": "slow but working", "committedDate": "2020-05-04T23:29:40Z", "type": "commit"}, {"oid": "810c84bb3759cf9813615376c1c4c4e4593c3357", "url": "https://github.com/apache/beam/commit/810c84bb3759cf9813615376c1c4c4e4593c3357", "message": "handle corner cases, improve javadoc", "committedDate": "2020-05-05T01:26:19Z", "type": "commit"}, {"oid": "a340017097a5443fc11d64865f8b3aaff1e6719e", "url": "https://github.com/apache/beam/commit/a340017097a5443fc11d64865f8b3aaff1e6719e", "message": "remove OffsetRangeTracker changes", "committedDate": "2020-05-05T01:28:19Z", "type": "commit"}, {"oid": "889129284b41eec6027f12fcb1ecae0e82bbd034", "url": "https://github.com/apache/beam/commit/889129284b41eec6027f12fcb1ecae0e82bbd034", "message": "add null check on lastAttemptedOffset in checkDone", "committedDate": "2020-05-05T01:34:03Z", "type": "commit"}, {"oid": "d2a094d5a133132d015fc7ed335e5b430a19f183", "url": "https://github.com/apache/beam/commit/d2a094d5a133132d015fc7ed335e5b430a19f183", "message": "clean up", "committedDate": "2020-05-06T18:51:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc1NjQ0NQ==", "url": "https://github.com/apache/beam/pull/11596#discussion_r421756445", "bodyText": "why not use the offset range tracker and convert time to long?", "author": "lukecwik", "createdAt": "2020-05-07T19:55:06Z", "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/splittabledofn/OrderedTimeRange.java", "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.transforms.splittabledofn;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.beam.sdk.coders.AtomicCoder;\n+import org.apache.beam.sdk.coders.CoderException;\n+import org.apache.beam.sdk.coders.InstantCoder;\n+import org.apache.beam.sdk.util.VarInt;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Objects;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+/** A restriction represented by a range of Instants [from, to). */\n+public class OrderedTimeRange", "originalCommit": "d2a094d5a133132d015fc7ed335e5b430a19f183", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTgwOTUxMA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r421809510", "bodyText": "TBH, the main value add here is more readable restriction bounds / values in the error messages for the context of the time range use case.\nIf there is a cleaner way of borrowing all implementation from OffsetRangeTracker but changing format of these error messages, I'd be all ears.\nI suppose I could add a  private final bool offestsAreInstants member to OffsetRangeTracker and throw conditional formatting on each error message?", "author": "jaketf", "createdAt": "2020-05-07T21:37:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc1NjQ0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTgxOTAwMQ==", "url": "https://github.com/apache/beam/pull/11596#discussion_r421819001", "bodyText": "Any bug in this space is an error in the implementation of the IO connector so these error messages will mostly come up during development and then if any bugs are discovered during the usage the user won't be able to do much and this will go to the Beam community/IO author to fix.\nIf you really want to, adding a format method and creating a subclass would make more sense then having effectively a copy.", "author": "lukecwik", "createdAt": "2020-05-07T21:58:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc1NjQ0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTgyNTI4OA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r421825288", "bodyText": "that make a lot of sense, thanks for the suggestion.", "author": "jaketf", "createdAt": "2020-05-07T22:13:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc1NjQ0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc1NzgxNQ==", "url": "https://github.com/apache/beam/pull/11596#discussion_r421757815", "bodyText": "Please make this a seperate PR and add a test that covers this case to the OffsetRangeTrackerTest\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                if (lastAttemptedOffset == null) {\n          \n          \n            \n                  throw new IllegalStateException(\"lastAttemptedOffset should not be null\");\n          \n          \n            \n                }\n          \n          \n            \n                checkState(\n          \n          \n            \n                    lastAttemptedOffset >= range.getTo() - 1,\n          \n          \n            \n                    \"Last attempted offset was %s in range %s, claiming work in [%s, %s) was not attempted\",\n          \n          \n            \n                checkState(\n          \n          \n            \n                    lastAttemptedOffset != null && lastAttemptedOffset >= range.getTo() - 1,\n          \n          \n            \n                    \"Last attempted offset was %s in range %s, claiming work in [%s, %s) was not attempted\",", "author": "lukecwik", "createdAt": "2020-05-07T19:57:27Z", "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/splittabledofn/OffsetRangeTracker.java", "diffHunk": "@@ -94,6 +94,9 @@ public void checkDone() throws IllegalStateException {\n     if (range.getFrom() == range.getTo()) {\n       return;\n     }\n+    if (lastAttemptedOffset == null) {\n+      throw new IllegalStateException(\"lastAttemptedOffset should not be null\");\n+    }\n     checkState(\n         lastAttemptedOffset >= range.getTo() - 1,\n         \"Last attempted offset was %s in range %s, claiming work in [%s, %s) was not attempted\",", "originalCommit": "d2a094d5a133132d015fc7ed335e5b430a19f183", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTgyNDQ2Mg==", "url": "https://github.com/apache/beam/pull/11596#discussion_r421824462", "bodyText": "Sure, I can move this to separate PR.\nKindly, disagree on suggestion as it will just cause a different NPE on L102 when you call lastAttemptedOffset + 1 to try and print this error message.\nI think the lastAttemptedOffset null check should be separate and throw a more specific error message before we get to this stateCheck.\nThis failure mode is almost definitely mis-use of OffsetRangeTracker that would even cause this, and would be difficult to say what work was or wasn't attempted.", "author": "jaketf", "createdAt": "2020-05-07T22:11:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc1NzgxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTgyNjQ0Ng==", "url": "https://github.com/apache/beam/pull/11596#discussion_r421826446", "bodyText": "Good point but we should structure message saying that we haven't claimed anything in the range which is non-empty.", "author": "lukecwik", "createdAt": "2020-05-07T22:16:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc1NzgxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjQzMDc4Mw==", "url": "https://github.com/apache/beam/pull/11596#discussion_r422430783", "bodyText": "opened #11648", "author": "jaketf", "createdAt": "2020-05-09T00:33:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc1NzgxNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc2MjMyMw==", "url": "https://github.com/apache/beam/pull/11596#discussion_r421762323", "bodyText": "Typically, doing one split for every 64mbs of output has been our guidance here in the past.\nDynamic splitting is meant to fill in the gap if there is too little splitting or a specific restriction has a lot more data then other restrictions.", "author": "lukecwik", "createdAt": "2020-05-07T20:05:40Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -472,24 +548,120 @@ public void initClient() throws IOException {\n       this.client = new HttpHealthcareApiClient();\n     }\n \n+    @GetInitialRestriction\n+    public OrderedTimeRange getEarliestToLatestRestriction(@Element String hl7v2Store)\n+        throws IOException {\n+      from = this.client.getEarliestHL7v2SendTime(hl7v2Store, this.filter);\n+      // filters are [from, to) to match logic of OffsetRangeTracker but need latest element to be\n+      // included in results set to add an extra ms to the upper bound.\n+      to = this.client.getLatestHL7v2SendTime(hl7v2Store, this.filter).plus(1);\n+      return new OrderedTimeRange(from, to);\n+    }\n+\n+    @NewTracker\n+    public OrderedTimeRangeTracker newTracker(@Restriction OrderedTimeRange timeRange) {\n+      return timeRange.newTracker();\n+    }\n+\n+    @SplitRestriction\n+    public void split(\n+        @Restriction OrderedTimeRange timeRange, OutputReceiver<OrderedTimeRange> out) {\n+      // TODO(jaketf) How to pick optimal values for desiredNumOffsetsPerSplit ?", "originalCommit": "d2a094d5a133132d015fc7ed335e5b430a19f183", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTgwNzA1OQ==", "url": "https://github.com/apache/beam/pull/11596#discussion_r421807059", "bodyText": "Unfortunately, in this use case dynamic splitting would be crucial because we can't know the distribution of data in the restriction dimension (sendTime).\nIf you imagine a hospital might be much busier during daytime / weekdays than night times weekends (though never dormant due to ICU and emergency services). \"Day time\" might change base on hospital location, week days are subject to holidays, etc.\nData distribution in sendTime may be subject to significant spikes if one of the upstream systems populating sendTime has to backfill after a maintenance period and doesn't responsibly set this field to event time but sets all of the sendTimes to a short range of  backfill\nprocessing time (this is sub optimal behavior of that system but sometimes a reality).", "author": "jaketf", "createdAt": "2020-05-07T21:32:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc2MjMyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTgxMzkxNQ==", "url": "https://github.com/apache/beam/pull/11596#discussion_r421813915", "bodyText": "Yeah, you'll have to choose a reasonable value based upon your knowledge within this domain and I understand that this may not work in practice.\nIn the case where people send a lot of data for a narrow time range, you would have to support filtering based upon other properties such as messageType or sendFacility and could break up the space based upon prefixes such as ~a, ~b, NOT ~a AND NOT ~b but this is dependent on this being efficient in the service as well.", "author": "lukecwik", "createdAt": "2020-05-07T21:46:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc2MjMyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTgyNzk2NA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r421827964", "bodyText": "Yeah I think the \"spiky backfill\" (many cases in a small sendTime) is a corner case of a hot split that would just be slow and users would have to accept that or take it up with their upstream system.\nsplitting on messageType / sendFacility are probably more popular logical filters and feels like a hack for a corner case that might mess with performance under the \"typical\" distribution of data in sendTime.", "author": "jaketf", "createdAt": "2020-05-07T22:20:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc2MjMyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTg0NzYzMw==", "url": "https://github.com/apache/beam/pull/11596#discussion_r421847633", "bodyText": "My intuition says hourly splits seems like a more reasonable starting point than day but I'm unsure about this without testing on a few datasets.\nHowever for super large time ranges 10 years = 87,600 splits. naturally this explodes if we think about even smaller time ranges.\nFor example, I assume the initial collection of splits returned in SplitRestriction has to fit in memory?\nOr even just the loop to define all these might take a significant amount of time", "author": "jaketf", "createdAt": "2020-05-07T23:18:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc2MjMyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjIzMzMwMw==", "url": "https://github.com/apache/beam/pull/11596#discussion_r422233303", "bodyText": "That seems like a lot.\nDataflow has an API limit of 20mbs for split descriptions when being returned which usually tops out around 10k splits for sources but even 10k is too much. Typically 20-50 splits is enough since dynamic splitting will ramp that up to 1000s if necessary.", "author": "lukecwik", "createdAt": "2020-05-08T16:14:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc2MjMyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjQyNjM4Mw==", "url": "https://github.com/apache/beam/pull/11596#discussion_r422426383", "bodyText": "Interesting, thanks for those details!\nBut I thought Dataflow doesn't really do dynamic splitting yet so the initial split is all that matters? Maybe I'm confusing dynamic rebalancing != dynamic splitting?\nPerhaps daily is the appropriate happy medium for now?\n1000s not 10,000s of initial splits.\nIn the future when dynamic splitting is supported bump initial split default to weeks?", "author": "jaketf", "createdAt": "2020-05-09T00:10:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc2MjMyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzIyNzk5OQ==", "url": "https://github.com/apache/beam/pull/11596#discussion_r423227999", "bodyText": "dynamic splitting is a subset of dynamic rebalancing since dynamic rebalancing also covers other aspects such as splitting a GroupByKey, scaling up/down workers, ...\ndynamic splitting is supported by batch Dataflow for bounded sinks using runner v1 and splittable dofns when running a batch pipeline when using runner v2", "author": "lukecwik", "createdAt": "2020-05-11T18:15:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc2MjMyMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzQzNzU5OA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r423437598", "bodyText": "Ok I think that dynamic splitting is \"nice to have\" for this connector and can wait for v2 runner.\nJust adding initial splitting w/ SDF and v1 runner is a huge improvement over the existing implementation.", "author": "jaketf", "createdAt": "2020-05-12T03:16:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTc2MjMyMw=="}], "type": "inlineReview"}, {"oid": "3f08f0d790500552068f7ca922b2ccde5bcd03f3", "url": "https://github.com/apache/beam/commit/3f08f0d790500552068f7ca922b2ccde5bcd03f3", "message": "remove OrderedTimeRangeTracker", "committedDate": "2020-05-09T00:15:19Z", "type": "commit"}, {"oid": "33a6f895de1374028239845ad9fe3d2cbf6369e3", "url": "https://github.com/apache/beam/commit/33a6f895de1374028239845ad9fe3d2cbf6369e3", "message": "Revert changes that were moved to #11648", "committedDate": "2020-05-12T03:19:18Z", "type": "commit"}, {"oid": "e8859e7ff7770c5965e3eea18e0b0da5e4fe3d9c", "url": "https://github.com/apache/beam/commit/e8859e7ff7770c5965e3eea18e0b0da5e4fe3d9c", "message": "remove todo", "committedDate": "2020-05-12T18:07:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzUwNjM2Ng==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427506366", "bodyText": "ValueProvider arguments are usually not known at pipeline construction time, so it is not useful to call get on them when you create the PCollection. The usual method is to have ValueProvider attributes for the class - when you get String arguments, you would wrap them with StaticValueProvider - and in the execution-time methods (e.g. processelement, finish/startbundle), you would call get on the valueproviders. I seem to have missed this point earlier. sorry about that.", "author": "pabloem", "createdAt": "2020-05-19T18:17:56Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -431,25 +455,70 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n       this.filter = filter.get();\n     }\n \n+    /**\n+     * Instantiates a new List hl 7 v 2 messages.\n+     *\n+     * @param hl7v2Stores the hl 7 v 2 stores\n+     * @param filter the filter\n+     * @param initialSplitDuration the initial split duration for sendTime dimension splits\n+     */\n+    ListHL7v2Messages(\n+        ValueProvider<List<String>> hl7v2Stores,\n+        ValueProvider<String> filter,\n+        Duration initialSplitDuration) {\n+      this.hl7v2Stores = hl7v2Stores.get();\n+      this.filter = filter.get();\n+      this.initialSplitDuration = initialSplitDuration;", "originalCommit": "e8859e7ff7770c5965e3eea18e0b0da5e4fe3d9c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzUyNTQyOQ==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427525429", "bodyText": "Would we output the first message twice?\nin the first iteration, msg = page.get(0), from line 616\nin the second iteration, msg = page.get(i++) - which is still 0, and then i is incremented?\nYou could use ++i, but then you would have to adjust the condition in the while loop, right?", "author": "pabloem", "createdAt": "2020-05-19T18:49:53Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -472,24 +547,118 @@ public void initClient() throws IOException {\n       this.client = new HttpHealthcareApiClient();\n     }\n \n+    @GetInitialRestriction\n+    public OffsetRange getEarliestToLatestRestriction(@Element String hl7v2Store)\n+        throws IOException {\n+      from = this.client.getEarliestHL7v2SendTime(hl7v2Store, this.filter);\n+      // filters are [from, to) to match logic of OffsetRangeTracker but need latest element to be\n+      // included in results set to add an extra ms to the upper bound.\n+      to = this.client.getLatestHL7v2SendTime(hl7v2Store, this.filter).plus(1);\n+      return new OffsetRange(from.getMillis(), to.getMillis());\n+    }\n+\n+    @NewTracker\n+    public OffsetRangeTracker newTracker(@Restriction OffsetRange timeRange) {\n+      return timeRange.newTracker();\n+    }\n+\n+    @SplitRestriction\n+    public void split(@Restriction OffsetRange timeRange, OutputReceiver<OffsetRange> out) {\n+      List<OffsetRange> splits =\n+          timeRange.split(initialSplitDuration.getMillis(), DEFAULT_MIN_SPLIT_DURATION.getMillis());\n+      Instant from = Instant.ofEpochMilli(timeRange.getFrom());\n+      Instant to = Instant.ofEpochMilli(timeRange.getTo());\n+      Duration totalDuration = new Duration(from, to);\n+      LOG.info(\n+          String.format(\n+              \"splitting initial sendTime restriction of [minSendTime, now): [%s,%s), \"\n+                  + \"or [%s, %s). \\n\"\n+                  + \"total days: %s \\n\"\n+                  + \"into %s splits. \\n\"\n+                  + \"Last split: %s\",\n+              from,\n+              to,\n+              timeRange.getFrom(),\n+              timeRange.getTo(),\n+              totalDuration.getStandardDays(),\n+              splits.size(),\n+              splits.get(splits.size() - 1).toString()));\n+\n+      for (OffsetRange s : splits) {\n+        out.output(s);\n+      }\n+    }\n+\n     /**\n      * List messages.\n      *\n-     * @param context the context\n+     * @param hl7v2Store the HL7v2 store to list messages from\n      * @throws IOException the io exception\n      */\n     @ProcessElement\n-    public void listMessages(ProcessContext context) throws IOException {\n-      String hl7v2Store = context.element();\n-      // Output all elements of all pages.\n+    public void listMessages(\n+        @Element String hl7v2Store,\n+        RestrictionTracker tracker,\n+        OutputReceiver<HL7v2Message> outputReceiver)\n+        throws IOException {\n+      OffsetRange currentRestriction = (OffsetRange) tracker.currentRestriction();\n+      Instant startRestriction = Instant.ofEpochMilli(currentRestriction.getFrom());\n+      Instant endRestriction = Instant.ofEpochMilli(currentRestriction.getTo());\n       HttpHealthcareApiClient.HL7v2MessagePages pages =\n-          new HttpHealthcareApiClient.HL7v2MessagePages(client, hl7v2Store, this.filter);\n+          new HttpHealthcareApiClient.HL7v2MessagePages(\n+              client, hl7v2Store, startRestriction, endRestriction, filter, \"sendTime\");\n       long reqestTime = Instant.now().getMillis();\n-      for (Stream<HL7v2Message> page : pages) {\n+      long lastClaimedMilliSecond;\n+      Instant cursor;\n+      boolean hangingClaim = false; // flag if the claimed ms spans spills over to the next page.\n+      for (List<HL7v2Message> page : pages) { // loop over pages.\n+        int i = 0;\n+        HL7v2Message msg = page.get(i);\n+        while (i < page.size()) { // loop over messages in page\n+          cursor = Instant.parse(msg.getSendTime());\n+          lastClaimedMilliSecond = cursor.getMillis();\n+          LOG.info(\n+              String.format(\n+                  \"initial claim for page %s lastClaimedMilliSecond = %s\",\n+                  i, lastClaimedMilliSecond));\n+          if (hangingClaim || tracker.tryClaim(lastClaimedMilliSecond)) {\n+            // This means we have claimed an entire millisecond we need to make sure that we\n+            // process all messages for this millisecond because sendTime is allegedly nano second\n+            // resolution.\n+            // https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages#Message\n+            while (cursor.getMillis() == lastClaimedMilliSecond\n+                && i < page.size()) { // loop over messages in millisecond.\n+              outputReceiver.output(msg);\n+              msg = page.get(i++);", "originalCommit": "e8859e7ff7770c5965e3eea18e0b0da5e4fe3d9c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MDQ2OA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427540468", "bodyText": "tl;dr No, we don't output the element twice. This is intended behavior.\npage is  List<HL7v2Message>\nWhen we call page.get we just call List::get.\nThis is safe to call twice and will \"get\" the first element of the list both times.\nWe only emit results in L631 where we call OutputReceiver::output", "author": "jaketf", "createdAt": "2020-05-19T19:16:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzUyNTQyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MjYxNw==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427542617", "bodyText": "but won't we go right back to 631, and emit the message that we got from 632 after calling get(0) for the second time?", "author": "pabloem", "createdAt": "2020-05-19T19:19:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzUyNTQyOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYzMDYwMA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427630600", "bodyText": "I agree with @pabloem that this logic is not simple to follow and I think you could really simplify your code if you used https://guava.dev/releases/21.0/api/docs/com/google/common/collect/FluentIterable.html#concat-java.lang.Iterable-\nsince it would convert Iterable<List<HL7v2Message>> into Iterable<HL7v2Message> and only accesses the elements lazily so it wouldn't prefetch everything.\nThis would allow you to not worry that messages are in a page and your processing multiple pages.", "author": "lukecwik", "createdAt": "2020-05-19T22:12:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzUyNTQyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzUyNzkxOA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427527918", "bodyText": "I don't know the API requirements, but you would be calling tryClaim twice on a milliSecond? Once in line 645, and once more here?", "author": "pabloem", "createdAt": "2020-05-19T18:54:18Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -472,24 +547,118 @@ public void initClient() throws IOException {\n       this.client = new HttpHealthcareApiClient();\n     }\n \n+    @GetInitialRestriction\n+    public OffsetRange getEarliestToLatestRestriction(@Element String hl7v2Store)\n+        throws IOException {\n+      from = this.client.getEarliestHL7v2SendTime(hl7v2Store, this.filter);\n+      // filters are [from, to) to match logic of OffsetRangeTracker but need latest element to be\n+      // included in results set to add an extra ms to the upper bound.\n+      to = this.client.getLatestHL7v2SendTime(hl7v2Store, this.filter).plus(1);\n+      return new OffsetRange(from.getMillis(), to.getMillis());\n+    }\n+\n+    @NewTracker\n+    public OffsetRangeTracker newTracker(@Restriction OffsetRange timeRange) {\n+      return timeRange.newTracker();\n+    }\n+\n+    @SplitRestriction\n+    public void split(@Restriction OffsetRange timeRange, OutputReceiver<OffsetRange> out) {\n+      List<OffsetRange> splits =\n+          timeRange.split(initialSplitDuration.getMillis(), DEFAULT_MIN_SPLIT_DURATION.getMillis());\n+      Instant from = Instant.ofEpochMilli(timeRange.getFrom());\n+      Instant to = Instant.ofEpochMilli(timeRange.getTo());\n+      Duration totalDuration = new Duration(from, to);\n+      LOG.info(\n+          String.format(\n+              \"splitting initial sendTime restriction of [minSendTime, now): [%s,%s), \"\n+                  + \"or [%s, %s). \\n\"\n+                  + \"total days: %s \\n\"\n+                  + \"into %s splits. \\n\"\n+                  + \"Last split: %s\",\n+              from,\n+              to,\n+              timeRange.getFrom(),\n+              timeRange.getTo(),\n+              totalDuration.getStandardDays(),\n+              splits.size(),\n+              splits.get(splits.size() - 1).toString()));\n+\n+      for (OffsetRange s : splits) {\n+        out.output(s);\n+      }\n+    }\n+\n     /**\n      * List messages.\n      *\n-     * @param context the context\n+     * @param hl7v2Store the HL7v2 store to list messages from\n      * @throws IOException the io exception\n      */\n     @ProcessElement\n-    public void listMessages(ProcessContext context) throws IOException {\n-      String hl7v2Store = context.element();\n-      // Output all elements of all pages.\n+    public void listMessages(\n+        @Element String hl7v2Store,\n+        RestrictionTracker tracker,\n+        OutputReceiver<HL7v2Message> outputReceiver)\n+        throws IOException {\n+      OffsetRange currentRestriction = (OffsetRange) tracker.currentRestriction();\n+      Instant startRestriction = Instant.ofEpochMilli(currentRestriction.getFrom());\n+      Instant endRestriction = Instant.ofEpochMilli(currentRestriction.getTo());\n       HttpHealthcareApiClient.HL7v2MessagePages pages =\n-          new HttpHealthcareApiClient.HL7v2MessagePages(client, hl7v2Store, this.filter);\n+          new HttpHealthcareApiClient.HL7v2MessagePages(\n+              client, hl7v2Store, startRestriction, endRestriction, filter, \"sendTime\");\n       long reqestTime = Instant.now().getMillis();\n-      for (Stream<HL7v2Message> page : pages) {\n+      long lastClaimedMilliSecond;\n+      Instant cursor;\n+      boolean hangingClaim = false; // flag if the claimed ms spans spills over to the next page.\n+      for (List<HL7v2Message> page : pages) { // loop over pages.\n+        int i = 0;\n+        HL7v2Message msg = page.get(i);\n+        while (i < page.size()) { // loop over messages in page\n+          cursor = Instant.parse(msg.getSendTime());\n+          lastClaimedMilliSecond = cursor.getMillis();\n+          LOG.info(\n+              String.format(\n+                  \"initial claim for page %s lastClaimedMilliSecond = %s\",\n+                  i, lastClaimedMilliSecond));\n+          if (hangingClaim || tracker.tryClaim(lastClaimedMilliSecond)) {", "originalCommit": "e8859e7ff7770c5965e3eea18e0b0da5e4fe3d9c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0NTYxNw==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427545617", "bodyText": "tl;dr No that is not possible based on 629-640\ntryClaim on 624 claims lastClaimedMillisSecond\ntryClaim on 645 claims the millisecond of the cursor (which is advanced based on the while loop in L629-633)\nif the cusor is not advanced to a new millisecond (this happens when many messages at the end of a page came in the same millisecond) the if block in L636-640 contains continue which will eagerly exit this iteration of the while loop before getting to the try claim on L645 again. I called this scenario \"hangingClaim\" because we  cannot know if the first message(s) of the next page will also be from this millisecond.", "author": "jaketf", "createdAt": "2020-05-19T19:25:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzUyNzkxOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0NjY0MQ==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427546641", "bodyText": "sgtm", "author": "pabloem", "createdAt": "2020-05-19T19:27:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzUyNzkxOA=="}], "type": "inlineReview"}, {"oid": "4cb7a5c81456779138615f35a06226f2ed24b3b5", "url": "https://github.com/apache/beam/commit/4cb7a5c81456779138615f35a06226f2ed24b3b5", "message": "fix handling of ValueProvider interface", "committedDate": "2020-05-19T19:29:02Z", "type": "commit"}, {"oid": "2a9b535c7e5d81b65c297e6af7c6875c77293c0a", "url": "https://github.com/apache/beam/commit/2a9b535c7e5d81b65c297e6af7c6875c77293c0a", "message": "fix IT healthcare dataset reference", "committedDate": "2020-05-19T19:30:28Z", "type": "commit"}, {"oid": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "url": "https://github.com/apache/beam/commit/32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "message": "fix value provider for read and write", "committedDate": "2020-05-19T19:50:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYxNjg1Ng==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427616856", "bodyText": "wouldn' this just be a small amount of waste since we would effectively get an empty response?", "author": "lukecwik", "createdAt": "2020-05-19T21:41:05Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -415,10 +423,29 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n     }\n   }\n \n-  /** List HL7v2 messages in HL7v2 Stores with optional filter. */\n+  /**\n+   * List HL7v2 messages in HL7v2 Stores with optional filter.\n+   *\n+   * <p>This transform is optimized for dynamic splitting of message.list calls for large batches of\n+   * historical data and assumes rather continuous stream of sendTimes. It will dynamically\n+   * rebalance resources to handle \"peak traffic times\" but will waste resources if there are large\n+   * durations (days) of the sendTime dimension without data.", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY0MDExMQ==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427640111", "bodyText": "correct.", "author": "jaketf", "createdAt": "2020-05-19T22:38:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYxNjg1Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY0Mzg4OA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427643888", "bodyText": "note to self: remove reference to \"dynamically rebalance\" as this is not yet supported by dataflow runner.", "author": "jaketf", "createdAt": "2020-05-19T22:50:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYxNjg1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYxNzI4Ng==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427617286", "bodyText": "consider using <ol> and <li> tags in the javadoc for your ordered list", "author": "lukecwik", "createdAt": "2020-05-19T21:42:09Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -415,10 +423,29 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n     }\n   }\n \n-  /** List HL7v2 messages in HL7v2 Stores with optional filter. */\n+  /**\n+   * List HL7v2 messages in HL7v2 Stores with optional filter.\n+   *\n+   * <p>This transform is optimized for dynamic splitting of message.list calls for large batches of\n+   * historical data and assumes rather continuous stream of sendTimes. It will dynamically\n+   * rebalance resources to handle \"peak traffic times\" but will waste resources if there are large\n+   * durations (days) of the sendTime dimension without data.\n+   *\n+   * <p>Implementation includes overhead for: 1. two api calls to determine the min/max sendTime of", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYxODA3MQ==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427618071", "bodyText": "Consider using {@code ...} when referring to code and {@link ...} for things you can directly link against.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * <p>This transform is optimized for dynamic splitting of message.list calls for large batches of\n          \n          \n            \n               * <p>This transform is optimized for dynamic splitting of {@code message.list} calls for large batches of", "author": "lukecwik", "createdAt": "2020-05-19T21:43:54Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -415,10 +423,29 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n     }\n   }\n \n-  /** List HL7v2 messages in HL7v2 Stores with optional filter. */\n+  /**\n+   * List HL7v2 messages in HL7v2 Stores with optional filter.\n+   *\n+   * <p>This transform is optimized for dynamic splitting of message.list calls for large batches of", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYxODYwMA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427618600", "bodyText": "I'm not sure if the users need to know the exact implementation details as this may lock future maintainers into meeting these goals even when they can produce a more efficient solution in the future.", "author": "lukecwik", "createdAt": "2020-05-19T21:45:05Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -415,10 +423,29 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n     }\n   }\n \n-  /** List HL7v2 messages in HL7v2 Stores with optional filter. */\n+  /**\n+   * List HL7v2 messages in HL7v2 Stores with optional filter.\n+   *\n+   * <p>This transform is optimized for dynamic splitting of message.list calls for large batches of\n+   * historical data and assumes rather continuous stream of sendTimes. It will dynamically\n+   * rebalance resources to handle \"peak traffic times\" but will waste resources if there are large\n+   * durations (days) of the sendTime dimension without data.\n+   *\n+   * <p>Implementation includes overhead for: 1. two api calls to determine the min/max sendTime of\n+   * the HL7v2 store at invocation time. 2. initial splitting into non-overlapping time ranges\n+   * (default daily) to achieve parallelization in separate messages.list calls.", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY0MDg3Mw==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427640873", "bodyText": "I originally included this for users who may try to benchmark this against tiny / sparse results set and be surprised why it is slow / making so many api calls.\nI see your point will remove.", "author": "jaketf", "createdAt": "2020-05-19T22:41:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYxODYwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYxODc0Ng==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427618746", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * sparse data sets in the sendTime dimension).\n          \n          \n            \n               * sparse data sets in the {@code sendTime} dimension).", "author": "lukecwik", "createdAt": "2020-05-19T21:45:25Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -415,10 +423,29 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n     }\n   }\n \n-  /** List HL7v2 messages in HL7v2 Stores with optional filter. */\n+  /**\n+   * List HL7v2 messages in HL7v2 Stores with optional filter.\n+   *\n+   * <p>This transform is optimized for dynamic splitting of message.list calls for large batches of\n+   * historical data and assumes rather continuous stream of sendTimes. It will dynamically\n+   * rebalance resources to handle \"peak traffic times\" but will waste resources if there are large\n+   * durations (days) of the sendTime dimension without data.\n+   *\n+   * <p>Implementation includes overhead for: 1. two api calls to determine the min/max sendTime of\n+   * the HL7v2 store at invocation time. 2. initial splitting into non-overlapping time ranges\n+   * (default daily) to achieve parallelization in separate messages.list calls.\n+   *\n+   * <p>This will make more queries than necessary when used with very small data sets. (or very\n+   * sparse data sets in the sendTime dimension).", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYxOTEyNg==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427619126", "bodyText": "I don't think we want people to do this since empty splits are not that expensive and will quickly clear out a block of work.", "author": "lukecwik", "createdAt": "2020-05-19T21:46:16Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -415,10 +423,29 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n     }\n   }\n \n-  /** List HL7v2 messages in HL7v2 Stores with optional filter. */\n+  /**\n+   * List HL7v2 messages in HL7v2 Stores with optional filter.\n+   *\n+   * <p>This transform is optimized for dynamic splitting of message.list calls for large batches of\n+   * historical data and assumes rather continuous stream of sendTimes. It will dynamically\n+   * rebalance resources to handle \"peak traffic times\" but will waste resources if there are large\n+   * durations (days) of the sendTime dimension without data.\n+   *\n+   * <p>Implementation includes overhead for: 1. two api calls to determine the min/max sendTime of\n+   * the HL7v2 store at invocation time. 2. initial splitting into non-overlapping time ranges\n+   * (default daily) to achieve parallelization in separate messages.list calls.\n+   *\n+   * <p>This will make more queries than necessary when used with very small data sets. (or very\n+   * sparse data sets in the sendTime dimension).\n+   *\n+   * <p>If you have large but sparse data (e.g. hours between consecutive message sendTimes) and\n+   * know something about the time ranges where you have no data, consider using multiple instances\n+   * of this transform specifying sendTime filters to omit the ranges where there is no data.", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY0MTM1MA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427641350", "bodyText": "That's great to know! will remove this guidance as it will lead to unnecessary complexity.", "author": "jaketf", "createdAt": "2020-05-19T22:42:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYxOTEyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYyMDQwOA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427620408", "bodyText": "even if a member variable is null, it should still be final since it doesn't look like we mutate it locally. Same reason for other places I suggest to change this.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private ValueProvider<String> filter;\n          \n          \n            \n                private Duration initialSplitDuration;\n          \n          \n            \n                private final ValueProvider<String> filter;\n          \n          \n            \n                private final Duration initialSplitDuration;", "author": "lukecwik", "createdAt": "2020-05-19T21:49:04Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -415,10 +423,29 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n     }\n   }\n \n-  /** List HL7v2 messages in HL7v2 Stores with optional filter. */\n+  /**\n+   * List HL7v2 messages in HL7v2 Stores with optional filter.\n+   *\n+   * <p>This transform is optimized for dynamic splitting of message.list calls for large batches of\n+   * historical data and assumes rather continuous stream of sendTimes. It will dynamically\n+   * rebalance resources to handle \"peak traffic times\" but will waste resources if there are large\n+   * durations (days) of the sendTime dimension without data.\n+   *\n+   * <p>Implementation includes overhead for: 1. two api calls to determine the min/max sendTime of\n+   * the HL7v2 store at invocation time. 2. initial splitting into non-overlapping time ranges\n+   * (default daily) to achieve parallelization in separate messages.list calls.\n+   *\n+   * <p>This will make more queries than necessary when used with very small data sets. (or very\n+   * sparse data sets in the sendTime dimension).\n+   *\n+   * <p>If you have large but sparse data (e.g. hours between consecutive message sendTimes) and\n+   * know something about the time ranges where you have no data, consider using multiple instances\n+   * of this transform specifying sendTime filters to omit the ranges where there is no data.\n+   */\n   public static class ListHL7v2Messages extends PTransform<PBegin, PCollection<HL7v2Message>> {\n-    private final List<String> hl7v2Stores;\n-    private final String filter;\n+    private final ValueProvider<List<String>> hl7v2Stores;\n+    private ValueProvider<String> filter;\n+    private Duration initialSplitDuration;", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYyMDk4Mw==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427620983", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              static class ListHL7v2MessagesFn extends DoFn<String, HL7v2Message> {\n          \n          \n            \n              @VisibleForTesting\n          \n          \n            \n              static class ListHL7v2MessagesFn extends DoFn<String, HL7v2Message> {", "author": "lukecwik", "createdAt": "2020-05-19T21:50:19Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -427,29 +454,75 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n      * @param filter the filter\n      */\n     ListHL7v2Messages(ValueProvider<List<String>> hl7v2Stores, ValueProvider<String> filter) {\n-      this.hl7v2Stores = hl7v2Stores.get();\n-      this.filter = filter.get();\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = filter;\n+    }\n+\n+    /**\n+     * Instantiates a new List hl 7 v 2 messages.\n+     *\n+     * @param hl7v2Stores the hl 7 v 2 stores\n+     * @param filter the filter\n+     * @param initialSplitDuration the initial split duration for sendTime dimension splits\n+     */\n+    ListHL7v2Messages(\n+        ValueProvider<List<String>> hl7v2Stores,\n+        ValueProvider<String> filter,\n+        Duration initialSplitDuration) {\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = filter;\n+      this.initialSplitDuration = initialSplitDuration;\n     }\n \n+    /**\n+     * Instantiates a new List hl7v2 messages.\n+     *\n+     * @param hl7v2Stores the hl7v2 stores\n+     */\n     ListHL7v2Messages(ValueProvider<List<String>> hl7v2Stores) {\n-      this.hl7v2Stores = hl7v2Stores.get();\n+      this.hl7v2Stores = hl7v2Stores;\n       this.filter = null;\n     }\n \n+    /**\n+     * Instantiates a new List hl7v2 messages.\n+     *\n+     * @param hl7v2Stores the hl7v2 stores\n+     * @param initialSplitDuration the initial split duration\n+     */\n+    ListHL7v2Messages(ValueProvider<List<String>> hl7v2Stores, Duration initialSplitDuration) {\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.initialSplitDuration = initialSplitDuration;\n+    }\n+\n     @Override\n     public PCollection<HL7v2Message> expand(PBegin input) {\n       return input\n-          .apply(Create.of(this.hl7v2Stores))\n-          .apply(ParDo.of(new ListHL7v2MessagesFn(this.filter)))\n+          .apply(Create.ofProvider(this.hl7v2Stores, ListCoder.of(StringUtf8Coder.of())))\n+          .apply(FlatMapElements.into(TypeDescriptors.strings()).via((x) -> x))\n+          .apply(ParDo.of(new ListHL7v2MessagesFn(this.filter, initialSplitDuration)))\n           .setCoder(new HL7v2MessageCoder())\n           // Break fusion to encourage parallelization of downstream processing.\n           .apply(Reshuffle.viaRandomKey());\n     }\n   }\n \n+  /**\n+   * Implemented as Splitable DoFn that claims millisecond resolutions of offset restrictions in the\n+   * Message.sendTime dimension.\n+   */\n+  @BoundedPerElement\n   static class ListHL7v2MessagesFn extends DoFn<String, HL7v2Message> {", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYyMjQzOA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427622438", "bodyText": "Can any of these be final?", "author": "lukecwik", "createdAt": "2020-05-19T21:53:36Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -427,29 +454,75 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n      * @param filter the filter\n      */\n     ListHL7v2Messages(ValueProvider<List<String>> hl7v2Stores, ValueProvider<String> filter) {\n-      this.hl7v2Stores = hl7v2Stores.get();\n-      this.filter = filter.get();\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = filter;\n+    }\n+\n+    /**\n+     * Instantiates a new List hl 7 v 2 messages.\n+     *\n+     * @param hl7v2Stores the hl 7 v 2 stores\n+     * @param filter the filter\n+     * @param initialSplitDuration the initial split duration for sendTime dimension splits\n+     */\n+    ListHL7v2Messages(\n+        ValueProvider<List<String>> hl7v2Stores,\n+        ValueProvider<String> filter,\n+        Duration initialSplitDuration) {\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = filter;\n+      this.initialSplitDuration = initialSplitDuration;\n     }\n \n+    /**\n+     * Instantiates a new List hl7v2 messages.\n+     *\n+     * @param hl7v2Stores the hl7v2 stores\n+     */\n     ListHL7v2Messages(ValueProvider<List<String>> hl7v2Stores) {\n-      this.hl7v2Stores = hl7v2Stores.get();\n+      this.hl7v2Stores = hl7v2Stores;\n       this.filter = null;\n     }\n \n+    /**\n+     * Instantiates a new List hl7v2 messages.\n+     *\n+     * @param hl7v2Stores the hl7v2 stores\n+     * @param initialSplitDuration the initial split duration\n+     */\n+    ListHL7v2Messages(ValueProvider<List<String>> hl7v2Stores, Duration initialSplitDuration) {\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.initialSplitDuration = initialSplitDuration;\n+    }\n+\n     @Override\n     public PCollection<HL7v2Message> expand(PBegin input) {\n       return input\n-          .apply(Create.of(this.hl7v2Stores))\n-          .apply(ParDo.of(new ListHL7v2MessagesFn(this.filter)))\n+          .apply(Create.ofProvider(this.hl7v2Stores, ListCoder.of(StringUtf8Coder.of())))\n+          .apply(FlatMapElements.into(TypeDescriptors.strings()).via((x) -> x))\n+          .apply(ParDo.of(new ListHL7v2MessagesFn(this.filter, initialSplitDuration)))\n           .setCoder(new HL7v2MessageCoder())\n           // Break fusion to encourage parallelization of downstream processing.\n           .apply(Reshuffle.viaRandomKey());\n     }\n   }\n \n+  /**\n+   * Implemented as Splitable DoFn that claims millisecond resolutions of offset restrictions in the\n+   * Message.sendTime dimension.\n+   */\n+  @BoundedPerElement\n   static class ListHL7v2MessagesFn extends DoFn<String, HL7v2Message> {\n \n-    private final String filter;\n+    private static final Logger LOG = LoggerFactory.getLogger(ListHL7v2MessagesFn.class);\n+    private ValueProvider<String> filter;\n+    // These control the initial restriction split which means that the list of integer pairs\n+    // must comfortably fit in memory.\n+    private static final Duration DEFAULT_DESIRED_SPLIT_DURATION = Duration.standardDays(1);\n+    private static final Duration DEFAULT_MIN_SPLIT_DURATION = Duration.standardHours(1);\n+    private Duration initialSplitDuration;\n+    private Instant from;\n+    private Instant to;", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY4Njk3NA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427686974", "bodyText": "I don't think so they don't get set until we make the earliest / lastest sendTime query in @GetInitialRestriction", "author": "jaketf", "createdAt": "2020-05-20T01:14:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYyMjQzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYyMjYwNA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427622604", "bodyText": "nit: Might want to group your statics at the top together separate from the member variables.", "author": "lukecwik", "createdAt": "2020-05-19T21:54:02Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -427,29 +454,75 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n      * @param filter the filter\n      */\n     ListHL7v2Messages(ValueProvider<List<String>> hl7v2Stores, ValueProvider<String> filter) {\n-      this.hl7v2Stores = hl7v2Stores.get();\n-      this.filter = filter.get();\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = filter;\n+    }\n+\n+    /**\n+     * Instantiates a new List hl 7 v 2 messages.\n+     *\n+     * @param hl7v2Stores the hl 7 v 2 stores\n+     * @param filter the filter\n+     * @param initialSplitDuration the initial split duration for sendTime dimension splits\n+     */\n+    ListHL7v2Messages(\n+        ValueProvider<List<String>> hl7v2Stores,\n+        ValueProvider<String> filter,\n+        Duration initialSplitDuration) {\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = filter;\n+      this.initialSplitDuration = initialSplitDuration;\n     }\n \n+    /**\n+     * Instantiates a new List hl7v2 messages.\n+     *\n+     * @param hl7v2Stores the hl7v2 stores\n+     */\n     ListHL7v2Messages(ValueProvider<List<String>> hl7v2Stores) {\n-      this.hl7v2Stores = hl7v2Stores.get();\n+      this.hl7v2Stores = hl7v2Stores;\n       this.filter = null;\n     }\n \n+    /**\n+     * Instantiates a new List hl7v2 messages.\n+     *\n+     * @param hl7v2Stores the hl7v2 stores\n+     * @param initialSplitDuration the initial split duration\n+     */\n+    ListHL7v2Messages(ValueProvider<List<String>> hl7v2Stores, Duration initialSplitDuration) {\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.initialSplitDuration = initialSplitDuration;\n+    }\n+\n     @Override\n     public PCollection<HL7v2Message> expand(PBegin input) {\n       return input\n-          .apply(Create.of(this.hl7v2Stores))\n-          .apply(ParDo.of(new ListHL7v2MessagesFn(this.filter)))\n+          .apply(Create.ofProvider(this.hl7v2Stores, ListCoder.of(StringUtf8Coder.of())))\n+          .apply(FlatMapElements.into(TypeDescriptors.strings()).via((x) -> x))\n+          .apply(ParDo.of(new ListHL7v2MessagesFn(this.filter, initialSplitDuration)))\n           .setCoder(new HL7v2MessageCoder())\n           // Break fusion to encourage parallelization of downstream processing.\n           .apply(Reshuffle.viaRandomKey());\n     }\n   }\n \n+  /**\n+   * Implemented as Splitable DoFn that claims millisecond resolutions of offset restrictions in the\n+   * Message.sendTime dimension.\n+   */\n+  @BoundedPerElement\n   static class ListHL7v2MessagesFn extends DoFn<String, HL7v2Message> {\n \n-    private final String filter;\n+    private static final Logger LOG = LoggerFactory.getLogger(ListHL7v2MessagesFn.class);\n+    private ValueProvider<String> filter;\n+    // These control the initial restriction split which means that the list of integer pairs\n+    // must comfortably fit in memory.\n+    private static final Duration DEFAULT_DESIRED_SPLIT_DURATION = Duration.standardDays(1);\n+    private static final Duration DEFAULT_MIN_SPLIT_DURATION = Duration.standardHours(1);", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYyMzExMA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427623110", "bodyText": "https://stackoverflow.com/questions/285177/how-do-i-call-one-constructor-from-another-in-java\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  new ListHL7v2MessagesFn(StaticValueProvider.of(filter), null);\n          \n          \n            \n                  this(StaticValueProvider.of(filter), null);", "author": "lukecwik", "createdAt": "2020-05-19T21:55:11Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -459,7 +532,13 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n      * @param filter the filter\n      */\n     ListHL7v2MessagesFn(String filter) {\n+      new ListHL7v2MessagesFn(StaticValueProvider.of(filter), null);", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYyNDIzOA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427624238", "bodyText": "This method is not necessary since OffsetRange supports HasDefaultTracker which your effectively invoking yourself.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                @NewTracker\n          \n          \n            \n                public OffsetRangeTracker newTracker(@Restriction OffsetRange timeRange) {\n          \n          \n            \n                  return timeRange.newTracker();\n          \n          \n            \n                }", "author": "lukecwik", "createdAt": "2020-05-19T21:57:39Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -472,24 +551,118 @@ public void initClient() throws IOException {\n       this.client = new HttpHealthcareApiClient();\n     }\n \n+    @GetInitialRestriction\n+    public OffsetRange getEarliestToLatestRestriction(@Element String hl7v2Store)\n+        throws IOException {\n+      from = this.client.getEarliestHL7v2SendTime(hl7v2Store, this.filter.get());\n+      // filters are [from, to) to match logic of OffsetRangeTracker but need latest element to be\n+      // included in results set to add an extra ms to the upper bound.\n+      to = this.client.getLatestHL7v2SendTime(hl7v2Store, this.filter.get()).plus(1);\n+      return new OffsetRange(from.getMillis(), to.getMillis());\n+    }\n+\n+    @NewTracker\n+    public OffsetRangeTracker newTracker(@Restriction OffsetRange timeRange) {\n+      return timeRange.newTracker();\n+    }\n+", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYyNTE2Nw==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427625167", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    RestrictionTracker tracker,\n          \n          \n            \n                    RestrictionTracker<OffsetRange, Long> tracker,", "author": "lukecwik", "createdAt": "2020-05-19T21:59:51Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -472,24 +551,118 @@ public void initClient() throws IOException {\n       this.client = new HttpHealthcareApiClient();\n     }\n \n+    @GetInitialRestriction\n+    public OffsetRange getEarliestToLatestRestriction(@Element String hl7v2Store)\n+        throws IOException {\n+      from = this.client.getEarliestHL7v2SendTime(hl7v2Store, this.filter.get());\n+      // filters are [from, to) to match logic of OffsetRangeTracker but need latest element to be\n+      // included in results set to add an extra ms to the upper bound.\n+      to = this.client.getLatestHL7v2SendTime(hl7v2Store, this.filter.get()).plus(1);\n+      return new OffsetRange(from.getMillis(), to.getMillis());\n+    }\n+\n+    @NewTracker\n+    public OffsetRangeTracker newTracker(@Restriction OffsetRange timeRange) {\n+      return timeRange.newTracker();\n+    }\n+\n+    @SplitRestriction\n+    public void split(@Restriction OffsetRange timeRange, OutputReceiver<OffsetRange> out) {\n+      List<OffsetRange> splits =\n+          timeRange.split(initialSplitDuration.getMillis(), DEFAULT_MIN_SPLIT_DURATION.getMillis());\n+      Instant from = Instant.ofEpochMilli(timeRange.getFrom());\n+      Instant to = Instant.ofEpochMilli(timeRange.getTo());\n+      Duration totalDuration = new Duration(from, to);\n+      LOG.info(\n+          String.format(\n+              \"splitting initial sendTime restriction of [minSendTime, now): [%s,%s), \"\n+                  + \"or [%s, %s). \\n\"\n+                  + \"total days: %s \\n\"\n+                  + \"into %s splits. \\n\"\n+                  + \"Last split: %s\",\n+              from,\n+              to,\n+              timeRange.getFrom(),\n+              timeRange.getTo(),\n+              totalDuration.getStandardDays(),\n+              splits.size(),\n+              splits.get(splits.size() - 1).toString()));\n+\n+      for (OffsetRange s : splits) {\n+        out.output(s);\n+      }\n+    }\n+\n     /**\n      * List messages.\n      *\n-     * @param context the context\n+     * @param hl7v2Store the HL7v2 store to list messages from\n      * @throws IOException the io exception\n      */\n     @ProcessElement\n-    public void listMessages(ProcessContext context) throws IOException {\n-      String hl7v2Store = context.element();\n-      // Output all elements of all pages.\n+    public void listMessages(\n+        @Element String hl7v2Store,\n+        RestrictionTracker tracker,", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYyOTMxMw==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427629313", "bodyText": "It would sense to move this into wherever we do the list call.", "author": "lukecwik", "createdAt": "2020-05-19T22:09:50Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -472,24 +551,118 @@ public void initClient() throws IOException {\n       this.client = new HttpHealthcareApiClient();\n     }\n \n+    @GetInitialRestriction\n+    public OffsetRange getEarliestToLatestRestriction(@Element String hl7v2Store)\n+        throws IOException {\n+      from = this.client.getEarliestHL7v2SendTime(hl7v2Store, this.filter.get());\n+      // filters are [from, to) to match logic of OffsetRangeTracker but need latest element to be\n+      // included in results set to add an extra ms to the upper bound.\n+      to = this.client.getLatestHL7v2SendTime(hl7v2Store, this.filter.get()).plus(1);\n+      return new OffsetRange(from.getMillis(), to.getMillis());\n+    }\n+\n+    @NewTracker\n+    public OffsetRangeTracker newTracker(@Restriction OffsetRange timeRange) {\n+      return timeRange.newTracker();\n+    }\n+\n+    @SplitRestriction\n+    public void split(@Restriction OffsetRange timeRange, OutputReceiver<OffsetRange> out) {\n+      List<OffsetRange> splits =\n+          timeRange.split(initialSplitDuration.getMillis(), DEFAULT_MIN_SPLIT_DURATION.getMillis());\n+      Instant from = Instant.ofEpochMilli(timeRange.getFrom());\n+      Instant to = Instant.ofEpochMilli(timeRange.getTo());\n+      Duration totalDuration = new Duration(from, to);\n+      LOG.info(\n+          String.format(\n+              \"splitting initial sendTime restriction of [minSendTime, now): [%s,%s), \"\n+                  + \"or [%s, %s). \\n\"\n+                  + \"total days: %s \\n\"\n+                  + \"into %s splits. \\n\"\n+                  + \"Last split: %s\",\n+              from,\n+              to,\n+              timeRange.getFrom(),\n+              timeRange.getTo(),\n+              totalDuration.getStandardDays(),\n+              splits.size(),\n+              splits.get(splits.size() - 1).toString()));\n+\n+      for (OffsetRange s : splits) {\n+        out.output(s);\n+      }\n+    }\n+\n     /**\n      * List messages.\n      *\n-     * @param context the context\n+     * @param hl7v2Store the HL7v2 store to list messages from\n      * @throws IOException the io exception\n      */\n     @ProcessElement\n-    public void listMessages(ProcessContext context) throws IOException {\n-      String hl7v2Store = context.element();\n-      // Output all elements of all pages.\n+    public void listMessages(\n+        @Element String hl7v2Store,\n+        RestrictionTracker tracker,\n+        OutputReceiver<HL7v2Message> outputReceiver)\n+        throws IOException {\n+      OffsetRange currentRestriction = (OffsetRange) tracker.currentRestriction();\n+      Instant startRestriction = Instant.ofEpochMilli(currentRestriction.getFrom());\n+      Instant endRestriction = Instant.ofEpochMilli(currentRestriction.getTo());\n       HttpHealthcareApiClient.HL7v2MessagePages pages =\n-          new HttpHealthcareApiClient.HL7v2MessagePages(client, hl7v2Store, this.filter);\n+          new HttpHealthcareApiClient.HL7v2MessagePages(\n+              client, hl7v2Store, startRestriction, endRestriction, filter.get(), \"sendTime\");\n       long reqestTime = Instant.now().getMillis();\n-      for (Stream<HL7v2Message> page : pages) {\n+      long lastClaimedMilliSecond;\n+      Instant cursor;\n+      boolean hangingClaim = false; // flag if the claimed ms spans spills over to the next page.\n+      for (List<HL7v2Message> page : pages) { // loop over pages.\n+        int i = 0;\n+        HL7v2Message msg = page.get(i);\n+        while (i < page.size()) { // loop over messages in page\n+          cursor = Instant.parse(msg.getSendTime());\n+          lastClaimedMilliSecond = cursor.getMillis();\n+          LOG.info(\n+              String.format(\n+                  \"initial claim for page %s lastClaimedMilliSecond = %s\",\n+                  i, lastClaimedMilliSecond));\n+          if (hangingClaim || tracker.tryClaim(lastClaimedMilliSecond)) {\n+            // This means we have claimed an entire millisecond we need to make sure that we\n+            // process all messages for this millisecond because sendTime is allegedly nano second\n+            // resolution.\n+            // https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages#Message\n+            while (cursor.getMillis() == lastClaimedMilliSecond\n+                && i < page.size()) { // loop over messages in millisecond.\n+              outputReceiver.output(msg);\n+              msg = page.get(i++);\n+              cursor = Instant.parse(msg.getSendTime());\n+            }\n+\n+            if (i == page.size() && cursor.getMillis() == lastClaimedMilliSecond) {\n+              // reached the end of the page and timestamp still in the claimed ms.\n+              hangingClaim = true;\n+              continue;\n+            }\n+\n+            // If reached this point, msg.sendTime is outside the current claim.\n+            // Need to claim time range up to (and including) the cursor to properly advance the\n+            // tracker.\n+            tracker.tryClaim(cursor.getMillis());\n+            lastClaimedMilliSecond = cursor.getMillis();\n+            LOG.info(\n+                String.format(\n+                    \"After claiming between messages lastClaimedMilliSecond = %s\",\n+                    lastClaimedMilliSecond));\n+          }\n+        }\n         messageListingLatencyMs.update(Instant.now().getMillis() - reqestTime);", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYzMzI0MA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427633240", "bodyText": "Should we be outputting elements with the timestamp of the message and should we be reporting a watermark?\nEven though you have a bounded SDF, it could be useful to report the watermark incase it is used in a streaming pipeline or users wanted to assign windows and perform grouping per window.\nThe current logic will assign the input's timestamp to all outputs which won't allow users to use windowing to effectively window the elements being output without assigning timestamps themselves. If we do want to go down this path it is simple right now because this transform always starts with PBegin but what would you want to do it the timestamp of the record is before the timestamp of the input element to the SDF (since it is illegal to output messages with timestamps before the input elements timestamp)?\nTo add watermark tracking based on timestamp of elements output, you would need to add the implementation for @GetInitialWatermarkEstimatorState and @NewWatermarkEstimator as seen in \n  \n    \n      beam/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/Watch.java\n    \n    \n         Line 763\n      in\n      27656d7\n    \n    \n    \n    \n\n        \n          \n           @GetInitialWatermarkEstimatorState", "author": "lukecwik", "createdAt": "2020-05-19T22:19:40Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -472,24 +551,118 @@ public void initClient() throws IOException {\n       this.client = new HttpHealthcareApiClient();\n     }\n \n+    @GetInitialRestriction\n+    public OffsetRange getEarliestToLatestRestriction(@Element String hl7v2Store)\n+        throws IOException {\n+      from = this.client.getEarliestHL7v2SendTime(hl7v2Store, this.filter.get());\n+      // filters are [from, to) to match logic of OffsetRangeTracker but need latest element to be\n+      // included in results set to add an extra ms to the upper bound.\n+      to = this.client.getLatestHL7v2SendTime(hl7v2Store, this.filter.get()).plus(1);\n+      return new OffsetRange(from.getMillis(), to.getMillis());\n+    }\n+\n+    @NewTracker\n+    public OffsetRangeTracker newTracker(@Restriction OffsetRange timeRange) {\n+      return timeRange.newTracker();\n+    }\n+\n+    @SplitRestriction\n+    public void split(@Restriction OffsetRange timeRange, OutputReceiver<OffsetRange> out) {\n+      List<OffsetRange> splits =\n+          timeRange.split(initialSplitDuration.getMillis(), DEFAULT_MIN_SPLIT_DURATION.getMillis());\n+      Instant from = Instant.ofEpochMilli(timeRange.getFrom());\n+      Instant to = Instant.ofEpochMilli(timeRange.getTo());\n+      Duration totalDuration = new Duration(from, to);\n+      LOG.info(\n+          String.format(\n+              \"splitting initial sendTime restriction of [minSendTime, now): [%s,%s), \"\n+                  + \"or [%s, %s). \\n\"\n+                  + \"total days: %s \\n\"\n+                  + \"into %s splits. \\n\"\n+                  + \"Last split: %s\",\n+              from,\n+              to,\n+              timeRange.getFrom(),\n+              timeRange.getTo(),\n+              totalDuration.getStandardDays(),\n+              splits.size(),\n+              splits.get(splits.size() - 1).toString()));\n+\n+      for (OffsetRange s : splits) {\n+        out.output(s);\n+      }\n+    }\n+\n     /**\n      * List messages.\n      *\n-     * @param context the context\n+     * @param hl7v2Store the HL7v2 store to list messages from\n      * @throws IOException the io exception\n      */\n     @ProcessElement\n-    public void listMessages(ProcessContext context) throws IOException {\n-      String hl7v2Store = context.element();\n-      // Output all elements of all pages.\n+    public void listMessages(\n+        @Element String hl7v2Store,\n+        RestrictionTracker tracker,\n+        OutputReceiver<HL7v2Message> outputReceiver)\n+        throws IOException {\n+      OffsetRange currentRestriction = (OffsetRange) tracker.currentRestriction();\n+      Instant startRestriction = Instant.ofEpochMilli(currentRestriction.getFrom());\n+      Instant endRestriction = Instant.ofEpochMilli(currentRestriction.getTo());\n       HttpHealthcareApiClient.HL7v2MessagePages pages =\n-          new HttpHealthcareApiClient.HL7v2MessagePages(client, hl7v2Store, this.filter);\n+          new HttpHealthcareApiClient.HL7v2MessagePages(\n+              client, hl7v2Store, startRestriction, endRestriction, filter.get(), \"sendTime\");\n       long reqestTime = Instant.now().getMillis();\n-      for (Stream<HL7v2Message> page : pages) {\n+      long lastClaimedMilliSecond;\n+      Instant cursor;\n+      boolean hangingClaim = false; // flag if the claimed ms spans spills over to the next page.\n+      for (List<HL7v2Message> page : pages) { // loop over pages.\n+        int i = 0;\n+        HL7v2Message msg = page.get(i);\n+        while (i < page.size()) { // loop over messages in page\n+          cursor = Instant.parse(msg.getSendTime());\n+          lastClaimedMilliSecond = cursor.getMillis();\n+          LOG.info(\n+              String.format(\n+                  \"initial claim for page %s lastClaimedMilliSecond = %s\",\n+                  i, lastClaimedMilliSecond));\n+          if (hangingClaim || tracker.tryClaim(lastClaimedMilliSecond)) {\n+            // This means we have claimed an entire millisecond we need to make sure that we\n+            // process all messages for this millisecond because sendTime is allegedly nano second\n+            // resolution.\n+            // https://cloud.google.com/healthcare/docs/reference/rest/v1beta1/projects.locations.datasets.hl7V2Stores.messages#Message\n+            while (cursor.getMillis() == lastClaimedMilliSecond\n+                && i < page.size()) { // loop over messages in millisecond.\n+              outputReceiver.output(msg);", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY1NDk4Ng==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427654986", "bodyText": "Thanks for suggestion.\nIn the interest of time, can I punt this to a future PR?", "author": "jaketf", "createdAt": "2020-05-19T23:23:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYzMzI0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEwNDkxMA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r428104910", "bodyText": "Yes we can defer since this would change what people are getting from the existing implementation and would likely require opt in to not break any existing users.\nIf nobody depends on this transform yet then it would be wise to address it before adoption since a lot of users typically expect the output timestamp to match the record's source timestamp. This may not apply to this specific source and is dependent on what users expect so itis your judgement call.\nIf you do go with changing the output timestamp, the watermark tracking would help for streaming pipelines since it would allow them to perform better. The current implementation would still produce correct results with or without and adding it later would be very safe (it may expose problems in pipelines that were already broken for other reasons).", "author": "lukecwik", "createdAt": "2020-05-20T15:28:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYzMzI0MA=="}], "type": "inlineReview"}, {"oid": "5642b3198b30ac6318ba431a3db079e551f86b80", "url": "https://github.com/apache/beam/commit/5642b3198b30ac6318ba431a3db079e551f86b80", "message": "Update sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java\n\nCo-authored-by: Lukasz Cwik <lcwik@google.com>", "committedDate": "2020-05-19T22:38:09Z", "type": "commit"}, {"oid": "b34a0a141acf58e3975017f7234ad08926d8fc9a", "url": "https://github.com/apache/beam/commit/b34a0a141acf58e3975017f7234ad08926d8fc9a", "message": "Update sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java\n\nCo-authored-by: Lukasz Cwik <lcwik@google.com>", "committedDate": "2020-05-19T22:41:09Z", "type": "commit"}, {"oid": "0fe405a0734322ad75860f1d9b6141423dd2790f", "url": "https://github.com/apache/beam/commit/0fe405a0734322ad75860f1d9b6141423dd2790f", "message": "Update sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java\n\nCo-authored-by: Lukasz Cwik <lcwik@google.com>", "committedDate": "2020-05-19T22:43:01Z", "type": "commit"}, {"oid": "87e47a351a317a84cf76348d17d0287a675c7337", "url": "https://github.com/apache/beam/commit/87e47a351a317a84cf76348d17d0287a675c7337", "message": "Update sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java\n\nCo-authored-by: Lukasz Cwik <lcwik@google.com>", "committedDate": "2020-05-19T22:43:26Z", "type": "commit"}, {"oid": "43b97bb2f2822e37c52882f19a9583de5271209a", "url": "https://github.com/apache/beam/commit/43b97bb2f2822e37c52882f19a9583de5271209a", "message": "Update sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java\n\nCo-authored-by: Lukasz Cwik <lcwik@google.com>", "committedDate": "2020-05-19T22:44:03Z", "type": "commit"}, {"oid": "3c74a0fe1da1478b3751327c7f2f81f5b383a1d5", "url": "https://github.com/apache/beam/commit/3c74a0fe1da1478b3751327c7f2f81f5b383a1d5", "message": "Update sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java\n\nCo-authored-by: Lukasz Cwik <lcwik@google.com>", "committedDate": "2020-05-19T22:44:29Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY0MzM4Nw==", "url": "https://github.com/apache/beam/pull/11596#discussion_r427643387", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * <p>This transform is optimized for dynamic splitting of message.list calls for large batches of\n          \n          \n            \n               * <p>This transform is optimized for splitting of message.list calls for large batches of", "author": "jaketf", "createdAt": "2020-05-19T22:48:23Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -415,10 +423,29 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n     }\n   }\n \n-  /** List HL7v2 messages in HL7v2 Stores with optional filter. */\n+  /**\n+   * List HL7v2 messages in HL7v2 Stores with optional filter.\n+   *\n+   * <p>This transform is optimized for dynamic splitting of message.list calls for large batches of", "originalCommit": "32d0bf08188aaadb36ea7efcb944a1ed5ec23898", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5033f23d087d9d910f10a4749d53e2eb6628d9c0", "url": "https://github.com/apache/beam/commit/5033f23d087d9d910f10a4749d53e2eb6628d9c0", "message": "Update sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java\n\nCo-authored-by: Lukasz Cwik <lcwik@google.com>", "committedDate": "2020-05-19T22:56:17Z", "type": "commit"}, {"oid": "c47fe42b355f603e6066c9f37db2e27420a6347b", "url": "https://github.com/apache/beam/commit/c47fe42b355f603e6066c9f37db2e27420a6347b", "message": "wip", "committedDate": "2020-05-20T01:00:01Z", "type": "commit"}, {"oid": "2af9ae6674f654aa34bb9234b2513f668fd62eee", "url": "https://github.com/apache/beam/commit/2af9ae6674f654aa34bb9234b2513f668fd62eee", "message": "Merge branch 'optimization/HL7v2IOListMessages' of github.com:jaketf/beam into optimization/HL7v2IOListMessages", "committedDate": "2020-05-20T01:09:59Z", "type": "commit"}, {"oid": "0b39ce7c7347732ce514296f53aefd0422501226", "url": "https://github.com/apache/beam/commit/0b39ce7c7347732ce514296f53aefd0422501226", "message": "address review feedback", "committedDate": "2020-05-20T01:18:59Z", "type": "commit"}, {"oid": "1502824158e87c35b7615287cd40237add4eb378", "url": "https://github.com/apache/beam/commit/1502824158e87c35b7615287cd40237add4eb378", "message": "fix mocked method in test and checkstyle", "committedDate": "2020-05-20T06:59:01Z", "type": "commit"}, {"oid": "efe64bef8fd3cfa91ad8ebbce25492c209f8bdc4", "url": "https://github.com/apache/beam/commit/efe64bef8fd3cfa91ad8ebbce25492c209f8bdc4", "message": "remove unused metric", "committedDate": "2020-05-20T07:27:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODA5NTM5MA==", "url": "https://github.com/apache/beam/pull/11596#discussion_r428095390", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (cursor.getMillis() > lastClaimedMilliSecond && tracker.tryClaim(cursor.getMillis())) {\n          \n          \n            \n                      lastClaimedMilliSecond = cursor.getMillis();\n          \n          \n            \n                    }\n          \n          \n            \n            \n          \n          \n            \n                    if (cursor.getMillis() == lastClaimedMilliSecond) { // loop over messages in millisecond.\n          \n          \n            \n                      outputReceiver.output(msg);\n          \n          \n            \n                    }\n          \n          \n            \n                    if (cursor.getMillis() > lastClaimedMilliSecond) {\n          \n          \n            \n                      // Return early after the first claim failure preventing us from iterating\n          \n          \n            \n                      // through the remaining messages.\n          \n          \n            \n                      if (!tracker.tryClaim(cursor.getMillis())) {\n          \n          \n            \n                        return;\n          \n          \n            \n                      }\n          \n          \n            \n                      lastClaimedMilliSecond = cursor.getMillis();\n          \n          \n            \n                    }\n          \n          \n            \n            \n          \n          \n            \n                    outputReceiver.output(msg);", "author": "lukecwik", "createdAt": "2020-05-20T15:15:44Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -472,24 +523,77 @@ public void initClient() throws IOException {\n       this.client = new HttpHealthcareApiClient();\n     }\n \n+    @GetInitialRestriction\n+    public OffsetRange getEarliestToLatestRestriction(@Element String hl7v2Store)\n+        throws IOException {\n+      from = this.client.getEarliestHL7v2SendTime(hl7v2Store, this.filter.get());\n+      // filters are [from, to) to match logic of OffsetRangeTracker but need latest element to be\n+      // included in results set to add an extra ms to the upper bound.\n+      to = this.client.getLatestHL7v2SendTime(hl7v2Store, this.filter.get()).plus(1);\n+      return new OffsetRange(from.getMillis(), to.getMillis());\n+    }\n+\n+    @SplitRestriction\n+    public void split(@Restriction OffsetRange timeRange, OutputReceiver<OffsetRange> out) {\n+      List<OffsetRange> splits =\n+          timeRange.split(initialSplitDuration.getMillis(), DEFAULT_MIN_SPLIT_DURATION.getMillis());\n+      Instant from = Instant.ofEpochMilli(timeRange.getFrom());\n+      Instant to = Instant.ofEpochMilli(timeRange.getTo());\n+      Duration totalDuration = new Duration(from, to);\n+      LOG.info(\n+          String.format(\n+              \"splitting initial sendTime restriction of [minSendTime, now): [%s,%s), \"\n+                  + \"or [%s, %s). \\n\"\n+                  + \"total days: %s \\n\"\n+                  + \"into %s splits. \\n\"\n+                  + \"Last split: %s\",\n+              from,\n+              to,\n+              timeRange.getFrom(),\n+              timeRange.getTo(),\n+              totalDuration.getStandardDays(),\n+              splits.size(),\n+              splits.get(splits.size() - 1).toString()));\n+\n+      for (OffsetRange s : splits) {\n+        out.output(s);\n+      }\n+    }\n+\n     /**\n      * List messages.\n      *\n-     * @param context the context\n+     * @param hl7v2Store the HL7v2 store to list messages from\n      * @throws IOException the io exception\n      */\n     @ProcessElement\n-    public void listMessages(ProcessContext context) throws IOException {\n-      String hl7v2Store = context.element();\n-      // Output all elements of all pages.\n+    public void listMessages(\n+        @Element String hl7v2Store,\n+        RestrictionTracker<OffsetRange, Long> tracker,\n+        OutputReceiver<HL7v2Message> outputReceiver)\n+        throws IOException {\n+      OffsetRange currentRestriction = (OffsetRange) tracker.currentRestriction();\n+      Instant startRestriction = Instant.ofEpochMilli(currentRestriction.getFrom());\n+      Instant endRestriction = Instant.ofEpochMilli(currentRestriction.getTo());\n       HttpHealthcareApiClient.HL7v2MessagePages pages =\n-          new HttpHealthcareApiClient.HL7v2MessagePages(client, hl7v2Store, this.filter);\n-      long reqestTime = Instant.now().getMillis();\n-      for (Stream<HL7v2Message> page : pages) {\n-        messageListingLatencyMs.update(Instant.now().getMillis() - reqestTime);\n-        page.forEach(context::output);\n-        reqestTime = Instant.now().getMillis();\n+          new HttpHealthcareApiClient.HL7v2MessagePages(\n+              client, hl7v2Store, startRestriction, endRestriction, filter.get(), \"sendTime\");\n+      Instant cursor;\n+      long lastClaimedMilliSecond = startRestriction.getMillis() - 1;\n+      for (HL7v2Message msg : FluentIterable.concat(pages)) {\n+        cursor = Instant.parse(msg.getSendTime());\n+        if (cursor.getMillis() > lastClaimedMilliSecond && tracker.tryClaim(cursor.getMillis())) {\n+          lastClaimedMilliSecond = cursor.getMillis();\n+        }\n+\n+        if (cursor.getMillis() == lastClaimedMilliSecond) { // loop over messages in millisecond.\n+          outputReceiver.output(msg);\n+        }", "originalCommit": "efe64bef8fd3cfa91ad8ebbce25492c209f8bdc4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEwNzYzNg==", "url": "https://github.com/apache/beam/pull/11596#discussion_r428107636", "bodyText": "from and to seem to only be used within @GetInitialRestriction, can we make them local variables there?", "author": "lukecwik", "createdAt": "2020-05-20T15:32:03Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -427,39 +458,59 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n      * @param filter the filter\n      */\n     ListHL7v2Messages(ValueProvider<List<String>> hl7v2Stores, ValueProvider<String> filter) {\n-      this.hl7v2Stores = hl7v2Stores.get();\n-      this.filter = filter.get();\n+      this.hl7v2Stores = hl7v2Stores;\n+      this.filter = filter;\n+      this.initialSplitDuration = null;\n     }\n \n-    ListHL7v2Messages(ValueProvider<List<String>> hl7v2Stores) {\n-      this.hl7v2Stores = hl7v2Stores.get();\n-      this.filter = null;\n+    public ListHL7v2Messages withInitialSplitDuration(Duration initialSplitDuration) {\n+      this.initialSplitDuration = initialSplitDuration;\n+      return this;\n     }\n \n     @Override\n     public PCollection<HL7v2Message> expand(PBegin input) {\n       return input\n-          .apply(Create.of(this.hl7v2Stores))\n-          .apply(ParDo.of(new ListHL7v2MessagesFn(this.filter)))\n-          .setCoder(new HL7v2MessageCoder())\n+          .apply(Create.ofProvider(this.hl7v2Stores, ListCoder.of(StringUtf8Coder.of())))\n+          .apply(FlatMapElements.into(TypeDescriptors.strings()).via((x) -> x))\n+          .apply(ParDo.of(new ListHL7v2MessagesFn(filter, initialSplitDuration)))\n+          .setCoder(HL7v2MessageCoder.of())\n           // Break fusion to encourage parallelization of downstream processing.\n           .apply(Reshuffle.viaRandomKey());\n     }\n   }\n \n+  /**\n+   * Implemented as Splitable DoFn that claims millisecond resolutions of offset restrictions in the\n+   * Message.sendTime dimension.\n+   */\n+  @BoundedPerElement\n+  @VisibleForTesting\n   static class ListHL7v2MessagesFn extends DoFn<String, HL7v2Message> {\n-\n-    private final String filter;\n+    // These control the initial restriction split which means that the list of integer pairs\n+    // must comfortably fit in memory.\n+    private static final Duration DEFAULT_DESIRED_SPLIT_DURATION = Duration.standardDays(1);\n+    private static final Duration DEFAULT_MIN_SPLIT_DURATION = Duration.standardHours(1);\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(ListHL7v2MessagesFn.class);\n+    private ValueProvider<String> filter;\n+    private Duration initialSplitDuration;\n+    private Instant from;\n+    private Instant to;", "originalCommit": "efe64bef8fd3cfa91ad8ebbce25492c209f8bdc4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEwODU0OQ==", "url": "https://github.com/apache/beam/pull/11596#discussion_r428108549", "bodyText": "Benchmarking By?\nAwkward sentence and capitalization.", "author": "lukecwik", "createdAt": "2020-05-20T15:33:21Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -415,10 +424,32 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n     }\n   }\n \n-  /** List HL7v2 messages in HL7v2 Stores with optional filter. */\n+  /**\n+   * List HL7v2 messages in HL7v2 Stores with optional filter.\n+   *\n+   * <p>This transform is optimized for splitting of message.list calls for large batches of\n+   * historical data and assumes rather continuous stream of sendTimes.\n+   *\n+   * <p>Note on Benchmarking By default, this will make more queries than necessary when used with", "originalCommit": "efe64bef8fd3cfa91ad8ebbce25492c209f8bdc4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1d94b4b67a8fba7ef8dd2425ce7d7a683b568fce", "url": "https://github.com/apache/beam/commit/1d94b4b67a8fba7ef8dd2425ce7d7a683b568fce", "message": "Update sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java\n\nCo-authored-by: Lukasz Cwik <lcwik@google.com>", "committedDate": "2020-05-20T16:01:52Z", "type": "commit"}, {"oid": "495865628421d75952269537a303dfd765b09bc2", "url": "https://github.com/apache/beam/commit/495865628421d75952269537a303dfd765b09bc2", "message": "incorporate review feedback", "committedDate": "2020-05-20T16:11:25Z", "type": "commit"}, {"oid": "ad57111e4ff59f1217520566d98da01ca3d8e390", "url": "https://github.com/apache/beam/commit/ad57111e4ff59f1217520566d98da01ca3d8e390", "message": "Merge branch 'optimization/HL7v2IOListMessages' of github.com:jaketf/beam into optimization/HL7v2IOListMessages", "committedDate": "2020-05-20T16:12:13Z", "type": "commit"}]}