{"pr_number": 10950, "pr_title": "[BEAM-9345] Add end-to-end Flink job submission test", "pr_createdAt": "2020-02-24T17:34:34Z", "pr_url": "https://github.com/apache/beam/pull/10950", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3MDQ2Nw==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383470467", "bodyText": "This method will return -1 if createRpcService has not been called. Maybe we should add an assertion here to prevent that.", "author": "ibzib", "createdAt": "2020-02-24T19:35:01Z", "path": "runners/flink/1.7/src/test/java/org/apache/beam/runners/flink/RemoteMiniClusterImpl.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import akka.actor.ActorSystem;\n+import com.typesafe.config.Config;\n+import org.apache.flink.api.common.time.Time;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.runtime.akka.AkkaUtils;\n+import org.apache.flink.runtime.minicluster.MiniCluster;\n+import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n+import org.apache.flink.runtime.rpc.RpcService;\n+import org.apache.flink.runtime.rpc.akka.AkkaRpcService;\n+\n+/** A {@link MiniCluster} which allows remote connections for the end-to-end test. */\n+public class RemoteMiniClusterImpl extends RemoteMiniCluster {\n+\n+  private int port = -1;\n+\n+  public RemoteMiniClusterImpl(MiniClusterConfiguration miniClusterConfiguration) {\n+    super(miniClusterConfiguration);\n+  }\n+\n+  @Override\n+  protected RpcService createRpcService(\n+      Configuration configuration, Time askTimeout, boolean remoteEnabled, String bindAddress) {\n+\n+    // Enable remote connections to the mini cluster which are disabled by default\n+    final Config akkaConfig = AkkaUtils.getAkkaConfig(configuration, \"localhost\", 0);\n+\n+    final Config effectiveAkkaConfig = AkkaUtils.testDispatcherConfig().withFallback(akkaConfig);\n+\n+    final ActorSystem actorSystem = AkkaUtils.createActorSystem(effectiveAkkaConfig);\n+\n+    AkkaRpcService akkaRpcService = new AkkaRpcService(actorSystem, askTimeout);\n+    this.port = akkaRpcService.getPort();\n+\n+    return akkaRpcService;\n+  }\n+\n+  @Override\n+  public int getClusterPort() {\n+    return port;", "originalCommit": "03454d39033d51eda1d991b636a2a7cbdcdf4991", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzc2MzIwMA==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383763200", "bodyText": "Yes, I was thinking the same but somehow missed this before opening the PR. Added the check now.", "author": "mxm", "createdAt": "2020-02-25T09:42:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3MDQ2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3NDMzNQ==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383474335", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  // The Clifrontend exited and we can move on to check if the job has finished\n          \n          \n            \n                  // The CliFrontend exited and we can move on to check if the job has finished", "author": "ibzib", "createdAt": "2020-02-24T19:42:29Z", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java", "diffHunk": "@@ -0,0 +1,224 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import java.io.File;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.nio.file.Files;\n+import java.security.Permission;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.runners.core.construction.resources.PipelineResources;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.GenerateSequence;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n+import org.apache.flink.client.cli.CliFrontend;\n+import org.apache.flink.configuration.ConfigConstants;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.JobManagerOptions;\n+import org.apache.flink.configuration.RestOptions;\n+import org.apache.flink.runtime.client.JobStatusMessage;\n+import org.apache.flink.runtime.jobgraph.JobStatus;\n+import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n+import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+\n+/** End-to-end submission test of Beam jobs on a Flink cluster. */\n+public class FlinkSubmissionTest {\n+\n+  @ClassRule public static final TemporaryFolder TEMP_FOLDER = new TemporaryFolder();\n+  private static final Map<String, String> ENV = System.getenv();\n+  private static final SecurityManager SECURITY_MANAGER = System.getSecurityManager();\n+\n+  /** Flink cluster that runs over the lifespan of the tests. */\n+  private static transient RemoteMiniCluster flinkCluster;\n+\n+  /** Each test has a timeout of 60 seconds (for safety). */\n+  @Rule public Timeout timeout = new Timeout(60, TimeUnit.SECONDS);\n+\n+  /** Counter which keeps track of the number of jobs submitted. */\n+  private static int expectedNumberOfJobs;\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Configuration config = new Configuration();\n+    // Avoid port collision in parallel tests on the same machine\n+    config.setInteger(RestOptions.PORT.key(), 0);\n+\n+    MiniClusterConfiguration clusterConfig =\n+        new MiniClusterConfiguration.Builder()\n+            .setConfiguration(config)\n+            .setNumTaskManagers(1)\n+            .setNumSlotsPerTaskManager(1)\n+            // Create a shared actor system for all cluster services\n+            .setRpcServiceSharing(RpcServiceSharing.SHARED)\n+            .build();\n+\n+    flinkCluster = new RemoteMiniClusterImpl(clusterConfig);\n+    flinkCluster.start();\n+    prepareEnvironment();\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() throws Exception {\n+    restoreEnvironment();\n+    flinkCluster.close();\n+    flinkCluster = null;\n+  }\n+\n+  @Test\n+  public void testSubmission() throws Exception {\n+    runSubmission(false);\n+  }\n+\n+  @Test\n+  public void testDetachedSubmission() throws Exception {\n+    runSubmission(true);\n+  }\n+\n+  private void runSubmission(boolean detached) throws Exception {\n+    PipelineOptions options = PipelineOptionsFactory.create();\n+    options.setTempLocation(TEMP_FOLDER.getRoot().getPath());\n+    String jarPath =\n+        Iterables.getFirst(\n+            PipelineResources.detectClassPathResourcesToStage(getClass().getClassLoader(), options),\n+            null);\n+\n+    try {\n+      throwExceptionOnSystemExit();\n+      ImmutableList.Builder<String> argsBuilder = ImmutableList.builder();\n+      argsBuilder.add(\"run\").add(\"-c\").add(getClass().getName());\n+      if (detached) {\n+        argsBuilder.add(\"-d\");\n+      }\n+      argsBuilder.add(jarPath);\n+\n+      expectedNumberOfJobs++;\n+      // Run end-to-end test\n+      CliFrontend.main(argsBuilder.build().toArray(new String[0]));\n+    } catch (SystemExitException e) {\n+      // The Clifrontend exited and we can move on to check if the job has finished", "originalCommit": "03454d39033d51eda1d991b636a2a7cbdcdf4991", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3NDQ5Mw==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383474493", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                // Create a new environment with the location of the Flink config for Clifrontend\n          \n          \n            \n                // Create a new environment with the location of the Flink config for CliFrontend", "author": "ibzib", "createdAt": "2020-02-24T19:42:46Z", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java", "diffHunk": "@@ -0,0 +1,224 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import java.io.File;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.nio.file.Files;\n+import java.security.Permission;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.runners.core.construction.resources.PipelineResources;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.GenerateSequence;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n+import org.apache.flink.client.cli.CliFrontend;\n+import org.apache.flink.configuration.ConfigConstants;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.JobManagerOptions;\n+import org.apache.flink.configuration.RestOptions;\n+import org.apache.flink.runtime.client.JobStatusMessage;\n+import org.apache.flink.runtime.jobgraph.JobStatus;\n+import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n+import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+\n+/** End-to-end submission test of Beam jobs on a Flink cluster. */\n+public class FlinkSubmissionTest {\n+\n+  @ClassRule public static final TemporaryFolder TEMP_FOLDER = new TemporaryFolder();\n+  private static final Map<String, String> ENV = System.getenv();\n+  private static final SecurityManager SECURITY_MANAGER = System.getSecurityManager();\n+\n+  /** Flink cluster that runs over the lifespan of the tests. */\n+  private static transient RemoteMiniCluster flinkCluster;\n+\n+  /** Each test has a timeout of 60 seconds (for safety). */\n+  @Rule public Timeout timeout = new Timeout(60, TimeUnit.SECONDS);\n+\n+  /** Counter which keeps track of the number of jobs submitted. */\n+  private static int expectedNumberOfJobs;\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Configuration config = new Configuration();\n+    // Avoid port collision in parallel tests on the same machine\n+    config.setInteger(RestOptions.PORT.key(), 0);\n+\n+    MiniClusterConfiguration clusterConfig =\n+        new MiniClusterConfiguration.Builder()\n+            .setConfiguration(config)\n+            .setNumTaskManagers(1)\n+            .setNumSlotsPerTaskManager(1)\n+            // Create a shared actor system for all cluster services\n+            .setRpcServiceSharing(RpcServiceSharing.SHARED)\n+            .build();\n+\n+    flinkCluster = new RemoteMiniClusterImpl(clusterConfig);\n+    flinkCluster.start();\n+    prepareEnvironment();\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() throws Exception {\n+    restoreEnvironment();\n+    flinkCluster.close();\n+    flinkCluster = null;\n+  }\n+\n+  @Test\n+  public void testSubmission() throws Exception {\n+    runSubmission(false);\n+  }\n+\n+  @Test\n+  public void testDetachedSubmission() throws Exception {\n+    runSubmission(true);\n+  }\n+\n+  private void runSubmission(boolean detached) throws Exception {\n+    PipelineOptions options = PipelineOptionsFactory.create();\n+    options.setTempLocation(TEMP_FOLDER.getRoot().getPath());\n+    String jarPath =\n+        Iterables.getFirst(\n+            PipelineResources.detectClassPathResourcesToStage(getClass().getClassLoader(), options),\n+            null);\n+\n+    try {\n+      throwExceptionOnSystemExit();\n+      ImmutableList.Builder<String> argsBuilder = ImmutableList.builder();\n+      argsBuilder.add(\"run\").add(\"-c\").add(getClass().getName());\n+      if (detached) {\n+        argsBuilder.add(\"-d\");\n+      }\n+      argsBuilder.add(jarPath);\n+\n+      expectedNumberOfJobs++;\n+      // Run end-to-end test\n+      CliFrontend.main(argsBuilder.build().toArray(new String[0]));\n+    } catch (SystemExitException e) {\n+      // The Clifrontend exited and we can move on to check if the job has finished\n+    } finally {\n+      restoreDefaultSystemExitBehavior();\n+    }\n+\n+    waitUntilJobIsCompleted();\n+  }\n+\n+  /** The Flink program which is executed by the CliFrontend. */\n+  public static void main(String[] args) {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setParallelism(1);\n+    Pipeline p = Pipeline.create(options);\n+    p.apply(GenerateSequence.from(0).to(1));\n+    p.run();\n+  }\n+\n+  private static void prepareEnvironment() throws Exception {\n+    // Write a Flink config\n+    File file = TEMP_FOLDER.newFile(\"flink-conf.yaml\");\n+    String config =\n+        String.format(\n+            \"%s: %s\\n%s: %s\\n%s: %s\",\n+            JobManagerOptions.ADDRESS.key(),\n+            \"localhost\",\n+            JobManagerOptions.PORT.key(),\n+            flinkCluster.getClusterPort(),\n+            RestOptions.PORT.key(),\n+            flinkCluster.getRestPort());\n+    Files.write(file.toPath(), config.getBytes(Charsets.UTF_8));\n+\n+    // Create a new environment with the location of the Flink config for Clifrontend", "originalCommit": "03454d39033d51eda1d991b636a2a7cbdcdf4991", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTU3OA==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383479578", "bodyText": "Instead of creating an all-new SecurityManager, should we instead wrap the original one? (Not sure if it actually matters.)", "author": "ibzib", "createdAt": "2020-02-24T19:52:41Z", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java", "diffHunk": "@@ -0,0 +1,224 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import java.io.File;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.nio.file.Files;\n+import java.security.Permission;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.runners.core.construction.resources.PipelineResources;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.GenerateSequence;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n+import org.apache.flink.client.cli.CliFrontend;\n+import org.apache.flink.configuration.ConfigConstants;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.JobManagerOptions;\n+import org.apache.flink.configuration.RestOptions;\n+import org.apache.flink.runtime.client.JobStatusMessage;\n+import org.apache.flink.runtime.jobgraph.JobStatus;\n+import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n+import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+\n+/** End-to-end submission test of Beam jobs on a Flink cluster. */\n+public class FlinkSubmissionTest {\n+\n+  @ClassRule public static final TemporaryFolder TEMP_FOLDER = new TemporaryFolder();\n+  private static final Map<String, String> ENV = System.getenv();\n+  private static final SecurityManager SECURITY_MANAGER = System.getSecurityManager();\n+\n+  /** Flink cluster that runs over the lifespan of the tests. */\n+  private static transient RemoteMiniCluster flinkCluster;\n+\n+  /** Each test has a timeout of 60 seconds (for safety). */\n+  @Rule public Timeout timeout = new Timeout(60, TimeUnit.SECONDS);\n+\n+  /** Counter which keeps track of the number of jobs submitted. */\n+  private static int expectedNumberOfJobs;\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Configuration config = new Configuration();\n+    // Avoid port collision in parallel tests on the same machine\n+    config.setInteger(RestOptions.PORT.key(), 0);\n+\n+    MiniClusterConfiguration clusterConfig =\n+        new MiniClusterConfiguration.Builder()\n+            .setConfiguration(config)\n+            .setNumTaskManagers(1)\n+            .setNumSlotsPerTaskManager(1)\n+            // Create a shared actor system for all cluster services\n+            .setRpcServiceSharing(RpcServiceSharing.SHARED)\n+            .build();\n+\n+    flinkCluster = new RemoteMiniClusterImpl(clusterConfig);\n+    flinkCluster.start();\n+    prepareEnvironment();\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() throws Exception {\n+    restoreEnvironment();\n+    flinkCluster.close();\n+    flinkCluster = null;\n+  }\n+\n+  @Test\n+  public void testSubmission() throws Exception {\n+    runSubmission(false);\n+  }\n+\n+  @Test\n+  public void testDetachedSubmission() throws Exception {\n+    runSubmission(true);\n+  }\n+\n+  private void runSubmission(boolean detached) throws Exception {\n+    PipelineOptions options = PipelineOptionsFactory.create();\n+    options.setTempLocation(TEMP_FOLDER.getRoot().getPath());\n+    String jarPath =\n+        Iterables.getFirst(\n+            PipelineResources.detectClassPathResourcesToStage(getClass().getClassLoader(), options),\n+            null);\n+\n+    try {\n+      throwExceptionOnSystemExit();\n+      ImmutableList.Builder<String> argsBuilder = ImmutableList.builder();\n+      argsBuilder.add(\"run\").add(\"-c\").add(getClass().getName());\n+      if (detached) {\n+        argsBuilder.add(\"-d\");\n+      }\n+      argsBuilder.add(jarPath);\n+\n+      expectedNumberOfJobs++;\n+      // Run end-to-end test\n+      CliFrontend.main(argsBuilder.build().toArray(new String[0]));\n+    } catch (SystemExitException e) {\n+      // The Clifrontend exited and we can move on to check if the job has finished\n+    } finally {\n+      restoreDefaultSystemExitBehavior();\n+    }\n+\n+    waitUntilJobIsCompleted();\n+  }\n+\n+  /** The Flink program which is executed by the CliFrontend. */\n+  public static void main(String[] args) {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setParallelism(1);\n+    Pipeline p = Pipeline.create(options);\n+    p.apply(GenerateSequence.from(0).to(1));\n+    p.run();\n+  }\n+\n+  private static void prepareEnvironment() throws Exception {\n+    // Write a Flink config\n+    File file = TEMP_FOLDER.newFile(\"flink-conf.yaml\");\n+    String config =\n+        String.format(\n+            \"%s: %s\\n%s: %s\\n%s: %s\",\n+            JobManagerOptions.ADDRESS.key(),\n+            \"localhost\",\n+            JobManagerOptions.PORT.key(),\n+            flinkCluster.getClusterPort(),\n+            RestOptions.PORT.key(),\n+            flinkCluster.getRestPort());\n+    Files.write(file.toPath(), config.getBytes(Charsets.UTF_8));\n+\n+    // Create a new environment with the location of the Flink config for Clifrontend\n+    ImmutableMap<String, String> newEnv =\n+        ImmutableMap.<String, String>builder()\n+            .putAll(ENV.entrySet())\n+            .put(ConfigConstants.ENV_FLINK_CONF_DIR, file.getParent())\n+            .build();\n+\n+    modifyEnv(newEnv);\n+  }\n+\n+  private static void restoreEnvironment() throws Exception {\n+    modifyEnv(ENV);\n+  }\n+\n+  private static void modifyEnv(Map<String, String> env) throws Exception {\n+    Class processEnv = Class.forName(\"java.lang.ProcessEnvironment\");\n+    Field envField = processEnv.getDeclaredField(\"theUnmodifiableEnvironment\");\n+\n+    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n+    modifiersField.setAccessible(true);\n+    modifiersField.setInt(envField, envField.getModifiers() & ~Modifier.FINAL);\n+\n+    envField.setAccessible(true);\n+    envField.set(null, env);\n+    envField.setAccessible(false);\n+\n+    modifiersField.setInt(envField, envField.getModifiers() & Modifier.FINAL);\n+    modifiersField.setAccessible(false);\n+  }\n+\n+  private void waitUntilJobIsCompleted() throws Exception {\n+    while (true) {\n+      Collection<JobStatusMessage> allJobsStates = flinkCluster.listJobs().get();\n+      assertThat(\n+          \"There should be a job per test run.\", allJobsStates.size(), is(expectedNumberOfJobs));\n+      if (allJobsStates.stream()\n+          .allMatch(jobStatus -> jobStatus.getJobState() == JobStatus.FINISHED)) {\n+        return;\n+      }\n+      Thread.sleep(50);\n+    }\n+  }\n+\n+  /** Prevents the CliFrontend from calling System.exit. */\n+  private static void throwExceptionOnSystemExit() {\n+    System.setSecurityManager(\n+        new SecurityManager() {", "originalCommit": "03454d39033d51eda1d991b636a2a7cbdcdf4991", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzc2MzQ1MA==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383763450", "bodyText": "I don't think it matters for tests, but doesn't hurt either. Updated.", "author": "mxm", "createdAt": "2020-02-25T09:42:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ3OTU3OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ4MDAxMw==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383480013", "bodyText": "Can you please add a comment saying why this is necessary?", "author": "ibzib", "createdAt": "2020-02-24T19:53:33Z", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java", "diffHunk": "@@ -0,0 +1,224 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import java.io.File;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.nio.file.Files;\n+import java.security.Permission;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.runners.core.construction.resources.PipelineResources;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.GenerateSequence;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n+import org.apache.flink.client.cli.CliFrontend;\n+import org.apache.flink.configuration.ConfigConstants;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.JobManagerOptions;\n+import org.apache.flink.configuration.RestOptions;\n+import org.apache.flink.runtime.client.JobStatusMessage;\n+import org.apache.flink.runtime.jobgraph.JobStatus;\n+import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n+import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+\n+/** End-to-end submission test of Beam jobs on a Flink cluster. */\n+public class FlinkSubmissionTest {\n+\n+  @ClassRule public static final TemporaryFolder TEMP_FOLDER = new TemporaryFolder();\n+  private static final Map<String, String> ENV = System.getenv();\n+  private static final SecurityManager SECURITY_MANAGER = System.getSecurityManager();\n+\n+  /** Flink cluster that runs over the lifespan of the tests. */\n+  private static transient RemoteMiniCluster flinkCluster;\n+\n+  /** Each test has a timeout of 60 seconds (for safety). */\n+  @Rule public Timeout timeout = new Timeout(60, TimeUnit.SECONDS);\n+\n+  /** Counter which keeps track of the number of jobs submitted. */\n+  private static int expectedNumberOfJobs;\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Configuration config = new Configuration();\n+    // Avoid port collision in parallel tests on the same machine\n+    config.setInteger(RestOptions.PORT.key(), 0);\n+\n+    MiniClusterConfiguration clusterConfig =\n+        new MiniClusterConfiguration.Builder()\n+            .setConfiguration(config)\n+            .setNumTaskManagers(1)\n+            .setNumSlotsPerTaskManager(1)\n+            // Create a shared actor system for all cluster services\n+            .setRpcServiceSharing(RpcServiceSharing.SHARED)\n+            .build();\n+\n+    flinkCluster = new RemoteMiniClusterImpl(clusterConfig);\n+    flinkCluster.start();\n+    prepareEnvironment();\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() throws Exception {\n+    restoreEnvironment();\n+    flinkCluster.close();\n+    flinkCluster = null;\n+  }\n+\n+  @Test\n+  public void testSubmission() throws Exception {\n+    runSubmission(false);\n+  }\n+\n+  @Test\n+  public void testDetachedSubmission() throws Exception {\n+    runSubmission(true);\n+  }\n+\n+  private void runSubmission(boolean detached) throws Exception {\n+    PipelineOptions options = PipelineOptionsFactory.create();\n+    options.setTempLocation(TEMP_FOLDER.getRoot().getPath());\n+    String jarPath =\n+        Iterables.getFirst(\n+            PipelineResources.detectClassPathResourcesToStage(getClass().getClassLoader(), options),\n+            null);\n+\n+    try {\n+      throwExceptionOnSystemExit();\n+      ImmutableList.Builder<String> argsBuilder = ImmutableList.builder();\n+      argsBuilder.add(\"run\").add(\"-c\").add(getClass().getName());\n+      if (detached) {\n+        argsBuilder.add(\"-d\");\n+      }\n+      argsBuilder.add(jarPath);\n+\n+      expectedNumberOfJobs++;\n+      // Run end-to-end test\n+      CliFrontend.main(argsBuilder.build().toArray(new String[0]));\n+    } catch (SystemExitException e) {\n+      // The Clifrontend exited and we can move on to check if the job has finished\n+    } finally {\n+      restoreDefaultSystemExitBehavior();\n+    }\n+\n+    waitUntilJobIsCompleted();\n+  }\n+\n+  /** The Flink program which is executed by the CliFrontend. */\n+  public static void main(String[] args) {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setParallelism(1);\n+    Pipeline p = Pipeline.create(options);\n+    p.apply(GenerateSequence.from(0).to(1));\n+    p.run();\n+  }\n+\n+  private static void prepareEnvironment() throws Exception {\n+    // Write a Flink config\n+    File file = TEMP_FOLDER.newFile(\"flink-conf.yaml\");\n+    String config =\n+        String.format(\n+            \"%s: %s\\n%s: %s\\n%s: %s\",\n+            JobManagerOptions.ADDRESS.key(),\n+            \"localhost\",\n+            JobManagerOptions.PORT.key(),\n+            flinkCluster.getClusterPort(),\n+            RestOptions.PORT.key(),\n+            flinkCluster.getRestPort());\n+    Files.write(file.toPath(), config.getBytes(Charsets.UTF_8));\n+\n+    // Create a new environment with the location of the Flink config for Clifrontend\n+    ImmutableMap<String, String> newEnv =\n+        ImmutableMap.<String, String>builder()\n+            .putAll(ENV.entrySet())\n+            .put(ConfigConstants.ENV_FLINK_CONF_DIR, file.getParent())\n+            .build();\n+\n+    modifyEnv(newEnv);\n+  }\n+\n+  private static void restoreEnvironment() throws Exception {\n+    modifyEnv(ENV);\n+  }\n+\n+  private static void modifyEnv(Map<String, String> env) throws Exception {", "originalCommit": "03454d39033d51eda1d991b636a2a7cbdcdf4991", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzc2MzUwMA==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383763500", "bodyText": "+1", "author": "mxm", "createdAt": "2020-02-25T09:42:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ4MDAxMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ4MDY1Mw==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383480653", "bodyText": "Removing the workaround and adding the new test should be in two discrete commits.", "author": "ibzib", "createdAt": "2020-02-24T19:54:51Z", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkJobInvoker.java", "diffHunk": "@@ -23,7 +23,6 @@\n import javax.annotation.Nullable;\n import org.apache.beam.model.pipeline.v1.RunnerApi;\n import org.apache.beam.runners.core.construction.PipelineOptionsTranslation;\n-import org.apache.beam.runners.flink.translation.utils.Workarounds;", "originalCommit": "03454d39033d51eda1d991b636a2a7cbdcdf4991", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Mzc2NTAwNQ==", "url": "https://github.com/apache/beam/pull/10950#discussion_r383765005", "bodyText": "That is debatable. I've split it up, but I do think these changes can exist together. It helps to reason why the test was introduced.", "author": "mxm", "createdAt": "2020-02-25T09:44:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzQ4MDY1Mw=="}], "type": "inlineReview"}, {"oid": "6fe154275f2cfcdb11af9dbed5f50dec95458c41", "url": "https://github.com/apache/beam/commit/6fe154275f2cfcdb11af9dbed5f50dec95458c41", "message": "[BEAM-9345] Remove workaround to restore stdout/stderr during JobGraph creation\n\nThis removes the workaround to restore stdout/stderr during JobGraph\ncreation. It has caused problems during job submission. Also, the workaround is\nnot necessary anymore in Flink 1.10 due to an upstream fix:\nhttps://issues.apache.org/jira/browse/FLINK-15504\n\nThe parent commit will add an end-to-end test to prevent breakage in the future.", "committedDate": "2020-02-25T09:37:13Z", "type": "commit"}, {"oid": "4303ff241e84851ee65f0bb14d39e7b9cfc32e25", "url": "https://github.com/apache/beam/commit/4303ff241e84851ee65f0bb14d39e7b9cfc32e25", "message": "[BEAM-9345] Add end-to-end Flink job submission test\n\nTo catch submission problems in the future (see child commit), this change\nadds an end-to-end test with a Flink cluster. The test starts from the\ncommand-line interface and executes a simple job for all combinations of\nregular/detached and batch/streaming mode.", "committedDate": "2020-02-25T09:42:11Z", "type": "commit"}, {"oid": "4303ff241e84851ee65f0bb14d39e7b9cfc32e25", "url": "https://github.com/apache/beam/commit/4303ff241e84851ee65f0bb14d39e7b9cfc32e25", "message": "[BEAM-9345] Add end-to-end Flink job submission test\n\nTo catch submission problems in the future (see child commit), this change\nadds an end-to-end test with a Flink cluster. The test starts from the\ncommand-line interface and executes a simple job for all combinations of\nregular/detached and batch/streaming mode.", "committedDate": "2020-02-25T09:42:11Z", "type": "forcePushed"}]}