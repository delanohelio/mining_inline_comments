{"pr_number": 13252, "pr_title": "[BEAM-9547] Provide some top level pandas functions.", "pr_createdAt": "2020-11-03T22:54:59Z", "pr_url": "https://github.com/apache/beam/pull/13252", "timeline": [{"oid": "94f6795b965fcb7ef8294e0731cb93ed2566c786", "url": "https://github.com/apache/beam/commit/94f6795b965fcb7ef8294e0731cb93ed2566c786", "message": "Allow use of index as series.", "committedDate": "2020-11-03T22:46:24Z", "type": "commit"}, {"oid": "26e8bd112f38673cb336cbbcfdb50e66ee606486", "url": "https://github.com/apache/beam/commit/26e8bd112f38673cb336cbbcfdb50e66ee606486", "message": "Allow setting columns.", "committedDate": "2020-11-03T22:46:25Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzAxMzc1OA==", "url": "https://github.com/apache/beam/pull/13252#discussion_r517013758", "bodyText": "It looks like this file is missing", "author": "TheNeuralBit", "createdAt": "2020-11-03T23:24:48Z", "path": "sdks/python/apache_beam/dataframe/doctests.py", "diffHunk": "@@ -58,6 +58,7 @@\n import apache_beam as beam\n from apache_beam.dataframe import expressions\n from apache_beam.dataframe import frames  # pylint: disable=unused-import\n+from apache_beam.dataframe import pandas_top_level_functions", "originalCommit": "bc0db2d95db19f6356c6a483c9ad2c14293fb728", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0c200514f861cea85bbd955a8b55073d5c571ed4", "url": "https://github.com/apache/beam/commit/0c200514f861cea85bbd955a8b55073d5c571ed4", "message": "Add utility to test a set of strings.\n\ntestmod() doesn't gather things not defined in that module's namespace,\nso we have to do the gathering ourselves.", "committedDate": "2020-11-03T23:55:23Z", "type": "commit"}, {"oid": "7c5618cda67b3ce88f170595c65d7dd92991f1e4", "url": "https://github.com/apache/beam/commit/7c5618cda67b3ce88f170595c65d7dd92991f1e4", "message": "Add a proxy for panda's top-level module functions.", "committedDate": "2020-11-03T23:55:23Z", "type": "commit"}, {"oid": "8a400dc6d8e40fd86bba10860ab749fbfce94161", "url": "https://github.com/apache/beam/commit/8a400dc6d8e40fd86bba10860ab749fbfce94161", "message": "[BEAM-9547] Implement pd.concat().", "committedDate": "2020-11-03T23:55:23Z", "type": "commit"}, {"oid": "8a400dc6d8e40fd86bba10860ab749fbfce94161", "url": "https://github.com/apache/beam/commit/8a400dc6d8e40fd86bba10860ab749fbfce94161", "message": "[BEAM-9547] Implement pd.concat().", "committedDate": "2020-11-03T23:55:23Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwNDExOQ==", "url": "https://github.com/apache/beam/pull/13252#discussion_r517504119", "bodyText": "nit\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                      'Use p | apache_beam.dataframe.io.%s' % name)\n          \n          \n            \n                      'Use `p | apache_beam.dataframe.io.%s`' % name)", "author": "TheNeuralBit", "createdAt": "2020-11-04T17:16:21Z", "path": "sdks/python/apache_beam/dataframe/pandas_top_level_functions.py", "diffHunk": "@@ -0,0 +1,148 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+\"\"\"A module providing various functionality from the top-level pandas namespace.\n+\"\"\"\n+\n+import re\n+from typing import Mapping\n+\n+import pandas as pd\n+\n+from apache_beam.dataframe import expressions\n+from apache_beam.dataframe import frame_base\n+from apache_beam.dataframe import partitionings\n+\n+\n+def _call_on_first_arg(name):\n+  def wrapper(target, *args, **kwargs):\n+    if isinstance(target, frame_base.DeferredBase):\n+      return getattr(target, name)(*args, **kwargs)\n+    else:\n+      return getattr(pd, name)(target, *args, **kwargs)\n+\n+  return staticmethod(wrapper)\n+\n+\n+def _defer_to_pandas(name):\n+  def wrapper(*args, **kwargs):\n+    res = getattr(pd, name)(*args, **kwargs)\n+    if type(res) in frame_base.DeferredBase._pandas_type_map.keys():\n+      return DeferredBase.wrap(expressions.ConstantExpression(res, res[0:0]))\n+    else:\n+      return res\n+\n+  return staticmethod(wrapper)\n+\n+\n+def _is_top_level_function(o):\n+  return (\n+      callable(o) and not isinstance(o, type) and hasattr(o, '__name__') and\n+      re.match('[a-z].*', o.__name__))\n+\n+\n+class DeferredPandasModule(object):\n+  array = _defer_to_pandas('array')\n+  bdate_range = _defer_to_pandas('bdate_range')\n+\n+  @staticmethod\n+  @frame_base.args_to_kwargs(pd)\n+  @frame_base.populate_defaults(pd)\n+  def concat(\n+      objs,\n+      axis,\n+      join,\n+      ignore_index,\n+      keys,\n+      levels,\n+      names,\n+      verify_integrity,\n+      sort,\n+      copy):\n+\n+    if ignore_index:\n+      raise NotImplementedError('concat(ignore_index)')\n+    if levels:\n+      raise NotImplementedError('concat(levels)')\n+\n+    if isinstance(objs, Mapping):\n+      if keys is None:\n+        keys = list(objs.keys())\n+      objs = [objs[k] for k in keys]\n+    else:\n+      objs = list(objs)\n+    deferred_none = expressions.ConstantExpression(None)\n+    exprs = [deferred_none if o is None else o._expr for o in objs]\n+\n+    if axis in (1, 'columns'):\n+      required_partitioning = partitionings.Index()\n+    elif verify_integrity:\n+      required_partitioning = partitionings.Index()\n+    else:\n+      required_partitioning = partitionings.Nothing()\n+\n+    return frame_base.DeferredBase.wrap(\n+        expressions.ComputedExpression(\n+            'concat',\n+            lambda *objs: pd.concat(\n+                objs,\n+                axis=axis,\n+                join=join,\n+                ignore_index=ignore_index,\n+                keys=keys,\n+                levels=levels,\n+                names=names,\n+                verify_integrity=verify_integrity),  # yapf break\n+            exprs,\n+            requires_partition_by=required_partitioning,\n+            preserves_partition_by=partitionings.Index()))\n+\n+  date_range = _defer_to_pandas('date_range')\n+  describe_option = _defer_to_pandas('describe_option')\n+  factorize = _call_on_first_arg('factorize')\n+  get_option = _defer_to_pandas('get_option')\n+  interval_range = _defer_to_pandas('interval_range')\n+  isna = _call_on_first_arg('isna')\n+  isnull = _call_on_first_arg('isnull')\n+  json_normalize = _defer_to_pandas('json_normalize')\n+  melt = _call_on_first_arg('melt')\n+  merge = _call_on_first_arg('merge')\n+  melt = _call_on_first_arg('melt')\n+  merge_ordered = frame_base.wont_implement_method('order-sensitive')\n+  notna = _call_on_first_arg('notna')\n+  notnull = _call_on_first_arg('notnull')\n+  option_context = _defer_to_pandas('option_context')\n+  period_range = _defer_to_pandas('period_range')\n+  pivot = _call_on_first_arg('pivot')\n+  pivot_table = _call_on_first_arg('pivot_table')\n+  show_versions = _defer_to_pandas('show_versions')\n+  test = frame_base.wont_implement_method('test')\n+  timedelta_range = _defer_to_pandas('timedelta_range')\n+  to_pickle = frame_base.wont_implement_method('order-sensitive')\n+  notna = _call_on_first_arg('notna')\n+\n+  def __getattr__(self, name):\n+    if name.startswith('read_'):\n+      return frame_base.wont_implement_method(\n+          'Use p | apache_beam.dataframe.io.%s' % name)", "originalCommit": "8a400dc6d8e40fd86bba10860ab749fbfce94161", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUyNTQxOA==", "url": "https://github.com/apache/beam/pull/13252#discussion_r517525418", "bodyText": "I think this will direct some users to methods that don't exist right? For one it will allow the completely non-existent pd.read_foo, but there are also some pd.read_* methods that we don't yet support in dataframe.io (I just checked and it looks like just read_{orc, sql, sql_query} are missing)\nI'd be fine with this as-is to make sure we have something for the 2.26.0 cut but I think we may want to populate directly from the items in dataframe.io in the future.", "author": "TheNeuralBit", "createdAt": "2020-11-04T17:51:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwNDExOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzgxNg==", "url": "https://github.com/apache/beam/pull/13252#discussion_r517707816", "bodyText": "We should probably populate that module with the missing read_ ones then. I'll take a pass after this PR.", "author": "robertwb", "createdAt": "2020-11-05T00:18:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUwNDExOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUzMjcxMQ==", "url": "https://github.com/apache/beam/pull/13252#discussion_r517532711", "bodyText": "Do we want to call to_series in all cases? It seems like this expression should provide the index itself to be general purpose.", "author": "TheNeuralBit", "createdAt": "2020-11-04T18:02:58Z", "path": "sdks/python/apache_beam/dataframe/frame_base.py", "diffHunk": "@@ -218,10 +218,20 @@ def wrapper(*args, **kwargs):\n     deferred_arg_indices = []\n     deferred_arg_exprs = []\n     constant_args = [None] * len(args)\n+    from apache_beam.dataframe.frames import _DeferredIndex\n     for ix, arg in enumerate(args):\n       if isinstance(arg, DeferredBase):\n         deferred_arg_indices.append(ix)\n         deferred_arg_exprs.append(arg._expr)\n+      elif isinstance(arg, _DeferredIndex):\n+        deferred_arg_indices.append(ix)\n+        deferred_arg_exprs.append(\n+            expressions.ComputedExpression(\n+                'index_as_series',\n+                lambda ix: ix.index.to_series(),  # yapf break\n+                [arg._frame._expr],\n+                preserves_partition_by=partitionings.Singleton(),\n+                requires_partition_by=partitionings.Nothing()))", "originalCommit": "8a400dc6d8e40fd86bba10860ab749fbfce94161", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwODAzNg==", "url": "https://github.com/apache/beam/pull/13252#discussion_r517708036", "bodyText": "Perhaps. Currently, however, the infrastructure requires anything partition-able to have an index, which indices don't have, so that wouldn't work. I'll drop a TODO.", "author": "robertwb", "createdAt": "2020-11-05T00:19:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUzMjcxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwOTQ3NQ==", "url": "https://github.com/apache/beam/pull/13252#discussion_r517709475", "bodyText": "Ah ok, thanks for the explanation", "author": "TheNeuralBit", "createdAt": "2020-11-05T00:23:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUzMjcxMQ=="}], "type": "inlineReview"}, {"oid": "174d2b61cb1449fec45b78a9ad34742e2d52b58a", "url": "https://github.com/apache/beam/commit/174d2b61cb1449fec45b78a9ad34742e2d52b58a", "message": "todo, lint", "committedDate": "2020-11-05T02:07:54Z", "type": "commit"}]}