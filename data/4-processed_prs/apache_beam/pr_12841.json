{"pr_number": 12841, "pr_title": "[BEAM-10894] Basic CSV reading and writing.", "pr_createdAt": "2020-09-14T16:38:38Z", "pr_url": "https://github.com/apache/beam/pull/12841", "timeline": [{"oid": "f812f8565f82eaf7dd30f9a10f0801109276146e", "url": "https://github.com/apache/beam/commit/f812f8565f82eaf7dd30f9a10f0801109276146e", "message": "[BEAM-10894] Basic CSV reading and writing.", "committedDate": "2020-09-14T16:36:19Z", "type": "commit"}, {"oid": "081840c7cadca2bfbb3784deb3576610c7feccba", "url": "https://github.com/apache/beam/commit/081840c7cadca2bfbb3784deb3576610c7feccba", "message": "lint, circular import", "committedDate": "2020-09-15T00:12:53Z", "type": "commit"}, {"oid": "28eb70c13f7114da4ff7659eb38641e8ab41770e", "url": "https://github.com/apache/beam/commit/28eb70c13f7114da4ff7659eb38641e8ab41770e", "message": "lint", "committedDate": "2020-09-15T00:21:19Z", "type": "commit"}, {"oid": "35d86ce1a7744e274656d1f3ac77f3a3b5158bad", "url": "https://github.com/apache/beam/commit/35d86ce1a7744e274656d1f3ac77f3a3b5158bad", "message": "lint, py2", "committedDate": "2020-09-15T15:37:42Z", "type": "commit"}, {"oid": "ab66e1ce1dfb1308a89a9cea21dbc9502c8c43e8", "url": "https://github.com/apache/beam/commit/ab66e1ce1dfb1308a89a9cea21dbc9502c8c43e8", "message": "new lint issue", "committedDate": "2020-09-15T16:03:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwNzY5OA==", "url": "https://github.com/apache/beam/pull/12841#discussion_r489207698", "bodyText": "Please add pydocs for public API here (or add a TODO/JIRA for this).", "author": "chamikaramj", "createdAt": "2020-09-16T07:01:13Z", "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,178 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+\n+\n+def read_csv(path, *args, **kwargs):", "originalCommit": "ab66e1ce1dfb1308a89a9cea21dbc9502c8c43e8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTgyMzgxMQ==", "url": "https://github.com/apache/beam/pull/12841#discussion_r489823811", "bodyText": "The idea here is to mirror the Pandas APIs. I suppose I should reference them at least.", "author": "robertwb", "createdAt": "2020-09-17T00:22:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwNzY5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODM5OQ==", "url": "https://github.com/apache/beam/pull/12841#discussion_r489208399", "bodyText": "Is there a reason to provide these as methods instead of transforms (similar to other IO connectors) ?", "author": "chamikaramj", "createdAt": "2020-09-16T07:02:38Z", "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,178 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+\n+\n+def read_csv(path, *args, **kwargs):\n+  return _ReadFromPandas(pd.read_csv, path, args, kwargs)\n+", "originalCommit": "ab66e1ce1dfb1308a89a9cea21dbc9502c8c43e8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTgyMzkwMA==", "url": "https://github.com/apache/beam/pull/12841#discussion_r489823900", "bodyText": "Mirroring the Pandas APIs. The _ReadFromPandas will be widely shared.", "author": "robertwb", "createdAt": "2020-09-17T00:23:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODM5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIyMjMwMA==", "url": "https://github.com/apache/beam/pull/12841#discussion_r489222300", "bodyText": "Probably we can replace above file-handling related transforms with transforms available in fileio.\nhttps://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/fileio.py\nFor example,\nfileio.MatchFiles(self.path) | ParDo(_ReadFromPandasFromReadableFileDoFn())\n(ReadableFile.metadata.path gives the file path).", "author": "chamikaramj", "createdAt": "2020-09-16T07:29:13Z", "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,178 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+\n+\n+def read_csv(path, *args, **kwargs):\n+  return _ReadFromPandas(pd.read_csv, path, args, kwargs)\n+\n+\n+def write_csv(df, path, *args, **kwargs):\n+  from apache_beam.dataframe import convert\n+  # TODO(roberwb): Amortize the computation for multiple writes?\n+  return convert.to_pcollection(df) | _WriteToPandas(\n+      pd.DataFrame.to_csv, path, args, kwargs, incremental=True, binary=False)\n+\n+\n+def _prefix_range_index_with(prefix, df):\n+  if isinstance(df.index, pd.RangeIndex):\n+    return df.set_index(prefix + df.index.map(str).astype(str))\n+  else:\n+    return df\n+\n+\n+class _ReadFromPandas(beam.PTransform):\n+  def __init__(self, reader, path, args, kwargs):\n+    if not isinstance(path, str):\n+      raise frame_base.WontImplementError('non-deferred')\n+    self.reader = reader\n+    self.path = path\n+    self.args = args\n+    self.kwargs = kwargs\n+\n+  def expand(self, root):\n+    # TODO(robertwb): Handle streaming (with explicit schema).\n+    paths_pcoll = root | beam.Create([self.path])\n+    first = io.filesystems.FileSystems.match([self.path],\n+                                             limits=[1\n+                                                     ])[0].metadata_list[0].path\n+    with io.filesystems.FileSystems.open(first) as handle:\n+      df = next(self.reader(handle, *self.args, chunksize=100, **self.kwargs))\n+\n+    # TODO(robertwb): Actually make an SDF.\n+    def expand_pattern(pattern):\n+      for match_result in io.filesystems.FileSystems.match([pattern]):\n+        for metadata in match_result.metadata_list:\n+          yield metadata.path\n+\n+    pcoll = (\n+        paths_pcoll\n+        | beam.FlatMap(expand_pattern)", "originalCommit": "ab66e1ce1dfb1308a89a9cea21dbc9502c8c43e8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDM1MTQ4MQ==", "url": "https://github.com/apache/beam/pull/12841#discussion_r490351481", "bodyText": "Done.", "author": "robertwb", "createdAt": "2020-09-17T15:39:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIyMjMwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIzNzUzMA==", "url": "https://github.com/apache/beam/pull/12841#discussion_r489237530", "bodyText": "Instead of extending FileBasedSink here please implement a fileio.FileSink and use fileio.WriteToFiles.\nhttps://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/fileio.py#L76", "author": "chamikaramj", "createdAt": "2020-09-16T07:55:16Z", "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,178 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+\n+\n+def read_csv(path, *args, **kwargs):\n+  return _ReadFromPandas(pd.read_csv, path, args, kwargs)\n+\n+\n+def write_csv(df, path, *args, **kwargs):\n+  from apache_beam.dataframe import convert\n+  # TODO(roberwb): Amortize the computation for multiple writes?\n+  return convert.to_pcollection(df) | _WriteToPandas(\n+      pd.DataFrame.to_csv, path, args, kwargs, incremental=True, binary=False)\n+\n+\n+def _prefix_range_index_with(prefix, df):\n+  if isinstance(df.index, pd.RangeIndex):\n+    return df.set_index(prefix + df.index.map(str).astype(str))\n+  else:\n+    return df\n+\n+\n+class _ReadFromPandas(beam.PTransform):\n+  def __init__(self, reader, path, args, kwargs):\n+    if not isinstance(path, str):\n+      raise frame_base.WontImplementError('non-deferred')\n+    self.reader = reader\n+    self.path = path\n+    self.args = args\n+    self.kwargs = kwargs\n+\n+  def expand(self, root):\n+    # TODO(robertwb): Handle streaming (with explicit schema).\n+    paths_pcoll = root | beam.Create([self.path])\n+    first = io.filesystems.FileSystems.match([self.path],\n+                                             limits=[1\n+                                                     ])[0].metadata_list[0].path\n+    with io.filesystems.FileSystems.open(first) as handle:\n+      df = next(self.reader(handle, *self.args, chunksize=100, **self.kwargs))\n+\n+    # TODO(robertwb): Actually make an SDF.\n+    def expand_pattern(pattern):\n+      for match_result in io.filesystems.FileSystems.match([pattern]):\n+        for metadata in match_result.metadata_list:\n+          yield metadata.path\n+\n+    pcoll = (\n+        paths_pcoll\n+        | beam.FlatMap(expand_pattern)\n+        | beam.ParDo(_ReadFromPandasDoFn(self.reader, self.args, self.kwargs)))\n+    from apache_beam.dataframe import convert\n+    return convert.to_dataframe(\n+        pcoll, proxy=_prefix_range_index_with(':', df[:0]))\n+\n+\n+class _ReadFromPandasDoFn(beam.DoFn):\n+  def __init__(self, reader, args, kwargs):\n+    # avoid pickling issues\n+    self.reader = reader.__name__\n+    self.args = args\n+    self.kwargs = kwargs\n+\n+  def process(self, path):\n+    reader = getattr(pd, self.reader)\n+    for df in reader(path, *self.args, chunksize=100, **self.kwargs):\n+      yield _prefix_range_index_with(path + ':', df)\n+\n+\n+class _WriteToPandas(beam.PTransform):\n+  def __init__(\n+      self, writer, path, args, kwargs, incremental=False, binary=True):\n+    self.writer = writer\n+    self.path = path\n+    self.args = args\n+    self.kwargs = kwargs\n+    self.incremental = incremental\n+    self.binary = binary\n+\n+  def expand(self, pcoll):\n+    return pcoll | io.Write(\n+        _WriteToPandasFileBasedSink(\n+            self.writer,\n+            self.path,\n+            self.args,\n+            self.kwargs,\n+            self.incremental,\n+            self.binary))\n+\n+\n+class _WriteToPandasFileBasedSink(io.FileBasedSink):", "originalCommit": "ab66e1ce1dfb1308a89a9cea21dbc9502c8c43e8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDM1MTUzMQ==", "url": "https://github.com/apache/beam/pull/12841#discussion_r490351531", "bodyText": "Done.", "author": "robertwb", "createdAt": "2020-09-17T15:39:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIzNzUzMA=="}], "type": "inlineReview"}, {"oid": "c2f7ae5626df4b0dec73a68b279b2db8c881aade", "url": "https://github.com/apache/beam/commit/c2f7ae5626df4b0dec73a68b279b2db8c881aade", "message": "Docs for read_csv.", "committedDate": "2020-09-17T00:39:37Z", "type": "commit"}, {"oid": "2604d6bfbff1a9f923c66cebe7025d02fff97cd6", "url": "https://github.com/apache/beam/commit/2604d6bfbff1a9f923c66cebe7025d02fff97cd6", "message": "Use fileio.MatchFiles.", "committedDate": "2020-09-17T00:47:41Z", "type": "commit"}, {"oid": "46a2df44bc6346e361c33d6b37093187d8670eb9", "url": "https://github.com/apache/beam/commit/46a2df44bc6346e361c33d6b37093187d8670eb9", "message": "Use fileio.FileSink.", "committedDate": "2020-09-17T15:35:47Z", "type": "commit"}, {"oid": "d5c2553759fcaf5fa137a77b682a2ffc14ab77db", "url": "https://github.com/apache/beam/commit/d5c2553759fcaf5fa137a77b682a2ffc14ab77db", "message": "lint", "committedDate": "2020-09-17T23:18:48Z", "type": "commit"}, {"oid": "1be53570550a175badfddfe5143ce825ce8ee088", "url": "https://github.com/apache/beam/commit/1be53570550a175badfddfe5143ce825ce8ee088", "message": "sep", "committedDate": "2020-09-18T16:46:53Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwMDU5OQ==", "url": "https://github.com/apache/beam/pull/12841#discussion_r491100599", "bodyText": "Import at top (here and below) ?", "author": "chamikaramj", "createdAt": "2020-09-18T17:45:51Z", "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,180 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+from apache_beam.io import fileio\n+\n+\n+def read_csv(path, *args, **kwargs):\n+  \"\"\"Emulates `pd.read_csv` from Pandas, but as a Beam PTransform.\n+\n+  Use this as\n+\n+      df = p | beam.dataframe.io.read_csv(...)\n+\n+  to get a deferred Beam dataframe representing the contents of the file.\n+  \"\"\"\n+  return _ReadFromPandas(pd.read_csv, path, args, kwargs)\n+\n+\n+def write_csv(df, path, *args, **kwargs):\n+  from apache_beam.dataframe import convert", "originalCommit": "1be53570550a175badfddfe5143ce825ce8ee088", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEzMjQ4NA==", "url": "https://github.com/apache/beam/pull/12841#discussion_r491132484", "bodyText": "I was running into circular import issues. Will add a comment.", "author": "robertwb", "createdAt": "2020-09-18T18:51:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwMDU5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTExMDYxMg==", "url": "https://github.com/apache/beam/pull/12841#discussion_r491110612", "bodyText": "test_read_csv (seems like this is testing read_csv) ?", "author": "chamikaramj", "createdAt": "2020-09-18T18:06:29Z", "path": "sdks/python/apache_beam/dataframe/io_test.py", "diffHunk": "@@ -0,0 +1,67 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import glob\n+import os\n+import shutil\n+import sys\n+import tempfile\n+import unittest\n+\n+import apache_beam as beam\n+from apache_beam.dataframe import io\n+\n+\n+class IOTest(unittest.TestCase):\n+  def setUp(self):\n+    self._temp_roots = []\n+\n+  def tearDown(self):\n+    for root in self._temp_roots:\n+      shutil.rmtree(root)\n+\n+  def temp_dir(self, files=None):\n+    dir = tempfile.mkdtemp(prefix='beam-test')\n+    self._temp_roots.append(dir)\n+    if files:\n+      for name, contents in files.items():\n+        with open(os.path.join(dir, name), 'w') as fout:\n+          fout.write(contents)\n+    return dir + os.sep\n+\n+  def read_all_lines(self, pattern):\n+    for path in glob.glob(pattern):\n+      with open(path) as fin:\n+        # TODO(Py3): yield from\n+        for line in fin:\n+          yield line.rstrip('\\n')\n+\n+  @unittest.skipIf(sys.version_info[0] < 3, 'unicode issues')\n+  def test_write_csv(self):", "originalCommit": "1be53570550a175badfddfe5143ce825ce8ee088", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEzNjYzMw==", "url": "https://github.com/apache/beam/pull/12841#discussion_r491136633", "bodyText": "This tests tests both read and write.", "author": "robertwb", "createdAt": "2020-09-18T19:00:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTExMDYxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTExMDk3MQ==", "url": "https://github.com/apache/beam/pull/12841#discussion_r491110971", "bodyText": "Add a test for write_cvs as well ?", "author": "chamikaramj", "createdAt": "2020-09-18T18:07:10Z", "path": "sdks/python/apache_beam/dataframe/io_test.py", "diffHunk": "@@ -0,0 +1,67 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import glob\n+import os\n+import shutil\n+import sys\n+import tempfile\n+import unittest\n+\n+import apache_beam as beam\n+from apache_beam.dataframe import io\n+\n+\n+class IOTest(unittest.TestCase):\n+  def setUp(self):\n+    self._temp_roots = []\n+\n+  def tearDown(self):\n+    for root in self._temp_roots:\n+      shutil.rmtree(root)\n+\n+  def temp_dir(self, files=None):\n+    dir = tempfile.mkdtemp(prefix='beam-test')\n+    self._temp_roots.append(dir)\n+    if files:\n+      for name, contents in files.items():\n+        with open(os.path.join(dir, name), 'w') as fout:\n+          fout.write(contents)\n+    return dir + os.sep\n+\n+  def read_all_lines(self, pattern):\n+    for path in glob.glob(pattern):\n+      with open(path) as fin:\n+        # TODO(Py3): yield from\n+        for line in fin:\n+          yield line.rstrip('\\n')\n+\n+  @unittest.skipIf(sys.version_info[0] < 3, 'unicode issues')\n+  def test_write_csv(self):\n+    input = self.temp_dir({'1.csv': 'a,b\\n1,2\\n', '2.csv': 'a,b\\n3,4\\n'})\n+    output = self.temp_dir()\n+    with beam.Pipeline() as p:", "originalCommit": "1be53570550a175badfddfe5143ce825ce8ee088", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEzNjY3Mw==", "url": "https://github.com/apache/beam/pull/12841#discussion_r491136673", "bodyText": "This tests tests both read and write. Updated name.", "author": "robertwb", "createdAt": "2020-09-18T19:00:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTExMDk3MQ=="}], "type": "inlineReview"}, {"oid": "951f47b69e17bfc16c6636b81b9e5b944da83843", "url": "https://github.com/apache/beam/commit/951f47b69e17bfc16c6636b81b9e5b944da83843", "message": "last couple fixes", "committedDate": "2020-09-18T19:03:40Z", "type": "commit"}, {"oid": "5002508dff064cb17e25751ec868f754ea2d997e", "url": "https://github.com/apache/beam/commit/5002508dff064cb17e25751ec868f754ea2d997e", "message": "Merge branch 'master' into dataframe-csv", "committedDate": "2020-09-18T19:03:44Z", "type": "commit"}]}