{"pr_number": 11469, "pr_title": "Added a batch example with covid tracking data for interactive notebook.", "pr_createdAt": "2020-04-20T21:52:30Z", "pr_url": "https://github.com/apache/beam/pull/11469", "timeline": [{"oid": "6f88f7ef2ce47ec9cc57cee43666cb3ce210acc9", "url": "https://github.com/apache/beam/commit/6f88f7ef2ce47ec9cc57cee43666cb3ce210acc9", "message": "Added a batch example with covid tracking data for interactive notebook.", "committedDate": "2020-04-20T21:51:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTc1NTA2NA==", "url": "https://github.com/apache/beam/pull/11469#discussion_r411755064", "bodyText": "Can we get this information from the data directly?", "author": "aaltay", "createdAt": "2020-04-20T23:18:39Z", "path": "sdks/python/apache_beam/runners/interactive/examples/UsCovidDataExample.ipynb", "diffHunk": "@@ -0,0 +1,478 @@\n+{\n+ \"cells\": [\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"# Get data from covidtracking.com\\n\",\n+    \"The data set is relatively small and used as a demonstration of working with Beam in an interactive notebook environment.\\n\",\n+    \"\\n\",\n+    \"There are two ways to get the data:\\n\",\n+    \"\\n\",\n+    \"- Get json data from APIs.\\n\",\n+    \"- Download data in csv files directly.\\n\",\n+    \"\\n\",\n+    \"We'll have a batch Beam pipeline example utilizing either method.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import json\\n\",\n+    \"import requests\\n\",\n+    \"\\n\",\n+    \"json_current='https://covidtracking.com/api/v1/states/current.json'\\n\",\n+    \"json_historical='https://covidtracking.com/api/v1/states/daily.json'\\n\",\n+    \"\\n\",\n+    \"def get_json_data(url):\\n\",\n+    \"  with requests.Session() as session:\\n\",\n+    \"    data = json.loads(session.get(url).text)\\n\",\n+    \"  return data\\n\",\n+    \"\\n\",\n+    \"csv_current = 'https://covidtracking.com/api/v1/states/current.csv'\\n\",\n+    \"csv_historical = 'https://covidtracking.com/api/v1/states/daily.csv'\\n\",\n+    \"\\n\",\n+    \"def download_csv(url, filename):\\n\",\n+    \"  if not filename.endswith('.csv'):\\n\",\n+    \"    filename = filename + '.csv'\\n\",\n+    \"  with requests.Session() as session:\\n\",\n+    \"    with open(filename, 'wb') as f:\\n\",\n+    \"      f.write(session.get(url).content)\\n\",\n+    \"  return filename\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Below reads data into memory as json.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"current_data = get_json_data(json_current)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Below downloads data in csv format stored in files.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"csv_file_current = download_csv(csv_current, 'current')\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Prepare some Apache Beam dependencies.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import apache_beam as beam\\n\",\n+    \"from apache_beam.runners.interactive import interactive_beam as ib\\n\",\n+    \"from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Create a Beam pipeline.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"p = beam.Pipeline(runner=InteractiveRunner())\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"You can create a PCollection from either in-memory json data or data in files.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"current_data_from_json = p | 'Create PCollection from json' >> beam.Create(current_data)\\n\",\n+    \"current_data_from_files = p | 'Create PCollection from files' >> beam.io.ReadFromText(csv_file_current, skip_header_lines=1)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"The in-memory json data is already structured.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(current_data_from_json)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"The data from files read as plain text is not structured, we'll have to handle it.\\n\",\n+    \"\\n\",\n+    \"For a batch pipeline reading files with huge content size, it's normal to read source data from files and let Beam handle the work load.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(current_data_from_files)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"We'll parse the plain texts into structured data with Beam SDK.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"current_data_headers = 'state,positive,positiveScore,negativeScore,negativeRegularScore,commercialScore,grade,score,negative,pending,hospitalizedCurrently,hospitalizedCumulative,inIcuCurrently,inIcuCumulative,onVentilatorCurrently,onVentilatorCumulative,recovered,lastUpdateEt,checkTimeEt,death,hospitalized,total,totalTestResults,posNeg,fips,dateModified,dateChecked,notes,hash_val'.split(',')\"", "originalCommit": "6f88f7ef2ce47ec9cc57cee43666cb3ce210acc9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ1NTM2MQ==", "url": "https://github.com/apache/beam/pull/11469#discussion_r412455361", "bodyText": "Yes, added a read_headers function to read headers directly from csv files.", "author": "KevinGG", "createdAt": "2020-04-21T20:06:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTc1NTA2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTc1NTI1OA==", "url": "https://github.com/apache/beam/pull/11469#discussion_r411755258", "bodyText": "How about pass state name as an argument and make this FilterbyState?", "author": "aaltay", "createdAt": "2020-04-20T23:19:12Z", "path": "sdks/python/apache_beam/runners/interactive/examples/UsCovidDataExample.ipynb", "diffHunk": "@@ -0,0 +1,478 @@\n+{\n+ \"cells\": [\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"# Get data from covidtracking.com\\n\",\n+    \"The data set is relatively small and used as a demonstration of working with Beam in an interactive notebook environment.\\n\",\n+    \"\\n\",\n+    \"There are two ways to get the data:\\n\",\n+    \"\\n\",\n+    \"- Get json data from APIs.\\n\",\n+    \"- Download data in csv files directly.\\n\",\n+    \"\\n\",\n+    \"We'll have a batch Beam pipeline example utilizing either method.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import json\\n\",\n+    \"import requests\\n\",\n+    \"\\n\",\n+    \"json_current='https://covidtracking.com/api/v1/states/current.json'\\n\",\n+    \"json_historical='https://covidtracking.com/api/v1/states/daily.json'\\n\",\n+    \"\\n\",\n+    \"def get_json_data(url):\\n\",\n+    \"  with requests.Session() as session:\\n\",\n+    \"    data = json.loads(session.get(url).text)\\n\",\n+    \"  return data\\n\",\n+    \"\\n\",\n+    \"csv_current = 'https://covidtracking.com/api/v1/states/current.csv'\\n\",\n+    \"csv_historical = 'https://covidtracking.com/api/v1/states/daily.csv'\\n\",\n+    \"\\n\",\n+    \"def download_csv(url, filename):\\n\",\n+    \"  if not filename.endswith('.csv'):\\n\",\n+    \"    filename = filename + '.csv'\\n\",\n+    \"  with requests.Session() as session:\\n\",\n+    \"    with open(filename, 'wb') as f:\\n\",\n+    \"      f.write(session.get(url).content)\\n\",\n+    \"  return filename\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Below reads data into memory as json.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"current_data = get_json_data(json_current)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Below downloads data in csv format stored in files.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"csv_file_current = download_csv(csv_current, 'current')\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Prepare some Apache Beam dependencies.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import apache_beam as beam\\n\",\n+    \"from apache_beam.runners.interactive import interactive_beam as ib\\n\",\n+    \"from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Create a Beam pipeline.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"p = beam.Pipeline(runner=InteractiveRunner())\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"You can create a PCollection from either in-memory json data or data in files.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"current_data_from_json = p | 'Create PCollection from json' >> beam.Create(current_data)\\n\",\n+    \"current_data_from_files = p | 'Create PCollection from files' >> beam.io.ReadFromText(csv_file_current, skip_header_lines=1)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"The in-memory json data is already structured.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(current_data_from_json)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"The data from files read as plain text is not structured, we'll have to handle it.\\n\",\n+    \"\\n\",\n+    \"For a batch pipeline reading files with huge content size, it's normal to read source data from files and let Beam handle the work load.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(current_data_from_files)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"We'll parse the plain texts into structured data with Beam SDK.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"current_data_headers = 'state,positive,positiveScore,negativeScore,negativeRegularScore,commercialScore,grade,score,negative,pending,hospitalizedCurrently,hospitalizedCumulative,inIcuCurrently,inIcuCumulative,onVentilatorCurrently,onVentilatorCumulative,recovered,lastUpdateEt,checkTimeEt,death,hospitalized,total,totalTestResults,posNeg,fips,dateModified,dateChecked,notes,hash_val'.split(',')\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"from collections import namedtuple\\n\",\n+    \"\\n\",\n+    \"UsCovidData = namedtuple('UsCovidData', current_data_headers)\\n\",\n+    \"\\n\",\n+    \"class UsCovidDataCsvReader(beam.DoFn):\\n\",\n+    \"  def __init__(self, schema):\\n\",\n+    \"    self._schema = schema\\n\",\n+    \"    \\n\",\n+    \"  def process(self, element):\\n\",\n+    \"    values = [int(val) if val.isdigit() else val for val in element.split(',')]\\n\",\n+    \"    return [self._schema(*values)]\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"current_data = current_data_from_files | 'Parse' >> beam.ParDo(UsCovidDataCsvReader(UsCovidData))\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(current_data)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"With Interactive Beam, you can collect a PCollection into a pandas dataframe. It's useful when you just want to play with small test data sets locally on a single machine.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"df = ib.collect(current_data)\\n\",\n+    \"df.describe()\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Now let's take a deeper look into the data with the visualization feature of Interactive Beam and come up with some tasks.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(current_data, visualize_data=True)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"We can find out that NY currently has the most positive COVID cases with above facets visualization because the data set is small (for demo).\\n\",\n+    \"\\n\",\n+    \"Now we can write a beam transform to try to get that same conclusion of which state has the highest positive number currently.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"from functools import total_ordering\\n\",\n+    \"\\n\",\n+    \"@total_ordering\\n\",\n+    \"class UsCovidDataOrderByPositive:\\n\",\n+    \"  def __init__(self, data):\\n\",\n+    \"    self._data = data\\n\",\n+    \"  \\n\",\n+    \"  def __gt__(self, other):\\n\",\n+    \"    return self._data.positive > other._data.positive\\n\",\n+    \"\\n\",\n+    \"\\n\",\n+    \"def maximum(values):\\n\",\n+    \"  return max(values) if values else None\\n\",\n+    \"\\n\",\n+    \"max_positive = (current_data \\n\",\n+    \"                | 'Data OrderByPositive' >> beam.Map(lambda data: UsCovidDataOrderByPositive(data))\\n\",\n+    \"                | 'Find Maximum Positive' >> beam.CombineGlobally(maximum)\\n\",\n+    \"                | 'Convert Back to Data' >> beam.Map(lambda orderable_data: orderable_data._data))\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(max_positive)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"We can also try to come up with the total positive case number in the US.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"total_positive = (current_data\\n\",\n+    \"                  | 'Positive Per State' >> beam.Map(lambda data: data.positive)\\n\",\n+    \"                  | 'Total Positive' >> beam.CombineGlobally(sum))\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(total_positive)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Now let's look at some more complicated data: the historical data.\\n\",\n+    \"\\n\",\n+    \"It contains similar data to current for each day until current day.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"csv_file_historical = download_csv(csv_historical, 'historical')\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"historical_data_from_files = p | 'Create PCollection for historical data from files' >> beam.io.ReadFromText(csv_file_historical, skip_header_lines=1)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(historical_data_from_files)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"historical_data_headers = 'date,state,positive,negative,pending,hospitalizedCurrently,hospitalizedCumulative,inIcuCurrently,inIcuCumulative,onVentilatorCurrently,onVentilatorCumulative,recovered,hash,dateChecked,death,hospitalized,total,totalTestResults,posNeg,fips,deathIncrease,hospitalizedIncrease,negativeIncrease,positiveIncrease,totalTestResultsIncrease'.split(',')\\n\",\n+    \"\\n\",\n+    \"HistoricalUsCovidData = namedtuple('HistoricalUsCovidData', historical_data_headers)\\n\",\n+    \"\\n\",\n+    \"historical_data = historical_data_from_files | 'Parse' >> beam.ParDo(UsCovidDataCsvReader(HistoricalUsCovidData))\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(historical_data)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"For demostration, let's just take a look at NY throughout the timeline.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"class FilterNy(beam.DoFn):\\n\",", "originalCommit": "6f88f7ef2ce47ec9cc57cee43666cb3ce210acc9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ1NTYzNA==", "url": "https://github.com/apache/beam/pull/11469#discussion_r412455634", "bodyText": "Changed it to FilterByState.", "author": "KevinGG", "createdAt": "2020-04-21T20:06:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTc1NTI1OA=="}], "type": "inlineReview"}, {"oid": "e0cd94a9d76e254f2a21fff49bdcb0f8d8a5f4ee", "url": "https://github.com/apache/beam/commit/e0cd94a9d76e254f2a21fff49bdcb0f8d8a5f4ee", "message": "Added read_headers utility and changed the filter to allow pass in a state.", "committedDate": "2020-04-21T20:05:27Z", "type": "commit"}, {"oid": "e9ea4fc8c43db957051a305e68e702397761ceca", "url": "https://github.com/apache/beam/commit/e9ea4fc8c43db957051a305e68e702397761ceca", "message": "Added apache 2.0 license to the example notebook.\n\nChange-Id: Ib15b9b05a915ce589b26603ddfe6a49af70c2383", "committedDate": "2020-04-22T18:20:56Z", "type": "commit"}]}