{"pr_number": 13175, "pr_title": "Adding performance improvements to ApproximateQuantiles.", "pr_createdAt": "2020-10-23T04:36:13Z", "pr_url": "https://github.com/apache/beam/pull/13175", "timeline": [{"oid": "29e18a260b0314df8fadcfc25436f0bb0620f2ed", "url": "https://github.com/apache/beam/commit/29e18a260b0314df8fadcfc25436f0bb0620f2ed", "message": "Adding Cythonization and other performance improvements to ApproximateQuantiles.", "committedDate": "2020-10-23T04:30:11Z", "type": "commit"}, {"oid": "cc7a48b4a4815ea9172b7db571fe6873612a82dc", "url": "https://github.com/apache/beam/commit/cc7a48b4a4815ea9172b7db571fe6873612a82dc", "message": "Pickling and Lint fixes.", "committedDate": "2020-10-23T15:55:00Z", "type": "commit"}, {"oid": "9f809cf45111b2b76ff6cc1237733ed28498325c", "url": "https://github.com/apache/beam/commit/9f809cf45111b2b76ff6cc1237733ed28498325c", "message": "More fixes.", "committedDate": "2020-10-23T19:44:02Z", "type": "commit"}, {"oid": "717c4f4d9898dd438e8a2f5ee3f8a3c6e54fd70b", "url": "https://github.com/apache/beam/commit/717c4f4d9898dd438e8a2f5ee3f8a3c6e54fd70b", "message": "More fixes.", "committedDate": "2020-10-23T20:56:49Z", "type": "commit"}, {"oid": "53aa529e754bcf34504a9f9ebecaf8a3ed7f2a3f", "url": "https://github.com/apache/beam/commit/53aa529e754bcf34504a9f9ebecaf8a3ed7f2a3f", "message": "More fixes.", "committedDate": "2020-10-25T22:01:33Z", "type": "commit"}, {"oid": "14ff653440e7f6187fac6b7146561a3c16a21952", "url": "https://github.com/apache/beam/commit/14ff653440e7f6187fac6b7146561a3c16a21952", "message": "Another pylint fix.", "committedDate": "2020-10-26T14:30:21Z", "type": "commit"}, {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671", "url": "https://github.com/apache/beam/commit/2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671", "message": "Finishing touch.", "committedDate": "2020-10-26T20:09:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng==", "url": "https://github.com/apache/beam/pull/13175#discussion_r513688196", "bodyText": "Are there downsides to just making this a dependency?", "author": "robertwb", "createdAt": "2020-10-28T18:56:16Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -61,30 +58,34 @@\n K = typing.TypeVar('K')\n V = typing.TypeVar('V')\n \n+try:\n+  import mmh3  # pylint: disable=import-error\n \n-def _get_default_hash_fn():\n-  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n-  try:\n-    import mmh3  # pylint: disable=import-error\n+  def _mmh3_hash(value):\n+    # mmh3.hash64 returns two 64-bit unsigned integers\n+    return mmh3.hash64(value, seed=0, signed=False)[0]\n+\n+  _default_hash_fn = _mmh3_hash\n+  _default_hash_fn_type = 'mmh3'\n+except ImportError:\n \n-    def _mmh3_hash(value):\n-      # mmh3.hash64 returns two 64-bit unsigned integers\n-      return mmh3.hash64(value, seed=0, signed=False)[0]\n+  def _md5_hash(value):\n+    # md5 is a 128-bit hash, so we truncate the hexdigest (string of 32\n+    # hexadecimal digits) to 16 digits and convert to int to get the 64-bit\n+    # integer fingerprint.\n+    return int(hashlib.md5(value).hexdigest()[:16], 16)\n \n-    return _mmh3_hash\n+  _default_hash_fn = _md5_hash\n+  _default_hash_fn_type = 'md5'\n \n-  except ImportError:\n+\n+def _get_default_hash_fn():\n+  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n+  if _default_hash_fn_type == 'md5':\n     logging.warning(\n         'Couldn\\'t find murmurhash. Install mmh3 for a faster implementation of'", "originalCommit": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM2Mzk5NQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r514363995", "bodyText": "Not sure if it's still maintained, last release happened 3 years ago. I'm not aware of any other downsides, wdyt?\nhttps://github.com/hajimes/mmh3", "author": "iindyk", "createdAt": "2020-10-29T15:45:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg2MTM3MQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r564861371", "bodyText": "One downside is that mmh3 has only source release, and does not release wheel files. Installing mmh3 requires certain c++ compiler/headers dependencies be present on the machine. It appears that the project is no longer maintained. I tried to contact the maintainer and did not receive a response... Note that sklearn has also implemented a python wrapper for murmurhash: https://scikit-learn.org/stable/modules/generated/sklearn.utils.murmurhash3_32.html. We could likewise incorporate murmurhash into Beam codebase, make a (maintainable) fork of mmh3 and release wheel files, use sklearn's implementation, or try to explore a different library for our hashing needs.", "author": "tvalentyn", "createdAt": "2021-01-26T21:57:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg2MzE2MA==", "url": "https://github.com/apache/beam/pull/13175#discussion_r564863160", "bodyText": "Looks like there is already a binary version: https://pypi.org/project/mmh3-binary/, with a somewhat recent release (Apr 2020, but only 3.6 wheels: https://pypi.org/project/mmh3-binary/#files).", "author": "tvalentyn", "createdAt": "2021-01-26T22:00:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcyMDM0Mw==", "url": "https://github.com/apache/beam/pull/13175#discussion_r570720343", "bodyText": "Should I make it a dependency then?", "author": "iindyk", "createdAt": "2021-02-05T04:55:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDE3NTgyNQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r574175825", "bodyText": "I wouldn't make it a dependency until it releases wheels.", "author": "tvalentyn", "createdAt": "2021-02-11T00:12:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDk2OTg1OQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r574969859", "bodyText": "sg", "author": "iindyk", "createdAt": "2021-02-12T03:26:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4OTc5Ng==", "url": "https://github.com/apache/beam/pull/13175#discussion_r513689796", "bodyText": "Nit: it'd be easier to read if reverse and key is None rather than having the extra negation in there.", "author": "robertwb", "createdAt": "2020-10-28T18:58:59Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:", "originalCommit": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM2NDA4Ng==", "url": "https://github.com/apache/beam/pull/13175#discussion_r514364086", "bodyText": "Done.", "author": "iindyk", "createdAt": "2020-10-29T15:45:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4OTc5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDM4Mw==", "url": "https://github.com/apache/beam/pull/13175#discussion_r513690383", "bodyText": "I'm curious if it's faster to always have weights (by default 1) than introducing this indirection everywhere.", "author": "robertwb", "createdAt": "2020-10-28T19:00:00Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))", "originalCommit": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM2NDE4OA==", "url": "https://github.com/apache/beam/pull/13175#discussion_r514364188", "bodyText": "It's not, unfortunately. It's about 30% slower in add_input (for batched inputs) and slightly more than that in merge_accumulators.", "author": "iindyk", "createdAt": "2020-10-29T15:45:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDM4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM2NTkyOQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r514365929", "bodyText": "And would also increase memory usage by elements_in_buffers * weight_type_size, which may be significant relative to the current memory usage.", "author": "iindyk", "createdAt": "2020-10-29T15:48:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDM4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk3Mzk1Nw==", "url": "https://github.com/apache/beam/pull/13175#discussion_r520973957", "bodyText": "Ah, OK. Thanks for the info.", "author": "robertwb", "createdAt": "2020-11-11T00:58:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDM4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDg3MQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r513690871", "bodyText": "Can we doubly inherit to keep the type checking?", "author": "robertwb", "createdAt": "2020-10-28T19:00:50Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):", "originalCommit": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM2NjAxMw==", "url": "https://github.com/apache/beam/pull/13175#discussion_r514366013", "bodyText": "Is there a good way to make this inheritance work with Cython?\nIt doesn't compile with inheritance from a non-extension type.", "author": "iindyk", "createdAt": "2020-10-29T15:48:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDg3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk3NDM5Mw==", "url": "https://github.com/apache/beam/pull/13175#discussion_r520974393", "bodyText": "You should be able to inherit rom both object and Generic[T].", "author": "robertwb", "createdAt": "2020-11-11T00:59:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDg3MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQzODg5NQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r521438895", "bodyText": "when inherit _QuantileBuffer(object, Generic[T]), without Cython I get\nTypeError: Cannot create a consistent method resolution order (MRO) for bases object, Generic\n\nWhen I do _QuantileBuffer(Generic[T], object), then it works for Python, but with Cythonization I get\nFirst base of '_QuantileBuffer' is not an extension type.\n\nand\nOnly one extension type base class allowed.\n\nAm I missing something?", "author": "iindyk", "createdAt": "2020-11-11T15:30:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDg3MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MzgxNA==", "url": "https://github.com/apache/beam/pull/13175#discussion_r513693814", "bodyText": "This will break if it's called twice. Instead put the call to zip here.", "author": "robertwb", "createdAt": "2020-10-28T19:05:48Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):\n+    # type: (List, List, bool, int, Any, Any) -> None\n     self.elements = elements\n-    self.weighted = weighted\n+    self.weights = weights\n     self.level = level\n-    self.weight = weight\n-\n-  def __lt__(self, other):\n-    if self.weighted:\n-      return [element[0] for element in self.elements\n-              ] < [element[0] for element in other.elements]\n+    if min_val is None or max_val is None:\n+      # Buffer is always initialized with sorted elements.\n+      self.min_val = elements[0]\n+      self.max_val = elements[-1]\n     else:\n-      return self.elements < other.elements\n-\n-  def sized_iterator(self):\n-    class QuantileBufferIterator(object):\n-      def __init__(self, elem, weighted, weight):\n-        self._iter = iter(elem)\n-        self.weighted = weighted\n-        self.weight = weight\n-\n-      def __iter__(self):\n-        return self\n+      # Note that collapsed buffer may not contain min and max in the list of\n+      # elements.\n+      self.min_val = min_val\n+      self.max_val = max_val\n+    self._iter = zip(\n+        self.elements,\n+        self.weights if weighted else itertools.repeat(self.weights[0]))\n \n-      def __next__(self):\n-        if self.weighted:\n-          return next(self._iter)\n-        else:\n-          value = next(self._iter)\n-          return (value, self.weight)\n+  def __iter__(self):\n+    return self._iter", "originalCommit": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM2NjE3MQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r514366171", "bodyText": "Done.", "author": "iindyk", "createdAt": "2020-10-29T15:48:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MzgxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5NDIyMQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r513694221", "bodyText": "Python 2 support no longer needed.", "author": "robertwb", "createdAt": "2020-10-28T19:06:33Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):\n+    # type: (List, List, bool, int, Any, Any) -> None\n     self.elements = elements\n-    self.weighted = weighted\n+    self.weights = weights\n     self.level = level\n-    self.weight = weight\n-\n-  def __lt__(self, other):\n-    if self.weighted:\n-      return [element[0] for element in self.elements\n-              ] < [element[0] for element in other.elements]\n+    if min_val is None or max_val is None:\n+      # Buffer is always initialized with sorted elements.\n+      self.min_val = elements[0]\n+      self.max_val = elements[-1]\n     else:\n-      return self.elements < other.elements\n-\n-  def sized_iterator(self):\n-    class QuantileBufferIterator(object):\n-      def __init__(self, elem, weighted, weight):\n-        self._iter = iter(elem)\n-        self.weighted = weighted\n-        self.weight = weight\n-\n-      def __iter__(self):\n-        return self\n+      # Note that collapsed buffer may not contain min and max in the list of\n+      # elements.\n+      self.min_val = min_val\n+      self.max_val = max_val\n+    self._iter = zip(\n+        self.elements,\n+        self.weights if weighted else itertools.repeat(self.weights[0]))\n \n-      def __next__(self):\n-        if self.weighted:\n-          return next(self._iter)\n-        else:\n-          value = next(self._iter)\n-          return (value, self.weight)\n+  def __iter__(self):\n+    return self._iter\n \n-      next = __next__  # For Python 2\n+  def __next__(self):", "originalCommit": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM2NjI1Nw==", "url": "https://github.com/apache/beam/pull/13175#discussion_r514366257", "bodyText": "Done.", "author": "iindyk", "createdAt": "2020-10-29T15:48:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5NDIyMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5NDM0MQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r513694341", "bodyText": "Same.", "author": "robertwb", "createdAt": "2020-10-28T19:06:47Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):\n+    # type: (List, List, bool, int, Any, Any) -> None\n     self.elements = elements\n-    self.weighted = weighted\n+    self.weights = weights\n     self.level = level\n-    self.weight = weight\n-\n-  def __lt__(self, other):\n-    if self.weighted:\n-      return [element[0] for element in self.elements\n-              ] < [element[0] for element in other.elements]\n+    if min_val is None or max_val is None:\n+      # Buffer is always initialized with sorted elements.\n+      self.min_val = elements[0]\n+      self.max_val = elements[-1]\n     else:\n-      return self.elements < other.elements\n-\n-  def sized_iterator(self):\n-    class QuantileBufferIterator(object):\n-      def __init__(self, elem, weighted, weight):\n-        self._iter = iter(elem)\n-        self.weighted = weighted\n-        self.weight = weight\n-\n-      def __iter__(self):\n-        return self\n+      # Note that collapsed buffer may not contain min and max in the list of\n+      # elements.\n+      self.min_val = min_val\n+      self.max_val = max_val\n+    self._iter = zip(\n+        self.elements,\n+        self.weights if weighted else itertools.repeat(self.weights[0]))\n \n-      def __next__(self):\n-        if self.weighted:\n-          return next(self._iter)\n-        else:\n-          value = next(self._iter)\n-          return (value, self.weight)\n+  def __iter__(self):\n+    return self._iter\n \n-      next = __next__  # For Python 2\n+  def __next__(self):\n+    return next(self._iter)\n \n-    return QuantileBufferIterator(self.elements, self.weighted, self.weight)\n+  def __lt__(self, other):\n+    return self.level < other.level\n \n \n-class _QuantileState(Generic[T]):\n+class _QuantileState(object):", "originalCommit": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0f36b7d5baca732684e678ed7a5cb6cea381ab59", "url": "https://github.com/apache/beam/commit/0f36b7d5baca732684e678ed7a5cb6cea381ab59", "message": "Addressing some comments.", "committedDate": "2020-10-29T15:19:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk3MzUxMg==", "url": "https://github.com/apache/beam/pull/13175#discussion_r520973512", "bodyText": "Go ahead and put a trailing comma on this one too.", "author": "robertwb", "createdAt": "2020-11-11T00:58:16Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -299,15 +300,17 @@ class ApproximateQuantiles(object):\n     out: [0, 2, 5, 7, 100]\n   \"\"\"\n   @staticmethod\n-  def _display_data(num_quantiles, key, reverse, weighted):\n+  def _display_data(num_quantiles, key, reverse, weighted, batch_input):\n     return {\n         'num_quantiles': DisplayDataItem(num_quantiles, label='Quantile Count'),\n         'key': DisplayDataItem(\n             key.__name__\n             if hasattr(key, '__name__') else key.__class__.__name__,\n             label='Record Comparer Key'),\n         'reverse': DisplayDataItem(str(reverse), label='Is Reversed'),\n-        'weighted': DisplayDataItem(str(weighted), label='Is Weighted')\n+        'weighted': DisplayDataItem(str(weighted), label='Is Weighted'),\n+        'batch_input': DisplayDataItem(\n+            str(batch_input), label='Is Input Batched')", "originalCommit": "0f36b7d5baca732684e678ed7a5cb6cea381ab59", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQzNDEyOQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r521434129", "bodyText": "Done.", "author": "iindyk", "createdAt": "2020-11-11T15:23:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk3MzUxMg=="}], "type": "inlineReview"}, {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264", "url": "https://github.com/apache/beam/commit/8fff438793b622ac6ae2493d9fb24a581edc4264", "message": "Adding comma.", "committedDate": "2020-11-11T15:21:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjk5MzkzNQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r562993935", "bodyText": "Re: line 766: could you please clarify what is N in the docstring\nAlso, can you please note that the algorithm referenced in the paper is generalized to compute weighted quantiles.", "author": "tvalentyn", "createdAt": "2021-01-23T01:13:25Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -501,6 +781,8 @@ class ApproximateQuantilesCombineFn(CombineFn, Generic[T]):\n     weighted: (optional) if set to True, the combiner produces weighted\n       quantiles. The input elements are then expected to be tuples of input\n       values with the corresponding weight.\n+    batch_input: (optional) if set to True, inputs are expected to be batches of", "originalCommit": "8fff438793b622ac6ae2493d9fb24a581edc4264", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNTc2OA==", "url": "https://github.com/apache/beam/pull/13175#discussion_r570715768", "bodyText": "Done.", "author": "iindyk", "createdAt": "2021-02-05T04:39:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjk5MzkzNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzQyNzYwMw==", "url": "https://github.com/apache/beam/pull/13175#discussion_r563427603", "bodyText": "Can you please comment on the structure of a 'batch' here? in particular for the weighted case. Consider also adding an example to line 295.\n\n\nLooking at the tests, it seems that for weighted case with batches, we expect users to provide  elements and weights as separate lists. From API/usability standpoint, what is the rationale on providing weights as a separate list in as opposed to augmenting the weight to the element in a tuple, which is how elements are represented for non-batched case?", "author": "tvalentyn", "createdAt": "2021-01-25T02:09:27Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -327,27 +330,39 @@ class Globally(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate", "originalCommit": "8fff438793b622ac6ae2493d9fb24a581edc4264", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg2NTgxNA==", "url": "https://github.com/apache/beam/pull/13175#discussion_r564865814", "bodyText": "wording suggestion: s/batch_input/input_batched  or inputs_batched, since the parameter refers to the input rather than the result (like in case of reverse).", "author": "tvalentyn", "createdAt": "2021-01-26T22:05:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzQyNzYwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNjA0Mg==", "url": "https://github.com/apache/beam/pull/13175#discussion_r570716042", "bodyText": "Done, also added examples.\nI think tuple (element, weight) generalizes the same way to (elements, weights) as it does to [(element1, weight1), ...], so I don't see any strong advantage of either from usability perspective (for instance, TFT's quantiles take them as separate tensors), but there's a benefit in taking (elements, weights) from code simplicity perspective - it allows weighted and unweighted cases to have a lot of code in common.", "author": "iindyk", "createdAt": "2021-02-05T04:40:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzQyNzYwMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzIxNTk0NQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r573215945", "bodyText": "SG, thank you.", "author": "tvalentyn", "createdAt": "2021-02-09T20:32:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzQyNzYwMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg3NTg5Mw==", "url": "https://github.com/apache/beam/pull/13175#discussion_r564875893", "bodyText": "Please comment that in non-weighted case weights stores a single element - the weight of the buffer in the sense of the algorithm. In the generalized (weighted) case, it stores weights of individual elements.", "author": "tvalentyn", "createdAt": "2021-01-26T22:25:16Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,126 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if reverse and key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif reverse:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+    elif key is None:\n+      self.less_than = lambda a, b: a < b\n+    else:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):", "originalCommit": "8fff438793b622ac6ae2493d9fb24a581edc4264", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNjEwMg==", "url": "https://github.com/apache/beam/pull/13175#discussion_r570716102", "bodyText": "Done.", "author": "iindyk", "createdAt": "2021-02-05T04:40:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg3NTg5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg4ODM4Nw==", "url": "https://github.com/apache/beam/pull/13175#discussion_r564888387", "bodyText": "For my education, why was this required? Is there some internal state that gets in the way of pickling? Also, could you please add a comment?", "author": "tvalentyn", "createdAt": "2021-01-26T22:49:55Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -452,15 +511,236 @@ def __init__(self, buffer_size, num_buffers, unbuffered_elements, buffers):\n     # into new, full buffers and then take them into account when computing the\n     # final output.\n     self.unbuffered_elements = unbuffered_elements\n+    self.unbuffered_weights = unbuffered_weights\n+\n+  def __reduce__(self):", "originalCommit": "8fff438793b622ac6ae2493d9fb24a581edc4264", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxOTc5OQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r570719799", "bodyText": "When Cythonization is enabled pickling fails without it. I can lookup the error description, if interested. Added a comment.", "author": "iindyk", "createdAt": "2021-02-05T04:53:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg4ODM4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTAzOTU3MA==", "url": "https://github.com/apache/beam/pull/13175#discussion_r565039570", "bodyText": "Nit: self.add_input = self._add_inputs may be easier to read.", "author": "tvalentyn", "createdAt": "2021-01-27T05:34:56Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -523,29 +805,25 @@ def __init__(\n       num_buffers,  # type: int\n       key=None,\n       reverse=False,\n-      weighted=False):\n-    def _comparator(a, b):\n-      if key:\n-        a, b = key(a), key(b)\n-\n-      retval = int(a > b) - int(a < b)\n-\n-      if reverse:\n-        return -retval\n-\n-      return retval\n-\n-    self._comparator = _comparator\n-\n+      weighted=False,\n+      batch_input=False):\n     self._num_quantiles = num_quantiles\n-    self._buffer_size = buffer_size\n-    self._num_buffers = num_buffers\n-    if weighted:\n-      self._key = (lambda x: x[0]) if key is None else (lambda x: key(x[0]))\n-    else:\n-      self._key = key\n-    self._reverse = reverse\n-    self._weighted = weighted\n+    self._spec = _QuantileSpec(buffer_size, num_buffers, weighted, key, reverse)\n+    self._batch_input = batch_input\n+    if self._batch_input:\n+      setattr(self, 'add_input', self._add_inputs)", "originalCommit": "8fff438793b622ac6ae2493d9fb24a581edc4264", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNjEzNg==", "url": "https://github.com/apache/beam/pull/13175#discussion_r570716136", "bodyText": "Done.", "author": "iindyk", "createdAt": "2021-02-05T04:40:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTAzOTU3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDk3MjcwMQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r574972701", "bodyText": "Just realized that the direct assignment causes a lint error:\n03:29:45 apache_beam/transforms/stats.py:837: error: Cannot assign to a method  [assignment]\n\nchanged back to setattr", "author": "iindyk", "createdAt": "2021-02-12T03:39:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTAzOTU3MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODg5MzM5Mg==", "url": "https://github.com/apache/beam/pull/13175#discussion_r578893392", "bodyText": "Thanks. Looks like this is python/mypy#2427.", "author": "tvalentyn", "createdAt": "2021-02-19T03:05:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTAzOTU3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0MTAxMQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r565641011", "bodyText": "I am not sure how k, b are computed here (see line 872) - it seems that b follows the experimental evaluation suggested in sect. 4.3 of the paper, which corresponds to a 'Munro-Paterson algorithm', while the experimental evaluation for the 'new' algorithm is covered in 4.5. Looking at the Table1, the 'new' algorithm has lower values of k, b, perhaps it is worth to reexamine this logic.", "author": "tvalentyn", "createdAt": "2021-01-27T21:19:40Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -582,6 +861,8 @@ def create(\n       weighted: (optional) if set to True, the combiner produces weighted\n         quantiles. The input elements are then expected to be tuples of values\n         with the corresponding weight.\n+      batch_input: (optional) if set to True, inputs are expected to be batches\n+        of elements.", "originalCommit": "8fff438793b622ac6ae2493d9fb24a581edc4264", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNjMxMg==", "url": "https://github.com/apache/beam/pull/13175#discussion_r570716312", "bodyText": "Yes, here the logic of the Munro-Paterson algorithm is used. Switching to the calculation from 4.5 would allow to reduce size of the (full) accumulator. But it's probably out of the scope of this PR, should I leave a TODO?", "author": "iindyk", "createdAt": "2021-02-05T04:41:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0MTAxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzIyMDYwOA==", "url": "https://github.com/apache/beam/pull/13175#discussion_r573220608", "bodyText": "Agree that this is out of scope, SGTM to add a note in case someone happens to read through this..\nAFAICT this is not critical, and these numbers numbers are tied to MAX_ELEMENTS, which is somewhat arbitrary and not exposed to in the user. Perhaps if we decide to expose MAX_ELEMENTS as a transform param, we'd have to take a closer look at this.", "author": "tvalentyn", "createdAt": "2021-02-09T20:38:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0MTAxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDk2OTk5Nw==", "url": "https://github.com/apache/beam/pull/13175#discussion_r574969997", "bodyText": "Added a note.", "author": "iindyk", "createdAt": "2021-02-12T03:27:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0MTAxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0Njg4Mg==", "url": "https://github.com/apache/beam/pull/13175#discussion_r565646882", "bodyText": "Would this hint work here ?\n# type: (List) -> Callable[[int], Any]", "author": "tvalentyn", "createdAt": "2021-01-27T21:29:13Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,126 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if reverse and key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif reverse:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+    elif key is None:\n+      self.less_than = lambda a, b: a < b\n+    else:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any", "originalCommit": "8fff438793b622ac6ae2493d9fb24a581edc4264", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNjM0MA==", "url": "https://github.com/apache/beam/pull/13175#discussion_r570716340", "bodyText": "Done.", "author": "iindyk", "createdAt": "2021-02-05T04:41:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0Njg4Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0ODMzNw==", "url": "https://github.com/apache/beam/pull/13175#discussion_r565648337", "bodyText": "would it make sense to make _collapse, _interpolate, _offset be methods of _QuantileState class ? Would that impact cythonization/performance?", "author": "tvalentyn", "createdAt": "2021-01-27T21:31:46Z", "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -636,132 +895,33 @@ def _offset(self, new_weight):\n       self._offset_jitter = 2 - self._offset_jitter\n       return (new_weight + self._offset_jitter) / 2\n \n-  def _collapse(self, buffers):\n-    # type: (Iterable[_QuantileBuffer[T]]) -> _QuantileBuffer[T]\n-    new_level = 0\n-    new_weight = 0\n-    for buffer_elem in buffers:\n-      # As presented in the paper, there should always be at least two\n-      # buffers of the same (minimal) level to collapse, but it is possible\n-      # to violate this condition when combining buffers from independently\n-      # computed shards.  If they differ we take the max.\n-      new_level = max([new_level, buffer_elem.level + 1])\n-      new_weight = new_weight + buffer_elem.weight\n-    if self._weighted:\n-      step = new_weight / (self._buffer_size - 1)\n-      offset = new_weight / (2 * self._buffer_size)\n-    else:\n-      step = new_weight\n-      offset = self._offset(new_weight)\n-    new_elements = self._interpolate(buffers, self._buffer_size, step, offset)\n-    return _QuantileBuffer(new_elements, self._weighted, new_level, new_weight)\n-\n-  def _collapse_if_needed(self, qs):\n-    # type: (_QuantileState) -> None\n-    while len(qs.buffers) > self._num_buffers:\n-      to_collapse = []\n-      to_collapse.append(heapq.heappop(qs.buffers))\n-      to_collapse.append(heapq.heappop(qs.buffers))\n-      min_level = to_collapse[1].level\n-\n-      while len(qs.buffers) > 0 and qs.buffers[0].level == min_level:\n-        to_collapse.append(heapq.heappop(qs.buffers))\n-\n-      heapq.heappush(qs.buffers, self._collapse(to_collapse))\n-\n-  def _interpolate(self, i_buffers, count, step, offset):\n-    \"\"\"\n-    Emulates taking the ordered union of all elements in buffers, repeated\n-    according to their weight, and picking out the (k * step + offset)-th\n-    elements of this list for `0 <= k < count`.\n-    \"\"\"\n-\n-    iterators = []\n-    new_elements = []\n-    compare_key = self._key\n-    if self._key and not self._weighted:\n-      compare_key = lambda x: self._key(x[0])\n-    for buffer_elem in i_buffers:\n-      iterators.append(buffer_elem.sized_iterator())\n-\n-    # Python 3 `heapq.merge` support key comparison and returns an iterator and\n-    # does not pull the data into memory all at once. Python 2 does not\n-    # support comparison on its `heapq.merge` api, so we use the itertools\n-    # which takes the `key` function for comparison and creates an iterator\n-    # from it.\n-    if sys.version_info[0] < 3:\n-      sorted_elem = iter(\n-          sorted(\n-              itertools.chain.from_iterable(iterators),\n-              key=compare_key,\n-              reverse=self._reverse))\n-    else:\n-      sorted_elem = heapq.merge(\n-          *iterators, key=compare_key, reverse=self._reverse)\n-\n-    weighted_element = next(sorted_elem)\n-    current = weighted_element[1]\n-    j = 0\n-    previous = 0\n-    while j < count:\n-      target = j * step + offset\n-      j = j + 1\n-      try:\n-        while current <= target:\n-          weighted_element = next(sorted_elem)\n-          current = current + weighted_element[1]\n-      except StopIteration:\n-        pass\n-      if self._weighted:\n-        new_elements.append((weighted_element[0], current - previous))\n-        previous = current\n-      else:\n-        new_elements.append(weighted_element[0])\n-    return new_elements\n-\n   # TODO(BEAM-7746): Signature incompatible with supertype\n   def create_accumulator(self):  # type: ignore[override]\n-    # type: () -> _QuantileState[T]\n+    # type: () -> _QuantileState\n     self._qs = _QuantileState(\n-        buffer_size=self._buffer_size,\n-        num_buffers=self._num_buffers,\n         unbuffered_elements=[],\n-        buffers=[])\n+        unbuffered_weights=[],\n+        buffers=[],\n+        spec=self._spec)\n     return self._qs\n \n   def add_input(self, quantile_state, element):\n     \"\"\"\n     Add a new element to the collection being summarized by quantile state.\n     \"\"\"\n-    value = element[0] if self._weighted else element\n-    if quantile_state.is_empty():\n-      quantile_state.min_val = quantile_state.max_val = value\n-    elif self._comparator(value, quantile_state.min_val) < 0:\n-      quantile_state.min_val = value\n-    elif self._comparator(value, quantile_state.max_val) > 0:\n-      quantile_state.max_val = value\n-    self._add_unbuffered(quantile_state, elements=[element])\n+    quantile_state.add_unbuffered([element], self._offset)", "originalCommit": "8fff438793b622ac6ae2493d9fb24a581edc4264", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNjQ3Ng==", "url": "https://github.com/apache/beam/pull/13175#discussion_r570716476", "bodyText": "I don't think that this may cause any problems with cythonization or performance. They will be static methods though, so the only difference is the namespace and neither of them deals with _QuantileState objects. But I don't have any strong preference, WDYT?", "author": "iindyk", "createdAt": "2021-02-05T04:42:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0ODMzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzIzNDM3Mw==", "url": "https://github.com/apache/beam/pull/13175#discussion_r573234373", "bodyText": "There is no big difference if they are static, but I thought that if they were instance methods you perhaps you wouldn't have to pass spec or offset_fn. No strong opinion, feel free to leave as is.", "author": "tvalentyn", "createdAt": "2021-02-09T20:56:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0ODMzNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDk3MDA3OQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r574970079", "bodyText": "sg", "author": "iindyk", "createdAt": "2021-02-12T03:27:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0ODMzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1MDMzMw==", "url": "https://github.com/apache/beam/pull/13175#discussion_r565650333", "bodyText": "I have some concerns about test coverage of  ApproximateQuantiles.\n\nDo any of the tests exercise merging of accumulators?\nDo any of the tests exercise collapsing of multiple buffers, including buffers with same & different weights?", "author": "tvalentyn", "createdAt": "2021-01-27T21:35:25Z", "path": "sdks/python/apache_beam/transforms/stats_test.py", "diffHunk": "@@ -482,13 +482,74 @@ def test_alternate_quantiles(self):\n           equal_to([[\"ccccc\", \"aaa\", \"b\"]]),\n           label='checkWithKeyAndReversed')\n \n+  def test_batched_quantiles(self):", "originalCommit": "8fff438793b622ac6ae2493d9fb24a581edc4264", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1Mjg5NA==", "url": "https://github.com/apache/beam/pull/13175#discussion_r565652894", "bodyText": "We should have codecov working again, but somehow retesting didn't trigger it. I think if you add commits to this branch or repush it, codecov will run and may give some signals re: test coverage.", "author": "tvalentyn", "createdAt": "2021-01-27T21:39:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1MDMzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNjY3OQ==", "url": "https://github.com/apache/beam/pull/13175#discussion_r570716679", "bodyText": "I think the tests use DirectRunner, so probably no.\nThe approximation will be properly tested only if either the number of inputs will be large with default settings, or max_num_elements and epsilon will be set to extremely low and large values, respectively. I tested approximation with large number of inputs and FlumeCppRunner during development, but it took some time to complete, so it's probably not suitable for continuous testing. It might make sense for me to initialize the CombineFn with the extreme values and test add_input, merge_accumulators and extract_output directly, WDYT?", "author": "iindyk", "createdAt": "2021-02-05T04:42:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1MDMzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzIzNTY0NA==", "url": "https://github.com/apache/beam/pull/13175#discussion_r573235644", "bodyText": "Given that a typo that creeps in might not be discovered until the code runs on a sufficiently large input, I'd be more comfortable merging this if we added targeted unit tests just for methods in question, exercising the logic that is not exercised in direct runner test due to small size/undeterminism.", "author": "tvalentyn", "createdAt": "2021-02-09T20:58:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1MDMzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDk3MDc2Mg==", "url": "https://github.com/apache/beam/pull/13175#discussion_r574970762", "bodyText": "Makes sense. I added a test that creates a combinefn with extremely small max_num_elements and manually split the data to a bunch of accumulators which are then merged. Also, the small max_num_elements will ensure that buffer collapsing and interpolation is exercised.", "author": "iindyk", "createdAt": "2021-02-12T03:30:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1MDMzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODg5NDUwNg==", "url": "https://github.com/apache/beam/pull/13175#discussion_r578894506", "bodyText": "Thank you, much appreciated!", "author": "tvalentyn", "createdAt": "2021-02-19T03:07:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1MDMzMw=="}], "type": "inlineReview"}, {"oid": "22a1c319e4b8815bf4983c54cb3789fe88a58a6c", "url": "https://github.com/apache/beam/commit/22a1c319e4b8815bf4983c54cb3789fe88a58a6c", "message": "Added comments and renamed the parameter.", "committedDate": "2021-02-05T04:35:25Z", "type": "commit"}, {"oid": "06806b025c88f4145ccd26d01e7b5af7dd48f325", "url": "https://github.com/apache/beam/commit/06806b025c88f4145ccd26d01e7b5af7dd48f325", "message": "Add another comment.", "committedDate": "2021-02-05T04:52:25Z", "type": "commit"}, {"oid": "2f4aebf76867613718550229b10ad7816bf4984f", "url": "https://github.com/apache/beam/commit/2f4aebf76867613718550229b10ad7816bf4984f", "message": "Added a test for buffers collapse and interpolation.", "committedDate": "2021-02-12T03:24:41Z", "type": "commit"}, {"oid": "ad955568c0886e1348ddb8f9a9e6f6f36e8b2886", "url": "https://github.com/apache/beam/commit/ad955568c0886e1348ddb8f9a9e6f6f36e8b2886", "message": "Changing direct method assignment to setattr.", "committedDate": "2021-02-12T03:35:22Z", "type": "commit"}, {"oid": "59b4d6a0ddaa6b82dcd40d1bb654250cb71e78eb", "url": "https://github.com/apache/beam/commit/59b4d6a0ddaa6b82dcd40d1bb654250cb71e78eb", "message": "Fixing lint error.", "committedDate": "2021-02-12T20:05:18Z", "type": "commit"}]}