{"pr_number": 13160, "pr_title": "[BEAM-11078] Add splittable DoFn documentation to programming guide", "pr_createdAt": "2020-10-21T17:47:06Z", "pr_url": "https://github.com/apache/beam/pull/13160", "timeline": [{"oid": "fa53a0dd61aedd848a0d6a5e0227af76b2178ffb", "url": "https://github.com/apache/beam/commit/fa53a0dd61aedd848a0d6a5e0227af76b2178ffb", "message": "[BEAM-11078, BEAM-2081] Convert to markdown, no changes of content from http://doc/1kpn0RxqZaoacUPVSMYhhnfmlo8fGT-p50fEblaFr2HE", "committedDate": "2020-10-20T21:49:55Z", "type": "commit"}, {"oid": "a5f39677388fa263aefe2742b9d76c95c4b68a26", "url": "https://github.com/apache/beam/commit/a5f39677388fa263aefe2742b9d76c95c4b68a26", "message": "Fill in placeholders for missing py snippets.\nMake website renderable.", "committedDate": "2020-10-20T23:04:54Z", "type": "commit"}, {"oid": "30f46307dfacd8642b5dbae3b430ed229c564d50", "url": "https://github.com/apache/beam/commit/30f46307dfacd8642b5dbae3b430ed229c564d50", "message": "edit heading", "committedDate": "2020-10-21T16:11:13Z", "type": "commit"}, {"oid": "beb01b11ed41349fdeed221e84021793196049c5", "url": "https://github.com/apache/beam/commit/beb01b11ed41349fdeed221e84021793196049c5", "message": "Update section menu", "committedDate": "2020-10-21T16:18:42Z", "type": "commit"}, {"oid": "521de77446da09cd7abb7ccdc45f279f6a0a222b", "url": "https://github.com/apache/beam/commit/521de77446da09cd7abb7ccdc45f279f6a0a222b", "message": "Fill in Python code snippets, make minor Java/Go code snippet changes", "committedDate": "2020-10-21T17:44:23Z", "type": "commit"}, {"oid": "e5a6622ae410e4bd7c22193ce0579372ccb33c05", "url": "https://github.com/apache/beam/commit/e5a6622ae410e4bd7c22193ce0579372ccb33c05", "message": "Fix lint issues in snippets", "committedDate": "2020-10-21T18:10:40Z", "type": "commit"}, {"oid": "bb81848f03998f830d1728daea8406015955de31", "url": "https://github.com/apache/beam/commit/bb81848f03998f830d1728daea8406015955de31", "message": "Fix Java snippets", "committedDate": "2020-10-21T18:15:35Z", "type": "commit"}, {"oid": "e25d66a22134e2316e336b9582b2f146dd81c34f", "url": "https://github.com/apache/beam/commit/e25d66a22134e2316e336b9582b2f146dd81c34f", "message": "fix whitespace lint issues in website", "committedDate": "2020-10-21T18:21:15Z", "type": "commit"}, {"oid": "e38f86acced96b71079c6ad3273abf9313b192b7", "url": "https://github.com/apache/beam/commit/e38f86acced96b71079c6ad3273abf9313b192b7", "message": "More python snippet lint fixes", "committedDate": "2020-10-21T18:23:42Z", "type": "commit"}, {"oid": "c2d0fcd65e3fa29793ef1998f9dec719aad61347", "url": "https://github.com/apache/beam/commit/c2d0fcd65e3fa29793ef1998f9dec719aad61347", "message": "Fix Java snippets spotless error", "committedDate": "2020-10-21T18:28:01Z", "type": "commit"}, {"oid": "5294ea19a2bba517ac5544e58e29b957d9536e60", "url": "https://github.com/apache/beam/commit/5294ea19a2bba517ac5544e58e29b957d9536e60", "message": "Add image to SDF high level overview", "committedDate": "2020-10-21T19:50:26Z", "type": "commit"}, {"oid": "cde1bf1761920deded30475f92c782848bf64244", "url": "https://github.com/apache/beam/commit/cde1bf1761920deded30475f92c782848bf64244", "message": "Remove current status link to be re-added back once capability matrix is updated", "committedDate": "2020-10-21T19:50:26Z", "type": "commit"}, {"oid": "cde1bf1761920deded30475f92c782848bf64244", "url": "https://github.com/apache/beam/commit/cde1bf1761920deded30475f92c782848bf64244", "message": "Remove current status link to be re-added back once capability matrix is updated", "committedDate": "2020-10-21T19:50:26Z", "type": "forcePushed"}, {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51", "url": "https://github.com/apache/beam/commit/626366b189b7dee572bd92fdefc7b11b6f7b2d51", "message": "Update Java snippets to satisfy spotbugs", "committedDate": "2020-10-21T21:03:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTgzMzYxOA==", "url": "https://github.com/apache/beam/pull/13160#discussion_r509833618", "bodyText": "Note that rest.Size() is a convenience function added to offsetrange.Restriction specifically, it's not part of the SDF API. It might be better to replace it with rest.End - rest.Start to avoid the expectation that all restrictions will have a size method.", "author": "youngoli", "createdAt": "2020-10-22T01:56:10Z", "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a\n+restriction tracker. The restriction is used to represent a subset of work for a given element.\n+The restriction provider lets SDF authors override default implementations for splitting, sizing,\n+watermark estimation, and so forth. In [Java](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L92)\n+and [Go](https://github.com/apache/beam/blob/0f466e6bcd4ac8677c2bd9ecc8e6af3836b7f3b8/sdks/go/pkg/beam/pardo.go#L226),\n+this is the DoFn. [Python](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/python/apache_beam/transforms/core.py#L213)\n+has a dedicated RestrictionProvider type. The restriction tracker is responsible for tracking\n+what subset of the restriction has been completed during processing.\n+\n+To define a splittable DoFn, you must choose whether the splittable DoFn is bounded (default) or\n+unbounded and define a way to initialize an initial restriction for an element.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) CreateInitialRestriction(filename string) offsetrange.Restriction {\n+\treturn offsetrange.Restriction{\n+\t\tStart: 0,\n+\t\tEnd:   getFileLength(filename),\n+\t}\n+}\n+\n+func (fn *splittableDoFn) CreateTracker(rest offsetrange.Restriction) *sdf.LockRTracker {\n+\treturn sdf.NewLockRTracker(offsetrange.NewTracker(rest))\n+}\n+\n+func (fn *splittableDoFn) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfor rt.TryClaim(offset) {\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+At this point, we have a splittable DoFn that supports [runner-initiated splits](#runner-initiated-split)\n+enabling dynamic work rebalancing. To increase the rate at which initial parallelization of work occurs\n+or for those runners that do not support runner-initiated splitting, we recommend providing\n+a set of initial splits:\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) SplitRestriction(filename string, rest offsetrange.Restriction) (splits []offsetrange.Restriction) {\n+\tsize := 64 * (1 << 20)\n+\ti := rest.Start\n+\tfor i < rest.End - size {\n+\t\t// Compute and output 64 MiB size ranges to process in parallel\n+\t\tend := i + size\n+     \t\tsplits = append(splits, offsetrange.Restriction{i, end})\n+\t\ti = end\n+\t}\n+\t// Output the last range\n+\tsplits = append(splits, offsetrange.Restriction{i, rest.End})\n+\treturn splits\n+}\n+{{< /highlight >}}\n+\n+### 12.2 Sizing and progress {#sizing-and-progress}\n+\n+Sizing and progress are used during execution of a splittable DoFn to inform runners so that they may\n+perform intelligent decisions about which restrictions to split and how to parallelize work.\n+\n+Before processing an element and restriction, an initial size may be used by a runner to choose\n+how and who processes the restrictions attempting to improve initial balancing and parallelization\n+of work. During the processing of an element and restriction, sizing and progress are used to choose\n+which restrictions to split and who should process them.\n+\n+By default, we use the restriction tracker\u2019s estimate for work remaining falling back to assuming\n+that all restrictions have an equal cost. To override the default, SDF authors can provide the\n+appropriate method within the restriction provider.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) RestrictionSize(filename string, rest offsetrange.Restriction) float64 {\n+\tweight := float64(1)\n+\tif strings.Contains(filename, \u201cexpensiveRecords\u201d) {\n+\t\tweight = 2\n+\t}\n+\treturn weight * rest.Size()", "originalCommit": "626366b189b7dee572bd92fdefc7b11b6f7b2d51", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg2NjIwOA==", "url": "https://github.com/apache/beam/pull/13160#discussion_r509866208", "bodyText": "Typo: \"As a splittable DoFn pr an element...\"", "author": "youngoli", "createdAt": "2020-10-22T04:00:52Z", "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a\n+restriction tracker. The restriction is used to represent a subset of work for a given element.\n+The restriction provider lets SDF authors override default implementations for splitting, sizing,\n+watermark estimation, and so forth. In [Java](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L92)\n+and [Go](https://github.com/apache/beam/blob/0f466e6bcd4ac8677c2bd9ecc8e6af3836b7f3b8/sdks/go/pkg/beam/pardo.go#L226),\n+this is the DoFn. [Python](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/python/apache_beam/transforms/core.py#L213)\n+has a dedicated RestrictionProvider type. The restriction tracker is responsible for tracking\n+what subset of the restriction has been completed during processing.\n+\n+To define a splittable DoFn, you must choose whether the splittable DoFn is bounded (default) or\n+unbounded and define a way to initialize an initial restriction for an element.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) CreateInitialRestriction(filename string) offsetrange.Restriction {\n+\treturn offsetrange.Restriction{\n+\t\tStart: 0,\n+\t\tEnd:   getFileLength(filename),\n+\t}\n+}\n+\n+func (fn *splittableDoFn) CreateTracker(rest offsetrange.Restriction) *sdf.LockRTracker {\n+\treturn sdf.NewLockRTracker(offsetrange.NewTracker(rest))\n+}\n+\n+func (fn *splittableDoFn) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfor rt.TryClaim(offset) {\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+At this point, we have a splittable DoFn that supports [runner-initiated splits](#runner-initiated-split)\n+enabling dynamic work rebalancing. To increase the rate at which initial parallelization of work occurs\n+or for those runners that do not support runner-initiated splitting, we recommend providing\n+a set of initial splits:\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) SplitRestriction(filename string, rest offsetrange.Restriction) (splits []offsetrange.Restriction) {\n+\tsize := 64 * (1 << 20)\n+\ti := rest.Start\n+\tfor i < rest.End - size {\n+\t\t// Compute and output 64 MiB size ranges to process in parallel\n+\t\tend := i + size\n+     \t\tsplits = append(splits, offsetrange.Restriction{i, end})\n+\t\ti = end\n+\t}\n+\t// Output the last range\n+\tsplits = append(splits, offsetrange.Restriction{i, rest.End})\n+\treturn splits\n+}\n+{{< /highlight >}}\n+\n+### 12.2 Sizing and progress {#sizing-and-progress}\n+\n+Sizing and progress are used during execution of a splittable DoFn to inform runners so that they may\n+perform intelligent decisions about which restrictions to split and how to parallelize work.\n+\n+Before processing an element and restriction, an initial size may be used by a runner to choose\n+how and who processes the restrictions attempting to improve initial balancing and parallelization\n+of work. During the processing of an element and restriction, sizing and progress are used to choose\n+which restrictions to split and who should process them.\n+\n+By default, we use the restriction tracker\u2019s estimate for work remaining falling back to assuming\n+that all restrictions have an equal cost. To override the default, SDF authors can provide the\n+appropriate method within the restriction provider.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) RestrictionSize(filename string, rest offsetrange.Restriction) float64 {\n+\tweight := float64(1)\n+\tif strings.Contains(filename, \u201cexpensiveRecords\u201d) {\n+\t\tweight = 2\n+\t}\n+\treturn weight * rest.Size()\n+}\n+{{< /highlight >}}\n+\n+### 12.3 User initiated checkpoint {#user-initiated-checkpoint}\n+\n+Some I/Os cannot produce all of the data necessary to complete a restriction within the lifetime of a\n+single bundle. This typically happens with unbounded restrictions, but can also happen with bounded\n+restrictions. For example, there could be more data that needs to be ingested but is not available yet.\n+Another cause of this scenario is the source system throttling your data.\n+\n+Your splittable DoFn can signal to you that you are not done processing the current restriction. This\n+signal can suggest a time to resume at. While the runner tries to honor the resume time, this is not\n+guaranteed. This allows execution to continue on a restriction that has available work improving\n+resource utilization.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_UserInitiatedCheckpoint >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_UserInitiatedCheckpoint >}}\n+{{< /highlight >}}\n+\n+### 12.4 Runner-initiated split {#runner-initiated-split}\n+\n+A runner at any time may attempt to split a restriction while it is being processed. This allows the\n+runner to either pause processing of the restriction so that other work may be done (common for\n+unbounded restrictions to limit the amount of output and/or improve latency) or split the restriction\n+into two pieces, increasing the available parallelism within the system. It is important to author a\n+splittable DoFn with this in mind since the end of the restriction may change. Thus when writing the\n+processing loop, it is important to use the result from trying to claim a piece of the restriction\n+instead of assuming one can process till the end.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BadTryClaimLoop >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BadTryClaimLoop >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *badTryClaimLoop) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// The restriction tracker can be modified by another thread in parallel\n+\t// so storing state locally is ill advised.\n+\tend = rt.GetRestriction().(offsetrange.Restriction).End\n+\tfor offset < end {\n+\t\t// Only after successfully claiming should we produce any output and/or\n+\t\t// perform side effects.\n+    \trt.TryClaim(offset)\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+### 12.5 Watermark estimation {#watermark-estimation}\n+\n+The default watermark estimator does not produce a watermark estimate. Therefore, the output watermark\n+is solely computed by the minimum of upstream watermarks.\n+\n+As a splittable DoFn pr an element and restriction pair, it can advance the output watermark by specifying", "originalCommit": "626366b189b7dee572bd92fdefc7b11b6f7b2d51", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMxODA3Mg==", "url": "https://github.com/apache/beam/pull/13160#discussion_r510318072", "bodyText": "The class DoFn should be in code font when it's within the text. I see that this is inconsistently applied in the programming guide, but let's make the changes in at least this section. https://developers.google.com/style/code-in-text", "author": "rosetn", "createdAt": "2020-10-22T16:59:00Z", "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a", "originalCommit": "626366b189b7dee572bd92fdefc7b11b6f7b2d51", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM0NTM4OQ==", "url": "https://github.com/apache/beam/pull/13160#discussion_r510345389", "bodyText": "You can leave \"SDF\" in normal font", "author": "rosetn", "createdAt": "2020-10-22T17:44:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMxODA3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMyMTYyMw==", "url": "https://github.com/apache/beam/pull/13160#discussion_r510321623", "bodyText": "Missing period\n12. Splittable DoFns {#splittable-dofns}", "author": "rosetn", "createdAt": "2020-10-22T17:04:50Z", "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}", "originalCommit": "626366b189b7dee572bd92fdefc7b11b6f7b2d51", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM0NjQxOA==", "url": "https://github.com/apache/beam/pull/13160#discussion_r510346418", "bodyText": "Also add them for each header. This stopped in the last two sections, but we can keep it consistent with the rest of the programming guide here.", "author": "rosetn", "createdAt": "2020-10-22T17:45:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMyMTYyMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMyMzcyNg==", "url": "https://github.com/apache/beam/pull/13160#discussion_r510323726", "bodyText": "Add comma\nTraditionally, users", "author": "rosetn", "createdAt": "2020-10-22T17:08:17Z", "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the", "originalCommit": "626366b189b7dee572bd92fdefc7b11b6f7b2d51", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM0NDk3MA==", "url": "https://github.com/apache/beam/pull/13160#discussion_r510344970", "bodyText": "Can you add more explanation to the \"Checkpoint/split\" bubble in the diagram on this list?", "author": "rosetn", "createdAt": "2020-10-22T17:43:24Z", "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).", "originalCommit": "626366b189b7dee572bd92fdefc7b11b6f7b2d51", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM5Nzg4Mg==", "url": "https://github.com/apache/beam/pull/13160#discussion_r510397882", "bodyText": "Below the diagram I have the explanation for the checkpoint/split. I moved it to be part of the list.", "author": "lukecwik", "createdAt": "2020-10-22T19:15:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM0NDk3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM0NTg5Mg==", "url": "https://github.com/apache/beam/pull/13160#discussion_r510345892", "bodyText": "User-initiated", "author": "rosetn", "createdAt": "2020-10-22T17:44:51Z", "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a\n+restriction tracker. The restriction is used to represent a subset of work for a given element.\n+The restriction provider lets SDF authors override default implementations for splitting, sizing,\n+watermark estimation, and so forth. In [Java](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L92)\n+and [Go](https://github.com/apache/beam/blob/0f466e6bcd4ac8677c2bd9ecc8e6af3836b7f3b8/sdks/go/pkg/beam/pardo.go#L226),\n+this is the DoFn. [Python](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/python/apache_beam/transforms/core.py#L213)\n+has a dedicated RestrictionProvider type. The restriction tracker is responsible for tracking\n+what subset of the restriction has been completed during processing.\n+\n+To define a splittable DoFn, you must choose whether the splittable DoFn is bounded (default) or\n+unbounded and define a way to initialize an initial restriction for an element.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) CreateInitialRestriction(filename string) offsetrange.Restriction {\n+\treturn offsetrange.Restriction{\n+\t\tStart: 0,\n+\t\tEnd:   getFileLength(filename),\n+\t}\n+}\n+\n+func (fn *splittableDoFn) CreateTracker(rest offsetrange.Restriction) *sdf.LockRTracker {\n+\treturn sdf.NewLockRTracker(offsetrange.NewTracker(rest))\n+}\n+\n+func (fn *splittableDoFn) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfor rt.TryClaim(offset) {\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+At this point, we have a splittable DoFn that supports [runner-initiated splits](#runner-initiated-split)\n+enabling dynamic work rebalancing. To increase the rate at which initial parallelization of work occurs\n+or for those runners that do not support runner-initiated splitting, we recommend providing\n+a set of initial splits:\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) SplitRestriction(filename string, rest offsetrange.Restriction) (splits []offsetrange.Restriction) {\n+\tsize := 64 * (1 << 20)\n+\ti := rest.Start\n+\tfor i < rest.End - size {\n+\t\t// Compute and output 64 MiB size ranges to process in parallel\n+\t\tend := i + size\n+     \t\tsplits = append(splits, offsetrange.Restriction{i, end})\n+\t\ti = end\n+\t}\n+\t// Output the last range\n+\tsplits = append(splits, offsetrange.Restriction{i, rest.End})\n+\treturn splits\n+}\n+{{< /highlight >}}\n+\n+### 12.2 Sizing and progress {#sizing-and-progress}\n+\n+Sizing and progress are used during execution of a splittable DoFn to inform runners so that they may\n+perform intelligent decisions about which restrictions to split and how to parallelize work.\n+\n+Before processing an element and restriction, an initial size may be used by a runner to choose\n+how and who processes the restrictions attempting to improve initial balancing and parallelization\n+of work. During the processing of an element and restriction, sizing and progress are used to choose\n+which restrictions to split and who should process them.\n+\n+By default, we use the restriction tracker\u2019s estimate for work remaining falling back to assuming\n+that all restrictions have an equal cost. To override the default, SDF authors can provide the\n+appropriate method within the restriction provider.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) RestrictionSize(filename string, rest offsetrange.Restriction) float64 {\n+\tweight := float64(1)\n+\tif strings.Contains(filename, \u201cexpensiveRecords\u201d) {\n+\t\tweight = 2\n+\t}\n+\treturn weight * rest.Size()\n+}\n+{{< /highlight >}}\n+\n+### 12.3 User initiated checkpoint {#user-initiated-checkpoint}", "originalCommit": "626366b189b7dee572bd92fdefc7b11b6f7b2d51", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM3MzE3NA==", "url": "https://github.com/apache/beam/pull/13160#discussion_r510373174", "bodyText": "Consider pointing out that with only the above example code, the restrictions don't currently do anything extra WRT the same DoFn without the restriction handling. It's a non-splittable-dofn with vestigial extras.  (there's probably a much better way to phrase this).", "author": "lostluck", "createdAt": "2020-10-22T18:31:35Z", "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a\n+restriction tracker. The restriction is used to represent a subset of work for a given element.\n+The restriction provider lets SDF authors override default implementations for splitting, sizing,\n+watermark estimation, and so forth. In [Java](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L92)\n+and [Go](https://github.com/apache/beam/blob/0f466e6bcd4ac8677c2bd9ecc8e6af3836b7f3b8/sdks/go/pkg/beam/pardo.go#L226),\n+this is the DoFn. [Python](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/python/apache_beam/transforms/core.py#L213)\n+has a dedicated RestrictionProvider type. The restriction tracker is responsible for tracking\n+what subset of the restriction has been completed during processing.\n+\n+To define a splittable DoFn, you must choose whether the splittable DoFn is bounded (default) or\n+unbounded and define a way to initialize an initial restriction for an element.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) CreateInitialRestriction(filename string) offsetrange.Restriction {\n+\treturn offsetrange.Restriction{\n+\t\tStart: 0,\n+\t\tEnd:   getFileLength(filename),\n+\t}\n+}\n+\n+func (fn *splittableDoFn) CreateTracker(rest offsetrange.Restriction) *sdf.LockRTracker {\n+\treturn sdf.NewLockRTracker(offsetrange.NewTracker(rest))\n+}\n+\n+func (fn *splittableDoFn) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfor rt.TryClaim(offset) {\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+At this point, we have a splittable DoFn that supports [runner-initiated splits](#runner-initiated-split)", "originalCommit": "626366b189b7dee572bd92fdefc7b11b6f7b2d51", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM5OTAzMA==", "url": "https://github.com/apache/beam/pull/13160#discussion_r510399030", "bodyText": "I think we should deal with this in the follow-up about trySplit being implemented correctly within a restriction tracker and adding that to the runner initiated splits section then lumping it in now.", "author": "lukecwik", "createdAt": "2020-10-22T19:17:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM3MzE3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDUyMDk2Ng==", "url": "https://github.com/apache/beam/pull/13160#discussion_r510520966", "bodyText": "Ack SGTM.", "author": "lostluck", "createdAt": "2020-10-22T23:55:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM3MzE3NA=="}], "type": "inlineReview"}, {"oid": "bf59970c4297e1721bc4eb5d93e09c5e2569b87c", "url": "https://github.com/apache/beam/commit/bf59970c4297e1721bc4eb5d93e09c5e2569b87c", "message": "Address PR comments", "committedDate": "2020-10-22T19:20:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ4NzkwMA==", "url": "https://github.com/apache/beam/pull/13160#discussion_r510487900", "bodyText": "Let's make these \"an SDF\"", "author": "rosetn", "createdAt": "2020-10-22T22:13:10Z", "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,281 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12. Splittable `DoFns` {#splittable-dofns}\n+\n+A Splittable `DoFn` (SDF) enables users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally, users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular `DoFn` that read the file (decreased performance). With SDF,\n+we bring the richness of Apache Beam\u2019s I/O APIs to a `DoFn` enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1. SDF basics {#sdf-basics}\n+\n+At a high level, a SDF is responsible for processing element and restriction pairs. A", "originalCommit": "bf59970c4297e1721bc4eb5d93e09c5e2569b87c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "ac8f773b096565ccf4eb95fb94e6e9b5ce947d14", "url": "https://github.com/apache/beam/commit/ac8f773b096565ccf4eb95fb94e6e9b5ce947d14", "message": "Replace 'a SDF' with 'an SDF'", "committedDate": "2020-10-22T22:16:56Z", "type": "commit"}]}