{"pr_number": 12471, "pr_title": "[BEAM-9615] Add initial Schema to Go conversions.", "pr_createdAt": "2020-08-05T16:51:53Z", "pr_url": "https://github.com/apache/beam/pull/12471", "timeline": [{"oid": "06a19b4ec9373bae117d3f6d539fd9779dac979e", "url": "https://github.com/apache/beam/commit/06a19b4ec9373bae117d3f6d539fd9779dac979e", "message": "[BEAM-9615] Add initial Schema to Go conversions.", "committedDate": "2020-08-05T16:41:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEyMDEzOA==", "url": "https://github.com/apache/beam/pull/12471#discussion_r466120138", "bodyText": "It's a small thing, but I'm not a huge fan of having a case explicitly excluding types from schema fields. How about instead just having reflectTypeToAtomicType return an error instead of panicking, then combining this case with the default by calling reflectTypeToAtomicType and panicking if it errors, with this error message.", "author": "youngoli", "createdAt": "2020-08-06T03:14:19Z", "path": "sdks/go/pkg/beam/core/runtime/graphx/schema/schema.go", "diffHunk": "@@ -0,0 +1,245 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+// Package schema contains utility functions for relating Go types and Beam Schemas.\n+//\n+// Not all Go types can be converted to schemas. This is Go is more expressive than\n+// Beam schemas. Just as not all Go types can be serialized, similarly,\n+// not all Beam Schemas will have a conversion to Go types, until the correct\n+// mechanism exists in the SDK to handle them.\n+//\n+// While efforts will be made to have conversions be reversable, this will not\n+// be possible in all instances. Eg. Go arrays as fields will be converted to\n+// Beam Arrays, but a Beam Array type will map by default to a Go slice.\n+package schema\n+\n+import (\n+\t\"fmt\"\n+\t\"reflect\"\n+\t\"strings\"\n+\n+\t\"github.com/apache/beam/sdks/go/pkg/beam/core/util/reflectx\"\n+\t\"github.com/apache/beam/sdks/go/pkg/beam/internal/errors\"\n+\tpipepb \"github.com/apache/beam/sdks/go/pkg/beam/model/pipeline_v1\"\n+)\n+\n+// FromType returns a Beam Schema of the passed in type.\n+// Returns an error if the type cannot be converted to a Schema.\n+func FromType(ot reflect.Type) (*pipepb.Schema, error) {\n+\tt := ot // keep the original type for errors.\n+\t// The top level schema for a pointer to struct and the struct is the same.\n+\tif t.Kind() == reflect.Ptr {\n+\t\tt = t.Elem()\n+\t}\n+\tif t.Kind() != reflect.Struct {\n+\t\treturn nil, errors.Errorf(\"cannot convert %v to schema. FromType only converts structs to schemas\", ot)\n+\t}\n+\treturn structToSchema(t), nil\n+}\n+\n+func structToSchema(t reflect.Type) *pipepb.Schema {\n+\tfields := make([]*pipepb.Field, 0, t.NumField())\n+\tfor i := 0; i < t.NumField(); i++ {\n+\t\tfields = append(fields, structFieldToField(t.Field(i)))\n+\t}\n+\treturn &pipepb.Schema{\n+\t\tFields: fields,\n+\t}\n+}\n+\n+func structFieldToField(sf reflect.StructField) *pipepb.Field {\n+\tname := sf.Name\n+\tif tag := sf.Tag.Get(\"beam\"); tag != \"\" {\n+\t\tname, _ = parseTag(tag)\n+\t}\n+\tftype := reflectTypeToFieldType(sf.Type)\n+\n+\treturn &pipepb.Field{\n+\t\tName: name,\n+\t\tType: ftype,\n+\t}\n+}\n+\n+func reflectTypeToFieldType(ot reflect.Type) *pipepb.FieldType {\n+\tvar isPtr bool\n+\tt := ot\n+\tif t.Kind() == reflect.Ptr {\n+\t\tisPtr = true\n+\t\tt = t.Elem()\n+\t}\n+\tswitch t.Kind() {\n+\tcase reflect.Map:\n+\t\tkt := reflectTypeToFieldType(t.Key())\n+\t\tvt := reflectTypeToFieldType(t.Elem())\n+\t\treturn &pipepb.FieldType{\n+\t\t\tNullable: isPtr,\n+\t\t\tTypeInfo: &pipepb.FieldType_MapType{\n+\t\t\t\tMapType: &pipepb.MapType{\n+\t\t\t\t\tKeyType:   kt,\n+\t\t\t\t\tValueType: vt,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t}\n+\tcase reflect.Struct:\n+\t\tsch := structToSchema(t)\n+\t\treturn &pipepb.FieldType{\n+\t\t\tNullable: isPtr,\n+\t\t\tTypeInfo: &pipepb.FieldType_RowType{\n+\t\t\t\tRowType: &pipepb.RowType{\n+\t\t\t\t\tSchema: sch,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t}\n+\tcase reflect.Slice, reflect.Array:\n+\t\t// Special handling for []byte\n+\t\tif t == reflectx.ByteSlice {\n+\t\t\treturn &pipepb.FieldType{\n+\t\t\t\tNullable: isPtr,\n+\t\t\t\tTypeInfo: &pipepb.FieldType_AtomicType{\n+\t\t\t\t\tAtomicType: pipepb.AtomicType_BYTES,\n+\t\t\t\t},\n+\t\t\t}\n+\t\t}\n+\t\tvt := reflectTypeToFieldType(t.Elem())\n+\t\treturn &pipepb.FieldType{\n+\t\t\tNullable: isPtr,\n+\t\t\tTypeInfo: &pipepb.FieldType_ArrayType{\n+\t\t\t\tArrayType: &pipepb.ArrayType{\n+\t\t\t\t\tElementType: vt,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t}\n+\tcase reflect.Interface, reflect.Chan, reflect.UnsafePointer, reflect.Complex128, reflect.Complex64, reflect.Int:\n+\t\tpanic(fmt.Sprintf(\"Unsupported type to convert to schema: %v\", ot))", "originalCommit": "06a19b4ec9373bae117d3f6d539fd9779dac979e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjU3MjM0Nw==", "url": "https://github.com/apache/beam/pull/12471#discussion_r466572347", "bodyText": "Good catch. I was definitely doing this out of iteration laziness. Handling error propagation now.", "author": "lostluck", "createdAt": "2020-08-06T17:28:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEyMDEzOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEyMTk1Nw==", "url": "https://github.com/apache/beam/pull/12471#discussion_r466121957", "bodyText": "Using a map for decoding atomic types and a switch statement for encoding them seems inconsistent. Is there a reason for it? If not I'd say to go with one approach in both cases.", "author": "youngoli", "createdAt": "2020-08-06T03:21:22Z", "path": "sdks/go/pkg/beam/core/runtime/graphx/schema/schema.go", "diffHunk": "@@ -0,0 +1,245 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+// Package schema contains utility functions for relating Go types and Beam Schemas.\n+//\n+// Not all Go types can be converted to schemas. This is Go is more expressive than\n+// Beam schemas. Just as not all Go types can be serialized, similarly,\n+// not all Beam Schemas will have a conversion to Go types, until the correct\n+// mechanism exists in the SDK to handle them.\n+//\n+// While efforts will be made to have conversions be reversable, this will not\n+// be possible in all instances. Eg. Go arrays as fields will be converted to\n+// Beam Arrays, but a Beam Array type will map by default to a Go slice.\n+package schema\n+\n+import (\n+\t\"fmt\"\n+\t\"reflect\"\n+\t\"strings\"\n+\n+\t\"github.com/apache/beam/sdks/go/pkg/beam/core/util/reflectx\"\n+\t\"github.com/apache/beam/sdks/go/pkg/beam/internal/errors\"\n+\tpipepb \"github.com/apache/beam/sdks/go/pkg/beam/model/pipeline_v1\"\n+)\n+\n+// FromType returns a Beam Schema of the passed in type.\n+// Returns an error if the type cannot be converted to a Schema.\n+func FromType(ot reflect.Type) (*pipepb.Schema, error) {\n+\tt := ot // keep the original type for errors.\n+\t// The top level schema for a pointer to struct and the struct is the same.\n+\tif t.Kind() == reflect.Ptr {\n+\t\tt = t.Elem()\n+\t}\n+\tif t.Kind() != reflect.Struct {\n+\t\treturn nil, errors.Errorf(\"cannot convert %v to schema. FromType only converts structs to schemas\", ot)\n+\t}\n+\treturn structToSchema(t), nil\n+}\n+\n+func structToSchema(t reflect.Type) *pipepb.Schema {\n+\tfields := make([]*pipepb.Field, 0, t.NumField())\n+\tfor i := 0; i < t.NumField(); i++ {\n+\t\tfields = append(fields, structFieldToField(t.Field(i)))\n+\t}\n+\treturn &pipepb.Schema{\n+\t\tFields: fields,\n+\t}\n+}\n+\n+func structFieldToField(sf reflect.StructField) *pipepb.Field {\n+\tname := sf.Name\n+\tif tag := sf.Tag.Get(\"beam\"); tag != \"\" {\n+\t\tname, _ = parseTag(tag)\n+\t}\n+\tftype := reflectTypeToFieldType(sf.Type)\n+\n+\treturn &pipepb.Field{\n+\t\tName: name,\n+\t\tType: ftype,\n+\t}\n+}\n+\n+func reflectTypeToFieldType(ot reflect.Type) *pipepb.FieldType {\n+\tvar isPtr bool\n+\tt := ot\n+\tif t.Kind() == reflect.Ptr {\n+\t\tisPtr = true\n+\t\tt = t.Elem()\n+\t}\n+\tswitch t.Kind() {\n+\tcase reflect.Map:\n+\t\tkt := reflectTypeToFieldType(t.Key())\n+\t\tvt := reflectTypeToFieldType(t.Elem())\n+\t\treturn &pipepb.FieldType{\n+\t\t\tNullable: isPtr,\n+\t\t\tTypeInfo: &pipepb.FieldType_MapType{\n+\t\t\t\tMapType: &pipepb.MapType{\n+\t\t\t\t\tKeyType:   kt,\n+\t\t\t\t\tValueType: vt,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t}\n+\tcase reflect.Struct:\n+\t\tsch := structToSchema(t)\n+\t\treturn &pipepb.FieldType{\n+\t\t\tNullable: isPtr,\n+\t\t\tTypeInfo: &pipepb.FieldType_RowType{\n+\t\t\t\tRowType: &pipepb.RowType{\n+\t\t\t\t\tSchema: sch,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t}\n+\tcase reflect.Slice, reflect.Array:\n+\t\t// Special handling for []byte\n+\t\tif t == reflectx.ByteSlice {\n+\t\t\treturn &pipepb.FieldType{\n+\t\t\t\tNullable: isPtr,\n+\t\t\t\tTypeInfo: &pipepb.FieldType_AtomicType{\n+\t\t\t\t\tAtomicType: pipepb.AtomicType_BYTES,\n+\t\t\t\t},\n+\t\t\t}\n+\t\t}\n+\t\tvt := reflectTypeToFieldType(t.Elem())\n+\t\treturn &pipepb.FieldType{\n+\t\t\tNullable: isPtr,\n+\t\t\tTypeInfo: &pipepb.FieldType_ArrayType{\n+\t\t\t\tArrayType: &pipepb.ArrayType{\n+\t\t\t\t\tElementType: vt,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t}\n+\tcase reflect.Interface, reflect.Chan, reflect.UnsafePointer, reflect.Complex128, reflect.Complex64, reflect.Int:\n+\t\tpanic(fmt.Sprintf(\"Unsupported type to convert to schema: %v\", ot))\n+\tdefault: // must be an atomic type\n+\t\tenum := reflectTypeToAtomicType(t)\n+\t\treturn &pipepb.FieldType{\n+\t\t\tNullable: isPtr,\n+\t\t\tTypeInfo: &pipepb.FieldType_AtomicType{\n+\t\t\t\tAtomicType: enum,\n+\t\t\t},\n+\t\t}\n+\t}\n+}\n+\n+func reflectTypeToAtomicType(rt reflect.Type) pipepb.AtomicType {\n+\tswitch rt {\n+\tcase reflectx.Uint8:\n+\t\treturn pipepb.AtomicType_BYTE\n+\tcase reflectx.Int16:\n+\t\treturn pipepb.AtomicType_INT16\n+\tcase reflectx.Int32:\n+\t\treturn pipepb.AtomicType_INT32\n+\tcase reflectx.Int64, reflectx.Int:\n+\t\treturn pipepb.AtomicType_INT64\n+\tcase reflectx.Float32:\n+\t\treturn pipepb.AtomicType_FLOAT\n+\tcase reflectx.Float64:\n+\t\treturn pipepb.AtomicType_DOUBLE\n+\tcase reflectx.String:\n+\t\treturn pipepb.AtomicType_STRING\n+\tcase reflectx.Bool:\n+\t\treturn pipepb.AtomicType_BOOLEAN\n+\tcase reflectx.ByteSlice:\n+\t\treturn pipepb.AtomicType_BYTES\n+\tdefault:\n+\t\tpanic(fmt.Sprintf(\"non atomic reflect type: %v\", rt))\n+\t}\n+}\n+\n+// ToType returns a Go type of the passed in Schema.\n+// Types returned by ToType are always of Struct kind.\n+// Returns an error if the Schema cannot be converted to a type.\n+func ToType(s *pipepb.Schema) (reflect.Type, error) {\n+\tfields := make([]reflect.StructField, 0, len(s.GetFields()))\n+\tfor _, sf := range s.GetFields() {\n+\t\trf := fieldToStructField(sf)\n+\t\tfields = append(fields, rf)\n+\t}\n+\treturn reflect.StructOf(fields), nil\n+}\n+\n+func fieldToStructField(sf *pipepb.Field) reflect.StructField {\n+\tname := sf.GetName()\n+\treturn reflect.StructField{\n+\t\tName: strings.ToUpper(name[:1]) + name[1:], // Go field name must be capitalized for export and encoding.\n+\t\tType: fieldTypeToReflectType(sf.GetType()),\n+\t\tTag:  reflect.StructTag(fmt.Sprintf(\"beam:\\\"%s\\\"\", name)),\n+\t}\n+}\n+\n+var atomicTypeToReflectType = map[pipepb.AtomicType]reflect.Type{", "originalCommit": "06a19b4ec9373bae117d3f6d539fd9779dac979e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjU3MjIzMA==", "url": "https://github.com/apache/beam/pull/12471#discussion_r466572230", "bodyText": "Honestly, when I first wrote it, it complained that reflect.Type couldn't be used as a key, but I do that all the time so... very strange.", "author": "lostluck", "createdAt": "2020-08-06T17:28:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEyMTk1Nw=="}], "type": "inlineReview"}, {"oid": "242f1f02a947b5ce8344ae19c23eede979342cff", "url": "https://github.com/apache/beam/commit/242f1f02a947b5ce8344ae19c23eede979342cff", "message": "[BEAM-9615] Improve error handling on schema conv", "committedDate": "2020-08-06T18:57:18Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc1Mzc4Ng==", "url": "https://github.com/apache/beam/pull/12471#discussion_r466753786", "bodyText": "Reviewed the change, and the full error propogation is even better than my original suggestion, so two thumbs up for that.\nBut I think you missed my suggestion to merge these unsupported type and default cases. I.E. combine them into one default case that tries using reflectTypeToAtomicTypeMap, and if that fails, then it's an unsupported type.\nHaving a specific case for unsupported types seems brittle and doesn't serve much of a purpose other than having a slightly different error message than the one under default. If one of these types gets added, this is just one more spot that needs to be changed and will break if you forget.\nObviouslt it's not so important it needs an immediate fix, but I'd say it's worth bundling into whatever schema PR is coming next.", "author": "youngoli", "createdAt": "2020-08-07T00:22:24Z", "path": "sdks/go/pkg/beam/core/runtime/graphx/schema/schema.go", "diffHunk": "@@ -0,0 +1,269 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+// Package schema contains utility functions for relating Go types and Beam Schemas.\n+//\n+// Not all Go types can be converted to schemas. This is Go is more expressive than\n+// Beam schemas. Just as not all Go types can be serialized, similarly,\n+// not all Beam Schemas will have a conversion to Go types, until the correct\n+// mechanism exists in the SDK to handle them.\n+//\n+// While efforts will be made to have conversions be reversable, this will not\n+// be possible in all instances. Eg. Go arrays as fields will be converted to\n+// Beam Arrays, but a Beam Array type will map by default to a Go slice.\n+package schema\n+\n+import (\n+\t\"fmt\"\n+\t\"reflect\"\n+\t\"strings\"\n+\n+\t\"github.com/apache/beam/sdks/go/pkg/beam/core/util/reflectx\"\n+\t\"github.com/apache/beam/sdks/go/pkg/beam/internal/errors\"\n+\tpipepb \"github.com/apache/beam/sdks/go/pkg/beam/model/pipeline_v1\"\n+)\n+\n+// FromType returns a Beam Schema of the passed in type.\n+// Returns an error if the type cannot be converted to a Schema.\n+func FromType(ot reflect.Type) (*pipepb.Schema, error) {\n+\tt := ot // keep the original type for errors.\n+\t// The top level schema for a pointer to struct and the struct is the same.\n+\tif t.Kind() == reflect.Ptr {\n+\t\tt = t.Elem()\n+\t}\n+\tif t.Kind() != reflect.Struct {\n+\t\treturn nil, errors.Errorf(\"cannot convert %v to schema. FromType only converts structs to schemas\", ot)\n+\t}\n+\treturn structToSchema(t)\n+}\n+\n+func structToSchema(t reflect.Type) (*pipepb.Schema, error) {\n+\tfields := make([]*pipepb.Field, 0, t.NumField())\n+\tfor i := 0; i < t.NumField(); i++ {\n+\t\tf, err := structFieldToField(t.Field(i))\n+\t\tif err != nil {\n+\t\t\treturn nil, errors.Wrapf(err, \"cannot convert field %v to schema\", t.Field(i).Name)\n+\t\t}\n+\t\tfields = append(fields, f)\n+\t}\n+\treturn &pipepb.Schema{\n+\t\tFields: fields,\n+\t}, nil\n+}\n+\n+func structFieldToField(sf reflect.StructField) (*pipepb.Field, error) {\n+\tname := sf.Name\n+\tif tag := sf.Tag.Get(\"beam\"); tag != \"\" {\n+\t\tname, _ = parseTag(tag)\n+\t}\n+\tftype, err := reflectTypeToFieldType(sf.Type)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\treturn &pipepb.Field{\n+\t\tName: name,\n+\t\tType: ftype,\n+\t}, nil\n+}\n+\n+func reflectTypeToFieldType(ot reflect.Type) (*pipepb.FieldType, error) {\n+\tvar isPtr bool\n+\tt := ot\n+\tif t.Kind() == reflect.Ptr {\n+\t\tisPtr = true\n+\t\tt = t.Elem()\n+\t}\n+\tswitch t.Kind() {\n+\tcase reflect.Map:\n+\t\tkt, err := reflectTypeToFieldType(t.Key())\n+\t\tif err != nil {\n+\t\t\treturn nil, errors.Wrapf(err, \"unable to convert key of %v to schema field\", ot)\n+\t\t}\n+\t\tvt, err := reflectTypeToFieldType(t.Elem())\n+\t\tif err != nil {\n+\t\t\treturn nil, errors.Wrapf(err, \"unable to convert value of %v to schema field\", ot)\n+\t\t}\n+\t\treturn &pipepb.FieldType{\n+\t\t\tNullable: isPtr,\n+\t\t\tTypeInfo: &pipepb.FieldType_MapType{\n+\t\t\t\tMapType: &pipepb.MapType{\n+\t\t\t\t\tKeyType:   kt,\n+\t\t\t\t\tValueType: vt,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t}, nil\n+\tcase reflect.Struct:\n+\t\tsch, err := structToSchema(t)\n+\t\tif err != nil {\n+\t\t\treturn nil, errors.Wrapf(err, \"unable to convert %v to schema field\", ot)\n+\t\t}\n+\t\treturn &pipepb.FieldType{\n+\t\t\tNullable: isPtr,\n+\t\t\tTypeInfo: &pipepb.FieldType_RowType{\n+\t\t\t\tRowType: &pipepb.RowType{\n+\t\t\t\t\tSchema: sch,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t}, nil\n+\tcase reflect.Slice, reflect.Array:\n+\t\t// Special handling for []byte\n+\t\tif t == reflectx.ByteSlice {\n+\t\t\treturn &pipepb.FieldType{\n+\t\t\t\tNullable: isPtr,\n+\t\t\t\tTypeInfo: &pipepb.FieldType_AtomicType{\n+\t\t\t\t\tAtomicType: pipepb.AtomicType_BYTES,\n+\t\t\t\t},\n+\t\t\t}, nil\n+\t\t}\n+\t\tvt, err := reflectTypeToFieldType(t.Elem())\n+\t\tif err != nil {\n+\t\t\treturn nil, errors.Wrapf(err, \"unable to convert element type of %v to schema field\", ot)\n+\t\t}\n+\t\treturn &pipepb.FieldType{\n+\t\t\tNullable: isPtr,\n+\t\t\tTypeInfo: &pipepb.FieldType_ArrayType{\n+\t\t\t\tArrayType: &pipepb.ArrayType{\n+\t\t\t\t\tElementType: vt,\n+\t\t\t\t},\n+\t\t\t},\n+\t\t}, nil\n+\tcase reflect.Interface, reflect.Chan, reflect.UnsafePointer, reflect.Complex128, reflect.Complex64:\n+\t\treturn nil, errors.Errorf(\"unable to convert unsupported type %v to schema\", ot)\n+\tdefault: // must be an atomic type", "originalCommit": "242f1f02a947b5ce8344ae19c23eede979342cff", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}