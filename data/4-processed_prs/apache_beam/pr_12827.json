{"pr_number": 12827, "pr_title": "[BEAM-10885] Add Avro support to Kafka table provider", "pr_createdAt": "2020-09-11T15:56:26Z", "pr_url": "https://github.com/apache/beam/pull/12827", "timeline": [{"oid": "13dc5e0f928c89010c4951be61830012472dec35", "url": "https://github.com/apache/beam/commit/13dc5e0f928c89010c4951be61830012472dec35", "message": "[BEAM-10885] Add Avro support to Kafka table provider", "committedDate": "2020-09-14T11:02:54Z", "type": "forcePushed"}, {"oid": "ad9d5ef4011b2c78d8d94ae4ebbd711d329a37e7", "url": "https://github.com/apache/beam/commit/ad9d5ef4011b2c78d8d94ae4ebbd711d329a37e7", "message": "[BEAM-10885] Add Avro support to Kafka table provider", "committedDate": "2020-09-14T11:11:03Z", "type": "forcePushed"}, {"oid": "43b206ebca95e67d710a8d807aa1ccb298603cb6", "url": "https://github.com/apache/beam/commit/43b206ebca95e67d710a8d807aa1ccb298603cb6", "message": "[BEAM-10885] Add Avro support to Kafka table provider", "committedDate": "2020-09-14T11:35:51Z", "type": "forcePushed"}, {"oid": "391c7d925e981d3483fa7bd41ce7b69f1c8102f7", "url": "https://github.com/apache/beam/commit/391c7d925e981d3483fa7bd41ce7b69f1c8102f7", "message": "[BEAM-10885] Add Avro support to Kafka table provider", "committedDate": "2020-09-14T11:45:15Z", "type": "forcePushed"}, {"oid": "b18894b8c444b7e037ca9c5fbc581aa515198168", "url": "https://github.com/apache/beam/commit/b18894b8c444b7e037ca9c5fbc581aa515198168", "message": "[BEAM-10885] Add Avro support to Kafka table provider", "committedDate": "2020-09-14T13:28:33Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODg2MjgxNg==", "url": "https://github.com/apache/beam/pull/12827#discussion_r488862816", "bodyText": "Nit: Can we change this to createKafkaTestRecord(String key, List values, int timestamp)?", "author": "ibzib", "createdAt": "2020-09-15T18:02:27Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -41,27 +40,49 @@\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataTypeSystem;\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.type.SqlTypeName;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n-import org.apache.commons.csv.CSVFormat;\n import org.junit.Assert;\n import org.junit.Rule;\n import org.junit.Test;\n \n /** Test for BeamKafkaCSVTable. */\n-public class BeamKafkaCSVTableTest {\n+public abstract class BeamKafkaTableTest {\n   @Rule public TestPipeline pipeline = TestPipeline.create();\n \n-  private static final Row ROW1 = Row.withSchema(genSchema()).addValues(1L, 1, 1.0).build();\n+  protected static final Schema BEAM_SQL_SCHEMA =\n+      TestTableUtils.buildBeamSqlSchema(\n+          Schema.FieldType.INT32,\n+          \"order_id\",\n+          Schema.FieldType.INT32,\n+          \"site_id\",\n+          Schema.FieldType.INT32,\n+          \"price\");\n \n-  private static final Row ROW2 = Row.withSchema(genSchema()).addValues(2L, 2, 2.0).build();\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  protected static final Schema SCHEMA = genSchema();\n+\n+  protected static final Row ROW1 = Row.withSchema(SCHEMA).addValues(1L, 1, 1.0).build();\n+\n+  protected static final Row ROW2 = Row.withSchema(SCHEMA).addValues(2L, 2, 2.0).build();\n+\n+  private static final Map<String, BeamSqlTable> tables = new HashMap<>();\n \n-  private static Map<String, BeamSqlTable> tables = new HashMap<>();\n   protected static BeamSqlEnv env = BeamSqlEnv.readOnly(\"test\", tables);\n \n+  protected abstract KafkaTestRecord<?> createKafkaTestRecord(", "originalCommit": "b18894b8c444b7e037ca9c5fbc581aa515198168", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIxMTgwOQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r489211809", "bodyText": "I really don't know what made me use those booleans, they are totally redundant.\nSure, List will match better here than doing some implicit magic inside.", "author": "piotr-szuberski", "createdAt": "2020-09-16T07:09:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODg2MjgxNg=="}], "type": "inlineReview"}, {"oid": "30d032fa019e19d7dc2f57529f423267ede27929", "url": "https://github.com/apache/beam/commit/30d032fa019e19d7dc2f57529f423267ede27929", "message": "Remove booleans, use List of values", "committedDate": "2020-09-17T09:19:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg1ODY0MA==", "url": "https://github.com/apache/beam/pull/12827#discussion_r493858640", "bodyText": "Could you instead have a method protected abstract BeamKafkaTable getTable() that gets overridden by each implementation?\nThen I think createRecorderDecoder and createRecorderEncoder can have concrete private implementations that are reused, like:\n  @Override\n  protected PCollection<Row> createRecorderEncoder(TestPipeline pipeline) {\n    BeamKafkaTable table = getTable();\n    return pipeline\n        .apply(Create.of(ROW1, ROW2))\n        .apply(table.getPTransformForInput())\n        .apply(table.getPTransformForOutput());\n  }\n\nThat way you're testing through the public interface and everything else (e.g. AvroRecorderEncoder) can be private.", "author": "TheNeuralBit", "createdAt": "2020-09-23T19:57:17Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -41,27 +40,49 @@\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataTypeSystem;\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.type.SqlTypeName;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n-import org.apache.commons.csv.CSVFormat;\n import org.junit.Assert;\n import org.junit.Rule;\n import org.junit.Test;\n \n /** Test for BeamKafkaCSVTable. */\n-public class BeamKafkaCSVTableTest {\n+public abstract class BeamKafkaTableTest {\n   @Rule public TestPipeline pipeline = TestPipeline.create();\n \n-  private static final Row ROW1 = Row.withSchema(genSchema()).addValues(1L, 1, 1.0).build();\n+  protected static final Schema BEAM_SQL_SCHEMA =\n+      TestTableUtils.buildBeamSqlSchema(\n+          Schema.FieldType.INT32,\n+          \"order_id\",\n+          Schema.FieldType.INT32,\n+          \"site_id\",\n+          Schema.FieldType.INT32,\n+          \"price\");\n \n-  private static final Row ROW2 = Row.withSchema(genSchema()).addValues(2L, 2, 2.0).build();\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  protected static final Schema SCHEMA = genSchema();\n+\n+  protected static final Row ROW1 = Row.withSchema(SCHEMA).addValues(1L, 1, 1d).build();\n+\n+  protected static final Row ROW2 = Row.withSchema(SCHEMA).addValues(2L, 2, 2d).build();\n+\n+  private static final Map<String, BeamSqlTable> tables = new HashMap<>();\n \n-  private static Map<String, BeamSqlTable> tables = new HashMap<>();\n   protected static BeamSqlEnv env = BeamSqlEnv.readOnly(\"test\", tables);\n \n+  protected abstract KafkaTestRecord<?> createKafkaTestRecord(\n+      String key, List<Object> values, long timestamp);\n+\n+  protected abstract KafkaTestTable getTable(int numberOfPartitions);\n+\n+  protected abstract PCollection<Row> createRecorderDecoder(TestPipeline pipeline);\n+\n+  protected abstract PCollection<Row> createRecorderEncoder(TestPipeline pipeline);", "originalCommit": "30d032fa019e19d7dc2f57529f423267ede27929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2Mzg1NA==", "url": "https://github.com/apache/beam/pull/12827#discussion_r493863854", "bodyText": "In that case it may make sense to get rid of createRecorderDecoder and createRecorderEncoder altogether and inline them in the couple of tests that use them.", "author": "TheNeuralBit", "createdAt": "2020-09-23T20:07:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg1ODY0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg2NTA5Mw==", "url": "https://github.com/apache/beam/pull/12827#discussion_r495865093", "bodyText": "I've got rid of createRecorderDecoder and Encoder but I had to make rowToBytesKV function to test the decoder.", "author": "piotr-szuberski", "createdAt": "2020-09-28T11:19:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg1ODY0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg1ODc0NA==", "url": "https://github.com/apache/beam/pull/12827#discussion_r493858744", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              protected abstract KafkaTestTable getTable(int numberOfPartitions);\n          \n          \n            \n              protected abstract KafkaTestTable getTestTable(int numberOfPartitions);", "author": "TheNeuralBit", "createdAt": "2020-09-23T19:57:30Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -41,27 +40,49 @@\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataTypeSystem;\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.type.SqlTypeName;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n-import org.apache.commons.csv.CSVFormat;\n import org.junit.Assert;\n import org.junit.Rule;\n import org.junit.Test;\n \n /** Test for BeamKafkaCSVTable. */\n-public class BeamKafkaCSVTableTest {\n+public abstract class BeamKafkaTableTest {\n   @Rule public TestPipeline pipeline = TestPipeline.create();\n \n-  private static final Row ROW1 = Row.withSchema(genSchema()).addValues(1L, 1, 1.0).build();\n+  protected static final Schema BEAM_SQL_SCHEMA =\n+      TestTableUtils.buildBeamSqlSchema(\n+          Schema.FieldType.INT32,\n+          \"order_id\",\n+          Schema.FieldType.INT32,\n+          \"site_id\",\n+          Schema.FieldType.INT32,\n+          \"price\");\n \n-  private static final Row ROW2 = Row.withSchema(genSchema()).addValues(2L, 2, 2.0).build();\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  protected static final Schema SCHEMA = genSchema();\n+\n+  protected static final Row ROW1 = Row.withSchema(SCHEMA).addValues(1L, 1, 1d).build();\n+\n+  protected static final Row ROW2 = Row.withSchema(SCHEMA).addValues(2L, 2, 2d).build();\n+\n+  private static final Map<String, BeamSqlTable> tables = new HashMap<>();\n \n-  private static Map<String, BeamSqlTable> tables = new HashMap<>();\n   protected static BeamSqlEnv env = BeamSqlEnv.readOnly(\"test\", tables);\n \n+  protected abstract KafkaTestRecord<?> createKafkaTestRecord(\n+      String key, List<Object> values, long timestamp);\n+\n+  protected abstract KafkaTestTable getTable(int numberOfPartitions);", "originalCommit": "30d032fa019e19d7dc2f57529f423267ede27929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg4NjExMg==", "url": "https://github.com/apache/beam/pull/12827#discussion_r495886112", "bodyText": "Done.", "author": "piotr-szuberski", "createdAt": "2020-09-28T12:02:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg1ODc0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2NDg5OA==", "url": "https://github.com/apache/beam/pull/12827#discussion_r493864898", "bodyText": "Could you add more fields to this schema to exercise more types?", "author": "TheNeuralBit", "createdAt": "2020-09-23T20:08:54Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/KafkaTableProviderIT.java", "diffHunk": "@@ -67,19 +67,25 @@\n import org.testcontainers.containers.KafkaContainer;\n \n /** This is an integration test for KafkaCSVTable. */\n-public class KafkaCSVTableIT {\n+public abstract class KafkaTableProviderIT {\n   @Rule public transient TestPipeline pipeline = TestPipeline.create();\n   @Rule public transient KafkaContainer kafka = new KafkaContainer();\n \n-  private KafkaOptions kafkaOptions;\n+  protected KafkaOptions kafkaOptions;\n \n-  private static final Schema TEST_TABLE_SCHEMA =\n+  protected static final Schema TEST_TABLE_SCHEMA =\n       Schema.builder()\n           .addNullableField(\"order_id\", Schema.FieldType.INT32)\n           .addNullableField(\"member_id\", Schema.FieldType.INT32)\n           .addNullableField(\"item_name\", Schema.FieldType.INT32)", "originalCommit": "30d032fa019e19d7dc2f57529f423267ede27929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg4NjAzOQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r495886039", "bodyText": "CSV is quite problematic here as most fields (bool, Row, etc) are  indistinguishable by the default csv parser. I'll make a getSchema() abstract and provide different fields for Avro and Csv.", "author": "piotr-szuberski", "createdAt": "2020-09-28T12:01:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2NDg5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2NTc3OQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r493865779", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            /** This is a MockKafkaCSVTestTable. It will use a Mock Consumer. */\n          \n          \n            \n            /** This is a mock BeamKafkaTable. It will use a Mock Consumer. */", "author": "TheNeuralBit", "createdAt": "2020-09-23T20:10:28Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/KafkaTestTable.java", "diffHunk": "@@ -44,23 +48,25 @@\n import org.apache.kafka.common.record.TimestampType;\n \n /** This is a MockKafkaCSVTestTable. It will use a Mock Consumer. */", "originalCommit": "30d032fa019e19d7dc2f57529f423267ede27929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg3NTM1Mg==", "url": "https://github.com/apache/beam/pull/12827#discussion_r495875352", "bodyText": "Done.", "author": "piotr-szuberski", "createdAt": "2020-09-28T11:40:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2NTc3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2NzE0NQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r493867145", "bodyText": "It looks like this is only actually used in BeamCsvTableTest, let's just move it there rather than making it protected.", "author": "TheNeuralBit", "createdAt": "2020-09-23T20:12:59Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -184,24 +185,11 @@ private static Schema genSchema() {\n             .build());\n   }\n \n-  private static class String2KvBytes extends DoFn<String, KV<byte[], byte[]>>\n+  protected static class String2KvBytes extends DoFn<String, KV<byte[], byte[]>>", "originalCommit": "30d032fa019e19d7dc2f57529f423267ede27929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDg0MTIyNw==", "url": "https://github.com/apache/beam/pull/12827#discussion_r494841227", "bodyText": "It will also be used in JSON table provider, that's why it's here as protected. But I can move it in the json PR in order to keep this one more consistent.", "author": "piotr-szuberski", "createdAt": "2020-09-25T08:47:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2NzE0NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTE0ODUyNw==", "url": "https://github.com/apache/beam/pull/12827#discussion_r495148527", "bodyText": "Ohh ok sorry about that. I'm fine with just making it protected here", "author": "TheNeuralBit", "createdAt": "2020-09-25T18:01:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2NzE0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2OTMzMQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r493869331", "bodyText": "Please test more types here too. Also I'm not sure why this is using JavaTypeFactory and converting to a Beam Schema, maybe it pre-dates the modern Schema class that has a nice builder interface. Could you change it to use Schema.builder()... or Schema.of(..)?", "author": "TheNeuralBit", "createdAt": "2020-09-23T20:17:13Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -123,57 +144,37 @@ public void testAllLate() {\n \n   @Test\n   public void testEmptyPartitionsRate() {\n-    KafkaCSVTestTable table = getTable(3);\n+    KafkaTestTable table = getTable(3);\n     BeamTableStatistics stats = table.getTableStatistics(null);\n     Assert.assertTrue(stats.isUnknown());\n   }\n \n   @Test\n   public void allTheRecordsSameTimeRate() {\n-    KafkaCSVTestTable table = getTable(3);\n-    for (int i = 0; i < 100; i++) {\n-      table.addRecord(KafkaTestRecord.create(\"key\" + i, i + \",1,2\", \"topic1\", 1000));\n+    KafkaTestTable table = getTable(3);\n+    for (long i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"key\" + i, ImmutableList.of(i, 1, 2d), 1000L));\n     }\n     BeamTableStatistics stats = table.getTableStatistics(null);\n     Assert.assertTrue(stats.isUnknown());\n   }\n \n-  private static class PrintDoFn extends DoFn<Row, Row> {\n-\n-    @ProcessElement\n-    public void process(ProcessContext c) {\n-      System.out.println(\"we are here\");\n-      System.out.println(c.element().getValues());\n-    }\n-  }\n-\n   @Test\n-  public void testCsvRecorderDecoder() {\n-    PCollection<Row> result =\n-        pipeline\n-            .apply(Create.of(\"1,\\\"1\\\",1.0\", \"2,2,2.0\"))\n-            .apply(ParDo.of(new String2KvBytes()))\n-            .apply(new BeamKafkaCSVTable.CsvRecorderDecoder(genSchema(), CSVFormat.DEFAULT));\n-\n+  public void testRecorderDecoder() {\n+    PCollection<Row> result = createRecorderDecoder(pipeline);\n     PAssert.that(result).containsInAnyOrder(ROW1, ROW2);\n \n     pipeline.run();\n   }\n \n   @Test\n-  public void testCsvRecorderEncoder() {\n-    PCollection<Row> result =\n-        pipeline\n-            .apply(Create.of(ROW1, ROW2))\n-            .apply(new BeamKafkaCSVTable.CsvRecorderEncoder(genSchema(), CSVFormat.DEFAULT))\n-            .apply(new BeamKafkaCSVTable.CsvRecorderDecoder(genSchema(), CSVFormat.DEFAULT));\n-\n+  public void testRecorderEncoder() {\n+    PCollection<Row> result = createRecorderDecoder(pipeline);\n     PAssert.that(result).containsInAnyOrder(ROW1, ROW2);\n-\n     pipeline.run();\n   }\n \n-  private static Schema genSchema() {\n+  protected static Schema genSchema() {", "originalCommit": "30d032fa019e19d7dc2f57529f423267ede27929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg2OTQ0Mw==", "url": "https://github.com/apache/beam/pull/12827#discussion_r495869443", "bodyText": "I thought it's for some integration with SQL types in Beam Tables. I'll change it to normal Schema builder.", "author": "piotr-szuberski", "createdAt": "2020-09-28T11:27:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2OTMzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NTgzNA==", "url": "https://github.com/apache/beam/pull/12827#discussion_r493875834", "bodyText": "Both of these methods will repeat the schema conversion for every Row. Instead both of these methods should convert the schema once and re-use avroSchema and coder for every instance of bytes or row that comes in. There are a few ways to do this, I don't really have a preference for which:\n\nReturn a lambda with avroSchema and coder in it's closure, like\n\nreturn (bytes) -> {\n  ByteArrayInputStream inputStream = new ByteArrayInputStream(bytes);\n  GenericRecord record = coder.decode(inputStream);\n  AvroUtils.toBeamRowStruct(record, schema);\n}\n\nCreate an AvroBytesToRow class with a process method that re-uses avroSchema/coder\nSimilarly, create an AvroBytesToRow DoFn with a process method that re-uses avroSchema/coder", "author": "TheNeuralBit", "createdAt": "2020-09-23T20:29:44Z", "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/utils/AvroUtils.java", "diffHunk": "@@ -428,6 +432,35 @@ public static GenericRecord toGenericRecord(\n     return new GenericRecordToRowFn(schema);\n   }\n \n+  public static Row avroBytesToRow(byte[] bytes, Schema schema) {\n+    try {\n+      org.apache.avro.Schema avroSchema = AvroUtils.toAvroSchema(schema);\n+      AvroCoder<GenericRecord> coder = AvroCoder.of(avroSchema);", "originalCommit": "30d032fa019e19d7dc2f57529f423267ede27929", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NjAxNw==", "url": "https://github.com/apache/beam/pull/12827#discussion_r493876017", "bodyText": "The last is probably the most natural for Beam", "author": "TheNeuralBit", "createdAt": "2020-09-23T20:30:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NTgzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTg2NjM5OA==", "url": "https://github.com/apache/beam/pull/12827#discussion_r495866398", "bodyText": "I had a quite hard time as AvroSchema is not serializable (and the tests were failing due to DoFn serialization exception), but I've learned the use case of transient keyword :) I've chosen the lambda way but had to define a class implementing SerializableFunction to be able to use transient for avroSchema. Done.", "author": "piotr-szuberski", "createdAt": "2020-09-28T11:21:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NTgzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzUzNTU5MQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r503535591", "bodyText": "Looks good, thanks for working through it :)", "author": "TheNeuralBit", "createdAt": "2020-10-12T21:15:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NTgzNA=="}], "type": "inlineReview"}, {"oid": "3a1816ccbdc860a5f66f92d391dc58f896e79c75", "url": "https://github.com/apache/beam/commit/3a1816ccbdc860a5f66f92d391dc58f896e79c75", "message": "Fixes after CR", "committedDate": "2020-09-28T13:18:03Z", "type": "forcePushed"}, {"oid": "edca112a19e5cc6df41db99c43bc5dd40ea0fe9e", "url": "https://github.com/apache/beam/commit/edca112a19e5cc6df41db99c43bc5dd40ea0fe9e", "message": "Fixes after CR", "committedDate": "2020-09-28T13:22:00Z", "type": "forcePushed"}, {"oid": "242e8aff494ac4c9cd68dba30cf01732a7c5a949", "url": "https://github.com/apache/beam/commit/242e8aff494ac4c9cd68dba30cf01732a7c5a949", "message": "Fixes after CR", "committedDate": "2020-09-28T13:50:11Z", "type": "forcePushed"}, {"oid": "15d0265ec5e18f7ff5112ce037a34fdc32fd1014", "url": "https://github.com/apache/beam/commit/15d0265ec5e18f7ff5112ce037a34fdc32fd1014", "message": "Change payloadFormat to format like in text table provider", "committedDate": "2020-09-29T10:50:08Z", "type": "forcePushed"}, {"oid": "0d8174c0d67451e310c759e245531eb7ce589f47", "url": "https://github.com/apache/beam/commit/0d8174c0d67451e310c759e245531eb7ce589f47", "message": "Fix checkstyle", "committedDate": "2020-09-29T11:59:36Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjMwODQ4NA==", "url": "https://github.com/apache/beam/pull/12827#discussion_r496308484", "bodyText": "I think I've seem issues with SchemaCoder and static members in the past, is that why this isn't static?", "author": "TheNeuralBit", "createdAt": "2020-09-29T00:33:34Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableAvroTest.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider.kafka;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.util.List;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.beam.sdk.coders.AvroCoder;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.utils.AvroUtils;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+import org.apache.beam.sdk.values.TypeDescriptors;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+\n+public class BeamKafkaTableAvroTest extends BeamKafkaTableTest {\n+  private static final Schema EMPTY_SCHEMA = Schema.builder().build();\n+\n+  private final Schema SCHEMA =", "originalCommit": "242e8aff494ac4c9cd68dba30cf01732a7c5a949", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQwNDAyMQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r500404021", "bodyText": "Actually no, I think I had some problem when applied lambdas to the pipeline but it's no longer the case. I've made it static again.", "author": "piotr-szuberski", "createdAt": "2020-10-06T15:43:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjMwODQ4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU3NzE4NQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r503577185", "bodyText": "For posterity, BEAM-10878 is the issue I was thinking of.", "author": "TheNeuralBit", "createdAt": "2020-10-12T23:05:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjMwODQ4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAwMjExNA==", "url": "https://github.com/apache/beam/pull/12827#discussion_r499002114", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            /** Test for BeamKafkaCSVTable. */\n          \n          \n            \n            /** Test utility for BeamKafkaTable implementations. */", "author": "TheNeuralBit", "createdAt": "2020-10-02T19:07:24Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider.kafka;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamSqlEnv;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n+import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+/** Test for BeamKafkaCSVTable. */", "originalCommit": "488562713d863377f6b33730f82b39cfda207163", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDMzNzMzOA==", "url": "https://github.com/apache/beam/pull/12827#discussion_r500337338", "bodyText": "Done", "author": "piotr-szuberski", "createdAt": "2020-10-06T14:32:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAwMjExNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAwMjc2MQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r499002761", "bodyText": "Please add a brief description of the abstract methods so it's clear for future implementers what they should do", "author": "TheNeuralBit", "createdAt": "2020-10-02T19:09:03Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider.kafka;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamSqlEnv;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n+import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+/** Test for BeamKafkaCSVTable. */\n+public abstract class BeamKafkaTableTest {\n+  @Rule public TestPipeline pipeline = TestPipeline.create();\n+\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  private static final Map<String, BeamSqlTable> tables = new HashMap<>();\n+\n+  protected static BeamSqlEnv env = BeamSqlEnv.readOnly(\"test\", tables);\n+\n+  protected abstract KafkaTestRecord<?> createKafkaTestRecord(String key, int i, long timestamp);\n+\n+  protected abstract KafkaTestTable getTestTable(int numberOfPartitions);\n+\n+  protected abstract BeamKafkaTable getBeamKafkaTable();\n+\n+  protected abstract PCollection<KV<byte[], byte[]>> applyRowToBytesKV(PCollection<Row> rows);\n+\n+  protected abstract List<Object> listFrom(int i);\n+\n+  protected abstract Schema getSchema();", "originalCommit": "488562713d863377f6b33730f82b39cfda207163", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQwMzI2OQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r500403269", "bodyText": "Done. I hope they are clear enough. I suppose that a future implementer will look at the other tests as well anyway.", "author": "piotr-szuberski", "createdAt": "2020-10-06T15:42:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAwMjc2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAzNTM4NA==", "url": "https://github.com/apache/beam/pull/12827#discussion_r499035384", "bodyText": "I don't think this test is meaningfully different from testRecorderEncoder. It looks like both of the implementations of applyRowToBytesKV are effectively the same as .apply(kafkaTable.getPTransformForOutput()), so we're not really getting a good signal that the encoder and decoder work as intended on their own.\nIt would be better if there were an abstract method like generateEncodedPayload(i) that returns the encoded counterpart for generateRow(i). Crucially, this method shouldn't use any of the code that we're testing here (like beamRow2CsvLines, or AvroUtils.getRowToAvroBytesFunction(getSchema())), it should instead generate the test data from scratch. This isn't too hard for CSV since its just a simple String. It's harder for Avro, but still doable, I think you can make it work by creating GenericRecord instances and encoding them.\nThen there could be tests like\n\ngenerate input with generateEncodedPayload, apply getPTransformForInput(), verify it matches data created with generateRow.\ngenerate input with generateRow, apply getPTransformForOutput(), verify it matches data created with generateEncodedPayload.\nwe could also have a round-trip test, like what's done in testRecorderEncoder now\n\nNote generateEncodedPayload could also be re-used in createKafkaTestRecord and it could have a concrete implementation in BeamKafkaTableTest as return KafkaTestRecord.create(key, generateEncodedPayload(i), \"topic1\", timestamp);", "author": "TheNeuralBit", "createdAt": "2020-10-02T20:27:54Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider.kafka;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamSqlEnv;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n+import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+/** Test for BeamKafkaCSVTable. */\n+public abstract class BeamKafkaTableTest {\n+  @Rule public TestPipeline pipeline = TestPipeline.create();\n+\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  private static final Map<String, BeamSqlTable> tables = new HashMap<>();\n+\n+  protected static BeamSqlEnv env = BeamSqlEnv.readOnly(\"test\", tables);\n+\n+  protected abstract KafkaTestRecord<?> createKafkaTestRecord(String key, int i, long timestamp);\n+\n+  protected abstract KafkaTestTable getTestTable(int numberOfPartitions);\n+\n+  protected abstract BeamKafkaTable getBeamKafkaTable();\n+\n+  protected abstract PCollection<KV<byte[], byte[]>> applyRowToBytesKV(PCollection<Row> rows);\n+\n+  protected abstract List<Object> listFrom(int i);\n+\n+  protected abstract Schema getSchema();\n+\n+  @Test\n+  public void testOrderedArrivalSinglePartitionRate() {\n+    KafkaTestTable table = getTestTable(1);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"k\" + i, i, 500L * i));\n+    }\n+\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(2d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testOrderedArrivalMultiplePartitionsRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"k\" + i, i, 500L * i));\n+    }\n+\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(2d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testOnePartitionAheadRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"1\", i, 1000L * i));\n+      table.addRecord(createKafkaTestRecord(\"2\", i, 500L * i));\n+    }\n+\n+    table.setNumberOfRecordsForRate(20);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(1d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testLateRecords() {\n+    KafkaTestTable table = getTestTable(3);\n+\n+    table.addRecord(createKafkaTestRecord(\"1\", 132, 1000L));\n+    for (int i = 0; i < 98; i++) {\n+      table.addRecord(createKafkaTestRecord(\"1\", i, 500L));\n+    }\n+    table.addRecord(createKafkaTestRecord(\"1\", 133, 2000L));\n+\n+    table.setNumberOfRecordsForRate(200);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(1d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testAllLate() {\n+    KafkaTestTable table = getTestTable(3);\n+\n+    table.addRecord(createKafkaTestRecord(\"1\", 132, 1000L));\n+    for (int i = 0; i < 98; i++) {\n+      table.addRecord(createKafkaTestRecord(\"1\", i, 500L));\n+    }\n+\n+    table.setNumberOfRecordsForRate(200);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertTrue(stats.isUnknown());\n+  }\n+\n+  @Test\n+  public void testEmptyPartitionsRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertTrue(stats.isUnknown());\n+  }\n+\n+  @Test\n+  public void allTheRecordsSameTimeRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"key\" + i, i, 1000L));\n+    }\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertTrue(stats.isUnknown());\n+  }\n+\n+  @Test\n+  public void testRecorderDecoder() {\n+    BeamKafkaTable kafkaTable = getBeamKafkaTable();\n+\n+    PCollection<Row> initialRows = pipeline.apply(Create.of(generateRow(1), generateRow(2)));\n+\n+    PCollection<KV<byte[], byte[]>> bytesKV = applyRowToBytesKV(initialRows);\n+    PCollection<Row> result = bytesKV.apply(kafkaTable.getPTransformForInput());\n+\n+    PAssert.that(result).containsInAnyOrder(generateRow(1), generateRow(2));\n+    pipeline.run();\n+  }", "originalCommit": "488562713d863377f6b33730f82b39cfda207163", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQwMjY3Ng==", "url": "https://github.com/apache/beam/pull/12827#discussion_r500402676", "bodyText": "Thanks so much for such in-depth review! I've done everything and also was able to remove the TestKafkaRecord generification which was actually a very complex workaround to the csv sending Strings instead of bytes.", "author": "piotr-szuberski", "createdAt": "2020-10-06T15:41:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAzNTM4NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU0Njg4Mg==", "url": "https://github.com/apache/beam/pull/12827#discussion_r503546882", "bodyText": "Thanks!", "author": "TheNeuralBit", "createdAt": "2020-10-12T21:36:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAzNTM4NA=="}], "type": "inlineReview"}, {"oid": "048f3801661e190bb84058fddf6d7bc26a13a3f5", "url": "https://github.com/apache/beam/commit/048f3801661e190bb84058fddf6d7bc26a13a3f5", "message": "Remove generification of KafkaTestRecord", "committedDate": "2020-10-12T16:12:06Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU1MDY2MA==", "url": "https://github.com/apache/beam/pull/12827#discussion_r503550660", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              /** Returns encoded payload for the tested format. */\n          \n          \n            \n              /** Returns encoded payload in the tested format corresponding to the row in `generateRow(i)`. */", "author": "TheNeuralBit", "createdAt": "2020-10-12T21:45:41Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider.kafka;\n+\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.SimpleFunction;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+/** Test utility for BeamKafkaTable implementations. */\n+public abstract class BeamKafkaTableTest {\n+  @Rule public TestPipeline pipeline = TestPipeline.create();\n+\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  /** Returns proper implementation of KafkaTestTable for the tested format */\n+  protected abstract KafkaTestTable getTestTable(int numberOfPartitions);\n+\n+  /** Returns proper implementation of BeamKafkaTable for the tested format */\n+  protected abstract BeamKafkaTable getBeamKafkaTable();\n+\n+  /** Returns encoded payload for the tested format. */", "originalCommit": "38a0901b3ae9c5185826520330dbc5edf28d0614", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzkwMTM1OQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r503901359", "bodyText": "Thanks!", "author": "piotr-szuberski", "createdAt": "2020-10-13T12:15:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU1MDY2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU1MjM5NQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r503552395", "bodyText": "nit: I think this is cleaner inlined, it doesn't look like its used anywhere else.", "author": "TheNeuralBit", "createdAt": "2020-10-12T21:50:36Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/KafkaTestTable.java", "diffHunk": "@@ -73,6 +77,10 @@ public void setNumberOfRecordsForRate(int numberOfRecordsForRate) {\n     this.numberOfRecordsForRate = numberOfRecordsForRate;\n   }\n \n+  private byte[] getRecordValueBytes(KafkaTestRecord record) {\n+    return record.getValue().toByteArray();\n+  }", "originalCommit": "38a0901b3ae9c5185826520330dbc5edf28d0614", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzkwMjEyNg==", "url": "https://github.com/apache/beam/pull/12827#discussion_r503902126", "bodyText": "I agree.", "author": "piotr-szuberski", "createdAt": "2020-10-13T12:17:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU1MjM5NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU1NTYyOA==", "url": "https://github.com/apache/beam/pull/12827#discussion_r503555628", "bodyText": "I don't think BeamKafkaTable#getTable is used, can we get rid of it?", "author": "TheNeuralBit", "createdAt": "2020-10-12T21:59:27Z", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTable.java", "diffHunk": "@@ -91,12 +91,14 @@ public BeamKafkaTable updateConsumerProperties(Map<String, Object> configUpdates\n     return PCollection.IsBounded.UNBOUNDED;\n   }\n \n-  public abstract PTransform<PCollection<KV<byte[], byte[]>>, PCollection<Row>>\n+  protected abstract PTransform<PCollection<KV<byte[], byte[]>>, PCollection<Row>>\n       getPTransformForInput();\n \n-  public abstract PTransform<PCollection<Row>, PCollection<KV<byte[], byte[]>>>\n+  protected abstract PTransform<PCollection<Row>, PCollection<KV<byte[], byte[]>>>\n       getPTransformForOutput();\n \n+  protected abstract BeamKafkaTable getTable();\n+", "originalCommit": "38a0901b3ae9c5185826520330dbc5edf28d0614", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzkwMzU4MA==", "url": "https://github.com/apache/beam/pull/12827#discussion_r503903580", "bodyText": "You're right. Thanks for your keen eye!", "author": "piotr-szuberski", "createdAt": "2020-10-13T12:19:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU1NTYyOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU3NjQ5OA==", "url": "https://github.com/apache/beam/pull/12827#discussion_r503576498", "bodyText": "The tests above this point are the only ones that use KafkaTestTable, and they're only exercising the getTableStatistics method, which never deserializes any records. So:\n\nWe shouldn't really need to repeat these tests for each payload format.\nWe don't need a separate KafkaTestTableCSV and KafkaTestTableAvro. There could just be a single concrete KafkaTestTable that raises an error in getPTransformFor{Input,Output}.\n\nI'm fine if we don't worry about (1) for now, but I'd like to address (2) for clarity.", "author": "TheNeuralBit", "createdAt": "2020-10-12T23:02:41Z", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider.kafka;\n+\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.SimpleFunction;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+/** Test utility for BeamKafkaTable implementations. */\n+public abstract class BeamKafkaTableTest {\n+  @Rule public TestPipeline pipeline = TestPipeline.create();\n+\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  /** Returns proper implementation of KafkaTestTable for the tested format */\n+  protected abstract KafkaTestTable getTestTable(int numberOfPartitions);\n+\n+  /** Returns proper implementation of BeamKafkaTable for the tested format */\n+  protected abstract BeamKafkaTable getBeamKafkaTable();\n+\n+  /** Returns encoded payload for the tested format. */\n+  protected abstract byte[] generateEncodedPayload(int i);\n+\n+  /** Provides a deterministic row from the given integer. */\n+  protected abstract Row generateRow(int i);\n+\n+  @Test\n+  public void testOrderedArrivalSinglePartitionRate() {\n+    KafkaTestTable table = getTestTable(1);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"k\" + i, i, 500L * i));\n+    }\n+\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(2d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testOrderedArrivalMultiplePartitionsRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"k\" + i, i, 500L * i));\n+    }\n+\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(2d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testOnePartitionAheadRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"1\", i, 1000L * i));\n+      table.addRecord(createKafkaTestRecord(\"2\", i, 500L * i));\n+    }\n+\n+    table.setNumberOfRecordsForRate(20);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(1d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testLateRecords() {\n+    KafkaTestTable table = getTestTable(3);\n+\n+    table.addRecord(createKafkaTestRecord(\"1\", 132, 1000L));\n+    for (int i = 0; i < 98; i++) {\n+      table.addRecord(createKafkaTestRecord(\"1\", i, 500L));\n+    }\n+    table.addRecord(createKafkaTestRecord(\"1\", 133, 2000L));\n+\n+    table.setNumberOfRecordsForRate(200);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(1d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testAllLate() {\n+    KafkaTestTable table = getTestTable(3);\n+\n+    table.addRecord(createKafkaTestRecord(\"1\", 132, 1000L));\n+    for (int i = 0; i < 98; i++) {\n+      table.addRecord(createKafkaTestRecord(\"1\", i, 500L));\n+    }\n+\n+    table.setNumberOfRecordsForRate(200);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertTrue(stats.isUnknown());\n+  }\n+\n+  @Test\n+  public void testEmptyPartitionsRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertTrue(stats.isUnknown());\n+  }\n+\n+  @Test\n+  public void allTheRecordsSameTimeRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"key\" + i, i, 1000L));\n+    }\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertTrue(stats.isUnknown());\n+  }", "originalCommit": "38a0901b3ae9c5185826520330dbc5edf28d0614", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzkzMDQ3Mw==", "url": "https://github.com/apache/beam/pull/12827#discussion_r503930473", "bodyText": "I've just realized that I've never checked what these tests actually are testing. I've moved the statistics tests to a separate file.\nI've also got rid of KafkaTestTableCSV and KafkaTestTableAvro.", "author": "piotr-szuberski", "createdAt": "2020-10-13T13:00:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU3NjQ5OA=="}], "type": "inlineReview"}, {"oid": "07782776d2e351a03e7275836be1884dc088b98b", "url": "https://github.com/apache/beam/commit/07782776d2e351a03e7275836be1884dc088b98b", "message": "[BEAM-10885] Add Avro support to Kafka table provider", "committedDate": "2020-10-13T13:22:32Z", "type": "commit"}, {"oid": "986c21e2f680cdce60235af0be8df96ce99be1c2", "url": "https://github.com/apache/beam/commit/986c21e2f680cdce60235af0be8df96ce99be1c2", "message": "Remove booleans, use List of values", "committedDate": "2020-10-13T13:22:32Z", "type": "commit"}, {"oid": "56802e30d18a98cca37ee6d9bdb8a522c2022379", "url": "https://github.com/apache/beam/commit/56802e30d18a98cca37ee6d9bdb8a522c2022379", "message": "Fixes after CR", "committedDate": "2020-10-13T13:22:32Z", "type": "commit"}, {"oid": "1a7462d67098e341d2377d1c0e18ca238190f9bc", "url": "https://github.com/apache/beam/commit/1a7462d67098e341d2377d1c0e18ca238190f9bc", "message": "Change payloadFormat to format like in text table provider", "committedDate": "2020-10-13T13:22:32Z", "type": "commit"}, {"oid": "e607bc6042ef423ece8a83b2980922fdf0984da9", "url": "https://github.com/apache/beam/commit/e607bc6042ef423ece8a83b2980922fdf0984da9", "message": "Fix checkstyle", "committedDate": "2020-10-13T13:22:32Z", "type": "commit"}, {"oid": "570eee6846fc52151487ee61e60c8361fab4f80b", "url": "https://github.com/apache/beam/commit/570eee6846fc52151487ee61e60c8361fab4f80b", "message": "Use SimpleFunction instead of SerializableFunction", "committedDate": "2020-10-13T13:22:33Z", "type": "commit"}, {"oid": "c2b8bf803773ea81aab9aa1ee52473f2210b000b", "url": "https://github.com/apache/beam/commit/c2b8bf803773ea81aab9aa1ee52473f2210b000b", "message": "Remove getSchema() and listFrom(), make abstract generateRow, add generateEncodedPayload(i)", "committedDate": "2020-10-13T13:22:33Z", "type": "commit"}, {"oid": "af435332f42a92beee9a9c3f6f54d4f218745c19", "url": "https://github.com/apache/beam/commit/af435332f42a92beee9a9c3f6f54d4f218745c19", "message": "Remove generification of KafkaTestRecord", "committedDate": "2020-10-13T13:22:33Z", "type": "commit"}, {"oid": "14405f98b2aedfd15a6545b43728f440259d76f3", "url": "https://github.com/apache/beam/commit/14405f98b2aedfd15a6545b43728f440259d76f3", "message": "Add missing close paren", "committedDate": "2020-10-13T13:22:33Z", "type": "commit"}, {"oid": "4f7cd0016a5865dc767bd4ed75d52554914c9e53", "url": "https://github.com/apache/beam/commit/4f7cd0016a5865dc767bd4ed75d52554914c9e53", "message": "Get rid of getTable() and KafkaTestTable inheritance", "committedDate": "2020-10-13T13:22:33Z", "type": "commit"}, {"oid": "76b2e51dac47411d13284e120bec675921d3159b", "url": "https://github.com/apache/beam/commit/76b2e51dac47411d13284e120bec675921d3159b", "message": "Fix comment", "committedDate": "2020-10-13T13:22:33Z", "type": "commit"}, {"oid": "0b39204d71818fccf4bf3ef9d765387477f063ba", "url": "https://github.com/apache/beam/commit/0b39204d71818fccf4bf3ef9d765387477f063ba", "message": "Inline getRecordValueBytes", "committedDate": "2020-10-13T13:22:33Z", "type": "commit"}, {"oid": "5f866ef478fe5f093e7e10f61db878279db0f339", "url": "https://github.com/apache/beam/commit/5f866ef478fe5f093e7e10f61db878279db0f339", "message": "Remove generification of generateProducerRecord", "committedDate": "2020-10-13T13:22:33Z", "type": "commit"}, {"oid": "23894dabb30c2e59a6fcf8354b5fc595559c54bd", "url": "https://github.com/apache/beam/commit/23894dabb30c2e59a6fcf8354b5fc595559c54bd", "message": "Add full-stops to javadocs", "committedDate": "2020-10-13T13:22:34Z", "type": "commit"}, {"oid": "d1217994ff3cf23eaed87ef157d23a1b7abd309b", "url": "https://github.com/apache/beam/commit/d1217994ff3cf23eaed87ef157d23a1b7abd309b", "message": "Move statistics tests to separate file", "committedDate": "2020-10-13T13:22:34Z", "type": "commit"}, {"oid": "1f930ef4e55e527c6b78dcf667a8fe1f821079d5", "url": "https://github.com/apache/beam/commit/1f930ef4e55e527c6b78dcf667a8fe1f821079d5", "message": "Throw exception instead of returning null.", "committedDate": "2020-10-13T13:22:34Z", "type": "commit"}, {"oid": "23c7188200f4c871f79e7705c8baef9b3a22f1dc", "url": "https://github.com/apache/beam/commit/23c7188200f4c871f79e7705c8baef9b3a22f1dc", "message": "Update create-external-table.md", "committedDate": "2020-10-13T13:22:34Z", "type": "commit"}, {"oid": "1705c7bfabbf361abbde250a9ebed38ab3a0f50e", "url": "https://github.com/apache/beam/commit/1705c7bfabbf361abbde250a9ebed38ab3a0f50e", "message": "Update CHANGES.md", "committedDate": "2020-10-13T13:22:34Z", "type": "commit"}, {"oid": "1705c7bfabbf361abbde250a9ebed38ab3a0f50e", "url": "https://github.com/apache/beam/commit/1705c7bfabbf361abbde250a9ebed38ab3a0f50e", "message": "Update CHANGES.md", "committedDate": "2020-10-13T13:22:34Z", "type": "forcePushed"}, {"oid": "97ecb909a5671281b78713e77aa93a612497201d", "url": "https://github.com/apache/beam/commit/97ecb909a5671281b78713e77aa93a612497201d", "message": "Use ByteArraySerializer as kafka value serializer", "committedDate": "2020-10-13T13:48:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDEzMTIxOQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r504131219", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * Support for avro format in Kafka Table added ([BEAM-10885](https://issues.apache.org/jira/browse/BEAM-10885))\n          \n          \n            \n            * Added support for avro payload format in Beam SQL Kafka Table ([BEAM-10885](https://issues.apache.org/jira/browse/BEAM-10885))", "author": "TheNeuralBit", "createdAt": "2020-10-13T17:24:30Z", "path": "CHANGES.md", "diffHunk": "@@ -61,7 +61,7 @@\n * Support for X source added (Java/Python) ([BEAM-X](https://issues.apache.org/jira/browse/BEAM-X)).\n \n ## New Features / Improvements\n-\n+* Support for avro format in Kafka Table added ([BEAM-10885](https://issues.apache.org/jira/browse/BEAM-10885))", "originalCommit": "97ecb909a5671281b78713e77aa93a612497201d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDEzMzYzNg==", "url": "https://github.com/apache/beam/pull/12827#discussion_r504133636", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            ### Supported Payload\n          \n          \n            \n            ### Supported Payload Formats", "author": "TheNeuralBit", "createdAt": "2020-10-13T17:28:39Z", "path": "website/www/site/content/en/documentation/dsls/sql/extensions/create-external-table.md", "diffHunk": "@@ -313,9 +315,12 @@ Write Mode supports writing to a topic.\n \n ### Supported Payload", "originalCommit": "97ecb909a5671281b78713e77aa93a612497201d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDEzNDU5MQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r504134591", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                {`csv`, `avro`}, capitalization does not matter. Defaults to `csv`.\n          \n          \n            \n                {`csv`, `avro`}. Defaults to `csv`.", "author": "TheNeuralBit", "createdAt": "2020-10-13T17:30:18Z", "path": "website/www/site/content/en/documentation/dsls/sql/extensions/create-external-table.md", "diffHunk": "@@ -294,14 +294,16 @@ KafkaIO is experimental in Beam SQL.\n CREATE EXTERNAL TABLE [ IF NOT EXISTS ] tableName (tableElement [, tableElement ]*)\n TYPE kafka\n LOCATION 'kafka://localhost:2181/brokers'\n-TBLPROPERTIES '{\"bootstrap.servers\":\"localhost:9092\", \"topics\": [\"topic1\", \"topic2\"]}'\n+TBLPROPERTIES '{\"bootstrap.servers\":\"localhost:9092\", \"topics\": [\"topic1\", \"topic2\"], \"format\": \"avro\"}'\n ```\n \n *   `LOCATION`: The Kafka topic URL.\n *   `TBLPROPERTIES`:\n     *   `bootstrap.servers`: Optional. Allows you to specify the bootstrap\n         server.\n     *   `topics`: Optional. Allows you to specify specific topics.\n+    *   `format`: Optional. Allows you to specify the Kafka values format. Possible values are\n+    {`csv`, `avro`}, capitalization does not matter. Defaults to `csv`.", "originalCommit": "97ecb909a5671281b78713e77aa93a612497201d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDMyMTY3NQ==", "url": "https://github.com/apache/beam/pull/12827#discussion_r504321675", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            *   CSV (default)\n          \n          \n            \n                *   Beam parses the messages, attempting to parse fields according to the\n          \n          \n            \n                    types specified in the schema.\n          \n          \n            \n            *   Avro\n          \n          \n            \n                *   Beam parses the messages, attempting to parse fields according to the\n          \n          \n            \n                    types specified in the schema. Avro schema is automatically deduced.\n          \n          \n            \n            *   CSV (default)\n          \n          \n            \n                *   Beam parses the messages, attempting to parse fields according to the\n          \n          \n            \n                    types specified in the schema.\n          \n          \n            \n            *   Avro\n          \n          \n            \n                *   An Avro schema is automatically generated from the specified field\n          \n          \n            \n                    types. It is used to parse incoming messages and to format outgoing\n          \n          \n            \n                    messages.", "author": "TheNeuralBit", "createdAt": "2020-10-13T23:50:43Z", "path": "website/www/site/content/en/documentation/dsls/sql/extensions/create-external-table.md", "diffHunk": "@@ -313,9 +315,12 @@ Write Mode supports writing to a topic.\n \n ### Supported Payload\n \n-*   CSV\n+*   CSV (default)\n     *   Beam parses the messages, attempting to parse fields according to the\n         types specified in the schema.\n+*   Avro\n+    *   Beam parses the messages, attempting to parse fields according to the\n+        types specified in the schema. Avro schema is automatically deduced.", "originalCommit": "97ecb909a5671281b78713e77aa93a612497201d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "d15b2f7f0e8dd7927346ae4a14738d7cd86b898f", "url": "https://github.com/apache/beam/commit/d15b2f7f0e8dd7927346ae4a14738d7cd86b898f", "message": "Update CHANGES.md", "committedDate": "2020-10-13T23:51:47Z", "type": "commit"}, {"oid": "ed18322a79a0fa8c6a88ca7ff6b1803a55b743aa", "url": "https://github.com/apache/beam/commit/ed18322a79a0fa8c6a88ca7ff6b1803a55b743aa", "message": "Update website/www/site/content/en/documentation/dsls/sql/extensions/create-external-table.md", "committedDate": "2020-10-13T23:52:01Z", "type": "commit"}, {"oid": "5d1d7a9bb05e091100aa84e22c66ea1f1e99cc04", "url": "https://github.com/apache/beam/commit/5d1d7a9bb05e091100aa84e22c66ea1f1e99cc04", "message": "Update website/www/site/content/en/documentation/dsls/sql/extensions/create-external-table.md", "committedDate": "2020-10-13T23:52:11Z", "type": "commit"}, {"oid": "d6a14e9abc8b93850fa3d08c9dfa72d9e4fd78ee", "url": "https://github.com/apache/beam/commit/d6a14e9abc8b93850fa3d08c9dfa72d9e4fd78ee", "message": "Update website/www/site/content/en/documentation/dsls/sql/extensions/create-external-table.md", "committedDate": "2020-10-13T23:52:25Z", "type": "commit"}]}