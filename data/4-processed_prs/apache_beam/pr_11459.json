{"pr_number": 11459, "pr_title": "[BEAM-2546] Add InfluxDbIO", "pr_createdAt": "2020-04-18T01:21:14Z", "pr_url": "https://github.com/apache/beam/pull/11459", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMDQ2OQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449600469", "bodyText": "Please, extract it as entity of project.ext.library in BeamModulePlugin.groovy", "author": "aromanenko-dev", "createdAt": "2020-07-03T14:05:17Z", "path": "sdks/java/io/influxdb/build.gradle", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one\n+* or more contributor license agreements.  See the NOTICE file\n+* distributed with this work for additional information\n+* regarding copyright ownership.  The ASF licenses this file\n+* to you under the Apache License, Version 2.0 (the\n+* License); you may not use this file except in compliance\n+* with the License.  You may obtain a copy of the License at\n+*\n+*     http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an AS IS BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+ \n+plugins { id 'org.apache.beam.module' }\n+applyJavaNature(automaticModuleName: 'org.apache.beam.sdk.io.influxdb')\n+provideIntegrationTestingDependencies()\n+enableJavaPerformanceTesting()\n+\n+description = \"Apache Beam :: SDKs :: Java :: IO :: InfluxDB\"\n+ext.summary = \"IO to read and write on InfluxDB\"\n+\n+dependencies {\n+  compile project(path: \":sdks:java:core\", configuration: \"shadow\")\n+  compile 'org.influxdb:influxdb-java:2.17'", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMTEwOQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449601109", "bodyText": "testRuntimeOnly project(path: \":runners:direct-java\", configuration: \"shadow\")", "author": "aromanenko-dev", "createdAt": "2020-07-03T14:06:43Z", "path": "sdks/java/io/influxdb/build.gradle", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one\n+* or more contributor license agreements.  See the NOTICE file\n+* distributed with this work for additional information\n+* regarding copyright ownership.  The ASF licenses this file\n+* to you under the Apache License, Version 2.0 (the\n+* License); you may not use this file except in compliance\n+* with the License.  You may obtain a copy of the License at\n+*\n+*     http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an AS IS BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+ \n+plugins { id 'org.apache.beam.module' }\n+applyJavaNature(automaticModuleName: 'org.apache.beam.sdk.io.influxdb')\n+provideIntegrationTestingDependencies()\n+enableJavaPerformanceTesting()\n+\n+description = \"Apache Beam :: SDKs :: Java :: IO :: InfluxDB\"\n+ext.summary = \"IO to read and write on InfluxDB\"\n+\n+dependencies {\n+  compile project(path: \":sdks:java:core\", configuration: \"shadow\")\n+  compile 'org.influxdb:influxdb-java:2.17'\n+  testCompile library.java.junit\n+  testRuntimeOnly project(\":runners:direct-java\")", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMjc4Ng==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449602786", "bodyText": "I don't think it's needed. Please, remove", "author": "aromanenko-dev", "createdAt": "2020-07-03T14:10:21Z", "path": "sdks/java/io/influxdb/build.gradle", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one\n+* or more contributor license agreements.  See the NOTICE file\n+* distributed with this work for additional information\n+* regarding copyright ownership.  The ASF licenses this file\n+* to you under the Apache License, Version 2.0 (the\n+* License); you may not use this file except in compliance\n+* with the License.  You may obtain a copy of the License at\n+*\n+*     http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an AS IS BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+ \n+plugins { id 'org.apache.beam.module' }\n+applyJavaNature(automaticModuleName: 'org.apache.beam.sdk.io.influxdb')\n+provideIntegrationTestingDependencies()\n+enableJavaPerformanceTesting()\n+\n+description = \"Apache Beam :: SDKs :: Java :: IO :: InfluxDB\"\n+ext.summary = \"IO to read and write on InfluxDB\"\n+\n+dependencies {\n+  compile project(path: \":sdks:java:core\", configuration: \"shadow\")\n+  compile 'org.influxdb:influxdb-java:2.17'\n+  testCompile library.java.junit\n+  testRuntimeOnly project(\":runners:direct-java\")\n+  testCompile group: 'org.apache.beam', name: 'beam-runners-direct-java', version: '2.15.0'", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMzEzMA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449603130", "bodyText": "Add class Javadoc and remove public", "author": "aromanenko-dev", "createdAt": "2020-07-03T14:11:05Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/DBShardInformation.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.influxdb.dto.QueryResult.Series;\n+\n+public class DBShardInformation {", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMzMwNw==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449603307", "bodyText": "Please, add class Javadoc", "author": "aromanenko-dev", "createdAt": "2020-07-03T14:11:31Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/LineProtocolConvertable.java", "diffHunk": "@@ -0,0 +1,22 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+public interface LineProtocolConvertable {", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMzM2Mw==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449603363", "bodyText": "Please, add class Javadoc", "author": "aromanenko-dev", "createdAt": "2020-07-03T14:11:40Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/ShardInformation.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.List;\n+import java.util.Objects;\n+import org.joda.time.DateTime;\n+\n+public class ShardInformation implements Comparable {", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwNTUwMQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449605501", "bodyText": "Please, rename the class name to InfluxDbIO to be compatible with other IOs, like MongoDbIO", "author": "aromanenko-dev", "createdAt": "2020-07-03T14:16:37Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwNjg0Mw==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449606843", "bodyText": "nit: \"You have ...\"", "author": "aromanenko-dev", "createdAt": "2020-07-03T14:19:42Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYxMzcwMA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449613700", "bodyText": "Is it a blocking operation?", "author": "aromanenko-dev", "createdAt": "2020-07-03T14:35:50Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(noOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element().toString());", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY0MTE2MQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449641161", "bodyText": "Would it make sense to take as input a PCollection of LineProtocolConvertable (instead of just String) or create own wrapper class, something like InfluxDbRecord implements LineProtocolConvertable?", "author": "aromanenko-dev", "createdAt": "2020-07-03T15:47:37Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY0MTgyMA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449641820", "bodyText": "What is a case when user would need to set it to true? It could be potential security issue.", "author": "aromanenko-dev", "createdAt": "2020-07-03T15:49:41Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1MTk1Mw==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449651953", "bodyText": "This class can be package-private.", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:24:18Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/DBShardInformation.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.influxdb.dto.QueryResult.Series;\n+\n+public class DBShardInformation {\n+\n+  private Map<String, List<ShardInformation>> shardInformation = new HashMap<>();\n+\n+  public DBShardInformation() {}", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1MjkxMg==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449652912", "bodyText": "nit: checkState", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:28:09Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1MzIxOQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449653219", "bodyText": "nit: numOfBlocksValue", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:29:34Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1Mzc4Mw==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449653783", "bodyText": "How big this result can be in terms of amount of returned data?", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:31:43Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NDgyMw==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449654823", "bodyText": "nit: numOfBlocks", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:35:57Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NjI0MA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449656240", "bodyText": "nit: numOfBlocksValueIterator", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:41:27Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NjMzNQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449656335", "bodyText": "nit: sizeOfBlocksValueIterator", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:41:48Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1Njk1OQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449656959", "bodyText": "It's not possible to split with query?", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:44:19Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NzgwOQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449657809", "bodyText": "Is it needed to allow user to configure this? Can we set just sufficient default value?", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:47:42Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzI2NzExMw==", "url": "https://github.com/apache/beam/pull/11459#discussion_r453267113", "bodyText": "If not applied, it uses the default value https://github.com/bipinupd/beam/blob/BEAM-2546/sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java#L133", "author": "bipinupd", "createdAt": "2020-07-12T04:50:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NzgwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyMTY2OA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r456521668", "bodyText": "Beam tends to reduce number of knobs exposed to user API.\nIs it quite possible that it will be required to change? Can we check in a loop (with a quite large timeout to prevent infinite loop) that everything was flushed?", "author": "aromanenko-dev", "createdAt": "2020-07-17T15:40:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NzgwOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NzkxNQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449657915", "bodyText": "nit: numOfElementsToBatch", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:48:12Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODE5OA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449658198", "bodyText": "What is a reason to have unsafe https client?", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:49:26Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(noOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element().toString());\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        connection.flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        if (connection != null) {\n+          connection.flush();\n+          connection.close();\n+          connection = null;\n+        }\n+      }\n+\n+      @Override\n+      public void populateDisplayData(DisplayData.Builder builder) {\n+        builder.delegate(Write.this);\n+      }\n+    }\n+  }\n+\n+  private static OkHttpClient.Builder getUnsafeOkHttpClient() {", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzI2MTMyNA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r453261324", "bodyText": "For the cases where InfluxDB is run without proper SSL in internal servers", "author": "bipinupd", "createdAt": "2020-07-12T03:23:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODE5OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyNjIxMA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r456526210", "bodyText": "I don't think that we have to expose it into user API and implement it inside IO. Can we just allow user to provide a custom client implementation for this case?", "author": "aromanenko-dev", "createdAt": "2020-07-17T15:48:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODE5OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODI0Ng==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449658246", "bodyText": "Is it needed to allow user to configure this? Can we set just sufficient default value?", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:49:41Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzI2MTE3NA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r453261174", "bodyText": "If not supplied.. It uses the default https://github.com/bipinupd/beam/blob/BEAM-2546/sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java#L134", "author": "bipinupd", "createdAt": "2020-07-12T03:20:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODI0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODM4OQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449658389", "bodyText": "nit: numOfBatchPoints", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:50:17Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1OTE0Mg==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449659142", "bodyText": "If InfluxDB  is not serialisable then it should be transient.", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:53:31Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY2MDA5Ng==", "url": "https://github.com/apache/beam/pull/11459#discussion_r449660096", "bodyText": "Do we need to handle for every connection.query() an empty result  (if possible) or any exceptions if they can happen?", "author": "aromanenko-dev", "createdAt": "2020-07-03T16:57:32Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(noOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element().toString());\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        connection.flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        if (connection != null) {\n+          connection.flush();\n+          connection.close();\n+          connection = null;\n+        }\n+      }\n+\n+      @Override\n+      public void populateDisplayData(DisplayData.Builder builder) {\n+        builder.delegate(Write.this);\n+      }\n+    }\n+  }\n+\n+  private static OkHttpClient.Builder getUnsafeOkHttpClient() {\n+    try {\n+      // Create a trust manager that does not validate certificate chains\n+      final TrustManager[] trustAllCerts =\n+          new TrustManager[] {\n+            new X509TrustManager() {\n+              @Override\n+              public void checkClientTrusted(\n+                  java.security.cert.X509Certificate[] chain, String authType) {}\n+\n+              @Override\n+              public void checkServerTrusted(\n+                  java.security.cert.X509Certificate[] chain, String authType) {}\n+\n+              @Override\n+              public java.security.cert.X509Certificate[] getAcceptedIssuers() {\n+                return new java.security.cert.X509Certificate[] {};\n+              }\n+            }\n+          };\n+\n+      // Install the all-trusting trust manager\n+      final SSLContext sslContext = SSLContext.getInstance(\"SSL\");\n+      sslContext.init(null, trustAllCerts, new java.security.SecureRandom());\n+      // Create an ssl socket factory with our all-trusting manager\n+      final SSLSocketFactory sslSocketFactory = sslContext.getSocketFactory();\n+\n+      OkHttpClient.Builder builder = new OkHttpClient.Builder();\n+      builder.sslSocketFactory(sslSocketFactory, (X509TrustManager) trustAllCerts[0]);\n+      builder.hostnameVerifier((hostname, session) -> true);\n+      return builder;\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+  }\n+  /** A POJO describing a DataSourceConfiguration such as URL, userName and password. */\n+  @AutoValue\n+  public abstract static class DataSourceConfiguration implements Serializable {\n+\n+    @Nullable\n+    abstract ValueProvider<String> url();\n+\n+    @Nullable\n+    abstract ValueProvider<String> userName();\n+\n+    @Nullable\n+    abstract ValueProvider<String> password();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+\n+      abstract Builder setUrl(ValueProvider<String> url);\n+\n+      abstract Builder setUserName(ValueProvider<String> userName);\n+\n+      abstract Builder setPassword(ValueProvider<String> password);\n+\n+      abstract DataSourceConfiguration build();\n+    }\n+\n+    public static DataSourceConfiguration create(String url, String userName, String password) {\n+      checkArgument(url != null, \"url can not be null\");\n+      checkArgument(userName != null, \"userName can not be null\");\n+      checkArgument(password != null, \"password can not be null\");\n+\n+      return create(\n+          ValueProvider.StaticValueProvider.of(url),\n+          ValueProvider.StaticValueProvider.of(userName),\n+          ValueProvider.StaticValueProvider.of(password));\n+    }\n+\n+    public static DataSourceConfiguration create(\n+        ValueProvider<String> url, ValueProvider<String> userName, ValueProvider<String> password) {\n+      checkArgument(url != null, \"url can not be null\");\n+      checkArgument(userName != null, \"userName can not be null\");\n+      checkArgument(password != null, \"password can not be null\");\n+\n+      return new AutoValue_InfluxDBIO_DataSourceConfiguration.Builder()\n+          .setUrl(url)\n+          .setUserName(userName)\n+          .setPassword(password)\n+          .build();\n+    }\n+\n+    public DataSourceConfiguration withUsername(String userName) {\n+      return withUsername(ValueProvider.StaticValueProvider.of(userName));\n+    }\n+\n+    public DataSourceConfiguration withUsername(ValueProvider<String> userName) {\n+      return builder().setUserName(userName).build();\n+    }\n+\n+    public DataSourceConfiguration withPassword(String password) {\n+      return withPassword(ValueProvider.StaticValueProvider.of(password));\n+    }\n+\n+    public DataSourceConfiguration withPassword(ValueProvider<String> password) {\n+      return builder().setPassword(password).build();\n+    }\n+\n+    public DataSourceConfiguration withUrl(String url) {\n+      return withPassword(ValueProvider.StaticValueProvider.of(url));\n+    }\n+\n+    public DataSourceConfiguration withUrl(ValueProvider<String> url) {\n+      return builder().setPassword(url).build();\n+    }\n+\n+    void populateDisplayData(DisplayData.Builder builder) {\n+\n+      builder.addIfNotNull(DisplayData.item(\"url\", url()));\n+      builder.addIfNotNull(DisplayData.item(\"userName\", userName()));\n+      builder.addIfNotNull(DisplayData.item(\"password\", password()));\n+    }\n+  }\n+\n+  private static class DataSourceProviderFromDataSourceConfiguration\n+      implements SerializableFunction<Void, DataSourceConfiguration>, HasDisplayData {\n+    private final DataSourceConfiguration config;\n+    private static DataSourceProviderFromDataSourceConfiguration instance;\n+\n+    private DataSourceProviderFromDataSourceConfiguration(DataSourceConfiguration config) {\n+      this.config = config;\n+    }\n+\n+    public static SerializableFunction<Void, DataSourceConfiguration> of(\n+        DataSourceConfiguration config) {\n+      if (instance == null) {\n+        instance = new DataSourceProviderFromDataSourceConfiguration(config);\n+      }\n+      return instance;\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      config.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public DataSourceConfiguration apply(Void input) {\n+      return config;\n+    }\n+  }\n+\n+  private static List<ShardInformation> getDBShardedInformation(\n+      String database,\n+      DataSourceConfiguration configuration,\n+      boolean sslInvalidHostNameAllowed,\n+      boolean sslEnabled) {\n+    String query = \"show shards\";\n+    DBShardInformation dbInfo = new DBShardInformation();\n+    try (InfluxDB connection =\n+        getConnection(configuration, sslInvalidHostNameAllowed, sslEnabled)) {\n+      QueryResult result = connection.query(new Query(query));", "originalCommit": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUxMDc4Nw==", "url": "https://github.com/apache/beam/pull/11459#discussion_r456510787", "bodyText": "Please, add Javadoc to this class.", "author": "aromanenko-dev", "createdAt": "2020-07-17T15:21:38Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/DBShardInformation.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.influxdb.dto.QueryResult.Series;\n+\n+class DBShardInformation {", "originalCommit": "1670ecb173d554f58e250265484e6a89ab23a5b9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUxMTg5Mw==", "url": "https://github.com/apache/beam/pull/11459#discussion_r456511893", "bodyText": "Please, add class Javadoc", "author": "aromanenko-dev", "createdAt": "2020-07-17T15:23:30Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/ShardInformation.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.List;\n+import java.util.Objects;\n+import org.joda.time.DateTime;\n+\n+class ShardInformation implements Comparable {", "originalCommit": "1670ecb173d554f58e250265484e6a89ab23a5b9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyNzgwNw==", "url": "https://github.com/apache/beam/pull/11459#discussion_r456527807", "bodyText": "The latest version is 2.19. Could you bump it?", "author": "aromanenko-dev", "createdAt": "2020-07-17T15:51:26Z", "path": "buildSrc/src/main/groovy/org/apache/beam/gradle/BeamModulePlugin.groovy", "diffHunk": "@@ -387,6 +387,7 @@ class BeamModulePlugin implements Plugin<Project> {\n     def guava_version = \"25.1-jre\"\n     def hadoop_version = \"2.8.5\"\n     def hamcrest_version = \"2.1\"\n+    def influxdb_version = \"2.17\"", "originalCommit": "1670ecb173d554f58e250265484e6a89ab23a5b9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUzMzM1MQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r456533351", "bodyText": "I believe it would be better to provide for user a way to create custom client with ClientProvider implementation (see KinesisIO.Read withAWSClientsProvider(AWSClientsProvider), for example).", "author": "aromanenko-dev", "createdAt": "2020-07-17T16:01:24Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,830 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>You have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database. InfluxDB line protocol reference\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNumOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {", "originalCommit": "1670ecb173d554f58e250265484e6a89ab23a5b9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUzNTk3OA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r456535978", "bodyText": "Does it just put a record into output queue when it will be flushed later?", "author": "aromanenko-dev", "createdAt": "2020-07-17T16:06:11Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,830 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>You have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database. InfluxDB line protocol reference\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNumOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkState(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkState(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkState(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(numOfBlocks)) {\n+                numOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> numOfBlocksValueIterator = numOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueIterator = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (numOfBlocksValueIterator.hasNext() && sizeOfBlocksValueIterator.hasNext()) {\n+        size = size + (numOfBlocksValueIterator.next() * sizeOfBlocksValueIterator.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        String retVal =\n+            String.format(\n+                \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+                spec.retentionPolicy(),\n+                String.join(\",\", spec.metrics()),\n+                spec.toDateTime(),\n+                spec.fromDateTime());\n+        return retVal;\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDbIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDbIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDbIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkState(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkState(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkState(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"numOfElementsToBatch\", numOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int numOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNumOfElementsToBatch(int numOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNumOfElementsToBatch(int numOfElementsToBatch) {\n+      return builder().setNumOfElementsToBatch(numOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn extends DoFn<String, Void> {\n+\n+      private final Write spec;\n+      private transient InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int numOfBatchPoints = spec.numOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(numOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element());", "originalCommit": "1670ecb173d554f58e250265484e6a89ab23a5b9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUzNjMzMA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r456536330", "bodyText": "Does it guarantee that all records were flushed properly?", "author": "aromanenko-dev", "createdAt": "2020-07-17T16:06:54Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,830 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>You have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database. InfluxDB line protocol reference\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNumOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkState(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkState(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkState(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(numOfBlocks)) {\n+                numOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> numOfBlocksValueIterator = numOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueIterator = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (numOfBlocksValueIterator.hasNext() && sizeOfBlocksValueIterator.hasNext()) {\n+        size = size + (numOfBlocksValueIterator.next() * sizeOfBlocksValueIterator.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        String retVal =\n+            String.format(\n+                \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+                spec.retentionPolicy(),\n+                String.join(\",\", spec.metrics()),\n+                spec.toDateTime(),\n+                spec.fromDateTime());\n+        return retVal;\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDbIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDbIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDbIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkState(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkState(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkState(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"numOfElementsToBatch\", numOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int numOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNumOfElementsToBatch(int numOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNumOfElementsToBatch(int numOfElementsToBatch) {\n+      return builder().setNumOfElementsToBatch(numOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn extends DoFn<String, Void> {\n+\n+      private final Write spec;\n+      private transient InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int numOfBatchPoints = spec.numOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(numOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element());\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        connection.flush();", "originalCommit": "1670ecb173d554f58e250265484e6a89ab23a5b9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5932a90028dd0ec7525d61cf07c37bd590e6be47", "url": "https://github.com/apache/beam/commit/5932a90028dd0ec7525d61cf07c37bd590e6be47", "message": "IT test", "committedDate": "2020-09-01T20:39:05Z", "type": "forcePushed"}, {"oid": "3471d89cec3c8a6ab44112c3edc058ca5cb48d1f", "url": "https://github.com/apache/beam/commit/3471d89cec3c8a6ab44112c3edc058ca5cb48d1f", "message": "BEAM-2546 Initial Commit", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "7bc05ebaf40bfde7213f6728fb2b8fde83b8dd86", "url": "https://github.com/apache/beam/commit/7bc05ebaf40bfde7213f6728fb2b8fde83b8dd86", "message": "Added yml file for IT test and related script", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "f33d91644762ae548d9019daf38966a00fd92ca6", "url": "https://github.com/apache/beam/commit/f33d91644762ae548d9019daf38966a00fd92ca6", "message": "Checkstyles, clean the build file and removed unused codes", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "308a41b15d627b5463a58515d719ac53f969f6d7", "url": "https://github.com/apache/beam/commit/308a41b15d627b5463a58515d719ac53f969f6d7", "message": "BEAM-2546 Initial Commit", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "be45fa20ec3d46b1c9c92960e362be65be77ddd5", "url": "https://github.com/apache/beam/commit/be45fa20ec3d46b1c9c92960e362be65be77ddd5", "message": "Checkstyles, clean the build file and removed unused codes", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "2a8e293f0125cc283580cd7d5e5000886b0bf876", "url": "https://github.com/apache/beam/commit/2a8e293f0125cc283580cd7d5e5000886b0bf876", "message": "adding influxdb in settings", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "136ae5f86959e361da6ff8a5c4b919cc95435586", "url": "https://github.com/apache/beam/commit/136ae5f86959e361da6ff8a5c4b919cc95435586", "message": "Addressing the comments", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "2ba23192a8a8980317065ea8922972e69df799ac", "url": "https://github.com/apache/beam/commit/2ba23192a8a8980317065ea8922972e69df799ac", "message": "Apply spotlessApply check", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "2b6360e7045b2492e12576f03f8766db2d5bdae9", "url": "https://github.com/apache/beam/commit/2b6360e7045b2492e12576f03f8766db2d5bdae9", "message": "Removing duplicate entry", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "542c1aaa1eb6f03992d73a8316c849a0cbcb8918", "url": "https://github.com/apache/beam/commit/542c1aaa1eb6f03992d73a8316c849a0cbcb8918", "message": "Update influxdb.yml", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "19ace7cdc99419c360cac974baceb45cbd0e73e6", "url": "https://github.com/apache/beam/commit/19ace7cdc99419c360cac974baceb45cbd0e73e6", "message": "Update build.gradle", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "0c8d2aafeae0e2fabcfc019dd45addaeef20eef3", "url": "https://github.com/apache/beam/commit/0c8d2aafeae0e2fabcfc019dd45addaeef20eef3", "message": "Addressing the comments", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "82628b8d4f277a6411930454c918762637870094", "url": "https://github.com/apache/beam/commit/82628b8d4f277a6411930454c918762637870094", "message": "Performance test for InfluxDB", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "c395a24b440a77d701a9aa0eb44e51f1ab8357d0", "url": "https://github.com/apache/beam/commit/c395a24b440a77d701a9aa0eb44e51f1ab8357d0", "message": "spotlessCheck", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "08497b15cce444a202c847e292bb9958ed834776", "url": "https://github.com/apache/beam/commit/08497b15cce444a202c847e292bb9958ed834776", "message": "Adding external dependency in BeamModulePlugin", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "248381901aae31b1609dec5651a4f9174ddd33b7", "url": "https://github.com/apache/beam/commit/248381901aae31b1609dec5651a4f9174ddd33b7", "message": "Formatting BeamModulePlugin.groovy", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "500c7f685e3c6ede8a34df55ff5fe4d8492a4003", "url": "https://github.com/apache/beam/commit/500c7f685e3c6ede8a34df55ff5fe4d8492a4003", "message": "adding influxdb in settings", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "605c48acfede19cca6af2a355351a40bb0efaf0f", "url": "https://github.com/apache/beam/commit/605c48acfede19cca6af2a355351a40bb0efaf0f", "message": "Removing duplicate entry", "committedDate": "2020-09-03T13:00:40Z", "type": "commit"}, {"oid": "d14ba125acd108c506b4700febbd9e086e5fc0df", "url": "https://github.com/apache/beam/commit/d14ba125acd108c506b4700febbd9e086e5fc0df", "message": "Merging conflicts", "committedDate": "2020-09-03T13:00:41Z", "type": "commit"}, {"oid": "25a69101934b54a593a37a6d1774080ac41fc690", "url": "https://github.com/apache/beam/commit/25a69101934b54a593a37a6d1774080ac41fc690", "message": "spotlessCheck", "committedDate": "2020-09-03T13:00:41Z", "type": "commit"}, {"oid": "b68363b789471158237eff699b608bf448e8119c", "url": "https://github.com/apache/beam/commit/b68363b789471158237eff699b608bf448e8119c", "message": "Update influxdb version", "committedDate": "2020-09-03T13:00:41Z", "type": "commit"}, {"oid": "a4358eac7bbed0faefbae81a18195271ede34f72", "url": "https://github.com/apache/beam/commit/a4358eac7bbed0faefbae81a18195271ede34f72", "message": "Resolving merge conflicts", "committedDate": "2020-09-03T13:00:41Z", "type": "commit"}, {"oid": "1fb4ab38db94e4e4c020e21a3b472df6e6b6478a", "url": "https://github.com/apache/beam/commit/1fb4ab38db94e4e4c020e21a3b472df6e6b6478a", "message": "IT test", "committedDate": "2020-09-03T13:00:41Z", "type": "commit"}, {"oid": "6828ac9993ec0aa11f92ceaf4b58abf62c2826b9", "url": "https://github.com/apache/beam/commit/6828ac9993ec0aa11f92ceaf4b58abf62c2826b9", "message": "additional IT test and null checks", "committedDate": "2020-09-03T13:00:41Z", "type": "commit"}, {"oid": "6ee9a269dcbb988f5b6aeb44546abd10bf4d3282", "url": "https://github.com/apache/beam/commit/6ee9a269dcbb988f5b6aeb44546abd10bf4d3282", "message": "infrastructure setup and teardown", "committedDate": "2020-09-03T13:00:41Z", "type": "commit"}, {"oid": "598131a299283129d110099a1c54cf3e5ef1ac61", "url": "https://github.com/apache/beam/commit/598131a299283129d110099a1c54cf3e5ef1ac61", "message": "Apply Whitespacelint", "committedDate": "2020-09-03T13:00:41Z", "type": "commit"}, {"oid": "b84df0a7b81f46236489e2a02006f76e4f282c13", "url": "https://github.com/apache/beam/commit/b84df0a7b81f46236489e2a02006f76e4f282c13", "message": "More logging for missing next work index. (#12718)", "committedDate": "2020-09-04T00:10:38Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAxODk2Nw==", "url": "https://github.com/apache/beam/pull/11459#discussion_r485018967", "bodyText": "nit: InfluxDbIO.read()", "author": "aromanenko-dev", "createdAt": "2020-09-08T15:41:39Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")", "originalCommit": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIwMDE4MA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r492200180", "bodyText": "Still not fixed, missing an \"IO\" suffix in the \"InfluxDB\" - it has to be InfluxDbIO", "author": "aromanenko-dev", "createdAt": "2020-09-21T16:40:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAxODk2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAxOTE2MA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r485019160", "bodyText": "nit: InfluxDbIO.write()", "author": "aromanenko-dev", "createdAt": "2020-09-08T15:41:54Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")", "originalCommit": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIwMDQzMA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r492200430", "bodyText": "The same - missing an \"IO\" suffix in the \"InfluxDB\" - it has to be InfluxDbIO", "author": "aromanenko-dev", "createdAt": "2020-09-21T16:40:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAxOTE2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAyMTM4OA==", "url": "https://github.com/apache/beam/pull/11459#discussion_r485021388", "bodyText": "nit: DEFAULT_RETENTION_POLICY since it's a constant string", "author": "aromanenko-dev", "createdAt": "2020-09-08T15:45:18Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";", "originalCommit": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAyMjQwNg==", "url": "https://github.com/apache/beam/pull/11459#discussion_r485022406", "bodyText": "Are these real or fake credentials?", "author": "aromanenko-dev", "createdAt": "2020-09-08T15:46:51Z", "path": ".test-infra/kubernetes/influxdb/influxdb.yml", "diffHunk": "@@ -0,0 +1,76 @@\n+#    Licensed to the Apache Software Foundation (ASF) under one or more\n+#    contributor license agreements.  See the NOTICE file distributed with\n+#    this work for additional information regarding copyright ownership.\n+#    The ASF licenses this file to You under the Apache License, Version 2.0\n+#    (the \"License\"); you may not use this file except in compliance with\n+#    the License.  You may obtain a copy of the License at\n+#\n+#       http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#    Unless required by applicable law or agreed to in writing, software\n+#    distributed under the License is distributed on an \"AS IS\" BASIS,\n+#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#    See the License for the specific language governing permissions and\n+#    limitations under the License.\n+\n+apiVersion: v1\n+kind: Secret\n+metadata:\n+  name: influxdb-creds\n+data:\n+  INFLUXDB_USER: c3VwZXJzYWRtaW4=\n+  INFLUXDB_USER_PASSWORD: c3VwZXJzZWNyZXRwYXNzd29yZA==", "originalCommit": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDI5NzExMQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r490297111", "bodyText": "Base64 encoded values for credentials. It is used to instantiate the container and used to test integration test.", "author": "bipinupd", "createdAt": "2020-09-17T14:34:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAyMjQwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAyNTMzNQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r485025335", "bodyText": "nit: remove  an in the end of the sentence.", "author": "aromanenko-dev", "createdAt": "2020-09-08T15:51:07Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>", "originalCommit": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAzNDcwMg==", "url": "https://github.com/apache/beam/pull/11459#discussion_r485034702", "bodyText": "Please, keep write() method without arguments for consistency with other IOs and add withDataSourceConfiguration(DataSourceConfiguration conf), which will be required to configure data source, and withDatabase(String) to set database name (see JdbcIO.write() as an example).\nSo, for the user it would be something like:\nInfluxDbIO.write().withDataSourceConfiguration(DataSourceConfiguration.create(...)).withDatabase(\"...\");", "author": "aromanenko-dev", "createdAt": "2020-09-08T16:04:59Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {", "originalCommit": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAzNzc4OQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r485037789", "bodyText": "The same recommendation as for write() method above - please, make read() without arguments.", "author": "aromanenko-dev", "createdAt": "2020-09-08T16:09:54Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .setDisableCertificateValidation(false)\n+        .setBatchSize(DEFAULT_BUFFER_LIMIT)\n+        .setConsistencyLevel(ConsistencyLevel.QUORUM)\n+        .build();\n+  }\n+\n+  public static Read read(String influxDbUrl, String username, String password, String database) {", "originalCommit": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MDY1OQ==", "url": "https://github.com/apache/beam/pull/11459#discussion_r485040659", "bodyText": "Do we really want to display credentials in plain text mode?", "author": "aromanenko-dev", "createdAt": "2020-09-08T16:14:33Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .setDisableCertificateValidation(false)\n+        .setBatchSize(DEFAULT_BUFFER_LIMIT)\n+        .setConsistencyLevel(ConsistencyLevel.QUORUM)\n+        .build();\n+  }\n+\n+  public static Read read(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setDisableCertificateValidation(false)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .build();\n+  }\n+\n+  ///////////////////////// Read  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+\n+  /**\n+   * A {@link PTransform} to read from InfluxDB metric or data related to query. See {@link\n+   * InfluxDB} for more information on usage and configuration.\n+   */\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract String retentionPolicy();\n+\n+    abstract String database();\n+\n+    abstract @Nullable String query();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract @Nullable String metric();\n+\n+    abstract @Nullable String fromDateTime();\n+\n+    abstract @Nullable String toDateTime();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(String toDateTime);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setFromDateTime(String fromDateTime);\n+\n+      abstract Builder setMetric(@Nullable String metric);\n+\n+      abstract Read build();\n+    }\n+    /** Read metric data till the toDateTime. * */\n+    public Read withToDateTime(String toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+    /** Read metric data from the fromDateTime. * */\n+    public Read withFromDateTime(String fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+    /** Sets the metric to use. * */\n+    public Read withMetric(@Nullable String metric) {\n+      return builder().setMetric(metric).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Read withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+    /** Sets the query to use. * */\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      dataSourceConfiguration().populateDisplayData(builder);\n+      builder.addIfNotNull(DisplayData.item(\"metric\", metric()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"fromDateTime\", fromDateTime()));\n+      builder.addIfNotNull(DisplayData.item(\"toDateTime\", toDateTime()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"disableCertificateValidation\", disableCertificateValidation()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+    }\n+  }\n+  /** A InfluxDb {@link BoundedSource} reading {@link String} from a given instance. */\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        String query = spec.query();\n+        final String db = spec.database();\n+        if (query == null) {\n+          checkState(spec.metric() != null, \"Both query and metrics are empty\");\n+          query = String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+        }\n+        QueryResult result = connection.query(new Query(\"EXPLAIN \" + query, db));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(numOfBlocks)) {\n+                numOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> numOfBlocksValueIterator = numOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueIterator = sizeOfBlocksValue.iterator();\n+      long size = 0L;\n+      while (numOfBlocksValueIterator.hasNext() && sizeOfBlocksValueIterator.hasNext()) {\n+        size = size + (numOfBlocksValueIterator.next() * sizeOfBlocksValueIterator.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) throws Exception {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(), spec.dataSourceConfiguration(), spec.disableCertificateValidation());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      String metric = spec.metric();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          sources.add(\n+              new InfluxDBSource(\n+                  spec.withMetric(metric)\n+                      .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                      .withToDateTime(sInfo.getStartTime())\n+                      .withFromDateTime(sInfo.getEndTime())));\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    String query = spec.query();\n+    if (query == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        String retVal =\n+            String.format(\n+                \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+                spec.retentionPolicy(), spec.metric(), spec.toDateTime(), spec.fromDateTime());\n+        return retVal;\n+      } else {\n+        return String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+      }\n+    } else {\n+      return query;\n+    }\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDbIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List<Object> current;\n+\n+    public BoundedInfluxDbReader(InfluxDbIO.InfluxDBSource source) {\n+      this.source = source;\n+      this.seriesIterator = Collections.emptyIterator();\n+      this.resultIterator = Collections.emptyIterator();\n+      this.valuesIterator = Collections.emptyIterator();\n+      this.current = Collections.EMPTY_LIST;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDbIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        final String db = spec.database();\n+        influxDB.setDatabase(spec.database());\n+        influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        String query = getQueryToRun(spec);\n+        final QueryResult queryResult = influxDB.query(new Query(query, db));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          Result result = resultIterator.next();\n+          if (result != null && result.getSeries() != null) {\n+            seriesIterator = result.getSeries().iterator();\n+          }\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource<String> getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  /** A {@link PTransform} to write to a InfluxDB datasource. */\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkState(\n+          checkDatabase(database(), dataSourceConfiguration(), disableCertificateValidation()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"batchSize\", batchSize()));\n+      builder.addIfNotNull(DisplayData.item(\"consistencyLevel\", consistencyLevel().value()));\n+    }\n+\n+    abstract String database();\n+\n+    abstract String retentionPolicy();\n+\n+    abstract int batchSize();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract ConsistencyLevel consistencyLevel();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setBatchSize(int batchSize);\n+\n+      abstract Builder setConsistencyLevel(ConsistencyLevel consistencyLevel);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+    /** Number of elements to batch. * */\n+    public Write withBatchSize(int batchSize) {\n+      return builder().setBatchSize(batchSize).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Write withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+    /**\n+     * Sets the consistency level to use. ALL(\"all\") Write succeeds only if write reached all\n+     * cluster members. ANY(\"any\") Write succeeds if write reached at least one cluster members.\n+     * ONE(\"one\") Write succeeds if write reached at least one cluster members. QUORUM(\"quorum\")\n+     * Write succeeds only if write reached a quorum of cluster members.\n+     */\n+    public Write withConsistencyLevel(ConsistencyLevel consistencyLevel) {\n+      return builder().setConsistencyLevel(consistencyLevel).build();\n+    }\n+\n+    static class InfluxWriterFn extends DoFn<String, Void> {\n+\n+      private final Write spec;\n+      private List<String> batch;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @StartBundle\n+      public void startBundle() {\n+        batch = new ArrayList<>();\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext context) {\n+        batch.add(context.element());\n+        if (batch.size() >= spec.batchSize()) {\n+          flush();\n+        }\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        flush();\n+      }\n+\n+      private void flush() {\n+        if (batch.isEmpty()) {\n+          return;\n+        }\n+        try (InfluxDB connection =\n+            getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+          connection.setDatabase(spec.database());\n+          connection.enableBatch();\n+          connection.setConsistency(spec.consistencyLevel());\n+          connection.write(batch);\n+        } catch (InfluxDBException exception) {\n+          throw exception;\n+        }\n+        batch.clear();\n+      }\n+    }\n+  }\n+\n+  /** A POJO describing a DataSourceConfiguration such as URL, userName and password. */\n+  @AutoValue\n+  public abstract static class DataSourceConfiguration implements Serializable {\n+\n+    abstract ValueProvider<String> url();\n+\n+    abstract ValueProvider<String> userName();\n+\n+    abstract ValueProvider<String> password();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+\n+      abstract Builder setUrl(ValueProvider<String> url);\n+\n+      abstract Builder setUserName(ValueProvider<String> userName);\n+\n+      abstract Builder setPassword(ValueProvider<String> password);\n+\n+      abstract DataSourceConfiguration build();\n+    }\n+\n+    public static DataSourceConfiguration create(\n+        ValueProvider<String> url, ValueProvider<String> userName, ValueProvider<String> password) {\n+      return new AutoValue_InfluxDbIO_DataSourceConfiguration.Builder()\n+          .setUrl(url)\n+          .setUserName(userName)\n+          .setPassword(password)\n+          .build();\n+    }\n+\n+    void populateDisplayData(DisplayData.Builder builder) {\n+      builder.add(DisplayData.item(\"url\", url()));\n+      builder.add(DisplayData.item(\"userName\", userName()));\n+      builder.add(DisplayData.item(\"password\", password()));", "originalCommit": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIwNjk1Mw==", "url": "https://github.com/apache/beam/pull/11459#discussion_r492206953", "bodyText": "Please, remove credentials from displayed data", "author": "aromanenko-dev", "createdAt": "2020-09-21T16:51:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MDY1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MjkxMw==", "url": "https://github.com/apache/beam/pull/11459#discussion_r485042913", "bodyText": "What s states for? Please, name it explicitly.", "author": "aromanenko-dev", "createdAt": "2020-09-08T16:17:56Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .setDisableCertificateValidation(false)\n+        .setBatchSize(DEFAULT_BUFFER_LIMIT)\n+        .setConsistencyLevel(ConsistencyLevel.QUORUM)\n+        .build();\n+  }\n+\n+  public static Read read(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setDisableCertificateValidation(false)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .build();\n+  }\n+\n+  ///////////////////////// Read  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+\n+  /**\n+   * A {@link PTransform} to read from InfluxDB metric or data related to query. See {@link\n+   * InfluxDB} for more information on usage and configuration.\n+   */\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract String retentionPolicy();\n+\n+    abstract String database();\n+\n+    abstract @Nullable String query();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract @Nullable String metric();\n+\n+    abstract @Nullable String fromDateTime();\n+\n+    abstract @Nullable String toDateTime();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(String toDateTime);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setFromDateTime(String fromDateTime);\n+\n+      abstract Builder setMetric(@Nullable String metric);\n+\n+      abstract Read build();\n+    }\n+    /** Read metric data till the toDateTime. * */\n+    public Read withToDateTime(String toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+    /** Read metric data from the fromDateTime. * */\n+    public Read withFromDateTime(String fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+    /** Sets the metric to use. * */\n+    public Read withMetric(@Nullable String metric) {\n+      return builder().setMetric(metric).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Read withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+    /** Sets the query to use. * */\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      dataSourceConfiguration().populateDisplayData(builder);\n+      builder.addIfNotNull(DisplayData.item(\"metric\", metric()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"fromDateTime\", fromDateTime()));\n+      builder.addIfNotNull(DisplayData.item(\"toDateTime\", toDateTime()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"disableCertificateValidation\", disableCertificateValidation()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+    }\n+  }\n+  /** A InfluxDb {@link BoundedSource} reading {@link String} from a given instance. */\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        String query = spec.query();\n+        final String db = spec.database();\n+        if (query == null) {\n+          checkState(spec.metric() != null, \"Both query and metrics are empty\");\n+          query = String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+        }\n+        QueryResult result = connection.query(new Query(\"EXPLAIN \" + query, db));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();", "originalCommit": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NzI5Mw==", "url": "https://github.com/apache/beam/pull/11459#discussion_r485047293", "bodyText": "nit: rename Result result", "author": "aromanenko-dev", "createdAt": "2020-09-08T16:25:11Z", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .setDisableCertificateValidation(false)\n+        .setBatchSize(DEFAULT_BUFFER_LIMIT)\n+        .setConsistencyLevel(ConsistencyLevel.QUORUM)\n+        .build();\n+  }\n+\n+  public static Read read(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setDisableCertificateValidation(false)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .build();\n+  }\n+\n+  ///////////////////////// Read  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+\n+  /**\n+   * A {@link PTransform} to read from InfluxDB metric or data related to query. See {@link\n+   * InfluxDB} for more information on usage and configuration.\n+   */\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract String retentionPolicy();\n+\n+    abstract String database();\n+\n+    abstract @Nullable String query();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract @Nullable String metric();\n+\n+    abstract @Nullable String fromDateTime();\n+\n+    abstract @Nullable String toDateTime();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(String toDateTime);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setFromDateTime(String fromDateTime);\n+\n+      abstract Builder setMetric(@Nullable String metric);\n+\n+      abstract Read build();\n+    }\n+    /** Read metric data till the toDateTime. * */\n+    public Read withToDateTime(String toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+    /** Read metric data from the fromDateTime. * */\n+    public Read withFromDateTime(String fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+    /** Sets the metric to use. * */\n+    public Read withMetric(@Nullable String metric) {\n+      return builder().setMetric(metric).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Read withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+    /** Sets the query to use. * */\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      dataSourceConfiguration().populateDisplayData(builder);\n+      builder.addIfNotNull(DisplayData.item(\"metric\", metric()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"fromDateTime\", fromDateTime()));\n+      builder.addIfNotNull(DisplayData.item(\"toDateTime\", toDateTime()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"disableCertificateValidation\", disableCertificateValidation()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+    }\n+  }\n+  /** A InfluxDb {@link BoundedSource} reading {@link String} from a given instance. */\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        String query = spec.query();\n+        final String db = spec.database();\n+        if (query == null) {\n+          checkState(spec.metric() != null, \"Both query and metrics are empty\");\n+          query = String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+        }\n+        QueryResult result = connection.query(new Query(\"EXPLAIN \" + query, db));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(numOfBlocks)) {\n+                numOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> numOfBlocksValueIterator = numOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueIterator = sizeOfBlocksValue.iterator();\n+      long size = 0L;\n+      while (numOfBlocksValueIterator.hasNext() && sizeOfBlocksValueIterator.hasNext()) {\n+        size = size + (numOfBlocksValueIterator.next() * sizeOfBlocksValueIterator.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) throws Exception {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(), spec.dataSourceConfiguration(), spec.disableCertificateValidation());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      String metric = spec.metric();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          sources.add(\n+              new InfluxDBSource(\n+                  spec.withMetric(metric)\n+                      .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                      .withToDateTime(sInfo.getStartTime())\n+                      .withFromDateTime(sInfo.getEndTime())));\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    String query = spec.query();\n+    if (query == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        String retVal =\n+            String.format(\n+                \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+                spec.retentionPolicy(), spec.metric(), spec.toDateTime(), spec.fromDateTime());\n+        return retVal;\n+      } else {\n+        return String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+      }\n+    } else {\n+      return query;\n+    }\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDbIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List<Object> current;\n+\n+    public BoundedInfluxDbReader(InfluxDbIO.InfluxDBSource source) {\n+      this.source = source;\n+      this.seriesIterator = Collections.emptyIterator();\n+      this.resultIterator = Collections.emptyIterator();\n+      this.valuesIterator = Collections.emptyIterator();\n+      this.current = Collections.EMPTY_LIST;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDbIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        final String db = spec.database();\n+        influxDB.setDatabase(spec.database());\n+        influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        String query = getQueryToRun(spec);\n+        final QueryResult queryResult = influxDB.query(new Query(query, db));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          Result result = resultIterator.next();\n+          if (result != null && result.getSeries() != null) {\n+            seriesIterator = result.getSeries().iterator();\n+          }\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource<String> getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  /** A {@link PTransform} to write to a InfluxDB datasource. */\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkState(\n+          checkDatabase(database(), dataSourceConfiguration(), disableCertificateValidation()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"batchSize\", batchSize()));\n+      builder.addIfNotNull(DisplayData.item(\"consistencyLevel\", consistencyLevel().value()));\n+    }\n+\n+    abstract String database();\n+\n+    abstract String retentionPolicy();\n+\n+    abstract int batchSize();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract ConsistencyLevel consistencyLevel();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setBatchSize(int batchSize);\n+\n+      abstract Builder setConsistencyLevel(ConsistencyLevel consistencyLevel);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+    /** Number of elements to batch. * */\n+    public Write withBatchSize(int batchSize) {\n+      return builder().setBatchSize(batchSize).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Write withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+    /**\n+     * Sets the consistency level to use. ALL(\"all\") Write succeeds only if write reached all\n+     * cluster members. ANY(\"any\") Write succeeds if write reached at least one cluster members.\n+     * ONE(\"one\") Write succeeds if write reached at least one cluster members. QUORUM(\"quorum\")\n+     * Write succeeds only if write reached a quorum of cluster members.\n+     */\n+    public Write withConsistencyLevel(ConsistencyLevel consistencyLevel) {\n+      return builder().setConsistencyLevel(consistencyLevel).build();\n+    }\n+\n+    static class InfluxWriterFn extends DoFn<String, Void> {\n+\n+      private final Write spec;\n+      private List<String> batch;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @StartBundle\n+      public void startBundle() {\n+        batch = new ArrayList<>();\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext context) {\n+        batch.add(context.element());\n+        if (batch.size() >= spec.batchSize()) {\n+          flush();\n+        }\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        flush();\n+      }\n+\n+      private void flush() {\n+        if (batch.isEmpty()) {\n+          return;\n+        }\n+        try (InfluxDB connection =\n+            getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+          connection.setDatabase(spec.database());\n+          connection.enableBatch();\n+          connection.setConsistency(spec.consistencyLevel());\n+          connection.write(batch);\n+        } catch (InfluxDBException exception) {\n+          throw exception;\n+        }\n+        batch.clear();\n+      }\n+    }\n+  }\n+\n+  /** A POJO describing a DataSourceConfiguration such as URL, userName and password. */\n+  @AutoValue\n+  public abstract static class DataSourceConfiguration implements Serializable {\n+\n+    abstract ValueProvider<String> url();\n+\n+    abstract ValueProvider<String> userName();\n+\n+    abstract ValueProvider<String> password();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+\n+      abstract Builder setUrl(ValueProvider<String> url);\n+\n+      abstract Builder setUserName(ValueProvider<String> userName);\n+\n+      abstract Builder setPassword(ValueProvider<String> password);\n+\n+      abstract DataSourceConfiguration build();\n+    }\n+\n+    public static DataSourceConfiguration create(\n+        ValueProvider<String> url, ValueProvider<String> userName, ValueProvider<String> password) {\n+      return new AutoValue_InfluxDbIO_DataSourceConfiguration.Builder()\n+          .setUrl(url)\n+          .setUserName(userName)\n+          .setPassword(password)\n+          .build();\n+    }\n+\n+    void populateDisplayData(DisplayData.Builder builder) {\n+      builder.add(DisplayData.item(\"url\", url()));\n+      builder.add(DisplayData.item(\"userName\", userName()));\n+      builder.add(DisplayData.item(\"password\", password()));\n+    }\n+  }\n+\n+  private static List<ShardInformation> getDBShardedInformation(\n+      String database, DataSourceConfiguration configuration, boolean disableCertificateValidation)\n+      throws Exception {\n+    String query = \"SHOW SHARDS\";\n+    DBShardInformation dbInfo = new DBShardInformation();\n+    try (InfluxDB connection = getConnection(configuration, disableCertificateValidation)) {\n+      QueryResult result = connection.query(new Query(query));\n+      List<Result> results = result.getResults();\n+      for (Result res : results) {", "originalCommit": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "4b81f1b57c0fa9bbceeed93e016af21e1cd04a67", "url": "https://github.com/apache/beam/commit/4b81f1b57c0fa9bbceeed93e016af21e1cd04a67", "message": "Addressing the comments", "committedDate": "2020-09-17T14:29:12Z", "type": "commit"}, {"oid": "4b81f1b57c0fa9bbceeed93e016af21e1cd04a67", "url": "https://github.com/apache/beam/commit/4b81f1b57c0fa9bbceeed93e016af21e1cd04a67", "message": "Addressing the comments", "committedDate": "2020-09-17T14:29:12Z", "type": "forcePushed"}, {"oid": "70b073fa91ebf2af6fa2ef42b3a96b3a77257832", "url": "https://github.com/apache/beam/commit/70b073fa91ebf2af6fa2ef42b3a96b3a77257832", "message": "InfluxDBIO", "committedDate": "2020-09-17T14:37:04Z", "type": "commit"}, {"oid": "ddc47edd0d5455824f02c8ecbce3e8c1d84fde5a", "url": "https://github.com/apache/beam/commit/ddc47edd0d5455824f02c8ecbce3e8c1d84fde5a", "message": "InfluxDBIO spotlessApply", "committedDate": "2020-09-17T14:39:31Z", "type": "commit"}, {"oid": "fbd981c2b14e08da6df639b8d1d24adb2cabfefe", "url": "https://github.com/apache/beam/commit/fbd981c2b14e08da6df639b8d1d24adb2cabfefe", "message": "Removing display for password and typos in docs", "committedDate": "2020-09-21T17:47:09Z", "type": "commit"}]}