{"pr_number": 11538, "pr_title": "[BEAM-9831] Improve UX for HL7v2IO", "pr_createdAt": "2020-04-27T18:26:42Z", "pr_url": "https://github.com/apache/beam/pull/11538", "timeline": [{"oid": "f47a9774755032d02575f7657d5843916f47dac9", "url": "https://github.com/apache/beam/commit/f47a9774755032d02575f7657d5843916f47dac9", "message": "Patches for HL7v2IO\n\n* Use TestPipeline in ITs\n* Drop schematized data before calling message ingest (should be output only) to help pipelines that read/write from/to two HL7v2 stores\n* Make HL7v2MessageCoder constructor public", "committedDate": "2020-04-17T19:17:20Z", "type": "commit"}, {"oid": "55ab1818c2399ad56be585ccbc30f882c1b32693", "url": "https://github.com/apache/beam/commit/55ab1818c2399ad56be585ccbc30f882c1b32693", "message": "block on run", "committedDate": "2020-04-17T20:15:36Z", "type": "commit"}, {"oid": "96d8e93032c3f61373012bea02c3febe53312c81", "url": "https://github.com/apache/beam/commit/96d8e93032c3f61373012bea02c3febe53312c81", "message": "add sleep to avoid flakiness due to asyncronous HL7v2 indexing", "committedDate": "2020-04-17T20:45:25Z", "type": "commit"}, {"oid": "1bbaea69187fe5f2a0e0f04e1af27f5528bb2f2a", "url": "https://github.com/apache/beam/commit/1bbaea69187fe5f2a0e0f04e1af27f5528bb2f2a", "message": "E2E integration test", "committedDate": "2020-04-17T23:51:33Z", "type": "commit"}, {"oid": "6ede0a8e60d6e7557a15a41d5baf4aaadbe784a8", "url": "https://github.com/apache/beam/commit/6ede0a8e60d6e7557a15a41d5baf4aaadbe784a8", "message": "fix merge issue", "committedDate": "2020-04-17T23:55:27Z", "type": "commit"}, {"oid": "40a23ef7efd9706e3b5f33c35b22213f84963e50", "url": "https://github.com/apache/beam/commit/40a23ef7efd9706e3b5f33c35b22213f84963e50", "message": "reconcile double sleeping", "committedDate": "2020-04-17T23:57:48Z", "type": "commit"}, {"oid": "194cf3e719b778ff5a4baf737134b00b8c601591", "url": "https://github.com/apache/beam/commit/194cf3e719b778ff5a4baf737134b00b8c601591", "message": "improve error hanlding", "committedDate": "2020-04-20T23:42:17Z", "type": "commit"}, {"oid": "7af97ddd2cec2f05faeaf3b49d7b495b72e2d7e4", "url": "https://github.com/apache/beam/commit/7af97ddd2cec2f05faeaf3b49d7b495b72e2d7e4", "message": "improve error handling", "committedDate": "2020-04-20T23:44:49Z", "type": "commit"}, {"oid": "6f86186e41c23a18d51036f24bb548d88efeac50", "url": "https://github.com/apache/beam/commit/6f86186e41c23a18d51036f24bb548d88efeac50", "message": "fix docs typo", "committedDate": "2020-04-21T00:19:30Z", "type": "commit"}, {"oid": "766e6fd64af3d17b75e551f1e25dd1aad428e018", "url": "https://github.com/apache/beam/commit/766e6fd64af3d17b75e551f1e25dd1aad428e018", "message": "add latency distribution metrics", "committedDate": "2020-04-22T20:02:10Z", "type": "commit"}, {"oid": "e989ec4601df842d377bdc15c53a1324a474de3f", "url": "https://github.com/apache/beam/commit/e989ec4601df842d377bdc15c53a1324a474de3f", "message": "Merge branch 'metrics/HL7v2IO' into patch/HL7v2IO", "committedDate": "2020-04-22T20:03:38Z", "type": "commit"}, {"oid": "16399f1494e2071cee97fadaf56dc21a9eefbed3", "url": "https://github.com/apache/beam/commit/16399f1494e2071cee97fadaf56dc21a9eefbed3", "message": "remove unused imports", "committedDate": "2020-04-22T21:41:01Z", "type": "commit"}, {"oid": "9ef3a33c532535873ee8029a27e2656929ac2e1f", "url": "https://github.com/apache/beam/commit/9ef3a33c532535873ee8029a27e2656929ac2e1f", "message": "Merge branch 'metrics/HL7v2IO' into patch/HL7v2IO", "committedDate": "2020-04-22T22:16:06Z", "type": "commit"}, {"oid": "c8b576636f99f006c5738481ff72f06c576c46d0", "url": "https://github.com/apache/beam/commit/c8b576636f99f006c5738481ff72f06c576c46d0", "message": "ingest only data and labels", "committedDate": "2020-04-22T22:21:16Z", "type": "commit"}, {"oid": "50ba3d8da29f4d4522b29468aa01b800ad96b5e9", "url": "https://github.com/apache/beam/commit/50ba3d8da29f4d4522b29468aa01b800ad96b5e9", "message": "fix comment", "committedDate": "2020-04-22T22:26:08Z", "type": "commit"}, {"oid": "461b7cd79ece7cf27fb24032fb89cb3616d439ef", "url": "https://github.com/apache/beam/commit/461b7cd79ece7cf27fb24032fb89cb3616d439ef", "message": "call spliterator directly, use page size 1000", "committedDate": "2020-04-22T22:55:14Z", "type": "commit"}, {"oid": "b2602b477a8ebe535fe3060d643cbef45f0e2892", "url": "https://github.com/apache/beam/commit/b2602b477a8ebe535fe3060d643cbef45f0e2892", "message": "output elements more eagerly in ListHL72MessageFn", "committedDate": "2020-04-22T23:29:10Z", "type": "commit"}, {"oid": "1503fd4600654064e608e3c98c6e9e9b0de20560", "url": "https://github.com/apache/beam/commit/1503fd4600654064e608e3c98c6e9e9b0de20560", "message": "eagerly emit data from early pages", "committedDate": "2020-04-23T23:43:42Z", "type": "commit"}, {"oid": "5f9bad7c1c9df7c004f0f4f67185a3d5099a351f", "url": "https://github.com/apache/beam/commit/5f9bad7c1c9df7c004f0f4f67185a3d5099a351f", "message": "Optimization of Listing and Stablization of ITs\n\n* allow HL7v2 Message listing to emit early panes rather than waiting on pagination of all list results\n* add EBO on HL7v2 Message listing reaching a certain expected length in ITs to account for async indexing BEAM-9779", "committedDate": "2020-04-24T00:51:47Z", "type": "commit"}, {"oid": "fc3a8443e7a88cfb46b18b81d6a4a72b880420cd", "url": "https://github.com/apache/beam/commit/fc3a8443e7a88cfb46b18b81d6a4a72b880420cd", "message": "implement improvements in BEAM-9831", "committedDate": "2020-04-27T18:21:35Z", "type": "commit"}, {"oid": "ea2f85e012134be5c1733c170e7b11aea5c952a7", "url": "https://github.com/apache/beam/commit/ea2f85e012134be5c1733c170e7b11aea5c952a7", "message": "use HL7V2_INDEXING_TIMEOUT_MINUTES everywhere", "committedDate": "2020-04-27T18:33:38Z", "type": "commit"}, {"oid": "402950d0ba4ef45e60d187845df511ea5479ffe3", "url": "https://github.com/apache/beam/commit/402950d0ba4ef45e60d187845df511ea5479ffe3", "message": "make HL7v2Message constructor public", "committedDate": "2020-04-27T21:39:14Z", "type": "commit"}, {"oid": "454f1ef7d920a799db10e034d0fb430399fa5f5c", "url": "https://github.com/apache/beam/commit/454f1ef7d920a799db10e034d0fb430399fa5f5c", "message": "Merge branch 'master' into optimization/HL7v2IO", "committedDate": "2020-04-28T16:30:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjA2MDM5Mw==", "url": "https://github.com/apache/beam/pull/11538#discussion_r416060393", "bodyText": "requestTime?", "author": "pabloem", "createdAt": "2020-04-27T18:44:16Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -475,7 +497,14 @@ public void initClient() throws IOException {\n     public void listMessages(ProcessContext context) throws IOException {\n       String hl7v2Store = context.element();\n       // Output all elements of all pages.\n-      this.client.getHL7v2MessageStream(hl7v2Store, this.filter).forEach(context::output);\n+      HttpHealthcareApiClient.HL7v2MessagePages pages =\n+          new HttpHealthcareApiClient.HL7v2MessagePages(client, hl7v2Store, this.filter);\n+      long reqestTime = Instant.now().getMillis();", "originalCommit": "ea2f85e012134be5c1733c170e7b11aea5c952a7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE0Mjg2NA==", "url": "https://github.com/apache/beam/pull/11538#discussion_r418142864", "bodyText": "This is to track latency of list pagination requests in a metric", "author": "jaketf", "createdAt": "2020-04-30T16:38:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjA2MDM5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNzc0MA==", "url": "https://github.com/apache/beam/pull/11538#discussion_r416927740", "bodyText": "Unfortunately, this is not possible. If you are paginating from inside the single DoFn processelement call, the data coming out of it will only go downstream after the element is done being processed, so this windowing is not changing that in the execution.\nThis is because bundle execution is committed atomically, so the whole bundle executes before data can go downstream. You do touch on an interesting example, which is one of the reasons that we came up with SplittableDoFn.\nSomething you could try to do is:\nPColll<HL7v2Message> pages = hl7v2Stores.apply(ParDo.of(new RetrieveAndOutputPagesFn()))\n\npages.apply(Reshuffle.viaRandomKey()).apply(ParDo.of(new FetchEachPageFn())\n\nThough I don't know if you can actually do that : )", "author": "pabloem", "createdAt": "2020-04-28T21:15:53Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/healthcare/HL7v2IO.java", "diffHunk": "@@ -437,6 +444,20 @@ private Message fetchMessage(HealthcareApiClient client, String msgId)\n           .apply(Create.of(this.hl7v2Stores))\n           .apply(ParDo.of(new ListHL7v2MessagesFn(this.filter)))\n           .setCoder(new HL7v2MessageCoder())\n+          // Listing takes a long time for each input element (HL7v2 store) because it has to\n+          // paginate through results in a single thread / ProcessElement call in order to keep\n+          // track of page token.\n+          // Eagerly emit data on 1 second intervals so downstream processing can get started before\n+          // all of the list results have been paginated through.", "originalCommit": "454f1ef7d920a799db10e034d0fb430399fa5f5c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk1NzI3Ng==", "url": "https://github.com/apache/beam/pull/11538#discussion_r416957276", "bodyText": "Each \"page\" of responses is a collection of messages. It don't think it make sense to page through all the pages (dropping the real data) to then re-fetch it in the downstream parallelized step.\nIn testing w/ customer when pointing at an HL7v2 store with many, many messages (and therefore pages) they reported\nbefore this change:\nthere was a long time before any elements were output. so long that they gave up and killed the pipeline.\nafter this change:\nthere was data coming out more regularly.\nThis could have been a misunderstanding or a bad test scenario.\nI will try to come up with a test that reproduces this behavior.", "author": "jaketf", "createdAt": "2020-04-28T22:16:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNzc0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzAwMDY5Ng==", "url": "https://github.com/apache/beam/pull/11538#discussion_r417000696", "bodyText": "@pabloem does this mean that all of a single element's output must be buffered in memory? or will runner be smart enough to spill to disk?\nBased on my initial investigation I was not able to reproduce the behavior reported by customer in a unit test.\nsummarized in this gist", "author": "jaketf", "createdAt": "2020-04-29T00:18:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNzc0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzU0MzQ4Mw==", "url": "https://github.com/apache/beam/pull/11538#discussion_r417543483", "bodyText": "I've opened https://issues.apache.org/jira/browse/BEAM-9856 to explore how this could be done with splittable dofn.", "author": "jaketf", "createdAt": "2020-04-29T19:02:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNzc0MA=="}], "type": "inlineReview"}, {"oid": "81a3cb2d6aa7aeb8a71aaa461e9bf779da66f16c", "url": "https://github.com/apache/beam/commit/81a3cb2d6aa7aeb8a71aaa461e9bf779da66f16c", "message": "add TODO for verifying triggering behavior BEAM-9847", "committedDate": "2020-04-28T22:46:54Z", "type": "commit"}, {"oid": "edf3c13764462da3cb935aad9963af78b2a1adfc", "url": "https://github.com/apache/beam/commit/edf3c13764462da3cb935aad9963af78b2a1adfc", "message": "remove inappropriate 'optimizaiton', add status code to HealthcareIOError", "committedDate": "2020-04-29T22:44:39Z", "type": "commit"}, {"oid": "251f41749cb5ca9483150b03c0dae563352c3e12", "url": "https://github.com/apache/beam/commit/251f41749cb5ca9483150b03c0dae563352c3e12", "message": "Merge branch 'optimization/HL7v2IO' of github.com:jaketf/beam into optimization/HL7v2IO", "committedDate": "2020-04-29T22:44:57Z", "type": "commit"}]}