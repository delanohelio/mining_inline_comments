{"pr_number": 13561, "pr_title": "Add DataFrame Preview announcment blog post", "pr_createdAt": "2020-12-16T01:36:50Z", "pr_url": "https://github.com/apache/beam/pull/13561", "timeline": [{"oid": "0407c7522a452e1efe3ae52b2befd714d6942a2a", "url": "https://github.com/apache/beam/commit/0407c7522a452e1efe3ae52b2befd714d6942a2a", "message": "Add Dataframe announcment blog post", "committedDate": "2020-12-16T01:36:03Z", "type": "commit"}, {"oid": "b19e82f3eede75b4e4e79b8e6dcdfbc53232ed80", "url": "https://github.com/apache/beam/commit/b19e82f3eede75b4e4e79b8e6dcdfbc53232ed80", "message": "Update dataframe-api-preview-available.md", "committedDate": "2020-12-16T01:49:25Z", "type": "commit"}, {"oid": "d19e0d62f46fb3e372d4d7b0eee834afbf6c47e2", "url": "https://github.com/apache/beam/commit/d19e0d62f46fb3e372d4d7b0eee834afbf6c47e2", "message": "Fix all the things", "committedDate": "2020-12-16T18:09:53Z", "type": "commit"}, {"oid": "1121982c73430bddfcc7c733a20826597f9508d1", "url": "https://github.com/apache/beam/commit/1121982c73430bddfcc7c733a20826597f9508d1", "message": "Merge branch 'master' into dataframe-blog", "committedDate": "2020-12-16T18:10:51Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTE2MDkyNg==", "url": "https://github.com/apache/beam/pull/13561#discussion_r545160926", "bodyText": "Dataframe -> DataFrame", "author": "pcoet", "createdAt": "2020-12-17T15:06:25Z", "path": "website/www/site/content/en/blog/dataframe-api-preview-available.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title:  \"DataFrame API Preview now Available!\"\n+date: \"2020-12-16T09:09:41-08:00\"\n+categories:\n+  - blog\n+authors:\n+  - bhulette\n+  - robertwb\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+We are proud to announce that a preview of the Beam Python SDK's new DataFrame\n+API is now available in [Beam\n+2.26.0](https://beam.apache.org/blog/beam-2.26.0/). Much like SqlTransform\n+([Java](https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/extensions/sql/SqlTransform.html),\n+[Python](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.sql.html#apache_beam.transforms.sql.SqlTransform)),\n+the DataFrame API gives Beam users a way to express complex\n+relational logic much more concisely than previously possible.\n+<!--more-->\n+\n+## A more expressive API\n+Beam's new Dataframe API aims to be compatible with the well known", "originalCommit": "1121982c73430bddfcc7c733a20826597f9508d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTE2MzY4NA==", "url": "https://github.com/apache/beam/pull/13561#discussion_r545163684", "bodyText": "Maybe something like, \"We're excited to announce ....\"", "author": "pcoet", "createdAt": "2020-12-17T15:09:59Z", "path": "website/www/site/content/en/blog/dataframe-api-preview-available.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title:  \"DataFrame API Preview now Available!\"\n+date: \"2020-12-16T09:09:41-08:00\"\n+categories:\n+  - blog\n+authors:\n+  - bhulette\n+  - robertwb\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+We are proud to announce that a preview of the Beam Python SDK's new DataFrame", "originalCommit": "1121982c73430bddfcc7c733a20826597f9508d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTIyMDc0Mw==", "url": "https://github.com/apache/beam/pull/13561#discussion_r545220743", "bodyText": "\"operations, we\u2019re\" -> \"operations. We\u2019re\"", "author": "pcoet", "createdAt": "2020-12-17T16:22:41Z", "path": "website/www/site/content/en/blog/dataframe-api-preview-available.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title:  \"DataFrame API Preview now Available!\"\n+date: \"2020-12-16T09:09:41-08:00\"\n+categories:\n+  - blog\n+authors:\n+  - bhulette\n+  - robertwb\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+We are proud to announce that a preview of the Beam Python SDK's new DataFrame\n+API is now available in [Beam\n+2.26.0](https://beam.apache.org/blog/beam-2.26.0/). Much like SqlTransform\n+([Java](https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/extensions/sql/SqlTransform.html),\n+[Python](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.sql.html#apache_beam.transforms.sql.SqlTransform)),\n+the DataFrame API gives Beam users a way to express complex\n+relational logic much more concisely than previously possible.\n+<!--more-->\n+\n+## A more expressive API\n+Beam's new Dataframe API aims to be compatible with the well known\n+[Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html)\n+DataFrame API, with a few caveats detailed below. With this new API a simple\n+pipeline that reads NYC taxiride data from a CSV, performs a grouped\n+aggregation, and writes the output to CSV, can be expressed very concisely:\n+\n+```\n+from apache_beam.dataframe.io import read_csv\n+\n+with beam.Pipeline() as p:\n+  df = p | read_csv(\"gs://apache-beam-samples/nyc_taxi/2019/*.csv\",\n+                    use_ncols=['passenger_count' , 'DOLocationID'])\n+  # Count the number of passengers dropped off per LocationID\n+  agg = df.groupby('DOLocationID').sum()\n+  agg.to_csv(output)\n+```\n+\n+Compare this to the same logic implemented as a conventional Beam python\n+pipeline with a `CombinePerKey`:\n+\n+```\n+with beam.Pipeline() as p:\n+  (p | beam.io.ReadFromText(\"gs://apache-beam-samples/nyc_taxi/2019/*.csv\",\n+                            skip_header_lines=1)\n+     | beam.Map(lambda line: line.split(','))\n+     # Parse CSV, create key - value pairs\n+     | beam.Map(lambda splits: (int(splits[8] or 0),  # DOLocationID\n+                                int(splits[3] or 0))) # passenger_count\n+     # Sum values per key\n+     | beam.CombinePerKey(sum)\n+     | beam.MapTuple(lambda loc_id, pc: f'{loc_id}: {pc}')\n+     | beam.io.WriteToText(known_args.output))\n+```\n+\n+The DataFrame example is much easier to quickly inspect and understand, as it\n+allows you to concisely express grouped aggregations without using the low-level\n+`CombinePerKey`.\n+\n+In addition to being more expressive and concise, a pipeline written with the\n+DataFrame API can often be more efficient than a conventional Beam pipeline.\n+This is because the DataFrame API defers to the very efficient, columnar Pandas\n+implementation as much as possible.\n+\n+## DataFrames as a DSL\n+You may already be aware of [Beam\n+SQL](https://beam.apache.org/documentation/dsls/sql/overview/), which is\n+a Domain-Specific Language (DSL) built with Beam's Java SDK. SQL is\n+considered a DSL because it's possible to express a full pipeline, including IOs\n+and complex operations, entirely with SQL.\u00a0\n+\n+Similarly, the DataFrame API is a DSL built with the Python SDK. You can see\n+that the above example is written without traditional Beam constructs like IOs,\n+ParDo, or CombinePerKey. In fact the only traditional Beam type is the Pipeline\n+instance! Otherwise this pipeline is written completely using the DataFrame API.\n+This is possible because the DataFrame API doesn't just implement Pandas'\n+computation operations, it also includes IOs based on the Pandas native\n+implementations (`pd.read_{csv,parquet,...}` and `pd.DataFrame.to_{csv,parquet,...}`).\n+\n+Like SQL, it\u2019s also possible to embed the DataFrame API into a larger pipeline\n+by using\n+[schemas](https://beam.apache.org/documentation/programming-guide/#what-is-a-schema).\n+A schema-aware PCollection can be converted to a DataFrame, processed, and the\n+result converted back to another schema-aware PCollection.  For example, if you\n+wanted to use traditional Beam IOs rather than one of the DataFrame IOs you\n+could rewrite the above pipeline like this:\n+\n+```\n+from apache_beam.dataframe.convert import to_dataframe\n+from apache_beam.dataframe.convert import to_pcollection\n+\n+with beam.Pipeline() as p:\n+  ...\n+  schema_pc = (p | beam.ReadFromText(..)\n+                 # Use beam.Select to assign a schema\n+                 | beam.Select(DOLocationID=lambda line: int(...),\n+                               passenger_count=lambda line: int(...)))\n+  df = to_dataframe(schema_pc)\n+  agg = df.groupby('DOLocationID').sum()\n+  agg_pc = to_pcollection(pc)\n+\n+  # agg_pc has a schema based on the structure of agg\n+  (agg_pc | beam.Map(lambda row: f'{row.DOLocationID}: {row.passenger_count}')\n+          | beam.WriteToText(..))\n+```\n+\n+It\u2019s also possible to use the DataFrame API by passing a function to\n+[`DataframeTransform`](https://beam.apache.org/releases/pydoc/current/apache_beam.dataframe.transforms.html#apache_beam.dataframe.transforms.DataframeTransform):\n+\n+```\n+from apache_beam.dataframe.transforms import DataframeTransform\n+\n+with beam.Pipeline() as p:\n+  ...\n+  | beam.Select(DOLocationID=lambda line: int(..),\n+                passenger_count=lambda line: int(..))\n+  | DataframeTransform(lambda df: df.groupby('DOLocationID').sum())\n+  | beam.Map(lambda row: f'{row.DOLocationID}: {row.passenger_count}')\n+  ...\n+```\n+\n+## Caveats\n+As hinted above, there are some differences between Beam's DataFrame API and the\n+Pandas API. The most significant difference is that the Beam  DataFrame API is\n+*deferred*, just like the rest of the Beam API. This means that you can't\n+`print()` a DataFrame instance in order to inspect the data, because we haven't\n+computed the data yet! The computation doesn't take place until the pipeline is\n+`run()`.  Before that, we only know about the shape/schema of the result (i.e.\n+the names and types of the columns), and not the result itself.\n+\n+There are a few common exceptions you will likely see when attempting to use\n+certain Pandas operations:\n+\n+- **NotImplementedError:** Indicates this is an operation or argument that we\n+  haven't had time to look at yet. We've tried to make as many Pandas operations\n+  as possible available in the Preview offering of this new API, but there's\n+  still a long tail of operations to go.\n+- **WontImplementError:** Indicates this is an operation or argument we do not\n+  intend to support in the near-term because it's incompatible with the Beam\n+  model. The largest class of operations that raise this error are those that\n+  are order sensitive (e.g. shift, cummax, cummin, head, tail, etc..). These\n+  cannot be trivially mapped to Beam because PCollections, representing\n+  distributed datasets, are unordered. Note that even some of these operations\n+  *may* get implemented in the future - we actually have some ideas for how we\n+  might support order sensitive operations - but it's a ways off.\n+\n+Finally, it's important to note that this is a preview of a new feature that\n+will get hardened over the next few Beam releases. We would love for you to try\n+it out now and give us some feedback, but we do not yet recommend it for use in\n+production workloads.\n+\n+## How to get involved\n+The easiest way to get involved with this effort is to try out DataFrames and\n+let us know what you think! You can send questions to user@beam.apache.org, or\n+file bug reports and feature requests in [jira](https://issues.apache.org/jira).\n+In particular, it would be really helpful to know if there\u2019s an operation we\n+haven\u2019t implemented yet that you\u2019d find useful, so that we can prioritize it.\n+\n+If you\u2019d like to learn more about how the DataFrame API works under the hood and\n+get involved with the development we recommend you take a look at the\n+[design doc](http://s.apache.org/beam-dataframes)\n+and our [Beam summit\n+presentation](https://2020.beamsummit.org/sessions/simpler-python-pipelines/).\n+From there the best way to help is to knock out some of those not implemented\n+operations, we\u2019re coordinating that work in", "originalCommit": "1121982c73430bddfcc7c733a20826597f9508d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8573eaba6b7076a2978f40012798fda01d557a83", "url": "https://github.com/apache/beam/commit/8573eaba6b7076a2978f40012798fda01d557a83", "message": "minor fixes", "committedDate": "2020-12-17T21:44:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3Mjk1Nw==", "url": "https://github.com/apache/beam/pull/13561#discussion_r545472957", "bodyText": "Should this be a comma rather than \": \" so it's 1:1 the same result?", "author": "robertwb", "createdAt": "2020-12-17T23:29:39Z", "path": "website/www/site/content/en/blog/dataframe-api-preview-available.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title:  \"DataFrame API Preview now Available!\"\n+date: \"2020-12-16T09:09:41-08:00\"\n+categories:\n+  - blog\n+authors:\n+  - bhulette\n+  - robertwb\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+We're excited to announce that a preview of the Beam Python SDK's new DataFrame\n+API is now available in [Beam\n+2.26.0](https://beam.apache.org/blog/beam-2.26.0/). Much like `SqlTransform`\n+([Java](https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/extensions/sql/SqlTransform.html),\n+[Python](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.sql.html#apache_beam.transforms.sql.SqlTransform)),\n+the DataFrame API gives Beam users a way to express complex\n+relational logic much more concisely than previously possible.\n+<!--more-->\n+\n+## A more expressive API\n+Beam's new DataFrame API aims to be compatible with the well known\n+[Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html)\n+DataFrame API, with a few caveats detailed below. With this new API a simple\n+pipeline that reads NYC taxiride data from a CSV, performs a grouped\n+aggregation, and writes the output to CSV, can be expressed very concisely:\n+\n+```\n+from apache_beam.dataframe.io import read_csv\n+\n+with beam.Pipeline() as p:\n+  df = p | read_csv(\"gs://apache-beam-samples/nyc_taxi/2019/*.csv\",\n+                    use_ncols=['passenger_count' , 'DOLocationID'])\n+  # Count the number of passengers dropped off per LocationID\n+  agg = df.groupby('DOLocationID').sum()\n+  agg.to_csv(output)\n+```\n+\n+Compare this to the same logic implemented as a conventional Beam python\n+pipeline with a `CombinePerKey`:\n+\n+```\n+with beam.Pipeline() as p:\n+  (p | beam.io.ReadFromText(\"gs://apache-beam-samples/nyc_taxi/2019/*.csv\",\n+                            skip_header_lines=1)\n+     | beam.Map(lambda line: line.split(','))\n+     # Parse CSV, create key - value pairs\n+     | beam.Map(lambda splits: (int(splits[8] or 0),  # DOLocationID\n+                                int(splits[3] or 0))) # passenger_count\n+     # Sum values per key\n+     | beam.CombinePerKey(sum)\n+     | beam.MapTuple(lambda loc_id, pc: f'{loc_id}: {pc}')", "originalCommit": "8573eaba6b7076a2978f40012798fda01d557a83", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ5MzcyNg==", "url": "https://github.com/apache/beam/pull/13561#discussion_r545493726", "bodyText": "Good catch, thank you!", "author": "TheNeuralBit", "createdAt": "2020-12-18T00:26:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3Mjk1Nw=="}], "type": "inlineReview"}, {"oid": "d26ab182718f9399dd090918795e74effed13c67", "url": "https://github.com/apache/beam/commit/d26ab182718f9399dd090918795e74effed13c67", "message": "Update dataframe-api-preview-available.md\n\nMake generated strings create valid CSV", "committedDate": "2020-12-18T00:26:32Z", "type": "commit"}]}