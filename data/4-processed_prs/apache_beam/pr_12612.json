{"pr_number": 12612, "pr_title": "[BEAM-10675] Add Python GBK Load Tests for streaming on Dataflow ", "pr_createdAt": "2020-08-18T14:11:01Z", "pr_url": "https://github.com/apache/beam/pull/12612", "timeline": [{"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13", "url": "https://github.com/apache/beam/commit/f67712b477f811e2fe61f5c816b58e1268db2e13", "message": "[BEAM-10675] Python GBK load test: add streaming job", "committedDate": "2020-08-20T10:02:13Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzMDE5MA==", "url": "https://github.com/apache/beam/pull/12612#discussion_r474830190", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    job_name             : 'load-tests-python-dataflow-${mode}-gbk-2-' + now,\n          \n          \n            \n                    job_name             : \"load-tests-python-dataflow-${mode}-gbk-2-${now}\",", "author": "tysonjh", "createdAt": "2020-08-21T17:25:26Z", "path": ".test-infra/jenkins/job_LoadTests_GBK_Python.groovy", "diffHunk": "@@ -22,119 +22,138 @@ import InfluxDBCredentialsHelper\n \n def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n \n-def loadTestConfigurations = { datasetName ->\n+// TODO(BEAM-10774): Skipping some cases because they are too slow.\n+def STREAMING_TESTS_TO_SKIP = [1, 2, 4, 5]\n+\n+def loadTestConfigurations = { mode, datasetName ->\n   [\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 10B records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-1-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-1-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_1',\n-        influx_measurement   : 'python_batch_gbk_1',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_1\",\n+        influx_measurement   : \"python_${mode}_gbk_1\",\n         input_options        : '\\'{\"num_records\": 200000000,' +\n         '\"key_size\": 1,' +\n         '\"value_size\": 9}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 100B records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-2-' + now,\n+        job_name             : 'load-tests-python-dataflow-${mode}-gbk-2-' + now,", "originalCommit": "f67712b477f811e2fe61f5c816b58e1268db2e13", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzMzgwNg==", "url": "https://github.com/apache/beam/pull/12612#discussion_r474833806", "bodyText": "Can you add a comment to explain what these settings are? It's unexpected to see that 'streaming: null' or 'enable_streaming_engine: null' somehow enables streaming, or why 'use_runner_v2' is required.", "author": "tysonjh", "createdAt": "2020-08-21T17:33:10Z", "path": ".test-infra/jenkins/job_LoadTests_GBK_Python.groovy", "diffHunk": "@@ -22,119 +22,138 @@ import InfluxDBCredentialsHelper\n \n def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n \n-def loadTestConfigurations = { datasetName ->\n+// TODO(BEAM-10774): Skipping some cases because they are too slow.\n+def STREAMING_TESTS_TO_SKIP = [1, 2, 4, 5]\n+\n+def loadTestConfigurations = { mode, datasetName ->\n   [\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 10B records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-1-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-1-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_1',\n-        influx_measurement   : 'python_batch_gbk_1',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_1\",\n+        influx_measurement   : \"python_${mode}_gbk_1\",\n         input_options        : '\\'{\"num_records\": 200000000,' +\n         '\"key_size\": 1,' +\n         '\"value_size\": 9}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 100B records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-2-' + now,\n+        job_name             : 'load-tests-python-dataflow-${mode}-gbk-2-' + now,\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_2',\n-        influx_measurement   : 'python_batch_gbk_2',\n+        metrics_table        : 'python_dataflow_${mode}_gbk_2',\n+        influx_measurement   : 'python_${mode}_gbk_2',\n         input_options        : '\\'{\"num_records\": 20000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 100kB records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-3-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-3-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_3',\n-        influx_measurement   : 'python_batch_gbk_3',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_3\",\n+        influx_measurement   : \"python_${mode}_gbk_3\",\n         input_options        : '\\'{\"num_records\": 20000,' +\n         '\"key_size\": 10000,' +\n         '\"value_size\": 90000}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: fanout 4 times with 2GB 10-byte records total',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-4-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-4-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_4',\n-        influx_measurement   : 'python_batch_gbk_4',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_4\",\n+        influx_measurement   : \"python_${mode}_gbk_4\",\n         input_options        : '\\'{\"num_records\": 5000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90}\\'',\n         iterations           : 1,\n         fanout               : 4,\n-        num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        num_workers          : 16,\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: fanout 8 times with 2GB 10-byte records total',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-5-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-5-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_5',\n-        influx_measurement   : 'python_batch_gbk_5',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_5\",\n+        influx_measurement   : \"python_${mode}_gbk_5\",\n         input_options        : '\\'{\"num_records\": 2500000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90}\\'',\n         iterations           : 1,\n         fanout               : 8,\n-        num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        num_workers          : 16,\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n-  ].each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  ]\n+  .each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  .each { test -> (mode != 'streaming') ?: addStreamingOptions(test) }\n+  .withIndex().collectMany { test, i ->\n+    mode == 'streaming' && STREAMING_TESTS_TO_SKIP.contains(i + 1) ? []: [test]\n+  }\n+}\n+\n+def addStreamingOptions(test) {\n+  test.pipelineOptions << [streaming: null, experiments: 'use_runner_v2',\n+    enable_streaming_engine: null ]\n+}", "originalCommit": "f67712b477f811e2fe61f5c816b58e1268db2e13", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTcwNzQwNA==", "url": "https://github.com/apache/beam/pull/12612#discussion_r475707404", "bodyText": "I removed --enable_streaming_engine, since it is now being added automatically when using use_runner_v2:  #12585", "author": "kamilwu", "createdAt": "2020-08-24T15:38:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzMzgwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzNDQ0Mw==", "url": "https://github.com/apache/beam/pull/12612#discussion_r474834443", "bodyText": "Same here, please add a comment.", "author": "tysonjh", "createdAt": "2020-08-21T17:34:28Z", "path": ".test-infra/jenkins/job_LoadTests_GBK_Python_reiterate.groovy", "diffHunk": "@@ -58,43 +58,47 @@ def loadTestConfigurations = { datasetName ->\n       pipelineOptions: [\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-7-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-7-${now}\",\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_7',\n-        influx_measurement   : 'python_batch_gbk_7',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_7\",\n+        influx_measurement   : \"python_${mode}_gbk_7\",\n         input_options        : '\\'{\"num_records\": 20000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90,' +\n         '\"num_hot_keys\": 10,' +\n         '\"hot_key_fraction\": 1}\\'',\n-        fanout               : 1,\n         iterations           : 4,\n+        fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: 'NONE'\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ]\n-  ].each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  ]\n+  .each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  .each { test -> (mode != 'streaming') ?: addStreamingOptions(test) }\n }\n \n-def batchLoadTestJob = { scope, triggeringContext ->\n-  scope.description('Runs Python GBK reiterate load tests on Dataflow runner in batch mode')\n-  commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+def addStreamingOptions(test) {", "originalCommit": "f67712b477f811e2fe61f5c816b58e1268db2e13", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzNDgxNg==", "url": "https://github.com/apache/beam/pull/12612#discussion_r474834816", "bodyText": "What's the methodology for picking the time to trigger these? Is it documented anywhere?", "author": "tysonjh", "createdAt": "2020-08-21T17:35:09Z", "path": ".test-infra/jenkins/job_LoadTests_GBK_Python_reiterate.groovy", "diffHunk": "@@ -58,43 +58,47 @@ def loadTestConfigurations = { datasetName ->\n       pipelineOptions: [\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-7-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-7-${now}\",\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_7',\n-        influx_measurement   : 'python_batch_gbk_7',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_7\",\n+        influx_measurement   : \"python_${mode}_gbk_7\",\n         input_options        : '\\'{\"num_records\": 20000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90,' +\n         '\"num_hot_keys\": 10,' +\n         '\"hot_key_fraction\": 1}\\'',\n-        fanout               : 1,\n         iterations           : 4,\n+        fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: 'NONE'\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ]\n-  ].each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  ]\n+  .each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  .each { test -> (mode != 'streaming') ?: addStreamingOptions(test) }\n }\n \n-def batchLoadTestJob = { scope, triggeringContext ->\n-  scope.description('Runs Python GBK reiterate load tests on Dataflow runner in batch mode')\n-  commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+def addStreamingOptions(test) {\n+  test.pipelineOptions << [streaming: null, experiments: 'use_runner_v2',\n+    enable_streaming_engine: null ]\n+}\n \n+def loadTestJob = { scope, triggeringContext, mode ->\n   def datasetName = loadTestsBuilder.getBigQueryDataset('load_test', triggeringContext)\n-  for (testConfiguration in loadTestConfigurations(datasetName)) {\n-    loadTestsBuilder.loadTest(scope, testConfiguration.title, testConfiguration.runner, CommonTestProperties.SDK.PYTHON_37, testConfiguration.pipelineOptions, testConfiguration.test)\n-  }\n+  loadTestsBuilder.loadTests(scope, CommonTestProperties.SDK.PYTHON_37,\n+      loadTestConfigurations(mode, datasetName), 'GBK reiterate', mode)\n }\n \n-CronJobBuilder.cronJob('beam_LoadTests_Python_GBK_reiterate_Dataflow_Batch', 'H 14 * * *', this) {\n-  additionalPipelineArgs = [\n-    influx_db_name: InfluxDBCredentialsHelper.InfluxDBDatabaseName,\n-    influx_hostname: InfluxDBCredentialsHelper.InfluxDBHostname,\n-  ]\n-  batchLoadTestJob(delegate, CommonTestProperties.TriggeringContext.POST_COMMIT)\n-}\n+CronJobBuilder.cronJob('beam_LoadTests_Python_GBK_reiterate_Dataflow_Batch',\n+    'H 14 * * *', this) {", "originalCommit": "f67712b477f811e2fe61f5c816b58e1268db2e13", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUyMDgxOA==", "url": "https://github.com/apache/beam/pull/12612#discussion_r475520818", "bodyText": "Ideally, each test suite (GBK, ParDo, IO tests, etc.) should has its own, unique time in order no to flood Jenkins with many tests that are triggered at the same time. When adding a new test suite, a contributor has to take a look at what time slots are already occupied and avoid using them.\nI think this is not documented. I'll add some information here: https://cwiki.apache.org/confluence/display/BEAM/Contribution+Testing+Guide#ContributionTestingGuide", "author": "kamilwu", "createdAt": "2020-08-24T11:01:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzNDgxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg0MDUyOA==", "url": "https://github.com/apache/beam/pull/12612#discussion_r474840528", "bodyText": "@kkucharc made a good point here in PR#12435 about using indices for ignoring tests. I'm more inclined towards the approach @kkucharc is taking by excluding using the job_name.", "author": "tysonjh", "createdAt": "2020-08-21T17:47:18Z", "path": ".test-infra/jenkins/job_LoadTests_GBK_Python.groovy", "diffHunk": "@@ -22,119 +22,138 @@ import InfluxDBCredentialsHelper\n \n def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n \n-def loadTestConfigurations = { datasetName ->\n+// TODO(BEAM-10774): Skipping some cases because they are too slow.\n+def STREAMING_TESTS_TO_SKIP = [1, 2, 4, 5]", "originalCommit": "f67712b477f811e2fe61f5c816b58e1268db2e13", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ2NzA2Mw==", "url": "https://github.com/apache/beam/pull/12612#discussion_r475467063", "bodyText": "Thanks, an argument that @kkucharc made in PR#12435 is convincing. I'll exclude those cases by using the job_name.", "author": "kamilwu", "createdAt": "2020-08-24T09:32:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg0MDUyOA=="}], "type": "inlineReview"}, {"oid": "7909cab3aaabf9f31cd06bf895d67309c0a31a1b", "url": "https://github.com/apache/beam/commit/7909cab3aaabf9f31cd06bf895d67309c0a31a1b", "message": "[BEAM-10675] Protect against None-valued metrics", "committedDate": "2020-08-24T13:51:16Z", "type": "commit"}, {"oid": "88dd6b3972ac43844fbef4da9a7970889800a04f", "url": "https://github.com/apache/beam/commit/88dd6b3972ac43844fbef4da9a7970889800a04f", "message": "[BEAM-10675] Python GBK load test: fix a bug where KV pairs were not properly returned from Ungroup transform", "committedDate": "2020-08-24T13:51:16Z", "type": "commit"}, {"oid": "0e6735ba225039920d888f0a729841475ea48c7b", "url": "https://github.com/apache/beam/commit/0e6735ba225039920d888f0a729841475ea48c7b", "message": "[BEAM-10675] Python GBK load test: add streaming job", "committedDate": "2020-08-24T13:51:16Z", "type": "commit"}, {"oid": "686122d512c70f4c18709e56497728f76ff529e7", "url": "https://github.com/apache/beam/commit/686122d512c70f4c18709e56497728f76ff529e7", "message": "fix: exclude test cases by job_name; add explanatory comments", "committedDate": "2020-08-24T13:51:16Z", "type": "commit"}, {"oid": "e6bbfe27007cb5b59cdb1df66bef1967f7f94ca2", "url": "https://github.com/apache/beam/commit/e6bbfe27007cb5b59cdb1df66bef1967f7f94ca2", "message": "fix: remove enable_streaming_engine option\n\nenable_streaming_engine is now being added automatically when running with 'use_runner_v2'", "committedDate": "2020-08-24T15:34:19Z", "type": "forcePushed"}, {"oid": "11a1a3b884c83cb6b5623105b252dc160ffa699a", "url": "https://github.com/apache/beam/commit/11a1a3b884c83cb6b5623105b252dc160ffa699a", "message": "fix: remove enable_streaming_engine option\n\nenable_streaming_engine is now being added automatically when running with 'use_runner_v2'", "committedDate": "2020-08-24T15:35:02Z", "type": "commit"}, {"oid": "11a1a3b884c83cb6b5623105b252dc160ffa699a", "url": "https://github.com/apache/beam/commit/11a1a3b884c83cb6b5623105b252dc160ffa699a", "message": "fix: remove enable_streaming_engine option\n\nenable_streaming_engine is now being added automatically when running with 'use_runner_v2'", "committedDate": "2020-08-24T15:35:02Z", "type": "forcePushed"}]}