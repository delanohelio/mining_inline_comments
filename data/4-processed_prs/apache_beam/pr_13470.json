{"pr_number": 13470, "pr_title": "[BEAM-10114] Convert PubsubLiteIO read to use SplittableDoFn.", "pr_createdAt": "2020-12-03T04:58:23Z", "pr_url": "https://github.com/apache/beam/pull/13470", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzg5NA==", "url": "https://github.com/apache/beam/pull/13470#discussion_r536433894", "bodyText": "If lastClaimed == Long.MAX_VALUE, you will get overflow here.", "author": "boyuanzz", "createdAt": "2020-12-04T23:00:18Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;", "originalCommit": "e4ba623c7fb6cc3935558a861444583496a413cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTgzODQ3OA==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539838478", "bodyText": "Correct. This doesn't currently handle MAX_VALUE offsets, as there is no reason one would be produced. I've added a \"checkState\" to ensure this doesn't overflow.", "author": "dpcollins-google", "createdAt": "2020-12-10T04:35:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzg5NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzNDg2OA==", "url": "https://github.com/apache/beam/pull/13470#discussion_r536434868", "bodyText": "If something goes wrong before we reaching to checkDone, we will have resource leak on backlogReader.", "author": "boyuanzz", "createdAt": "2020-12-04T23:02:52Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {\n+    // Cannot split a bounded range. This should already be completely claimed.\n+    if (range.getTo() != Long.MAX_VALUE) return null;\n+    range = new OffsetRange(currentRestriction().getFrom(), nextOffset());\n+    return SplitResult.of(this.range, new OffsetRange(nextOffset(), Long.MAX_VALUE));\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"unboxing.of.nullable\")\n+  public void checkDone() throws IllegalStateException {\n+    backlogReader.close();", "originalCommit": "e4ba623c7fb6cc3935558a861444583496a413cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUwNjI3NQ==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539506275", "bodyText": "Good to know, but it doesn't look like OffsetByteRangeTracker has any lifecycle methods? Where would you suggest this object is cleaned up?", "author": "dpcollins-google", "createdAt": "2020-12-09T17:33:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzNDg2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTcwNTI5OA==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539705298", "bodyText": "You can override Java Object finalize() function to close the reader when GC happens.", "author": "boyuanzz", "createdAt": "2020-12-09T22:46:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzNDg2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTg0MDk4MQ==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539840981", "bodyText": "You know finalize() is deprecated yes? https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/Object.html#finalize() It seems like a model deficiency that this object doesn't have a cleanup function (i.e. implementing autocloseable) But I've added this.", "author": "dpcollins-google", "createdAt": "2020-12-10T04:43:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzNDg2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzYzMjg4Mw==", "url": "https://github.com/apache/beam/pull/13470#discussion_r543632883", "bodyText": "You know finalize() is deprecated yes?\nI don't, but good to know.\n\nWe only have lifecycle management on DoFn, thus you should manage the resource of your objects.", "author": "boyuanzz", "createdAt": "2020-12-15T19:38:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzNDg2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzODkyNQ==", "url": "https://github.com/apache/beam/pull/13470#discussion_r536438925", "bodyText": "Please add some javadoc to this tracker, especially about the assumption around range.getTo() == Long.MAX_VALUE and you ignore the fractionOfRemainder in trySplit", "author": "boyuanzz", "createdAt": "2020-12-04T23:14:33Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>", "originalCommit": "e4ba623c7fb6cc3935558a861444583496a413cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTgzODIyMw==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539838223", "bodyText": "Done.", "author": "dpcollins-google", "createdAt": "2020-12-10T04:34:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzODkyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MTY0Mg==", "url": "https://github.com/apache/beam/pull/13470#discussion_r536441642", "bodyText": "I think you may also want to track watermark by implementing watermark related APIs: https://beam.apache.org/documentation/programming-guide/#watermark-estimation", "author": "boyuanzz", "createdAt": "2020-12-04T23:23:11Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {", "originalCommit": "e4ba623c7fb6cc3935558a861444583496a413cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUxMTEyNQ==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539511125", "bodyText": "Pub/Sub Lite publish timestamps on a single partition will never go backwards (we haven't published this guarantee, but it is true of the system). If this is true, is the default behavior sufficient?", "author": "dpcollins-google", "createdAt": "2020-12-09T17:38:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MTY0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTcyMTU1OA==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539721558", "bodyText": "In that case, you may want to use MonotonicallyIncreasing one. What you need to do is to implement @ GetInitialWatermarkEstimatorState and  @NewWatermarkEstimator. And you want to use outputWithTimestamp to update the watermark estimator with the timestamp.", "author": "boyuanzz", "createdAt": "2020-12-09T23:20:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MTY0Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTk0ODA1MA==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539948050", "bodyText": "Done.", "author": "dpcollins-google", "createdAt": "2020-12-10T07:52:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MTY0Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NTM4Mw==", "url": "https://github.com/apache/beam/pull/13470#discussion_r536445383", "bodyText": "Please file a JIRA and add a TODO here which talks about the improvement you are going to make.", "author": "boyuanzz", "createdAt": "2020-12-04T23:35:17Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {", "originalCommit": "e4ba623c7fb6cc3935558a861444583496a413cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUxMTQ1OQ==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539511459", "bodyText": "Added a TODO, but since I already have this written a jira seems like overkill.", "author": "dpcollins-google", "createdAt": "2020-12-09T17:39:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NTM4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTgzODU2NA==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539838564", "bodyText": "Actually just merged this in here.", "author": "dpcollins-google", "createdAt": "2020-12-10T04:35:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NTM4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NjU4NA==", "url": "https://github.com/apache/beam/pull/13470#discussion_r536446584", "bodyText": "I'm wondering how a partition can locate a read, I would image we at least need a topic. Is it plumped through by subscriberFactory  during construction time?", "author": "boyuanzz", "createdAt": "2020-12-04T23:39:24Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {\n+  private static final GoogleLogger logger = GoogleLogger.forEnclosingClass();\n+  private final Duration maxSleepTime;\n+  private final SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>>\n+      subscriberFactory;\n+  private final SerializableFunction<Partition, Committer> committerFactory;\n+  private final SerializableSupplier<Sleeper> sleeperSupplier;\n+  private final SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+\n+  Duration sleepTimeRemaining;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>> subscriberFactory,\n+      SerializableFunction<Partition, Committer> committerFactory,\n+      SerializableSupplier<Sleeper> sleeperSupplier,\n+      SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.sleepTimeRemaining = maxSleepTime;\n+    this.subscriberFactory = subscriberFactory;\n+    this.committerFactory = committerFactory;\n+    this.sleeperSupplier = sleeperSupplier;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+  }\n+\n+  private List<SequencedMessage> doPoll(PullSubscriber<SequencedMessage> subscriber)\n+      throws Exception {\n+    Sleeper sleeper = sleeperSupplier.get();\n+    while (sleepTimeRemaining.isLongerThan(Duration.ZERO)) {\n+      List<SequencedMessage> messages = subscriber.pull();\n+      if (!messages.isEmpty()) {\n+        return messages;\n+      }\n+      Duration sleepTime =\n+          Collections.min(ImmutableList.of(sleepTimeRemaining, Duration.millis(50)));\n+      sleepTimeRemaining = sleepTimeRemaining.minus(sleepTime);\n+      sleeper.sleep(sleepTime.getMillis());\n+    }\n+    return ImmutableList.of();\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element Partition partition,", "originalCommit": "e4ba623c7fb6cc3935558a861444583496a413cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUxMjE4Mg==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539512182", "bodyText": "Yes", "author": "dpcollins-google", "createdAt": "2020-12-09T17:40:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NjU4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1MTczMA==", "url": "https://github.com/apache/beam/pull/13470#discussion_r536451730", "bodyText": "It seems like the PubsubLiteIO.read() is for reading one topic(subscription). Do we have a plan to have PubsubLiteIO expose readAll() API to read from multiple topics/subscriptions?", "author": "boyuanzz", "createdAt": "2020-12-04T23:57:44Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PubsubLiteIO.java", "diffHunk": "@@ -64,8 +64,8 @@ private PubsubLiteIO() {}\n    *     .build()), \"read\");\n    * }</pre>\n    */\n-  public static Read.Unbounded<SequencedMessage> read(SubscriberOptions options) {\n-    return Read.from(new PubsubLiteUnboundedSource(options));\n+  public static PTransform<PBegin, PCollection<SequencedMessage>> read(SubscriberOptions options) {", "originalCommit": "e4ba623c7fb6cc3935558a861444583496a413cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUxNDk1MQ==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539514951", "bodyText": "I don't (it adds to the api surface for an uncommon case), but this can be implemented in userland by:\nPCollectionList list = PCollectionList.of();\nfor (SubscriptionPath subscription : subscriptions) {\n  list = list.and(p.apply(PubsubLiteIO.read(SubscriberOptions.newBuilder()\n      .setSubscriptionPath(subscriptionPath)\n      .build()), \"read\"));\n}\nreturn list.apply(Flatten.<SequencedMessage>pCollections())", "author": "dpcollins-google", "createdAt": "2020-12-09T17:43:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1MTczMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTczMjM4MQ==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539732381", "bodyText": "The main goal for us to build composite transform is to offer end users simple API to do complex work. I would say it's more convenient for pipeline authors to have readAll() API instead of writing more code by their own.", "author": "boyuanzz", "createdAt": "2020-12-09T23:43:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1MTczMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTg0MTc4MQ==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539841781", "bodyText": "Yeah I don't agree. Reading from multiple subscriptions to process the same data is a niche use-case: especially given that we try to commit to not only never breaking API but the internal structure to prevent from breaking dataflow refreshing, I think we should keep the API surface as small as possible. Given how niche this is and how easy it is (5 LOC), I see no benefit in adding noise to the API surface of PubsubLiteIO.", "author": "dpcollins-google", "createdAt": "2020-12-10T04:45:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1MTczMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzYzNjAyNQ==", "url": "https://github.com/apache/beam/pull/13470#discussion_r543636025", "bodyText": "I'll let you know when there is a FR on readAll", "author": "boyuanzz", "createdAt": "2020-12-15T19:43:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1MTczMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1Mjk4NQ==", "url": "https://github.com/apache/beam/pull/13470#discussion_r536452985", "bodyText": "I'm thinking about whether it makes sense to have PerPartitionSdf to read from a SubscriberOptions or something that can locate a read(topic + partition + something else). It will also help us to enable readAll() API I mentioned above. Also the PerPartitionSdf will also be able to read from subscriptions/partitions that are created during pipeline execution time.\nOne major feature request for Kafka IO is to read from new added topics/partitions dynamically, which I think PubsubLiteIO might have the similar customer needs.", "author": "boyuanzz", "createdAt": "2020-12-05T00:02:15Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static com.google.cloud.pubsublite.internal.ExtractStatus.toCanonical;\n+\n+import com.google.api.gax.rpc.ApiException;\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.BufferingPullSubscriber;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.proto.Cursor;\n+import com.google.cloud.pubsublite.proto.SeekRequest;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.Reshuffle;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+\n+class SubscribeTransform extends PTransform<PBegin, PCollection<SequencedMessage>> {\n+  private static final Duration MAX_SLEEP_TIME = Duration.standardMinutes(1);\n+\n+  private final SubscriberOptions options;\n+\n+  SubscribeTransform(SubscriberOptions options) {\n+    this.options = options;\n+  }\n+\n+  private PullSubscriber<SequencedMessage> newPullSubscriber(Partition partition, Offset offset)\n+      throws ApiException {\n+    try {\n+      return new TranslatingPullSubscriber(\n+          new BufferingPullSubscriber(\n+              options.getSubscriberFactory(partition),\n+              options.flowControlSettings(),\n+              SeekRequest.newBuilder()\n+                  .setCursor(Cursor.newBuilder().setOffset(offset.value()))\n+                  .build()));\n+    } catch (Throwable t) {\n+      throw toCanonical(t).underlying;\n+    }\n+  }\n+\n+  private RestrictionTracker<OffsetRange, OffsetByteProgress> newRestrictionTracker(\n+      Partition partition, OffsetRange initial) {\n+    return new OffsetByteRangeTracker(initial, options.getBacklogReader(partition));\n+  }\n+\n+  @Override\n+  public PCollection<SequencedMessage> expand(PBegin input) {\n+    PCollection<Partition> partitions = Create.of(options.partitions()).expand(input);\n+    // Prevent fusion between Create and read.\n+    PCollection<Partition> shuffledPartitions = partitions.apply(Reshuffle.viaRandomKey());\n+    return shuffledPartitions.apply(\n+        ParDo.of(\n+            new PerPartitionSdf(", "originalCommit": "e4ba623c7fb6cc3935558a861444583496a413cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUxNjY1Mg==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539516652", "bodyText": "I disagree and thinks this adds complexity without a use case.\nNote that the feature requests I've seen are for adding <partitions> dynamically, not topics, which I will be modifying PubsubLiteIO to support shortly.", "author": "dpcollins-google", "createdAt": "2020-12-09T17:46:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1Mjk4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTk0MzAwOA==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539943008", "bodyText": "I've added this, but don't think it is at all useful.", "author": "dpcollins-google", "createdAt": "2020-12-10T07:42:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1Mjk4NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1NjEzOA==", "url": "https://github.com/apache/beam/pull/13470#discussion_r536456138", "bodyText": "What'e the effect of committing offset? Are we able to read from that offset again if it's committed?", "author": "boyuanzz", "createdAt": "2020-12-05T00:14:24Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {\n+  private static final GoogleLogger logger = GoogleLogger.forEnclosingClass();\n+  private final Duration maxSleepTime;\n+  private final SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>>\n+      subscriberFactory;\n+  private final SerializableFunction<Partition, Committer> committerFactory;\n+  private final SerializableSupplier<Sleeper> sleeperSupplier;\n+  private final SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+\n+  Duration sleepTimeRemaining;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>> subscriberFactory,\n+      SerializableFunction<Partition, Committer> committerFactory,\n+      SerializableSupplier<Sleeper> sleeperSupplier,\n+      SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.sleepTimeRemaining = maxSleepTime;\n+    this.subscriberFactory = subscriberFactory;\n+    this.committerFactory = committerFactory;\n+    this.sleeperSupplier = sleeperSupplier;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+  }\n+\n+  private List<SequencedMessage> doPoll(PullSubscriber<SequencedMessage> subscriber)\n+      throws Exception {\n+    Sleeper sleeper = sleeperSupplier.get();\n+    while (sleepTimeRemaining.isLongerThan(Duration.ZERO)) {\n+      List<SequencedMessage> messages = subscriber.pull();\n+      if (!messages.isEmpty()) {\n+        return messages;\n+      }\n+      Duration sleepTime =\n+          Collections.min(ImmutableList.of(sleepTimeRemaining, Duration.millis(50)));\n+      sleepTimeRemaining = sleepTimeRemaining.minus(sleepTime);\n+      sleeper.sleep(sleepTime.getMillis());\n+    }\n+    return ImmutableList.of();\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element Partition partition,\n+      OutputReceiver<SequencedMessage> receiver)\n+      throws Exception {\n+    logger.atInfo().log(\"Starting processing for partition \" + partition);\n+    sleepTimeRemaining = maxSleepTime;\n+    Committer committer = committerFactory.apply(partition);\n+    committer.startAsync().awaitRunning();\n+    try (PullSubscriber<SequencedMessage> subscriber =\n+        subscriberFactory.apply(partition, Offset.of(tracker.currentRestriction().getFrom()))) {\n+      while (true) {\n+        List<SequencedMessage> messages = doPoll(subscriber);\n+        // We polled for as long as possible, yield to the runtime to allow it to reschedule us on\n+        // a new task.\n+        if (messages.isEmpty()) {\n+          logger.atInfo().log(\"Yielding due to timeout on partition \" + partition);\n+          return ProcessContinuation.resume();\n+        }\n+        Offset lastOffset = Offset.of(Iterables.getLast(messages).getCursor().getOffset());\n+        long byteSize = messages.stream().mapToLong(SequencedMessage::getSizeBytes).sum();\n+        if (tracker.tryClaim(OffsetByteProgress.of(lastOffset, byteSize))) {\n+          messages.forEach(\n+              message ->\n+                  receiver.outputWithTimestamp(\n+                      message, new Instant(Timestamps.toMillis(message.getPublishTime()))));\n+          committer.commitOffset(Offset.of(lastOffset.value() + 1)).get();", "originalCommit": "e4ba623c7fb6cc3935558a861444583496a413cf", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODgzMDE3Nw==", "url": "https://github.com/apache/beam/pull/13470#discussion_r538830177", "bodyText": "It updates internal metrics and changes a stored integer value. It has no effect on where the current I/O reads from or what messages can be read.", "author": "dpcollins-google", "createdAt": "2020-12-08T21:44:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1NjEzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUxODQxNg==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539518416", "bodyText": "This does actually affect where the I/O will start on clean restarts. Where this should be depends on how the beam model / dataflow handles drains for SDF pipelines. Do you have any information on this?", "author": "dpcollins-google", "createdAt": "2020-12-09T17:48:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1NjEzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTczNTk3MA==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539735970", "bodyText": "You can either use bundle finalization to commit offsets, which is best-effort. This is similar to how CheckpointMark of UnboundedSource works. Or you can do something similar to Kafka CommitOffset transform.", "author": "boyuanzz", "createdAt": "2020-12-09T23:51:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1NjEzOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTk0MjYzMA==", "url": "https://github.com/apache/beam/pull/13470#discussion_r539942630", "bodyText": "Done.", "author": "dpcollins-google", "createdAt": "2020-12-10T07:41:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1NjEzOA=="}], "type": "inlineReview"}, {"oid": "c0fd31a800c721e50faf3ff2d8934bef8f0e467f", "url": "https://github.com/apache/beam/commit/c0fd31a800c721e50faf3ff2d8934bef8f0e467f", "message": "[BEAM-10114] Convert PubsubLiteIO to use an SDF for reads.", "committedDate": "2020-12-09T17:48:28Z", "type": "forcePushed"}, {"oid": "31dcd532d447aaf8bba8916a016fb263ccd5f4d0", "url": "https://github.com/apache/beam/commit/31dcd532d447aaf8bba8916a016fb263ccd5f4d0", "message": "[BEAM-10114] Convert PubsubLiteIO read to use SplittableDoFn.\n\nAlso bump the Pub/Sub Lite version and make the requisite changes, and simplify options.", "committedDate": "2020-12-10T04:33:59Z", "type": "commit"}, {"oid": "ec3efe20bbd75a8add3c26a4377430b15d73d9dc", "url": "https://github.com/apache/beam/commit/ec3efe20bbd75a8add3c26a4377430b15d73d9dc", "message": "Fix test.", "committedDate": "2020-12-10T04:33:59Z", "type": "commit"}, {"oid": "d3336fe45c838f5b05fcb4b83e4b92c572b49fcc", "url": "https://github.com/apache/beam/commit/d3336fe45c838f5b05fcb4b83e4b92c572b49fcc", "message": "fix: Testing issues", "committedDate": "2020-12-10T04:33:59Z", "type": "commit"}, {"oid": "8892c1c809694cdc839502b42869bc30b24d93a2", "url": "https://github.com/apache/beam/commit/8892c1c809694cdc839502b42869bc30b24d93a2", "message": "[BEAM-10114] Convert PubsubLiteIO to use an SDF for reads.", "committedDate": "2020-12-10T04:33:59Z", "type": "commit"}, {"oid": "f5c61088f90d7ad98d513fde47cc4ac85ff09760", "url": "https://github.com/apache/beam/commit/f5c61088f90d7ad98d513fde47cc4ac85ff09760", "message": "[BEAM-10114] Add byte and time limiting", "committedDate": "2020-12-10T04:33:59Z", "type": "commit"}, {"oid": "f5c61088f90d7ad98d513fde47cc4ac85ff09760", "url": "https://github.com/apache/beam/commit/f5c61088f90d7ad98d513fde47cc4ac85ff09760", "message": "[BEAM-10114] Add byte and time limiting", "committedDate": "2020-12-10T04:33:59Z", "type": "forcePushed"}, {"oid": "6d8c0a9f2491013336ef7301678f2ecd2b666c4e", "url": "https://github.com/apache/beam/commit/6d8c0a9f2491013336ef7301678f2ecd2b666c4e", "message": "[BEAM-10114] Add byte and time limiting", "committedDate": "2020-12-10T04:46:25Z", "type": "commit"}, {"oid": "762b7ba066cdc9895e18d4821696fb090dbd9a19", "url": "https://github.com/apache/beam/commit/762b7ba066cdc9895e18d4821696fb090dbd9a19", "message": "[BEAM-10114] Add byte and time limiting", "committedDate": "2020-12-10T07:31:54Z", "type": "commit"}, {"oid": "65b2c42a1916dc68b8bb75438f26e752ecb6f854", "url": "https://github.com/apache/beam/commit/65b2c42a1916dc68b8bb75438f26e752ecb6f854", "message": "[BEAM-10114] Add byte and time limiting", "committedDate": "2020-12-10T07:36:00Z", "type": "commit"}, {"oid": "418b3ac6d14384d191cf861866bd009d79b58f6e", "url": "https://github.com/apache/beam/commit/418b3ac6d14384d191cf861866bd009d79b58f6e", "message": "[BEAM-10114] Add byte and time limiting", "committedDate": "2020-12-10T07:40:25Z", "type": "commit"}, {"oid": "843fc4a6cecc00818246c7d8a84c33458f71d801", "url": "https://github.com/apache/beam/commit/843fc4a6cecc00818246c7d8a84c33458f71d801", "message": "[BEAM-10114] Add byte and time limiting", "committedDate": "2020-12-10T07:52:10Z", "type": "commit"}, {"oid": "fa3fc2dbcb1f426de1c71062a10143d15f48192c", "url": "https://github.com/apache/beam/commit/fa3fc2dbcb1f426de1c71062a10143d15f48192c", "message": "fix: Linter issues", "committedDate": "2020-12-14T17:30:44Z", "type": "commit"}, {"oid": "ea33f9ec500d4710386dacc00b885e5a1334c659", "url": "https://github.com/apache/beam/commit/ea33f9ec500d4710386dacc00b885e5a1334c659", "message": "fix: linters", "committedDate": "2020-12-14T17:41:19Z", "type": "commit"}, {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b", "url": "https://github.com/apache/beam/commit/88a30211fe9046969e36f6934dd00f971836ac4b", "message": "fix: linters", "committedDate": "2020-12-14T19:40:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc4NjkyNw==", "url": "https://github.com/apache/beam/pull/13470#discussion_r543786927", "bodyText": "You also want to return null when fractionOfRemainder > 0.0", "author": "boyuanzz", "createdAt": "2020-12-16T00:28:56Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Stopwatch;\n+import org.joda.time.Duration;\n+\n+/**\n+ * OffsetByteRangeTracker is an unbounded restriction tracker for Pub/Sub lite partitions that\n+ * tracks offsets for checkpointing and bytes for progress.\n+ *\n+ * <p>Any valid instance of an OffsetByteRangeTracker tracks one of exactly two types of ranges: -\n+ * Unbounded ranges whose last offset is Long.MAX_VALUE - Completed ranges that are either empty\n+ * (From == To) or fully claimed (lastClaimed == To - 1)\n+ *\n+ * <p>Also prevents splitting until minTrackingTime has passed or minBytesReceived have been\n+ * received. IMPORTANT: minTrackingTime must be strictly smaller than the SDF read timeout when it\n+ * would return ProcessContinuation.resume().\n+ */\n+class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private final Duration minTrackingTime;\n+  private final long minBytesReceived;\n+  private final Stopwatch stopwatch;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(\n+      OffsetRange range,\n+      TopicBacklogReader backlogReader,\n+      Stopwatch stopwatch,\n+      Duration minTrackingTime,\n+      long minBytesReceived) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.minTrackingTime = minTrackingTime;\n+    this.minBytesReceived = minBytesReceived;\n+    this.stopwatch = stopwatch.reset().start();\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public void finalize() {\n+    this.backlogReader.close();\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    checkState(lastClaimed == null || lastClaimed < Long.MAX_VALUE);\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  /**\n+   * Whether the tracker has received enough data/been running for enough time that it can\n+   * checkpoint and be confident it can get sufficient throughput.\n+   */\n+  private boolean receivedEnough() {\n+    Duration duration = Duration.millis(stopwatch.elapsed(TimeUnit.MILLISECONDS));\n+    if (duration.isLongerThan(minTrackingTime)) {\n+      return true;\n+    }\n+    if (byteCount >= minBytesReceived) {\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {", "originalCommit": "88a30211fe9046969e36f6934dd00f971836ac4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc4OTEyOA==", "url": "https://github.com/apache/beam/pull/13470#discussion_r543789128", "bodyText": "SubscriptionPartitionFactory?", "author": "boyuanzz", "createdAt": "2020-12-16T00:34:33Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PartitionProcessorFactory.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.io.Serializable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+\n+interface PartitionProcessorFactory extends Serializable {", "originalCommit": "88a30211fe9046969e36f6934dd00f971836ac4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc4OTI4Mw==", "url": "https://github.com/apache/beam/pull/13470#discussion_r543789283", "bodyText": "SubscriptionPartitionProcessor?", "author": "boyuanzz", "createdAt": "2020-12-16T00:34:55Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PartitionProcessor.java", "diffHunk": "@@ -17,12 +17,12 @@\n  */\n package org.apache.beam.sdk.io.gcp.pubsublite;\n \n-import com.google.cloud.pubsublite.Offset;\n-import com.google.cloud.pubsublite.Partition;\n import com.google.cloud.pubsublite.internal.CheckedApiException;\n-import java.util.Map;\n+import org.apache.beam.sdk.transforms.DoFn.ProcessContinuation;\n+import org.joda.time.Duration;\n \n-/** An internal interface for finalizing offsets. */\n-interface OffsetFinalizer {\n-  void finalizeOffsets(Map<Partition, Offset> offsets) throws CheckedApiException;\n+interface PartitionProcessor extends AutoCloseable {", "originalCommit": "88a30211fe9046969e36f6934dd00f971836ac4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc4OTQ2Mg==", "url": "https://github.com/apache/beam/pull/13470#discussion_r543789462", "bodyText": "SubscriptionPartitionProcessorImpl?", "author": "boyuanzz", "createdAt": "2020-12-16T00:35:26Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PartitionProcessorImpl.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.api.core.ApiService.Listener;\n+import com.google.api.core.ApiService.State;\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.cloudpubsub.FlowControlSettings;\n+import com.google.cloud.pubsublite.internal.CheckedApiException;\n+import com.google.cloud.pubsublite.internal.ExtractStatus;\n+import com.google.cloud.pubsublite.internal.wire.Subscriber;\n+import com.google.cloud.pubsublite.proto.Cursor;\n+import com.google.cloud.pubsublite.proto.FlowControlRequest;\n+import com.google.cloud.pubsublite.proto.SeekRequest;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.DoFn.ProcessContinuation;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.util.concurrent.MoreExecutors;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.util.concurrent.SettableFuture;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PartitionProcessorImpl extends Listener implements PartitionProcessor {", "originalCommit": "88a30211fe9046969e36f6934dd00f971836ac4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc5MDQzOQ==", "url": "https://github.com/apache/beam/pull/13470#discussion_r543790439", "bodyText": "PerSubscriptionPartitionSdf?", "author": "boyuanzz", "createdAt": "2020-12-16T00:37:57Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.Optional;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+import org.apache.beam.sdk.transforms.splittabledofn.WatermarkEstimators.MonotonicallyIncreasing;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<SubscriptionPartition, SequencedMessage> {", "originalCommit": "88a30211fe9046969e36f6934dd00f971836ac4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc5MjcxMw==", "url": "https://github.com/apache/beam/pull/13470#discussion_r543792713", "bodyText": "When you have got the result from processor.waitForCompletion(maxSleepTime), the tracker.currentRestriction().getTo() will be the lastClaimed you want.", "author": "boyuanzz", "createdAt": "2020-12-16T00:43:52Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.Optional;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+import org.apache.beam.sdk.transforms.splittabledofn.WatermarkEstimators.MonotonicallyIncreasing;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<SubscriptionPartition, SequencedMessage> {\n+  private final Duration maxSleepTime;\n+  private final PartitionProcessorFactory processorFactory;\n+  private final SerializableFunction<SubscriptionPartition, InitialOffsetReader>\n+      offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          SubscriptionPartition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+  private final SerializableFunction<SubscriptionPartition, Committer> committerFactory;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableFunction<SubscriptionPartition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              SubscriptionPartition,\n+              OffsetRange,\n+              RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory,\n+      PartitionProcessorFactory processorFactory,\n+      SerializableFunction<SubscriptionPartition, Committer> committerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.processorFactory = processorFactory;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+    this.committerFactory = committerFactory;\n+  }\n+\n+  private static final class WrappedTracker\n+      extends RestrictionTracker<OffsetRange, OffsetByteProgress> {\n+    private final RestrictionTracker<OffsetRange, OffsetByteProgress> underlying;\n+    Optional<Offset> lastClaimed;\n+\n+    WrappedTracker(RestrictionTracker<OffsetRange, OffsetByteProgress> underlying) {\n+      this.underlying = underlying;\n+      this.lastClaimed = Optional.empty();\n+    }\n+\n+    @Override\n+    public boolean tryClaim(OffsetByteProgress position) {\n+      boolean claimed = underlying.tryClaim(position);\n+      if (claimed) {\n+        lastClaimed = Optional.of(position.lastOffset());\n+      }\n+      return claimed;\n+    }\n+\n+    @Override\n+    public OffsetRange currentRestriction() {\n+      return underlying.currentRestriction();\n+    }\n+\n+    @Override\n+    public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {\n+      return underlying.trySplit(fractionOfRemainder);\n+    }\n+\n+    @Override\n+    public void checkDone() throws IllegalStateException {\n+      underlying.checkDone();\n+    }\n+\n+    @Override\n+    public IsBounded isBounded() {\n+      return underlying.isBounded();\n+    }\n+  }\n+\n+  @GetInitialWatermarkEstimatorState\n+  Instant getInitialWatermarkState() {\n+    return Instant.EPOCH;\n+  }\n+\n+  @NewWatermarkEstimator\n+  MonotonicallyIncreasing newWatermarkEstimator(@WatermarkEstimatorState Instant state) {\n+    return new MonotonicallyIncreasing(state);\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element SubscriptionPartition subscriptionPartition,\n+      OutputReceiver<SequencedMessage> receiver,\n+      BundleFinalizer finalizer)\n+      throws Exception {\n+    WrappedTracker wrapped = new WrappedTracker(tracker);\n+    try (PartitionProcessor processor =\n+        processorFactory.newProcessor(subscriptionPartition, wrapped, receiver)) {\n+      processor.start();\n+      ProcessContinuation result = processor.waitForCompletion(maxSleepTime);\n+      wrapped.lastClaimed.ifPresent(", "originalCommit": "88a30211fe9046969e36f6934dd00f971836ac4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc5NjAyNQ==", "url": "https://github.com/apache/beam/pull/13470#discussion_r543796025", "bodyText": "I don'y think inserting a Reshuffle is necessary.", "author": "boyuanzz", "createdAt": "2020-12-16T00:52:41Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static com.google.cloud.pubsublite.internal.ExtractStatus.toCanonical;\n+import static com.google.cloud.pubsublite.internal.UncheckedApiPreconditions.checkArgument;\n+\n+import com.google.api.gax.rpc.ApiException;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.internal.wire.Subscriber;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.List;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.Reshuffle;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Stopwatch;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.math.LongMath;\n+import org.joda.time.Duration;\n+\n+class SubscribeTransform extends PTransform<PBegin, PCollection<SequencedMessage>> {\n+  private static final Duration MAX_SLEEP_TIME = Duration.standardMinutes(1);\n+\n+  private final SubscriberOptions options;\n+\n+  SubscribeTransform(SubscriberOptions options) {\n+    this.options = options;\n+  }\n+\n+  private void checkSubscription(SubscriptionPartition subscriptionPartition) throws ApiException {\n+    checkArgument(subscriptionPartition.subscription().equals(options.subscriptionPath()));\n+  }\n+\n+  private Subscriber newSubscriber(Partition partition, Consumer<List<SequencedMessage>> consumer) {\n+    try {\n+      return options\n+          .getSubscriberFactory(partition)\n+          .newSubscriber(\n+              messages ->\n+                  consumer.accept(\n+                      messages.stream()\n+                          .map(message -> message.toProto())\n+                          .collect(Collectors.toList())));\n+    } catch (Throwable t) {\n+      throw toCanonical(t).underlying;\n+    }\n+  }\n+\n+  private PartitionProcessor newPartitionProcessor(\n+      SubscriptionPartition subscriptionPartition,\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      OutputReceiver<SequencedMessage> receiver)\n+      throws ApiException {\n+    checkSubscription(subscriptionPartition);\n+    return new PartitionProcessorImpl(\n+        tracker,\n+        receiver,\n+        consumer -> newSubscriber(subscriptionPartition.partition(), consumer),\n+        options.flowControlSettings());\n+  }\n+\n+  private RestrictionTracker<OffsetRange, OffsetByteProgress> newRestrictionTracker(\n+      SubscriptionPartition subscriptionPartition, OffsetRange initial) {\n+    checkSubscription(subscriptionPartition);\n+    return new OffsetByteRangeTracker(\n+        initial,\n+        options.getBacklogReader(subscriptionPartition.partition()),\n+        Stopwatch.createUnstarted(),\n+        MAX_SLEEP_TIME.multipliedBy(3).dividedBy(4),\n+        LongMath.saturatedMultiply(options.flowControlSettings().bytesOutstanding(), 10));\n+  }\n+\n+  private InitialOffsetReader newInitialOffsetReader(SubscriptionPartition subscriptionPartition) {\n+    checkSubscription(subscriptionPartition);\n+    return options.getInitialOffsetReader(subscriptionPartition.partition());\n+  }\n+\n+  private Committer newCommitter(SubscriptionPartition subscriptionPartition) {\n+    checkSubscription(subscriptionPartition);\n+    return options.getCommitter(subscriptionPartition.partition());\n+  }\n+\n+  @Override\n+  public PCollection<SequencedMessage> expand(PBegin input) {\n+    PCollection<SubscriptionPartition> partitions =\n+        Create.of(\n+                options.partitions().stream()\n+                    .map(\n+                        partition ->\n+                            SubscriptionPartition.of(options.subscriptionPath(), partition))\n+                    .collect(Collectors.toList()))\n+            .expand(input);\n+    // Prevent fusion between Create and read.\n+    PCollection<SubscriptionPartition> shuffledPartitions =", "originalCommit": "88a30211fe9046969e36f6934dd00f971836ac4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzgwMDIyNQ==", "url": "https://github.com/apache/beam/pull/13470#discussion_r543800225", "bodyText": "I'm curious why we need a trackerFactory here instead of returning your OffsetByteRangeTracker directly. Do you expect your SDF user to implement their own restriction tracker?", "author": "boyuanzz", "createdAt": "2020-12-16T01:03:53Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.Optional;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+import org.apache.beam.sdk.transforms.splittabledofn.WatermarkEstimators.MonotonicallyIncreasing;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<SubscriptionPartition, SequencedMessage> {\n+  private final Duration maxSleepTime;\n+  private final PartitionProcessorFactory processorFactory;\n+  private final SerializableFunction<SubscriptionPartition, InitialOffsetReader>\n+      offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          SubscriptionPartition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+  private final SerializableFunction<SubscriptionPartition, Committer> committerFactory;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableFunction<SubscriptionPartition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              SubscriptionPartition,\n+              OffsetRange,\n+              RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory,\n+      PartitionProcessorFactory processorFactory,\n+      SerializableFunction<SubscriptionPartition, Committer> committerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.processorFactory = processorFactory;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+    this.committerFactory = committerFactory;\n+  }\n+\n+  private static final class WrappedTracker\n+      extends RestrictionTracker<OffsetRange, OffsetByteProgress> {\n+    private final RestrictionTracker<OffsetRange, OffsetByteProgress> underlying;\n+    Optional<Offset> lastClaimed;\n+\n+    WrappedTracker(RestrictionTracker<OffsetRange, OffsetByteProgress> underlying) {\n+      this.underlying = underlying;\n+      this.lastClaimed = Optional.empty();\n+    }\n+\n+    @Override\n+    public boolean tryClaim(OffsetByteProgress position) {\n+      boolean claimed = underlying.tryClaim(position);\n+      if (claimed) {\n+        lastClaimed = Optional.of(position.lastOffset());\n+      }\n+      return claimed;\n+    }\n+\n+    @Override\n+    public OffsetRange currentRestriction() {\n+      return underlying.currentRestriction();\n+    }\n+\n+    @Override\n+    public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {\n+      return underlying.trySplit(fractionOfRemainder);\n+    }\n+\n+    @Override\n+    public void checkDone() throws IllegalStateException {\n+      underlying.checkDone();\n+    }\n+\n+    @Override\n+    public IsBounded isBounded() {\n+      return underlying.isBounded();\n+    }\n+  }\n+\n+  @GetInitialWatermarkEstimatorState\n+  Instant getInitialWatermarkState() {\n+    return Instant.EPOCH;\n+  }\n+\n+  @NewWatermarkEstimator\n+  MonotonicallyIncreasing newWatermarkEstimator(@WatermarkEstimatorState Instant state) {\n+    return new MonotonicallyIncreasing(state);\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element SubscriptionPartition subscriptionPartition,\n+      OutputReceiver<SequencedMessage> receiver,\n+      BundleFinalizer finalizer)\n+      throws Exception {\n+    WrappedTracker wrapped = new WrappedTracker(tracker);\n+    try (PartitionProcessor processor =\n+        processorFactory.newProcessor(subscriptionPartition, wrapped, receiver)) {\n+      processor.start();\n+      ProcessContinuation result = processor.waitForCompletion(maxSleepTime);\n+      wrapped.lastClaimed.ifPresent(\n+          lastClaimedOffset ->\n+              finalizer.afterBundleCommit(\n+                  Instant.ofEpochMilli(Long.MAX_VALUE),\n+                  () -> {\n+                    Committer committer = committerFactory.apply(subscriptionPartition);\n+                    committer.startAsync().awaitRunning();\n+                    // Commit the next-to-deliver offset.\n+                    committer.commitOffset(Offset.of(lastClaimedOffset.value() + 1)).get();\n+                    committer.stopAsync().awaitTerminated();\n+                  }));\n+      return result;\n+    }\n+  }\n+\n+  @GetInitialRestriction\n+  public OffsetRange getInitialRestriction(@Element SubscriptionPartition subscriptionPartition) {\n+    try (InitialOffsetReader reader = offsetReaderFactory.apply(subscriptionPartition)) {\n+      Offset offset = reader.read();\n+      return new OffsetRange(offset.value(), Long.MAX_VALUE /* open interval */);\n+    }\n+  }\n+\n+  @NewTracker\n+  public RestrictionTracker<OffsetRange, OffsetByteProgress> newTracker(\n+      @Element SubscriptionPartition subscriptionPartition, @Restriction OffsetRange range) {\n+    return trackerFactory.apply(subscriptionPartition, range);", "originalCommit": "88a30211fe9046969e36f6934dd00f971836ac4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzgwMTk0OQ==", "url": "https://github.com/apache/beam/pull/13470#discussion_r543801949", "bodyText": "Can the PerPartitionSdf take the SubscriberOptions  as the constructor? Then the PerParittionSdf can construct  Committer, PartitionProcessor and InitialOffsetReader by itself, instead of asking the caller to do so?", "author": "boyuanzz", "createdAt": "2020-12-16T01:08:11Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static com.google.cloud.pubsublite.internal.ExtractStatus.toCanonical;\n+import static com.google.cloud.pubsublite.internal.UncheckedApiPreconditions.checkArgument;\n+\n+import com.google.api.gax.rpc.ApiException;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.internal.wire.Subscriber;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.List;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.Reshuffle;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Stopwatch;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.math.LongMath;\n+import org.joda.time.Duration;\n+\n+class SubscribeTransform extends PTransform<PBegin, PCollection<SequencedMessage>> {\n+  private static final Duration MAX_SLEEP_TIME = Duration.standardMinutes(1);\n+\n+  private final SubscriberOptions options;\n+\n+  SubscribeTransform(SubscriberOptions options) {\n+    this.options = options;\n+  }\n+\n+  private void checkSubscription(SubscriptionPartition subscriptionPartition) throws ApiException {\n+    checkArgument(subscriptionPartition.subscription().equals(options.subscriptionPath()));\n+  }\n+\n+  private Subscriber newSubscriber(Partition partition, Consumer<List<SequencedMessage>> consumer) {\n+    try {\n+      return options\n+          .getSubscriberFactory(partition)\n+          .newSubscriber(\n+              messages ->\n+                  consumer.accept(\n+                      messages.stream()\n+                          .map(message -> message.toProto())\n+                          .collect(Collectors.toList())));\n+    } catch (Throwable t) {\n+      throw toCanonical(t).underlying;\n+    }\n+  }\n+\n+  private PartitionProcessor newPartitionProcessor(\n+      SubscriptionPartition subscriptionPartition,\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      OutputReceiver<SequencedMessage> receiver)\n+      throws ApiException {\n+    checkSubscription(subscriptionPartition);\n+    return new PartitionProcessorImpl(\n+        tracker,\n+        receiver,\n+        consumer -> newSubscriber(subscriptionPartition.partition(), consumer),\n+        options.flowControlSettings());\n+  }\n+\n+  private RestrictionTracker<OffsetRange, OffsetByteProgress> newRestrictionTracker(\n+      SubscriptionPartition subscriptionPartition, OffsetRange initial) {\n+    checkSubscription(subscriptionPartition);\n+    return new OffsetByteRangeTracker(\n+        initial,\n+        options.getBacklogReader(subscriptionPartition.partition()),\n+        Stopwatch.createUnstarted(),\n+        MAX_SLEEP_TIME.multipliedBy(3).dividedBy(4),\n+        LongMath.saturatedMultiply(options.flowControlSettings().bytesOutstanding(), 10));\n+  }\n+\n+  private InitialOffsetReader newInitialOffsetReader(SubscriptionPartition subscriptionPartition) {\n+    checkSubscription(subscriptionPartition);\n+    return options.getInitialOffsetReader(subscriptionPartition.partition());\n+  }\n+\n+  private Committer newCommitter(SubscriptionPartition subscriptionPartition) {\n+    checkSubscription(subscriptionPartition);\n+    return options.getCommitter(subscriptionPartition.partition());\n+  }\n+\n+  @Override\n+  public PCollection<SequencedMessage> expand(PBegin input) {\n+    PCollection<SubscriptionPartition> partitions =\n+        Create.of(\n+                options.partitions().stream()\n+                    .map(\n+                        partition ->\n+                            SubscriptionPartition.of(options.subscriptionPath(), partition))\n+                    .collect(Collectors.toList()))\n+            .expand(input);\n+    // Prevent fusion between Create and read.\n+    PCollection<SubscriptionPartition> shuffledPartitions =\n+        partitions.apply(Reshuffle.viaRandomKey());\n+    return shuffledPartitions.apply(\n+        ParDo.of(\n+            new PerPartitionSdf(\n+                MAX_SLEEP_TIME,\n+                this::newInitialOffsetReader,", "originalCommit": "88a30211fe9046969e36f6934dd00f971836ac4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzgwMjUyMw==", "url": "https://github.com/apache/beam/pull/13470#discussion_r543802523", "bodyText": "Have you consider the x-lang usage, where you may want to use Schema to represent your element?", "author": "boyuanzz", "createdAt": "2020-12-16T01:09:49Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscriptionPartitionCoder.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.SubscriptionPath;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import org.apache.beam.sdk.coders.AtomicCoder;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.CoderProvider;\n+import org.apache.beam.sdk.coders.CoderProviders;\n+import org.apache.beam.sdk.coders.DelegateCoder;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.coders.VarLongCoder;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+\n+public class SubscriptionPartitionCoder extends AtomicCoder<SubscriptionPartition> {", "originalCommit": "88a30211fe9046969e36f6934dd00f971836ac4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzgwMzUxNw==", "url": "https://github.com/apache/beam/pull/13470#discussion_r543803517", "bodyText": "Why not put the whole logic into PubSubLiteIO?", "author": "boyuanzz", "createdAt": "2020-12-16T01:12:21Z", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static com.google.cloud.pubsublite.internal.ExtractStatus.toCanonical;\n+import static com.google.cloud.pubsublite.internal.UncheckedApiPreconditions.checkArgument;\n+\n+import com.google.api.gax.rpc.ApiException;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.internal.wire.Subscriber;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.List;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.Reshuffle;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Stopwatch;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.math.LongMath;\n+import org.joda.time.Duration;\n+\n+class SubscribeTransform extends PTransform<PBegin, PCollection<SequencedMessage>> {", "originalCommit": "88a30211fe9046969e36f6934dd00f971836ac4b", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b731da8a2cf8fc8c227e33e23955333da19adbbd", "url": "https://github.com/apache/beam/commit/b731da8a2cf8fc8c227e33e23955333da19adbbd", "message": "fix: Remove unnecessary shuffle.", "committedDate": "2020-12-16T01:27:09Z", "type": "commit"}, {"oid": "a432e8f05ffad7db85cdb690e277b5aeb3e10ba8", "url": "https://github.com/apache/beam/commit/a432e8f05ffad7db85cdb690e277b5aeb3e10ba8", "message": "fix: Address comments", "committedDate": "2020-12-16T02:45:14Z", "type": "commit"}]}