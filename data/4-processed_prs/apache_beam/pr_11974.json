{"pr_number": 11974, "pr_title": "[BEAM-9547] Add more methods to deferred dataframes.", "pr_createdAt": "2020-06-10T20:49:44Z", "pr_url": "https://github.com/apache/beam/pull/11974", "timeline": [{"oid": "36dc7650ba6bbf2923771069019a96d4cc441f99", "url": "https://github.com/apache/beam/commit/36dc7650ba6bbf2923771069019a96d4cc441f99", "message": "Extend elementwise to generic proxy fn.", "committedDate": "2020-07-17T17:37:47Z", "type": "commit"}, {"oid": "ce5d75b1fdccc672977da155fbebec12ccc6afee", "url": "https://github.com/apache/beam/commit/ce5d75b1fdccc672977da155fbebec12ccc6afee", "message": "Add a more methods to dataframes.", "committedDate": "2020-07-17T18:31:43Z", "type": "commit"}, {"oid": "24effc3a1e056727ca755e7494070da2a368b602", "url": "https://github.com/apache/beam/commit/24effc3a1e056727ca755e7494070da2a368b602", "message": "More dataframes methods and test filters.", "committedDate": "2020-07-17T18:42:35Z", "type": "forcePushed"}, {"oid": "a37170e5c6210d56a54b53b54a6044f62dac4626", "url": "https://github.com/apache/beam/commit/a37170e5c6210d56a54b53b54a6044f62dac4626", "message": "Add support for dataframe scalar values.", "committedDate": "2020-07-17T22:28:26Z", "type": "commit"}, {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "url": "https://github.com/apache/beam/commit/8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "message": "More dataframes methods and test filters.", "committedDate": "2020-07-17T22:28:26Z", "type": "commit"}, {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "url": "https://github.com/apache/beam/commit/8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "message": "More dataframes methods and test filters.", "committedDate": "2020-07-17T22:28:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0MjY0NQ==", "url": "https://github.com/apache/beam/pull/11974#discussion_r461942645", "bodyText": "Doesn't need to happen in this PR, but it could be preferable to have different types/modes of skip. e.g.\n\nallow_wont_implement: passes if WontImplementError is thrown.\nallow_error: passes if any other exception is thrown\nalllow_error_or_wrong_answer: passes if an exception is thrown or if Beam is producing the wrong answer.\n\nThat way it'll be clearly documented which ops we don't intend to implement, and which ones can produce incorrect data and should be avoided.", "author": "TheNeuralBit", "createdAt": "2020-07-28T23:04:48Z", "path": "sdks/python/apache_beam/dataframe/pandas_doctests_test.py", "diffHunk": "@@ -34,77 +34,54 @@ def test_dataframe_tests(self):\n             'pandas.core.frame.DataFrame.T': ['*'],\n             'pandas.core.frame.DataFrame.agg': ['*'],\n             'pandas.core.frame.DataFrame.aggregate': ['*'],\n-            'pandas.core.frame.DataFrame.all': ['*'],\n-            'pandas.core.frame.DataFrame.any': ['*'],\n             'pandas.core.frame.DataFrame.append': ['*'],\n             'pandas.core.frame.DataFrame.apply': ['*'],\n-            'pandas.core.frame.DataFrame.applymap': ['*'],\n+            'pandas.core.frame.DataFrame.applymap': ['df ** 2'],\n             'pandas.core.frame.DataFrame.assign': ['*'],\n             'pandas.core.frame.DataFrame.axes': ['*'],\n             'pandas.core.frame.DataFrame.combine': ['*'],\n             'pandas.core.frame.DataFrame.combine_first': ['*'],\n             'pandas.core.frame.DataFrame.corr': ['*'],\n             'pandas.core.frame.DataFrame.count': ['*'],\n             'pandas.core.frame.DataFrame.cov': ['*'],\n-            'pandas.core.frame.DataFrame.cummax': ['*'],\n-            'pandas.core.frame.DataFrame.cummin': ['*'],\n-            'pandas.core.frame.DataFrame.cumprod': ['*'],\n-            'pandas.core.frame.DataFrame.cumsum': ['*'],\n-            'pandas.core.frame.DataFrame.diff': ['*'],\n             'pandas.core.frame.DataFrame.dot': ['*'],\n             'pandas.core.frame.DataFrame.drop': ['*'],\n-            'pandas.core.frame.DataFrame.dropna': ['*'],\n             'pandas.core.frame.DataFrame.eval': ['*'],\n             'pandas.core.frame.DataFrame.explode': ['*'],\n             'pandas.core.frame.DataFrame.fillna': ['*'],\n             'pandas.core.frame.DataFrame.info': ['*'],\n             'pandas.core.frame.DataFrame.isin': ['*'],\n-            'pandas.core.frame.DataFrame.isna': ['*'],\n-            'pandas.core.frame.DataFrame.isnull': ['*'],\n-            'pandas.core.frame.DataFrame.items': ['*'],\n-            'pandas.core.frame.DataFrame.iteritems': ['*'],\n-            'pandas.core.frame.DataFrame.iterrows': ['*'],\n-            'pandas.core.frame.DataFrame.itertuples': ['*'],\n+            'pandas.core.frame.DataFrame.iterrows': [\"print(df['int'].dtype)\"],\n             'pandas.core.frame.DataFrame.join': ['*'],\n-            'pandas.core.frame.DataFrame.max': ['*'],\n             'pandas.core.frame.DataFrame.melt': ['*'],\n             'pandas.core.frame.DataFrame.memory_usage': ['*'],\n             'pandas.core.frame.DataFrame.merge': ['*'],\n-            'pandas.core.frame.DataFrame.min': ['*'],\n-            'pandas.core.frame.DataFrame.mode': ['*'],\n+            # Not equal to df.agg('mode', axis='columns', numeric_only=True)\n+            'pandas.core.frame.DataFrame.mode': [\n+                \"df.mode(axis='columns', numeric_only=True)\"\n+            ],\n             'pandas.core.frame.DataFrame.nlargest': ['*'],\n-            'pandas.core.frame.DataFrame.notna': ['*'],\n-            'pandas.core.frame.DataFrame.notnull': ['*'],\n             'pandas.core.frame.DataFrame.nsmallest': ['*'],\n             'pandas.core.frame.DataFrame.nunique': ['*'],\n             'pandas.core.frame.DataFrame.pivot': ['*'],\n             'pandas.core.frame.DataFrame.pivot_table': ['*'],\n-            'pandas.core.frame.DataFrame.prod': ['*'],\n-            'pandas.core.frame.DataFrame.product': ['*'],\n-            'pandas.core.frame.DataFrame.quantile': ['*'],\n             'pandas.core.frame.DataFrame.query': ['*'],\n             'pandas.core.frame.DataFrame.reindex': ['*'],\n             'pandas.core.frame.DataFrame.reindex_axis': ['*'],\n             'pandas.core.frame.DataFrame.rename': ['*'],\n-            'pandas.core.frame.DataFrame.replace': ['*'],\n-            'pandas.core.frame.DataFrame.reset_index': ['*'],\n+            # Raises right exception, but testing framework has matching issues.\n+            'pandas.core.frame.DataFrame.replace': [\n+                \"df.replace({'a string': 'new value', True: False})  # raises\"\n+            ],\n+            # Uses unseeded np.random.\n             'pandas.core.frame.DataFrame.round': ['*'],\n-            'pandas.core.frame.DataFrame.select_dtypes': ['*'],\n             'pandas.core.frame.DataFrame.set_index': ['*'],\n-            'pandas.core.frame.DataFrame.shape': ['*'],\n-            'pandas.core.frame.DataFrame.shift': ['*'],\n-            'pandas.core.frame.DataFrame.sort_values': ['*'],\n-            'pandas.core.frame.DataFrame.stack': ['*'],\n-            'pandas.core.frame.DataFrame.sum': ['*'],\n-            'pandas.core.frame.DataFrame.to_dict': ['*'],\n-            'pandas.core.frame.DataFrame.to_numpy': ['*'],\n+            'pandas.core.frame.DataFrame.transpose': [\n+                'df1_transposed.dtypes', 'df2_transposed.dtypes'\n+            ],\n+            'pandas.core.frame.DataFrame.to_sparse': ['type(df)'],\n+            # Uses df.index", "originalCommit": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1MDQzNg==", "url": "https://github.com/apache/beam/pull/11974#discussion_r462450436", "bodyText": "Good idea. (One unfortunate thing is that each of these actually implements multiple tests, but that just means the declarations might be overly broad.)", "author": "robertwb", "createdAt": "2020-07-29T17:02:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0MjY0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1MTc4Ng==", "url": "https://github.com/apache/beam/pull/11974#discussion_r461951786", "bodyText": "Looks like this can be 'columns' as well: https://pandas.pydata.org/pandas-docs/version/0.24.2/reference/api/pandas.DataFrame.shift.html?highlight=shift#pandas.DataFrame.shift\nWe should check for that  throughout so we don't end up using Singleton partitioning unnecessarily.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                if axis == 1:\n          \n          \n            \n                if axis == 1 or axis == 'columns':", "author": "TheNeuralBit", "createdAt": "2020-07-28T23:31:53Z", "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -111,19 +164,181 @@ def at(self, *args, **kwargs):\n   def loc(self):\n     return _DeferredLoc(self)\n \n-  def aggregate(self, func, axis=0, *args, **kwargs):\n-    if axis != 0:\n-      raise NotImplementedError()\n+  def aggregate(self, *args, **kwargs):\n+    if 'axis' in kwargs and kwargs['axis'] is None:\n+      return self.agg(*args, **dict(kwargs, axis=1)).agg(\n+          *args, **dict(kwargs, axis=0))\n     return frame_base.DeferredFrame.wrap(\n         expressions.ComputedExpression(\n             'aggregate',\n-            lambda df: df.agg(func, axis, *args, **kwargs),\n+            lambda df: df.agg(*args, **kwargs),\n             [self._expr],\n             # TODO(robertwb): Sub-aggregate when possible.\n             requires_partition_by=partitionings.Singleton()))\n \n   agg = aggregate\n \n+  applymap = frame_base._elementwise_method('applymap')\n+\n+  def memory_usage(self):\n+    raise frame_base.WontImplementError()\n+\n+  all = frame_base._associative_agg_method('all')\n+  any = frame_base._associative_agg_method('any')\n+\n+  cummax = cummin = cumsum = cumprod = frame_base.wont_implement_method(\n+      'order-sensitive')\n+  diff = frame_base.wont_implement_method('order-sensitive')\n+\n+  max = frame_base._associative_agg_method('max')\n+  min = frame_base._associative_agg_method('min')\n+  mode = frame_base._agg_method('mode')\n+\n+  def dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False, *args, **kwargs):\n+    # TODO(robertwb): This is a common pattern. Generalize?\n+    if axis == 1:\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'dropna',\n+            lambda df: df.dropna(axis, how, thresh, subset, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  items = itertuples = iterrows = iteritems = frame_base.wont_implement_method(\n+      'non-lazy')\n+\n+  isna = frame_base._elementwise_method('isna')\n+  notnull = notna = frame_base._elementwise_method('notna')\n+\n+  prod = product = frame_base._associative_agg_method('prod')\n+\n+  def quantile(self, q=0.5, axis=0, *args, **kwargs):\n+    if axis != 0:\n+      raise frame_base.WontImplementError('non-deferred column values')\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'quantile',\n+            lambda df: df.quantile(q, axis, *args, **kwargs),\n+            [self._expr],\n+            #TODO(robertwb): Approximate quantiles?\n+            requires_partition_by=partitionings.Singleton(),\n+            preserves_partition_by=partitionings.Singleton()))\n+\n+  query = frame_base._elementwise_method('query')\n+\n+  def replace(self, to_replace=None,\n+      value=None,\n+      inplace=False,\n+      limit=None, *args, **kwargs):\n+    if limit is None:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'replace',\n+            lambda df: df.replace(to_replace, value, False, limit, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  def reset_index(self, level=None, drop=False, inplace=False, *args, **kwargs):\n+    if level is not None and not isinstance(level, (tuple, list)):\n+      level = [level]\n+    if level is None or len(level) == len(self._expr.proxy().index.levels):\n+      # TODO: Could do distributed re-index with offsets.\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'reset_index',\n+            lambda df: df.reset_index(level, drop, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  round = frame_base._elementwise_method('round')\n+  select_dtypes = frame_base._elementwise_method('select_dtypes')\n+\n+  def shift(self, periods=1, freq=None, axis=0, *args, **kwargs):\n+    if axis == 1:", "originalCommit": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ0NzQ0NA==", "url": "https://github.com/apache/beam/pull/11974#discussion_r462447444", "bodyText": "Fixed several occurrences.", "author": "robertwb", "createdAt": "2020-07-29T16:57:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1MTc4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1Mjc4Nw==", "url": "https://github.com/apache/beam/pull/11974#discussion_r461952787", "bodyText": "nit: should this be scalar?", "author": "TheNeuralBit", "createdAt": "2020-07-28T23:34:50Z", "path": "sdks/python/apache_beam/dataframe/frame_base.py", "diffHunk": "@@ -41,16 +42,34 @@ def wrapper(deferred_type):\n \n   @classmethod\n   def wrap(cls, expr):\n-    return cls._pandas_type_map[type(expr.proxy())](expr)\n+    proxy_type = type(expr.proxy())\n+    if proxy_type in cls._pandas_type_map:\n+      wrapper_type = cls._pandas_type_map[proxy_type]\n+    else:\n+      if expr.requires_partition_by() != partitionings.Singleton():\n+        raise ValueError(\n+            'Scalar expression %s partitoned by non-singleton %s' %\n+            (expr, expr.requires_partition_by()))\n+      wrapper_type = _DeferredScaler\n+    return wrapper_type(expr)\n \n   def _elementwise(self, func, name=None, other_args=(), inplace=False):\n     return _elementwise_function(func, name, inplace=inplace)(self, *other_args)\n \n+\n+class DeferredFrame(DeferredBase):\n   @property\n   def dtypes(self):\n     return self._expr.proxy().dtypes\n \n \n+class _DeferredScaler(DeferredBase):", "originalCommit": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ0NTI3Ng==", "url": "https://github.com/apache/beam/pull/11974#discussion_r462445276", "bodyText": "Yes, thanks.", "author": "robertwb", "createdAt": "2020-07-29T16:54:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1Mjc4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NzQzMQ==", "url": "https://github.com/apache/beam/pull/11974#discussion_r461957431", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              def to_string(self, *args, **kwargs):\n          \n          \n            \n                raise frame_base.WontImplementError('non-deferred value')\n          \n          \n            \n            \n          \n          \n            \n              to_records = to_dict = to_numpy = to_string\n          \n          \n            \n              to_records = to_dict = to_numpy = to_string = frame_base.wont_implement_method('non-deferred value')\n          \n      \n    \n    \n  \n\nnit: I think we should prefer wont_implement_method instead of def and raise", "author": "TheNeuralBit", "createdAt": "2020-07-28T23:49:33Z", "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -111,19 +164,181 @@ def at(self, *args, **kwargs):\n   def loc(self):\n     return _DeferredLoc(self)\n \n-  def aggregate(self, func, axis=0, *args, **kwargs):\n-    if axis != 0:\n-      raise NotImplementedError()\n+  def aggregate(self, *args, **kwargs):\n+    if 'axis' in kwargs and kwargs['axis'] is None:\n+      return self.agg(*args, **dict(kwargs, axis=1)).agg(\n+          *args, **dict(kwargs, axis=0))\n     return frame_base.DeferredFrame.wrap(\n         expressions.ComputedExpression(\n             'aggregate',\n-            lambda df: df.agg(func, axis, *args, **kwargs),\n+            lambda df: df.agg(*args, **kwargs),\n             [self._expr],\n             # TODO(robertwb): Sub-aggregate when possible.\n             requires_partition_by=partitionings.Singleton()))\n \n   agg = aggregate\n \n+  applymap = frame_base._elementwise_method('applymap')\n+\n+  def memory_usage(self):\n+    raise frame_base.WontImplementError()\n+\n+  all = frame_base._associative_agg_method('all')\n+  any = frame_base._associative_agg_method('any')\n+\n+  cummax = cummin = cumsum = cumprod = frame_base.wont_implement_method(\n+      'order-sensitive')\n+  diff = frame_base.wont_implement_method('order-sensitive')\n+\n+  max = frame_base._associative_agg_method('max')\n+  min = frame_base._associative_agg_method('min')\n+  mode = frame_base._agg_method('mode')\n+\n+  def dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False, *args, **kwargs):\n+    # TODO(robertwb): This is a common pattern. Generalize?\n+    if axis == 1:\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'dropna',\n+            lambda df: df.dropna(axis, how, thresh, subset, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  items = itertuples = iterrows = iteritems = frame_base.wont_implement_method(\n+      'non-lazy')\n+\n+  isna = frame_base._elementwise_method('isna')\n+  notnull = notna = frame_base._elementwise_method('notna')\n+\n+  prod = product = frame_base._associative_agg_method('prod')\n+\n+  def quantile(self, q=0.5, axis=0, *args, **kwargs):\n+    if axis != 0:\n+      raise frame_base.WontImplementError('non-deferred column values')\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'quantile',\n+            lambda df: df.quantile(q, axis, *args, **kwargs),\n+            [self._expr],\n+            #TODO(robertwb): Approximate quantiles?\n+            requires_partition_by=partitionings.Singleton(),\n+            preserves_partition_by=partitionings.Singleton()))\n+\n+  query = frame_base._elementwise_method('query')\n+\n+  def replace(self, to_replace=None,\n+      value=None,\n+      inplace=False,\n+      limit=None, *args, **kwargs):\n+    if limit is None:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'replace',\n+            lambda df: df.replace(to_replace, value, False, limit, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  def reset_index(self, level=None, drop=False, inplace=False, *args, **kwargs):\n+    if level is not None and not isinstance(level, (tuple, list)):\n+      level = [level]\n+    if level is None or len(level) == len(self._expr.proxy().index.levels):\n+      # TODO: Could do distributed re-index with offsets.\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'reset_index',\n+            lambda df: df.reset_index(level, drop, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  round = frame_base._elementwise_method('round')\n+  select_dtypes = frame_base._elementwise_method('select_dtypes')\n+\n+  def shift(self, periods=1, freq=None, axis=0, *args, **kwargs):\n+    if axis == 1:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'shift',\n+            lambda df: df.shift(periods, freq, axis, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+\n+  @property\n+  def shape(self):\n+    raise frame_base.WontImplementError('scalar value')\n+\n+  def sort_values(self, by, axis=0, ascending=True, inplace=False, *args, **kwargs):\n+    if axis == 1:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'sort_values',\n+            lambda df: df.sort_values(by, axis, ascending, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  stack = frame_base._elementwise_method('stack')\n+\n+  sum = frame_base._associative_agg_method('sum')\n+\n+  def to_string(self, *args, **kwargs):\n+    raise frame_base.WontImplementError('non-deferred value')\n+\n+  to_records = to_dict = to_numpy = to_string", "originalCommit": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ0ODMzMg==", "url": "https://github.com/apache/beam/pull/11974#discussion_r462448332", "bodyText": "Agreed. (I added this helper later.)", "author": "robertwb", "createdAt": "2020-07-29T16:58:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NzQzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1ODc0Ng==", "url": "https://github.com/apache/beam/pull/11974#discussion_r461958746", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        'pandas.core.frame.DataFrame.agg': ['*'],\n          \n          \n            \n                        'pandas.core.frame.DataFrame.aggregate': ['*'],\n          \n      \n    \n    \n  \n\nThese should be supported right (also for Series)? Looks like the tests pass for me locally with these unskipped.", "author": "TheNeuralBit", "createdAt": "2020-07-28T23:53:45Z", "path": "sdks/python/apache_beam/dataframe/pandas_doctests_test.py", "diffHunk": "@@ -34,77 +34,54 @@ def test_dataframe_tests(self):\n             'pandas.core.frame.DataFrame.T': ['*'],\n             'pandas.core.frame.DataFrame.agg': ['*'],\n             'pandas.core.frame.DataFrame.aggregate': ['*'],", "originalCommit": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk2MDczMQ==", "url": "https://github.com/apache/beam/pull/11974#discussion_r461960731", "bodyText": "Any thoughts on how we should communicate to the user that Singleton partitioning is happening and it's bad?\nMaybe we should refuse to apply operations that require singleton partitioning by default unless a user opts in?", "author": "TheNeuralBit", "createdAt": "2020-07-29T00:00:16Z", "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -111,19 +164,181 @@ def at(self, *args, **kwargs):\n   def loc(self):\n     return _DeferredLoc(self)\n \n-  def aggregate(self, func, axis=0, *args, **kwargs):\n-    if axis != 0:\n-      raise NotImplementedError()\n+  def aggregate(self, *args, **kwargs):\n+    if 'axis' in kwargs and kwargs['axis'] is None:\n+      return self.agg(*args, **dict(kwargs, axis=1)).agg(\n+          *args, **dict(kwargs, axis=0))\n     return frame_base.DeferredFrame.wrap(\n         expressions.ComputedExpression(\n             'aggregate',\n-            lambda df: df.agg(func, axis, *args, **kwargs),\n+            lambda df: df.agg(*args, **kwargs),\n             [self._expr],\n             # TODO(robertwb): Sub-aggregate when possible.\n             requires_partition_by=partitionings.Singleton()))\n \n   agg = aggregate\n \n+  applymap = frame_base._elementwise_method('applymap')\n+\n+  def memory_usage(self):\n+    raise frame_base.WontImplementError()\n+\n+  all = frame_base._associative_agg_method('all')\n+  any = frame_base._associative_agg_method('any')\n+\n+  cummax = cummin = cumsum = cumprod = frame_base.wont_implement_method(\n+      'order-sensitive')\n+  diff = frame_base.wont_implement_method('order-sensitive')\n+\n+  max = frame_base._associative_agg_method('max')\n+  min = frame_base._associative_agg_method('min')\n+  mode = frame_base._agg_method('mode')\n+\n+  def dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False, *args, **kwargs):\n+    # TODO(robertwb): This is a common pattern. Generalize?\n+    if axis == 1:\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'dropna',\n+            lambda df: df.dropna(axis, how, thresh, subset, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  items = itertuples = iterrows = iteritems = frame_base.wont_implement_method(\n+      'non-lazy')\n+\n+  isna = frame_base._elementwise_method('isna')\n+  notnull = notna = frame_base._elementwise_method('notna')\n+\n+  prod = product = frame_base._associative_agg_method('prod')\n+\n+  def quantile(self, q=0.5, axis=0, *args, **kwargs):\n+    if axis != 0:\n+      raise frame_base.WontImplementError('non-deferred column values')\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'quantile',\n+            lambda df: df.quantile(q, axis, *args, **kwargs),\n+            [self._expr],\n+            #TODO(robertwb): Approximate quantiles?\n+            requires_partition_by=partitionings.Singleton(),\n+            preserves_partition_by=partitionings.Singleton()))\n+\n+  query = frame_base._elementwise_method('query')\n+\n+  def replace(self, to_replace=None,\n+      value=None,\n+      inplace=False,\n+      limit=None, *args, **kwargs):\n+    if limit is None:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'replace',\n+            lambda df: df.replace(to_replace, value, False, limit, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  def reset_index(self, level=None, drop=False, inplace=False, *args, **kwargs):\n+    if level is not None and not isinstance(level, (tuple, list)):\n+      level = [level]\n+    if level is None or len(level) == len(self._expr.proxy().index.levels):\n+      # TODO: Could do distributed re-index with offsets.\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'reset_index',\n+            lambda df: df.reset_index(level, drop, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  round = frame_base._elementwise_method('round')\n+  select_dtypes = frame_base._elementwise_method('select_dtypes')\n+\n+  def shift(self, periods=1, freq=None, axis=0, *args, **kwargs):\n+    if axis == 1:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'shift',\n+            lambda df: df.shift(periods, freq, axis, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+\n+  @property\n+  def shape(self):\n+    raise frame_base.WontImplementError('scalar value')\n+\n+  def sort_values(self, by, axis=0, ascending=True, inplace=False, *args, **kwargs):\n+    if axis == 1:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()", "originalCommit": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ0Nzg3Mg==", "url": "https://github.com/apache/beam/pull/11974#discussion_r462447872", "bodyText": "Yes, I was thinking of using context managers to allow/disallow this. (Future PR.)", "author": "robertwb", "createdAt": "2020-07-29T16:58:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk2MDczMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk2MjYwOA==", "url": "https://github.com/apache/beam/pull/11974#discussion_r461962608", "bodyText": "This should accept *args, **kwargs:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              def memory_usage(self):\n          \n          \n            \n                raise frame_base.WontImplementError()\n          \n          \n            \n              memory_usage = frame_base.wont_implement_method('scalar value')\n          \n      \n    \n    \n  \n\nIt looks like this still can't be un-skipped after that change though because the test uses df.head()", "author": "TheNeuralBit", "createdAt": "2020-07-29T00:06:32Z", "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -111,19 +164,181 @@ def at(self, *args, **kwargs):\n   def loc(self):\n     return _DeferredLoc(self)\n \n-  def aggregate(self, func, axis=0, *args, **kwargs):\n-    if axis != 0:\n-      raise NotImplementedError()\n+  def aggregate(self, *args, **kwargs):\n+    if 'axis' in kwargs and kwargs['axis'] is None:\n+      return self.agg(*args, **dict(kwargs, axis=1)).agg(\n+          *args, **dict(kwargs, axis=0))\n     return frame_base.DeferredFrame.wrap(\n         expressions.ComputedExpression(\n             'aggregate',\n-            lambda df: df.agg(func, axis, *args, **kwargs),\n+            lambda df: df.agg(*args, **kwargs),\n             [self._expr],\n             # TODO(robertwb): Sub-aggregate when possible.\n             requires_partition_by=partitionings.Singleton()))\n \n   agg = aggregate\n \n+  applymap = frame_base._elementwise_method('applymap')\n+\n+  def memory_usage(self):\n+    raise frame_base.WontImplementError()", "originalCommit": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ0NjYyMA==", "url": "https://github.com/apache/beam/pull/11974#discussion_r462446620", "bodyText": "Yeah. Done.", "author": "robertwb", "createdAt": "2020-07-29T16:56:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk2MjYwOA=="}], "type": "inlineReview"}, {"oid": "b365608fe67d757f283dd59ca2b98c0e0642dc14", "url": "https://github.com/apache/beam/commit/b365608fe67d757f283dd59ca2b98c0e0642dc14", "message": "Reviewer comments.", "committedDate": "2020-07-29T17:16:56Z", "type": "commit"}, {"oid": "de7fa96d05d9c570c36ba94f7122ac3a9a307fe4", "url": "https://github.com/apache/beam/commit/de7fa96d05d9c570c36ba94f7122ac3a9a307fe4", "message": "Skip dict-order-sensitive tests on 3.5.", "committedDate": "2020-07-29T19:10:05Z", "type": "commit"}, {"oid": "de7fa96d05d9c570c36ba94f7122ac3a9a307fe4", "url": "https://github.com/apache/beam/commit/de7fa96d05d9c570c36ba94f7122ac3a9a307fe4", "message": "Skip dict-order-sensitive tests on 3.5.", "committedDate": "2020-07-29T19:10:05Z", "type": "forcePushed"}]}