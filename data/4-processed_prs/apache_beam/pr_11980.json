{"pr_number": 11980, "pr_title": "[BEAM-9546] DataframeTransform can now consume a schema-aware PCollection", "pr_createdAt": "2020-06-10T23:35:24Z", "pr_url": "https://github.com/apache/beam/pull/11980", "timeline": [{"oid": "55c492088bcd5b7b2b8bd8fbeb46fbf68b167a30", "url": "https://github.com/apache/beam/commit/55c492088bcd5b7b2b8bd8fbeb46fbf68b167a30", "message": "Add BatchRowsAsDataframe and generate_proxy, integrated into DataFrameTransform", "committedDate": "2020-08-07T00:47:24Z", "type": "forcePushed"}, {"oid": "f658cb2c6e7a02985efc6cb3e17b268a0018bb08", "url": "https://github.com/apache/beam/commit/f658cb2c6e7a02985efc6cb3e17b268a0018bb08", "message": "Add BatchRowsAsDataframe and generate_proxy, integrated into DataFrameTransform", "committedDate": "2020-08-07T20:32:59Z", "type": "commit"}, {"oid": "f658cb2c6e7a02985efc6cb3e17b268a0018bb08", "url": "https://github.com/apache/beam/commit/f658cb2c6e7a02985efc6cb3e17b268a0018bb08", "message": "Add BatchRowsAsDataframe and generate_proxy, integrated into DataFrameTransform", "committedDate": "2020-08-07T20:32:59Z", "type": "forcePushed"}, {"oid": "e8ab82a3e73e553deb3fecf0e21cefe7f85a9a42", "url": "https://github.com/apache/beam/commit/e8ab82a3e73e553deb3fecf0e21cefe7f85a9a42", "message": "lint", "committedDate": "2020-08-07T21:16:19Z", "type": "commit"}, {"oid": "424b4939b6e19abf9beefc787c046b34a513c47e", "url": "https://github.com/apache/beam/commit/424b4939b6e19abf9beefc787c046b34a513c47e", "message": "fix ci failures", "committedDate": "2020-08-07T22:29:40Z", "type": "commit"}, {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539", "url": "https://github.com/apache/beam/commit/a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539", "message": "yapf?", "committedDate": "2020-08-07T23:51:28Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MDAyMQ==", "url": "https://github.com/apache/beam/pull/11980#discussion_r470850021", "bodyText": "Woo hoo!", "author": "robertwb", "createdAt": "2020-08-14T20:26:51Z", "path": "sdks/python/apache_beam/dataframe/convert.py", "diffHunk": "@@ -36,7 +37,7 @@\n # TODO: Or should this be called as_dataframe?\n def to_dataframe(\n     pcoll,  # type: pvalue.PCollection\n-    proxy,  # type: pandas.core.generic.NDFrame\n+    proxy=None,  # type: pandas.core.generic.NDFrame", "originalCommit": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjAxNw==", "url": "https://github.com/apache/beam/pull/11980#discussion_r470852017", "bodyText": "Rather than subclassing, it would probably be cleaner to make this just a PTransform whose expand method returns\n`pcoll | BatchElements(...) | Pardo(...)`.\n\nIf you want to accept all the parameter from BatchElements, you could construct the BatchElements instance in your constructor.", "author": "robertwb", "createdAt": "2020-08-14T20:31:58Z", "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn\n+from apache_beam.transforms.core import ParDo\n+from apache_beam.transforms.util import BatchElements\n+from apache_beam.typehints.schemas import named_fields_from_element_type\n+\n+__all__ = ('BatchRowsAsDataFrame', 'generate_proxy')\n+\n+T = TypeVar('T', bound=NamedTuple)\n+\n+\n+@typehints.with_input_types(T)\n+@typehints.with_output_types(pd.DataFrame)\n+class BatchRowsAsDataFrame(BatchElements):\n+  \"\"\"A transform that batches schema-aware PCollection elements into DataFrames\n+\n+  Batching parameters are inherited from\n+  :class:`~apache_beam.transforms.util.BatchElements`.\n+  \"\"\"\n+  def __init__(self, *args, **kwargs):\n+    super(BatchRowsAsDataFrame, self).__init__(*args, **kwargs)\n+    self._batch_elements_transform = BatchElements(*args, **kwargs)\n+\n+  def expand(self, pcoll):\n+    return super(BatchRowsAsDataFrame, self).expand(pcoll) | ParDo(", "originalCommit": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMwODM0Ng==", "url": "https://github.com/apache/beam/pull/11980#discussion_r472308346", "bodyText": "Done! Looks like I actually started to do it that way with the unused self._batch_elements_transform but then changed my mind", "author": "TheNeuralBit", "createdAt": "2020-08-18T16:01:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjAxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjcwOA==", "url": "https://github.com/apache/beam/pull/11980#discussion_r470852708", "bodyText": "Rather than letting this be a full DoFn, you could just let columns be a local variable in the map above, and then write\n... | Map(lambda batch: pd.DataFrame.from_records(batch, columns))", "author": "robertwb", "createdAt": "2020-08-14T20:33:49Z", "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn\n+from apache_beam.transforms.core import ParDo\n+from apache_beam.transforms.util import BatchElements\n+from apache_beam.typehints.schemas import named_fields_from_element_type\n+\n+__all__ = ('BatchRowsAsDataFrame', 'generate_proxy')\n+\n+T = TypeVar('T', bound=NamedTuple)\n+\n+\n+@typehints.with_input_types(T)\n+@typehints.with_output_types(pd.DataFrame)\n+class BatchRowsAsDataFrame(BatchElements):\n+  \"\"\"A transform that batches schema-aware PCollection elements into DataFrames\n+\n+  Batching parameters are inherited from\n+  :class:`~apache_beam.transforms.util.BatchElements`.\n+  \"\"\"\n+  def __init__(self, *args, **kwargs):\n+    super(BatchRowsAsDataFrame, self).__init__(*args, **kwargs)\n+    self._batch_elements_transform = BatchElements(*args, **kwargs)\n+\n+  def expand(self, pcoll):\n+    return super(BatchRowsAsDataFrame, self).expand(pcoll) | ParDo(\n+        _RowBatchToDataFrameDoFn(pcoll.element_type))\n+\n+\n+class _RowBatchToDataFrameDoFn(DoFn):", "originalCommit": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMwNzYyMQ==", "url": "https://github.com/apache/beam/pull/11980#discussion_r472307621", "bodyText": "Done", "author": "TheNeuralBit", "createdAt": "2020-08-18T16:00:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjcwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MzU2Nw==", "url": "https://github.com/apache/beam/pull/11980#discussion_r470853567", "bodyText": "Nit. We typically have the style of importing modules, and then using qualified names (which results in less churn and makes it a bit easier to figure out where things come from). Instead of core, it's typical to do import apache_beam as beam and use beam.DoFn, etc.", "author": "robertwb", "createdAt": "2020-08-14T20:36:05Z", "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn", "originalCommit": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMwODQxMg==", "url": "https://github.com/apache/beam/pull/11980#discussion_r472308412", "bodyText": "Done", "author": "TheNeuralBit", "createdAt": "2020-08-18T16:02:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MzU2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NDE5Mw==", "url": "https://github.com/apache/beam/pull/11980#discussion_r470854193", "bodyText": "Can we get rid of this one too? (Or at least drop a TODO to do it in a subsequent PR?)", "author": "robertwb", "createdAt": "2020-08-14T20:37:53Z", "path": "sdks/python/apache_beam/dataframe/schemas_test.py", "diffHunk": "@@ -0,0 +1,110 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Tests for schemas.\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import unittest\n+from typing import NamedTuple\n+\n+import future.tests.base  # pylint: disable=unused-import\n+# patches unittest.testcase to be python3 compatible\n+import pandas as pd\n+from past.builtins import unicode\n+\n+import apache_beam as beam\n+from apache_beam.coders import RowCoder\n+from apache_beam.coders.typecoders import registry as coders_registry\n+from apache_beam.dataframe import schemas\n+from apache_beam.dataframe import transforms\n+from apache_beam.testing.test_pipeline import TestPipeline\n+from apache_beam.testing.util import assert_that\n+\n+Simple = NamedTuple(\n+    'Simple', [('name', unicode), ('id', int), ('height', float)])\n+coders_registry.register_coder(Simple, RowCoder)\n+Animal = NamedTuple('Animal', [('animal', unicode), ('max_speed', float)])\n+coders_registry.register_coder(Animal, RowCoder)\n+\n+\n+def matches_df(expected):\n+  def check_df_pcoll_equal(actual):\n+    actual = pd.concat(actual)\n+    sorted_actual = actual.sort_values(by=list(actual.columns)).reset_index(\n+        drop=True)\n+    sorted_expected = expected.sort_values(\n+        by=list(expected.columns)).reset_index(drop=True)\n+    if not sorted_actual.equals(sorted_expected):\n+      raise AssertionError(\n+          'Dataframes not equal: \\n\\nActual:\\n%s\\n\\nExpected:\\n%s' %\n+          (sorted_actual, sorted_expected))\n+\n+  return check_df_pcoll_equal\n+\n+\n+class SchemasTest(unittest.TestCase):\n+  def test_simple_df(self):\n+    expected = pd.DataFrame({\n+        'name': list(unicode(i) for i in range(5)),\n+        'id': list(range(5)),\n+        'height': list(float(i) for i in range(5))\n+    },\n+                            columns=['name', 'id', 'height'])\n+\n+    with TestPipeline() as p:\n+      res = (\n+          p\n+          | beam.Create([\n+              Simple(name=unicode(i), id=i, height=float(i)) for i in range(5)\n+          ])\n+          | schemas.BatchRowsAsDataFrame(min_batch_size=10, max_batch_size=10))\n+      assert_that(res, matches_df(expected))\n+\n+  def test_generate_proxy(self):\n+    expected = pd.DataFrame({\n+        'animal': pd.Series(dtype=unicode), 'max_speed': pd.Series(dtype=float)\n+    })\n+\n+    self.assertTrue(schemas.generate_proxy(Animal).equals(expected))\n+\n+  def test_batch_with_df_transform(self):\n+    with TestPipeline() as p:\n+      res = (\n+          p\n+          | beam.Create([\n+              Animal('Falcon', 380.0),\n+              Animal('Falcon', 370.0),\n+              Animal('Parrot', 24.0),\n+              Animal('Parrot', 26.0)\n+          ])\n+          | schemas.BatchRowsAsDataFrame()\n+          | transforms.DataframeTransform(\n+              lambda df: df.groupby('animal').mean(),\n+              proxy=schemas.generate_proxy(Animal)))", "originalCommit": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTgyNzg5MQ==", "url": "https://github.com/apache/beam/pull/11980#discussion_r471827891", "bodyText": "Added a TODO for now. I guess we'd need to store some type information on a PCollection[DataFrame], should we just store a proxy object when we know it?", "author": "TheNeuralBit", "createdAt": "2020-08-17T23:25:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NDE5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NDQzMw==", "url": "https://github.com/apache/beam/pull/11980#discussion_r470854433", "bodyText": "Maybe do a test using to_dataframe?", "author": "robertwb", "createdAt": "2020-08-14T20:38:30Z", "path": "sdks/python/apache_beam/dataframe/schemas_test.py", "diffHunk": "@@ -0,0 +1,110 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Tests for schemas.\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import unittest\n+from typing import NamedTuple\n+\n+import future.tests.base  # pylint: disable=unused-import\n+# patches unittest.testcase to be python3 compatible\n+import pandas as pd\n+from past.builtins import unicode\n+\n+import apache_beam as beam\n+from apache_beam.coders import RowCoder\n+from apache_beam.coders.typecoders import registry as coders_registry\n+from apache_beam.dataframe import schemas\n+from apache_beam.dataframe import transforms\n+from apache_beam.testing.test_pipeline import TestPipeline\n+from apache_beam.testing.util import assert_that\n+\n+Simple = NamedTuple(\n+    'Simple', [('name', unicode), ('id', int), ('height', float)])\n+coders_registry.register_coder(Simple, RowCoder)\n+Animal = NamedTuple('Animal', [('animal', unicode), ('max_speed', float)])\n+coders_registry.register_coder(Animal, RowCoder)\n+\n+\n+def matches_df(expected):\n+  def check_df_pcoll_equal(actual):\n+    actual = pd.concat(actual)\n+    sorted_actual = actual.sort_values(by=list(actual.columns)).reset_index(\n+        drop=True)\n+    sorted_expected = expected.sort_values(\n+        by=list(expected.columns)).reset_index(drop=True)\n+    if not sorted_actual.equals(sorted_expected):\n+      raise AssertionError(\n+          'Dataframes not equal: \\n\\nActual:\\n%s\\n\\nExpected:\\n%s' %\n+          (sorted_actual, sorted_expected))\n+\n+  return check_df_pcoll_equal\n+\n+\n+class SchemasTest(unittest.TestCase):\n+  def test_simple_df(self):\n+    expected = pd.DataFrame({\n+        'name': list(unicode(i) for i in range(5)),\n+        'id': list(range(5)),\n+        'height': list(float(i) for i in range(5))\n+    },\n+                            columns=['name', 'id', 'height'])\n+\n+    with TestPipeline() as p:\n+      res = (\n+          p\n+          | beam.Create([\n+              Simple(name=unicode(i), id=i, height=float(i)) for i in range(5)\n+          ])\n+          | schemas.BatchRowsAsDataFrame(min_batch_size=10, max_batch_size=10))\n+      assert_that(res, matches_df(expected))\n+\n+  def test_generate_proxy(self):\n+    expected = pd.DataFrame({\n+        'animal': pd.Series(dtype=unicode), 'max_speed': pd.Series(dtype=float)\n+    })\n+\n+    self.assertTrue(schemas.generate_proxy(Animal).equals(expected))\n+\n+  def test_batch_with_df_transform(self):", "originalCommit": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMwODUzNQ==", "url": "https://github.com/apache/beam/pull/11980#discussion_r472308535", "bodyText": "I added a test using to_dataframe in transforms_test: test_batching_beam_row_to_dataframe.\nI intended for these tests to just test schemas.py, while transforms_test verifies the integration with DataframeTransform. The one below was a stepping stone to integrating, we could even remove it now.", "author": "TheNeuralBit", "createdAt": "2020-08-18T16:02:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NDQzMw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1Nzk3NA==", "url": "https://github.com/apache/beam/pull/11980#discussion_r470857974", "bodyText": "This threw me because I was expecting the result to be ['Aardvark', 'Ant']. I see now that it's filtering down to the column names that start with A, but perhaps the filter could be written a bit differently to make it more obvious (e.g. filter on the values, let the regex be 'Anim*', or use another operation).", "author": "robertwb", "createdAt": "2020-08-14T20:48:12Z", "path": "sdks/python/apache_beam/dataframe/transforms_test.py", "diffHunk": "@@ -112,6 +133,64 @@ def test_scalar(self):\n       self.run_scenario(\n           df, lambda df: df.groupby('key').sum().val / df.val.agg(sum))\n \n+  def test_batching_named_tuple_input(self):\n+    with beam.Pipeline() as p:\n+      result = (\n+          p | beam.Create([\n+              AnimalSpeed('Aardvark', 5),\n+              AnimalSpeed('Ant', 2),\n+              AnimalSpeed('Elephant', 35),\n+              AnimalSpeed('Zebra', 40)\n+          ]).with_output_types(AnimalSpeed)\n+          | transforms.DataframeTransform(lambda df: df.filter(regex='A.*')))", "originalCommit": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMxMTgwNg==", "url": "https://github.com/apache/beam/pull/11980#discussion_r472311806", "bodyText": "You and me both :) I just reused the operation from test_filter above. Changed it to Anim.* in both places", "author": "TheNeuralBit", "createdAt": "2020-08-18T16:07:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1Nzk3NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1ODgwMQ==", "url": "https://github.com/apache/beam/pull/11980#discussion_r470858801", "bodyText": "Or a type constraint. (Not all our type hints are types.)", "author": "robertwb", "createdAt": "2020-08-14T20:50:22Z", "path": "sdks/python/apache_beam/pvalue.py", "diffHunk": "@@ -88,7 +88,7 @@ class PValue(object):\n   def __init__(self,\n                pipeline,  # type: Pipeline\n                tag=None,  # type: Optional[str]\n-               element_type=None,  # type: Optional[object]\n+               element_type=None,  # type: Optional[type]", "originalCommit": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMxNTA1Mw==", "url": "https://github.com/apache/beam/pull/11980#discussion_r472315053", "bodyText": "Done", "author": "TheNeuralBit", "createdAt": "2020-08-18T16:12:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1ODgwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1OTA1Nw==", "url": "https://github.com/apache/beam/pull/11980#discussion_r470859057", "bodyText": "Is this worth a JIRA?", "author": "robertwb", "createdAt": "2020-08-14T20:50:58Z", "path": "sdks/python/apache_beam/typehints/schemas.py", "diffHunk": "@@ -251,3 +258,23 @@ def named_tuple_from_schema(schema):\n \n def named_tuple_to_schema(named_tuple):\n   return typing_to_runner_api(named_tuple).row_type.schema\n+\n+\n+def schema_from_element_type(element_type):  # (type) -> schema_pb2.Schema\n+  \"\"\"Get a schema for the given PCollection element_type.\n+\n+  Returns schema as a list of (name, python_type) tuples\"\"\"\n+  if isinstance(element_type, row_type.RowTypeConstraint):\n+    # TODO: Make sure beam.Row generated schemas are registered and de-duped", "originalCommit": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MDI1MA==", "url": "https://github.com/apache/beam/pull/11980#discussion_r471850250", "bodyText": "Filed BEAM-10722 for this", "author": "TheNeuralBit", "createdAt": "2020-08-18T00:45:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1OTA1Nw=="}], "type": "inlineReview"}, {"oid": "c0c552c841600ecf951d5174790f6fdfec510c33", "url": "https://github.com/apache/beam/commit/c0c552c841600ecf951d5174790f6fdfec510c33", "message": "Address PR comments", "committedDate": "2020-08-18T16:51:59Z", "type": "commit"}, {"oid": "66d258d22ee7f21b96c7bdcd77f523281773135d", "url": "https://github.com/apache/beam/commit/66d258d22ee7f21b96c7bdcd77f523281773135d", "message": "Update DataframeTransform docstring", "committedDate": "2020-08-18T16:52:26Z", "type": "commit"}, {"oid": "00c5b16afe00cb1a982bd4c90d46b36d465b82a0", "url": "https://github.com/apache/beam/commit/00c5b16afe00cb1a982bd4c90d46b36d465b82a0", "message": "lint", "committedDate": "2020-08-18T16:55:28Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMxMTAyMw==", "url": "https://github.com/apache/beam/pull/11980#discussion_r472311023", "bodyText": "Note there's actually a diff here from the original check_correct. It sorts by value and resets the index rather than sorting by index.  I had to do this because the concatenated indices of the batches (e.g. [0,1,2,0,1,0,]) wouldn't match the index in my expected df (e.g. [0,1,2,3,4,5]).", "author": "TheNeuralBit", "createdAt": "2020-08-18T16:06:07Z", "path": "sdks/python/apache_beam/dataframe/transforms_test.py", "diffHunk": "@@ -17,17 +17,61 @@\n from __future__ import absolute_import\n from __future__ import division\n \n+import typing\n import unittest\n \n import pandas as pd\n+from past.builtins import unicode\n \n import apache_beam as beam\n+from apache_beam import coders\n from apache_beam.dataframe import expressions\n from apache_beam.dataframe import frame_base\n from apache_beam.dataframe import transforms\n from apache_beam.testing.util import assert_that\n \n \n+def sort_by_value_and_drop_index(df):\n+  if isinstance(df, pd.DataFrame):\n+    sorted_df = df.sort_values(by=list(df.columns))\n+  else:\n+    sorted_df = df.sort_values()\n+  return sorted_df.reset_index(drop=True)", "originalCommit": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}