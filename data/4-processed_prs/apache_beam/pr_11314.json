{"pr_number": 11314, "pr_title": "[BEAM-9562] Send Timers over Data Channel as Elements", "pr_createdAt": "2020-04-04T06:02:23Z", "pr_url": "https://github.com/apache/beam/pull/11314", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEwMjQyMQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405102421", "bodyText": "Generic transforms don't have the notion of main inputs, let's filter things out in the implementation in ParDo.", "author": "robertwb", "createdAt": "2020-04-07T20:47:21Z", "path": "sdks/python/apache_beam/pipeline.py", "diffHunk": "@@ -1071,6 +1071,14 @@ def named_inputs(self):\n     }\n     return dict(main_inputs, **side_inputs)\n \n+  def main_inputs(self):", "originalCommit": "a08d427e27715890ff619d2cea8b724275140667", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEwMjk1NA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405102954", "bodyText": "This is starting to look like a lot of code duplication. How about we pass (all) inputs as a keyword argument, and let PTransform.to_runner_api take an **extra_kwargs that it passes on to to_runner_api_parameter.", "author": "robertwb", "createdAt": "2020-04-07T20:48:15Z", "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -1294,16 +1295,43 @@ def _pardo_fn_data(self):\n     windowing = None\n     return self.fn, self.args, self.kwargs, si_tags_and_types, windowing\n \n-  def to_runner_api_parameter(self, context):\n+  def to_runner_api(self, context, main_inputs, has_parts=False):", "originalCommit": "a08d427e27715890ff619d2cea8b724275140667", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "5c1db9bf0737d3d6b528ca7f69d738b32dd6b3d3", "url": "https://github.com/apache/beam/commit/5c1db9bf0737d3d6b528ca7f69d738b32dd6b3d3", "message": "Python sdk/runner harness processes timer over data_channel", "committedDate": "2020-04-08T19:37:14Z", "type": "forcePushed"}, {"oid": "e046783b3c0f91ff7295f5fac7098d87404fc9e2", "url": "https://github.com/apache/beam/commit/e046783b3c0f91ff7295f5fac7098d87404fc9e2", "message": "Python sdk/runner harness processes timer over data_channel", "committedDate": "2020-04-08T20:13:04Z", "type": "forcePushed"}, {"oid": "3ff8c3eb28944cbe7c757fdbae49947b57c3774f", "url": "https://github.com/apache/beam/commit/3ff8c3eb28944cbe7c757fdbae49947b57c3774f", "message": "Python sdk/runner harness processes timer over data_channel", "committedDate": "2020-04-08T20:18:30Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgxNTE2MA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405815160", "bodyText": "A type on this parameter would be useful.", "author": "robertwb", "createdAt": "2020-04-08T21:06:52Z", "path": "sdks/python/apache_beam/runners/worker/bundle_processor.py", "diffHunk": "@@ -562,45 +562,45 @@ class OutputTimer(object):\n   def __init__(self,\n                key,\n                window,  # type: windowed_value.BoundedWindow\n-               receiver  # type: operations.ConsumerSet\n+               paneinfo,\n+               timer_family_id,\n+               timer_coder_impl,\n+               output_stream", "originalCommit": "a2a716455edb8d1a80ae4d302a79b19ef6053484", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgxNjQ2MA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405816460", "bodyText": "Don't bother setting these timestamps, or paneinfo.", "author": "robertwb", "createdAt": "2020-04-08T21:09:21Z", "path": "sdks/python/apache_beam/runners/worker/bundle_processor.py", "diffHunk": "@@ -562,45 +562,45 @@ class OutputTimer(object):\n   def __init__(self,\n                key,\n                window,  # type: windowed_value.BoundedWindow\n-               receiver  # type: operations.ConsumerSet\n+               paneinfo,\n+               timer_family_id,\n+               timer_coder_impl,\n+               output_stream\n               ):\n     self._key = key\n     self._window = window\n-    self._receiver = receiver\n+    self._paneinfo = paneinfo\n+    self._timer_family_id = timer_family_id\n+    self._output_stream = output_stream\n+    self._timer_coder_impl = timer_coder_impl\n \n   def set(self, ts):\n     ts = timestamp.Timestamp.of(ts)\n-    # TODO(BEAM-9562): Plumb through actual timer fields.\n-    self._receiver.receive(\n-        windowed_value.WindowedValue((\n-            self._key,\n-            userstate.Timer(\n-                user_key='',\n-                dynamic_timer_tag='',\n-                windows=(self._window, ),\n-                clear_bit=False,\n-                fire_timestamp=ts,\n-                hold_timestamp=ts,\n-                paneinfo=windowed_value.PANE_INFO_UNKNOWN)),\n-                                     ts, (self._window, )))\n+    timer = userstate.Timer(\n+        user_key=self._key,\n+        dynamic_timer_tag='',\n+        windows=(self._window, ),\n+        clear_bit=False,\n+        fire_timestamp=ts,\n+        hold_timestamp=ts,\n+        paneinfo=self._paneinfo)\n+    self._timer_coder_impl.encode_to_stream(timer, self._output_stream, True)\n+    self._output_stream.maybe_flush()\n \n   def clear(self):\n     # type: () -> None\n     dummy_millis = int(common_urns.constants.MAX_TIMESTAMP_MILLIS.constant) + 1\n     clear_ts = timestamp.Timestamp(micros=dummy_millis * 1000)\n-    # TODO(BEAM-9562): Plumb through actual paneinfo.\n-    self._receiver.receive(\n-        windowed_value.WindowedValue((\n-            self._key,\n-            userstate.Timer(\n-                user_key='',\n-                dynamic_timer_tag='',\n-                windows=(self._window, ),\n-                clear_bit=False,\n-                fire_timestamp=timestamp.Timestamp.of(clear_ts),\n-                hold_timestamp=timestamp.Timestamp.of(0),\n-                paneinfo=windowed_value.PANE_INFO_UNKNOWN)),\n-                                     0, (self._window, )))\n+    timer = userstate.Timer(\n+        user_key=self._key,\n+        dynamic_timer_tag='',\n+        windows=(self._window, ),\n+        clear_bit=False,\n+        fire_timestamp=clear_ts,", "originalCommit": "a2a716455edb8d1a80ae4d302a79b19ef6053484", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgxNzMxNw==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405817317", "bodyText": "(Should the coder be ignoring them as well?)", "author": "robertwb", "createdAt": "2020-04-08T21:11:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgxNjQ2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg5Mjk3OA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405892978", "bodyText": "(Should the coder be ignoring them as well?)\n\nNo, the timer coder is encoding all of these info now.\n\nDon't bother setting these timestamps, or paneinfo.\n\nCould you please explain more about this?", "author": "boyuanzz", "createdAt": "2020-04-09T00:39:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgxNjQ2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk4OTMwNw==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405989307", "bodyText": "They're meaningless when we're clearing a timer (e.g. it won't fire, hold back the watermark, or have a pane info).", "author": "robertwb", "createdAt": "2020-04-09T06:46:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgxNjQ2MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjM0NDg5MQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406344891", "bodyText": "Correct, when clear_bit is True, the coder ignores these fields. I think we should have a better Timer with API of and clear like in Java as a follow up.", "author": "boyuanzz", "createdAt": "2020-04-09T16:58:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgxNjQ2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgxNzg5OQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405817899", "bodyText": "type?", "author": "robertwb", "createdAt": "2020-04-08T21:12:19Z", "path": "sdks/python/apache_beam/runners/worker/bundle_processor.py", "diffHunk": "@@ -611,7 +611,7 @@ def __init__(self,\n                transform_id,  # type: str\n                key_coder,  # type: coders.Coder\n                window_coder,  # type: coders.Coder\n-               timer_family_specs  # type: Mapping[str, beam_runner_api_pb2.TimerFamilySpec]\n+               timer_coders", "originalCommit": "a2a716455edb8d1a80ae4d302a79b19ef6053484", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgyNDI5MA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405824290", "bodyText": "I see us doing this loop three times now. Perhaps it would be more useful to do the loop once to set everything up, creating a single dictionary (transform_id, timer_family_id) -> (all info about that timer we need to dispatch them).", "author": "robertwb", "createdAt": "2020-04-08T21:25:04Z", "path": "sdks/python/apache_beam/runners/worker/bundle_processor.py", "diffHunk": "@@ -1088,6 +1142,30 @@ def create_operation(self,\n         transform_proto.spec.payload, parameter_type)\n     return creator(self, transform_id, transform_proto, payload, consumers)\n \n+  def get_timer_coders(self):\n+    timer_coder = {}\n+    for transform_id, transform_proto in self.descriptor.transforms.items():", "originalCommit": "a2a716455edb8d1a80ae4d302a79b19ef6053484", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgyNTM5Mg==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405825392", "bodyText": "Nit: rather than this double nesting, it might simplify things to have an update_timer_output_streams(timer_id, output_stream) method that could be called repeatedly.", "author": "robertwb", "createdAt": "2020-04-08T21:27:28Z", "path": "sdks/python/apache_beam/runners/worker/bundle_processor.py", "diffHunk": "@@ -846,6 +870,30 @@ def process_bundle(self, instruction_id):\n         data_channels[input_op.data_channel].append(input_op.transform_id)\n         input_op_by_transform_id[input_op.transform_id] = input_op\n \n+        # Set up timer output stream\n+      timer_output_streams = {}\n+      for transform_id, timer_list in self.timer_ids.items():\n+        output_streams = {}\n+        for timer_id in timer_list:\n+          output_streams[\n+              timer_id] = self.timer_data_channel.output_timer_stream(\n+                  instruction_id, transform_id, timer_id)\n+          timer_output_streams[transform_id] = output_streams\n+        self.process_timer_ops[\n+            transform_id].user_state_context.update_timer_output_streams(", "originalCommit": "a2a716455edb8d1a80ae4d302a79b19ef6053484", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgyNjgzNw==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405826837", "bodyText": "We can't safely assume the runner will finish sending all timers before sending any of the data (and the buffer may get full, resulting in a deadlock). I think we need to have a data_channel.inputs() that returns both data and timers and then branch in the loop.", "author": "robertwb", "createdAt": "2020-04-08T21:30:19Z", "path": "sdks/python/apache_beam/runners/worker/bundle_processor.py", "diffHunk": "@@ -846,6 +870,30 @@ def process_bundle(self, instruction_id):\n         data_channels[input_op.data_channel].append(input_op.transform_id)\n         input_op_by_transform_id[input_op.transform_id] = input_op\n \n+        # Set up timer output stream\n+      timer_output_streams = {}\n+      for transform_id, timer_list in self.timer_ids.items():\n+        output_streams = {}\n+        for timer_id in timer_list:\n+          output_streams[\n+              timer_id] = self.timer_data_channel.output_timer_stream(\n+                  instruction_id, transform_id, timer_id)\n+          timer_output_streams[transform_id] = output_streams\n+        self.process_timer_ops[\n+            transform_id].user_state_context.update_timer_output_streams(\n+                output_streams)\n+\n+      # Process timers\n+      if self.timer_data_channel:", "originalCommit": "a2a716455edb8d1a80ae4d302a79b19ef6053484", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgyMzkxNg==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405823916", "bodyText": "This test is testStateCallsFailIfNoStateApiServiceDescriptorSpecified. Is there value in a testTimerCallsFailIfNoTimerApiServiceDescriptorSpecified to exercise the new \"Timers are unsupported because ...\" exception?", "author": "TheNeuralBit", "createdAt": "2020-04-08T21:24:14Z", "path": "sdks/java/harness/src/test/java/org/apache/beam/fn/harness/control/ProcessBundleHandlerTest.java", "diffHunk": "@@ -914,6 +923,7 @@ public Object createRunnerForPTransform(\n                       PipelineOptions pipelineOptions,\n                       BeamFnDataClient beamFnDataClient,\n                       BeamFnStateClient beamFnStateClient,\n+                      BeamFnTimerClient beamFnTimerClient,\n                       String pTransformId,\n                       PTransform pTransform,\n                       Supplier<String> processBundleInstructionId,", "originalCommit": "a2a716455edb8d1a80ae4d302a79b19ef6053484", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg3MzI2NA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405873264", "bodyText": "for completeness yes", "author": "lukecwik", "createdAt": "2020-04-08T23:32:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgyMzkxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgzMTkyMA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405831920", "bodyText": "Just curious: did we not have this check before, and just failed when attempting to cast to KVCoder  (in the removed block from translate above)?", "author": "TheNeuralBit", "createdAt": "2020-04-08T21:41:29Z", "path": "runners/core-construction-java/src/main/java/org/apache/beam/runners/core/construction/ParDoTranslation.java", "diffHunk": "@@ -257,6 +230,19 @@ public static ParDoPayload translateParDo(\n       restrictionCoderId = \"\";\n     }\n \n+    Coder<BoundedWindow> windowCoder =\n+        (Coder<BoundedWindow>) mainInput.getWindowingStrategy().getWindowFn().windowCoder();\n+    Coder<?> keyCoder;\n+    if (signature.usesState() || signature.usesTimers()) {\n+      checkArgument(\n+          mainInput.getCoder() instanceof KvCoder,\n+          \"DoFn's that use state or timers must have an input PCollection with a KvCoder but received %s\",\n+          mainInput.getCoder());", "originalCommit": "a2a716455edb8d1a80ae4d302a79b19ef6053484", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg3MDUzOQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405870539", "bodyText": "It was being covered by validation in DoFnSignatures but it is being repeated here for defense in depth reasons.", "author": "lukecwik", "createdAt": "2020-04-08T23:24:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTgzMTkyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg1NTY5Ng==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405855696", "bodyText": "Isn't the timer API service descriptor different from the data API service descriptor? Does that need to be plumbed through SdkHarnessRegistry and used here instead of the data API descriptor? (same question below and in streaming worker)", "author": "TheNeuralBit", "createdAt": "2020-04-08T22:40:57Z", "path": "runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/BatchDataflowWorker.java", "diffHunk": "@@ -238,9 +238,14 @@ protected BatchDataflowWorker(\n         sdkFusedStage =\n             pipeline == null\n                 ? RegisterNodeFunction.withoutPipeline(\n-                    idGenerator, sdkHarnessRegistry.beamFnStateApiServiceDescriptor())\n+                    idGenerator,\n+                    sdkHarnessRegistry.beamFnStateApiServiceDescriptor(),\n+                    sdkHarnessRegistry.beamFnDataApiServiceDescriptor())", "originalCommit": "9cae48c6c036f45274beb60b10a6a7850941dc6c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg3MDg4Mg==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405870882", "bodyText": "They both use the Data API so no. All were saying here is that we will re-use the same gRPC channel for both timers and data.", "author": "lukecwik", "createdAt": "2020-04-08T23:25:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg1NTY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg5MDIxNQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405890215", "bodyText": "I see. So we only have a separate timer_api_service_descriptor in the protos so that a runner has the option to make it separate, but it doesn't need to be separate?", "author": "TheNeuralBit", "createdAt": "2020-04-09T00:29:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg1NTY5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTkwNzUwNA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405907504", "bodyText": "That is correct.", "author": "lukecwik", "createdAt": "2020-04-09T01:35:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg1NTY5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTg5MjYzNQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405892635", "bodyText": "timerApiServiceDescriptor isn't used? Should it be stored and written to the ProcessBundleDescrioptor?", "author": "TheNeuralBit", "createdAt": "2020-04-09T00:38:41Z", "path": "runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/graph/RegisterNodeFunction.java", "diffHunk": "@@ -134,14 +136,18 @@ public static RegisterNodeFunction forPipeline(\n    * harnesses, then this method should be removed.\n    */\n   public static RegisterNodeFunction withoutPipeline(\n-      IdGenerator idGenerator, Endpoints.ApiServiceDescriptor stateApiServiceDescriptor) {\n-    return new RegisterNodeFunction(null, idGenerator, stateApiServiceDescriptor);\n+      IdGenerator idGenerator,\n+      Endpoints.ApiServiceDescriptor stateApiServiceDescriptor,\n+      Endpoints.ApiServiceDescriptor timerApiServiceDescriptor) {\n+    return new RegisterNodeFunction(\n+        null, idGenerator, stateApiServiceDescriptor, timerApiServiceDescriptor);\n   }\n \n   private RegisterNodeFunction(\n       @Nullable RunnerApi.Pipeline pipeline,\n       IdGenerator idGenerator,\n-      Endpoints.ApiServiceDescriptor stateApiServiceDescriptor) {\n+      Endpoints.ApiServiceDescriptor stateApiServiceDescriptor,\n+      Endpoints.ApiServiceDescriptor timerApiServiceDescriptor) {", "originalCommit": "9cae48c6c036f45274beb60b10a6a7850941dc6c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk4NTY5MQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405985691", "bodyText": "You can leave this in the parameter list.", "author": "robertwb", "createdAt": "2020-04-09T06:37:45Z", "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -1323,12 +1325,47 @@ def _pardo_fn_data(self):\n     windowing = None\n     return self.fn, self.args, self.kwargs, si_tags_and_types, windowing\n \n-  def to_runner_api_parameter(self, context):\n+  def _get_key_and_window_coder(self, named_inputs):\n+    if named_inputs is None or not self._signature.is_stateful_dofn():\n+      return None, None\n+    main_input = list(set(named_inputs.keys()) - set(self.side_inputs))[0]\n+    input_pcoll = named_inputs[main_input]\n+    kv_type_hint = input_pcoll.element_type\n+    if kv_type_hint and kv_type_hint != typehints.Any:\n+      coder = coders.registry.get_coder(kv_type_hint)\n+      if not coder.is_kv_coder():\n+        raise ValueError(\n+            'Input elements to the transform %s with stateful DoFn must be '\n+            'key-value pairs.' % self)\n+      key_coder = coder.key_coder()\n+    else:\n+      key_coder = coders.registry.get_coder(typehints.Any)\n+    window_coder = input_pcoll.windowing.windowfn.get_window_coder()\n+    return key_coder, window_coder\n+\n+  def to_runner_api(self, context, **extra_kwargs):\n+    # type: (PipelineContext, bool) -> beam_runner_api_pb2.FunctionSpec\n+    has_parts = extra_kwargs.get('has_part', False)", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk4NjUyOQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405986529", "bodyText": "Maybe put this in the if block below closer to where they're used?", "author": "robertwb", "createdAt": "2020-04-09T06:39:39Z", "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -1323,12 +1325,47 @@ def _pardo_fn_data(self):\n     windowing = None\n     return self.fn, self.args, self.kwargs, si_tags_and_types, windowing\n \n-  def to_runner_api_parameter(self, context):\n+  def _get_key_and_window_coder(self, named_inputs):\n+    if named_inputs is None or not self._signature.is_stateful_dofn():\n+      return None, None\n+    main_input = list(set(named_inputs.keys()) - set(self.side_inputs))[0]\n+    input_pcoll = named_inputs[main_input]\n+    kv_type_hint = input_pcoll.element_type\n+    if kv_type_hint and kv_type_hint != typehints.Any:\n+      coder = coders.registry.get_coder(kv_type_hint)\n+      if not coder.is_kv_coder():\n+        raise ValueError(\n+            'Input elements to the transform %s with stateful DoFn must be '\n+            'key-value pairs.' % self)\n+      key_coder = coder.key_coder()\n+    else:\n+      key_coder = coders.registry.get_coder(typehints.Any)\n+    window_coder = input_pcoll.windowing.windowfn.get_window_coder()\n+    return key_coder, window_coder\n+\n+  def to_runner_api(self, context, **extra_kwargs):\n+    # type: (PipelineContext, bool) -> beam_runner_api_pb2.FunctionSpec\n+    has_parts = extra_kwargs.get('has_part', False)\n+    urn, typed_param = self.to_runner_api_parameter(context, **extra_kwargs)\n+    if urn == python_urns.GENERIC_COMPOSITE_TRANSFORM and not has_parts:\n+      # TODO(BEAM-3812): Remove this fallback.\n+      urn, typed_param = self.to_runner_api_pickled(context)\n+    return beam_runner_api_pb2.FunctionSpec(\n+        urn=urn,\n+        payload=typed_param.SerializeToString() if isinstance(\n+            typed_param, message.Message) else typed_param.encode('utf-8')\n+        if isinstance(typed_param, str) else typed_param)\n+\n+  def to_runner_api_parameter(self, context, **extra_kwargs):\n     # type: (PipelineContext) -> typing.Tuple[str, message.Message]\n     assert isinstance(self, ParDo), \\\n         \"expected instance of ParDo, but got %s\" % self.__class__\n+    key_coder, window_coder = self._get_key_and_window_coder(", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk4NzkzMg==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405987932", "bodyText": "https://engdoc.corp.google.com/eng/doc/devguide/py/totw/026.md?cl=head", "author": "robertwb", "createdAt": "2020-04-09T06:43:08Z", "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -1323,12 +1325,47 @@ def _pardo_fn_data(self):\n     windowing = None\n     return self.fn, self.args, self.kwargs, si_tags_and_types, windowing\n \n-  def to_runner_api_parameter(self, context):\n+  def _get_key_and_window_coder(self, named_inputs):\n+    if named_inputs is None or not self._signature.is_stateful_dofn():\n+      return None, None\n+    main_input = list(set(named_inputs.keys()) - set(self.side_inputs))[0]\n+    input_pcoll = named_inputs[main_input]\n+    kv_type_hint = input_pcoll.element_type\n+    if kv_type_hint and kv_type_hint != typehints.Any:\n+      coder = coders.registry.get_coder(kv_type_hint)\n+      if not coder.is_kv_coder():\n+        raise ValueError(\n+            'Input elements to the transform %s with stateful DoFn must be '\n+            'key-value pairs.' % self)\n+      key_coder = coder.key_coder()\n+    else:\n+      key_coder = coders.registry.get_coder(typehints.Any)\n+    window_coder = input_pcoll.windowing.windowfn.get_window_coder()\n+    return key_coder, window_coder\n+\n+  def to_runner_api(self, context, **extra_kwargs):\n+    # type: (PipelineContext, bool) -> beam_runner_api_pb2.FunctionSpec\n+    has_parts = extra_kwargs.get('has_part', False)\n+    urn, typed_param = self.to_runner_api_parameter(context, **extra_kwargs)", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ0MjQ4Ng==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406442486", "bodyText": "Nevermind, I see what's going on here.", "author": "robertwb", "createdAt": "2020-04-09T19:56:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk4NzkzMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk5MDAyNg==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405990026", "bodyText": "If this were a single map rather that two parallel maps, you could write something like\noutput_tream, timer_coder_impl = self._timer_info(timer_spec.name]", "author": "robertwb", "createdAt": "2020-04-09T06:48:38Z", "path": "sdks/python/apache_beam/runners/worker/bundle_processor.py", "diffHunk": "@@ -629,28 +628,28 @@ def __init__(self,\n     self._transform_id = transform_id\n     self._key_coder = key_coder\n     self._window_coder = window_coder\n-    self._timer_family_specs = timer_family_specs\n-    self._timer_receivers = None  # type: Optional[Dict[str, operations.ConsumerSet]]\n+    # A mapping of {timer_family_id: OutputStream}\n+    self._timer_output_streams = {}\n+    self._timer_coders_impl = {}\n     self._all_states = {\n     }  # type: Dict[tuple, userstate.AccumulatingRuntimeState]\n \n-  def update_timer_receivers(self, receivers):\n-    # type: (operations._TaggedReceivers) -> None\n-\n-    \"\"\"TODO\"\"\"\n-    self._timer_receivers = {}\n-    for tag in self._timer_family_specs:\n-      self._timer_receivers[tag] = receivers.pop(tag)\n+  def add_timer_info(self, timer_family_id, output_stream, coder_impl):\n+    self._timer_output_streams[timer_family_id] = output_stream\n+    self._timer_coders_impl[timer_family_id] = coder_impl\n \n   def get_timer(\n       self,\n       timer_spec,\n       key,\n-      window  # type: windowed_value.BoundedWindow\n-  ):\n+      window,  # type: windowed_value.BoundedWindow\n+      pane):\n     # type: (...) -> OutputTimer\n-    assert self._timer_receivers is not None\n-    return OutputTimer(key, window, self._timer_receivers[timer_spec.name])\n+    output_stream = self._timer_output_streams[timer_spec.name]", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk5MDQxMg==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405990412", "bodyText": "Nit: The mapping stays (or is) empty...", "author": "robertwb", "createdAt": "2020-04-09T06:49:32Z", "path": "sdks/python/apache_beam/runners/worker/bundle_processor.py", "diffHunk": "@@ -745,6 +746,24 @@ def __init__(self,\n     self.process_bundle_descriptor = process_bundle_descriptor\n     self.state_handler = state_handler\n     self.data_channel_factory = data_channel_factory\n+\n+    # There is no guarantee that the runner only set\n+    # timer_api_service_descriptor when having timers. So this field cannot be\n+    # used as an indicator of timers.\n+    if self.process_bundle_descriptor.timer_api_service_descriptor:\n+      self.timer_data_channel = (\n+          data_channel_factory.create_data_channel_from_url(\n+              self.process_bundle_descriptor.timer_api_service_descriptor.url))\n+    else:\n+      self.timer_data_channel = None\n+\n+    # A mapping of\n+    # {(transform_id, timer_family_id):\n+    # {\"timer_coder_impl\": coder, \"output_stream\": stream}}\n+    # The mapping keeps empty when there is no timer_family_specs in the", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk5NDg4Ng==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405994886", "bodyText": "Optonal: [Named] tuples are usually easier to work with than dicts.", "author": "robertwb", "createdAt": "2020-04-09T06:59:54Z", "path": "sdks/python/apache_beam/runners/worker/bundle_processor.py", "diffHunk": "@@ -745,6 +746,24 @@ def __init__(self,\n     self.process_bundle_descriptor = process_bundle_descriptor\n     self.state_handler = state_handler\n     self.data_channel_factory = data_channel_factory\n+\n+    # There is no guarantee that the runner only set\n+    # timer_api_service_descriptor when having timers. So this field cannot be\n+    # used as an indicator of timers.\n+    if self.process_bundle_descriptor.timer_api_service_descriptor:\n+      self.timer_data_channel = (\n+          data_channel_factory.create_data_channel_from_url(\n+              self.process_bundle_descriptor.timer_api_service_descriptor.url))\n+    else:\n+      self.timer_data_channel = None\n+\n+    # A mapping of\n+    # {(transform_id, timer_family_id):\n+    # {\"timer_coder_impl\": coder, \"output_stream\": stream}}", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk5NTU1NA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405995554", "bodyText": "I would populate output_stream here as well rather than above.", "author": "robertwb", "createdAt": "2020-04-09T07:01:32Z", "path": "sdks/python/apache_beam/runners/worker/bundle_processor.py", "diffHunk": "@@ -1088,6 +1145,21 @@ def create_operation(self,\n         transform_proto.spec.payload, parameter_type)\n     return creator(self, transform_id, transform_proto, payload, consumers)\n \n+  def extract_timers_info(self):", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjM4Mjk1NA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406382954", "bodyText": "We can only populate output_stream when processing bundle since instruction_id is required.", "author": "boyuanzz", "createdAt": "2020-04-09T18:05:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk5NTU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjM4Nzg0Mg==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406387842", "bodyText": "Ack, expanding the whole diff I see that this is happening in different methods now (in which case here two separate maps, as you had originally, might be preferable). But not a big deal.", "author": "robertwb", "createdAt": "2020-04-09T18:14:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk5NTU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjM5NDg2MQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406394861", "bodyText": "The keys of maps should still be the same though(tuple of (transform_id, timer_family_id)). That's why I make the value as a map{coder_impl, output_stream}", "author": "boyuanzz", "createdAt": "2020-04-09T18:26:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk5NTU1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk5ODAwOQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405998009", "bodyText": "It'd be good to not lose the typing information. You can make an alias at the top of the file DataOrTimers = Union[beam_fn_api_pb2.Elements.Data, beam_fn_api_pb2.Elements.Timer] to cut down on verbosity, here and elsewhere.", "author": "robertwb", "createdAt": "2020-04-09T07:07:02Z", "path": "sdks/python/apache_beam/runners/worker/data_plane.py", "diffHunk": "@@ -274,20 +301,47 @@ def inverse(self):\n     return self._inverse\n \n   def input_elements(self,\n-                     instruction_id,  # type: str\n-                     unused_expected_transforms=None,  # type: Optional[Collection[str]]\n-                     abort_callback=None  # type: Optional[Callable[[], bool]]\n-                    ):\n-    # type: (...) -> Iterator[beam_fn_api_pb2.Elements.Data]", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk5ODIzNw==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405998237", "bodyText": "inputes -> inputs", "author": "robertwb", "createdAt": "2020-04-09T07:07:36Z", "path": "sdks/python/apache_beam/runners/worker/data_plane.py", "diffHunk": "@@ -274,20 +301,47 @@ def inverse(self):\n     return self._inverse\n \n   def input_elements(self,\n-                     instruction_id,  # type: str\n-                     unused_expected_transforms=None,  # type: Optional[Collection[str]]\n-                     abort_callback=None  # type: Optional[Callable[[], bool]]\n-                    ):\n-    # type: (...) -> Iterator[beam_fn_api_pb2.Elements.Data]\n+      instruction_id,  # type: str\n+      unused_expected_inputes=None,   # type: Collection[str]", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk5OTA4OQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405999089", "bodyText": "update type hint", "author": "robertwb", "createdAt": "2020-04-09T07:09:27Z", "path": "sdks/python/apache_beam/runners/worker/data_plane.py", "diffHunk": "@@ -354,15 +410,15 @@ def input_elements(self,\n \n     Args:\n       instruction_id(str): instruction_id for which data is read\n-      expected_transforms(collection): expected transforms\n+      expected_inputs(collection): expected inputs, include both data and timer.\n     \"\"\"\n     received = self._receiving_queue(instruction_id)\n-    done_transforms = set()  # type: Set[str]\n+    done_inputs = set()  # type: Set[str]", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTk5OTM0Ng==", "url": "https://github.com/apache/beam/pull/11314#discussion_r405999346", "bodyText": "elif", "author": "robertwb", "createdAt": "2020-04-09T07:10:05Z", "path": "sdks/python/apache_beam/runners/worker/data_plane.py", "diffHunk": "@@ -372,12 +428,18 @@ def input_elements(self,\n             t, v, tb = self._exc_info\n             raise_(t, v, tb)\n         else:\n-          # TODO(BEAM-9558): Cleanup once dataflow is updated.\n-          if not data.data or data.is_last:\n-            done_transforms.add(data.transform_id)\n-          else:\n-            assert data.transform_id not in done_transforms\n-            yield data\n+          if isinstance(element, beam_fn_api_pb2.Elements.Timer):\n+            if element.is_last:\n+              done_inputs.add((element.transform_id, element.timer_family_id))\n+            else:\n+              yield element\n+          if isinstance(element, beam_fn_api_pb2.Elements.Data):", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjAwMjU1MA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406002550", "bodyText": "This will always be true (given the loop condition).", "author": "robertwb", "createdAt": "2020-04-09T07:16:51Z", "path": "sdks/python/apache_beam/runners/worker/data_plane.py", "diffHunk": "@@ -408,27 +470,67 @@ def close_callback(data):\n     return ClosableOutputStream.create(\n         close_callback, add_to_send_queue, self._data_buffer_time_limit_ms)\n \n+  def output_timer_stream(self, instruction_id, transform_id, timer_family_id):\n+    def add_to_send_queue(timer):\n+      if timer:\n+        self._to_send.put(\n+            beam_fn_api_pb2.Elements.Timer(\n+                instruction_id=instruction_id,\n+                transform_id=transform_id,\n+                timer_family_id=timer_family_id,\n+                timers=timer,\n+                is_last=False))\n+\n+    def close_callback(timer):\n+      add_to_send_queue(timer)\n+      self._to_send.put(\n+          beam_fn_api_pb2.Elements.Timer(\n+              instruction_id=instruction_id,\n+              transform_id=transform_id,\n+              timer_family_id=timer_family_id,\n+              timers=b'',\n+              is_last=True))\n+\n+    return ClosableOutputStream.create(\n+        close_callback, add_to_send_queue, self._data_buffer_time_limit_ms)\n+\n   def _write_outputs(self):\n     # type: () -> Iterator[beam_fn_api_pb2.Elements]\n-    done = False\n-    while not done:\n-      data = [self._to_send.get()]\n-      try:\n-        # Coalesce up to 100 other items.\n-        for _ in range(100):\n-          data.append(self._to_send.get_nowait())\n-      except queue.Empty:\n-        pass\n-      if data[-1] is self._WRITES_FINISHED:\n-        done = True\n-        data.pop()\n-      if data:\n-        yield beam_fn_api_pb2.Elements(data=data)\n+    stream_done = False\n+    while not stream_done:\n+      streams = None\n+      if not stream_done:", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjAwMzQyNA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406003424", "bodyText": "No need to have these conditionals, you can just write\nyield beam_fn_api_pb2.Elements(data=data_stream, timer=timer_stream)", "author": "robertwb", "createdAt": "2020-04-09T07:18:42Z", "path": "sdks/python/apache_beam/runners/worker/data_plane.py", "diffHunk": "@@ -408,27 +470,67 @@ def close_callback(data):\n     return ClosableOutputStream.create(\n         close_callback, add_to_send_queue, self._data_buffer_time_limit_ms)\n \n+  def output_timer_stream(self, instruction_id, transform_id, timer_family_id):\n+    def add_to_send_queue(timer):\n+      if timer:\n+        self._to_send.put(\n+            beam_fn_api_pb2.Elements.Timer(\n+                instruction_id=instruction_id,\n+                transform_id=transform_id,\n+                timer_family_id=timer_family_id,\n+                timers=timer,\n+                is_last=False))\n+\n+    def close_callback(timer):\n+      add_to_send_queue(timer)\n+      self._to_send.put(\n+          beam_fn_api_pb2.Elements.Timer(\n+              instruction_id=instruction_id,\n+              transform_id=transform_id,\n+              timer_family_id=timer_family_id,\n+              timers=b'',\n+              is_last=True))\n+\n+    return ClosableOutputStream.create(\n+        close_callback, add_to_send_queue, self._data_buffer_time_limit_ms)\n+\n   def _write_outputs(self):\n     # type: () -> Iterator[beam_fn_api_pb2.Elements]\n-    done = False\n-    while not done:\n-      data = [self._to_send.get()]\n-      try:\n-        # Coalesce up to 100 other items.\n-        for _ in range(100):\n-          data.append(self._to_send.get_nowait())\n-      except queue.Empty:\n-        pass\n-      if data[-1] is self._WRITES_FINISHED:\n-        done = True\n-        data.pop()\n-      if data:\n-        yield beam_fn_api_pb2.Elements(data=data)\n+    stream_done = False\n+    while not stream_done:\n+      streams = None\n+      if not stream_done:\n+        streams = [self._to_send.get()]\n+        try:\n+          # Coalesce up to 100 other items.\n+          for _ in range(100):\n+            streams.append(self._to_send.get_nowait())\n+        except queue.Empty:\n+          pass\n+        if streams and streams[-1] is self._WRITES_FINISHED:\n+          stream_done = True\n+          streams.pop()\n+      if streams:\n+        elements = beam_fn_api_pb2.Elements()\n+        data_stream = []\n+        timer_stream = []\n+        for stream in streams:\n+          if isinstance(stream, beam_fn_api_pb2.Elements.Timer):\n+            timer_stream.append(stream)\n+          if isinstance(stream, beam_fn_api_pb2.Elements.Data):\n+            data_stream.append(stream)\n+        if data_stream:", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjAwMzQ3NA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406003474", "bodyText": "else", "author": "robertwb", "createdAt": "2020-04-09T07:18:48Z", "path": "sdks/python/apache_beam/runners/worker/data_plane.py", "diffHunk": "@@ -408,27 +470,67 @@ def close_callback(data):\n     return ClosableOutputStream.create(\n         close_callback, add_to_send_queue, self._data_buffer_time_limit_ms)\n \n+  def output_timer_stream(self, instruction_id, transform_id, timer_family_id):\n+    def add_to_send_queue(timer):\n+      if timer:\n+        self._to_send.put(\n+            beam_fn_api_pb2.Elements.Timer(\n+                instruction_id=instruction_id,\n+                transform_id=transform_id,\n+                timer_family_id=timer_family_id,\n+                timers=timer,\n+                is_last=False))\n+\n+    def close_callback(timer):\n+      add_to_send_queue(timer)\n+      self._to_send.put(\n+          beam_fn_api_pb2.Elements.Timer(\n+              instruction_id=instruction_id,\n+              transform_id=transform_id,\n+              timer_family_id=timer_family_id,\n+              timers=b'',\n+              is_last=True))\n+\n+    return ClosableOutputStream.create(\n+        close_callback, add_to_send_queue, self._data_buffer_time_limit_ms)\n+\n   def _write_outputs(self):\n     # type: () -> Iterator[beam_fn_api_pb2.Elements]\n-    done = False\n-    while not done:\n-      data = [self._to_send.get()]\n-      try:\n-        # Coalesce up to 100 other items.\n-        for _ in range(100):\n-          data.append(self._to_send.get_nowait())\n-      except queue.Empty:\n-        pass\n-      if data[-1] is self._WRITES_FINISHED:\n-        done = True\n-        data.pop()\n-      if data:\n-        yield beam_fn_api_pb2.Elements(data=data)\n+    stream_done = False\n+    while not stream_done:\n+      streams = None\n+      if not stream_done:\n+        streams = [self._to_send.get()]\n+        try:\n+          # Coalesce up to 100 other items.\n+          for _ in range(100):\n+            streams.append(self._to_send.get_nowait())\n+        except queue.Empty:\n+          pass\n+        if streams and streams[-1] is self._WRITES_FINISHED:\n+          stream_done = True\n+          streams.pop()\n+      if streams:\n+        elements = beam_fn_api_pb2.Elements()\n+        data_stream = []\n+        timer_stream = []\n+        for stream in streams:\n+          if isinstance(stream, beam_fn_api_pb2.Elements.Timer):\n+            timer_stream.append(stream)\n+          if isinstance(stream, beam_fn_api_pb2.Elements.Data):", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjAwNDM1Mg==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406004352", "bodyText": "Rather than making this public, I would add an add_timer_info method to this operation.", "author": "robertwb", "createdAt": "2020-04-09T07:20:41Z", "path": "sdks/python/apache_beam/runners/worker/operations.pxd", "diffHunk": "@@ -92,7 +92,7 @@ cdef class DoOperation(Operation):\n   cdef DoFnRunner dofn_runner\n   cdef object tagged_receivers\n   cdef object side_input_maps\n-  cdef object user_state_context\n+  cpdef public object user_state_context", "originalCommit": "0324f490365477c16138d22b597586af4f1a5571", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ0NDY1Ng==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406444656", "bodyText": "Are these still used?", "author": "robertwb", "createdAt": "2020-04-09T20:00:42Z", "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -1272,6 +1272,8 @@ def expand(self, pcoll):\n         key_coder = coder.key_coder()\n       else:\n         key_coder = coders.registry.get_coder(typehints.Any)\n+      self.window_coder = pcoll.windowing.windowfn.get_window_coder()", "originalCommit": "77e69d8c362a5ae20b4527bfa85feb99e21eede8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ5MDQ1NA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406490454", "bodyText": "No. Will removed.", "author": "boyuanzz", "createdAt": "2020-04-09T21:34:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ0NDY1Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ0NDc4MQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406444781", "bodyText": "This code looks like it's copied from the superclass, instead just do\ndef to_runner_api(self, context, named_inputs, **extra_kwargs):\n  super(ParDo, self).to_runner_api, named_inputs=named_inputs, **extra_kwargs)", "author": "robertwb", "createdAt": "2020-04-09T20:00:59Z", "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -1323,12 +1325,47 @@ def _pardo_fn_data(self):\n     windowing = None\n     return self.fn, self.args, self.kwargs, si_tags_and_types, windowing\n \n-  def to_runner_api_parameter(self, context):\n+  def _get_key_and_window_coder(self, named_inputs):\n+    if named_inputs is None or not self._signature.is_stateful_dofn():\n+      return None, None\n+    main_input = list(set(named_inputs.keys()) - set(self.side_inputs))[0]\n+    input_pcoll = named_inputs[main_input]\n+    kv_type_hint = input_pcoll.element_type\n+    if kv_type_hint and kv_type_hint != typehints.Any:\n+      coder = coders.registry.get_coder(kv_type_hint)\n+      if not coder.is_kv_coder():\n+        raise ValueError(\n+            'Input elements to the transform %s with stateful DoFn must be '\n+            'key-value pairs.' % self)\n+      key_coder = coder.key_coder()\n+    else:\n+      key_coder = coders.registry.get_coder(typehints.Any)\n+    window_coder = input_pcoll.windowing.windowfn.get_window_coder()\n+    return key_coder, window_coder\n+\n+  def to_runner_api(self, context, **extra_kwargs):", "originalCommit": "77e69d8c362a5ae20b4527bfa85feb99e21eede8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ4MTgyMA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406481820", "bodyText": "We can delete this override since we pass extra_kwargs from PTransform now.", "author": "boyuanzz", "createdAt": "2020-04-09T21:15:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ0NDc4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ2NTUxNA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406465514", "bodyText": "This comment is a bit misleading, as the injection doesn't happen in this for loop. (Similarly with timers.)", "author": "robertwb", "createdAt": "2020-04-09T20:43:02Z", "path": "sdks/python/apache_beam/runners/worker/bundle_processor.py", "diffHunk": "@@ -837,25 +869,59 @@ def process_bundle(self, instruction_id):\n         op.execution_context = execution_context\n         op.start()\n \n-      # Inject inputs from data plane.\n+      # Each data_channel is mapped to a list of expected inputs which includes\n+      # both data input and timer input. The data input is identied by\n+      # transform_id. The data input is identified by\n+      # (transform_id, timer_family_id).\n       data_channels = collections.defaultdict(\n           list\n       )  # type: DefaultDict[data_plane.GrpcClientDataChannel, List[str]]\n+\n+      # Inject data inputs from data plane.", "originalCommit": "481546d0d06b3d360c03c076b7c7663c83cd74d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ5MDUwNA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406490504", "bodyText": "Updated the comment.", "author": "boyuanzz", "createdAt": "2020-04-09T21:34:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ2NTUxNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ2NjIxNQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406466215", "bodyText": "Nice simplification here :).", "author": "robertwb", "createdAt": "2020-04-09T20:44:24Z", "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/translations.py", "diffHunk": "@@ -1321,80 +1321,18 @@ def remove_data_plane_ops(stages, pipeline_context):\n       yield stage\n \n \n-def inject_timer_pcollections(stages, pipeline_context):\n+def setup_timer_mapping(stages, pipeline_context):\n   # type: (Iterable[Stage], TransformContext) -> Iterator[Stage]\n \n-  \"\"\"Create PCollections for fired timers and to-be-set timers.\n-\n-  At execution time, fired timers and timers-to-set are represented as\n-  PCollections that are managed by the runner.  This phase adds the\n-  necissary collections, with their read and writes, to any stages using\n-  timers.\n+  \"\"\"Set up a mapping of {transform_id: [timer_ids]} for each stage.\n   \"\"\"\n   for stage in stages:\n-    for transform in list(stage.transforms):\n+    for transform in stage.transforms:\n       if transform.spec.urn in PAR_DO_URNS:\n         payload = proto_utils.parse_Bytes(\n             transform.spec.payload, beam_runner_api_pb2.ParDoPayload)\n-        for tag, spec in payload.timer_family_specs.items():\n-          if len(transform.inputs) > 1:\n-            raise NotImplementedError('Timers and side inputs.')\n-          input_pcoll = pipeline_context.components.pcollections[next(\n-              iter(transform.inputs.values()))]\n-          # Create the appropriate coder for the timer PCollection.\n-          key_coder_id = input_pcoll.coder_id\n-          if (pipeline_context.components.coders[key_coder_id].spec.urn ==\n-              common_urns.coders.KV.urn):\n-            key_coder_id = pipeline_context.components.coders[\n-                key_coder_id].component_coder_ids[0]\n-          key_timer_coder_id = pipeline_context.add_or_get_coder_id(\n-              beam_runner_api_pb2.Coder(\n-                  spec=beam_runner_api_pb2.FunctionSpec(\n-                      urn=common_urns.coders.KV.urn),\n-                  component_coder_ids=[\n-                      key_coder_id, spec.timer_family_coder_id\n-                  ]))\n-          # Inject the read and write pcollections.\n-          timer_read_pcoll = unique_name(\n-              pipeline_context.components.pcollections,\n-              '%s_timers_to_read_%s' % (transform.unique_name, tag))\n-          timer_write_pcoll = unique_name(\n-              pipeline_context.components.pcollections,\n-              '%s_timers_to_write_%s' % (transform.unique_name, tag))\n-          pipeline_context.components.pcollections[timer_read_pcoll].CopyFrom(\n-              beam_runner_api_pb2.PCollection(\n-                  unique_name=timer_read_pcoll,\n-                  coder_id=key_timer_coder_id,\n-                  windowing_strategy_id=input_pcoll.windowing_strategy_id,\n-                  is_bounded=input_pcoll.is_bounded))\n-          pipeline_context.components.pcollections[timer_write_pcoll].CopyFrom(\n-              beam_runner_api_pb2.PCollection(\n-                  unique_name=timer_write_pcoll,\n-                  coder_id=key_timer_coder_id,\n-                  windowing_strategy_id=input_pcoll.windowing_strategy_id,\n-                  is_bounded=input_pcoll.is_bounded))\n-          stage.transforms.append(\n-              beam_runner_api_pb2.PTransform(\n-                  unique_name=timer_read_pcoll + '/Read',\n-                  outputs={'out': timer_read_pcoll},\n-                  spec=beam_runner_api_pb2.FunctionSpec(\n-                      urn=bundle_processor.DATA_INPUT_URN,\n-                      payload=create_buffer_id(timer_read_pcoll,\n-                                               kind='timers'))))\n-          stage.transforms.append(\n-              beam_runner_api_pb2.PTransform(\n-                  unique_name=timer_write_pcoll + '/Write',\n-                  inputs={'in': timer_write_pcoll},\n-                  spec=beam_runner_api_pb2.FunctionSpec(\n-                      urn=bundle_processor.DATA_OUTPUT_URN,\n-                      payload=create_buffer_id(\n-                          timer_write_pcoll, kind='timers'))))\n-          assert tag not in transform.inputs\n-          transform.inputs[tag] = timer_read_pcoll\n-          assert tag not in transform.outputs\n-          transform.outputs[tag] = timer_write_pcoll\n-          stage.timer_pcollections.append(\n-              (timer_read_pcoll + '/Read', timer_write_pcoll))\n+        for timer_family_id in payload.timer_family_specs.keys():\n+          stage.timers.add((transform.unique_name, timer_family_id))", "originalCommit": "481546d0d06b3d360c03c076b7c7663c83cd74d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ2NzQ4MQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406467481", "bodyText": "For consistency, should this be a Mapping[Tuple[str, str], PartitionableBuffer]?", "author": "robertwb", "createdAt": "2020-04-09T20:46:54Z", "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "diffHunk": "@@ -987,8 +1019,10 @@ def __init__(\n \n   def process_bundle(self,\n                      inputs,  # type: Mapping[str, PartitionableBuffer]\n-                     expected_outputs  # type: DataOutput\n-                    ):\n+                     expected_outputs,  # type: DataOutput\n+                     fired_timers,  # type: Mapping[str, Mapping[str, PartitionableBuffer]]", "originalCommit": "481546d0d06b3d360c03c076b7c7663c83cd74d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ5MDU1Ng==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406490556", "bodyText": "I updated the fired_timers implementation but forgot to update the typing here. Thanks!", "author": "boyuanzz", "createdAt": "2020-04-09T21:34:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ2NzQ4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ2ODMzMQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406468331", "bodyText": "Put {} on its own line. (Surprised yapf didn't complain, or maybe you haven't run it yet.)", "author": "robertwb", "createdAt": "2020-04-09T20:48:26Z", "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "diffHunk": "@@ -536,7 +525,8 @@ def _run_stage(self,\n         runner_execution_context,\n         bundle_context_manager,\n         data_input,\n-        data_output,\n+        data_output, {},", "originalCommit": "481546d0d06b3d360c03c076b7c7663c83cd74d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ5MTMxNg==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406491316", "bodyText": "yapf helps me put the {} here.", "author": "boyuanzz", "createdAt": "2020-04-09T21:35:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ2ODMzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ3MTA5MQ==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406471091", "bodyText": "Mapping[Tuple[str, str], PartitionableBuffer]?", "author": "robertwb", "createdAt": "2020-04-09T20:53:48Z", "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "diffHunk": "@@ -896,7 +906,9 @@ def _generate_splits_for_testing(self,\n \n   def process_bundle(self,\n                      inputs,  # type: Mapping[str, PartitionableBuffer]\n-                     expected_outputs  # type: DataOutput\n+                     expected_outputs,  # type: DataOutput\n+                     fired_timers,  # type: Mapping[str, Mapping[str, PartitionableBuffer]]", "originalCommit": "481546d0d06b3d360c03c076b7c7663c83cd74d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ3MzIzMA==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406473230", "bodyText": "This is a subtle point. I might write something like \"The worker waits for a logical timer stream to be closed for every possible timer, regardless of whether there are any timers to be sent.\"\nMaybe it'd be clearer to iterate over expected_output_timers, and send fired_timers.get((transform_id, timer_family_id), []).", "author": "robertwb", "createdAt": "2020-04-09T20:58:02Z", "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "diffHunk": "@@ -914,6 +926,17 @@ def process_bundle(self,\n \n     split_manager = self._select_split_manager()\n     if not split_manager:\n+      # Send the fired timers if any.\n+      for (transform_id, timer_family_id), timers in fired_timers.items():\n+        self._send_timers_to_worker(\n+            process_bundle_id, transform_id, timer_family_id, timers)\n+\n+      for transform_id, timer_family_id in (\n+          set(expected_output_timers.keys()) - set(fired_timers.keys())):\n+        # Close the stream if there is no timers to be sent.", "originalCommit": "481546d0d06b3d360c03c076b7c7663c83cd74d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjQ3NDQ2Mw==", "url": "https://github.com/apache/beam/pull/11314#discussion_r406474463", "bodyText": "The key error if it's not present below will be sufficient.", "author": "robertwb", "createdAt": "2020-04-09T21:00:20Z", "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "diffHunk": "@@ -355,20 +364,41 @@ def _build_process_bundle_descriptor(self):\n             items()),\n         environments=dict(\n             self.execution_context.pipeline_components.environments.items()),\n-        state_api_service_descriptor=self.state_api_service_descriptor())\n+        state_api_service_descriptor=self.state_api_service_descriptor(),\n+        timer_api_service_descriptor=self.data_api_service_descriptor())\n \n   def get_input_coder_impl(self, transform_id):\n     # type: (str) -> CoderImpl\n     coder_id = beam_fn_api_pb2.RemoteGrpcPort.FromString(\n         self.process_bundle_descriptor.transforms[transform_id].spec.payload\n     ).coder_id\n     assert coder_id\n+    return self.get_coder_impl(coder_id)\n+\n+  def _build_timer_coders_id_map(self):\n+    timer_coder_ids = {}\n+    for transform_id, transform_proto in (self._process_bundle_descriptor\n+        .transforms.items()):\n+      if transform_proto.spec.urn == common_urns.primitives.PAR_DO.urn:\n+        pardo_payload = proto_utils.parse_Bytes(\n+            transform_proto.spec.payload, beam_runner_api_pb2.ParDoPayload)\n+        for id, timer_family_spec in pardo_payload.timer_family_specs.items():\n+          timer_coder_ids[(transform_id, id)] = (\n+              timer_family_spec.timer_family_coder_id)\n+    return timer_coder_ids\n+\n+  def get_coder_impl(self, coder_id):\n     if coder_id in self.execution_context.safe_coders:\n       return self.execution_context.pipeline_context.coders[\n           self.execution_context.safe_coders[coder_id]].get_impl()\n     else:\n       return self.execution_context.pipeline_context.coders[coder_id].get_impl()\n \n+  def get_timer_coder_impl(self, transform_id, timer_family_id):\n+    assert (transform_id, timer_family_id) in self._timer_coder_ids", "originalCommit": "481546d0d06b3d360c03c076b7c7663c83cd74d1", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0c1e830b25c27a3b6f58eafe3ded48e7386108a2", "url": "https://github.com/apache/beam/commit/0c1e830b25c27a3b6f58eafe3ded48e7386108a2", "message": "[BEAM-9562, BEAM-6274] Fix-up timers to use Elements.Timer proto in data channel in Beam Java and Python", "committedDate": "2020-04-09T22:43:19Z", "type": "forcePushed"}, {"oid": "8db19a4645b8588ce9e046637b7619815169bdb1", "url": "https://github.com/apache/beam/commit/8db19a4645b8588ce9e046637b7619815169bdb1", "message": "[BEAM-9562, BEAM-6274] Fix-up timers to use Elements.Timer proto in data channel in Beam Java and Python", "committedDate": "2020-04-09T22:49:56Z", "type": "commit"}, {"oid": "8db19a4645b8588ce9e046637b7619815169bdb1", "url": "https://github.com/apache/beam/commit/8db19a4645b8588ce9e046637b7619815169bdb1", "message": "[BEAM-9562, BEAM-6274] Fix-up timers to use Elements.Timer proto in data channel in Beam Java and Python", "committedDate": "2020-04-09T22:49:56Z", "type": "forcePushed"}]}