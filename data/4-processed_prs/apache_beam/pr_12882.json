{"pr_number": 12882, "pr_title": "[BEAM-10814][BEAM-10570] DataframeTransform outputs elements", "pr_createdAt": "2020-09-20T00:12:09Z", "pr_url": "https://github.com/apache/beam/pull/12882", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NDU4NA==", "url": "https://github.com/apache/beam/pull/12882#discussion_r491664584", "bodyText": "Put ()'s around (key, pc) for better formatting.", "author": "robertwb", "createdAt": "2020-09-20T07:45:06Z", "path": "sdks/python/apache_beam/dataframe/convert.py", "diffHunk": "@@ -118,6 +119,15 @@ def extract_input(placeholder):\n              } | label >> transforms._DataframeExpressionsTransform(\n                  dict((ix, df._expr) for ix, df in enumerate(\n                      dataframes)))  # type: Dict[Any, pvalue.PCollection]\n+\n+  if not yield_dataframes:\n+    results = {\n+        key: pc | \"Unbatch '%s'\" % dataframes[key]._expr._id >>\n+        schemas.UnbatchPandas(dataframes[key]._expr.proxy())\n+        for key,", "originalCommit": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NDc3Ng==", "url": "https://github.com/apache/beam/pull/12882#discussion_r491664776", "bodyText": "We should consider whether we want flattening here (e.g. with dotted attributes). Let's at least mark this paragraph as subject to change.", "author": "robertwb", "createdAt": "2020-09-20T07:48:07Z", "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -15,25 +15,129 @@\n # limitations under the License.\n #\n \n-\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+r\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\n+pandas dtype               Python typing\n+np.int{8,16,32,64}      <-----> np.int{8,16,32,64}*\n+pd.Int{8,16,32,64}Dtype <-----> Optional[np.int{8,16,32,64}]*\n+np.float{32,64}         <-----> Optional[np.float{32,64}]\n+                           \\--- np.float{32,64}\n+np.dtype('S')           <-----> bytes\n+Not supported           <------ Optional[bytes]\n+np.bool                 <-----> np.bool\n+\n+* int, float, bool are treated the same as np.int64, np.float64, np.bool\n+\n+Any unknown or unsupported types are trested as Any and shunted to\n+np.object:\n+\n+np.object               <-----> Any\n+\n+Strings and nullable Booleans are handled differently when using pandas 0.x vs.\n+1.x. pandas 0.x has no mapping for these types, so they are shunted lossily to\n+  np.object.\n+\n+pandas 0.x:\n+np.object         <------ Optional[bool]\n+                     \\--- Optional[str]\n+                      \\-- str\n+\n+pandas 1.x:\n+pd.BooleanDType() <-----> Optional[bool]\n+pd.StringDType()  <-----> Optional[str]\n+                     \\--- str\n+\n+Pandas does not support hierarchical data natively. All structured types", "originalCommit": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjMyOTQxNw==", "url": "https://github.com/apache/beam/pull/12882#discussion_r492329417", "bodyText": "SG, I added a sentence indicating we might add better support for these types in the future.", "author": "TheNeuralBit", "createdAt": "2020-09-21T20:33:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NDc3Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NDg4Nw==", "url": "https://github.com/apache/beam/pull/12882#discussion_r491664887", "bodyText": "This will break for betas, rcs, etc. Maybe just do int(pd.__version__.split('.')[0])", "author": "robertwb", "createdAt": "2020-09-20T07:49:41Z", "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -15,25 +15,129 @@\n # limitations under the License.\n #\n \n-\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+r\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\n+pandas dtype               Python typing\n+np.int{8,16,32,64}      <-----> np.int{8,16,32,64}*\n+pd.Int{8,16,32,64}Dtype <-----> Optional[np.int{8,16,32,64}]*\n+np.float{32,64}         <-----> Optional[np.float{32,64}]\n+                           \\--- np.float{32,64}\n+np.dtype('S')           <-----> bytes\n+Not supported           <------ Optional[bytes]\n+np.bool                 <-----> np.bool\n+\n+* int, float, bool are treated the same as np.int64, np.float64, np.bool\n+\n+Any unknown or unsupported types are trested as Any and shunted to\n+np.object:\n+\n+np.object               <-----> Any\n+\n+Strings and nullable Booleans are handled differently when using pandas 0.x vs.\n+1.x. pandas 0.x has no mapping for these types, so they are shunted lossily to\n+  np.object.\n+\n+pandas 0.x:\n+np.object         <------ Optional[bool]\n+                     \\--- Optional[str]\n+                      \\-- str\n+\n+pandas 1.x:\n+pd.BooleanDType() <-----> Optional[bool]\n+pd.StringDType()  <-----> Optional[str]\n+                     \\--- str\n+\n+Pandas does not support hierarchical data natively. All structured types\n+(Sequence, Mapping, nested NamedTuple types), will be shunted lossily to\n+np.object/Any.\n+\n+TODO: Mapping for date/time types\n+https://pandas.pydata.org/docs/user_guide/timeseries.html#overview\n+\n+timestamps and timedeltas in pandas always use nanosecond precision\n \"\"\"\n \n # pytype: skip-file\n \n from __future__ import absolute_import\n \n-import typing\n+from typing import Any\n+from typing import NamedTuple\n+from typing import Optional\n+from typing import TypeVar\n+from typing import Union\n \n+import numpy as np\n import pandas as pd\n \n import apache_beam as beam\n from apache_beam import typehints\n+from apache_beam.portability.api import schema_pb2\n from apache_beam.transforms.util import BatchElements\n+from apache_beam.typehints.native_type_compatibility import _match_is_optional\n from apache_beam.typehints.schemas import named_fields_from_element_type\n+from apache_beam.typehints.schemas import named_fields_to_schema\n+from apache_beam.typehints.schemas import named_tuple_from_schema\n+from apache_beam.typehints.schemas import named_tuple_to_schema\n+from apache_beam.utils import proto_utils\n+\n+__all__ = (\n+    'BatchRowsAsDataFrame',\n+    'generate_proxy',\n+    'UnbatchPandas',\n+    'element_type_from_proxy')\n+\n+T = TypeVar('T', bound=NamedTuple)\n+\n+PD_MAJOR, _, _ = map(int, pd.__version__.split('.'))", "originalCommit": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjMyOTE1NA==", "url": "https://github.com/apache/beam/pull/12882#discussion_r492329154", "bodyText": "Fixed, thanks", "author": "TheNeuralBit", "createdAt": "2020-09-21T20:32:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NDg4Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NDk3OQ==", "url": "https://github.com/apache/beam/pull/12882#discussion_r491664979", "bodyText": "extra whitespace?", "author": "robertwb", "createdAt": "2020-09-20T07:50:56Z", "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+", "originalCommit": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjMyOTA4NQ==", "url": "https://github.com/apache/beam/pull/12882#discussion_r492329085", "bodyText": "Removed", "author": "TheNeuralBit", "createdAt": "2020-09-21T20:32:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NDk3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTA2Mg==", "url": "https://github.com/apache/beam/pull/12882#discussion_r491665062", "bodyText": "Is whitespace stripped at the beginning of a docstring? (Similarly below.)", "author": "robertwb", "createdAt": "2020-09-20T07:52:01Z", "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+\n+  return pd.Series(name=name, dtype=dtype)\n \n \n def generate_proxy(element_type):\n   # type: (type) -> pd.DataFrame\n-  return pd.DataFrame({\n-      name: _make_empty_series(name, typ)\n-      for name,\n-      typ in named_fields_from_element_type(element_type)\n-  })\n+\n+  \"\"\" Generate a proxy pandas object for the given PCollection element_type.", "originalCommit": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjMyOTAxNA==", "url": "https://github.com/apache/beam/pull/12882#discussion_r492329014", "bodyText": "Done", "author": "TheNeuralBit", "createdAt": "2020-09-21T20:32:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTA2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTQwNg==", "url": "https://github.com/apache/beam/pull/12882#discussion_r491665406", "bodyText": "I was wondering about this as well--do we want to return the index iff it's a multi-index or it's named? Should we make whether to return the index another option?", "author": "robertwb", "createdAt": "2020-09-20T07:55:56Z", "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+\n+  return pd.Series(name=name, dtype=dtype)\n \n \n def generate_proxy(element_type):\n   # type: (type) -> pd.DataFrame\n-  return pd.DataFrame({\n-      name: _make_empty_series(name, typ)\n-      for name,\n-      typ in named_fields_from_element_type(element_type)\n-  })\n+\n+  \"\"\" Generate a proxy pandas object for the given PCollection element_type.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  fields = named_fields_from_element_type(element_type)\n+  return pd.DataFrame(\n+      {name: _make_proxy_series(name, typehint)\n+       for name, typehint in fields},\n+      columns=[name for name, _ in fields])\n+\n+\n+def element_type_from_proxy(proxy):\n+  # type: (pd.DataFrame) -> type\n+\n+  \"\"\" Generate an element_type for an element-wise PCollection from a proxy\n+  pandas object. Currently only supports converting the element_type for\n+  a schema-aware PCollection to a proxy DataFrame.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  indices = [] if proxy.index.names == (None, ) else [", "originalCommit": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIxOTMxNw==", "url": "https://github.com/apache/beam/pull/12882#discussion_r492219317", "bodyText": "I thought the MultiIndex or named case was important since otherwise we'll drop the grouped column(s) when unbatching the result of a grouped aggregation.\nIt raise some tricky issues though:\n\nIndex names are not required to be unique.\nIt looks like my assumption that all MultiIndexes are named is wrong. It's possible to create a MultiIndex with names=[None, None, 'foo'], which would break this badly.\nType information is not necessarily preserved in indexes. e.g. Int64Index doesn't support nulls like Series with Int64Dtype does. if one is added it's converted to a Float64Index with nans.\n\nMaybe including the index shouldn't be the default until we have a better handle on these edge cases.", "author": "TheNeuralBit", "createdAt": "2020-09-21T17:13:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTQwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIxOTkzNg==", "url": "https://github.com/apache/beam/pull/12882#discussion_r492219936", "bodyText": "We could log a warning if there's a named index in the result and include_indexes is False", "author": "TheNeuralBit", "createdAt": "2020-09-21T17:14:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTQwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjMzMDE4NA==", "url": "https://github.com/apache/beam/pull/12882#discussion_r492330184", "bodyText": "I added an include_indexes option on DataframeTransform, to_pcollection, and UnbatchPandas. It raises an exception if used when index names are not unique or unnamed. PTAL", "author": "TheNeuralBit", "createdAt": "2020-09-21T20:34:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTQwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ2NTI5NA==", "url": "https://github.com/apache/beam/pull/12882#discussion_r492465294", "bodyText": "+1 We should probably allow an explicit include_indexes=False to not raise an exception.", "author": "robertwb", "createdAt": "2020-09-22T04:15:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTQwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTkxNg==", "url": "https://github.com/apache/beam/pull/12882#discussion_r491665916", "bodyText": "Maybe ..._from_dataframe? (Proxy may not be a dataframe.)", "author": "robertwb", "createdAt": "2020-09-20T08:01:52Z", "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+\n+  return pd.Series(name=name, dtype=dtype)\n \n \n def generate_proxy(element_type):\n   # type: (type) -> pd.DataFrame\n-  return pd.DataFrame({\n-      name: _make_empty_series(name, typ)\n-      for name,\n-      typ in named_fields_from_element_type(element_type)\n-  })\n+\n+  \"\"\" Generate a proxy pandas object for the given PCollection element_type.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  fields = named_fields_from_element_type(element_type)\n+  return pd.DataFrame(\n+      {name: _make_proxy_series(name, typehint)\n+       for name, typehint in fields},\n+      columns=[name for name, _ in fields])\n+\n+\n+def element_type_from_proxy(proxy):", "originalCommit": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjMyODkxOQ==", "url": "https://github.com/apache/beam/pull/12882#discussion_r492328919", "bodyText": "Done", "author": "TheNeuralBit", "createdAt": "2020-09-21T20:32:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTkxNg=="}], "type": "inlineReview"}, {"oid": "c80993de04bc7752a49b26dd90af2b2e3a9a13df", "url": "https://github.com/apache/beam/commit/c80993de04bc7752a49b26dd90af2b2e3a9a13df", "message": "fix io_test", "committedDate": "2020-09-22T22:09:14Z", "type": "forcePushed"}, {"oid": "e3cac41275c5726e4b0a3056648efe4ce614bb2b", "url": "https://github.com/apache/beam/commit/e3cac41275c5726e4b0a3056648efe4ce614bb2b", "message": "Add support for encoding 'Any'  with FastPrimitivesCoder", "committedDate": "2020-09-23T02:56:42Z", "type": "commit"}, {"oid": "3a6566055ee8191d737f0f8f9a45c61f85c6e557", "url": "https://github.com/apache/beam/commit/3a6566055ee8191d737f0f8f9a45c61f85c6e557", "message": "Add support for 'unbatching' DataframeTransform.", "committedDate": "2020-09-23T02:56:46Z", "type": "commit"}, {"oid": "8b2ab3cbf54c536d4ca0f4f3e84d5fb1ef4aad63", "url": "https://github.com/apache/beam/commit/8b2ab3cbf54c536d4ca0f4f3e84d5fb1ef4aad63", "message": "lint", "committedDate": "2020-09-23T02:56:46Z", "type": "commit"}, {"oid": "31cafeb2ad64a4bd8362f2e56e1b56d27a85574e", "url": "https://github.com/apache/beam/commit/31cafeb2ad64a4bd8362f2e56e1b56d27a85574e", "message": "Give user the option to include indexes or not", "committedDate": "2020-09-23T02:56:46Z", "type": "commit"}, {"oid": "a60334e626983424f5d44b07fcc803195cbe3ccb", "url": "https://github.com/apache/beam/commit/a60334e626983424f5d44b07fcc803195cbe3ccb", "message": "mypy", "committedDate": "2020-09-23T02:56:46Z", "type": "commit"}, {"oid": "53fb1aa1f7fdc52f207e80035029d6048bc793aa", "url": "https://github.com/apache/beam/commit/53fb1aa1f7fdc52f207e80035029d6048bc793aa", "message": "docs", "committedDate": "2020-09-23T02:56:46Z", "type": "commit"}, {"oid": "4e9193a05951d7eacbc8f70ab81bcde35af3ba21", "url": "https://github.com/apache/beam/commit/4e9193a05951d7eacbc8f70ab81bcde35af3ba21", "message": "Unknown primitive uses Any", "committedDate": "2020-09-23T02:56:46Z", "type": "commit"}, {"oid": "0f48b5501709b05f6603d52f299147b499eb9fee", "url": "https://github.com/apache/beam/commit/0f48b5501709b05f6603d52f299147b499eb9fee", "message": "fix io_test", "committedDate": "2020-09-23T02:56:46Z", "type": "commit"}, {"oid": "c86da9504b5ae300ec3b680f54123827db2887f9", "url": "https://github.com/apache/beam/commit/c86da9504b5ae300ec3b680f54123827db2887f9", "message": "Don't run python 3.5 in precommit", "committedDate": "2020-09-23T02:56:46Z", "type": "commit"}, {"oid": "c86da9504b5ae300ec3b680f54123827db2887f9", "url": "https://github.com/apache/beam/commit/c86da9504b5ae300ec3b680f54123827db2887f9", "message": "Don't run python 3.5 in precommit", "committedDate": "2020-09-23T02:56:46Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzcxMjUxNg==", "url": "https://github.com/apache/beam/pull/12882#discussion_r493712516", "bodyText": "FYI @tvalentyn I just merged this PR including a commit to drop python 3.5 in the precommit", "author": "TheNeuralBit", "createdAt": "2020-09-23T16:04:15Z", "path": "build.gradle", "diffHunk": "@@ -199,7 +199,6 @@ task goIntegrationTests() {\n \n task pythonPreCommit() {\n   dependsOn \":sdks:python:test-suites:tox:pycommon:preCommitPyCommon\"\n-  dependsOn \":sdks:python:test-suites:tox:py35:preCommitPy35\"", "originalCommit": "c86da9504b5ae300ec3b680f54123827db2887f9", "replyToReviewId": null, "replies": null, "type": "inlineReview"}]}