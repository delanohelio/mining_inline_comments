{"pr_number": 12149, "pr_title": "[BEAM-9897] Add cross-language support to SnowflakeIO.Read", "pr_createdAt": "2020-07-01T12:41:36Z", "pr_url": "https://github.com/apache/beam/pull/12149", "timeline": [{"oid": "808d858339d162e30586f9e21e3388e50afc726a", "url": "https://github.com/apache/beam/commit/808d858339d162e30586f9e21e3388e50afc726a", "message": "[BEAM-9897] add xlang support for SnowflakeIO.read", "committedDate": "2020-07-01T13:00:17Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNTcwMg==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453425702", "bodyText": "You should not need this. You just have to make sure that dependencies correctly get determined (and staged) during cross language expansion.", "author": "chamikaramj", "createdAt": "2020-07-13T04:15:42Z", "path": "sdks/java/container/boot.go", "diffHunk": "@@ -122,6 +122,7 @@ func main() {\n \t\tfilepath.Join(jarsDir, \"beam-sdks-java-harness.jar\"),\n \t\tfilepath.Join(jarsDir, \"beam-sdks-java-io-kafka.jar\"),\n \t\tfilepath.Join(jarsDir, \"kafka-clients.jar\"),\n+\t\tfilepath.Join(jarsDir, \"beam-sdks-java-io-snowflake.jar\"),", "originalCommit": "be8ce595829b2b86e0e66f7ce26efe3eeba23f72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQ3MjcyNg==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453472726", "bodyText": "I removed it, thanks.", "author": "purbanow", "createdAt": "2020-07-13T08:11:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNTcwMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNTgwNQ==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453425805", "bodyText": "Ditto.", "author": "chamikaramj", "createdAt": "2020-07-13T04:16:08Z", "path": "sdks/java/container/build.gradle", "diffHunk": "@@ -49,6 +49,7 @@ dependencies {\n   dockerDependency project(\":sdks:java:io:kafka\")\n   // This dependency is set to 'provided' scope in :sdks:java:io:kafka\n   dockerDependency library.java.kafka_clients\n+  dockerDependency project(path: \":sdks:java:io:snowflake\", configuration: \"shadow\")", "originalCommit": "be8ce595829b2b86e0e66f7ce26efe3eeba23f72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQ3Mjg2Mg==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453472862", "bodyText": "I removed it, thanks.", "author": "purbanow", "createdAt": "2020-07-13T08:12:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNTgwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNTg2NQ==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453425865", "bodyText": "Ditto.", "author": "chamikaramj", "createdAt": "2020-07-13T04:16:20Z", "path": "sdks/java/container/build.gradle", "diffHunk": "@@ -60,6 +61,8 @@ task copyDockerfileDependencies(type: Copy) {\n   rename 'beam-sdks-java-harness-.*.jar', 'beam-sdks-java-harness.jar'\n   rename 'beam-sdks-java-io-kafka.*.jar', 'beam-sdks-java-io-kafka.jar'\n   rename 'kafka-clients.*.jar', 'kafka-clients.jar'\n+  rename 'beam-sdks-java-io-snowflake.*SNAPSHOT.jar', 'beam-sdks-java-io-snowflake.jar'", "originalCommit": "be8ce595829b2b86e0e66f7ce26efe3eeba23f72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQ3MjkzMQ==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453472931", "bodyText": "I removed it, thanks.", "author": "purbanow", "createdAt": "2020-07-13T08:12:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNTg2NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNTk2OA==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453425968", "bodyText": "Why are we adding a dependency here ?", "author": "chamikaramj", "createdAt": "2020-07-13T04:16:45Z", "path": "sdks/java/expansion-service/build.gradle", "diffHunk": "@@ -42,6 +42,8 @@ dependencies {\n   compile library.java.slf4j_api\n   runtimeOnly library.java.slf4j_jdk14\n   testCompile library.java.junit\n+\n+  runtime project(\":sdks:java:io:snowflake\")", "originalCommit": "be8ce595829b2b86e0e66f7ce26efe3eeba23f72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQ3MzIxMQ==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453473211", "bodyText": "I removed it and checked if everything is working, thanks for spotting this.", "author": "purbanow", "createdAt": "2020-07-13T08:13:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNTk2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNjQ2OQ==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453426469", "bodyText": "Why are we implementing separate methods here ? Also probably this should be a separate PR.", "author": "chamikaramj", "createdAt": "2020-07-13T04:19:17Z", "path": "sdks/java/io/snowflake/src/main/java/org/apache/beam/sdk/io/snowflake/SnowflakeIO.java", "diffHunk": "@@ -960,26 +953,44 @@ public static DataSourceConfiguration create(DataSource dataSource) {\n      * @param credentials - an instance of {@link SnowflakeCredentials}.\n      */\n     public static DataSourceConfiguration create(SnowflakeCredentials credentials) {\n-      if (credentials instanceof UsernamePasswordSnowflakeCredentials) {\n-        return new AutoValue_SnowflakeIO_DataSourceConfiguration.Builder()\n-            .setValidate(true)\n-            .setUsername(((UsernamePasswordSnowflakeCredentials) credentials).getUsername())\n-            .setPassword(((UsernamePasswordSnowflakeCredentials) credentials).getPassword())\n-            .build();\n-      } else if (credentials instanceof OAuthTokenSnowflakeCredentials) {\n-        return new AutoValue_SnowflakeIO_DataSourceConfiguration.Builder()\n-            .setValidate(true)\n-            .setOauthToken(((OAuthTokenSnowflakeCredentials) credentials).getToken())\n-            .build();\n-      } else if (credentials instanceof KeyPairSnowflakeCredentials) {\n-        return new AutoValue_SnowflakeIO_DataSourceConfiguration.Builder()\n-            .setValidate(true)\n-            .setUsername(((KeyPairSnowflakeCredentials) credentials).getUsername())\n-            .setPrivateKey(((KeyPairSnowflakeCredentials) credentials).getPrivateKey())\n-            .build();\n-      }\n-      throw new IllegalArgumentException(\n-          \"Can't create DataSourceConfiguration from given credentials\");\n+      return credentials.createSnowflakeDataSourceConfiguration();\n+    }\n+\n+    /**\n+     * Creates {@link DataSourceConfiguration} from instance of {@link", "originalCommit": "be8ce595829b2b86e0e66f7ce26efe3eeba23f72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzUwNDU5OQ==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453504599", "bodyText": "I removed this improvement from this PR.", "author": "purbanow", "createdAt": "2020-07-13T09:07:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNjQ2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNjkyMA==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453426920", "bodyText": "I suggest moving changes to credentials to a separate PR since this seems to be unrelated to x-lang changes.", "author": "chamikaramj", "createdAt": "2020-07-13T04:21:12Z", "path": "sdks/java/io/snowflake/src/main/java/org/apache/beam/sdk/io/snowflake/credentials/OAuthTokenSnowflakeCredentials.java", "diffHunk": "@@ -28,4 +30,9 @@ public OAuthTokenSnowflakeCredentials(String token) {\n   public String getToken() {\n     return token;\n   }\n+\n+  @Override", "originalCommit": "be8ce595829b2b86e0e66f7ce26efe3eeba23f72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzUwNDk3Mg==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453504972", "bodyText": "I removed this improvement from this PR and I will prepare separate PR.", "author": "purbanow", "createdAt": "2020-07-13T09:08:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNjkyMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNzE2MA==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453427160", "bodyText": "Probably just leave this in the package \"org.apache.beam.sdk.io.snowflake\" ? Is there a need to add a new package ? (and if so probably use long form \"crosslanguage\").", "author": "chamikaramj", "createdAt": "2020-07-13T04:22:35Z", "path": "sdks/java/io/snowflake/src/main/java/org/apache/beam/sdk/io/snowflake/xlang/Configuration.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.snowflake.xlang;", "originalCommit": "be8ce595829b2b86e0e66f7ce26efe3eeba23f72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQ3NjgwOA==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453476808", "bodyText": "It makes sense for me to keep it in separate package. If you insist on keeping it in org.apache.beam.sdk.io.snowflakepackage, i will remove crosslanguage package", "author": "purbanow", "createdAt": "2020-07-13T08:22:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNzE2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNzM5Ng==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453427396", "bodyText": "Probably call this SnowflakeReadRegistrar.", "author": "chamikaramj", "createdAt": "2020-07-13T04:23:57Z", "path": "sdks/java/io/snowflake/src/main/java/org/apache/beam/sdk/io/snowflake/xlang/ExternalRead.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.snowflake.xlang;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import java.nio.charset.Charset;\n+import java.util.Map;\n+import javax.sql.DataSource;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.ByteArrayCoder;\n+import org.apache.beam.sdk.expansion.ExternalTransformRegistrar;\n+import org.apache.beam.sdk.io.snowflake.SnowflakeIO;\n+import org.apache.beam.sdk.io.snowflake.credentials.SnowflakeCredentials;\n+import org.apache.beam.sdk.io.snowflake.credentials.SnowflakeCredentialsFactory;\n+import org.apache.beam.sdk.transforms.ExternalTransformBuilder;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+\n+/** Exposes {@link SnowflakeIO.Read} as an external transform for cross-language usage. */\n+@Experimental\n+@AutoService(ExternalTransformRegistrar.class)\n+public final class ExternalRead implements ExternalTransformRegistrar {", "originalCommit": "be8ce595829b2b86e0e66f7ce26efe3eeba23f72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQ3MjE2NQ==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453472165", "bodyText": "I changed name to SnowflakeReadRegistrar.", "author": "purbanow", "createdAt": "2020-07-13T08:02:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyNzM5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyODE5Ng==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453428196", "bodyText": "You have to either add snowflake jars to \"io:expansion-service\" or expose a new Snowflake shadow jar that this wrapper can use (for expansion and for staging for runtime). What will be the size diff of \"sdks:java:io:expansion-service:shadowJar\" after including Snowflake ? If that is large we should go for the second option since this jar is shared by a bunch of cross-language wrappers.", "author": "chamikaramj", "createdAt": "2020-07-13T04:27:48Z", "path": "sdks/python/apache_beam/io/external/snowflake.py", "diffHunk": "@@ -0,0 +1,144 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import typing\n+\n+from past.builtins import unicode\n+\n+import apache_beam as beam\n+from apache_beam.transforms.external import BeamJarExpansionService\n+from apache_beam.transforms.external import ExternalTransform\n+from apache_beam.transforms.external import NamedTupleBasedPayloadBuilder\n+\n+__all__ = ['ReadFromSnowflake']\n+\n+\n+def default_io_expansion_service():\n+  return BeamJarExpansionService('sdks:java:io:expansion-service:shadowJar')", "originalCommit": "be8ce595829b2b86e0e66f7ce26efe3eeba23f72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzUzMjU4Mg==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453532582", "bodyText": "After adding snowflake to \"io:expansion-service\", jar size increased from  52,4 MB to 117,4 MB, so I think we should go with the second option, can you give me some hints how to proceed with it?", "author": "purbanow", "createdAt": "2020-07-13T09:53:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyODE5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDIyOTAyNQ==", "url": "https://github.com/apache/beam/pull/12149#discussion_r460229025", "bodyText": "One solution might be to add a new expansion service jar just for Snowflake but I'm not sure if we want to keep adding expansion service jars for various IOs. On the other hand I don't think basically doubling the size of existing IO expansion service jar is acceptable since that will affect the staging/pipeline construction time for users of all Java external sources.\n@robertwb for thoughts here.", "author": "chamikaramj", "createdAt": "2020-07-24T18:48:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyODE5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTEzMjAxOQ==", "url": "https://github.com/apache/beam/pull/12149#discussion_r461132019", "bodyText": "Yes, I think going with a separate jar makes sense given its size.\nTo do this, create a rule for a fat jar in sdks/java/io/snowflake/build.gradle that depends on both sdks:java:expansion-service and sdks:java:io:snowflake. (I'm not an expert on how the java nature creates fat jars; perhaps the simplest would be to put this in a new package sdks/java/io/snowflake/expansion-service whose sole contents would be exactly the same as sdks/java/io/expansion-service/build.gradle except depend on snowflake rather than kafka and jdbc.", "author": "robertwb", "createdAt": "2020-07-27T19:54:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyODE5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTYwNTE1OQ==", "url": "https://github.com/apache/beam/pull/12149#discussion_r461605159", "bodyText": "Thanks @robertwb. I added it", "author": "purbanow", "createdAt": "2020-07-28T14:03:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyODE5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyODUwOQ==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453428509", "bodyText": "Have you tested this against portable Flink/Spark and or Dataflow. Please mention here the runners this have been tested for and supported. Also mention details about prerequisites for the user. See following for an example.\nhttps://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py#L18", "author": "chamikaramj", "createdAt": "2020-07-13T04:29:31Z", "path": "sdks/python/apache_beam/io/external/snowflake.py", "diffHunk": "@@ -0,0 +1,144 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import typing\n+\n+from past.builtins import unicode\n+\n+import apache_beam as beam\n+from apache_beam.transforms.external import BeamJarExpansionService\n+from apache_beam.transforms.external import ExternalTransform\n+from apache_beam.transforms.external import NamedTupleBasedPayloadBuilder\n+\n+__all__ = ['ReadFromSnowflake']\n+\n+\n+def default_io_expansion_service():\n+  return BeamJarExpansionService('sdks:java:io:expansion-service:shadowJar')\n+\n+\n+ReadFromSnowflakeSchema = typing.NamedTuple(\n+    'WriteToSnowflakeSchema',\n+    [\n+        ('server_name', unicode),\n+        ('schema', unicode),\n+        ('database', unicode),\n+        ('staging_bucket_name', unicode),\n+        ('storage_integration_name', unicode),\n+        ('username', typing.Optional[unicode]),\n+        ('password', typing.Optional[unicode]),\n+        ('private_key_path', typing.Optional[unicode]),\n+        ('private_key_passphrase', typing.Optional[unicode]),\n+        ('o_auth_token', typing.Optional[unicode]),\n+        ('table', typing.Optional[unicode]),\n+        ('query', typing.Optional[unicode]),\n+    ])\n+\n+\n+class ReadFromSnowflake(beam.PTransform):\n+  \"\"\"An external PTransform which reads from Snowflake.\"\"\"\n+\n+  URN = 'beam:external:java:snowflake:read:v1'\n+\n+  def __init__(\n+      self,\n+      server_name,\n+      schema,\n+      database,\n+      staging_bucket_name,\n+      storage_integration_name,\n+      csv_mapper,\n+      username=None,\n+      password=None,\n+      private_key_path=None,\n+      private_key_passphrase=None,\n+      o_auth_token=None,\n+      table=None,\n+      query=None,\n+      expansion_service=None):\n+    \"\"\"\n+    Initializes a read operation from Snowflake.\n+\n+    Required parameters:\n+    :param server_name: full Snowflake server name with the following format\n+        account.region.gcp.snowflakecomputing.com.\n+    :param schema: name of the Snowflake schema in the database to use.\n+    :param database: name of the Snowflake database to use.\n+    :param staging_bucket_name: name of the Google Cloud Storage bucket.\n+        Bucket will be used as a temporary location for storing CSV files.\n+        Those temporary directories will be named\n+        `sf_copy_csv_DATE_TIME_RANDOMSUFFIX`\n+        and they will be removed automatically once Read operation finishes.\n+    :param storage_integration_name: is the name of storage integration\n+        object created according to Snowflake documentation.\n+    :param csv_mapper: specifies a function which must translate\n+        user-defined object to array of strings.\n+        SnowflakeIO uses a COPY INTO <location> statement to\n+        move data from a Snowflake table to Google Cloud Storage as CSV files.\n+        These files are then downloaded via FileIO and processed line by line.\n+        Each line is split into an array of Strings using the OpenCSV\n+        The csv_mapper function job is to give the user the possibility to\n+        convert the array of Strings to a user-defined type,\n+        ie. GenericRecord for Avro or Parquet files, or custom objects.\n+            Example:\n+                ```\n+                    def csv_mapper(strings_array):\n+ \t\t                return User(strings_array[0], int(strings_array[1])))\n+                ```\n+    :param table or query: specifies a Snowflake table name or custom SQL query\n+    :param expansion_service: specifies URL of expansion service.\n+\n+    Authentication parameters:\n+    It's required to pass one of the following combinations of valid parameters:\n+    :param username and password: specifies username and password\n+        for username/password authentication method.\n+    :param private_key_path and private_key_passphrase:\n+        specifies a private key file and password\n+        for key/ pair authentication method.\n+    :param o_auth_token: specifies access token for OAuth authentication method.\n+    \"\"\"\n+\n+    self.params = ReadFromSnowflakeSchema(", "originalCommit": "be8ce595829b2b86e0e66f7ce26efe3eeba23f72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzUzMjgyMA==", "url": "https://github.com/apache/beam/pull/12149#discussion_r453532820", "bodyText": "I tested it against Flink.\nI added missing information.", "author": "purbanow", "createdAt": "2020-07-13T09:53:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyODUwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDI0MDgyOQ==", "url": "https://github.com/apache/beam/pull/12149#discussion_r460240829", "bodyText": "Can you try against Dataflow as well ? Instructions are here: https://github.com/apache/beam/tree/master/sdks/python/apache_beam/examples/kafkataxi\n(it's for Kafka but you should be able to adapt)", "author": "chamikaramj", "createdAt": "2020-07-24T19:14:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyODUwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTUyNTgyMw==", "url": "https://github.com/apache/beam/pull/12149#discussion_r461525823", "bodyText": "@chamikaramj, I tried to reproduce it for Snowflake but I'm not able to overcome the following error:\nNotImplementedError: Execution of [<ExternalTransform(PTransform) label=[ExternalTransform(beam:external:java:snowflake:read:v1)]>] not implemented in runner <apache_beam.runners.dataflow.dataflow_runner.DataflowRunner \nDo you have some idea how to solve this?", "author": "purbanow", "createdAt": "2020-07-28T12:01:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyODUwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzM0MjIxMw==", "url": "https://github.com/apache/beam/pull/12149#discussion_r463342213", "bodyText": "I added instructions for running Kafka against Dataflow for HEAD to here: https://github.com/apache/beam/blob/master/sdks/python/apache_beam/examples/kafkataxi/README.md\nFor example, you need to setup \"--experiments=use_runner_v2\" and \"--sdk_harness_container_image_overrides\". Feel free to try this out and update the pydoc above if successful.", "author": "chamikaramj", "createdAt": "2020-07-31T00:26:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyODUwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQ1MzQ0Ng==", "url": "https://github.com/apache/beam/pull/12149#discussion_r463453446", "bodyText": "@chamikaramj . I'm getting following error:\n  File \"/Users/urban/Desktop/beam/sdks/python/apache_beam/utils/urns.py\", line 186, in from_runner_api\n    parameter_type, constructor = cls._known_urns[fn_proto.urn]\nKeyError: 'beam:window_fn:serialized_java:v1'", "author": "purbanow", "createdAt": "2020-07-31T07:37:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyODUwOQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzcxMDE2NQ==", "url": "https://github.com/apache/beam/pull/12149#discussion_r463710165", "bodyText": "Thanks. This is potentially due to https://issues.apache.org/jira/browse/BEAM-10507.", "author": "chamikaramj", "createdAt": "2020-07-31T16:29:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzQyODUwOQ=="}], "type": "inlineReview"}, {"oid": "4caae3cf5cc3ecb8543caf013b2edfb68bac39d5", "url": "https://github.com/apache/beam/commit/4caae3cf5cc3ecb8543caf013b2edfb68bac39d5", "message": "refactor: revert auth mechanism and add missing docs", "committedDate": "2020-07-13T09:54:43Z", "type": "forcePushed"}, {"oid": "90c2f62fcdb6c6217a10b6fa208d9233278e5e26", "url": "https://github.com/apache/beam/commit/90c2f62fcdb6c6217a10b6fa208d9233278e5e26", "message": "refactor: revert auth mechanism and add missing docs", "committedDate": "2020-07-13T09:59:38Z", "type": "forcePushed"}, {"oid": "984fb159a651dbff00d1247aef30b14e5dad3fea", "url": "https://github.com/apache/beam/commit/984fb159a651dbff00d1247aef30b14e5dad3fea", "message": "refactor: revert auth mechanism and add missing docs", "committedDate": "2020-07-13T10:04:38Z", "type": "forcePushed"}, {"oid": "a680d37ec635d2142dd2bfefaf5c62b61a1b3d7d", "url": "https://github.com/apache/beam/commit/a680d37ec635d2142dd2bfefaf5c62b61a1b3d7d", "message": "refactor: revert auth mechanism and add missing docs", "committedDate": "2020-07-13T10:10:01Z", "type": "forcePushed"}, {"oid": "d80540dc993103b33b133afe8a2aa998aa9c7cdf", "url": "https://github.com/apache/beam/commit/d80540dc993103b33b133afe8a2aa998aa9c7cdf", "message": "refactor: revert auth mechanism and add missing docs", "committedDate": "2020-07-13T10:11:54Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzM0MTUwMw==", "url": "https://github.com/apache/beam/pull/12149#discussion_r463341503", "bodyText": "Pls drop \"This option is only available for Beam 2.22.0 and later\". This was just for Kafka.", "author": "chamikaramj", "createdAt": "2020-07-31T00:23:48Z", "path": "sdks/python/apache_beam/io/external/snowflake.py", "diffHunk": "@@ -0,0 +1,185 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import typing\n+\n+from past.builtins import unicode\n+\n+import apache_beam as beam\n+from apache_beam.transforms.external import BeamJarExpansionService\n+from apache_beam.transforms.external import ExternalTransform\n+from apache_beam.transforms.external import NamedTupleBasedPayloadBuilder\n+\n+\"\"\"Snowflake transforms tested against Flink portable runner.\n+  **Setup**\n+  Transforms provided in this module are cross-language transforms\n+  implemented in the Beam Java SDK. During the pipeline construction, Python SDK\n+  will connect to a Java expansion service to expand these transforms.\n+  To facilitate this, a small amount of setup is needed before using these\n+  transforms in a Beam Python pipeline.\n+  There are several ways to setup cross-language Snowflake transforms.\n+  * Option 1: use the default expansion service\n+  * Option 2: specify a custom expansion service\n+  See below for details regarding each of these options.\n+  *Option 1: Use the default expansion service*\n+  This is the recommended and easiest setup option for using Python Kafka\n+  transforms. This option is only available for Beam 2.22.0 and later.", "originalCommit": "9f42a997c017828f731db07ec40b33d7bceef139", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzQyNzUyNA==", "url": "https://github.com/apache/beam/pull/12149#discussion_r463427524", "bodyText": "Thanks, I fixed it.", "author": "purbanow", "createdAt": "2020-07-31T06:25:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzM0MTUwMw=="}], "type": "inlineReview"}, {"oid": "412a8b3feef3685a188d47bef67886066a0768fc", "url": "https://github.com/apache/beam/commit/412a8b3feef3685a188d47bef67886066a0768fc", "message": "feat: add custom expansion-service", "committedDate": "2020-07-31T08:47:53Z", "type": "forcePushed"}, {"oid": "888abcfff81852e1a6e8729ca8422b9e11597e2f", "url": "https://github.com/apache/beam/commit/888abcfff81852e1a6e8729ca8422b9e11597e2f", "message": "feat: add custom expansion-service", "committedDate": "2020-08-01T09:58:46Z", "type": "forcePushed"}, {"oid": "ff960e31d5bc78587730b5e9c5113dbecb34db32", "url": "https://github.com/apache/beam/commit/ff960e31d5bc78587730b5e9c5113dbecb34db32", "message": "feat: add custom expansion-service", "committedDate": "2020-08-01T12:41:02Z", "type": "forcePushed"}, {"oid": "37fe29336955c8df4c3faee88dc70ff18bc89135", "url": "https://github.com/apache/beam/commit/37fe29336955c8df4c3faee88dc70ff18bc89135", "message": "[BEAM-9897] improve credentials mechanism", "committedDate": "2020-08-04T16:11:39Z", "type": "commit"}, {"oid": "0ad69cb2617d91903cb3c475cfefede8ace4782d", "url": "https://github.com/apache/beam/commit/0ad69cb2617d91903cb3c475cfefede8ace4782d", "message": "[BEAM-9897] add xlang support for SnowflakeIO.read", "committedDate": "2020-08-04T16:11:39Z", "type": "commit"}, {"oid": "535a9054e7af371ae7925fab1325d9bb01c1ae37", "url": "https://github.com/apache/beam/commit/535a9054e7af371ae7925fab1325d9bb01c1ae37", "message": "fix: python lint", "committedDate": "2020-08-04T16:11:39Z", "type": "commit"}, {"oid": "f632a8a7a4447463180a8deda2f1d404b5865753", "url": "https://github.com/apache/beam/commit/f632a8a7a4447463180a8deda2f1d404b5865753", "message": "refactor: revert auth mechanism and add missing docs", "committedDate": "2020-08-04T16:11:39Z", "type": "commit"}, {"oid": "5867b3a2beefb865ba729d0145ea357b864f951a", "url": "https://github.com/apache/beam/commit/5867b3a2beefb865ba729d0145ea357b864f951a", "message": "feat: add custom expansion-service", "committedDate": "2020-08-04T16:11:40Z", "type": "commit"}, {"oid": "0ac450195554a20d489e143d91f689f8e7be1b2f", "url": "https://github.com/apache/beam/commit/0ac450195554a20d489e143d91f689f8e7be1b2f", "message": "fix: CI", "committedDate": "2020-08-04T16:11:40Z", "type": "forcePushed"}, {"oid": "b1a1c5f57f6de6f41f8e4f37de91e1c8bfd84781", "url": "https://github.com/apache/beam/commit/b1a1c5f57f6de6f41f8e4f37de91e1c8bfd84781", "message": "fix: CI", "committedDate": "2020-08-04T16:15:21Z", "type": "forcePushed"}, {"oid": "ac8b0ca7d017e4d4bb7c8dc5668ee88cba3a7991", "url": "https://github.com/apache/beam/commit/ac8b0ca7d017e4d4bb7c8dc5668ee88cba3a7991", "message": "fix: CI", "committedDate": "2020-08-04T18:44:16Z", "type": "forcePushed"}, {"oid": "951b54cbb2e22bd77aa78604dcbc78a758bfd5ca", "url": "https://github.com/apache/beam/commit/951b54cbb2e22bd77aa78604dcbc78a758bfd5ca", "message": "fix: CI", "committedDate": "2020-08-04T19:01:50Z", "type": "commit"}, {"oid": "951b54cbb2e22bd77aa78604dcbc78a758bfd5ca", "url": "https://github.com/apache/beam/commit/951b54cbb2e22bd77aa78604dcbc78a758bfd5ca", "message": "fix: CI", "committedDate": "2020-08-04T19:01:50Z", "type": "forcePushed"}]}