{"pr_number": 10497, "pr_title": "[BEAM-8335] Add the ReverseTestStream", "pr_createdAt": "2020-01-03T17:55:27Z", "pr_url": "https://github.com/apache/beam/pull/10497", "timeline": [{"oid": "11fcc4921e16b910b0d8c04d0aa8f2f1592ce4ed", "url": "https://github.com/apache/beam/commit/11fcc4921e16b910b0d8c04d0aa8f2f1592ce4ed", "message": "first impl of reverseteststream", "committedDate": "2020-01-09T23:19:32Z", "type": "forcePushed"}, {"oid": "ebeff38739232c9fed0a5a467bed0570e07a5c45", "url": "https://github.com/apache/beam/commit/ebeff38739232c9fed0a5a467bed0570e07a5c45", "message": "CHERRY PICK Move TestStream implementation to replacement transform\n\n* This also moves the DirectRunner's TestStream implementation to a\nreplacement transform. This is because the TestStream relies on getting\nthe output_tags from the PTransform.\n\nChange-Id: Ibd80b0d25cd8cc5ff5c28e127f7313638e6664da", "committedDate": "2020-02-20T00:00:43Z", "type": "forcePushed"}, {"oid": "fee866b3368dd739c48dfcf12d2fa6c0cac89f41", "url": "https://github.com/apache/beam/commit/fee866b3368dd739c48dfcf12d2fa6c0cac89f41", "message": "CHERRY PICK Move TestStream implementation to replacement transform\n\n* This also moves the DirectRunner's TestStream implementation to a\nreplacement transform. This is because the TestStream relies on getting\nthe output_tags from the PTransform.\n\nChange-Id: Ibd80b0d25cd8cc5ff5c28e127f7313638e6664da", "committedDate": "2020-02-20T01:32:35Z", "type": "forcePushed"}, {"oid": "118eb4a093eae3e8f86045c62192e7175bd8856a", "url": "https://github.com/apache/beam/commit/118eb4a093eae3e8f86045c62192e7175bd8856a", "message": "ReverseTestStream Implementation\n\nChange-Id: Ie59b9483f4a36796efa203f811610c7fa6cc318c", "committedDate": "2020-02-27T03:11:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk3OTA0NQ==", "url": "https://github.com/apache/beam/pull/10497#discussion_r385979045", "bodyText": "We may want to be careful with time skew on the processing time timer firings. If they skew consistently, the time we think it is in this transform may be very different from the time it actually is.", "author": "pabloem", "createdAt": "2020-02-29T00:22:34Z", "path": "sdks/python/apache_beam/testing/test_stream.py", "diffHunk": "@@ -314,3 +355,239 @@ def from_runner_api_parameter(ptransform, payload, context):\n         coder=coder,\n         events=[Event.from_runner_api(e, coder) for e in payload.events],\n         output_tags=output_tags)\n+\n+\n+class TimingInfo(object):\n+  def __init__(self, processing_time, watermark):\n+    self._processing_time = timestamp.Timestamp.of(processing_time)\n+    self._watermark = timestamp.Timestamp.of(watermark)\n+\n+  @property\n+  def processing_time(self):\n+    return self._processing_time\n+\n+  @property\n+  def watermark(self):\n+    return self._watermark\n+\n+  def __repr__(self):\n+    return '({}, {}, {})'.format(\n+        self.event_timestamp, self.processing_time, self.watermark)\n+\n+\n+class PairWithTiming(PTransform):\n+  \"\"\"Pairs the input element with timing information.\n+\n+  Input: element; output: KV(element, timing information)\n+  Where timing information := (processing time, watermark)\n+\n+  This is used in the ReverseTestStream implementation to replay watermark\n+  advancements.\n+  \"\"\"\n+\n+  URN = \"beam:transform:pair_with_timing:v1\"\n+\n+  def expand(self, pcoll):\n+    return pvalue.PCollection.from_(pcoll)\n+\n+\n+class ReverseTestStream(PTransform):\n+  \"\"\"A Transform that can create TestStream events from a stream of elements.\n+\n+  This currently assumes that this the pipeline being run on a single machine\n+  and elements come in order and are outputted in the same order that they came\n+  in.\n+  \"\"\"\n+  class Format(Enum):\n+    TEST_STREAM_EVENTS = 1\n+    TEST_STREAM_FILE_RECORDS = 2\n+    SERIALIZED_TEST_STREAM_FILE_RECORDS = 3\n+\n+  def __init__(\n+      self, sample_resolution_sec, output_tag, coder=None, output_format=None):\n+    self._sample_resolution_sec = sample_resolution_sec\n+    self._output_tag = output_tag\n+    self._output_format = output_format if output_format \\\n+                          else ReverseTestStream.Format.TEST_STREAM_EVENTS\n+    self._coder = coder if coder else beam.coders.FastPrimitivesCoder()\n+\n+  def expand(self, pcoll):\n+    generator = (\n+        _TestStreamFileRecordGenerator(coder=self._coder) if (\n+            self._output_format in (\n+                self.Format.TEST_STREAM_FILE_RECORDS,\n+                self.Format.SERIALIZED_TEST_STREAM_FILE_RECORDS)) else\n+        _TestStreamEventGenerator())\n+\n+    ret = (\n+        pcoll\n+        | beam.WindowInto(beam.window.GlobalWindows())\n+\n+        # First get the initial timing information. This will be used to start\n+        # the periodic timers which will generate processing time and watermark\n+        # advancements every `sample_resolution_sec`.\n+        | 'initial timing' >> PairWithTiming()\n+\n+        # Next, map every element to the same key so that only a single timer is\n+        # started for this given ReverseTestStream.\n+        | beam.Map(lambda x: (0, x))\n+\n+        # Next, pass-through each element which will be paired with its timing\n+        # info in the next step. Also, start the periodic timers. We use timers\n+        # in this situation to capture watermark advancements that occur when\n+        # there are no elements being produced upstream.\n+        | beam.ParDo(\n+            _WatermarkEventGenerator(\n+                output_tag=self._output_tag,\n+                sample_resolution_sec=self._sample_resolution_sec))\n+\n+        # Next, retrieve the timing information for watermark events that were\n+        # generated in the previous step. This is because elements generated\n+        # through the timers don't have their timing information yet.\n+        | 'timing info for watermarks' >> PairWithTiming()\n+\n+        # Format the events properly.\n+        | beam.ParDo(generator))\n+\n+    if self._output_format == self.Format.SERIALIZED_TEST_STREAM_FILE_RECORDS:\n+\n+      def serializer(e):\n+        return e.SerializeToString()\n+\n+      ret = ret | 'serializer' >> beam.Map(serializer)\n+\n+    return ret\n+\n+\n+class _WatermarkEventGenerator(beam.DoFn):\n+  # Used to return the initial timing information.\n+  EXECUTE_ONCE_STATE = beam.transforms.userstate.BagStateSpec(\n+      name='execute_once_state', coder=beam.coders.FastPrimitivesCoder())\n+  WATERMARK_TRACKER = TimerSpec('watermark_tracker', TimeDomain.REAL_TIME)\n+\n+  def __init__(self, output_tag, sample_resolution_sec=0.1):\n+    self._output_tag = output_tag\n+    self._sample_resolution_sec = sample_resolution_sec\n+\n+  @on_timer(WATERMARK_TRACKER)\n+  def on_watermark_tracker(\n+      self,\n+      timestamp=beam.DoFn.TimestampParam,\n+      window=beam.DoFn.WindowParam,\n+      watermark_tracker=beam.DoFn.TimerParam(WATERMARK_TRACKER)):\n+    next_sample_time = (timestamp.micros * 1e-6) + self._sample_resolution_sec\n+    watermark_tracker.set(next_sample_time)", "originalCommit": "118eb4a093eae3e8f86045c62192e7175bd8856a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjcyMzMxOA==", "url": "https://github.com/apache/beam/pull/10497#discussion_r386723318", "bodyText": "Added state in the _TestStreamFormatter to keep track of the delta.", "author": "rohdesamuel", "createdAt": "2020-03-02T23:58:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk3OTA0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4MDQyNQ==", "url": "https://github.com/apache/beam/pull/10497#discussion_r385980425", "bodyText": "Here we're using the SDK-inferred processing time, but we have access to the runner-provided actual processing time in timing info. Maybe it's worth using that (maybe it'll help us work around the timer skew issue from above)", "author": "pabloem", "createdAt": "2020-02-29T00:30:55Z", "path": "sdks/python/apache_beam/testing/test_stream.py", "diffHunk": "@@ -314,3 +355,239 @@ def from_runner_api_parameter(ptransform, payload, context):\n         coder=coder,\n         events=[Event.from_runner_api(e, coder) for e in payload.events],\n         output_tags=output_tags)\n+\n+\n+class TimingInfo(object):\n+  def __init__(self, processing_time, watermark):\n+    self._processing_time = timestamp.Timestamp.of(processing_time)\n+    self._watermark = timestamp.Timestamp.of(watermark)\n+\n+  @property\n+  def processing_time(self):\n+    return self._processing_time\n+\n+  @property\n+  def watermark(self):\n+    return self._watermark\n+\n+  def __repr__(self):\n+    return '({}, {}, {})'.format(\n+        self.event_timestamp, self.processing_time, self.watermark)\n+\n+\n+class PairWithTiming(PTransform):\n+  \"\"\"Pairs the input element with timing information.\n+\n+  Input: element; output: KV(element, timing information)\n+  Where timing information := (processing time, watermark)\n+\n+  This is used in the ReverseTestStream implementation to replay watermark\n+  advancements.\n+  \"\"\"\n+\n+  URN = \"beam:transform:pair_with_timing:v1\"\n+\n+  def expand(self, pcoll):\n+    return pvalue.PCollection.from_(pcoll)\n+\n+\n+class ReverseTestStream(PTransform):\n+  \"\"\"A Transform that can create TestStream events from a stream of elements.\n+\n+  This currently assumes that this the pipeline being run on a single machine\n+  and elements come in order and are outputted in the same order that they came\n+  in.\n+  \"\"\"\n+  class Format(Enum):\n+    TEST_STREAM_EVENTS = 1\n+    TEST_STREAM_FILE_RECORDS = 2\n+    SERIALIZED_TEST_STREAM_FILE_RECORDS = 3\n+\n+  def __init__(\n+      self, sample_resolution_sec, output_tag, coder=None, output_format=None):\n+    self._sample_resolution_sec = sample_resolution_sec\n+    self._output_tag = output_tag\n+    self._output_format = output_format if output_format \\\n+                          else ReverseTestStream.Format.TEST_STREAM_EVENTS\n+    self._coder = coder if coder else beam.coders.FastPrimitivesCoder()\n+\n+  def expand(self, pcoll):\n+    generator = (\n+        _TestStreamFileRecordGenerator(coder=self._coder) if (\n+            self._output_format in (\n+                self.Format.TEST_STREAM_FILE_RECORDS,\n+                self.Format.SERIALIZED_TEST_STREAM_FILE_RECORDS)) else\n+        _TestStreamEventGenerator())\n+\n+    ret = (\n+        pcoll\n+        | beam.WindowInto(beam.window.GlobalWindows())\n+\n+        # First get the initial timing information. This will be used to start\n+        # the periodic timers which will generate processing time and watermark\n+        # advancements every `sample_resolution_sec`.\n+        | 'initial timing' >> PairWithTiming()\n+\n+        # Next, map every element to the same key so that only a single timer is\n+        # started for this given ReverseTestStream.\n+        | beam.Map(lambda x: (0, x))\n+\n+        # Next, pass-through each element which will be paired with its timing\n+        # info in the next step. Also, start the periodic timers. We use timers\n+        # in this situation to capture watermark advancements that occur when\n+        # there are no elements being produced upstream.\n+        | beam.ParDo(\n+            _WatermarkEventGenerator(\n+                output_tag=self._output_tag,\n+                sample_resolution_sec=self._sample_resolution_sec))\n+\n+        # Next, retrieve the timing information for watermark events that were\n+        # generated in the previous step. This is because elements generated\n+        # through the timers don't have their timing information yet.\n+        | 'timing info for watermarks' >> PairWithTiming()\n+\n+        # Format the events properly.\n+        | beam.ParDo(generator))\n+\n+    if self._output_format == self.Format.SERIALIZED_TEST_STREAM_FILE_RECORDS:\n+\n+      def serializer(e):\n+        return e.SerializeToString()\n+\n+      ret = ret | 'serializer' >> beam.Map(serializer)\n+\n+    return ret\n+\n+\n+class _WatermarkEventGenerator(beam.DoFn):\n+  # Used to return the initial timing information.\n+  EXECUTE_ONCE_STATE = beam.transforms.userstate.BagStateSpec(\n+      name='execute_once_state', coder=beam.coders.FastPrimitivesCoder())\n+  WATERMARK_TRACKER = TimerSpec('watermark_tracker', TimeDomain.REAL_TIME)\n+\n+  def __init__(self, output_tag, sample_resolution_sec=0.1):\n+    self._output_tag = output_tag\n+    self._sample_resolution_sec = sample_resolution_sec\n+\n+  @on_timer(WATERMARK_TRACKER)\n+  def on_watermark_tracker(\n+      self,\n+      timestamp=beam.DoFn.TimestampParam,\n+      window=beam.DoFn.WindowParam,\n+      watermark_tracker=beam.DoFn.TimerParam(WATERMARK_TRACKER)):\n+    next_sample_time = (timestamp.micros * 1e-6) + self._sample_resolution_sec\n+    watermark_tracker.set(next_sample_time)\n+\n+    # Generate two events, the delta since the last sample and a place-holder\n+    # WatermarkEvent. This is a placeholder because we can't otherwise add the\n+    # watermark from the runner to the event.\n+    yield ProcessingTimeEvent(self._sample_resolution_sec)\n+    yield WatermarkEvent(MIN_TIMESTAMP)\n+\n+  def process(\n+      self,\n+      e,\n+      timestamp=beam.DoFn.TimestampParam,\n+      window=beam.DoFn.WindowParam,\n+      watermark_tracker=beam.DoFn.TimerParam(WATERMARK_TRACKER),\n+      execute_once_state=beam.DoFn.StateParam(EXECUTE_ONCE_STATE)):\n+\n+    _, (element, timing_info) = e\n+\n+    first_time = next(execute_once_state.read(), True)\n+    if first_time:\n+      # Generate the initial timing events.\n+      execute_once_state.add(False)\n+      now_sec = timing_info.processing_time.micros * 1e-6\n+      watermark_tracker.set(now_sec + self._sample_resolution_sec)\n+\n+      # Here we capture the initial time offset and initial watermark. This is\n+      # where we emit the TestStreamFileHeader.\n+      yield TestStreamFileHeader(tag=self._output_tag)\n+      yield ProcessingTimeEvent(\n+          Duration(micros=timing_info.processing_time.micros))\n+      yield WatermarkEvent(MIN_TIMESTAMP)\n+    yield element\n+\n+\n+class _TestStreamEventGenerator(beam.DoFn):\n+  def start_bundle(self):\n+    self.elements = []\n+    self.timing_events = []\n+\n+  def finish_bundle(self):\n+    if self.timing_events:\n+      yield WindowedValue(\n+          self.timing_events, timestamp=0, windows=[beam.window.GlobalWindow()])\n+\n+    if self.elements:\n+      yield WindowedValue([ElementEvent(self.elements)],\n+                          timestamp=0,\n+                          windows=[beam.window.GlobalWindow()])\n+\n+  def process(self, e, timestamp=beam.DoFn.TimestampParam):\n+    element, timing_info = e\n+    if isinstance(element, WatermarkEvent):\n+      element.new_watermark = timing_info.watermark.micros\n+      self.timing_events.append(element)\n+    elif isinstance(element, ProcessingTimeEvent):\n+      self.timing_events.append(element)", "originalCommit": "118eb4a093eae3e8f86045c62192e7175bd8856a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjcyMzM3MQ==", "url": "https://github.com/apache/beam/pull/10497#discussion_r386723371", "bodyText": "ack (see previous comment)", "author": "rohdesamuel", "createdAt": "2020-03-02T23:58:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4MDQyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4MDk5Mg==", "url": "https://github.com/apache/beam/pull/10497#discussion_r385980992", "bodyText": "We may want to deduplicate here if there multiple watermark events with the same watermark (and the same bundle)", "author": "pabloem", "createdAt": "2020-02-29T00:34:15Z", "path": "sdks/python/apache_beam/testing/test_stream.py", "diffHunk": "@@ -314,3 +355,239 @@ def from_runner_api_parameter(ptransform, payload, context):\n         coder=coder,\n         events=[Event.from_runner_api(e, coder) for e in payload.events],\n         output_tags=output_tags)\n+\n+\n+class TimingInfo(object):\n+  def __init__(self, processing_time, watermark):\n+    self._processing_time = timestamp.Timestamp.of(processing_time)\n+    self._watermark = timestamp.Timestamp.of(watermark)\n+\n+  @property\n+  def processing_time(self):\n+    return self._processing_time\n+\n+  @property\n+  def watermark(self):\n+    return self._watermark\n+\n+  def __repr__(self):\n+    return '({}, {}, {})'.format(\n+        self.event_timestamp, self.processing_time, self.watermark)\n+\n+\n+class PairWithTiming(PTransform):\n+  \"\"\"Pairs the input element with timing information.\n+\n+  Input: element; output: KV(element, timing information)\n+  Where timing information := (processing time, watermark)\n+\n+  This is used in the ReverseTestStream implementation to replay watermark\n+  advancements.\n+  \"\"\"\n+\n+  URN = \"beam:transform:pair_with_timing:v1\"\n+\n+  def expand(self, pcoll):\n+    return pvalue.PCollection.from_(pcoll)\n+\n+\n+class ReverseTestStream(PTransform):\n+  \"\"\"A Transform that can create TestStream events from a stream of elements.\n+\n+  This currently assumes that this the pipeline being run on a single machine\n+  and elements come in order and are outputted in the same order that they came\n+  in.\n+  \"\"\"\n+  class Format(Enum):\n+    TEST_STREAM_EVENTS = 1\n+    TEST_STREAM_FILE_RECORDS = 2\n+    SERIALIZED_TEST_STREAM_FILE_RECORDS = 3\n+\n+  def __init__(\n+      self, sample_resolution_sec, output_tag, coder=None, output_format=None):\n+    self._sample_resolution_sec = sample_resolution_sec\n+    self._output_tag = output_tag\n+    self._output_format = output_format if output_format \\\n+                          else ReverseTestStream.Format.TEST_STREAM_EVENTS\n+    self._coder = coder if coder else beam.coders.FastPrimitivesCoder()\n+\n+  def expand(self, pcoll):\n+    generator = (\n+        _TestStreamFileRecordGenerator(coder=self._coder) if (\n+            self._output_format in (\n+                self.Format.TEST_STREAM_FILE_RECORDS,\n+                self.Format.SERIALIZED_TEST_STREAM_FILE_RECORDS)) else\n+        _TestStreamEventGenerator())\n+\n+    ret = (\n+        pcoll\n+        | beam.WindowInto(beam.window.GlobalWindows())\n+\n+        # First get the initial timing information. This will be used to start\n+        # the periodic timers which will generate processing time and watermark\n+        # advancements every `sample_resolution_sec`.\n+        | 'initial timing' >> PairWithTiming()\n+\n+        # Next, map every element to the same key so that only a single timer is\n+        # started for this given ReverseTestStream.\n+        | beam.Map(lambda x: (0, x))\n+\n+        # Next, pass-through each element which will be paired with its timing\n+        # info in the next step. Also, start the periodic timers. We use timers\n+        # in this situation to capture watermark advancements that occur when\n+        # there are no elements being produced upstream.\n+        | beam.ParDo(\n+            _WatermarkEventGenerator(\n+                output_tag=self._output_tag,\n+                sample_resolution_sec=self._sample_resolution_sec))\n+\n+        # Next, retrieve the timing information for watermark events that were\n+        # generated in the previous step. This is because elements generated\n+        # through the timers don't have their timing information yet.\n+        | 'timing info for watermarks' >> PairWithTiming()\n+\n+        # Format the events properly.\n+        | beam.ParDo(generator))\n+\n+    if self._output_format == self.Format.SERIALIZED_TEST_STREAM_FILE_RECORDS:\n+\n+      def serializer(e):\n+        return e.SerializeToString()\n+\n+      ret = ret | 'serializer' >> beam.Map(serializer)\n+\n+    return ret\n+\n+\n+class _WatermarkEventGenerator(beam.DoFn):\n+  # Used to return the initial timing information.\n+  EXECUTE_ONCE_STATE = beam.transforms.userstate.BagStateSpec(\n+      name='execute_once_state', coder=beam.coders.FastPrimitivesCoder())\n+  WATERMARK_TRACKER = TimerSpec('watermark_tracker', TimeDomain.REAL_TIME)\n+\n+  def __init__(self, output_tag, sample_resolution_sec=0.1):\n+    self._output_tag = output_tag\n+    self._sample_resolution_sec = sample_resolution_sec\n+\n+  @on_timer(WATERMARK_TRACKER)\n+  def on_watermark_tracker(\n+      self,\n+      timestamp=beam.DoFn.TimestampParam,\n+      window=beam.DoFn.WindowParam,\n+      watermark_tracker=beam.DoFn.TimerParam(WATERMARK_TRACKER)):\n+    next_sample_time = (timestamp.micros * 1e-6) + self._sample_resolution_sec\n+    watermark_tracker.set(next_sample_time)\n+\n+    # Generate two events, the delta since the last sample and a place-holder\n+    # WatermarkEvent. This is a placeholder because we can't otherwise add the\n+    # watermark from the runner to the event.\n+    yield ProcessingTimeEvent(self._sample_resolution_sec)\n+    yield WatermarkEvent(MIN_TIMESTAMP)\n+\n+  def process(\n+      self,\n+      e,\n+      timestamp=beam.DoFn.TimestampParam,\n+      window=beam.DoFn.WindowParam,\n+      watermark_tracker=beam.DoFn.TimerParam(WATERMARK_TRACKER),\n+      execute_once_state=beam.DoFn.StateParam(EXECUTE_ONCE_STATE)):\n+\n+    _, (element, timing_info) = e\n+\n+    first_time = next(execute_once_state.read(), True)\n+    if first_time:\n+      # Generate the initial timing events.\n+      execute_once_state.add(False)\n+      now_sec = timing_info.processing_time.micros * 1e-6\n+      watermark_tracker.set(now_sec + self._sample_resolution_sec)\n+\n+      # Here we capture the initial time offset and initial watermark. This is\n+      # where we emit the TestStreamFileHeader.\n+      yield TestStreamFileHeader(tag=self._output_tag)\n+      yield ProcessingTimeEvent(\n+          Duration(micros=timing_info.processing_time.micros))\n+      yield WatermarkEvent(MIN_TIMESTAMP)\n+    yield element\n+\n+\n+class _TestStreamEventGenerator(beam.DoFn):\n+  def start_bundle(self):\n+    self.elements = []\n+    self.timing_events = []\n+\n+  def finish_bundle(self):\n+    if self.timing_events:\n+      yield WindowedValue(\n+          self.timing_events, timestamp=0, windows=[beam.window.GlobalWindow()])\n+\n+    if self.elements:\n+      yield WindowedValue([ElementEvent(self.elements)],\n+                          timestamp=0,\n+                          windows=[beam.window.GlobalWindow()])\n+\n+  def process(self, e, timestamp=beam.DoFn.TimestampParam):\n+    element, timing_info = e\n+    if isinstance(element, WatermarkEvent):\n+      element.new_watermark = timing_info.watermark.micros", "originalCommit": "118eb4a093eae3e8f86045c62192e7175bd8856a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY5MzE2Mg==", "url": "https://github.com/apache/beam/pull/10497#discussion_r386693162", "bodyText": "Done", "author": "rohdesamuel", "createdAt": "2020-03-02T22:36:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4MDk5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4MTEwNA==", "url": "https://github.com/apache/beam/pull/10497#discussion_r385981104", "bodyText": "We may also want to deduplicate processing time events with duplicated timestamps - we should think whether that makes sense", "author": "pabloem", "createdAt": "2020-02-29T00:35:08Z", "path": "sdks/python/apache_beam/testing/test_stream.py", "diffHunk": "@@ -314,3 +355,239 @@ def from_runner_api_parameter(ptransform, payload, context):\n         coder=coder,\n         events=[Event.from_runner_api(e, coder) for e in payload.events],\n         output_tags=output_tags)\n+\n+\n+class TimingInfo(object):\n+  def __init__(self, processing_time, watermark):\n+    self._processing_time = timestamp.Timestamp.of(processing_time)\n+    self._watermark = timestamp.Timestamp.of(watermark)\n+\n+  @property\n+  def processing_time(self):\n+    return self._processing_time\n+\n+  @property\n+  def watermark(self):\n+    return self._watermark\n+\n+  def __repr__(self):\n+    return '({}, {}, {})'.format(\n+        self.event_timestamp, self.processing_time, self.watermark)\n+\n+\n+class PairWithTiming(PTransform):\n+  \"\"\"Pairs the input element with timing information.\n+\n+  Input: element; output: KV(element, timing information)\n+  Where timing information := (processing time, watermark)\n+\n+  This is used in the ReverseTestStream implementation to replay watermark\n+  advancements.\n+  \"\"\"\n+\n+  URN = \"beam:transform:pair_with_timing:v1\"\n+\n+  def expand(self, pcoll):\n+    return pvalue.PCollection.from_(pcoll)\n+\n+\n+class ReverseTestStream(PTransform):\n+  \"\"\"A Transform that can create TestStream events from a stream of elements.\n+\n+  This currently assumes that this the pipeline being run on a single machine\n+  and elements come in order and are outputted in the same order that they came\n+  in.\n+  \"\"\"\n+  class Format(Enum):\n+    TEST_STREAM_EVENTS = 1\n+    TEST_STREAM_FILE_RECORDS = 2\n+    SERIALIZED_TEST_STREAM_FILE_RECORDS = 3\n+\n+  def __init__(\n+      self, sample_resolution_sec, output_tag, coder=None, output_format=None):\n+    self._sample_resolution_sec = sample_resolution_sec\n+    self._output_tag = output_tag\n+    self._output_format = output_format if output_format \\\n+                          else ReverseTestStream.Format.TEST_STREAM_EVENTS\n+    self._coder = coder if coder else beam.coders.FastPrimitivesCoder()\n+\n+  def expand(self, pcoll):\n+    generator = (\n+        _TestStreamFileRecordGenerator(coder=self._coder) if (\n+            self._output_format in (\n+                self.Format.TEST_STREAM_FILE_RECORDS,\n+                self.Format.SERIALIZED_TEST_STREAM_FILE_RECORDS)) else\n+        _TestStreamEventGenerator())\n+\n+    ret = (\n+        pcoll\n+        | beam.WindowInto(beam.window.GlobalWindows())\n+\n+        # First get the initial timing information. This will be used to start\n+        # the periodic timers which will generate processing time and watermark\n+        # advancements every `sample_resolution_sec`.\n+        | 'initial timing' >> PairWithTiming()\n+\n+        # Next, map every element to the same key so that only a single timer is\n+        # started for this given ReverseTestStream.\n+        | beam.Map(lambda x: (0, x))\n+\n+        # Next, pass-through each element which will be paired with its timing\n+        # info in the next step. Also, start the periodic timers. We use timers\n+        # in this situation to capture watermark advancements that occur when\n+        # there are no elements being produced upstream.\n+        | beam.ParDo(\n+            _WatermarkEventGenerator(\n+                output_tag=self._output_tag,\n+                sample_resolution_sec=self._sample_resolution_sec))\n+\n+        # Next, retrieve the timing information for watermark events that were\n+        # generated in the previous step. This is because elements generated\n+        # through the timers don't have their timing information yet.\n+        | 'timing info for watermarks' >> PairWithTiming()\n+\n+        # Format the events properly.\n+        | beam.ParDo(generator))\n+\n+    if self._output_format == self.Format.SERIALIZED_TEST_STREAM_FILE_RECORDS:\n+\n+      def serializer(e):\n+        return e.SerializeToString()\n+\n+      ret = ret | 'serializer' >> beam.Map(serializer)\n+\n+    return ret\n+\n+\n+class _WatermarkEventGenerator(beam.DoFn):\n+  # Used to return the initial timing information.\n+  EXECUTE_ONCE_STATE = beam.transforms.userstate.BagStateSpec(\n+      name='execute_once_state', coder=beam.coders.FastPrimitivesCoder())\n+  WATERMARK_TRACKER = TimerSpec('watermark_tracker', TimeDomain.REAL_TIME)\n+\n+  def __init__(self, output_tag, sample_resolution_sec=0.1):\n+    self._output_tag = output_tag\n+    self._sample_resolution_sec = sample_resolution_sec\n+\n+  @on_timer(WATERMARK_TRACKER)\n+  def on_watermark_tracker(\n+      self,\n+      timestamp=beam.DoFn.TimestampParam,\n+      window=beam.DoFn.WindowParam,\n+      watermark_tracker=beam.DoFn.TimerParam(WATERMARK_TRACKER)):\n+    next_sample_time = (timestamp.micros * 1e-6) + self._sample_resolution_sec\n+    watermark_tracker.set(next_sample_time)\n+\n+    # Generate two events, the delta since the last sample and a place-holder\n+    # WatermarkEvent. This is a placeholder because we can't otherwise add the\n+    # watermark from the runner to the event.\n+    yield ProcessingTimeEvent(self._sample_resolution_sec)\n+    yield WatermarkEvent(MIN_TIMESTAMP)\n+\n+  def process(\n+      self,\n+      e,\n+      timestamp=beam.DoFn.TimestampParam,\n+      window=beam.DoFn.WindowParam,\n+      watermark_tracker=beam.DoFn.TimerParam(WATERMARK_TRACKER),\n+      execute_once_state=beam.DoFn.StateParam(EXECUTE_ONCE_STATE)):\n+\n+    _, (element, timing_info) = e\n+\n+    first_time = next(execute_once_state.read(), True)\n+    if first_time:\n+      # Generate the initial timing events.\n+      execute_once_state.add(False)\n+      now_sec = timing_info.processing_time.micros * 1e-6\n+      watermark_tracker.set(now_sec + self._sample_resolution_sec)\n+\n+      # Here we capture the initial time offset and initial watermark. This is\n+      # where we emit the TestStreamFileHeader.\n+      yield TestStreamFileHeader(tag=self._output_tag)\n+      yield ProcessingTimeEvent(\n+          Duration(micros=timing_info.processing_time.micros))\n+      yield WatermarkEvent(MIN_TIMESTAMP)\n+    yield element\n+\n+\n+class _TestStreamEventGenerator(beam.DoFn):\n+  def start_bundle(self):\n+    self.elements = []\n+    self.timing_events = []\n+\n+  def finish_bundle(self):\n+    if self.timing_events:\n+      yield WindowedValue(\n+          self.timing_events, timestamp=0, windows=[beam.window.GlobalWindow()])\n+\n+    if self.elements:\n+      yield WindowedValue([ElementEvent(self.elements)],\n+                          timestamp=0,\n+                          windows=[beam.window.GlobalWindow()])\n+\n+  def process(self, e, timestamp=beam.DoFn.TimestampParam):\n+    element, timing_info = e\n+    if isinstance(element, WatermarkEvent):\n+      element.new_watermark = timing_info.watermark.micros\n+      self.timing_events.append(element)\n+    elif isinstance(element, ProcessingTimeEvent):", "originalCommit": "118eb4a093eae3e8f86045c62192e7175bd8856a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjcxMTA0Mw==", "url": "https://github.com/apache/beam/pull/10497#discussion_r386711043", "bodyText": "We probably don't have to do this because there is a potential of having multiple ProcessingTimeEvents in the same bundle.", "author": "rohdesamuel", "createdAt": "2020-03-02T23:21:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4MTEwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4MzI2NA==", "url": "https://github.com/apache/beam/pull/10497#discussion_r385983264", "bodyText": "For performance, it may be worth considering evaluating watermark and processing time once, rather than on every element.", "author": "pabloem", "createdAt": "2020-02-29T00:49:58Z", "path": "sdks/python/apache_beam/runners/direct/transform_evaluator.py", "diffHunk": "@@ -432,6 +439,45 @@ def finish_bundle(self):\n         self, self.bundles, [], None, {None: self._watermark})\n \n \n+class PairWithTimingEvaluator(_TransformEvaluator):\n+  \"\"\"TransformEvaluator for the PairWithTiming transform.\n+\n+  This transform takes an element as an input and outputs\n+  KV(element, `TimingInfo`). Where the `TimingInfo` contains both the\n+  processing time timestamp and watermark.\n+  \"\"\"\n+  def __init__(\n+      self,\n+      evaluation_context,\n+      applied_ptransform,\n+      input_committed_bundle,\n+      side_inputs):\n+    assert not side_inputs\n+    super(PairWithTimingEvaluator, self).__init__(\n+        evaluation_context,\n+        applied_ptransform,\n+        input_committed_bundle,\n+        side_inputs)\n+\n+  def start_bundle(self):\n+    main_output = list(self._outputs)[0]\n+    self.bundle = self._evaluation_context.create_bundle(main_output)\n+\n+  def process_element(self, element):\n+    watermark_manager = self._evaluation_context._watermark_manager\n+    watermarks = watermark_manager.get_watermarks(self._applied_ptransform)", "originalCommit": "118eb4a093eae3e8f86045c62192e7175bd8856a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY5NDM0Nw==", "url": "https://github.com/apache/beam/pull/10497#discussion_r386694347", "bodyText": "Done, moved to start_bundle", "author": "rohdesamuel", "createdAt": "2020-03-02T22:38:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4MzI2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4NDczNA==", "url": "https://github.com/apache/beam/pull/10497#discussion_r385984734", "bodyText": "Question:\nWhat happens if tv.value is a dict from the upstream pcollection?\nWe are supposing that it's a dict containing the window, pane info, value, and tstamp OR if we get a  typeerror, then it's not a dict, it's only the element itself - but what if the element itself is a dict?", "author": "pabloem", "createdAt": "2020-02-29T01:00:49Z", "path": "sdks/python/apache_beam/runners/direct/transform_evaluator.py", "diffHunk": "@@ -421,8 +424,12 @@ def process_element(self, element):\n       main_output = list(self._outputs)[0]\n       bundle = self._evaluation_context.create_bundle(main_output)\n       for tv in event.timestamped_values:\n-        bundle.output(\n-            GlobalWindows.windowed_value(tv.value, timestamp=tv.timestamp))\n+        # Unreify the value into the correct window.\n+        try:\n+          bundle.output(WindowedValue(**tv.value))\n+        except TypeError:\n+          bundle.output(\n+              GlobalWindows.windowed_value(tv.value, timestamp=tv.timestamp))", "originalCommit": "118eb4a093eae3e8f86045c62192e7175bd8856a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjY5NDkzNQ==", "url": "https://github.com/apache/beam/pull/10497#discussion_r386694935", "bodyText": "Added a test for this", "author": "rohdesamuel", "createdAt": "2020-03-02T22:40:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4NDczNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTk4NDgzNg==", "url": "https://github.com/apache/beam/pull/10497#discussion_r385984836", "bodyText": "TODO: @pabloem - Review this section of the code", "author": "pabloem", "createdAt": "2020-02-29T01:01:41Z", "path": "sdks/python/apache_beam/runners/direct/transform_evaluator.py", "diffHunk": "@@ -471,7 +517,14 @@ def process_element(self, element):\n     # We can either have the _TestStream or the _WatermarkController to emit\n     # the elements. We chose to emit in the _WatermarkController so that the\n     # element is emitted at the correct watermark value.\n-    for event in self.test_stream.events(self.current_index):\n+    events = []\n+    if self.watermark == MIN_TIMESTAMP:\n+      for event in self.test_stream._set_up(self.test_stream.output_tags):\n+        events.append(event)\n+\n+    events += [e for e in self.test_stream.events(self.current_index)]\n+\n+    for event in events:", "originalCommit": "118eb4a093eae3e8f86045c62192e7175bd8856a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjcxNDc3Nw==", "url": "https://github.com/apache/beam/pull/10497#discussion_r386714777", "bodyText": "I wonder if we intend this to only be called once - and if it's possible for it to be called more than once.\nIn our discussion, it seems that:\n\nIt is possible for this to be called more than once - right?\nIt may be okay for it to be called more htan once.\n\nLet's confirm which of those are true", "author": "pabloem", "createdAt": "2020-03-02T23:32:06Z", "path": "sdks/python/apache_beam/runners/direct/transform_evaluator.py", "diffHunk": "@@ -471,7 +517,14 @@ def process_element(self, element):\n     # We can either have the _TestStream or the _WatermarkController to emit\n     # the elements. We chose to emit in the _WatermarkController so that the\n     # element is emitted at the correct watermark value.\n-    for event in self.test_stream.events(self.current_index):\n+    events = []\n+    if self.watermark == MIN_TIMESTAMP:", "originalCommit": "118eb4a093eae3e8f86045c62192e7175bd8856a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjcyNjUxMA==", "url": "https://github.com/apache/beam/pull/10497#discussion_r386726510", "bodyText": "Yep, this can be called more than once, and I verified that it's okay for it to be called multiple times.", "author": "rohdesamuel", "createdAt": "2020-03-03T00:07:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjcxNDc3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjcyNjcyNg==", "url": "https://github.com/apache/beam/pull/10497#discussion_r386726726", "bodyText": "I added a comment that explains this loop and its idempotency.", "author": "rohdesamuel", "createdAt": "2020-03-03T00:08:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjcxNDc3Nw=="}], "type": "inlineReview"}, {"oid": "1d670c14e6ec793cf29b112635aedeb3e8c405d7", "url": "https://github.com/apache/beam/commit/1d670c14e6ec793cf29b112635aedeb3e8c405d7", "message": "ReverseTestStream Implementation\n\nChange-Id: Ie59b9483f4a36796efa203f811610c7fa6cc318c", "committedDate": "2020-03-02T23:57:39Z", "type": "forcePushed"}, {"oid": "35c58186c8c24c7b38bc14aa7ba0ac27425faa2b", "url": "https://github.com/apache/beam/commit/35c58186c8c24c7b38bc14aa7ba0ac27425faa2b", "message": "ReverseTestStream Implementation\n\nChange-Id: Ie59b9483f4a36796efa203f811610c7fa6cc318c", "committedDate": "2020-03-03T00:07:50Z", "type": "forcePushed"}, {"oid": "8c8e37fd4cdbd6f8aab2695347f8f42cd34295c1", "url": "https://github.com/apache/beam/commit/8c8e37fd4cdbd6f8aab2695347f8f42cd34295c1", "message": "ReverseTestStream Implementation\n\nChange-Id: Ie59b9483f4a36796efa203f811610c7fa6cc318c", "committedDate": "2020-03-03T21:33:47Z", "type": "forcePushed"}, {"oid": "773528b083315daec52d8f1ea310401e00327ca6", "url": "https://github.com/apache/beam/commit/773528b083315daec52d8f1ea310401e00327ca6", "message": "ReverseTestStream Implementation\n\nChange-Id: Ie59b9483f4a36796efa203f811610c7fa6cc318c", "committedDate": "2020-03-04T00:39:20Z", "type": "commit"}, {"oid": "773528b083315daec52d8f1ea310401e00327ca6", "url": "https://github.com/apache/beam/commit/773528b083315daec52d8f1ea310401e00327ca6", "message": "ReverseTestStream Implementation\n\nChange-Id: Ie59b9483f4a36796efa203f811610c7fa6cc318c", "committedDate": "2020-03-04T00:39:20Z", "type": "forcePushed"}]}