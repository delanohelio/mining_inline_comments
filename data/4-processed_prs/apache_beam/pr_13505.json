{"pr_number": 13505, "pr_title": "[BEAM-11425] Metrics extraction via Monitoring API", "pr_createdAt": "2020-12-08T16:58:52Z", "pr_url": "https://github.com/apache/beam/pull/13505", "timeline": [{"oid": "5bf2a3a50913184f306e99be227ce603876fda41", "url": "https://github.com/apache/beam/commit/5bf2a3a50913184f306e99be227ce603876fda41", "message": "[BEAM-11425] Move some methods from metricsx to metrics package", "committedDate": "2020-12-08T16:36:44Z", "type": "commit"}, {"oid": "c980c291fd5fa7cfe7e246e7f101757449b6ed5f", "url": "https://github.com/apache/beam/commit/c980c291fd5fa7cfe7e246e7f101757449b6ed5f", "message": "[BEAM-11425] Metrics extraction via Monitoring API", "committedDate": "2020-12-08T16:37:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAxNDU5Mg==", "url": "https://github.com/apache/beam/pull/13505#discussion_r539014592", "bodyText": "Note that an exported field on an unexported struct is still nominally inaccessible. Consider unexporting it, and having a JobID() method instead.", "author": "lostluck", "createdAt": "2020-12-09T05:23:56Z", "path": "sdks/go/pkg/beam/runners/dataflow/dataflowlib/execute.go", "diffHunk": "@@ -122,3 +135,21 @@ func PrintJob(ctx context.Context, job *df.Job) {\n \t}\n \tlog.Info(ctx, string(str))\n }\n+\n+type dataflowPipelineResult struct {\n+\tJobID   string", "originalCommit": "c980c291fd5fa7cfe7e246e7f101757449b6ed5f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTIzMTgyNQ==", "url": "https://github.com/apache/beam/pull/13505#discussion_r539231825", "bodyText": "Let's have a JobID() method. I think accessing a job ID might be useful in some cases.", "author": "kamilwu", "createdAt": "2020-12-09T11:34:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAxNDU5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTI0NjY4Nw==", "url": "https://github.com/apache/beam/pull/13505#discussion_r539246687", "bodyText": "I had to add the JobID() to the PipelineResult interface also. But I think it's fine, since most runners have some kind of a job ID.", "author": "kamilwu", "createdAt": "2020-12-09T11:58:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAxNDU5Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU3MTg1Mw==", "url": "https://github.com/apache/beam/pull/13505#discussion_r539571853", "bodyText": "SGTM for JobID. Remember that in Go it's not necessary to return the exact interface that's supported every time. If the dataflow results or the flink results need different method sets, they can export different methods, and just document what are available on a custom results interface, that can be type asserted to.", "author": "lostluck", "createdAt": "2020-12-09T19:07:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAxNDU5Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAxNzk0Mw==", "url": "https://github.com/apache/beam/pull/13505#discussion_r539017943", "bodyText": "If the goal here is to only provide either the tentative values OR the commited values, and not both, wouldn't\nif isTentative != tentative {\n  continue\n}\n\nbe simpler?", "author": "lostluck", "createdAt": "2020-12-09T05:33:17Z", "path": "sdks/go/pkg/beam/runners/dataflow/dataflowlib/metrics.go", "diffHunk": "@@ -0,0 +1,125 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+// Package dataflowlib translates a Beam pipeline model to the\n+// Dataflow API job model, for submission to Google Cloud Dataflow.\n+\n+package dataflowlib\n+\n+import (\n+\t\"encoding/json\"\n+\t\"fmt\"\n+\n+\t\"github.com/apache/beam/sdks/go/pkg/beam/core/metrics\"\n+\tdf \"google.golang.org/api/dataflow/v1b3\"\n+)\n+\n+// FromMetricUpdates extracts metrics from a slice of MetricUpdate objects and\n+// groups them into counters, distributions and gauges.\n+//\n+// Dataflow currently only reports Counter and Distribution metrics to Cloud\n+// Monitoring. Gauge metrics are not supported. The output metrics.Results will\n+// not contain any gauges.\n+func FromMetricUpdates(allMetrics []*df.MetricUpdate, job *df.Job) *metrics.Results {\n+\tac, ad := groupByType(allMetrics, job, true)\n+\tcc, cd := groupByType(allMetrics, job, false)\n+\n+\treturn metrics.NewResults(metrics.MergeCounters(ac, cc), metrics.MergeDistributions(ad, cd), make([]metrics.GaugeResult, 0))\n+}\n+\n+func groupByType(allMetrics []*df.MetricUpdate, job *df.Job, tentative bool) (\n+\tmap[metrics.StepKey]int64,\n+\tmap[metrics.StepKey]metrics.DistributionValue) {\n+\tcounters := make(map[metrics.StepKey]int64)\n+\tdistributions := make(map[metrics.StepKey]metrics.DistributionValue)\n+\n+\tfor _, metric := range allMetrics {\n+\t\tisTentative := metric.Name.Context[\"tentative\"] == \"true\"\n+\t\t// Returns true when variables differ (exclusive or)\n+\t\tif (isTentative || tentative) && (!isTentative || !tentative) {", "originalCommit": "c980c291fd5fa7cfe7e246e7f101757449b6ed5f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTI0ODQzNQ==", "url": "https://github.com/apache/beam/pull/13505#discussion_r539248435", "bodyText": "Right, I overcomplicated it. Thank you.", "author": "kamilwu", "createdAt": "2020-12-09T12:01:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAxNzk0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTU1NjcyNw==", "url": "https://github.com/apache/beam/pull/13505#discussion_r539556727", "bodyText": "No worries. I've been there myself.", "author": "lostluck", "createdAt": "2020-12-09T18:45:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAxNzk0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAyMDI2OA==", "url": "https://github.com/apache/beam/pull/13505#discussion_r539020268", "bodyText": "I love this implementation. That is all.", "author": "lostluck", "createdAt": "2020-12-09T05:39:34Z", "path": "sdks/go/pkg/beam/runners/dataflow/dataflowlib/metrics.go", "diffHunk": "@@ -0,0 +1,125 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+// Package dataflowlib translates a Beam pipeline model to the\n+// Dataflow API job model, for submission to Google Cloud Dataflow.\n+\n+package dataflowlib\n+\n+import (\n+\t\"encoding/json\"\n+\t\"fmt\"\n+\n+\t\"github.com/apache/beam/sdks/go/pkg/beam/core/metrics\"\n+\tdf \"google.golang.org/api/dataflow/v1b3\"\n+)\n+\n+// FromMetricUpdates extracts metrics from a slice of MetricUpdate objects and\n+// groups them into counters, distributions and gauges.\n+//\n+// Dataflow currently only reports Counter and Distribution metrics to Cloud\n+// Monitoring. Gauge metrics are not supported. The output metrics.Results will\n+// not contain any gauges.\n+func FromMetricUpdates(allMetrics []*df.MetricUpdate, job *df.Job) *metrics.Results {\n+\tac, ad := groupByType(allMetrics, job, true)\n+\tcc, cd := groupByType(allMetrics, job, false)\n+\n+\treturn metrics.NewResults(metrics.MergeCounters(ac, cc), metrics.MergeDistributions(ad, cd), make([]metrics.GaugeResult, 0))\n+}\n+\n+func groupByType(allMetrics []*df.MetricUpdate, job *df.Job, tentative bool) (\n+\tmap[metrics.StepKey]int64,\n+\tmap[metrics.StepKey]metrics.DistributionValue) {\n+\tcounters := make(map[metrics.StepKey]int64)\n+\tdistributions := make(map[metrics.StepKey]metrics.DistributionValue)\n+\n+\tfor _, metric := range allMetrics {\n+\t\tisTentative := metric.Name.Context[\"tentative\"] == \"true\"\n+\t\t// Returns true when variables differ (exclusive or)\n+\t\tif (isTentative || tentative) && (!isTentative || !tentative) {\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\tkey, err := extractKey(metric, job)\n+\t\tif err != nil {\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\tif metric.Scalar != nil {\n+\t\t\tv, err := extractCounterValue(metric.Scalar)\n+\t\t\tif err != nil {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tcounters[key] = v\n+\t\t} else if metric.Distribution != nil {\n+\t\t\tv, err := extractDistributionValue(metric.Distribution)\n+\t\t\tif err != nil {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tdistributions[key] = v\n+\t\t}\n+\t}\n+\treturn counters, distributions\n+}\n+\n+func extractKey(metric *df.MetricUpdate, job *df.Job) (metrics.StepKey, error) {\n+\tstepName, ok := metric.Name.Context[\"step\"]\n+\tif !ok {\n+\t\treturn metrics.StepKey{}, fmt.Errorf(\"could not find the internal step name\")\n+\t}\n+\tuserStepName := \"\"\n+\n+\tfor _, step := range job.Steps {\n+\t\tif step.Name == stepName {\n+\t\t\tproperties := make(map[string]string)\n+\t\t\tjson.Unmarshal(step.Properties, &properties)\n+\t\t\tuserStepName = properties[\"user_name\"]\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\tif userStepName == \"\" {\n+\t\treturn metrics.StepKey{}, fmt.Errorf(\"could not translate the internal step name %v\", stepName)\n+\t}\n+\n+\tnamespace := metric.Name.Context[\"namespace\"]\n+\tif namespace == \"\" {\n+\t\tnamespace = \"dataflow/v1b3\"\n+\t}\n+\n+\treturn metrics.StepKey{Step: userStepName, Name: metric.Name.Name, Namespace: namespace}, nil\n+}\n+\n+func extractCounterValue(obj interface{}) (int64, error) {\n+\tv, ok := obj.(float64)\n+\tif !ok {\n+\t\treturn -1, fmt.Errorf(\"expected float64, got data of type %T instead\", obj)\n+\t}\n+\treturn int64(v), nil\n+}\n+\n+func extractDistributionValue(obj interface{}) (metrics.DistributionValue, error) {\n+\tm := obj.(map[string]interface{})\n+\tpropertiesToVisit := []string{\"count\", \"sum\", \"min\", \"max\"}\n+\tvalues := make([]int64, 4)\n+\n+\tfor i, p := range propertiesToVisit {\n+\t\tv, ok := m[p].(float64)\n+\t\tif !ok {\n+\t\t\treturn metrics.DistributionValue{}, fmt.Errorf(\"expected float64, got data of type %T instead\", m[p])\n+\t\t}\n+\t\tvalues[i] = int64(v)\n+\t}\n+\treturn metrics.DistributionValue{Count: values[0], Sum: values[1], Min: values[2], Max: values[3]}, nil\n+}", "originalCommit": "c980c291fd5fa7cfe7e246e7f101757449b6ed5f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTIzODU2OQ==", "url": "https://github.com/apache/beam/pull/13505#discussion_r539238569", "bodyText": "Good to hear that!", "author": "kamilwu", "createdAt": "2020-12-09T11:45:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAyMDI2OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTAyMTYyNg==", "url": "https://github.com/apache/beam/pull/13505#discussion_r539021626", "bodyText": "Since we know we have a fixed 4 properties anyway,  consider just using an array [4]int64 instead of a slice. It works the same.", "author": "lostluck", "createdAt": "2020-12-09T05:41:39Z", "path": "sdks/go/pkg/beam/runners/dataflow/dataflowlib/metrics.go", "diffHunk": "@@ -0,0 +1,125 @@\n+// Licensed to the Apache Software Foundation (ASF) under one or more\n+// contributor license agreements.  See the NOTICE file distributed with\n+// this work for additional information regarding copyright ownership.\n+// The ASF licenses this file to You under the Apache License, Version 2.0\n+// (the \"License\"); you may not use this file except in compliance with\n+// the License.  You may obtain a copy of the License at\n+//\n+//    http://www.apache.org/licenses/LICENSE-2.0\n+//\n+// Unless required by applicable law or agreed to in writing, software\n+// distributed under the License is distributed on an \"AS IS\" BASIS,\n+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+// See the License for the specific language governing permissions and\n+// limitations under the License.\n+\n+// Package dataflowlib translates a Beam pipeline model to the\n+// Dataflow API job model, for submission to Google Cloud Dataflow.\n+\n+package dataflowlib\n+\n+import (\n+\t\"encoding/json\"\n+\t\"fmt\"\n+\n+\t\"github.com/apache/beam/sdks/go/pkg/beam/core/metrics\"\n+\tdf \"google.golang.org/api/dataflow/v1b3\"\n+)\n+\n+// FromMetricUpdates extracts metrics from a slice of MetricUpdate objects and\n+// groups them into counters, distributions and gauges.\n+//\n+// Dataflow currently only reports Counter and Distribution metrics to Cloud\n+// Monitoring. Gauge metrics are not supported. The output metrics.Results will\n+// not contain any gauges.\n+func FromMetricUpdates(allMetrics []*df.MetricUpdate, job *df.Job) *metrics.Results {\n+\tac, ad := groupByType(allMetrics, job, true)\n+\tcc, cd := groupByType(allMetrics, job, false)\n+\n+\treturn metrics.NewResults(metrics.MergeCounters(ac, cc), metrics.MergeDistributions(ad, cd), make([]metrics.GaugeResult, 0))\n+}\n+\n+func groupByType(allMetrics []*df.MetricUpdate, job *df.Job, tentative bool) (\n+\tmap[metrics.StepKey]int64,\n+\tmap[metrics.StepKey]metrics.DistributionValue) {\n+\tcounters := make(map[metrics.StepKey]int64)\n+\tdistributions := make(map[metrics.StepKey]metrics.DistributionValue)\n+\n+\tfor _, metric := range allMetrics {\n+\t\tisTentative := metric.Name.Context[\"tentative\"] == \"true\"\n+\t\t// Returns true when variables differ (exclusive or)\n+\t\tif (isTentative || tentative) && (!isTentative || !tentative) {\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\tkey, err := extractKey(metric, job)\n+\t\tif err != nil {\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\tif metric.Scalar != nil {\n+\t\t\tv, err := extractCounterValue(metric.Scalar)\n+\t\t\tif err != nil {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tcounters[key] = v\n+\t\t} else if metric.Distribution != nil {\n+\t\t\tv, err := extractDistributionValue(metric.Distribution)\n+\t\t\tif err != nil {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\t\t\tdistributions[key] = v\n+\t\t}\n+\t}\n+\treturn counters, distributions\n+}\n+\n+func extractKey(metric *df.MetricUpdate, job *df.Job) (metrics.StepKey, error) {\n+\tstepName, ok := metric.Name.Context[\"step\"]\n+\tif !ok {\n+\t\treturn metrics.StepKey{}, fmt.Errorf(\"could not find the internal step name\")\n+\t}\n+\tuserStepName := \"\"\n+\n+\tfor _, step := range job.Steps {\n+\t\tif step.Name == stepName {\n+\t\t\tproperties := make(map[string]string)\n+\t\t\tjson.Unmarshal(step.Properties, &properties)\n+\t\t\tuserStepName = properties[\"user_name\"]\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\tif userStepName == \"\" {\n+\t\treturn metrics.StepKey{}, fmt.Errorf(\"could not translate the internal step name %v\", stepName)\n+\t}\n+\n+\tnamespace := metric.Name.Context[\"namespace\"]\n+\tif namespace == \"\" {\n+\t\tnamespace = \"dataflow/v1b3\"\n+\t}\n+\n+\treturn metrics.StepKey{Step: userStepName, Name: metric.Name.Name, Namespace: namespace}, nil\n+}\n+\n+func extractCounterValue(obj interface{}) (int64, error) {\n+\tv, ok := obj.(float64)\n+\tif !ok {\n+\t\treturn -1, fmt.Errorf(\"expected float64, got data of type %T instead\", obj)\n+\t}\n+\treturn int64(v), nil\n+}\n+\n+func extractDistributionValue(obj interface{}) (metrics.DistributionValue, error) {\n+\tm := obj.(map[string]interface{})\n+\tpropertiesToVisit := []string{\"count\", \"sum\", \"min\", \"max\"}\n+\tvalues := make([]int64, 4)", "originalCommit": "c980c291fd5fa7cfe7e246e7f101757449b6ed5f", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "55b3858886eca56a4ec45037dc83047f0e138762", "url": "https://github.com/apache/beam/commit/55b3858886eca56a4ec45037dc83047f0e138762", "message": "fix: review changes", "committedDate": "2020-12-09T12:01:07Z", "type": "commit"}]}