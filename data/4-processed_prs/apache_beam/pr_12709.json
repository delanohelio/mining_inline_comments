{"pr_number": 12709, "pr_title": "[BEAM-8258] add more options and monitoring to nexmark launcher", "pr_createdAt": "2020-08-27T23:28:04Z", "pr_url": "https://github.com/apache/beam/pull/12709", "timeline": [{"oid": "83c38b9f2b38a298c8eccb91a818a5b903633cf3", "url": "https://github.com/apache/beam/commit/83c38b9f2b38a298c8eccb91a818a5b903633cf3", "message": "streamline launcher", "committedDate": "2020-08-27T23:22:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5MjI2Mg==", "url": "https://github.com/apache/beam/pull/12709#discussion_r481492262", "bodyText": "can we just import time", "author": "y1chi", "createdAt": "2020-09-01T23:44:57Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -67,18 +67,20 @@\n import logging\n import sys\n import uuid\n-\n-from google.cloud import pubsub\n+from time import sleep", "originalCommit": "fea6af21ac98b03b74453f4009222bf83028a92c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3NTQ1Ng==", "url": "https://github.com/apache/beam/pull/12709#discussion_r483275456", "bodyText": "yeah I think so.", "author": "leiyiz", "createdAt": "2020-09-03T21:57:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5MjI2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3NTcxOQ==", "url": "https://github.com/apache/beam/pull/12709#discussion_r483275719", "bodyText": "but what is the reason to import time instead of only needed methods here", "author": "leiyiz", "createdAt": "2020-09-03T21:57:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5MjI2Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI4OTUzNg==", "url": "https://github.com/apache/beam/pull/12709#discussion_r483289536", "bodyText": "since you wouldn't have to import each function you want to use from time module. It's not a big deal but I believe calling time.sleep() and time.time() will be concise enough.", "author": "y1chi", "createdAt": "2020-09-03T22:36:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5MjI2Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5NDAzNg==", "url": "https://github.com/apache/beam/pull/12709#discussion_r481494036", "bodyText": "can we raise exception instead?", "author": "y1chi", "createdAt": "2020-09-01T23:50:51Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -156,34 +191,32 @@ def parse_args(self):\n \n     # Usage with Dataflow requires a project to be supplied.\n     self.project = self.pipeline_options.view_as(GoogleCloudOptions).project\n-    if self.project is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --project is required')\n-      sys.exit(1)\n-\n-    # Pub/Sub is currently available for use only in streaming pipelines.\n     self.streaming = self.pipeline_options.view_as(StandardOptions).streaming\n-    if self.streaming is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --streaming is required')\n-      sys.exit(1)\n \n     # wait_until_finish ensures that the streaming job is canceled.\n     self.wait_until_finish_duration = (\n         self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-    if self.wait_until_finish_duration is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --wait_until_finish_duration is required')  # pylint: disable=line-too-long\n-      sys.exit(1)\n+    self.runner = self.pipeline_options.view_as(StandardOptions).runner\n+\n+    if self.streaming:\n+      if self.wait_until_finish_duration is None\\\n+          or self.project is None or self.runner != 'DataflowRunner':\n+        print('error: argument --wait_until_finish_duration\\n' +", "originalCommit": "fea6af21ac98b03b74453f4009222bf83028a92c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3OTE3Mg==", "url": "https://github.com/apache/beam/pull/12709#discussion_r483279172", "bodyText": "RuntimeError right? as it is an unexpected error", "author": "leiyiz", "createdAt": "2020-09-03T22:06:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5NDAzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI4ODg4NQ==", "url": "https://github.com/apache/beam/pull/12709#discussion_r483288885", "bodyText": "It could be ValueError since the argument combination is invalid.", "author": "y1chi", "createdAt": "2020-09-03T22:34:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5NDAzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzMwNzI5OA==", "url": "https://github.com/apache/beam/pull/12709#discussion_r483307298", "bodyText": "thanks", "author": "leiyiz", "createdAt": "2020-09-03T23:36:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5NDAzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5NDYxMQ==", "url": "https://github.com/apache/beam/pull/12709#discussion_r481494611", "bodyText": "why are we limiting this to dataflow runner? the benchmark should be made available to all runners", "author": "y1chi", "createdAt": "2020-09-01T23:53:00Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -156,34 +191,32 @@ def parse_args(self):\n \n     # Usage with Dataflow requires a project to be supplied.\n     self.project = self.pipeline_options.view_as(GoogleCloudOptions).project\n-    if self.project is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --project is required')\n-      sys.exit(1)\n-\n-    # Pub/Sub is currently available for use only in streaming pipelines.\n     self.streaming = self.pipeline_options.view_as(StandardOptions).streaming\n-    if self.streaming is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --streaming is required')\n-      sys.exit(1)\n \n     # wait_until_finish ensures that the streaming job is canceled.\n     self.wait_until_finish_duration = (\n         self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-    if self.wait_until_finish_duration is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --wait_until_finish_duration is required')  # pylint: disable=line-too-long\n-      sys.exit(1)\n+    self.runner = self.pipeline_options.view_as(StandardOptions).runner\n+\n+    if self.streaming:\n+      if self.wait_until_finish_duration is None\\\n+          or self.project is None or self.runner != 'DataflowRunner':", "originalCommit": "fea6af21ac98b03b74453f4009222bf83028a92c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI4ODM1MQ==", "url": "https://github.com/apache/beam/pull/12709#discussion_r483288351", "bodyText": "the ReadFromPubsub on DirectRunner does not support id_label argument that's all", "author": "leiyiz", "createdAt": "2020-09-03T22:32:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5NDYxMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI5Mjk5OQ==", "url": "https://github.com/apache/beam/pull/12709#discussion_r483292999", "bodyText": "we can also ignore id_label for now if that is the case, I believe id_label was useful for deduplication, but in the case of a benchmark it is arguably acceptable.", "author": "y1chi", "createdAt": "2020-09-03T22:47:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5NDYxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5NDc3Ng==", "url": "https://github.com/apache/beam/pull/12709#discussion_r481494776", "bodyText": "ditto", "author": "y1chi", "createdAt": "2020-09-01T23:53:38Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -156,34 +191,32 @@ def parse_args(self):\n \n     # Usage with Dataflow requires a project to be supplied.\n     self.project = self.pipeline_options.view_as(GoogleCloudOptions).project\n-    if self.project is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --project is required')\n-      sys.exit(1)\n-\n-    # Pub/Sub is currently available for use only in streaming pipelines.\n     self.streaming = self.pipeline_options.view_as(StandardOptions).streaming\n-    if self.streaming is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --streaming is required')\n-      sys.exit(1)\n \n     # wait_until_finish ensures that the streaming job is canceled.\n     self.wait_until_finish_duration = (\n         self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-    if self.wait_until_finish_duration is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --wait_until_finish_duration is required')  # pylint: disable=line-too-long\n-      sys.exit(1)\n+    self.runner = self.pipeline_options.view_as(StandardOptions).runner\n+\n+    if self.streaming:\n+      if self.wait_until_finish_duration is None\\\n+          or self.project is None or self.runner != 'DataflowRunner':\n+        print('error: argument --wait_until_finish_duration\\n' +\n+              '--project and --DataflowRunner required when running in streaming mode')  # pylint: disable=line-too-long\n+        sys.exit(1)\n+    else:\n+      if self.args.input is None:\n+        print('error: argument --input is required when running in batch mode')", "originalCommit": "fea6af21ac98b03b74453f4009222bf83028a92c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5Njc1OQ==", "url": "https://github.com/apache/beam/pull/12709#discussion_r481496759", "bodyText": "we should use google pydoc style.", "author": "y1chi", "createdAt": "2020-09-02T00:00:26Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_util.py", "diffHunk": "@@ -230,6 +230,15 @@ def millis_to_timestamp(millis):\n \n def get_counter_metric(result, namespace, name):\n   # type: (PipelineResult, str, str) -> int\n+\n+  \"\"\"\n+  get specific counter metric from pipeline result", "originalCommit": "fea6af21ac98b03b74453f4009222bf83028a92c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5OTQxMA==", "url": "https://github.com/apache/beam/pull/12709#discussion_r481499410", "bodyText": "class is probably not needed.", "author": "y1chi", "createdAt": "2020-09-02T00:09:24Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -200,46 +233,128 @@ def generate_events(self):\n \n     logging.info('Finished event generation.')\n \n+  def read_from_file(self):\n+    return (\n+        self.pipeline\n+        | 'reading_from_file' >> beam.io.ReadFromText(self.args.input)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn())\n+        | 'timestamping' >>\n+        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n+\n+  def read_from_pubsub(self):\n     # Read from PubSub into a PCollection.\n-    if self.args.subscription_name:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          subscription=sub.full_name)\n+    if self.subscription_name:\n+      raw_events = self.pipeline | 'ReadPubSub_sub' >> beam.io.ReadFromPubSub(\n+          subscription=self.subscription_name,\n+          with_attributes=True,\n+          id_label='id',\n+          timestamp_attribute='timestamp')\n     else:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          topic=topic.full_name)\n-    raw_events = (\n+      raw_events = self.pipeline | 'ReadPubSub_topic' >> beam.io.ReadFromPubSub(\n+          topic=self.topic_name,\n+          with_attributes=True,\n+          id_label='id',\n+          timestamp_attribute='timestamp')\n+    events = (\n         raw_events\n-        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEvnetFn())\n-        | 'timestamping' >>\n-        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n-    return raw_events\n+        | 'pubsub_unwrap' >> beam.Map(lambda m: m.data)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn()))\n+    return events\n \n   def run_query(self, query, query_args, query_errors):\n     try:\n-      self.parse_args()\n       self.pipeline = beam.Pipeline(options=self.pipeline_options)\n       nexmark_util.setup_coder()\n \n       event_monitor = Monitor('.events', 'event')\n       result_monitor = Monitor('.results', 'result')\n \n-      events = self.generate_events()\n+      if self.streaming:\n+        if self.pubsub_mode != 'SUBSCRIBE_ONLY':\n+          self.generate_events()\n+        if self.pubsub_mode == 'PUBLISH_ONLY':\n+          return\n+        events = self.read_from_pubsub()\n+      else:\n+        events = self.read_from_file()\n+\n       events = events | 'event_monitor' >> beam.ParDo(event_monitor.doFn)\n       output = query.load(events, query_args)\n       output | 'result_monitor' >> beam.ParDo(result_monitor.doFn)  # pylint: disable=expression-not-assigned\n \n       result = self.pipeline.run()\n-      job_duration = (\n-          self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-      if self.pipeline_options.view_as(StandardOptions).runner == 'DataflowRunner':  # pylint: disable=line-too-long\n-        result.wait_until_finish(duration=job_duration)\n-        result.cancel()\n+      if self.runner == 'DataflowRunner':\n+        result.wait_until_finish(duration=self.wait_until_finish_duration)\n       else:\n         result.wait_until_finish()\n+      perf = self.monitor(result, event_monitor, result_monitor)\n+      self.__class__.log_performance(perf)", "originalCommit": "fea6af21ac98b03b74453f4009222bf83028a92c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUwMzQ4NQ==", "url": "https://github.com/apache/beam/pull/12709#discussion_r481503485", "bodyText": "typo acticity -> activity", "author": "y1chi", "createdAt": "2020-09-02T00:23:13Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -200,46 +233,128 @@ def generate_events(self):\n \n     logging.info('Finished event generation.')\n \n+  def read_from_file(self):\n+    return (\n+        self.pipeline\n+        | 'reading_from_file' >> beam.io.ReadFromText(self.args.input)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn())\n+        | 'timestamping' >>\n+        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n+\n+  def read_from_pubsub(self):\n     # Read from PubSub into a PCollection.\n-    if self.args.subscription_name:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          subscription=sub.full_name)\n+    if self.subscription_name:\n+      raw_events = self.pipeline | 'ReadPubSub_sub' >> beam.io.ReadFromPubSub(\n+          subscription=self.subscription_name,\n+          with_attributes=True,\n+          id_label='id',\n+          timestamp_attribute='timestamp')\n     else:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          topic=topic.full_name)\n-    raw_events = (\n+      raw_events = self.pipeline | 'ReadPubSub_topic' >> beam.io.ReadFromPubSub(\n+          topic=self.topic_name,\n+          with_attributes=True,\n+          id_label='id',\n+          timestamp_attribute='timestamp')\n+    events = (\n         raw_events\n-        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEvnetFn())\n-        | 'timestamping' >>\n-        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n-    return raw_events\n+        | 'pubsub_unwrap' >> beam.Map(lambda m: m.data)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn()))\n+    return events\n \n   def run_query(self, query, query_args, query_errors):\n     try:\n-      self.parse_args()\n       self.pipeline = beam.Pipeline(options=self.pipeline_options)\n       nexmark_util.setup_coder()\n \n       event_monitor = Monitor('.events', 'event')\n       result_monitor = Monitor('.results', 'result')\n \n-      events = self.generate_events()\n+      if self.streaming:\n+        if self.pubsub_mode != 'SUBSCRIBE_ONLY':\n+          self.generate_events()\n+        if self.pubsub_mode == 'PUBLISH_ONLY':\n+          return\n+        events = self.read_from_pubsub()\n+      else:\n+        events = self.read_from_file()\n+\n       events = events | 'event_monitor' >> beam.ParDo(event_monitor.doFn)\n       output = query.load(events, query_args)\n       output | 'result_monitor' >> beam.ParDo(result_monitor.doFn)  # pylint: disable=expression-not-assigned\n \n       result = self.pipeline.run()\n-      job_duration = (\n-          self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-      if self.pipeline_options.view_as(StandardOptions).runner == 'DataflowRunner':  # pylint: disable=line-too-long\n-        result.wait_until_finish(duration=job_duration)\n-        result.cancel()\n+      if self.runner == 'DataflowRunner':\n+        result.wait_until_finish(duration=self.wait_until_finish_duration)\n       else:\n         result.wait_until_finish()\n+      perf = self.monitor(result, event_monitor, result_monitor)\n+      self.__class__.log_performance(perf)\n+\n     except Exception as exc:\n       query_errors.append(str(exc))\n       raise\n \n+  def monitor(self, job, event_monitor, result_monitor):\n+    last_active_ms = -1\n+    perf = None\n+    cancel_job = False\n+    waiting_for_shutdown = False\n+\n+    while True:\n+      now = int(time() * 1000)  # current time in ms\n+      logging.debug('now is %d', now)\n+\n+      curr_perf = NexmarkLauncher.get_performance(\n+          job, event_monitor, result_monitor)\n+      if perf is None or curr_perf.is_active(perf):\n+        last_active_ms = now\n+      if self.streaming and not waiting_for_shutdown:\n+        quiet_duration = (now - last_active_ms) // 1000\n+        if curr_perf.event_count >= self.args.num_events and\\\n+           curr_perf.result_count >= 0 and quiet_duration > self.DONE_DELAY:\n+          logging.info('streaming query appears to have finished executing')\n+          waiting_for_shutdown = True\n+          cancel_job = True\n+        elif quiet_duration > self.TERMINATE_DELAY:\n+          logging.error(\n+              'streaming query have been stuck for %d seconds', quiet_duration)\n+          logging.error('canceling streaming job')\n+          waiting_for_shutdown = True\n+          cancel_job = True\n+        elif quiet_duration > self.WARNING_DELAY:\n+          logging.warning(\n+              'streaming query have been stuck for %d seconds', quiet_duration)\n+\n+        if cancel_job:\n+          job.cancel()\n+\n+      stopped = PipelineState.is_terminal(job.state)\n+      if stopped:\n+        break\n+\n+      perf = curr_perf\n+      if not waiting_for_shutdown:\n+        if last_active_ms == now:\n+          logging.info('acticity seen, new performance data extracted')", "originalCommit": "fea6af21ac98b03b74453f4009222bf83028a92c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUwNTU2NA==", "url": "https://github.com/apache/beam/pull/12709#discussion_r481505564", "bodyText": "if we are proactively terminating the job, wait_until_finish_duration is not needed then.", "author": "y1chi", "createdAt": "2020-09-02T00:30:40Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -200,46 +233,128 @@ def generate_events(self):\n \n     logging.info('Finished event generation.')\n \n+  def read_from_file(self):\n+    return (\n+        self.pipeline\n+        | 'reading_from_file' >> beam.io.ReadFromText(self.args.input)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn())\n+        | 'timestamping' >>\n+        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n+\n+  def read_from_pubsub(self):\n     # Read from PubSub into a PCollection.\n-    if self.args.subscription_name:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          subscription=sub.full_name)\n+    if self.subscription_name:\n+      raw_events = self.pipeline | 'ReadPubSub_sub' >> beam.io.ReadFromPubSub(\n+          subscription=self.subscription_name,\n+          with_attributes=True,\n+          id_label='id',\n+          timestamp_attribute='timestamp')\n     else:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          topic=topic.full_name)\n-    raw_events = (\n+      raw_events = self.pipeline | 'ReadPubSub_topic' >> beam.io.ReadFromPubSub(\n+          topic=self.topic_name,\n+          with_attributes=True,\n+          id_label='id',\n+          timestamp_attribute='timestamp')\n+    events = (\n         raw_events\n-        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEvnetFn())\n-        | 'timestamping' >>\n-        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n-    return raw_events\n+        | 'pubsub_unwrap' >> beam.Map(lambda m: m.data)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn()))\n+    return events\n \n   def run_query(self, query, query_args, query_errors):\n     try:\n-      self.parse_args()\n       self.pipeline = beam.Pipeline(options=self.pipeline_options)\n       nexmark_util.setup_coder()\n \n       event_monitor = Monitor('.events', 'event')\n       result_monitor = Monitor('.results', 'result')\n \n-      events = self.generate_events()\n+      if self.streaming:\n+        if self.pubsub_mode != 'SUBSCRIBE_ONLY':\n+          self.generate_events()\n+        if self.pubsub_mode == 'PUBLISH_ONLY':\n+          return\n+        events = self.read_from_pubsub()\n+      else:\n+        events = self.read_from_file()\n+\n       events = events | 'event_monitor' >> beam.ParDo(event_monitor.doFn)\n       output = query.load(events, query_args)\n       output | 'result_monitor' >> beam.ParDo(result_monitor.doFn)  # pylint: disable=expression-not-assigned\n \n       result = self.pipeline.run()\n-      job_duration = (\n-          self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-      if self.pipeline_options.view_as(StandardOptions).runner == 'DataflowRunner':  # pylint: disable=line-too-long\n-        result.wait_until_finish(duration=job_duration)\n-        result.cancel()\n+      if self.runner == 'DataflowRunner':\n+        result.wait_until_finish(duration=self.wait_until_finish_duration)", "originalCommit": "fea6af21ac98b03b74453f4009222bf83028a92c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3NDYxMQ==", "url": "https://github.com/apache/beam/pull/12709#discussion_r483274611", "bodyText": "Don't we need to wait for a little bit for the python pipeline to spin up?", "author": "leiyiz", "createdAt": "2020-09-03T21:54:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUwNTU2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI4ODQxOQ==", "url": "https://github.com/apache/beam/pull/12709#discussion_r483288419", "bodyText": "wait_until_finish duration is overall timeout, we don't need to wait for python pipeline to spin up, and I don't think wait_until_finish was meant for that.", "author": "y1chi", "createdAt": "2020-09-03T22:32:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUwNTU2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUwODQ5Nw==", "url": "https://github.com/apache/beam/pull/12709#discussion_r481508497", "bodyText": "you can add these fields to NexmarkPerf init as kwarg.", "author": "y1chi", "createdAt": "2020-09-02T00:42:14Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -263,24 +378,27 @@ def get_performance(result, event_monitor, result_monitor):\n         result_monitor.namespace,\n         result_monitor.name_prefix + MonitorSuffix.EVENT_TIME)\n \n+    perf = NexmarkPerf()\n+    perf.event_count = event_count", "originalCommit": "fea6af21ac98b03b74453f4009222bf83028a92c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUwOTAxNA==", "url": "https://github.com/apache/beam/pull/12709#discussion_r481509014", "bodyText": "nit: lets s/other/previous_perf/, s/is_active/has_progress/, I think this will make it more understandable.", "author": "y1chi", "createdAt": "2020-09-02T00:44:20Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_perf.py", "diffHunk": "@@ -0,0 +1,42 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+performance summary for a run of nexmark query\n+\"\"\"\n+\n+\n+class NexmarkPerf(object):\n+  def __init__(self):\n+    self.runtime_sec = -1.0\n+    self.event_count = -1\n+    self.event_per_sec = -1.0\n+    self.result_count = -1\n+\n+  def is_active(self, other):", "originalCommit": "fea6af21ac98b03b74453f4009222bf83028a92c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI3Mzk2Mg==", "url": "https://github.com/apache/beam/pull/12709#discussion_r483273962", "bodyText": "what does it mean? sorry i don't quite get it", "author": "leiyiz", "createdAt": "2020-09-03T21:53:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUwOTAxNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI4Njc2MQ==", "url": "https://github.com/apache/beam/pull/12709#discussion_r483286761", "bodyText": "sorry for any confusion, I meant replace other with previous_perf and replace is_active with has_progress", "author": "y1chi", "createdAt": "2020-09-03T22:27:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUwOTAxNA=="}], "type": "inlineReview"}, {"oid": "d3bb694d2a87c6764228ce70173cb1251796ce69", "url": "https://github.com/apache/beam/commit/d3bb694d2a87c6764228ce70173cb1251796ce69", "message": "job monitoring and auto cancelling", "committedDate": "2020-09-03T19:41:42Z", "type": "commit"}, {"oid": "1c0d677a84c0d6502a383485a6eaa1de0ca25113", "url": "https://github.com/apache/beam/commit/1c0d677a84c0d6502a383485a6eaa1de0ca25113", "message": "resolve issues in review", "committedDate": "2020-09-04T01:16:54Z", "type": "commit"}, {"oid": "b5eb0cb9868fff1f6db0a33f378b59e40f8f4274", "url": "https://github.com/apache/beam/commit/b5eb0cb9868fff1f6db0a33f378b59e40f8f4274", "message": "removed wait_until_finish_duration argument requirement", "committedDate": "2020-09-04T01:24:50Z", "type": "commit"}, {"oid": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d", "url": "https://github.com/apache/beam/commit/1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d", "message": "remove unused import", "committedDate": "2020-09-04T01:33:43Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkyODY5OQ==", "url": "https://github.com/apache/beam/pull/12709#discussion_r484928699", "bodyText": "Do you need to timestamp as well?", "author": "pabloem", "createdAt": "2020-09-08T13:40:17Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -200,46 +223,126 @@ def generate_events(self):\n \n     logging.info('Finished event generation.')\n \n+  def read_from_file(self):\n+    return (\n+        self.pipeline\n+        | 'reading_from_file' >> beam.io.ReadFromText(self.args.input)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn())\n+        | 'timestamping' >>\n+        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n+\n+  def read_from_pubsub(self):\n     # Read from PubSub into a PCollection.\n-    if self.args.subscription_name:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          subscription=sub.full_name)\n+    if self.subscription_name:\n+      raw_events = self.pipeline | 'ReadPubSub_sub' >> beam.io.ReadFromPubSub(\n+          subscription=self.subscription_name,\n+          with_attributes=True,\n+          timestamp_attribute='timestamp')\n     else:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          topic=topic.full_name)\n-    raw_events = (\n+      raw_events = self.pipeline | 'ReadPubSub_topic' >> beam.io.ReadFromPubSub(\n+          topic=self.topic_name,\n+          with_attributes=True,\n+          timestamp_attribute='timestamp')\n+    events = (\n         raw_events\n-        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEvnetFn())\n-        | 'timestamping' >>\n-        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n-    return raw_events\n+        | 'pubsub_unwrap' >> beam.Map(lambda m: m.data)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn()))", "originalCommit": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEyNTAyMw==", "url": "https://github.com/apache/beam/pull/12709#discussion_r485125023", "bodyText": "no because when we read from the pubsub we have timestamp read from attribute", "author": "leiyiz", "createdAt": "2020-09-08T18:45:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkyODY5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkzMDUzNA==", "url": "https://github.com/apache/beam/pull/12709#discussion_r484930534", "bodyText": "We don't usually rely on \\ to add newlines. We use parentheses (e.g. if (curr_perf.event_count >=.... \\n\\t something something):", "author": "pabloem", "createdAt": "2020-09-08T13:42:54Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -200,46 +223,126 @@ def generate_events(self):\n \n     logging.info('Finished event generation.')\n \n+  def read_from_file(self):\n+    return (\n+        self.pipeline\n+        | 'reading_from_file' >> beam.io.ReadFromText(self.args.input)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn())\n+        | 'timestamping' >>\n+        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n+\n+  def read_from_pubsub(self):\n     # Read from PubSub into a PCollection.\n-    if self.args.subscription_name:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          subscription=sub.full_name)\n+    if self.subscription_name:\n+      raw_events = self.pipeline | 'ReadPubSub_sub' >> beam.io.ReadFromPubSub(\n+          subscription=self.subscription_name,\n+          with_attributes=True,\n+          timestamp_attribute='timestamp')\n     else:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          topic=topic.full_name)\n-    raw_events = (\n+      raw_events = self.pipeline | 'ReadPubSub_topic' >> beam.io.ReadFromPubSub(\n+          topic=self.topic_name,\n+          with_attributes=True,\n+          timestamp_attribute='timestamp')\n+    events = (\n         raw_events\n-        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEvnetFn())\n-        | 'timestamping' >>\n-        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n-    return raw_events\n+        | 'pubsub_unwrap' >> beam.Map(lambda m: m.data)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn()))\n+    return events\n \n   def run_query(self, query, query_args, query_errors):\n     try:\n-      self.parse_args()\n       self.pipeline = beam.Pipeline(options=self.pipeline_options)\n       nexmark_util.setup_coder()\n \n       event_monitor = Monitor('.events', 'event')\n       result_monitor = Monitor('.results', 'result')\n \n-      events = self.generate_events()\n+      if self.streaming:\n+        if self.pubsub_mode != 'SUBSCRIBE_ONLY':\n+          self.generate_events()\n+        if self.pubsub_mode == 'PUBLISH_ONLY':\n+          return\n+        events = self.read_from_pubsub()\n+      else:\n+        events = self.read_from_file()\n+\n       events = events | 'event_monitor' >> beam.ParDo(event_monitor.doFn)\n       output = query.load(events, query_args)\n       output | 'result_monitor' >> beam.ParDo(result_monitor.doFn)  # pylint: disable=expression-not-assigned\n \n       result = self.pipeline.run()\n-      job_duration = (\n-          self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-      if self.pipeline_options.view_as(StandardOptions).runner == 'DataflowRunner':  # pylint: disable=line-too-long\n-        result.wait_until_finish(duration=job_duration)\n-        result.cancel()\n-      else:\n+      if not self.streaming:\n         result.wait_until_finish()\n+      perf = self.monitor(result, event_monitor, result_monitor)\n+      self.log_performance(perf)\n+\n     except Exception as exc:\n       query_errors.append(str(exc))\n       raise\n \n+  def monitor(self, job, event_monitor, result_monitor):\n+    logging.info('starting to monitor the job')\n+    last_active_ms = -1\n+    perf = None\n+    cancel_job = False\n+    waiting_for_shutdown = False\n+\n+    while True:\n+      now = int(time.time() * 1000)  # current time in ms\n+      logging.debug('now is %d', now)\n+\n+      curr_perf = NexmarkLauncher.get_performance(\n+          job, event_monitor, result_monitor)\n+      if perf is None or curr_perf.has_progress(perf):\n+        last_active_ms = now\n+      if self.streaming and not waiting_for_shutdown:\n+        quiet_duration = (now - last_active_ms) // 1000\n+        if curr_perf.event_count >= self.args.num_events and\\", "originalCommit": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkzMjY5MQ==", "url": "https://github.com/apache/beam/pull/12709#discussion_r484932691", "bodyText": "@leiyiz the logic in this method is a little difficult to follow (the spurious codecov annotations don't help either) - do you think you could add a pydoc at the top roughly describing what the method does?", "author": "pabloem", "createdAt": "2020-09-08T13:45:47Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -200,46 +223,126 @@ def generate_events(self):\n \n     logging.info('Finished event generation.')\n \n+  def read_from_file(self):\n+    return (\n+        self.pipeline\n+        | 'reading_from_file' >> beam.io.ReadFromText(self.args.input)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn())\n+        | 'timestamping' >>\n+        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n+\n+  def read_from_pubsub(self):\n     # Read from PubSub into a PCollection.\n-    if self.args.subscription_name:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          subscription=sub.full_name)\n+    if self.subscription_name:\n+      raw_events = self.pipeline | 'ReadPubSub_sub' >> beam.io.ReadFromPubSub(\n+          subscription=self.subscription_name,\n+          with_attributes=True,\n+          timestamp_attribute='timestamp')\n     else:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          topic=topic.full_name)\n-    raw_events = (\n+      raw_events = self.pipeline | 'ReadPubSub_topic' >> beam.io.ReadFromPubSub(\n+          topic=self.topic_name,\n+          with_attributes=True,\n+          timestamp_attribute='timestamp')\n+    events = (\n         raw_events\n-        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEvnetFn())\n-        | 'timestamping' >>\n-        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n-    return raw_events\n+        | 'pubsub_unwrap' >> beam.Map(lambda m: m.data)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn()))\n+    return events\n \n   def run_query(self, query, query_args, query_errors):\n     try:\n-      self.parse_args()\n       self.pipeline = beam.Pipeline(options=self.pipeline_options)\n       nexmark_util.setup_coder()\n \n       event_monitor = Monitor('.events', 'event')\n       result_monitor = Monitor('.results', 'result')\n \n-      events = self.generate_events()\n+      if self.streaming:\n+        if self.pubsub_mode != 'SUBSCRIBE_ONLY':\n+          self.generate_events()\n+        if self.pubsub_mode == 'PUBLISH_ONLY':\n+          return\n+        events = self.read_from_pubsub()\n+      else:\n+        events = self.read_from_file()\n+\n       events = events | 'event_monitor' >> beam.ParDo(event_monitor.doFn)\n       output = query.load(events, query_args)\n       output | 'result_monitor' >> beam.ParDo(result_monitor.doFn)  # pylint: disable=expression-not-assigned\n \n       result = self.pipeline.run()\n-      job_duration = (\n-          self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-      if self.pipeline_options.view_as(StandardOptions).runner == 'DataflowRunner':  # pylint: disable=line-too-long\n-        result.wait_until_finish(duration=job_duration)\n-        result.cancel()\n-      else:\n+      if not self.streaming:\n         result.wait_until_finish()\n+      perf = self.monitor(result, event_monitor, result_monitor)\n+      self.log_performance(perf)\n+\n     except Exception as exc:\n       query_errors.append(str(exc))\n       raise\n \n+  def monitor(self, job, event_monitor, result_monitor):\n+    logging.info('starting to monitor the job')\n+    last_active_ms = -1\n+    perf = None\n+    cancel_job = False\n+    waiting_for_shutdown = False\n+\n+    while True:\n+      now = int(time.time() * 1000)  # current time in ms\n+      logging.debug('now is %d', now)\n+\n+      curr_perf = NexmarkLauncher.get_performance(\n+          job, event_monitor, result_monitor)\n+      if perf is None or curr_perf.has_progress(perf):\n+        last_active_ms = now\n+      if self.streaming and not waiting_for_shutdown:\n+        quiet_duration = (now - last_active_ms) // 1000\n+        if curr_perf.event_count >= self.args.num_events and\\\n+           curr_perf.result_count >= 0 and quiet_duration > self.DONE_DELAY:", "originalCommit": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkzMzI1NA==", "url": "https://github.com/apache/beam/pull/12709#discussion_r484933254", "bodyText": "It looks like you can call self.cleanup for most of these, and save a few lines? : )", "author": "pabloem", "createdAt": "2020-09-08T13:46:32Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -96,24 +94,41 @@\n \n \n class NexmarkLauncher(object):\n+\n+  # how long after some result is seen and no activity seen do we cancel job\n+  DONE_DELAY = 5 * 60\n+  # delay in seconds between sample perf data\n+  PERF_DELAY = 20\n+  # delay before cancelling the job when pipeline appears to be stuck\n+  TERMINATE_DELAY = 1 * 60 * 60\n+  # delay before warning when pipeline appears to be stuck\n+  WARNING_DELAY = 10 * 60\n+\n   def __init__(self):\n     self.parse_args()\n-    self.uuid = str(uuid.uuid4())\n-    self.topic_name = self.args.topic_name + self.uuid\n-    self.subscription_name = self.args.subscription_name + self.uuid\n-    publish_client = pubsub.Client(project=self.project)\n-    topic = publish_client.topic(self.topic_name)\n-    if topic.exists():\n-      logging.info('deleting topic %s', self.topic_name)\n-      topic.delete()\n-    logging.info('creating topic %s', self.topic_name)\n-    topic.create()\n-    sub = topic.subscription(self.subscription_name)\n-    if sub.exists():\n-      logging.info('deleting sub %s', self.topic_name)\n-      sub.delete()\n-    logging.info('creating sub %s', self.topic_name)\n-    sub.create()\n+    self.manage_resources = self.args.manage_resources\n+    self.uuid = str(uuid.uuid4()) if self.manage_resources else ''\n+    self.topic_name = (\n+        self.args.topic_name + self.uuid if self.args.topic_name else None)\n+    self.subscription_name = (\n+        self.args.subscription_name +\n+        self.uuid if self.args.subscription_name else None)\n+    self.pubsub_mode = self.args.pubsub_mode\n+    if self.manage_resources:\n+      from google.cloud import pubsub\n+      publish_client = pubsub.Client(project=self.project)\n+      topic = publish_client.topic(self.topic_name)\n+      if topic.exists():\n+        logging.info('deleting topic %s', self.topic_name)\n+        topic.delete()\n+      logging.info('creating topic %s', self.topic_name)\n+      topic.create()\n+      sub = topic.subscription(self.subscription_name)\n+      if sub.exists():\n+        logging.info('deleting sub %s', self.topic_name)\n+        sub.delete()", "originalCommit": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkzNzY1OA==", "url": "https://github.com/apache/beam/pull/12709#discussion_r484937658", "bodyText": "let's use parentheses instead of \\", "author": "pabloem", "createdAt": "2020-09-08T13:52:25Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_perf.py", "diffHunk": "@@ -0,0 +1,49 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+performance summary for a run of nexmark query\n+\"\"\"\n+\n+\n+class NexmarkPerf(object):\n+  def __init__(\n+      self,\n+      runtime_sec=None,\n+      event_count=None,\n+      event_per_sec=None,\n+      result_count=None):\n+    self.runtime_sec = runtime_sec if runtime_sec else -1.0\n+    self.event_count = event_count if event_count else -1\n+    self.event_per_sec = event_per_sec if event_per_sec else -1.0\n+    self.result_count = result_count if result_count else -1\n+\n+  def has_progress(self, previous_perf):\n+    # type: (NexmarkPerf) -> bool\n+\n+    \"\"\"\n+    Args:\n+      previous_perf: a NexmarkPerf object to be compared to self\n+\n+    Returns:\n+      True if there are activity between self and other NexmarkPerf values\n+    \"\"\"\n+    if self.runtime_sec != previous_perf.runtime_sec or\\", "originalCommit": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkzODMzMQ==", "url": "https://github.com/apache/beam/pull/12709#discussion_r484938331", "bodyText": "e.g.\nif (self.r_s != ... or\n    self.abc != self.def or ...):", "author": "pabloem", "createdAt": "2020-09-08T13:53:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkzNzY1OA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkzOTc1Mw==", "url": "https://github.com/apache/beam/pull/12709#discussion_r484939753", "bodyText": "Also, is progress in runtime_sec an indicator of progress in the pipeline? Perhaps could you add pydoc for this class describing what each attribute represents?", "author": "pabloem", "createdAt": "2020-09-08T13:55:11Z", "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_perf.py", "diffHunk": "@@ -0,0 +1,49 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+performance summary for a run of nexmark query\n+\"\"\"\n+\n+\n+class NexmarkPerf(object):\n+  def __init__(\n+      self,\n+      runtime_sec=None,\n+      event_count=None,\n+      event_per_sec=None,\n+      result_count=None):\n+    self.runtime_sec = runtime_sec if runtime_sec else -1.0\n+    self.event_count = event_count if event_count else -1\n+    self.event_per_sec = event_per_sec if event_per_sec else -1.0\n+    self.result_count = result_count if result_count else -1\n+\n+  def has_progress(self, previous_perf):\n+    # type: (NexmarkPerf) -> bool\n+\n+    \"\"\"\n+    Args:\n+      previous_perf: a NexmarkPerf object to be compared to self\n+\n+    Returns:\n+      True if there are activity between self and other NexmarkPerf values\n+    \"\"\"\n+    if self.runtime_sec != previous_perf.runtime_sec or\\\n+       self.event_count != previous_perf.event_count or\\\n+       self.result_count != previous_perf.result_count:", "originalCommit": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "b0b62500de9354faac2686affab5d6222dec2d84", "url": "https://github.com/apache/beam/commit/b0b62500de9354faac2686affab5d6222dec2d84", "message": "added more docs and better formatting", "committedDate": "2020-09-08T22:35:49Z", "type": "commit"}]}