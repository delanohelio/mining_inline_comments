{"pr_number": 10731, "pr_title": "[BEAM-7926] Data-centric Interactive Part3", "pr_createdAt": "2020-01-30T21:44:17Z", "pr_url": "https://github.com/apache/beam/pull/10731", "timeline": [{"oid": "a735ac102def4f6da23e0bfe19a2591b494a45d7", "url": "https://github.com/apache/beam/commit/a735ac102def4f6da23e0bfe19a2591b494a45d7", "message": "[BEAM-7926] Data-centric Interactive Part3\n\n1. Implemented `show` API in `interactive_beam` module. Users can\ninvoke the API to introspect data through dynamic visualization for\ngiven PCollections immediately after they define those PCollections\nwithout running pipelines explicitly. API `show` always implicitly\nexecutes the right pipeline fragment no matter how broken/messy the\nin-memory state is for a notebook which makes the user flow\ndata-centric.\n2. Updated the example notebook.\n3. Use heading to sample data from PCollectionVisualization for\nprint-display when there is no frontend.\n4. Spell out build_pipeline_instrument to replace the abbrev. pin function.", "committedDate": "2020-02-10T18:33:38Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1MTE3OQ==", "url": "https://github.com/apache/beam/pull/10731#discussion_r377251179", "bodyText": "doc string above says \"The PCollections given must belong to the same pipeline and be watched\". But even if they are not watched, they will be auto-watched. Should we update the doc string?", "author": "aaltay", "createdAt": "2020-02-10T18:53:23Z", "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "diffHunk": "@@ -82,7 +89,100 @@ def run_pipeline(self):\n   ie.current_env().watch(watchable)\n \n \n-def visualize(pcoll):\n-  \"\"\"Visualizes a PCollection.\"\"\"\n-  # TODO(BEAM-7926)\n-  pass\n+def show(*pcolls):\n+  \"\"\"Visualizes given PCollections in an interactive exploratory way if used\n+  within a notebook, or prints a heading sampled data if used within an ipython\n+  shell. Noop if used in a non-interactive environment.\n+\n+  Ad hoc builds a pipeline fragment including only transforms that are\n+  necessary to produce data for given PCollections pcolls, runs the pipeline\n+  fragment to compute data for those pcolls and then visualizes the data.\n+\n+  The function is always blocking. If used within a notebook, the data\n+  visualized might be dynamically updated before the function returns as more\n+  and more data could getting processed and emitted when the pipeline fragment\n+  is being executed. If used within an ipython shell, there will be no dynamic\n+  plotting but a static plotting in the end of pipeline fragment execution.\n+\n+  The PCollections given must belong to the same pipeline and be watched by\n+  Interactive Beam (PCollections defined in __main__ are automatically watched).\n+\n+    For example::\n+\n+      p = beam.Pipeline(InteractiveRunner())\n+      init = p | 'Init' >> beam.Create(range(1000))\n+      square = init | 'Square' >> beam.Map(lambda x: x * x)\n+      cube = init | 'Cube' >> beam.Map(lambda x: x ** 3)\n+\n+      # Below builds a pipeline fragment from the defined pipeline `p` that\n+      # contains only applied transforms of `Init` and `Square`. Then the\n+      # interactive runner runs the pipeline fragment implicitly to compute data\n+      # represented by PCollection `square` and visualizes it.\n+      show(square)\n+\n+      # This is equivalent to `show(square)` because `square` depends on `init`\n+      # and `init` is included in the pipeline fragment and computed anyway.\n+      show(init, square)\n+\n+      # Below is similar to running `p.run()`. It computes data for both\n+      # PCollection `square` and PCollection `cube`, then visualizes them.\n+      show(square, cube)\n+  \"\"\"\n+  assert len(pcolls) > 0, (\n+      'Need at least 1 PCollection to show data visualization.')\n+  for pcoll in pcolls:\n+    assert isinstance(pcoll, beam.pvalue.PCollection), (\n+        '{} is not an apache_beam.pvalue.PCollection.'.format(pcoll))\n+  user_pipeline = pcolls[0].pipeline\n+  for pcoll in pcolls:\n+    assert pcoll.pipeline is user_pipeline, (\n+        '{} belongs to a different user-defined pipeline ({}) than that of'\n+        ' other PCollections ({}).'.format(\n+            pcoll, pcoll.pipeline, user_pipeline))\n+  runner = user_pipeline.runner\n+  if isinstance(runner, ir.InteractiveRunner):\n+    runner = runner._underlying_runner\n+\n+  # Make sure that all PCollections to be shown are watched. If a PCollection\n+  # has not been watched, make up a variable name for that PCollection and watch\n+  # it. No validation is needed here because the watch logic can handle\n+  # arbitrary variables.\n+  watched_pcollections = set()\n+  for watching in ie.current_env().watching():\n+    for key, val in watching:\n+      if hasattr(val, '__class__') and isinstance(val, beam.pvalue.PCollection):\n+        watched_pcollections.add(val)\n+  for pcoll in pcolls:\n+    if pcoll not in watched_pcollections:\n+      watch({re.sub(r'[\\[\\]\\(\\)]', '_', str(pcoll)): pcoll})", "originalCommit": "a735ac102def4f6da23e0bfe19a2591b494a45d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIwMDkzMw==", "url": "https://github.com/apache/beam/pull/10731#discussion_r379200933", "bodyText": "Removed the must be watched statement from the docstrings.", "author": "KevinGG", "createdAt": "2020-02-14T00:54:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1MTE3OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1MjA2MQ==", "url": "https://github.com/apache/beam/pull/10731#discussion_r377252061", "bodyText": "What is dynamic_plotting_interval ? Is it a 1 second update?", "author": "aaltay", "createdAt": "2020-02-10T18:54:59Z", "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "diffHunk": "@@ -82,7 +89,100 @@ def run_pipeline(self):\n   ie.current_env().watch(watchable)\n \n \n-def visualize(pcoll):\n-  \"\"\"Visualizes a PCollection.\"\"\"\n-  # TODO(BEAM-7926)\n-  pass\n+def show(*pcolls):\n+  \"\"\"Visualizes given PCollections in an interactive exploratory way if used\n+  within a notebook, or prints a heading sampled data if used within an ipython\n+  shell. Noop if used in a non-interactive environment.\n+\n+  Ad hoc builds a pipeline fragment including only transforms that are\n+  necessary to produce data for given PCollections pcolls, runs the pipeline\n+  fragment to compute data for those pcolls and then visualizes the data.\n+\n+  The function is always blocking. If used within a notebook, the data\n+  visualized might be dynamically updated before the function returns as more\n+  and more data could getting processed and emitted when the pipeline fragment\n+  is being executed. If used within an ipython shell, there will be no dynamic\n+  plotting but a static plotting in the end of pipeline fragment execution.\n+\n+  The PCollections given must belong to the same pipeline and be watched by\n+  Interactive Beam (PCollections defined in __main__ are automatically watched).\n+\n+    For example::\n+\n+      p = beam.Pipeline(InteractiveRunner())\n+      init = p | 'Init' >> beam.Create(range(1000))\n+      square = init | 'Square' >> beam.Map(lambda x: x * x)\n+      cube = init | 'Cube' >> beam.Map(lambda x: x ** 3)\n+\n+      # Below builds a pipeline fragment from the defined pipeline `p` that\n+      # contains only applied transforms of `Init` and `Square`. Then the\n+      # interactive runner runs the pipeline fragment implicitly to compute data\n+      # represented by PCollection `square` and visualizes it.\n+      show(square)\n+\n+      # This is equivalent to `show(square)` because `square` depends on `init`\n+      # and `init` is included in the pipeline fragment and computed anyway.\n+      show(init, square)\n+\n+      # Below is similar to running `p.run()`. It computes data for both\n+      # PCollection `square` and PCollection `cube`, then visualizes them.\n+      show(square, cube)\n+  \"\"\"\n+  assert len(pcolls) > 0, (\n+      'Need at least 1 PCollection to show data visualization.')\n+  for pcoll in pcolls:\n+    assert isinstance(pcoll, beam.pvalue.PCollection), (\n+        '{} is not an apache_beam.pvalue.PCollection.'.format(pcoll))\n+  user_pipeline = pcolls[0].pipeline\n+  for pcoll in pcolls:\n+    assert pcoll.pipeline is user_pipeline, (\n+        '{} belongs to a different user-defined pipeline ({}) than that of'\n+        ' other PCollections ({}).'.format(\n+            pcoll, pcoll.pipeline, user_pipeline))\n+  runner = user_pipeline.runner\n+  if isinstance(runner, ir.InteractiveRunner):\n+    runner = runner._underlying_runner\n+\n+  # Make sure that all PCollections to be shown are watched. If a PCollection\n+  # has not been watched, make up a variable name for that PCollection and watch\n+  # it. No validation is needed here because the watch logic can handle\n+  # arbitrary variables.\n+  watched_pcollections = set()\n+  for watching in ie.current_env().watching():\n+    for key, val in watching:\n+      if hasattr(val, '__class__') and isinstance(val, beam.pvalue.PCollection):\n+        watched_pcollections.add(val)\n+  for pcoll in pcolls:\n+    if pcoll not in watched_pcollections:\n+      watch({re.sub(r'[\\[\\]\\(\\)]', '_', str(pcoll)): pcoll})\n+\n+  # Attempt to run background caching job since we have the reference to the\n+  # user-defined pipeline.\n+  bcj.attempt_to_run_background_caching_job(runner, user_pipeline)\n+\n+  # Build a pipeline fragment for the PCollections and run it.\n+  result = pf.PipelineFragment(list(pcolls)).run()\n+  ie.current_env().set_pipeline_result(\n+      user_pipeline,\n+      result,\n+      is_main_job=True)\n+\n+  # If in notebook, dynamic plotting as computation goes.\n+  if ie.current_env().is_in_notebook:\n+    for pcoll in pcolls:\n+      visualize(pcoll, dynamic_plotting_interval=1)", "originalCommit": "a735ac102def4f6da23e0bfe19a2591b494a45d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIwMTY0OA==", "url": "https://github.com/apache/beam/pull/10731#discussion_r379201648", "bodyText": "Yes, its unit is second. The underlying implementation uses a datetime.timedelta. This is to simplify the visualize interface and its usages.", "author": "KevinGG", "createdAt": "2020-02-14T00:56:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1MjA2MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1MzEwNw==", "url": "https://github.com/apache/beam/pull/10731#discussion_r377253107", "bodyText": "This test will break if anything changes related to this arbitrary naming. Maybe just check that it exists.", "author": "aaltay", "createdAt": "2020-02-10T18:56:56Z", "path": "sdks/python/apache_beam/runners/interactive/interactive_beam_test.py", "diffHunk": "@@ -67,6 +77,31 @@ def test_watch_class_instance(self):\n     test_env.watch(self)\n     self.assertEqual(ie.current_env().watching(), test_env.watching())\n \n+  def test_show_always_watch_given_pcolls(self):\n+    p = beam.Pipeline(ir.InteractiveRunner())\n+    # pylint: disable=range-builtin-not-iterating\n+    pcoll = p | 'Create' >> beam.Create(range(10))\n+    # The pcoll is not watched since watch(locals()) is not explicitly called.\n+    self.assertFalse(\n+        pcoll in _get_watched_pcollections_with_variable_names())\n+    # The call of show watches pcoll.\n+    ib.show(pcoll)\n+    self.assertTrue(\n+        pcoll in _get_watched_pcollections_with_variable_names())\n+    # The name of pcoll is made up by show.\n+    self.assertEqual(\n+        'PCollection_Create/Map_decode_.None_',", "originalCommit": "a735ac102def4f6da23e0bfe19a2591b494a45d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIwMTc0MQ==", "url": "https://github.com/apache/beam/pull/10731#discussion_r379201741", "bodyText": "Removed the str assertion. Kept the existence check.", "author": "KevinGG", "createdAt": "2020-02-14T00:57:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1MzEwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1Mzg4NA==", "url": "https://github.com/apache/beam/pull/10731#discussion_r377253884", "bodyText": "Use blocking instead of blocking_run? (Since that is what we use in other places.)", "author": "aaltay", "createdAt": "2020-02-10T18:58:23Z", "path": "sdks/python/apache_beam/runners/interactive/pipeline_fragment.py", "diffHunk": "@@ -100,17 +100,23 @@ def deduce_fragment(self):\n         self._runner_pipeline.runner,\n         self._options)\n \n-  def run(self, display_pipeline_graph=False, use_cache=True):\n+  def run(self,\n+          display_pipeline_graph=False,\n+          use_cache=True,\n+          blocking_run=False):", "originalCommit": "a735ac102def4f6da23e0bfe19a2591b494a45d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIwMjEwNg==", "url": "https://github.com/apache/beam/pull/10731#discussion_r379202106", "bodyText": "Renamed blocking_run to blocking.\nRenamed all try-finally preserve-and-reset variables with preserved_ prefix.", "author": "KevinGG", "createdAt": "2020-02-14T00:58:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1Mzg4NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1NDU4NQ==", "url": "https://github.com/apache/beam/pull/10731#discussion_r377254585", "bodyText": "You renamed pin to build_pipeline_instrument in another place. Do you want to switch these to background_caching_job if you are trying to be more explicit in general?", "author": "aaltay", "createdAt": "2020-02-10T18:59:41Z", "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "diffHunk": "@@ -82,7 +89,100 @@ def run_pipeline(self):\n   ie.current_env().watch(watchable)\n \n \n-def visualize(pcoll):\n-  \"\"\"Visualizes a PCollection.\"\"\"\n-  # TODO(BEAM-7926)\n-  pass\n+def show(*pcolls):\n+  \"\"\"Visualizes given PCollections in an interactive exploratory way if used\n+  within a notebook, or prints a heading sampled data if used within an ipython\n+  shell. Noop if used in a non-interactive environment.\n+\n+  Ad hoc builds a pipeline fragment including only transforms that are\n+  necessary to produce data for given PCollections pcolls, runs the pipeline\n+  fragment to compute data for those pcolls and then visualizes the data.\n+\n+  The function is always blocking. If used within a notebook, the data\n+  visualized might be dynamically updated before the function returns as more\n+  and more data could getting processed and emitted when the pipeline fragment\n+  is being executed. If used within an ipython shell, there will be no dynamic\n+  plotting but a static plotting in the end of pipeline fragment execution.\n+\n+  The PCollections given must belong to the same pipeline and be watched by\n+  Interactive Beam (PCollections defined in __main__ are automatically watched).\n+\n+    For example::\n+\n+      p = beam.Pipeline(InteractiveRunner())\n+      init = p | 'Init' >> beam.Create(range(1000))\n+      square = init | 'Square' >> beam.Map(lambda x: x * x)\n+      cube = init | 'Cube' >> beam.Map(lambda x: x ** 3)\n+\n+      # Below builds a pipeline fragment from the defined pipeline `p` that\n+      # contains only applied transforms of `Init` and `Square`. Then the\n+      # interactive runner runs the pipeline fragment implicitly to compute data\n+      # represented by PCollection `square` and visualizes it.\n+      show(square)\n+\n+      # This is equivalent to `show(square)` because `square` depends on `init`\n+      # and `init` is included in the pipeline fragment and computed anyway.\n+      show(init, square)\n+\n+      # Below is similar to running `p.run()`. It computes data for both\n+      # PCollection `square` and PCollection `cube`, then visualizes them.\n+      show(square, cube)\n+  \"\"\"\n+  assert len(pcolls) > 0, (\n+      'Need at least 1 PCollection to show data visualization.')\n+  for pcoll in pcolls:\n+    assert isinstance(pcoll, beam.pvalue.PCollection), (\n+        '{} is not an apache_beam.pvalue.PCollection.'.format(pcoll))\n+  user_pipeline = pcolls[0].pipeline\n+  for pcoll in pcolls:\n+    assert pcoll.pipeline is user_pipeline, (\n+        '{} belongs to a different user-defined pipeline ({}) than that of'\n+        ' other PCollections ({}).'.format(\n+            pcoll, pcoll.pipeline, user_pipeline))\n+  runner = user_pipeline.runner\n+  if isinstance(runner, ir.InteractiveRunner):\n+    runner = runner._underlying_runner\n+\n+  # Make sure that all PCollections to be shown are watched. If a PCollection\n+  # has not been watched, make up a variable name for that PCollection and watch\n+  # it. No validation is needed here because the watch logic can handle\n+  # arbitrary variables.\n+  watched_pcollections = set()\n+  for watching in ie.current_env().watching():\n+    for key, val in watching:\n+      if hasattr(val, '__class__') and isinstance(val, beam.pvalue.PCollection):\n+        watched_pcollections.add(val)\n+  for pcoll in pcolls:\n+    if pcoll not in watched_pcollections:\n+      watch({re.sub(r'[\\[\\]\\(\\)]', '_', str(pcoll)): pcoll})\n+\n+  # Attempt to run background caching job since we have the reference to the\n+  # user-defined pipeline.\n+  bcj.attempt_to_run_background_caching_job(runner, user_pipeline)", "originalCommit": "a735ac102def4f6da23e0bfe19a2591b494a45d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIwMjgyNw==", "url": "https://github.com/apache/beam/pull/10731#discussion_r379202827", "bodyText": "This is to discern instances from modules.\nFor example, given a background_caching_job, it feels more like an instance of BackgroundCachingJob.\nFor pipeline_instrument, when importing the module, we normally rename it to instr or inst.\nBecause pipeline_instrument = instr.build_pipeline_instrument(...).\nThe abbreviation is to avoid name conflicts.", "author": "KevinGG", "createdAt": "2020-02-14T01:01:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1NDU4NQ=="}], "type": "inlineReview"}, {"oid": "a138ac1bcad3ce64d0557f84d4195e09918cde38", "url": "https://github.com/apache/beam/commit/a138ac1bcad3ce64d0557f84d4195e09918cde38", "message": "Rebased to upstream master head and fix lint/format", "committedDate": "2020-02-14T18:51:04Z", "type": "forcePushed"}, {"oid": "3c2acaaa515970285192a1a95b62dcd47a17d869", "url": "https://github.com/apache/beam/commit/3c2acaaa515970285192a1a95b62dcd47a17d869", "message": "[BEAM-7926] Data-centric Interactive Part3\n\n1. Implemented `show` API in `interactive_beam` module. Users can\ninvoke the API to introspect data through dynamic visualization for\ngiven PCollections immediately after they define those PCollections\nwithout running pipelines explicitly. API `show` always implicitly\nexecutes the right pipeline fragment no matter how broken/messy the\nin-memory state is for a notebook which makes the user flow\ndata-centric.\n2. Updated the example notebook.\n3. Use heading to sample data from PCollectionVisualization for\nprint-display when there is no frontend.\n4. Spell out build_pipeline_instrument to replace the abbrev. pin function.", "committedDate": "2020-02-19T18:40:37Z", "type": "commit"}, {"oid": "cda118018b5241590b9b3e0d5f4f7369e77107f7", "url": "https://github.com/apache/beam/commit/cda118018b5241590b9b3e0d5f4f7369e77107f7", "message": "changes based on comments", "committedDate": "2020-02-19T18:40:38Z", "type": "commit"}, {"oid": "35521c1cb85a9cb0105ded1c1174d22c90c11750", "url": "https://github.com/apache/beam/commit/35521c1cb85a9cb0105ded1c1174d22c90c11750", "message": "Rebased to upstream master head and fix lint/format", "committedDate": "2020-02-19T18:40:38Z", "type": "commit"}, {"oid": "35521c1cb85a9cb0105ded1c1174d22c90c11750", "url": "https://github.com/apache/beam/commit/35521c1cb85a9cb0105ded1c1174d22c90c11750", "message": "Rebased to upstream master head and fix lint/format", "committedDate": "2020-02-19T18:40:38Z", "type": "forcePushed"}]}