{"pr_number": 12754, "pr_title": "[BEAM-10791] Identify and log additional information needed to debug \u2026", "pr_createdAt": "2020-09-01T19:52:03Z", "pr_url": "https://github.com/apache/beam/pull/12754", "timeline": [{"oid": "b16742b3ea78334dc21b33ff351d1419e1ee466e", "url": "https://github.com/apache/beam/commit/b16742b3ea78334dc21b33ff351d1419e1ee466e", "message": "[BEAM-10791] Identify and log additional information needed to debug streaming insert requests for Python SDK", "committedDate": "2020-09-01T19:17:15Z", "type": "commit"}, {"oid": "2cf173793b574b2affc68937af48df3fbe7252b9", "url": "https://github.com/apache/beam/commit/2cf173793b574b2affc68937af48df3fbe7252b9", "message": "share histogram in a single process", "committedDate": "2020-09-03T01:38:24Z", "type": "commit"}, {"oid": "33c9e34b16c626928faf560d56856d609a8a4eec", "url": "https://github.com/apache/beam/commit/33c9e34b16c626928faf560d56856d609a8a4eec", "message": "add tests", "committedDate": "2020-09-03T08:29:19Z", "type": "commit"}, {"oid": "cfe61fdfd434bf869eb7c5172946ab5bd4b96f9b", "url": "https://github.com/apache/beam/commit/cfe61fdfd434bf869eb7c5172946ab5bd4b96f9b", "message": "add comments", "committedDate": "2020-09-03T09:14:24Z", "type": "commit"}, {"oid": "e521d101130af1be236827136c24d3ad15f889fd", "url": "https://github.com/apache/beam/commit/e521d101130af1be236827136c24d3ad15f889fd", "message": "safer locking", "committedDate": "2020-09-03T09:42:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzA5NTIwMQ==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483095201", "bodyText": "Help me understand a bit here. Am I correct about this:\n\nThere are multiple threads\nBut due to Global Interpreter Lock, only one thread runs at a time\nBut threads can possibly block in these sections, get preempted and another thread will start running\nso we need the locking to ensure only one thread is running in this block at a time.\n\nIn addition\n\nMultiple python processes also execute, and there are multiple python SDK harnesses running in order to get more parallelism (they don't have the same type of threading concurrency issues, but may communicate with the multiprocessing module).\nThough this is not why the lock is introduced", "author": "ajamato", "createdAt": "2020-09-03T16:09:54Z", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1198,8 +1209,34 @@ def process(self, element, *schema_side_inputs):\n       return self._flush_all_batches()\n \n   def finish_bundle(self):\n+    current_millis = int(time.time() * 1000)\n+    if BigQueryWriteFn.LATENCY_LOGGING_LOCK.acquire(False):", "originalCommit": "e521d101130af1be236827136c24d3ad15f889fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI4MTkzNQ==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483281935", "bodyText": "Lock was introduced for sharing the same histogram object between threads in a single python process. My first attempt was having a separate histogram object per DoFn but it produced too many logs since we're creating dozens of DoFns per process with streaming pipelines (# of workers * # of cores * # of DoFn threads).\nThere are two locks: the first one is for synchronizing histogram object itself and the second one is only for printing out the logs with a given interval. For the second lock, other threads don't need to wait if one thread occupies the lock. It's okay that any one of threads puts its hands up first and does the job and others just skip the whole code block.", "author": "ihji", "createdAt": "2020-09-03T22:14:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzA5NTIwMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzA5Njc1NA==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483096754", "bodyText": "acquire with the false parameter can skip this section entirely, if another thread has the lock. So if that happens we won't record current_millis into the histogram", "author": "ajamato", "createdAt": "2020-09-03T16:12:13Z", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1198,8 +1209,34 @@ def process(self, element, *schema_side_inputs):\n       return self._flush_all_batches()\n \n   def finish_bundle(self):\n+    current_millis = int(time.time() * 1000)\n+    if BigQueryWriteFn.LATENCY_LOGGING_LOCK.acquire(False):", "originalCommit": "e521d101130af1be236827136c24d3ad15f889fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI4MTk2NQ==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483281965", "bodyText": "current_millis is only for checking whether the enough amount of time passed after the last log reporting time. acquire with the false parameter was intentional to minimize performance impact for log reporting. Please see the other comment above.", "author": "ihji", "createdAt": "2020-09-03T22:14:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzA5Njc1NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEwMDQzMQ==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483100431", "bodyText": "Are we sure finishBundle is called frequently enough? I.e. are there bundles which process for a long time? Are we sure this code will get invoked when there are failures to write to BQ?", "author": "ajamato", "createdAt": "2020-09-03T16:18:04Z", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1198,8 +1209,34 @@ def process(self, element, *schema_side_inputs):\n       return self._flush_all_batches()\n \n   def finish_bundle(self):\n+    current_millis = int(time.time() * 1000)", "originalCommit": "e521d101130af1be236827136c24d3ad15f889fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI4MjAzOQ==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483282039", "bodyText": "Are we sure finishBundle is called frequently enough?\n\nYes, for streaming pipeline. The bundle size is sufficiently small.\n\nAre we sure this code will get invoked when there are failures to write to BQ?\n\nYes, there's a test case for that.", "author": "ihji", "createdAt": "2020-09-03T22:14:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEwMDQzMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEwMjYyNQ==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483102625", "bodyText": "\" Note that the total count and each percentile value may not be correlated each other\"\nI don't fully grasp the meaning. Would you please rephrase? :)", "author": "ajamato", "createdAt": "2020-09-03T16:21:23Z", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1198,8 +1209,34 @@ def process(self, element, *schema_side_inputs):\n       return self._flush_all_batches()\n \n   def finish_bundle(self):\n+    current_millis = int(time.time() * 1000)\n+    if BigQueryWriteFn.LATENCY_LOGGING_LOCK.acquire(False):\n+      try:\n+        if (BigQueryWriteFn.LATENCY_LOGGING_HISTOGRAM.total_count() > 0 and\n+            (current_millis -\n+             BigQueryWriteFn.LATENCY_LOGGING_LAST_REPORTED_MILLIS) >\n+            self._latency_logging_frequency * 1000):\n+          self._log_percentiles()\n+          BigQueryWriteFn.LATENCY_LOGGING_HISTOGRAM.clear()\n+          BigQueryWriteFn.LATENCY_LOGGING_LAST_REPORTED_MILLIS = current_millis\n+      finally:\n+        BigQueryWriteFn.LATENCY_LOGGING_LOCK.release()\n     return self._flush_all_batches()\n \n+  @classmethod\n+  def _log_percentiles(cls):\n+    # Note that the total count and each percentile value may not be correlated", "originalCommit": "e521d101130af1be236827136c24d3ad15f889fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI4MjUyMw==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483282523", "bodyText": "Which means, for example, that it's possible that between p90() and p50() calls record might be called as well from different threads so that p90() calculates the percentile for 100 recorded values but following p50() calculates the percentile for 101 recorded values. It's because we lock each p90(),p50() and record method, not p90() + p50(). Hope this explanation is clear \ud83d\ude05", "author": "ihji", "createdAt": "2020-09-03T22:15:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEwMjYyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzQ3MzI5OA==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483473298", "bodyText": "Outdated.", "author": "ihji", "createdAt": "2020-09-04T08:36:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEwMjYyNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEwNzEyOQ==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483107129", "bodyText": "add units to variable name\ni.e.\n_latency_logging_frequency_msec", "author": "ajamato", "createdAt": "2020-09-03T16:28:28Z", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1096,6 +1106,7 @@ def __init__(\n     self.failed_rows_metric = Metrics.distribution(\n         self.__class__, \"rows_failed_per_batch\")\n     self.bigquery_wrapper = None\n+    self._latency_logging_frequency = latency_logging_frequency or 180", "originalCommit": "e521d101130af1be236827136c24d3ad15f889fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzMzMTkxMA==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483331910", "bodyText": "done.", "author": "ihji", "createdAt": "2020-09-04T01:11:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEwNzEyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEwODg3Nw==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483108877", "bodyText": "add units, _secs, _msecs, etc.", "author": "ajamato", "createdAt": "2020-09-03T16:31:20Z", "path": "sdks/python/apache_beam/options/pipeline_options.py", "diffHunk": "@@ -675,6 +675,27 @@ def validate(self, validator):\n     return errors\n \n \n+class BigQueryOptions(PipelineOptions):\n+  \"\"\"BigQueryIO configuration options.\"\"\"\n+  @classmethod\n+  def _add_argparse_args(cls, parser):\n+    parser.add_argument(\n+        '--latency_logging_frequency',", "originalCommit": "e521d101130af1be236827136c24d3ad15f889fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzMzMTkzNQ==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483331935", "bodyText": "done.", "author": "ihji", "createdAt": "2020-09-04T01:11:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEwODg3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExMjE5Ng==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483112196", "bodyText": "This shouldn't be in an else block, Please always record the latency. Place large values it in a bucket representing -INF and +INF boundaries, as we discussed in the java PR", "author": "ajamato", "createdAt": "2020-09-03T16:36:33Z", "path": "sdks/python/apache_beam/utils/histogram.py", "diffHunk": "@@ -0,0 +1,176 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import logging\n+import math\n+import threading\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+\n+class Histogram(object):\n+  \"\"\"A histogram that supports estimated percentile with linear interpolation.\n+\n+  This class is considered experimental and may break or receive backwards-\n+  incompatible changes in future versions of the Apache Beam SDK.\n+  \"\"\"\n+  def __init__(self, bucket_type):\n+    self._lock = threading.Lock()\n+    self._bucket_type = bucket_type\n+    self._buckets = {}\n+    self._num_records = 0\n+    self._num_top_records = 0\n+    self._num_bot_records = 0\n+\n+  def clear(self):\n+    with self._lock:\n+      self._buckets = {}\n+      self._num_records = 0\n+      self._num_top_records = 0\n+      self._num_bot_records = 0\n+\n+  def record(self, *args):\n+    for arg in args:\n+      self._record(arg)\n+\n+  def _record(self, value):\n+    range_from = self._bucket_type.range_from()\n+    range_to = self._bucket_type.range_to()\n+    with self._lock:\n+      if value >= range_to:\n+        _LOGGER.warning('record is out of upper bound %s: %s', range_to, value)\n+        self._num_top_records += 1\n+      elif value < range_from:\n+        _LOGGER.warning(\n+            'record is out of lower bound %s: %s', range_from, value)\n+        self._num_bot_records += 1\n+      else:", "originalCommit": "e521d101130af1be236827136c24d3ad15f889fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzMxNTY3MQ==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483315671", "bodyText": "The latency is always recorded. self._num_bot_records and self._num_top_records represent the buckets (-oo, range_from) and [range_to, -oo) respectively.", "author": "ihji", "createdAt": "2020-09-04T00:06:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExMjE5Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExNDE0MA==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483114140", "bodyText": "This doesn't seem like an Error. Instead of Raising a RuntimeError, consider returning an empty/unpopulated result", "author": "ajamato", "createdAt": "2020-09-03T16:39:41Z", "path": "sdks/python/apache_beam/utils/histogram.py", "diffHunk": "@@ -0,0 +1,176 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import logging\n+import math\n+import threading\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+\n+class Histogram(object):\n+  \"\"\"A histogram that supports estimated percentile with linear interpolation.\n+\n+  This class is considered experimental and may break or receive backwards-\n+  incompatible changes in future versions of the Apache Beam SDK.\n+  \"\"\"\n+  def __init__(self, bucket_type):\n+    self._lock = threading.Lock()\n+    self._bucket_type = bucket_type\n+    self._buckets = {}\n+    self._num_records = 0\n+    self._num_top_records = 0\n+    self._num_bot_records = 0\n+\n+  def clear(self):\n+    with self._lock:\n+      self._buckets = {}\n+      self._num_records = 0\n+      self._num_top_records = 0\n+      self._num_bot_records = 0\n+\n+  def record(self, *args):\n+    for arg in args:\n+      self._record(arg)\n+\n+  def _record(self, value):\n+    range_from = self._bucket_type.range_from()\n+    range_to = self._bucket_type.range_to()\n+    with self._lock:\n+      if value >= range_to:\n+        _LOGGER.warning('record is out of upper bound %s: %s', range_to, value)\n+        self._num_top_records += 1\n+      elif value < range_from:\n+        _LOGGER.warning(\n+            'record is out of lower bound %s: %s', range_from, value)\n+        self._num_bot_records += 1\n+      else:\n+        index = self._bucket_type.bucket_index(value)\n+        self._buckets[index] = self._buckets.get(index, 0) + 1\n+        self._num_records += 1\n+\n+  def total_count(self):\n+    return self._num_records + self._num_top_records + self._num_bot_records\n+\n+  def p99(self):\n+    return self.get_linear_interpolation(0.99)\n+\n+  def p90(self):\n+    return self.get_linear_interpolation(0.90)\n+\n+  def p50(self):\n+    return self.get_linear_interpolation(0.50)\n+\n+  def get_linear_interpolation(self, percentile):\n+    \"\"\"Calculate percentile estimation based on linear interpolation.\n+\n+    It first finds the bucket which includes the target percentile and\n+    projects the estimated point in the bucket by assuming all the elements\n+    in the bucket are uniformly distributed.\n+    \"\"\"\n+    with self._lock:\n+      total_num_records = self.total_count()\n+      if total_num_records == 0:\n+        raise RuntimeError('histogram has no record.')", "originalCommit": "e521d101130af1be236827136c24d3ad15f889fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzMxNjk5Mw==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483316993", "bodyText": "Do you mean it would be better to return None? The type of the returning value is a floating point number and the full range of the value (-oo, +oo) is already used for returning a valid result.", "author": "ihji", "createdAt": "2020-09-04T00:11:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExNDE0MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExNTIxMQ==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483115211", "bodyText": "Rather than stating inf or -inf, state that the percentile is at least as large as the smallest/largest bucket. Which is a more meaningful message to a user reading it", "author": "ajamato", "createdAt": "2020-09-03T16:41:22Z", "path": "sdks/python/apache_beam/utils/histogram.py", "diffHunk": "@@ -0,0 +1,176 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import logging\n+import math\n+import threading\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+\n+class Histogram(object):\n+  \"\"\"A histogram that supports estimated percentile with linear interpolation.\n+\n+  This class is considered experimental and may break or receive backwards-\n+  incompatible changes in future versions of the Apache Beam SDK.\n+  \"\"\"\n+  def __init__(self, bucket_type):\n+    self._lock = threading.Lock()\n+    self._bucket_type = bucket_type\n+    self._buckets = {}\n+    self._num_records = 0\n+    self._num_top_records = 0\n+    self._num_bot_records = 0\n+\n+  def clear(self):\n+    with self._lock:\n+      self._buckets = {}\n+      self._num_records = 0\n+      self._num_top_records = 0\n+      self._num_bot_records = 0\n+\n+  def record(self, *args):\n+    for arg in args:\n+      self._record(arg)\n+\n+  def _record(self, value):\n+    range_from = self._bucket_type.range_from()\n+    range_to = self._bucket_type.range_to()\n+    with self._lock:\n+      if value >= range_to:\n+        _LOGGER.warning('record is out of upper bound %s: %s', range_to, value)\n+        self._num_top_records += 1\n+      elif value < range_from:\n+        _LOGGER.warning(\n+            'record is out of lower bound %s: %s', range_from, value)\n+        self._num_bot_records += 1\n+      else:\n+        index = self._bucket_type.bucket_index(value)\n+        self._buckets[index] = self._buckets.get(index, 0) + 1\n+        self._num_records += 1\n+\n+  def total_count(self):\n+    return self._num_records + self._num_top_records + self._num_bot_records\n+\n+  def p99(self):\n+    return self.get_linear_interpolation(0.99)\n+\n+  def p90(self):\n+    return self.get_linear_interpolation(0.90)\n+\n+  def p50(self):\n+    return self.get_linear_interpolation(0.50)\n+\n+  def get_linear_interpolation(self, percentile):\n+    \"\"\"Calculate percentile estimation based on linear interpolation.\n+\n+    It first finds the bucket which includes the target percentile and\n+    projects the estimated point in the bucket by assuming all the elements\n+    in the bucket are uniformly distributed.\n+    \"\"\"\n+    with self._lock:\n+      total_num_records = self.total_count()\n+      if total_num_records == 0:\n+        raise RuntimeError('histogram has no record.')\n+\n+      index = 0\n+      record_sum = self._num_bot_records\n+      if record_sum / total_num_records >= percentile:\n+        return float('-inf')", "originalCommit": "e521d101130af1be236827136c24d3ad15f889fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzQ3Mjc5Ng==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483472796", "bodyText": "Done.", "author": "ihji", "createdAt": "2020-09-04T08:35:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExNTIxMQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExNTQ1Mw==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483115453", "bodyText": "indent this line by 4", "author": "ajamato", "createdAt": "2020-09-03T16:41:44Z", "path": "sdks/python/apache_beam/utils/histogram.py", "diffHunk": "@@ -0,0 +1,176 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import logging\n+import math\n+import threading\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+\n+class Histogram(object):\n+  \"\"\"A histogram that supports estimated percentile with linear interpolation.\n+\n+  This class is considered experimental and may break or receive backwards-\n+  incompatible changes in future versions of the Apache Beam SDK.\n+  \"\"\"\n+  def __init__(self, bucket_type):\n+    self._lock = threading.Lock()\n+    self._bucket_type = bucket_type\n+    self._buckets = {}\n+    self._num_records = 0\n+    self._num_top_records = 0\n+    self._num_bot_records = 0\n+\n+  def clear(self):\n+    with self._lock:\n+      self._buckets = {}\n+      self._num_records = 0\n+      self._num_top_records = 0\n+      self._num_bot_records = 0\n+\n+  def record(self, *args):\n+    for arg in args:\n+      self._record(arg)\n+\n+  def _record(self, value):\n+    range_from = self._bucket_type.range_from()\n+    range_to = self._bucket_type.range_to()\n+    with self._lock:\n+      if value >= range_to:\n+        _LOGGER.warning('record is out of upper bound %s: %s', range_to, value)\n+        self._num_top_records += 1\n+      elif value < range_from:\n+        _LOGGER.warning(\n+            'record is out of lower bound %s: %s', range_from, value)\n+        self._num_bot_records += 1\n+      else:\n+        index = self._bucket_type.bucket_index(value)\n+        self._buckets[index] = self._buckets.get(index, 0) + 1\n+        self._num_records += 1\n+\n+  def total_count(self):\n+    return self._num_records + self._num_top_records + self._num_bot_records\n+\n+  def p99(self):\n+    return self.get_linear_interpolation(0.99)\n+\n+  def p90(self):\n+    return self.get_linear_interpolation(0.90)\n+\n+  def p50(self):\n+    return self.get_linear_interpolation(0.50)\n+\n+  def get_linear_interpolation(self, percentile):\n+    \"\"\"Calculate percentile estimation based on linear interpolation.\n+\n+    It first finds the bucket which includes the target percentile and\n+    projects the estimated point in the bucket by assuming all the elements\n+    in the bucket are uniformly distributed.\n+    \"\"\"\n+    with self._lock:\n+      total_num_records = self.total_count()\n+      if total_num_records == 0:\n+        raise RuntimeError('histogram has no record.')\n+\n+      index = 0\n+      record_sum = self._num_bot_records\n+      if record_sum / total_num_records >= percentile:\n+        return float('-inf')\n+      while index < self._bucket_type.num_buckets():\n+        record_sum += self._buckets.get(index, 0)\n+        if record_sum / total_num_records >= percentile:\n+          break\n+        index += 1\n+      if index == self._bucket_type.num_buckets():\n+        return float('inf')\n+\n+      frac_percentile = percentile - (\n+          record_sum - self._buckets[index]) / total_num_records\n+      bucket_percentile = self._buckets[index] / total_num_records\n+    frac_bucket_size = frac_percentile * self._bucket_type.bucket_size(\n+        index) / bucket_percentile\n+    return self._bucket_type.range_from(\n+    ) + self._bucket_type.accumulated_bucket_size(index) + frac_bucket_size", "originalCommit": "e521d101130af1be236827136c24d3ad15f889fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzMzMjA3NA==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483332074", "bodyText": "done.", "author": "ihji", "createdAt": "2020-09-04T01:12:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExNTQ1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExNzg0Mw==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483117843", "bodyText": "Add a pydoc for the percentile parameter. Stating that it should be in the range (0, 1)", "author": "ajamato", "createdAt": "2020-09-03T16:45:40Z", "path": "sdks/python/apache_beam/utils/histogram.py", "diffHunk": "@@ -0,0 +1,176 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import logging\n+import math\n+import threading\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+\n+class Histogram(object):\n+  \"\"\"A histogram that supports estimated percentile with linear interpolation.\n+\n+  This class is considered experimental and may break or receive backwards-\n+  incompatible changes in future versions of the Apache Beam SDK.\n+  \"\"\"\n+  def __init__(self, bucket_type):\n+    self._lock = threading.Lock()\n+    self._bucket_type = bucket_type\n+    self._buckets = {}\n+    self._num_records = 0\n+    self._num_top_records = 0\n+    self._num_bot_records = 0\n+\n+  def clear(self):\n+    with self._lock:\n+      self._buckets = {}\n+      self._num_records = 0\n+      self._num_top_records = 0\n+      self._num_bot_records = 0\n+\n+  def record(self, *args):\n+    for arg in args:\n+      self._record(arg)\n+\n+  def _record(self, value):\n+    range_from = self._bucket_type.range_from()\n+    range_to = self._bucket_type.range_to()\n+    with self._lock:\n+      if value >= range_to:\n+        _LOGGER.warning('record is out of upper bound %s: %s', range_to, value)\n+        self._num_top_records += 1\n+      elif value < range_from:\n+        _LOGGER.warning(\n+            'record is out of lower bound %s: %s', range_from, value)\n+        self._num_bot_records += 1\n+      else:\n+        index = self._bucket_type.bucket_index(value)\n+        self._buckets[index] = self._buckets.get(index, 0) + 1\n+        self._num_records += 1\n+\n+  def total_count(self):\n+    return self._num_records + self._num_top_records + self._num_bot_records\n+\n+  def p99(self):\n+    return self.get_linear_interpolation(0.99)\n+\n+  def p90(self):\n+    return self.get_linear_interpolation(0.90)\n+\n+  def p50(self):\n+    return self.get_linear_interpolation(0.50)\n+\n+  def get_linear_interpolation(self, percentile):", "originalCommit": "e521d101130af1be236827136c24d3ad15f889fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzMzMjEwMA==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483332100", "bodyText": "done.", "author": "ihji", "createdAt": "2020-09-04T01:12:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExNzg0Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExOTgxNg==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483119816", "bodyText": "Seems like since you don't use the same lock to write here, as you do to record into the histogram. That there can be threads which write to this as you are printing it. Changing the values in the histogram as you are logging.\nYou could fix this by having one call inside the LATENCY_LOGGING_HISTOGRAM which requires the histogram's internal lock returns all the variables you re logging", "author": "ajamato", "createdAt": "2020-09-03T16:49:16Z", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1198,8 +1209,34 @@ def process(self, element, *schema_side_inputs):\n       return self._flush_all_batches()\n \n   def finish_bundle(self):\n+    current_millis = int(time.time() * 1000)\n+    if BigQueryWriteFn.LATENCY_LOGGING_LOCK.acquire(False):\n+      try:\n+        if (BigQueryWriteFn.LATENCY_LOGGING_HISTOGRAM.total_count() > 0 and\n+            (current_millis -\n+             BigQueryWriteFn.LATENCY_LOGGING_LAST_REPORTED_MILLIS) >\n+            self._latency_logging_frequency * 1000):\n+          self._log_percentiles()\n+          BigQueryWriteFn.LATENCY_LOGGING_HISTOGRAM.clear()\n+          BigQueryWriteFn.LATENCY_LOGGING_LAST_REPORTED_MILLIS = current_millis\n+      finally:\n+        BigQueryWriteFn.LATENCY_LOGGING_LOCK.release()\n     return self._flush_all_batches()\n \n+  @classmethod\n+  def _log_percentiles(cls):\n+    # Note that the total count and each percentile value may not be correlated\n+    # each other. Histogram releases lock between each percentile calculation\n+    # so additional latencies could be added anytime.\n+    # pylint: disable=round-builtin\n+    _LOGGER.info(", "originalCommit": "e521d101130af1be236827136c24d3ad15f889fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI4MzY3Mg==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483283672", "bodyText": "Each of the methods has the same lock so the value doesn't change during the single call like p50(). So thread1: p50() -> thread 2: record() -> thread 1: p90() is possible but thread1: p50() + thread2: record() running at the same time is impossible.\nI didn't create and lock the method with multiple percentile calculation because of performance concerns. Also I thought this logging is for informational purpose so small misalignment might be allowable.", "author": "ihji", "createdAt": "2020-09-03T22:18:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExOTgxNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzQ1NzMxMg==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483457312", "bodyText": "Changed to atomic logging with the internal lock.", "author": "ihji", "createdAt": "2020-09-04T08:06:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExOTgxNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEyMjk3Nw==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483122977", "bodyText": "I noticed that you have three calls to time.time(). This is an expensive system call. Is there any way to eliminate this additional usage here? I.e. You could just update the current_millis, in other places where you call time.time().\nThough since this is in finish_bundle, maybe this is fine\nThough see other comment, not sure its wise to do this in finish_bundle. We still need to be careful that we don't starve out the logging. The solution to that may be to log in both finish bundle (always). and after each request (if we have exceeded the logging interval)\n@chamikaramj WDYT?", "author": "ajamato", "createdAt": "2020-09-03T16:54:35Z", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1198,8 +1209,34 @@ def process(self, element, *schema_side_inputs):\n       return self._flush_all_batches()\n \n   def finish_bundle(self):\n+    current_millis = int(time.time() * 1000)", "originalCommit": "e521d101130af1be236827136c24d3ad15f889fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI4ODk5NA==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483288994", "bodyText": "The three calls have their own role. One for remembering request time. One for measuring response time so that we can subtract the start time from the end time. And the last one is for checking log reporting interval.\nWe might slightly reduce the overhead by moving the last time.time() call inside the synchronized block. In that case, the thread that skips the synchronized section won't execute time.time() (probably the saving is small though)", "author": "ihji", "createdAt": "2020-09-03T22:34:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEyMjk3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEyNjUzMQ==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483126531", "bodyText": "Is there a reason why you clear? I think we need to have a good sample of elements over a period of time to a decent latency breakdown. This seems like it will be cleared quite frequently.\nIn the metric case we will just pass it all to stackdriver, and it can basically get these latencies over a sliding window. I.e. at each minute show the 50, 95, 99th percentile latencies for the last 10 minute window.\nIn the logging case, we would like to have something similar. I'm not saying you need to make such a complex calculation to move things in and out of the window.\nThough, maybe this is perfectly fine, for 180 seconds we can probably record a decent number of requests.", "author": "ajamato", "createdAt": "2020-09-03T17:00:34Z", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1198,8 +1209,34 @@ def process(self, element, *schema_side_inputs):\n       return self._flush_all_batches()\n \n   def finish_bundle(self):\n+    current_millis = int(time.time() * 1000)\n+    if BigQueryWriteFn.LATENCY_LOGGING_LOCK.acquire(False):\n+      try:\n+        if (BigQueryWriteFn.LATENCY_LOGGING_HISTOGRAM.total_count() > 0 and\n+            (current_millis -\n+             BigQueryWriteFn.LATENCY_LOGGING_LAST_REPORTED_MILLIS) >\n+            self._latency_logging_frequency * 1000):\n+          self._log_percentiles()\n+          BigQueryWriteFn.LATENCY_LOGGING_HISTOGRAM.clear()", "originalCommit": "e521d101130af1be236827136c24d3ad15f889fd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI4NjMxMQ==", "url": "https://github.com/apache/beam/pull/12754#discussion_r483286311", "bodyText": "Is there a reason why you clear? I think we need to have a good sample of elements over a period of time to a decent latency breakdown. This seems like it will be cleared quite frequently.\n\nThe default interval is 3 minutes so it isn't cleared that frequently. And also the interval is configurable so we could increase it by specifying a pipeline option.\n\nIn the logging case, we would like to have something similar. I'm not saying you need to make such a complex calculation to move things in and out of the window.\n\nYes, it would have been great if we used sliding window for histogram recording. We could improve the histogram object with time awareness in the future.\n\nThough, maybe this is perfectly fine, for 180 seconds we can probably record a decent number of requests.\n\n\ud83d\ude04", "author": "ihji", "createdAt": "2020-09-03T22:26:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEyNjUzMQ=="}], "type": "inlineReview"}, {"oid": "f08762f0c0ed6d4cc6f6306dc4bc997561a22b3c", "url": "https://github.com/apache/beam/commit/f08762f0c0ed6d4cc6f6306dc4bc997561a22b3c", "message": "addressing comments", "committedDate": "2020-09-04T00:14:11Z", "type": "commit"}, {"oid": "ccd5d6bb6d0b50f107071b25d0467390e53615f9", "url": "https://github.com/apache/beam/commit/ccd5d6bb6d0b50f107071b25d0467390e53615f9", "message": "fix tests", "committedDate": "2020-09-04T01:10:07Z", "type": "commit"}, {"oid": "3613ac51c6954b40318e28973d35fff43124853e", "url": "https://github.com/apache/beam/commit/3613ac51c6954b40318e28973d35fff43124853e", "message": "get atomic percentile loggings", "committedDate": "2020-09-04T08:01:45Z", "type": "commit"}, {"oid": "50009a8488e9b190bf05c79d3f4926187353be78", "url": "https://github.com/apache/beam/commit/50009a8488e9b190bf05c79d3f4926187353be78", "message": "add tests", "committedDate": "2020-09-04T08:32:28Z", "type": "commit"}]}