{"pr_number": 10705, "pr_title": "[BEAM-8298] Implement side input caching.", "pr_createdAt": "2020-01-28T19:44:54Z", "pr_url": "https://github.com/apache/beam/pull/10705", "timeline": [{"oid": "203ca10ef26573c98a832f529d1f8e944a1db287", "url": "https://github.com/apache/beam/commit/203ca10ef26573c98a832f529d1f8e944a1db287", "message": "Only cache first page of paginated state.\n\nTo cache the whole thing defeats the purpose of using a continuation token to avoid OOM.", "committedDate": "2020-01-28T19:31:59Z", "type": "commit"}, {"oid": "05d8830b5e0995215d2aa85fc633cdfa1f4c2960", "url": "https://github.com/apache/beam/commit/05d8830b5e0995215d2aa85fc633cdfa1f4c2960", "message": "Perform bundle-level caching if no cache token is given.", "committedDate": "2020-01-28T19:31:59Z", "type": "commit"}, {"oid": "a4929a914fa2f0cc2dd3b690132e3f4a99cde20c", "url": "https://github.com/apache/beam/commit/a4929a914fa2f0cc2dd3b690132e3f4a99cde20c", "message": "[BEAM-8298] Support side input cache tokens.", "committedDate": "2020-01-28T19:43:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjA3NDUxMQ==", "url": "https://github.com/apache/beam/pull/10705#discussion_r372074511", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                \"\"\"Materialized the first page of data, concatinated with a lazy iterable\n          \n          \n            \n                \"\"\"Materialized the first page of data, concatenated with a lazy iterable", "author": "lukecwik", "createdAt": "2020-01-28T21:43:16Z", "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -825,43 +833,92 @@ def extend(self,\n \n   def clear(self, state_key, is_cached=False):\n     # type: (beam_fn_api_pb2.StateKey, bool) -> _Future\n-    if self._should_be_cached(is_cached):\n+    cache_token = self._get_cache_token(state_key, is_cached)\n+    if cache_token:\n       cache_key = self._convert_to_cache_key(state_key)\n-      self._state_cache.clear(cache_key, self._context.cache_token)\n+      self._state_cache.clear(cache_key, cache_token)\n     return self._underlying.clear(state_key)\n \n   def done(self):\n     # type: () -> None\n     self._underlying.done()\n \n-  def _materialize_iter(self,\n-                        state_key,  # type: beam_fn_api_pb2.StateKey\n-                        coder  # type: coder_impl.CoderImpl\n-                       ):\n+  def _lazy_iterator(\n+      self,\n+      state_key,  # type: beam_fn_api_pb2.StateKey\n+      coder,  # type: coder_impl.CoderImpl\n+      continuation_token=None  # type: Optional[bytes]\n+    ):\n     # type: (...) -> Iterator[Any]\n     \"\"\"Materializes the state lazily, one element at a time.\n        :return A generator which returns the next element if advanced.\n     \"\"\"\n-    continuation_token = None\n     while True:\n-      data, continuation_token = \\\n-          self._underlying.get_raw(state_key, continuation_token)\n+      data, continuation_token = (\n+          self._underlying.get_raw(state_key, continuation_token))\n       input_stream = coder_impl.create_InputStream(data)\n       while input_stream.size() > 0:\n         yield coder.decode_from_stream(input_stream, True)\n       if not continuation_token:\n         break\n \n-  def _should_be_cached(self, request_is_cached):\n-    return (self._state_cache.is_cache_enabled() and\n-            request_is_cached and\n-            self._context.cache_token)\n+  def _get_cache_token(self, state_key, request_is_cached):\n+    if not self._state_cache.is_cache_enabled():\n+      return None\n+    elif state_key.HasField('bag_user_state'):\n+      if request_is_cached and self._context.user_state_cache_token:\n+        return self._context.user_state_cache_token\n+      else:\n+        return self._context.bundle_cache_token\n+    elif state_key.WhichOneof('type').endswith('_side_input'):\n+      side_input = getattr(state_key, state_key.WhichOneof('type'))\n+      return self._context.side_input_cache_tokens.get(\n+        (side_input.transform_id, side_input.side_input_id),\n+        self._context.bundle_cache_token)\n+\n+  def _partially_cached_iterable(\n+      self,\n+      state_key,  # type: beam_fn_api_pb2.StateKey\n+      coder  # type: coder_impl.CoderImpl\n+    ):\n+    # type: (...) -> Iterable[Any]\n+    \"\"\"Materialized the first page of data, concatinated with a lazy iterable", "originalCommit": "a4929a914fa2f0cc2dd3b690132e3f4a99cde20c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjA4MDgyOA==", "url": "https://github.com/apache/beam/pull/10705#discussion_r372080828", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                return iter_func()\n          \n          \n            \n                return iter_func", "author": "lukecwik", "createdAt": "2020-01-28T21:56:00Z", "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -825,43 +833,92 @@ def extend(self,\n \n   def clear(self, state_key, is_cached=False):\n     # type: (beam_fn_api_pb2.StateKey, bool) -> _Future\n-    if self._should_be_cached(is_cached):\n+    cache_token = self._get_cache_token(state_key, is_cached)\n+    if cache_token:\n       cache_key = self._convert_to_cache_key(state_key)\n-      self._state_cache.clear(cache_key, self._context.cache_token)\n+      self._state_cache.clear(cache_key, cache_token)\n     return self._underlying.clear(state_key)\n \n   def done(self):\n     # type: () -> None\n     self._underlying.done()\n \n-  def _materialize_iter(self,\n-                        state_key,  # type: beam_fn_api_pb2.StateKey\n-                        coder  # type: coder_impl.CoderImpl\n-                       ):\n+  def _lazy_iterator(\n+      self,\n+      state_key,  # type: beam_fn_api_pb2.StateKey\n+      coder,  # type: coder_impl.CoderImpl\n+      continuation_token=None  # type: Optional[bytes]\n+    ):\n     # type: (...) -> Iterator[Any]\n     \"\"\"Materializes the state lazily, one element at a time.\n        :return A generator which returns the next element if advanced.\n     \"\"\"\n-    continuation_token = None\n     while True:\n-      data, continuation_token = \\\n-          self._underlying.get_raw(state_key, continuation_token)\n+      data, continuation_token = (\n+          self._underlying.get_raw(state_key, continuation_token))\n       input_stream = coder_impl.create_InputStream(data)\n       while input_stream.size() > 0:\n         yield coder.decode_from_stream(input_stream, True)\n       if not continuation_token:\n         break\n \n-  def _should_be_cached(self, request_is_cached):\n-    return (self._state_cache.is_cache_enabled() and\n-            request_is_cached and\n-            self._context.cache_token)\n+  def _get_cache_token(self, state_key, request_is_cached):\n+    if not self._state_cache.is_cache_enabled():\n+      return None\n+    elif state_key.HasField('bag_user_state'):\n+      if request_is_cached and self._context.user_state_cache_token:\n+        return self._context.user_state_cache_token\n+      else:\n+        return self._context.bundle_cache_token\n+    elif state_key.WhichOneof('type').endswith('_side_input'):\n+      side_input = getattr(state_key, state_key.WhichOneof('type'))\n+      return self._context.side_input_cache_tokens.get(\n+        (side_input.transform_id, side_input.side_input_id),\n+        self._context.bundle_cache_token)\n+\n+  def _partially_cached_iterable(\n+      self,\n+      state_key,  # type: beam_fn_api_pb2.StateKey\n+      coder  # type: coder_impl.CoderImpl\n+    ):\n+    # type: (...) -> Iterable[Any]\n+    \"\"\"Materialized the first page of data, concatinated with a lazy iterable\n+    of the rest, if any.\n+    \"\"\"\n+    data, continuation_token = (\n+            self._underlying.get_raw(state_key, None))\n+    head = []\n+    input_stream = coder_impl.create_InputStream(data)\n+    while input_stream.size() > 0:\n+      head.append(coder.decode_from_stream(input_stream, True))\n+\n+    if continuation_token is None:\n+      return head\n+    else:\n+      def iter_func():\n+        for item in head:\n+          yield item\n+        for item in self._lazy_iterator(state_key, coder, continuation_token):\n+          yield item\n+      return _IterableFromIterator(iter_func)\n \n   @staticmethod\n   def _convert_to_cache_key(state_key):\n     return state_key.SerializeToString()\n \n \n+class _IterableFromIterator(object):\n+  \"\"\"Wraps an iterator as an iterable.\"\"\"\n+  def __init__(self, iter_func):\n+    self._iter_func = iter_func\n+  def __iter__(self):\n+    return iter_func()", "originalCommit": "a4929a914fa2f0cc2dd3b690132e3f4a99cde20c", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "f776da4ca40e1b52c409f3893d70d39b8a8334fa", "url": "https://github.com/apache/beam/commit/f776da4ca40e1b52c409f3893d70d39b8a8334fa", "message": "fix continuation token iter", "committedDate": "2020-01-29T02:26:08Z", "type": "commit"}, {"oid": "8e30655bd56da5d885357517c5898663936a0578", "url": "https://github.com/apache/beam/commit/8e30655bd56da5d885357517c5898663936a0578", "message": "lint for side input tokens", "committedDate": "2020-01-29T02:26:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjI3NTQyMQ==", "url": "https://github.com/apache/beam/pull/10705#discussion_r372275421", "bodyText": "Bundle caching for get requests is a good improvement.", "author": "mxm", "createdAt": "2020-01-29T09:36:28Z", "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -759,50 +759,57 @@ def __init__(self,\n \n   @contextlib.contextmanager\n   def process_instruction_id(self, bundle_id, cache_tokens):\n-    if getattr(self._context, 'cache_token', None) is not None:\n+    if getattr(self._context, 'user_state_cache_token', None) is not None:\n       raise RuntimeError(\n-          'Cache tokens already set to %s' % self._context.cache_token)\n-    # TODO Also handle cache tokens for side input, if present:\n-    # https://issues.apache.org/jira/browse/BEAM-8298\n+          'Cache tokens already set to %s'\n+          % self._context.user_state_cache_token)\n+    self._context.side_input_cache_tokens = {}\n     user_state_cache_token = None\n     for cache_token_struct in cache_tokens:\n       if cache_token_struct.HasField(\"user_state\"):\n         # There should only be one user state token present\n         assert not user_state_cache_token\n         user_state_cache_token = cache_token_struct.token\n+      elif cache_token_struct.HasField(\"side_input\"):\n+        self._context.side_input_cache_tokens[\n+            cache_token_struct.side_input.transform_id,\n+            cache_token_struct.side_input.side_input_id\n+        ] = cache_token_struct.token\n+    self._context.bundle_cache_token = bundle_id", "originalCommit": "8e30655bd56da5d885357517c5898663936a0578", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjI3NTk2OA==", "url": "https://github.com/apache/beam/pull/10705#discussion_r372275968", "bodyText": "AFAIK Continuation tokens are not implemented but it's good we support this now.", "author": "mxm", "createdAt": "2020-01-29T09:37:35Z", "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -825,43 +833,92 @@ def extend(self,\n \n   def clear(self, state_key, is_cached=False):\n     # type: (beam_fn_api_pb2.StateKey, bool) -> _Future\n-    if self._should_be_cached(is_cached):\n+    cache_token = self._get_cache_token(state_key, is_cached)\n+    if cache_token:\n       cache_key = self._convert_to_cache_key(state_key)\n-      self._state_cache.clear(cache_key, self._context.cache_token)\n+      self._state_cache.clear(cache_key, cache_token)\n     return self._underlying.clear(state_key)\n \n   def done(self):\n     # type: () -> None\n     self._underlying.done()\n \n-  def _materialize_iter(self,\n-                        state_key,  # type: beam_fn_api_pb2.StateKey\n-                        coder  # type: coder_impl.CoderImpl\n-                       ):\n+  def _lazy_iterator(\n+      self,\n+      state_key,  # type: beam_fn_api_pb2.StateKey\n+      coder,  # type: coder_impl.CoderImpl\n+      continuation_token=None  # type: Optional[bytes]\n+    ):\n     # type: (...) -> Iterator[Any]\n     \"\"\"Materializes the state lazily, one element at a time.\n        :return A generator which returns the next element if advanced.\n     \"\"\"\n-    continuation_token = None\n     while True:\n-      data, continuation_token = \\\n-          self._underlying.get_raw(state_key, continuation_token)\n+      data, continuation_token = (\n+          self._underlying.get_raw(state_key, continuation_token))\n       input_stream = coder_impl.create_InputStream(data)\n       while input_stream.size() > 0:\n         yield coder.decode_from_stream(input_stream, True)\n       if not continuation_token:\n         break\n \n-  def _should_be_cached(self, request_is_cached):\n-    return (self._state_cache.is_cache_enabled() and\n-            request_is_cached and\n-            self._context.cache_token)\n+  def _get_cache_token(self, state_key, request_is_cached):\n+    if not self._state_cache.is_cache_enabled():\n+      return None\n+    elif state_key.HasField('bag_user_state'):\n+      if request_is_cached and self._context.user_state_cache_token:\n+        return self._context.user_state_cache_token\n+      else:\n+        return self._context.bundle_cache_token\n+    elif state_key.WhichOneof('type').endswith('_side_input'):\n+      side_input = getattr(state_key, state_key.WhichOneof('type'))\n+      return self._context.side_input_cache_tokens.get(\n+          (side_input.transform_id, side_input.side_input_id),\n+          self._context.bundle_cache_token)\n+\n+  def _partially_cached_iterable(\n+      self,\n+      state_key,  # type: beam_fn_api_pb2.StateKey\n+      coder  # type: coder_impl.CoderImpl\n+    ):\n+    # type: (...) -> Iterable[Any]\n+    \"\"\"Materialized the first page of data, concatenated with a lazy iterable\n+    of the rest, if any.\n+    \"\"\"\n+    data, continuation_token = self._underlying.get_raw(state_key, None)\n+    head = []\n+    input_stream = coder_impl.create_InputStream(data)\n+    while input_stream.size() > 0:\n+      head.append(coder.decode_from_stream(input_stream, True))\n+\n+    if continuation_token is None:\n+      return head\n+    else:\n+      def iter_func():", "originalCommit": "8e30655bd56da5d885357517c5898663936a0578", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjI3NzA0Ng==", "url": "https://github.com/apache/beam/pull/10705#discussion_r372277046", "bodyText": "The combined use of (state_key, cache_token) simplifies the lookup. Thanks for fixing this.", "author": "mxm", "createdAt": "2020-01-29T09:39:40Z", "path": "sdks/python/apache_beam/runners/worker/statecache.py", "diffHunk": "@@ -148,47 +148,43 @@ class StateCache(object):\n \n   def __init__(self, max_entries):\n     _LOGGER.info('Creating state cache with size %s', max_entries)\n-    self._cache = self.LRUCache(max_entries, (None, None))\n+    self._missing = None\n+    self._cache = self.LRUCache(max_entries, self._missing)\n     self._lock = threading.RLock()\n     self._metrics = Metrics()\n \n   @Metrics.counter_hit_miss(\"get\", \"hit\", \"miss\")\n   def get(self, state_key, cache_token):\n     assert cache_token and self.is_cache_enabled()\n     with self._lock:\n-      token, value = self._cache.get(state_key)\n-    return value if token == cache_token else None\n+      return self._cache.get((state_key, cache_token))\n \n   @Metrics.counter(\"put\")\n   def put(self, state_key, cache_token, value):\n     assert cache_token and self.is_cache_enabled()\n     with self._lock:\n-      return self._cache.put(state_key, (cache_token, value))\n+      return self._cache.put((state_key, cache_token), value)", "originalCommit": "8e30655bd56da5d885357517c5898663936a0578", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "cd58afe37f08140a6c6cf3ca7c43122cca8e3186", "url": "https://github.com/apache/beam/commit/cd58afe37f08140a6c6cf3ca7c43122cca8e3186", "message": "Fix state cache test.\n\nWe now support multiple cache tokens per state key,\nso this required some changes to the test.", "committedDate": "2020-01-29T20:50:05Z", "type": "commit"}, {"oid": "dacdb88797dcef2953c17cc96cfbeab6d1093b1a", "url": "https://github.com/apache/beam/commit/dacdb88797dcef2953c17cc96cfbeab6d1093b1a", "message": "TODO about two-level caching.", "committedDate": "2020-01-29T20:50:46Z", "type": "commit"}, {"oid": "3cf830598b92f8e89a24d816769fcfab9fae192e", "url": "https://github.com/apache/beam/commit/3cf830598b92f8e89a24d816769fcfab9fae192e", "message": "CachingStateHandler unit test.", "committedDate": "2020-01-29T20:51:12Z", "type": "commit"}, {"oid": "2a869c267b12959bb6bba7357ee736c9ad6f1453", "url": "https://github.com/apache/beam/commit/2a869c267b12959bb6bba7357ee736c9ad6f1453", "message": "test lint", "committedDate": "2020-01-30T20:17:44Z", "type": "commit"}, {"oid": "9c99c882bd04383e270ce66cb2dc6579b4e40a57", "url": "https://github.com/apache/beam/commit/9c99c882bd04383e270ce66cb2dc6579b4e40a57", "message": "Fix extending non-list.", "committedDate": "2020-01-30T20:23:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzE4Njg3NQ==", "url": "https://github.com/apache/beam/pull/10705#discussion_r373186875", "bodyText": "Nice.", "author": "lukecwik", "createdAt": "2020-01-30T20:51:37Z", "path": "sdks/python/apache_beam/runners/worker/sdk_worker_test.py", "diffHunk": "@@ -115,6 +118,116 @@ def test_fn_registration(self):\n     self._check_fn_registration_multi_request((1, 4), (4, 4))\n \n \n+class CachingStateHandlerTest(unittest.TestCase):", "originalCommit": "9c99c882bd04383e270ce66cb2dc6579b4e40a57", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "3b4b1cb3b656516463d7b9e7dd155f24ab92542a", "url": "https://github.com/apache/beam/commit/3b4b1cb3b656516463d7b9e7dd155f24ab92542a", "message": "Fix flink counters test.\n\nThere are additional cache hits and misses now that we cache at the bundle\nlevel when explicit cache tokens are not given.\n\nAlso make the test easier to debug.", "committedDate": "2020-01-31T00:33:40Z", "type": "commit"}]}