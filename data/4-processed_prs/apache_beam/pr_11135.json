{"pr_number": 11135, "pr_title": "Add spark structured streaming runner to load tests", "pr_createdAt": "2020-03-16T07:48:44Z", "pr_url": "https://github.com/apache/beam/pull/11135", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg0ODA4MA==", "url": "https://github.com/apache/beam/pull/11135#discussion_r392848080", "bodyText": "Not sure if this should be in separate file or together with other test cases in  job__LoadTests_GBK_Java.grooy", "author": "lgajowy", "createdAt": "2020-03-16T08:21:41Z", "path": ".test-infra/jenkins/job_LoadTests_GBK_Java_spark_structured_streaming.groovy", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import CommonJobProperties as commonJobProperties\n+import CommonTestProperties\n+import LoadTestsBuilder as loadTestsBuilder\n+import PhraseTriggeringPostCommitBuilder\n+\n+def loadTestConfigurations = { mode, isStreaming, datasetName ->", "originalCommit": "d64e82471d2891252501103ce070a11c6e7d89b5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg0ODE1Mw==", "url": "https://github.com/apache/beam/pull/11135#discussion_r392848153", "bodyText": "@mwalenia could you confirm?", "author": "lgajowy", "createdAt": "2020-03-16T08:21:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg0ODA4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg2NTIzMQ==", "url": "https://github.com/apache/beam/pull/11135#discussion_r392865231", "bodyText": "as the java test file contained only dataflow tests, I separated spark but sure I can merge. Waiting for the answer", "author": "echauchot", "createdAt": "2020-03-16T08:56:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg0ODA4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg5NTE3MQ==", "url": "https://github.com/apache/beam/pull/11135#discussion_r392895171", "bodyText": "I think we can split the job definitions runner-wise into files, that way the files won't get too bloated", "author": "mwalenia", "createdAt": "2020-03-16T09:51:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg0ODA4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5MDkyOA==", "url": "https://github.com/apache/beam/pull/11135#discussion_r395290928", "bodyText": "I'm fine with both options then.", "author": "lgajowy", "createdAt": "2020-03-19T20:09:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg0ODA4MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg1MDEwMA==", "url": "https://github.com/apache/beam/pull/11135#discussion_r392850100", "bodyText": "should this be false?", "author": "lgajowy", "createdAt": "2020-03-16T08:25:49Z", "path": ".test-infra/jenkins/job_LoadTests_GBK_Java_spark_structured_streaming.groovy", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import CommonJobProperties as commonJobProperties\n+import CommonTestProperties\n+import LoadTestsBuilder as loadTestsBuilder\n+import PhraseTriggeringPostCommitBuilder\n+\n+def loadTestConfigurations = { mode, isStreaming, datasetName ->\n+    [\n+            [\n+                    title          : 'Load test: 2GB of 10B records',\n+                    test           : 'org.apache.beam.sdk.loadtests.GroupByKeyLoadTest',\n+                    runner         : CommonTestProperties.Runner.SPARK_STRUCTURED_STREAMING,\n+                    pipelineOptions: [\n+                            project               : 'apache-beam-testing',\n+                            appName               : \"load_tests_Java_SparkStructuredStreaming_${mode}_GBK_1\",\n+                            tempLocation          : 'gs://temp-storage-for-perf-tests/loadtests',\n+                            publishToBigQuery     : false,", "originalCommit": "d64e82471d2891252501103ce070a11c6e7d89b5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg2MDY1MA==", "url": "https://github.com/apache/beam/pull/11135#discussion_r392860650", "bodyText": "This was for testing at first but, sure I can put true", "author": "echauchot", "createdAt": "2020-03-16T08:47:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg1MDEwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5MDQzOA==", "url": "https://github.com/apache/beam/pull/11135#discussion_r395290438", "bodyText": "Let's put true then. :)", "author": "lgajowy", "createdAt": "2020-03-19T20:08:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg1MDEwMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTM3ODg1Ng==", "url": "https://github.com/apache/beam/pull/11135#discussion_r405378856", "bodyText": "done", "author": "echauchot", "createdAt": "2020-04-08T09:16:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg1MDEwMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg1MDgwNg==", "url": "https://github.com/apache/beam/pull/11135#discussion_r392850806", "bodyText": "This runs only when we type Run load test... in the comment. Should we add the Cron-trigged version?", "author": "lgajowy", "createdAt": "2020-03-16T08:27:12Z", "path": ".test-infra/jenkins/job_LoadTests_GBK_Java_spark_structured_streaming.groovy", "diffHunk": "@@ -0,0 +1,208 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import CommonJobProperties as commonJobProperties\n+import CommonTestProperties\n+import LoadTestsBuilder as loadTestsBuilder\n+import PhraseTriggeringPostCommitBuilder\n+\n+def loadTestConfigurations = { mode, isStreaming, datasetName ->\n+    [\n+            [\n+                    title          : 'Load test: 2GB of 10B records',\n+                    test           : 'org.apache.beam.sdk.loadtests.GroupByKeyLoadTest',\n+                    runner         : CommonTestProperties.Runner.SPARK_STRUCTURED_STREAMING,\n+                    pipelineOptions: [\n+                            project               : 'apache-beam-testing',\n+                            appName               : \"load_tests_Java_SparkStructuredStreaming_${mode}_GBK_1\",\n+                            tempLocation          : 'gs://temp-storage-for-perf-tests/loadtests',\n+                            publishToBigQuery     : false,\n+                            bigQueryDataset       : datasetName,\n+                            bigQueryTable         : \"java_sparkstructuredstreaming_${mode}_GBK_1\",\n+                            sourceOptions         : \"\"\"\n+                                            {\n+                                              \"numRecords\": 200000000,\n+                                              \"keySizeBytes\": 1,\n+                                              \"valueSizeBytes\": 9\n+                                            }\n+                                       \"\"\".trim().replaceAll(\"\\\\s\", \"\"),\n+                            fanout                : 1,\n+                            iterations            : 1,\n+                            streaming             : isStreaming\n+                    ]\n+            ],\n+            [\n+                    title          : 'Load test: 2GB of 100B records',\n+                    test           : 'org.apache.beam.sdk.loadtests.GroupByKeyLoadTest',\n+                    runner         : CommonTestProperties.Runner.SPARK_STRUCTURED_STREAMING,\n+                    pipelineOptions: [\n+                            project               : 'apache-beam-testing',\n+                            appName               : \"load_tests_Java_SparkStructuredStreaming_${mode}_GBK_2\",\n+                            tempLocation          : 'gs://temp-storage-for-perf-tests/loadtests',\n+                            publishToBigQuery     : false,\n+                            bigQueryDataset       : datasetName,\n+                            bigQueryTable         : \"java_SparkStructuredStreaming_${mode}_GBK_2\",\n+                            sourceOptions         : \"\"\"\n+                                            {\n+                                              \"numRecords\": 20000000,\n+                                              \"keySizeBytes\": 10,\n+                                              \"valueSizeBytes\": 90\n+                                            }\n+                                       \"\"\".trim().replaceAll(\"\\\\s\", \"\"),\n+                            fanout                : 1,\n+                            iterations            : 1,\n+                            streaming             : isStreaming\n+                    ]\n+            ],\n+            [\n+\n+                    title          : 'Load test: 2GB of 100kB records',\n+                    test           : 'org.apache.beam.sdk.loadtests.GroupByKeyLoadTest',\n+                    runner         : CommonTestProperties.Runner.SPARK_STRUCTURED_STREAMING,\n+                    pipelineOptions: [\n+                            project               : 'apache-beam-testing',\n+                            appName               : \"load_tests_Java_SparkStructuredStreaming_${mode}_GBK_3\",\n+                            tempLocation          : 'gs://temp-storage-for-perf-tests/loadtests',\n+                            publishToBigQuery     : false,\n+                            bigQueryDataset       : datasetName,\n+                            bigQueryTable         : \"java_SparkStructuredStreaming_${mode}_GBK_3\",\n+                            sourceOptions         : \"\"\"\n+                                            {\n+                                              \"numRecords\": 20000,\n+                                              \"keySizeBytes\": 10000,\n+                                              \"valueSizeBytes\": 90000\n+                                            }\n+                                       \"\"\".trim().replaceAll(\"\\\\s\", \"\"),\n+                            fanout                : 1,\n+                            iterations            : 1,\n+                            streaming             : isStreaming\n+                    ]\n+\n+            ],\n+            [\n+                    title          : 'Load test: fanout 4 times with 2GB 10-byte records total',\n+                    test           : 'org.apache.beam.sdk.loadtests.GroupByKeyLoadTest',\n+                    runner         : CommonTestProperties.Runner.SPARK_STRUCTURED_STREAMING,\n+                    pipelineOptions: [\n+                            project               : 'apache-beam-testing',\n+                            appName               : 'load_tests_Java_SparkStructuredStreaming_${mode}_GBK_4',\n+                            tempLocation          : 'gs://temp-storage-for-perf-tests/loadtests',\n+                            publishToBigQuery     : false,\n+                            bigQueryDataset       : datasetName,\n+                            bigQueryTable         : \"java_SparkStructuredStreaming_${mode}_GBK_4\",\n+                            sourceOptions         : \"\"\"\n+                                            {\n+                                              \"numRecords\": 5000000,\n+                                              \"keySizeBytes\": 10,\n+                                              \"valueSizeBytes\": 90\n+                                            }\n+                                       \"\"\".trim().replaceAll(\"\\\\s\", \"\"),\n+                            fanout                : 4,\n+                            iterations            : 1,\n+                            streaming             : isStreaming\n+                    ]\n+            ],\n+            [\n+                    title          : 'Load test: fanout 8 times with 2GB 10-byte records total',\n+                    test           : 'org.apache.beam.sdk.loadtests.GroupByKeyLoadTest',\n+                    runner         : CommonTestProperties.Runner.SPARK_STRUCTURED_STREAMING,\n+                    pipelineOptions: [\n+                            project               : 'apache-beam-testing',\n+                            appName               : \"load_tests_Java_SparkStructuredStreaming_${mode}_GBK_5\",\n+                            tempLocation          : 'gs://temp-storage-for-perf-tests/loadtests',\n+                            publishToBigQuery     : false,\n+                            bigQueryDataset       : datasetName,\n+                            bigQueryTable         : \"java_SparkStructuredStreaming_${mode}_GBK_5\",\n+                            sourceOptions         : \"\"\"\n+                                            {\n+                                              \"numRecords\": 2500000,\n+                                              \"keySizeBytes\": 10,\n+                                              \"valueSizeBytes\": 90\n+                                            }\n+                                       \"\"\".trim().replaceAll(\"\\\\s\", \"\"),\n+                            fanout                : 8,\n+                            iterations            : 1,\n+                            streaming             : isStreaming\n+                    ]\n+            ],\n+            [\n+                    title          : 'Load test: reiterate 4 times 10kB values',\n+                    test           : 'org.apache.beam.sdk.loadtests.GroupByKeyLoadTest',\n+                    runner         : CommonTestProperties.Runner.SPARK_STRUCTURED_STREAMING,\n+                    pipelineOptions: [\n+                            project               : 'apache-beam-testing',\n+                            appName               : \"load_tests_Java_SparkStructuredStreaming_${mode}_GBK_6\",\n+                            tempLocation          : 'gs://temp-storage-for-perf-tests/loadtests',\n+                            publishToBigQuery     : false,\n+                            bigQueryDataset       : datasetName,\n+                            bigQueryTable         : \"java_SparkStructuredStreaming_${mode}_GBK_6\",\n+                            sourceOptions         : \"\"\"\n+                                            {\n+                                              \"numRecords\": 20000000,\n+                                              \"keySizeBytes\": 10,\n+                                              \"valueSizeBytes\": 90,\n+                                              \"numHotKeys\": 200,\n+                                              \"hotKeyFraction\": 1\n+                                            }\n+                                       \"\"\".trim().replaceAll(\"\\\\s\", \"\"),\n+                            fanout                : 1,\n+                            iterations            : 4,\n+                            streaming             : isStreaming\n+                    ]\n+            ],\n+            [\n+                    title          : 'Load test: reiterate 4 times 2MB values',\n+                    test           : 'org.apache.beam.sdk.loadtests.GroupByKeyLoadTest',\n+                    runner         : CommonTestProperties.Runner.SPARK_STRUCTURED_STREAMING,\n+                    pipelineOptions: [\n+                            project               : 'apache-beam-testing',\n+                            appName               : \"load_tests_Java_SparkStructuredStreaming_${mode}_GBK_7\",\n+                            tempLocation          : 'gs://temp-storage-for-perf-tests/loadtests',\n+                            publishToBigQuery     : false,\n+                            bigQueryDataset       : datasetName,\n+                            bigQueryTable         : \"java_SparkStructuredStreaming_${mode}_GBK_7\",\n+                            sourceOptions         : \"\"\"\n+                                            {\n+                                              \"numRecords\": 20000000,\n+                                              \"keySizeBytes\": 10,\n+                                              \"valueSizeBytes\": 90,\n+                                              \"numHotKeys\": 10,\n+                                              \"hotKeyFraction\": 1\n+                                            }\n+                                       \"\"\".trim().replaceAll(\"\\\\s\", \"\"),\n+                            fanout                : 1,\n+                            iterations            : 4,\n+                            streaming             : isStreaming\n+                    ]\n+            ]\n+    ]\n+}\n+\n+def batchLoadTestJob = { scope, triggeringContext ->\n+    def datasetName = loadTestsBuilder.getBigQueryDataset('load_test', triggeringContext)\n+    loadTestsBuilder.loadTests(scope, CommonTestProperties.SDK.JAVA, loadTestConfigurations('batch', false, datasetName), \"GBK\", \"batch\")\n+}\n+\n+PhraseTriggeringPostCommitBuilder.postCommitJob(", "originalCommit": "d64e82471d2891252501103ce070a11c6e7d89b5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg2MTIyMg==", "url": "https://github.com/apache/beam/pull/11135#discussion_r392861222", "bodyText": "same as above ;)", "author": "echauchot", "createdAt": "2020-03-16T08:48:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg1MDgwNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTM3ODk3MA==", "url": "https://github.com/apache/beam/pull/11135#discussion_r405378970", "bodyText": "cron added", "author": "echauchot", "createdAt": "2020-04-08T09:16:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg1MDgwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg1MjAyOA==", "url": "https://github.com/apache/beam/pull/11135#discussion_r392852028", "bodyText": "I'm not really sure if \"smoke\" tests are used by anyone tbh. If not, I wouldn't bother adding new scenarios here and propose to create an issue to remove smoke tests (unused code, unused jobs). If however they are used then pls ignore this comment :)\n@mwalenia could you confirm what is the case here?", "author": "lgajowy", "createdAt": "2020-03-16T08:29:52Z", "path": ".test-infra/jenkins/job_LoadTests_GBK_Java_Smoke.groovy", "diffHunk": "@@ -79,7 +79,23 @@ def smokeTestConfigurations = { datasetName -> [\n                         fanout           : 10,\n                         iterations       : 1,\n                 ]\n+        ],", "originalCommit": "d64e82471d2891252501103ce070a11c6e7d89b5", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg2MTQ2Nw==", "url": "https://github.com/apache/beam/pull/11135#discussion_r392861467", "bodyText": "ok waiting for the confirmation that it is useless", "author": "echauchot", "createdAt": "2020-03-16T08:48:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg1MjAyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg4Mzg3Mg==", "url": "https://github.com/apache/beam/pull/11135#discussion_r392883872", "bodyText": "Jenkins logs show that nobody uses the smoke tests, I don't think it's worth the hassle to add more of them", "author": "mwalenia", "createdAt": "2020-03-16T09:31:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg1MjAyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI5MDA3Ng==", "url": "https://github.com/apache/beam/pull/11135#discussion_r395290076", "bodyText": "So I suggest to remove this part @echauchot. :)\nand the issue: https://issues.apache.org/jira/browse/BEAM-9559", "author": "lgajowy", "createdAt": "2020-03-19T20:07:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg1MjAyOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTM4NTQyMw==", "url": "https://github.com/apache/beam/pull/11135#discussion_r405385423", "bodyText": "ok, I reverted the cahnge that added the smoke tests. I did not touch to other runners smoke tests, just in case.", "author": "echauchot", "createdAt": "2020-04-08T09:26:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mjg1MjAyOA=="}], "type": "inlineReview"}, {"oid": "dac4758f1313154e87063b48773eeb2a8d568f3d", "url": "https://github.com/apache/beam/commit/dac4758f1313154e87063b48773eeb2a8d568f3d", "message": "Revert \"Add spark structured streaming runner to GBK smoke load tests script\"\n\nThis reverts commit d64e8247", "committedDate": "2020-04-08T09:28:45Z", "type": "forcePushed"}, {"oid": "d5701b19e5d18ca24107fb5afa0b7d3925b74230", "url": "https://github.com/apache/beam/commit/d5701b19e5d18ca24107fb5afa0b7d3925b74230", "message": "Add Pardo load tests script for spark structured streaming runner", "committedDate": "2020-04-10T08:23:56Z", "type": "forcePushed"}, {"oid": "289cb6657174980c267d94f5d0f6ebd791f0a62d", "url": "https://github.com/apache/beam/commit/289cb6657174980c267d94f5d0f6ebd791f0a62d", "message": "Add GBK load tests script for spark structured streaming runner", "committedDate": "2020-04-16T07:38:30Z", "type": "commit"}, {"oid": "210658af474541b293a25ef35fef5ff9a0490a1f", "url": "https://github.com/apache/beam/commit/210658af474541b293a25ef35fef5ff9a0490a1f", "message": "Add CoGBK load tests script for spark structured streaming runner", "committedDate": "2020-04-16T07:38:30Z", "type": "commit"}, {"oid": "1709a6b0a1dc7a0a5f467f019bc96a9bd4b43ea6", "url": "https://github.com/apache/beam/commit/1709a6b0a1dc7a0a5f467f019bc96a9bd4b43ea6", "message": "Add Combine load tests script for spark structured streaming runner", "committedDate": "2020-04-16T07:38:30Z", "type": "commit"}, {"oid": "8a14cf0a394567a2b2772abce7aa0eaba9345b43", "url": "https://github.com/apache/beam/commit/8a14cf0a394567a2b2772abce7aa0eaba9345b43", "message": "Add Pardo load tests script for spark structured streaming runner", "committedDate": "2020-04-16T07:38:30Z", "type": "commit"}, {"oid": "8a14cf0a394567a2b2772abce7aa0eaba9345b43", "url": "https://github.com/apache/beam/commit/8a14cf0a394567a2b2772abce7aa0eaba9345b43", "message": "Add Pardo load tests script for spark structured streaming runner", "committedDate": "2020-04-16T07:38:30Z", "type": "forcePushed"}]}