{"pr_number": 12670, "pr_title": "[BEAM-5757] Add ElasticsearchIO: delete document support", "pr_createdAt": "2020-08-23T14:10:32Z", "pr_url": "https://github.com/apache/beam/pull/12670", "timeline": [{"oid": "2f1329404413b959e9f62f003fc3fe2cf469df50", "url": "https://github.com/apache/beam/commit/2f1329404413b959e9f62f003fc3fe2cf469df50", "message": "[BEAM-5757] Add ElasticsearchIO: delete document support", "committedDate": "2020-08-23T14:07:59Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYxMzgwNQ==", "url": "https://github.com/apache/beam/pull/12670#discussion_r482613805", "bodyText": "Not really your problem but this is my first time looking at these tests, and this structure tests seems really odd to me. It looks like we could get rid of a lof of duplicate code if we just implemented both ElasticsearchIOIT and ElasticsearchIOTest  in elasticsearch common, then the implementations for each version could inherit from those with an (almost) empty implementation.\nAgain, not asking to do anything here, but I might try to tackle this myself, let me know if you think that's not possible.", "author": "TheNeuralBit", "createdAt": "2020-09-03T00:21:27Z", "path": "sdks/java/io/elasticsearch-tests/elasticsearch-tests-2/src/test/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIOIT.java", "diffHunk": "@@ -140,4 +140,38 @@ public void testWritePartialUpdate() throws Exception {\n     elasticsearchIOTestCommonUpdate.setPipeline(pipeline);\n     elasticsearchIOTestCommonUpdate.testWritePartialUpdate();\n   }\n+\n+  /**\n+   * This test verifies volume deletes of Elasticsearch. The test dataset index is cloned and then\n+   * around half of the documents are deleted and the other half is partially updated using bulk\n+   * delete request. The test then asserts the documents were deleted successfully.\n+   */\n+  @Test\n+  public void testWriteWithIsDeletedFnWithPartialUpdates() throws Exception {\n+    ElasticsearchIOTestUtils.copyIndex(\n+        restClient,\n+        readConnectionConfiguration.getIndex(),\n+        updateConnectionConfiguration.getIndex());\n+    ElasticsearchIOTestCommon elasticsearchIOTestCommonDeleteFn =\n+        new ElasticsearchIOTestCommon(updateConnectionConfiguration, restClient, true);\n+    elasticsearchIOTestCommonDeleteFn.setPipeline(pipeline);\n+    elasticsearchIOTestCommonDeleteFn.testWriteWithIsDeletedFnWithPartialUpdates();\n+  }\n+\n+  /**\n+   * This test verifies volume deletes of Elasticsearch. The test dataset index is cloned and then\n+   * around half of the documents are deleted using bulk delete request. The test then asserts the\n+   * documents were deleted successfully.\n+   */\n+  @Test\n+  public void testWriteWithIsDeletedFnWithoutPartialUpdate() throws Exception {\n+    ElasticsearchIOTestUtils.copyIndex(\n+        restClient,\n+        readConnectionConfiguration.getIndex(),\n+        updateConnectionConfiguration.getIndex());\n+    ElasticsearchIOTestCommon elasticsearchIOTestCommonDeleteFn =\n+        new ElasticsearchIOTestCommon(updateConnectionConfiguration, restClient, true);\n+    elasticsearchIOTestCommonDeleteFn.setPipeline(pipeline);\n+    elasticsearchIOTestCommonDeleteFn.testWriteWithIsDeletedFnWithoutPartialUpdate();\n+  }", "originalCommit": "2f1329404413b959e9f62f003fc3fe2cf469df50", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjg1OTc2Mw==", "url": "https://github.com/apache/beam/pull/12670#discussion_r482859763", "bodyText": "Hi @TheNeuralBit I am also new to the Apache Beam code base \ud83d\ude05. But I also think there is a good opportunity to remove duplicate codes.", "author": "jithin-sukumar", "createdAt": "2020-09-03T10:00:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYxMzgwNQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYyMjMyOQ==", "url": "https://github.com/apache/beam/pull/12670#discussion_r482622329", "bodyText": "Could we instead just verify that IdFn is specified whenever DeleteFn is specified? Then we could move this check out to Write#expand and raise an exception when constructing the pipeline, rather than when it's executing. WDYT?", "author": "TheNeuralBit", "createdAt": "2020-09-03T00:39:57Z", "path": "sdks/java/io/elasticsearch/src/main/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIO.java", "diffHunk": "@@ -1346,17 +1359,36 @@ private static String lowerCaseOrNull(String input) {\n \n       @ProcessElement\n       public void processElement(ProcessContext context) throws Exception {\n-        String document = context.element();\n-        String documentMetadata = getDocumentMetadata(document);\n-\n-        // index is an insert/upsert and update is a partial update (or insert if not existing)\n-        if (spec.getUsePartialUpdate()) {\n-          batch.add(\n-              String.format(\n-                  \"{ \\\"update\\\" : %s }%n{ \\\"doc\\\" : %s, \\\"doc_as_upsert\\\" : true }%n\",\n-                  documentMetadata, document));\n+        String document = context.element(); // use configuration and auto-generated document IDs\n+        String documentMetadata = \"{}\";\n+        boolean isDelete = false;\n+        if (spec.getIndexFn() != null || spec.getTypeFn() != null || spec.getIdFn() != null) {\n+          // parse once and reused for efficiency\n+          JsonNode parsedDocument = OBJECT_MAPPER.readTree(document);\n+          documentMetadata = getDocumentMetadata(parsedDocument);\n+          if (spec.getIsDeleteFn() != null) {\n+            isDelete = spec.getIsDeleteFn().apply(parsedDocument);\n+            // if it is a delete opration, then it is mandatory to specify the document id using\n+            // getIdFn\n+            checkArgument(\n+                !(isDelete && spec.getIdFn() == null),\n+                \"Id needs to be specified by withIdFn for delete operation\");", "originalCommit": "2f1329404413b959e9f62f003fc3fe2cf469df50", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjg2MDYxNA==", "url": "https://github.com/apache/beam/pull/12670#discussion_r482860614", "bodyText": "Yes, I think that is a better way to handle it. I fixed it.\nThanks.", "author": "jithin-sukumar", "createdAt": "2020-09-03T10:01:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYyMjMyOQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYyMzUyOA==", "url": "https://github.com/apache/beam/pull/12670#discussion_r482623528", "bodyText": "nit: I'd probably write this the other way so we don't have to reason about the double-negative:\nif (isDelete) {\n  // do a delete\n} else {\n  // do an insert/upsert\n}\nBut that's a big nit, feel free to leave it this way if you prefer.", "author": "TheNeuralBit", "createdAt": "2020-09-03T00:44:50Z", "path": "sdks/java/io/elasticsearch/src/main/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIO.java", "diffHunk": "@@ -1346,17 +1359,36 @@ private static String lowerCaseOrNull(String input) {\n \n       @ProcessElement\n       public void processElement(ProcessContext context) throws Exception {\n-        String document = context.element();\n-        String documentMetadata = getDocumentMetadata(document);\n-\n-        // index is an insert/upsert and update is a partial update (or insert if not existing)\n-        if (spec.getUsePartialUpdate()) {\n-          batch.add(\n-              String.format(\n-                  \"{ \\\"update\\\" : %s }%n{ \\\"doc\\\" : %s, \\\"doc_as_upsert\\\" : true }%n\",\n-                  documentMetadata, document));\n+        String document = context.element(); // use configuration and auto-generated document IDs\n+        String documentMetadata = \"{}\";\n+        boolean isDelete = false;\n+        if (spec.getIndexFn() != null || spec.getTypeFn() != null || spec.getIdFn() != null) {\n+          // parse once and reused for efficiency\n+          JsonNode parsedDocument = OBJECT_MAPPER.readTree(document);\n+          documentMetadata = getDocumentMetadata(parsedDocument);\n+          if (spec.getIsDeleteFn() != null) {\n+            isDelete = spec.getIsDeleteFn().apply(parsedDocument);\n+            // if it is a delete opration, then it is mandatory to specify the document id using\n+            // getIdFn\n+            checkArgument(\n+                !(isDelete && spec.getIdFn() == null),\n+                \"Id needs to be specified by withIdFn for delete operation\");\n+          }\n+        }\n+\n+        if (!isDelete) {\n+          // index is an insert/upsert and update is a partial update (or insert if not existing)\n+          if (spec.getUsePartialUpdate()) {\n+            batch.add(\n+                String.format(\n+                    \"{ \\\"update\\\" : %s }%n{ \\\"doc\\\" : %s, \\\"doc_as_upsert\\\" : true }%n\",\n+                    documentMetadata, document));\n+          } else {\n+            batch.add(String.format(\"{ \\\"index\\\" : %s }%n%s%n\", documentMetadata, document));\n+          }\n         } else {\n-          batch.add(String.format(\"{ \\\"index\\\" : %s }%n%s%n\", documentMetadata, document));\n+          // delete request used for deleting a document.\n+          batch.add(String.format(\"{ \\\"delete\\\" : %s }%n\", documentMetadata));", "originalCommit": "2f1329404413b959e9f62f003fc3fe2cf469df50", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjg4MTA3MA==", "url": "https://github.com/apache/beam/pull/12670#discussion_r482881070", "bodyText": "Sure, that is better for readability.", "author": "jithin-sukumar", "createdAt": "2020-09-03T10:40:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYyMzUyOA=="}], "type": "inlineReview"}, {"oid": "c7217f4682efaa7bfe483c963d8e8b204d39abb8", "url": "https://github.com/apache/beam/commit/c7217f4682efaa7bfe483c963d8e8b204d39abb8", "message": "[BEAM-5757] ElasticsearchIO: fix idFn and deleteFn check", "committedDate": "2020-09-03T09:51:58Z", "type": "commit"}]}