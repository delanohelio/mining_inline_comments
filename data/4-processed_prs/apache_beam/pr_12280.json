{"pr_number": 12280, "pr_title": "Improving BQ IO documentation", "pr_createdAt": "2020-07-16T17:56:53Z", "pr_url": "https://github.com/apache/beam/pull/12280", "timeline": [{"oid": "b93772a525288d28cdeb18c1e5e864fe985f327d", "url": "https://github.com/apache/beam/commit/b93772a525288d28cdeb18c1e5e864fe985f327d", "message": "Improving BQ IO documentation", "committedDate": "2020-07-16T17:56:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA5OTUzNg==", "url": "https://github.com/apache/beam/pull/12280#discussion_r459099536", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            This is due to the fact that ReadFromBigQuery uses Avro expors by default.\n          \n          \n            \n            This is due to the fact that ReadFromBigQuery uses Avro exports by default.", "author": "udim", "createdAt": "2020-07-22T21:39:52Z", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -65,18 +65,19 @@\n table. If specified, the result obtained by executing the specified query will\n be used as the data of the input transform.::\n \n-  query_results = pipeline | beam.io.Read(beam.io.BigQuerySource(\n-      query='SELECT year, mean_temp FROM samples.weather_stations'))\n+  query_results = pipeline | beam.io.gcp.bigquery.ReadFromBigQuery(\n+      query='SELECT year, mean_temp FROM samples.weather_stations')\n \n When creating a BigQuery input transform, users should provide either a query\n or a table. Pipeline construction will fail with a validation error if neither\n or both are specified.\n \n-When reading from BigQuery using `BigQuerySource`, bytes are returned as\n-base64-encoded bytes. When reading via `ReadFromBigQuery`, bytes are returned\n-as bytes without base64 encoding. This is due to the fact that ReadFromBigQuery\n-uses Avro expors by default. To get base64-encoded bytes, you can use the flag\n-`use_json_exports` to export data as JSON, and receive base64-encoded bytes.\n+When reading via `ReadFromBigQuery`, bytes are returned decoded as bytes.\n+This is due to the fact that ReadFromBigQuery uses Avro expors by default.", "originalCommit": "b93772a525288d28cdeb18c1e5e864fe985f327d", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "42e82924c47a62e7b055799cd95dbd767d4977fa", "url": "https://github.com/apache/beam/commit/42e82924c47a62e7b055799cd95dbd767d4977fa", "message": "Update sdks/python/apache_beam/io/gcp/bigquery.py\n\nCo-authored-by: Udi Meiri <udim@users.noreply.github.com>", "committedDate": "2020-07-22T21:51:47Z", "type": "commit"}]}