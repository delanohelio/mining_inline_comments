{"pr_number": 12485, "pr_title": "[BEAM-6064] Improvements to BQ streaming insert performance", "pr_createdAt": "2020-08-06T21:00:46Z", "pr_url": "https://github.com/apache/beam/pull/12485", "timeline": [{"oid": "6ac5356c611b029d1a4e0645a7ead46b1785d543", "url": "https://github.com/apache/beam/commit/6ac5356c611b029d1a4e0645a7ead46b1785d543", "message": "[BEAM-6064] Improvements to BQ streaming insert performance", "committedDate": "2020-08-06T20:57:20Z", "type": "commit"}, {"oid": "52b08843adaa753efaa76d49e01018ecc272ef85", "url": "https://github.com/apache/beam/commit/52b08843adaa753efaa76d49e01018ecc272ef85", "message": "Fixup", "committedDate": "2020-08-06T20:58:32Z", "type": "commit"}, {"oid": "ca0857b6c38abc71b557c27a359b1a4711222835", "url": "https://github.com/apache/beam/commit/ca0857b6c38abc71b557c27a359b1a4711222835", "message": "Fixup", "committedDate": "2020-08-06T20:59:51Z", "type": "commit"}, {"oid": "2b6c0bf4488a2cfdc42c77c5ad231790ede40506", "url": "https://github.com/apache/beam/commit/2b6c0bf4488a2cfdc42c77c5ad231790ede40506", "message": "Fixup", "committedDate": "2020-08-07T19:10:08Z", "type": "commit"}, {"oid": "b2b548f5c64ee709b56b65fc4d752fbf43e74c4b", "url": "https://github.com/apache/beam/commit/b2b548f5c64ee709b56b65fc4d752fbf43e74c4b", "message": "Fixup", "committedDate": "2020-08-07T22:29:04Z", "type": "commit"}, {"oid": "ad922386540f1ea3c6c411227fc9e2f73eb545ba", "url": "https://github.com/apache/beam/commit/ad922386540f1ea3c6c411227fc9e2f73eb545ba", "message": "fixup", "committedDate": "2020-08-07T22:43:01Z", "type": "commit"}, {"oid": "1e075755b871ee99454580fc17d0ff9b89c42dc9", "url": "https://github.com/apache/beam/commit/1e075755b871ee99454580fc17d0ff9b89c42dc9", "message": "fixup", "committedDate": "2020-08-07T22:48:45Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI3OTE3Mg==", "url": "https://github.com/apache/beam/pull/12485#discussion_r468279172", "bodyText": "I believe Java uses 50 shards. Do we need a larger default for Python ?", "author": "chamikaramj", "createdAt": "2020-08-11T01:45:52Z", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -304,6 +308,8 @@ def compute_table_name(row):\n NOTE: This job name template does not have backwards compatibility guarantees.\n \"\"\"\n BQ_JOB_NAME_TEMPLATE = \"beam_bq_job_{job_type}_{job_id}_{step_id}{random}\"\n+\"\"\"The number of shards per destination when writing via streaming inserts.\"\"\"\n+DEFAULT_SHARDS_PER_DESTINATION = 500", "originalCommit": "1e075755b871ee99454580fc17d0ff9b89c42dc9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgyNTY3Nw==", "url": "https://github.com/apache/beam/pull/12485#discussion_r468825677", "bodyText": "we've been able to reach ~1k EPS per worker in Python. If we have 50 shards, we'll only reach ~50k maximum. I'd like to have a larger default, so we don't automatically cap EPS at a very low rate.", "author": "pabloem", "createdAt": "2020-08-11T19:50:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI3OTE3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgyOTg1Ng==", "url": "https://github.com/apache/beam/pull/12485#discussion_r468829856", "bodyText": "Note that Java also allows users control this through a pipeline option and Dataflow support ask users to update this parameter as they fit.", "author": "chamikaramj", "createdAt": "2020-08-11T19:57:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI3OTE3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgzMDExNg==", "url": "https://github.com/apache/beam/pull/12485#discussion_r468830116", "bodyText": "https://github.com/apache/beam/blob/master/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryOptions.java#L58", "author": "chamikaramj", "createdAt": "2020-08-11T19:58:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI3OTE3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgzMDQ1MA==", "url": "https://github.com/apache/beam/pull/12485#discussion_r468830450", "bodyText": "These flags for streaming inserts can be added in a separate PR though.", "author": "chamikaramj", "createdAt": "2020-08-11T19:59:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI3OTE3Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg0Mjg5MA==", "url": "https://github.com/apache/beam/pull/12485#discussion_r468842890", "bodyText": "Filed https://issues.apache.org/jira/browse/BEAM-10680 - thanks Cham!", "author": "pabloem", "createdAt": "2020-08-11T20:24:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI3OTE3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI3OTY4MQ==", "url": "https://github.com/apache/beam/pull/12485#discussion_r468279681", "bodyText": "This is just a documentation update for a already available (and verified) feature ?", "author": "chamikaramj", "createdAt": "2020-08-11T01:47:50Z", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1419,7 +1448,18 @@ def __init__(\n         Default is to retry always. This means that whenever there are rows\n         that fail to be inserted to BigQuery, they will be retried indefinitely.\n         Other retry strategy settings will produce a deadletter PCollection\n-        as output.\n+        as output. Appropriate values are:\n+\n+        * `RetryStrategy.RETRY_ALWAYS`: retry all rows if\n+          there are any kind of errors. Note that this will hold your pipeline\n+          back if there are errors until you cancel or update it.", "originalCommit": "1e075755b871ee99454580fc17d0ff9b89c42dc9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgyNTA5OQ==", "url": "https://github.com/apache/beam/pull/12485#discussion_r468825099", "bodyText": "that's correct.", "author": "pabloem", "createdAt": "2020-08-11T19:48:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI3OTY4MQ=="}], "type": "inlineReview"}]}