{"pr_number": 135, "pr_title": "Add flaky test finder workflow to run on push", "pr_createdAt": "2020-03-25T19:11:56Z", "pr_url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135", "timeline": [{"oid": "128a670cbe163288de4555512907498717eafc92", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/128a670cbe163288de4555512907498717eafc92", "message": "Add flaky test finder workflow", "committedDate": "2020-03-25T19:12:51Z", "type": "forcePushed"}, {"oid": "f4868e438883db4ff6c833b955bd434bde0c8eae", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/f4868e438883db4ff6c833b955bd434bde0c8eae", "message": "Add flaky test finder workflow", "committedDate": "2020-03-25T19:16:35Z", "type": "forcePushed"}, {"oid": "568cf4d5dc450954241842579f473efaa40930c3", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/568cf4d5dc450954241842579f473efaa40930c3", "message": "Add flaky test finder workflow", "committedDate": "2020-03-25T19:34:30Z", "type": "forcePushed"}, {"oid": "609a5fb4b9e6838f9d8ad46e45938a8468a02515", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/609a5fb4b9e6838f9d8ad46e45938a8468a02515", "message": "Add flaky test finder workflow", "committedDate": "2020-03-25T20:02:54Z", "type": "forcePushed"}, {"oid": "2205c285a53b57964a10aad677890123b949bdf1", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/2205c285a53b57964a10aad677890123b949bdf1", "message": "Add flaky test finder workflow", "committedDate": "2020-03-25T20:17:00Z", "type": "forcePushed"}, {"oid": "f136a982a93db9986f7fb57eae2dc43f2017e943", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/f136a982a93db9986f7fb57eae2dc43f2017e943", "message": "Add flaky test finder workflow", "committedDate": "2020-03-25T21:57:12Z", "type": "forcePushed"}, {"oid": "9ab4ce03be775fa227c9e56fdd972d393fd49dd6", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/9ab4ce03be775fa227c9e56fdd972d393fd49dd6", "message": "Add flaky test finder workflow", "committedDate": "2020-03-26T01:40:25Z", "type": "forcePushed"}, {"oid": "a7cd059ef6324648ea9317eaff1f1d6c34b9399c", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a7cd059ef6324648ea9317eaff1f1d6c34b9399c", "message": "Add flaky test finder workflow", "committedDate": "2020-03-26T01:42:49Z", "type": "forcePushed"}, {"oid": "c60df4bffef1b969ff9638a079185491caefb1a4", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/c60df4bffef1b969ff9638a079185491caefb1a4", "message": "Add flaky test finder workflow", "committedDate": "2020-03-26T01:44:18Z", "type": "forcePushed"}, {"oid": "736c83db3bdf3e6accf584d5b48e11aae113ba6e", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/736c83db3bdf3e6accf584d5b48e11aae113ba6e", "message": "Add flaky test finder workflow", "committedDate": "2020-03-26T01:45:08Z", "type": "forcePushed"}, {"oid": "1cc87b75681b64d94874b5a874c4b4d16478e2ef", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/1cc87b75681b64d94874b5a874c4b4d16478e2ef", "message": "Add flaky test finder workflow", "committedDate": "2020-03-26T01:49:10Z", "type": "forcePushed"}, {"oid": "ec691c2c46d1bedc8708f31d54d0efb8ad874d24", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/ec691c2c46d1bedc8708f31d54d0efb8ad874d24", "message": "Add flaky test finder workflow", "committedDate": "2020-03-26T02:45:46Z", "type": "forcePushed"}, {"oid": "cce179fe9c36b4ef4040f04b96a64d3ce597bff4", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/cce179fe9c36b4ef4040f04b96a64d3ce597bff4", "message": "Add flaky test finder workflow", "committedDate": "2020-03-26T02:46:15Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc1ODI4Ng==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r398758286", "bodyText": "NIT: make 'failed_tests' a const", "author": "ShirleyZheng92", "createdAt": "2020-03-26T17:30:20Z", "path": ".github/scripts/flake.py", "diffHunk": "@@ -0,0 +1,106 @@\n+#  Copyright Amazon.com Inc. or its affiliates.\n+#  SPDX-License-Identifier: Apache-2.0\n+\n+import argparse\n+import json\n+import os\n+import subprocess\n+import xml.etree.ElementTree as ET\n+from collections import defaultdict\n+\n+from agithub.GitHub import GitHub\n+\n+\n+def main():\n+    parser = argparse.ArgumentParser()\n+    parser.add_argument('--cmd', type=str, help='Command to run')\n+    parser.add_argument('-i', type=int, help='Iterations')\n+    parser.add_argument('--token', type=str, help='GitHub token')\n+    parser.add_argument('-ff', action=\"store_true\", help='Fail fast. If enabled, quit '\n+                                                         'after the first failure')\n+    args = parser.parse_args()\n+\n+    command = args.cmd\n+    iterations = args.i\n+    token = args.token\n+    results = defaultdict(lambda: defaultdict(list))\n+\n+    for i in range(0, iterations):\n+        print(f\"Running iteration {i + 1} of {iterations}\", flush=True)\n+        process = subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=True)\n+        # If the tests failed, then we should check which test(s) failed in order to report it\n+        if process.returncode != 0:\n+            print(f\"Iteration {i + 1} failed, saving and parsing results now\", flush=True)\n+            parse_test_results(i, results)\n+            if args.ff:\n+                break\n+        else:\n+            print(\"Succeeded with no failure\", flush=True)\n+\n+    if len(results) > 0:\n+        print(\"Found some flakiness. Creating/updating GitHub issue.\", flush=True)\n+        print(json.dumps(results), flush=True)\n+\n+        gh = GitHub(token=token)\n+        title = \"[Bot] Flaky Test(s) Identified\"\n+        existing_issues = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues.get(creator=\"app/github-actions\")\n+        if existing_issues[0] == 200:\n+            existing_issues = list(filter(lambda i: title in i[\"title\"], existing_issues[1]))\n+        else:\n+            existing_issues = []\n+\n+        body = f\"Flaky test(s) found for commit {os.getenv('GITHUB_SHA')}.\\n\" \\\n+               f\" See the uploaded artifacts from the action for details.\\n\\n\"\n+        for test_class, v in results.items():\n+            for test_case, failures in v.items():\n+                body += f\"- {test_class}.{test_case} failed {len(failures)} times over {iterations} iterations \"\n+                unique_failure_reasons = set(map(lambda f: f[\"failure\"], failures))\n+                body += f\"with {len(unique_failure_reasons)} unique failures.\\n\"\n+\n+        if existing_issues:\n+            issue_number = existing_issues[0][\"number\"]\n+            updated_issue = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues[issue_number].patch(body={\"body\": body,\n+                                                                                                      \"title\": title})\n+            print(updated_issue, flush=True)\n+        else:\n+            issue = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues.post(body={\"body\": body,\n+                                                                               \"title\": title})\n+            print(issue, flush=True)\n+\n+\n+def parse_test_results(iteration, previous_results):\n+    report_dir = \"target/surefire-reports/\"\n+    if not os.path.exists(report_dir):\n+        return\n+    reports = list(filter(lambda f: f.startswith(\"TEST-\") and f.endswith(\".xml\"), os.listdir(report_dir)))\n+    for r in reports:\n+        tree = ET.parse(report_dir + r)\n+        for testcase in tree.getroot().findall(\"./testcase\"):\n+            failure = None\n+            # Find failures and errors (there's no important difference between these for us)\n+            if testcase.find(\"failure\") is not None:\n+                failure = testcase.find(\"failure\").text\n+            elif testcase.find(\"error\") is not None:\n+                failure = testcase.find(\"error\").text\n+            if failure is not None:\n+                previous_results[testcase.get(\"classname\")][testcase.get(\"name\")] \\\n+                    .append({\"iteration\": iteration, \"failure\": failure})\n+                if not os.path.exists('failed_tests'):", "originalCommit": "cce179fe9c36b4ef4040f04b96a64d3ce597bff4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODgxNTM3MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r398815370", "bodyText": "sure", "author": "MikeDombo", "createdAt": "2020-03-26T18:53:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc1ODI4Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc1OTY0MQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r398759641", "bodyText": "I think in Python3.2+ you can do os.makedirs(\"path/to/directory\", exist_ok=True)\nhttps://docs.python.org/3/library/os.html", "author": "ShirleyZheng92", "createdAt": "2020-03-26T17:31:50Z", "path": ".github/scripts/flake.py", "diffHunk": "@@ -0,0 +1,106 @@\n+#  Copyright Amazon.com Inc. or its affiliates.\n+#  SPDX-License-Identifier: Apache-2.0\n+\n+import argparse\n+import json\n+import os\n+import subprocess\n+import xml.etree.ElementTree as ET\n+from collections import defaultdict\n+\n+from agithub.GitHub import GitHub\n+\n+\n+def main():\n+    parser = argparse.ArgumentParser()\n+    parser.add_argument('--cmd', type=str, help='Command to run')\n+    parser.add_argument('-i', type=int, help='Iterations')\n+    parser.add_argument('--token', type=str, help='GitHub token')\n+    parser.add_argument('-ff', action=\"store_true\", help='Fail fast. If enabled, quit '\n+                                                         'after the first failure')\n+    args = parser.parse_args()\n+\n+    command = args.cmd\n+    iterations = args.i\n+    token = args.token\n+    results = defaultdict(lambda: defaultdict(list))\n+\n+    for i in range(0, iterations):\n+        print(f\"Running iteration {i + 1} of {iterations}\", flush=True)\n+        process = subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=True)\n+        # If the tests failed, then we should check which test(s) failed in order to report it\n+        if process.returncode != 0:\n+            print(f\"Iteration {i + 1} failed, saving and parsing results now\", flush=True)\n+            parse_test_results(i, results)\n+            if args.ff:\n+                break\n+        else:\n+            print(\"Succeeded with no failure\", flush=True)\n+\n+    if len(results) > 0:\n+        print(\"Found some flakiness. Creating/updating GitHub issue.\", flush=True)\n+        print(json.dumps(results), flush=True)\n+\n+        gh = GitHub(token=token)\n+        title = \"[Bot] Flaky Test(s) Identified\"\n+        existing_issues = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues.get(creator=\"app/github-actions\")\n+        if existing_issues[0] == 200:\n+            existing_issues = list(filter(lambda i: title in i[\"title\"], existing_issues[1]))\n+        else:\n+            existing_issues = []\n+\n+        body = f\"Flaky test(s) found for commit {os.getenv('GITHUB_SHA')}.\\n\" \\\n+               f\" See the uploaded artifacts from the action for details.\\n\\n\"\n+        for test_class, v in results.items():\n+            for test_case, failures in v.items():\n+                body += f\"- {test_class}.{test_case} failed {len(failures)} times over {iterations} iterations \"\n+                unique_failure_reasons = set(map(lambda f: f[\"failure\"], failures))\n+                body += f\"with {len(unique_failure_reasons)} unique failures.\\n\"\n+\n+        if existing_issues:\n+            issue_number = existing_issues[0][\"number\"]\n+            updated_issue = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues[issue_number].patch(body={\"body\": body,\n+                                                                                                      \"title\": title})\n+            print(updated_issue, flush=True)\n+        else:\n+            issue = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues.post(body={\"body\": body,\n+                                                                               \"title\": title})\n+            print(issue, flush=True)\n+\n+\n+def parse_test_results(iteration, previous_results):\n+    report_dir = \"target/surefire-reports/\"\n+    if not os.path.exists(report_dir):\n+        return\n+    reports = list(filter(lambda f: f.startswith(\"TEST-\") and f.endswith(\".xml\"), os.listdir(report_dir)))\n+    for r in reports:\n+        tree = ET.parse(report_dir + r)\n+        for testcase in tree.getroot().findall(\"./testcase\"):\n+            failure = None\n+            # Find failures and errors (there's no important difference between these for us)\n+            if testcase.find(\"failure\") is not None:\n+                failure = testcase.find(\"failure\").text\n+            elif testcase.find(\"error\") is not None:\n+                failure = testcase.find(\"error\").text\n+            if failure is not None:\n+                previous_results[testcase.get(\"classname\")][testcase.get(\"name\")] \\\n+                    .append({\"iteration\": iteration, \"failure\": failure})\n+                if not os.path.exists('failed_tests'):\n+                    os.mkdir('failed_tests')", "originalCommit": "cce179fe9c36b4ef4040f04b96a64d3ce597bff4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODgxNTU1Ng==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r398815556", "bodyText": "Sure", "author": "MikeDombo", "createdAt": "2020-03-26T18:53:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc1OTY0MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc2MTA3NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r398761075", "bodyText": "NIT: make f'failed_tests/{iteration}-{testcase.get(\"classname\")}.' a variable", "author": "ShirleyZheng92", "createdAt": "2020-03-26T17:33:49Z", "path": ".github/scripts/flake.py", "diffHunk": "@@ -0,0 +1,106 @@\n+#  Copyright Amazon.com Inc. or its affiliates.\n+#  SPDX-License-Identifier: Apache-2.0\n+\n+import argparse\n+import json\n+import os\n+import subprocess\n+import xml.etree.ElementTree as ET\n+from collections import defaultdict\n+\n+from agithub.GitHub import GitHub\n+\n+\n+def main():\n+    parser = argparse.ArgumentParser()\n+    parser.add_argument('--cmd', type=str, help='Command to run')\n+    parser.add_argument('-i', type=int, help='Iterations')\n+    parser.add_argument('--token', type=str, help='GitHub token')\n+    parser.add_argument('-ff', action=\"store_true\", help='Fail fast. If enabled, quit '\n+                                                         'after the first failure')\n+    args = parser.parse_args()\n+\n+    command = args.cmd\n+    iterations = args.i\n+    token = args.token\n+    results = defaultdict(lambda: defaultdict(list))\n+\n+    for i in range(0, iterations):\n+        print(f\"Running iteration {i + 1} of {iterations}\", flush=True)\n+        process = subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=True)\n+        # If the tests failed, then we should check which test(s) failed in order to report it\n+        if process.returncode != 0:\n+            print(f\"Iteration {i + 1} failed, saving and parsing results now\", flush=True)\n+            parse_test_results(i, results)\n+            if args.ff:\n+                break\n+        else:\n+            print(\"Succeeded with no failure\", flush=True)\n+\n+    if len(results) > 0:\n+        print(\"Found some flakiness. Creating/updating GitHub issue.\", flush=True)\n+        print(json.dumps(results), flush=True)\n+\n+        gh = GitHub(token=token)\n+        title = \"[Bot] Flaky Test(s) Identified\"\n+        existing_issues = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues.get(creator=\"app/github-actions\")\n+        if existing_issues[0] == 200:\n+            existing_issues = list(filter(lambda i: title in i[\"title\"], existing_issues[1]))\n+        else:\n+            existing_issues = []\n+\n+        body = f\"Flaky test(s) found for commit {os.getenv('GITHUB_SHA')}.\\n\" \\\n+               f\" See the uploaded artifacts from the action for details.\\n\\n\"\n+        for test_class, v in results.items():\n+            for test_case, failures in v.items():\n+                body += f\"- {test_class}.{test_case} failed {len(failures)} times over {iterations} iterations \"\n+                unique_failure_reasons = set(map(lambda f: f[\"failure\"], failures))\n+                body += f\"with {len(unique_failure_reasons)} unique failures.\\n\"\n+\n+        if existing_issues:\n+            issue_number = existing_issues[0][\"number\"]\n+            updated_issue = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues[issue_number].patch(body={\"body\": body,\n+                                                                                                      \"title\": title})\n+            print(updated_issue, flush=True)\n+        else:\n+            issue = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues.post(body={\"body\": body,\n+                                                                               \"title\": title})\n+            print(issue, flush=True)\n+\n+\n+def parse_test_results(iteration, previous_results):\n+    report_dir = \"target/surefire-reports/\"\n+    if not os.path.exists(report_dir):\n+        return\n+    reports = list(filter(lambda f: f.startswith(\"TEST-\") and f.endswith(\".xml\"), os.listdir(report_dir)))\n+    for r in reports:\n+        tree = ET.parse(report_dir + r)\n+        for testcase in tree.getroot().findall(\"./testcase\"):\n+            failure = None\n+            # Find failures and errors (there's no important difference between these for us)\n+            if testcase.find(\"failure\") is not None:\n+                failure = testcase.find(\"failure\").text\n+            elif testcase.find(\"error\") is not None:\n+                failure = testcase.find(\"error\").text\n+            if failure is not None:\n+                previous_results[testcase.get(\"classname\")][testcase.get(\"name\")] \\\n+                    .append({\"iteration\": iteration, \"failure\": failure})\n+                if not os.path.exists('failed_tests'):\n+                    os.mkdir('failed_tests')\n+                # Save test stdout and stderr\n+                if testcase.find(\"system-out\") is not None:\n+                    with open(f'failed_tests/{iteration}-{testcase.get(\"classname\")}.'", "originalCommit": "cce179fe9c36b4ef4040f04b96a64d3ce597bff4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODgxNTY0NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r398815645", "bodyText": "Sure", "author": "MikeDombo", "createdAt": "2020-03-26T18:53:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc2MTA3NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc2MjYxOQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r398762619", "bodyText": "Or you can do if (len(results) == 0) { return;}", "author": "ShirleyZheng92", "createdAt": "2020-03-26T17:35:55Z", "path": ".github/scripts/flake.py", "diffHunk": "@@ -0,0 +1,106 @@\n+#  Copyright Amazon.com Inc. or its affiliates.\n+#  SPDX-License-Identifier: Apache-2.0\n+\n+import argparse\n+import json\n+import os\n+import subprocess\n+import xml.etree.ElementTree as ET\n+from collections import defaultdict\n+\n+from agithub.GitHub import GitHub\n+\n+\n+def main():\n+    parser = argparse.ArgumentParser()\n+    parser.add_argument('--cmd', type=str, help='Command to run')\n+    parser.add_argument('-i', type=int, help='Iterations')\n+    parser.add_argument('--token', type=str, help='GitHub token')\n+    parser.add_argument('-ff', action=\"store_true\", help='Fail fast. If enabled, quit '\n+                                                         'after the first failure')\n+    args = parser.parse_args()\n+\n+    command = args.cmd\n+    iterations = args.i\n+    token = args.token\n+    results = defaultdict(lambda: defaultdict(list))\n+\n+    for i in range(0, iterations):\n+        print(f\"Running iteration {i + 1} of {iterations}\", flush=True)\n+        process = subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=True)\n+        # If the tests failed, then we should check which test(s) failed in order to report it\n+        if process.returncode != 0:\n+            print(f\"Iteration {i + 1} failed, saving and parsing results now\", flush=True)\n+            parse_test_results(i, results)\n+            if args.ff:\n+                break\n+        else:\n+            print(\"Succeeded with no failure\", flush=True)\n+\n+    if len(results) > 0:", "originalCommit": "cce179fe9c36b4ef4040f04b96a64d3ce597bff4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc2ODMyNw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r398768327", "bodyText": "can you add a comment of the format here? It took me a while to figure out results is a dict of [className][testCaseName] - List of Failed Iteration Details", "author": "ShirleyZheng92", "createdAt": "2020-03-26T17:44:05Z", "path": ".github/scripts/flake.py", "diffHunk": "@@ -0,0 +1,106 @@\n+#  Copyright Amazon.com Inc. or its affiliates.\n+#  SPDX-License-Identifier: Apache-2.0\n+\n+import argparse\n+import json\n+import os\n+import subprocess\n+import xml.etree.ElementTree as ET\n+from collections import defaultdict\n+\n+from agithub.GitHub import GitHub\n+\n+\n+def main():\n+    parser = argparse.ArgumentParser()\n+    parser.add_argument('--cmd', type=str, help='Command to run')\n+    parser.add_argument('-i', type=int, help='Iterations')\n+    parser.add_argument('--token', type=str, help='GitHub token')\n+    parser.add_argument('-ff', action=\"store_true\", help='Fail fast. If enabled, quit '\n+                                                         'after the first failure')\n+    args = parser.parse_args()\n+\n+    command = args.cmd\n+    iterations = args.i\n+    token = args.token\n+    results = defaultdict(lambda: defaultdict(list))", "originalCommit": "cce179fe9c36b4ef4040f04b96a64d3ce597bff4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODgxNTcxOQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r398815719", "bodyText": "Yep sure.", "author": "MikeDombo", "createdAt": "2020-03-26T18:53:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc2ODMyNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc2OTk2OQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r398769969", "bodyText": "Is there a way to query an issue given the title? Or you can only list and search?", "author": "ShirleyZheng92", "createdAt": "2020-03-26T17:46:28Z", "path": ".github/scripts/flake.py", "diffHunk": "@@ -0,0 +1,106 @@\n+#  Copyright Amazon.com Inc. or its affiliates.\n+#  SPDX-License-Identifier: Apache-2.0\n+\n+import argparse\n+import json\n+import os\n+import subprocess\n+import xml.etree.ElementTree as ET\n+from collections import defaultdict\n+\n+from agithub.GitHub import GitHub\n+\n+\n+def main():\n+    parser = argparse.ArgumentParser()\n+    parser.add_argument('--cmd', type=str, help='Command to run')\n+    parser.add_argument('-i', type=int, help='Iterations')\n+    parser.add_argument('--token', type=str, help='GitHub token')\n+    parser.add_argument('-ff', action=\"store_true\", help='Fail fast. If enabled, quit '\n+                                                         'after the first failure')\n+    args = parser.parse_args()\n+\n+    command = args.cmd\n+    iterations = args.i\n+    token = args.token\n+    results = defaultdict(lambda: defaultdict(list))\n+\n+    for i in range(0, iterations):\n+        print(f\"Running iteration {i + 1} of {iterations}\", flush=True)\n+        process = subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=True)\n+        # If the tests failed, then we should check which test(s) failed in order to report it\n+        if process.returncode != 0:\n+            print(f\"Iteration {i + 1} failed, saving and parsing results now\", flush=True)\n+            parse_test_results(i, results)\n+            if args.ff:\n+                break\n+        else:\n+            print(\"Succeeded with no failure\", flush=True)\n+\n+    if len(results) > 0:\n+        print(\"Found some flakiness. Creating/updating GitHub issue.\", flush=True)\n+        print(json.dumps(results), flush=True)\n+\n+        gh = GitHub(token=token)\n+        title = \"[Bot] Flaky Test(s) Identified\"\n+        existing_issues = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues.get(creator=\"app/github-actions\")", "originalCommit": "cce179fe9c36b4ef4040f04b96a64d3ce597bff4", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODgxNjAwNw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r398816007", "bodyText": "No, according to their API docs there doesn't seem to be a way to search by title or other keyword.", "author": "MikeDombo", "createdAt": "2020-03-26T18:54:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc2OTk2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODc3MDc3OA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r398770778", "bodyText": "Same here: if failure is None: return\nwe can save one level of indentation", "author": "ShirleyZheng92", "createdAt": "2020-03-26T17:47:38Z", "path": ".github/scripts/flake.py", "diffHunk": "@@ -0,0 +1,106 @@\n+#  Copyright Amazon.com Inc. or its affiliates.\n+#  SPDX-License-Identifier: Apache-2.0\n+\n+import argparse\n+import json\n+import os\n+import subprocess\n+import xml.etree.ElementTree as ET\n+from collections import defaultdict\n+\n+from agithub.GitHub import GitHub\n+\n+\n+def main():\n+    parser = argparse.ArgumentParser()\n+    parser.add_argument('--cmd', type=str, help='Command to run')\n+    parser.add_argument('-i', type=int, help='Iterations')\n+    parser.add_argument('--token', type=str, help='GitHub token')\n+    parser.add_argument('-ff', action=\"store_true\", help='Fail fast. If enabled, quit '\n+                                                         'after the first failure')\n+    args = parser.parse_args()\n+\n+    command = args.cmd\n+    iterations = args.i\n+    token = args.token\n+    results = defaultdict(lambda: defaultdict(list))\n+\n+    for i in range(0, iterations):\n+        print(f\"Running iteration {i + 1} of {iterations}\", flush=True)\n+        process = subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=True)\n+        # If the tests failed, then we should check which test(s) failed in order to report it\n+        if process.returncode != 0:\n+            print(f\"Iteration {i + 1} failed, saving and parsing results now\", flush=True)\n+            parse_test_results(i, results)\n+            if args.ff:\n+                break\n+        else:\n+            print(\"Succeeded with no failure\", flush=True)\n+\n+    if len(results) > 0:\n+        print(\"Found some flakiness. Creating/updating GitHub issue.\", flush=True)\n+        print(json.dumps(results), flush=True)\n+\n+        gh = GitHub(token=token)\n+        title = \"[Bot] Flaky Test(s) Identified\"\n+        existing_issues = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues.get(creator=\"app/github-actions\")\n+        if existing_issues[0] == 200:\n+            existing_issues = list(filter(lambda i: title in i[\"title\"], existing_issues[1]))\n+        else:\n+            existing_issues = []\n+\n+        body = f\"Flaky test(s) found for commit {os.getenv('GITHUB_SHA')}.\\n\" \\\n+               f\" See the uploaded artifacts from the action for details.\\n\\n\"\n+        for test_class, v in results.items():\n+            for test_case, failures in v.items():\n+                body += f\"- {test_class}.{test_case} failed {len(failures)} times over {iterations} iterations \"\n+                unique_failure_reasons = set(map(lambda f: f[\"failure\"], failures))\n+                body += f\"with {len(unique_failure_reasons)} unique failures.\\n\"\n+\n+        if existing_issues:\n+            issue_number = existing_issues[0][\"number\"]\n+            updated_issue = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues[issue_number].patch(body={\"body\": body,\n+                                                                                                      \"title\": title})\n+            print(updated_issue, flush=True)\n+        else:\n+            issue = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues.post(body={\"body\": body,\n+                                                                               \"title\": title})\n+            print(issue, flush=True)\n+\n+\n+def parse_test_results(iteration, previous_results):\n+    report_dir = \"target/surefire-reports/\"\n+    if not os.path.exists(report_dir):\n+        return\n+    reports = list(filter(lambda f: f.startswith(\"TEST-\") and f.endswith(\".xml\"), os.listdir(report_dir)))\n+    for r in reports:\n+        tree = ET.parse(report_dir + r)\n+        for testcase in tree.getroot().findall(\"./testcase\"):\n+            failure = None\n+            # Find failures and errors (there's no important difference between these for us)\n+            if testcase.find(\"failure\") is not None:\n+                failure = testcase.find(\"failure\").text\n+            elif testcase.find(\"error\") is not None:\n+                failure = testcase.find(\"error\").text\n+            if failure is not None:", "originalCommit": "cce179fe9c36b4ef4040f04b96a64d3ce597bff4", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1d8426c77a0b4d536d2590ad4982fa2cf0818820", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/1d8426c77a0b4d536d2590ad4982fa2cf0818820", "message": "Add flaky test finder workflow", "committedDate": "2020-03-26T18:59:56Z", "type": "commit"}, {"oid": "1d8426c77a0b4d536d2590ad4982fa2cf0818820", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/1d8426c77a0b4d536d2590ad4982fa2cf0818820", "message": "Add flaky test finder workflow", "committedDate": "2020-03-26T18:59:56Z", "type": "forcePushed"}, {"oid": "99606e793a61174b71580e69af2fb8cd403fcfcd", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/99606e793a61174b71580e69af2fb8cd403fcfcd", "message": "Merge branch 'master' into flake", "committedDate": "2020-03-26T22:58:32Z", "type": "commit"}, {"oid": "305a10103c9d2d40f42c36ffdc00fc9ab855f13a", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/305a10103c9d2d40f42c36ffdc00fc9ab855f13a", "message": "Merge branch 'master' into flake", "committedDate": "2020-03-27T16:54:42Z", "type": "commit"}, {"oid": "3a096c42d6f926b1918067217aaa805c8d51c4e2", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/3a096c42d6f926b1918067217aaa805c8d51c4e2", "message": "Merge branch 'master' into flake", "committedDate": "2020-03-27T20:57:48Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU2OTUxOA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r399569518", "bodyText": "Why \"./testcase\"? Should it be just \"testcase\"?", "author": "abanthiy", "createdAt": "2020-03-27T22:39:20Z", "path": ".github/scripts/flake.py", "diffHunk": "@@ -0,0 +1,111 @@\n+#  Copyright Amazon.com Inc. or its affiliates.\n+#  SPDX-License-Identifier: Apache-2.0\n+\n+import argparse\n+import json\n+import os\n+import subprocess\n+import xml.etree.ElementTree as ET\n+from collections import defaultdict\n+\n+from agithub.GitHub import GitHub\n+\n+\n+def main():\n+    parser = argparse.ArgumentParser()\n+    parser.add_argument('--cmd', type=str, help='Command to run')\n+    parser.add_argument('-i', type=int, help='Iterations')\n+    parser.add_argument('--token', type=str, help='GitHub token')\n+    parser.add_argument('-ff', action=\"store_true\", help='Fail fast. If enabled, quit '\n+                                                         'after the first failure')\n+    args = parser.parse_args()\n+\n+    command = args.cmd\n+    iterations = args.i\n+    token = args.token\n+\n+    # Dict for results as a dict of classname -> method name -> [failure details]\n+    results = defaultdict(lambda: defaultdict(list))\n+\n+    for i in range(0, iterations):\n+        print(f\"Running iteration {i + 1} of {iterations}\", flush=True)\n+        process = subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=True)\n+        # If the tests failed, then we should check which test(s) failed in order to report it\n+        if process.returncode != 0:\n+            print(f\"Iteration {i + 1} failed, saving and parsing results now\", flush=True)\n+            parse_test_results(i, results)\n+            if args.ff:\n+                break\n+        else:\n+            print(\"Succeeded with no failure\", flush=True)\n+\n+    if len(results) == 0:\n+        return\n+\n+    print(\"Found some flakiness. Creating/updating GitHub issue.\", flush=True)\n+    print(json.dumps(results), flush=True)\n+\n+    gh = GitHub(token=token)\n+    title = \"[Bot] Flaky Test(s) Identified\"\n+    existing_issues = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues.get(creator=\"app/github-actions\")\n+    if existing_issues[0] == 200:\n+        existing_issues = list(filter(lambda i: title in i[\"title\"], existing_issues[1]))\n+    else:\n+        existing_issues = []\n+\n+    body = f\"Flaky test(s) found for commit {os.getenv('GITHUB_SHA')}.\\n\" \\\n+           f\" See the uploaded artifacts from the action for details.\\n\\n\"\n+    for test_class, v in results.items():\n+        for test_case, failures in v.items():\n+            body += f\"- {test_class}.{test_case} failed {len(failures)} times over {iterations} iterations \"\n+            unique_failure_reasons = set(map(lambda f: f[\"failure\"], failures))\n+            body += f\"with {len(unique_failure_reasons)} unique failures.\\n\"\n+\n+    if existing_issues:\n+        issue_number = existing_issues[0][\"number\"]\n+        updated_issue = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues[issue_number].patch(body={\"body\": body,\n+                                                                                                  \"title\": title})\n+        print(updated_issue, flush=True)\n+    else:\n+        issue = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues.post(body={\"body\": body,\n+                                                                           \"title\": title})\n+        print(issue, flush=True)\n+\n+\n+def parse_test_results(iteration, previous_results):\n+    report_dir = \"target/surefire-reports/\"\n+    failed_test_dir = \"failed_tests/\"\n+\n+    if not os.path.exists(report_dir):\n+        return\n+    reports = list(filter(lambda f: f.startswith(\"TEST-\") and f.endswith(\".xml\"), os.listdir(report_dir)))\n+    for r in reports:\n+        tree = ET.parse(report_dir + r)\n+        for testcase in tree.getroot().findall(\"./testcase\"):", "originalCommit": "3a096c42d6f926b1918067217aaa805c8d51c4e2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NjEzOA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r399576138", "bodyText": "Needs to be that. We're parsing XML and that is the XPATH. Or at least I know that this works.", "author": "MikeDombo", "createdAt": "2020-03-27T23:04:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU2OTUxOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MTQzMQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r399571431", "bodyText": "May take this as argument since caller workflow is uploading the same directory", "author": "abanthiy", "createdAt": "2020-03-27T22:46:36Z", "path": ".github/scripts/flake.py", "diffHunk": "@@ -0,0 +1,111 @@\n+#  Copyright Amazon.com Inc. or its affiliates.\n+#  SPDX-License-Identifier: Apache-2.0\n+\n+import argparse\n+import json\n+import os\n+import subprocess\n+import xml.etree.ElementTree as ET\n+from collections import defaultdict\n+\n+from agithub.GitHub import GitHub\n+\n+\n+def main():\n+    parser = argparse.ArgumentParser()\n+    parser.add_argument('--cmd', type=str, help='Command to run')\n+    parser.add_argument('-i', type=int, help='Iterations')\n+    parser.add_argument('--token', type=str, help='GitHub token')\n+    parser.add_argument('-ff', action=\"store_true\", help='Fail fast. If enabled, quit '\n+                                                         'after the first failure')\n+    args = parser.parse_args()\n+\n+    command = args.cmd\n+    iterations = args.i\n+    token = args.token\n+\n+    # Dict for results as a dict of classname -> method name -> [failure details]\n+    results = defaultdict(lambda: defaultdict(list))\n+\n+    for i in range(0, iterations):\n+        print(f\"Running iteration {i + 1} of {iterations}\", flush=True)\n+        process = subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=True)\n+        # If the tests failed, then we should check which test(s) failed in order to report it\n+        if process.returncode != 0:\n+            print(f\"Iteration {i + 1} failed, saving and parsing results now\", flush=True)\n+            parse_test_results(i, results)\n+            if args.ff:\n+                break\n+        else:\n+            print(\"Succeeded with no failure\", flush=True)\n+\n+    if len(results) == 0:\n+        return\n+\n+    print(\"Found some flakiness. Creating/updating GitHub issue.\", flush=True)\n+    print(json.dumps(results), flush=True)\n+\n+    gh = GitHub(token=token)\n+    title = \"[Bot] Flaky Test(s) Identified\"\n+    existing_issues = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues.get(creator=\"app/github-actions\")\n+    if existing_issues[0] == 200:\n+        existing_issues = list(filter(lambda i: title in i[\"title\"], existing_issues[1]))\n+    else:\n+        existing_issues = []\n+\n+    body = f\"Flaky test(s) found for commit {os.getenv('GITHUB_SHA')}.\\n\" \\\n+           f\" See the uploaded artifacts from the action for details.\\n\\n\"\n+    for test_class, v in results.items():\n+        for test_case, failures in v.items():\n+            body += f\"- {test_class}.{test_case} failed {len(failures)} times over {iterations} iterations \"\n+            unique_failure_reasons = set(map(lambda f: f[\"failure\"], failures))\n+            body += f\"with {len(unique_failure_reasons)} unique failures.\\n\"\n+\n+    if existing_issues:\n+        issue_number = existing_issues[0][\"number\"]\n+        updated_issue = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues[issue_number].patch(body={\"body\": body,\n+                                                                                                  \"title\": title})\n+        print(updated_issue, flush=True)\n+    else:\n+        issue = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues.post(body={\"body\": body,\n+                                                                           \"title\": title})\n+        print(issue, flush=True)\n+\n+\n+def parse_test_results(iteration, previous_results):\n+    report_dir = \"target/surefire-reports/\"\n+    failed_test_dir = \"failed_tests/\"", "originalCommit": "3a096c42d6f926b1918067217aaa805c8d51c4e2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NTE3Nw==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r399575177", "bodyText": "Are we going to override the issue. If the failures in previous run were different that in the latest run then will the previous run be oerridden?", "author": "abanthiy", "createdAt": "2020-03-27T23:00:46Z", "path": ".github/scripts/flake.py", "diffHunk": "@@ -0,0 +1,111 @@\n+#  Copyright Amazon.com Inc. or its affiliates.\n+#  SPDX-License-Identifier: Apache-2.0\n+\n+import argparse\n+import json\n+import os\n+import subprocess\n+import xml.etree.ElementTree as ET\n+from collections import defaultdict\n+\n+from agithub.GitHub import GitHub\n+\n+\n+def main():\n+    parser = argparse.ArgumentParser()\n+    parser.add_argument('--cmd', type=str, help='Command to run')\n+    parser.add_argument('-i', type=int, help='Iterations')\n+    parser.add_argument('--token', type=str, help='GitHub token')\n+    parser.add_argument('-ff', action=\"store_true\", help='Fail fast. If enabled, quit '\n+                                                         'after the first failure')\n+    args = parser.parse_args()\n+\n+    command = args.cmd\n+    iterations = args.i\n+    token = args.token\n+\n+    # Dict for results as a dict of classname -> method name -> [failure details]\n+    results = defaultdict(lambda: defaultdict(list))\n+\n+    for i in range(0, iterations):\n+        print(f\"Running iteration {i + 1} of {iterations}\", flush=True)\n+        process = subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, shell=True)\n+        # If the tests failed, then we should check which test(s) failed in order to report it\n+        if process.returncode != 0:\n+            print(f\"Iteration {i + 1} failed, saving and parsing results now\", flush=True)\n+            parse_test_results(i, results)\n+            if args.ff:\n+                break\n+        else:\n+            print(\"Succeeded with no failure\", flush=True)\n+\n+    if len(results) == 0:\n+        return\n+\n+    print(\"Found some flakiness. Creating/updating GitHub issue.\", flush=True)\n+    print(json.dumps(results), flush=True)\n+\n+    gh = GitHub(token=token)\n+    title = \"[Bot] Flaky Test(s) Identified\"\n+    existing_issues = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues.get(creator=\"app/github-actions\")\n+    if existing_issues[0] == 200:\n+        existing_issues = list(filter(lambda i: title in i[\"title\"], existing_issues[1]))\n+    else:\n+        existing_issues = []\n+\n+    body = f\"Flaky test(s) found for commit {os.getenv('GITHUB_SHA')}.\\n\" \\\n+           f\" See the uploaded artifacts from the action for details.\\n\\n\"\n+    for test_class, v in results.items():\n+        for test_case, failures in v.items():\n+            body += f\"- {test_class}.{test_case} failed {len(failures)} times over {iterations} iterations \"\n+            unique_failure_reasons = set(map(lambda f: f[\"failure\"], failures))\n+            body += f\"with {len(unique_failure_reasons)} unique failures.\\n\"\n+\n+    if existing_issues:\n+        issue_number = existing_issues[0][\"number\"]\n+        updated_issue = gh.repos[os.getenv(\"GITHUB_REPOSITORY\")].issues[issue_number].patch(body={\"body\": body,\n+                                                                                                  \"title\": title})", "originalCommit": "3a096c42d6f926b1918067217aaa805c8d51c4e2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NjU0NQ==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r399576545", "bodyText": "Consider making separate issues for different classname/classmethod which failed", "author": "abanthiy", "createdAt": "2020-03-27T23:06:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NTE3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NjU3NA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r399576574", "bodyText": "Yes. I don't think this is an issue, and in fact I do want it to overwrite so that as we fix the issues, they will be removed from the issue. If we \"miss\" a flaky test, then it may not actually be flaky. In future, I'd expect that we increase the number of rounds from 10 to be higher, and then there's even less chance of missing flakiness.", "author": "MikeDombo", "createdAt": "2020-03-27T23:06:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NTE3Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3Njk1MA==", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/135#discussion_r399576950", "bodyText": "Also, the full edit history is still available on the issue if we really wanted.", "author": "MikeDombo", "createdAt": "2020-03-27T23:08:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3NTE3Nw=="}], "type": "inlineReview"}, {"oid": "8fa280c2446b78ab17d4996633383fb30048109c", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/8fa280c2446b78ab17d4996633383fb30048109c", "message": "Merge branch 'master' into flake", "committedDate": "2020-03-27T23:06:32Z", "type": "commit"}, {"oid": "5fbfa6001301b4c600e62fe92d1319462c6851f2", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/5fbfa6001301b4c600e62fe92d1319462c6851f2", "message": "Update for comments, increase E2E timeout from 5 minutes", "committedDate": "2020-03-27T23:16:42Z", "type": "commit"}]}