{"pr_number": 11898, "pr_title": "Balder/all in single chunk", "pr_createdAt": "2020-01-23T05:59:01Z", "pr_url": "https://github.com/vespa-engine/vespa/pull/11898", "timeline": [{"oid": "694e53f832e65010f246ba9ef4ab02796700c873", "url": "https://github.com/vespa-engine/vespa/commit/694e53f832e65010f246ba9ef4ab02796700c873", "message": "Use a single chunk", "committedDate": "2020-01-23T05:56:45Z", "type": "commit"}, {"oid": "ca8545560297ee05c5d22eb4888613adbeb6e7f8", "url": "https://github.com/vespa-engine/vespa/commit/ca8545560297ee05c5d22eb4888613adbeb6e7f8", "message": "Remove cloneability.", "committedDate": "2020-01-23T05:56:45Z", "type": "commit"}, {"oid": "9f438cdcdae81a9fd55dc370a42af85b275a934c", "url": "https://github.com/vespa-engine/vespa/commit/9f438cdcdae81a9fd55dc370a42af85b275a934c", "message": "Add indirection for the unlikely stuff to keep the likely members close and tight.", "committedDate": "2020-01-23T05:56:45Z", "type": "commit"}, {"oid": "753c6869ac764e8b1463ba214980c82401479a88", "url": "https://github.com/vespa-engine/vespa/commit/753c6869ac764e8b1463ba214980c82401479a88", "message": "Remove ByteBuffer indirection.", "committedDate": "2020-01-23T05:56:45Z", "type": "commit"}, {"oid": "5d2e89d0e9fea8e19720dedfca283f4f788958d7", "url": "https://github.com/vespa-engine/vespa/commit/5d2e89d0e9fea8e19720dedfca283f4f788958d7", "message": "Just use the stack", "committedDate": "2020-01-23T05:56:45Z", "type": "commit"}, {"oid": "e7f0c18c77929909632121f9baa52805addc4842", "url": "https://github.com/vespa-engine/vespa/commit/e7f0c18c77929909632121f9baa52805addc4842", "message": "Move the transaction implementation from StructuredFieldValue to Document", "committedDate": "2020-01-23T09:23:47Z", "type": "commit"}, {"oid": "7a97a9c569be961b79bea5990296f414d7f3f935", "url": "https://github.com/vespa-engine/vespa/commit/7a97a9c569be961b79bea5990296f414d7f3f935", "message": "Avoid duplicating information.", "committedDate": "2020-01-23T11:59:54Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDAyMjA2OQ==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370022069", "bodyText": "Consider adding a if (&rhs != this) { self-assignment guard if this makes sense to have", "author": "vekterli", "createdAt": "2020-01-23T09:54:26Z", "path": "document/src/vespa/document/fieldvalue/serializablearray.cpp", "diffHunk": "@@ -81,6 +81,13 @@ SerializableArray::SerializableArray(const SerializableArray& other)\n     }\n }\n \n+SerializableArray &\n+SerializableArray::operator=(const SerializableArray &rhs)\n+{\n+    *this = SerializableArray(rhs);", "originalCommit": "694e53f832e65010f246ba9ef4ab02796700c873", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxODc0Mg==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370218742", "bodyText": "Fixed", "author": "baldersheim", "createdAt": "2020-01-23T16:21:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDAyMjA2OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3NDI5OQ==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370074299", "bodyText": "As an aside, assuming there's no member with a potentially throwing destructor (marked noexcept(false)) destructors are implicitly noexcept by default. But even the core guidelines aren't 100% on when to specify it or not (https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#c37-make-destructors-noexcept) so a core, complex type like this is probably a good place to have them.", "author": "vekterli", "createdAt": "2020-01-23T11:51:35Z", "path": "document/src/vespa/document/base/documentid.cpp", "diffHunk": "@@ -29,7 +29,7 @@ DocumentId::DocumentId(vespalib::nbostream & is)\n \n DocumentId::DocumentId(const DocumentId & rhs) = default;\n DocumentId & DocumentId::operator = (const DocumentId & rhs) = default;\n-DocumentId::~DocumentId() = default;\n+DocumentId::~DocumentId() noexcept = default;", "originalCommit": "e7f0c18c77929909632121f9baa52805addc4842", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxOTMyNg==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370219326", "bodyText": "K, so more is better than less..", "author": "baldersheim", "createdAt": "2020-01-23T16:22:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3NDI5OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDExNDA0Ng==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370114046", "bodyText": "Consider renaming this type to something that describes the semantics a bit more. LazyUncompressableFieldData or something down that lane?", "author": "vekterli", "createdAt": "2020-01-23T13:26:00Z", "path": "document/src/vespa/document/fieldvalue/serializablearray.h", "diffHunk": "@@ -159,17 +162,22 @@ class SerializableArray : public vespalib::Cloneable\n     }\n     void deCompress(); // throw (DeserializeException);\n \n+    struct Unlikely {", "originalCommit": "e7f0c18c77929909632121f9baa52805addc4842", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE3NTY3Mg==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370175672", "bodyText": "Presumably if we've merged two legacy chunks down to one, this ends up transitively setting hasChanged() == true for the struct, thereby causing it to be re-serialized as one chunk (as would be expected)?", "author": "vekterli", "createdAt": "2020-01-23T15:11:50Z", "path": "document/src/vespa/document/serialization/vespadocumentserializer.cpp", "diffHunk": "@@ -86,89 +86,45 @@ void VespaDocumentSerializer::write(const DocumentType &value) {\n             << static_cast<uint16_t>(0);  // version\n }\n \n+namespace {\n+\n uint8_t\n-VespaDocumentSerializer::getContentCode(bool hasHeader, bool hasBody) const\n+getContentCode(bool hasContent)\n {\n-    uint8_t content = 0x01;  // Document type is always present.\n-    if (hasHeader) {\n-        content |= 0x02;  // Header is present.\n-    }\n-    if (hasBody) {\n-        content |= 0x04;  // Body is present.\n-    }\n-    return content;\n+    return 0x01u |  // Document type is always present\n+           (hasContent ? 0x02u : 0x00u);   // Payload ?\n }\n \n-static inline size_t wantChunks(bool hasHeader, bool hasBody) {\n-    size_t res = 0;\n-    if (hasHeader) ++res;\n-    if (hasBody) ++res;\n-    return res;\n }\n \n void\n-VespaDocumentSerializer::write(const Document &value, DocSerializationMode mode) {\n+VespaDocumentSerializer::write(const Document &value) {\n     nbostream doc_stream;\n     VespaDocumentSerializer doc_serializer(doc_stream);\n     doc_serializer.write(value.getId());\n \n-    bool hasHeader = false;\n-    bool hasBody = false;\n-\n-    const StructFieldValue::Chunks & chunks = value.getFields().getChunks();\n-\n-    for (const Field & field : value.getFields()) {\n-        if (field.isHeaderField()) {\n-            hasHeader = true;\n-        } else {\n-            hasBody = true;\n-        }\n-        if (hasHeader && hasBody) {\n-            break;\n-        }\n-    }\n-    if (mode != COMPLETE) {\n-        hasBody = false;\n-    }\n-    doc_stream << getContentCode(hasHeader, hasBody);\n+    bool hasContent = ! value.getFields().empty();\n+    doc_stream << getContentCode(hasContent);\n     doc_serializer.write(value.getType());\n \n-    if (chunks.size() == wantChunks(hasHeader, hasBody) &&\n-        !structNeedsReserialization(value.getFields()))\n-    {\n-        // here we assume the receiver can handle whatever serialization the\n-        // chunks contain, so we just send them as-is, even if some fields\n-        // may have moved from header to body or vice versa.\n-        if (hasHeader || hasBody) {\n-            assert( ! chunks.empty());\n-            doc_serializer.writeUnchanged(chunks[0]);\n-        }\n-        if (hasHeader && hasBody) {\n-            assert(chunks.size() == 2);\n-            doc_serializer.writeUnchanged(chunks[1]);\n-        }\n-    } else {\n-        if (hasHeader) {\n-            doc_serializer.write(value.getFields(), HeaderFields());\n-        }\n-        if (hasBody) {\n-            doc_serializer.write(value.getFields(), BodyFields());\n+    if ( hasContent ) {\n+        if (!structNeedsReserialization(value.getFields())) {\n+            doc_serializer.writeUnchanged(value.getFields().getFields());", "originalCommit": "e7f0c18c77929909632121f9baa52805addc4842", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxMTU1OQ==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370211559", "bodyText": "That was at least the intention.", "author": "baldersheim", "createdAt": "2020-01-23T16:09:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE3NTY3Mg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE3Nzg2Nw==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370177867", "bodyText": "Nit: spurious extra indent", "author": "vekterli", "createdAt": "2020-01-23T15:15:28Z", "path": "storage/src/tests/persistence/processalltest.cpp", "diffHunk": "@@ -166,7 +165,7 @@ TEST_F(ProcessAllHandlerTest, stat_bucket_request_can_returned_removed_entries)\n         \"  Timestamp: 208, id:mail:testdoctype1:n=4:42967.html, gid(0x04000000f19ece1668e6de48) (remove)\\n\"\n         \"  Timestamp: 209, id:mail:testdoctype1:n=4:6925.html, gid(0x04000000667c0b3cada830be) (remove)\\n\";\n \n-    EXPECT_EQ(expected, reply.getResults());\n+        EXPECT_EQ(expected, reply.getResults());", "originalCommit": "e7f0c18c77929909632121f9baa52805addc4842", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIxNzYzNA==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370217634", "bodyText": "Fixed", "author": "baldersheim", "createdAt": "2020-01-23T16:20:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE3Nzg2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE5Mzk2MA==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370193960", "bodyText": "Is it possible for _unlikely to be nullptr at this point?", "author": "vekterli", "createdAt": "2020-01-23T15:40:45Z", "path": "document/src/vespa/document/fieldvalue/serializablearray.cpp", "diffHunk": "@@ -26,84 +26,103 @@ class BufferMap : public BufferMapT {\n \n }\n \n-SerializableArray::SerializableArray()\n-    : _serializedCompression(CompressionConfig::NONE),\n-      _uncompressedLength(0)\n-{\n-}\n+SerializableArray::SerializableArray() = default;\n \n-SerializableArray::SerializableArray(EntryMap entries, ByteBuffer::UP buffer,\n+SerializableArray::SerializableArray(EntryMap entries, ByteBuffer buffer,\n                                      CompressionConfig::Type comp_type, uint32_t uncompressed_length)\n     : _entries(std::move(entries)),\n-      _owned(),\n-      _serializedCompression(comp_type)\n+      _uncompSerData(),\n+      _unlikely()\n {\n \n-    if (CompressionConfig::isCompressed(_serializedCompression)) {\n-        _compSerData = std::move(buffer);\n-        _uncompressedLength = uncompressed_length;\n+    if (CompressionConfig::isCompressed(comp_type)) {\n+        _unlikely = std::make_unique<Unlikely>();\n+        _unlikely->_compSerData = std::move(buffer);\n+        _unlikely->_serializedCompression = comp_type;\n+        _unlikely->_uncompressedLength = uncompressed_length;\n     } else {\n-        _uncompressedLength = buffer->getRemaining();\n         _uncompSerData = std::move(buffer);\n     }\n }\n \n-serializablearray::BufferMap &\n-ensure(std::unique_ptr<serializablearray::BufferMap> & owned) {\n+SerializableArray::SerializableArray(SerializableArray &&) noexcept = default;\n+SerializableArray& SerializableArray::operator=(SerializableArray &&) noexcept = default;\n+SerializableArray::~SerializableArray() = default;\n+\n+namespace {\n+\n+template <typename T>\n+T &\n+ensure(std::unique_ptr<T> &owned) {\n     if (!owned) {\n-        owned = std::make_unique<serializablearray::BufferMap>();\n+        owned = std::make_unique<T>();\n     }\n     return *owned;\n }\n \n-SerializableArray::SerializableArray(const SerializableArray& other)\n-    : Cloneable(),\n-      _entries(other._entries),\n-      _owned(),\n-      _uncompSerData(other._uncompSerData.get() ? new ByteBuffer(*other._uncompSerData) : nullptr),\n-      _compSerData(other._compSerData.get() ? new ByteBuffer(*other._compSerData) : nullptr),\n-      _serializedCompression(other._serializedCompression),\n-      _uncompressedLength(other._uncompressedLength)\n+}\n+\n+SerializableArray::Unlikely::Unlikely()\n+    : _owned(),\n+      _compSerData(nullptr, 0),\n+      _serializedCompression(CompressionConfig::NONE),\n+      _uncompressedLength(0)\n+{ }\n+SerializableArray::Unlikely::~Unlikely() = default;\n+\n+SerializableArray::Unlikely::Unlikely(const Unlikely & rhs)\n+    : _owned(),\n+      _compSerData(rhs._compSerData),\n+      _serializedCompression(rhs._serializedCompression),\n+      _uncompressedLength(rhs._uncompressedLength)\n+{ }\n+\n+SerializableArray::SerializableArray(const SerializableArray& rhs)\n+    : _entries(rhs._entries),\n+      _uncompSerData(rhs._uncompSerData),\n+      _unlikely(rhs._unlikely ? new Unlikely(*rhs._unlikely) : nullptr)\n {\n     for (size_t i(0); i < _entries.size(); i++) {\n         Entry & e(_entries[i]);\n         if (e.hasBuffer()) {\n             // Pointing to a buffer in the _owned structure.\n-            ByteBuffer::UP buf(ByteBuffer::copyBuffer(e.getBuffer(_uncompSerData.get()), e.size()));\n-            e.setBuffer(buf->getBuffer());\n-            ensure(_owned)[e.id()] = std::move(buf);\n+            ByteBuffer buf(ByteBuffer::copyBuffer(e.getBuffer(&_uncompSerData), e.size()));\n+            e.setBuffer(buf.getBuffer());\n+            ensure(_unlikely->_owned)[e.id()] = std::move(buf);", "originalCommit": "7a97a9c569be961b79bea5990296f414d7f3f935", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIyMjgyMg==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370222822", "bodyText": "No, that should not be possible.\ne.hasBuffer will only be true if rhs._unlikely._owened has an entry for e._id.\nAnd that again should guarantee that _unlikely is created in the initializer list.", "author": "baldersheim", "createdAt": "2020-01-23T16:28:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE5Mzk2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIwMDExNw==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370200117", "bodyText": "Wondering if we should add an assert(buffer.getRemaining() < 0x80000000) to ensure Entry does not get tricked into believing the size MSB means something else than it does (it decides union interpretation based on this today).", "author": "vekterli", "createdAt": "2020-01-23T15:50:38Z", "path": "document/src/vespa/document/fieldvalue/serializablearray.cpp", "diffHunk": "@@ -26,84 +26,103 @@ class BufferMap : public BufferMapT {\n \n }\n \n-SerializableArray::SerializableArray()\n-    : _serializedCompression(CompressionConfig::NONE),\n-      _uncompressedLength(0)\n-{\n-}\n+SerializableArray::SerializableArray() = default;\n \n-SerializableArray::SerializableArray(EntryMap entries, ByteBuffer::UP buffer,\n+SerializableArray::SerializableArray(EntryMap entries, ByteBuffer buffer,\n                                      CompressionConfig::Type comp_type, uint32_t uncompressed_length)\n     : _entries(std::move(entries)),\n-      _owned(),\n-      _serializedCompression(comp_type)\n+      _uncompSerData(),\n+      _unlikely()\n {\n \n-    if (CompressionConfig::isCompressed(_serializedCompression)) {\n-        _compSerData = std::move(buffer);\n-        _uncompressedLength = uncompressed_length;\n+    if (CompressionConfig::isCompressed(comp_type)) {\n+        _unlikely = std::make_unique<Unlikely>();\n+        _unlikely->_compSerData = std::move(buffer);\n+        _unlikely->_serializedCompression = comp_type;\n+        _unlikely->_uncompressedLength = uncompressed_length;\n     } else {\n-        _uncompressedLength = buffer->getRemaining();\n         _uncompSerData = std::move(buffer);\n     }\n }\n \n-serializablearray::BufferMap &\n-ensure(std::unique_ptr<serializablearray::BufferMap> & owned) {\n+SerializableArray::SerializableArray(SerializableArray &&) noexcept = default;\n+SerializableArray& SerializableArray::operator=(SerializableArray &&) noexcept = default;\n+SerializableArray::~SerializableArray() = default;\n+\n+namespace {\n+\n+template <typename T>\n+T &\n+ensure(std::unique_ptr<T> &owned) {\n     if (!owned) {\n-        owned = std::make_unique<serializablearray::BufferMap>();\n+        owned = std::make_unique<T>();\n     }\n     return *owned;\n }\n \n-SerializableArray::SerializableArray(const SerializableArray& other)\n-    : Cloneable(),\n-      _entries(other._entries),\n-      _owned(),\n-      _uncompSerData(other._uncompSerData.get() ? new ByteBuffer(*other._uncompSerData) : nullptr),\n-      _compSerData(other._compSerData.get() ? new ByteBuffer(*other._compSerData) : nullptr),\n-      _serializedCompression(other._serializedCompression),\n-      _uncompressedLength(other._uncompressedLength)\n+}\n+\n+SerializableArray::Unlikely::Unlikely()\n+    : _owned(),\n+      _compSerData(nullptr, 0),\n+      _serializedCompression(CompressionConfig::NONE),\n+      _uncompressedLength(0)\n+{ }\n+SerializableArray::Unlikely::~Unlikely() = default;\n+\n+SerializableArray::Unlikely::Unlikely(const Unlikely & rhs)\n+    : _owned(),\n+      _compSerData(rhs._compSerData),\n+      _serializedCompression(rhs._serializedCompression),\n+      _uncompressedLength(rhs._uncompressedLength)\n+{ }\n+\n+SerializableArray::SerializableArray(const SerializableArray& rhs)\n+    : _entries(rhs._entries),\n+      _uncompSerData(rhs._uncompSerData),\n+      _unlikely(rhs._unlikely ? new Unlikely(*rhs._unlikely) : nullptr)\n {\n     for (size_t i(0); i < _entries.size(); i++) {\n         Entry & e(_entries[i]);\n         if (e.hasBuffer()) {\n             // Pointing to a buffer in the _owned structure.\n-            ByteBuffer::UP buf(ByteBuffer::copyBuffer(e.getBuffer(_uncompSerData.get()), e.size()));\n-            e.setBuffer(buf->getBuffer());\n-            ensure(_owned)[e.id()] = std::move(buf);\n+            ByteBuffer buf(ByteBuffer::copyBuffer(e.getBuffer(&_uncompSerData), e.size()));\n+            e.setBuffer(buf.getBuffer());\n+            ensure(_unlikely->_owned)[e.id()] = std::move(buf);\n         } else {\n             // If not it is relative to the buffer _uncompSerData, and hence it is valid as is.\n         }\n     }\n-    if (_uncompSerData.get()) {\n-        LOG_ASSERT(_uncompressedLength == _uncompSerData->getRemaining());\n-    }\n+}\n+\n+SerializableArray &\n+SerializableArray::operator=(const SerializableArray &rhs)\n+{\n+    *this = SerializableArray(rhs);\n+    return *this;\n }\n \n void SerializableArray::clear()\n {\n     _entries.clear();\n-    _uncompSerData.reset();\n-    _compSerData.reset();\n-    _serializedCompression = CompressionConfig::NONE;\n-    _uncompressedLength = 0;\n+    _uncompSerData = ByteBuffer(nullptr, 0);\n+    _unlikely.reset();\n }\n \n-SerializableArray::~SerializableArray() = default;\n-\n void\n SerializableArray::invalidate()\n {\n-    _compSerData.reset();\n+    if (_unlikely) {\n+        _unlikely->_compSerData = ByteBuffer(nullptr, 0);;\n+    }\n }\n \n void\n-SerializableArray::set(int id, ByteBuffer::UP buffer)\n+SerializableArray::set(int id, ByteBuffer buffer)\n {\n     maybeDecompress();\n-    Entry e(id, buffer->getRemaining(), buffer->getBuffer());\n-    ensure(_owned)[id] = std::move(buffer);\n+    Entry e(id, buffer.getRemaining(), buffer.getBuffer());", "originalCommit": "7a97a9c569be961b79bea5990296f414d7f3f935", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIyNjUwMA==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370226500", "bodyText": "Fixed", "author": "baldersheim", "createdAt": "2020-01-23T16:34:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIwMDExNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIwNDUwOQ==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370204509", "bodyText": "Will this be enough of a change in size that it will fail some sizeof-checking unit tests? PR build is broken on a presumably unrelated Java unit test, so C++ tests haven't been run.", "author": "vekterli", "createdAt": "2020-01-23T15:57:52Z", "path": "document/src/vespa/document/base/idstring.h", "diffHunk": "@@ -57,7 +59,7 @@ class IdString {\n     private:\n         static constexpr uint32_t MAX_COMPONENTS = 4;\n         Offsets(vespalib::stringref id);\n-        uint16_t _offsets[MAX_COMPONENTS + 1];\n+        uint16_t _offsets[MAX_COMPONENTS];", "originalCommit": "7a97a9c569be961b79bea5990296f414d7f3f935", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIyNTA3MA==", "url": "https://github.com/vespa-engine/vespa/pull/11898#discussion_r370225070", "bodyText": "No, it did not change size due to alignment requirement. Just added padding.", "author": "baldersheim", "createdAt": "2020-01-23T16:32:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIwNDUwOQ=="}], "type": "inlineReview"}, {"oid": "19c8f9406297f359c0e04e7bda9f12ef625f1df6", "url": "https://github.com/vespa-engine/vespa/commit/19c8f9406297f359c0e04e7bda9f12ef625f1df6", "message": "Add an extra indirection to the rarely used owned buffers, in order to keep the frequently accesed members in StructFieldValue close", "committedDate": "2020-01-23T16:18:43Z", "type": "commit"}, {"oid": "4d24ae39cd172474502b7a3a2b7c43f26338d86f", "url": "https://github.com/vespa-engine/vespa/commit/4d24ae39cd172474502b7a3a2b7c43f26338d86f", "message": "Followup on code comments.", "committedDate": "2020-01-23T16:38:55Z", "type": "commit"}]}