{"pr_number": 1228, "pr_title": "issue #1227 refactor bulkdata jbatch job codes", "pr_createdAt": "2020-06-15T19:36:05Z", "pr_url": "https://github.com/IBM/FHIR/pull/1228", "timeline": [{"oid": "d2d7517f97ae5f6c2ffa7456c604eb4ceb406a99", "url": "https://github.com/IBM/FHIR/commit/d2d7517f97ae5f6c2ffa7456c604eb4ceb406a99", "message": "issue #1227 refactor bulkdata jbatch job codes\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-06-15T19:33:16Z", "type": "commit"}, {"oid": "2d5b49459c28fb36da563633da19ab9d561bbfeb", "url": "https://github.com/IBM/FHIR/commit/2d5b49459c28fb36da563633da19ab9d561bbfeb", "message": "issue #1227 refactor bulkdata import\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-06-16T18:36:18Z", "type": "commit"}, {"oid": "f5cdbcef85f0d2a6ccd2af4160b24dcc05ee06aa", "url": "https://github.com/IBM/FHIR/commit/f5cdbcef85f0d2a6ccd2af4160b24dcc05ee06aa", "message": "issue #1227 rollback the unintended changes to searchTest.java\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-06-16T18:44:00Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTA3MTE0NQ==", "url": "https://github.com/IBM/FHIR/pull/1228#discussion_r441071145", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n                }\n          \n          \n            \n                }", "author": "prb112", "createdAt": "2020-06-16T18:50:57Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/jbatch/bulkdata/export/common/TransientUserData.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.jbatch.bulkdata.export.common;\n+\n+import java.io.ByteArrayOutputStream;\n+\n+/**\n+ * Bulk export Chunk implementation - job cache data.\n+ *\n+ */\n+public class TransientUserData extends CheckPointUserData {\n+    private static final long serialVersionUID = -5892726731783560418L;\n+    private ByteArrayOutputStream bufferStream = new ByteArrayOutputStream();\n+\n+    protected TransientUserData() {\n+        super();\n+    }\n+\n+    public static TransientUserData fromCheckPointUserData(CheckPointUserData checkPointData) {\n+        return (TransientUserData)TransientUserData.Builder.builder()\n+            .pageNum(checkPointData.pageNum)\n+            .uploadId(checkPointData.uploadId)\n+            .cosDataPacks(checkPointData.cosDataPacks)\n+            .partNum(checkPointData.partNum)\n+            .indexOfCurrentTypeFilter(checkPointData.indexOfCurrentTypeFilter)\n+            .resourceTypeSummary(checkPointData.resourceTypeSummary)\n+            .totalResourcesNum(checkPointData.totalResourcesNum)\n+            .currentUploadResourceNum(checkPointData.currentUploadResourceNum)\n+            .currentUploadSize(checkPointData.currentUploadSize)\n+            .uploadCount(checkPointData.uploadCount)\n+            .lastPageNum(checkPointData.lastPageNum)\n+            .lastWritePageNum(checkPointData.lastWritePageNum)\n+            .build();\n+    }\n+\n+    public ByteArrayOutputStream getBufferStream() {\n+        return bufferStream;\n+    }\n+\n+\n+    public static class Builder extends CheckPointUserData.Builder {\n+\n+        public static Builder builder() {\n+            return new Builder();\n+        }\n+\n+        @Override\n+        public CheckPointUserData build(){\n+            TransientUserData transientUserData = new TransientUserData();\n+            transientUserData.pageNum  = this.pageNum;\n+            transientUserData.lastPageNum = this.lastPageNum;\n+            transientUserData.partNum = this.partNum;\n+            transientUserData.uploadId = this.uploadId;\n+            transientUserData.uploadCount = this.uploadCount;\n+            transientUserData.cosDataPacks = this.cosDataPacks;\n+            transientUserData.currentUploadResourceNum = this.currentUploadResourceNum;\n+            transientUserData.currentUploadSize = this.currentUploadSize;\n+            transientUserData.totalResourcesNum = this.totalResourcesNum;\n+            transientUserData.indexOfCurrentTypeFilter = this.indexOfCurrentTypeFilter;\n+            transientUserData.resourceTypeSummary = this.resourceTypeSummary;\n+            transientUserData.lastWritePageNum = this.lastWritePageNum;\n+            return transientUserData;\n+        }\n+\n+    }\n+", "originalCommit": "f5cdbcef85f0d2a6ccd2af4160b24dcc05ee06aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTA3MTMxNA==", "url": "https://github.com/IBM/FHIR/pull/1228#discussion_r441071314", "bodyText": "Suggested change", "author": "prb112", "createdAt": "2020-06-16T18:51:16Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/jbatch/bulkdata/export/common/TransientUserData.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.jbatch.bulkdata.export.common;\n+\n+import java.io.ByteArrayOutputStream;\n+\n+/**\n+ * Bulk export Chunk implementation - job cache data.\n+ *\n+ */\n+public class TransientUserData extends CheckPointUserData {\n+    private static final long serialVersionUID = -5892726731783560418L;\n+    private ByteArrayOutputStream bufferStream = new ByteArrayOutputStream();\n+\n+    protected TransientUserData() {\n+        super();\n+    }\n+\n+    public static TransientUserData fromCheckPointUserData(CheckPointUserData checkPointData) {\n+        return (TransientUserData)TransientUserData.Builder.builder()\n+            .pageNum(checkPointData.pageNum)\n+            .uploadId(checkPointData.uploadId)\n+            .cosDataPacks(checkPointData.cosDataPacks)\n+            .partNum(checkPointData.partNum)\n+            .indexOfCurrentTypeFilter(checkPointData.indexOfCurrentTypeFilter)\n+            .resourceTypeSummary(checkPointData.resourceTypeSummary)\n+            .totalResourcesNum(checkPointData.totalResourcesNum)\n+            .currentUploadResourceNum(checkPointData.currentUploadResourceNum)\n+            .currentUploadSize(checkPointData.currentUploadSize)\n+            .uploadCount(checkPointData.uploadCount)\n+            .lastPageNum(checkPointData.lastPageNum)\n+            .lastWritePageNum(checkPointData.lastWritePageNum)\n+            .build();\n+    }\n+\n+    public ByteArrayOutputStream getBufferStream() {\n+        return bufferStream;\n+    }\n+\n+", "originalCommit": "f5cdbcef85f0d2a6ccd2af4160b24dcc05ee06aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTA3MjA4MQ==", "url": "https://github.com/IBM/FHIR/pull/1228#discussion_r441072081", "bodyText": "I really love this code. Very readable.\nConstants would make this more readable, e.g. why null for resourceTypeSummary", "author": "prb112", "createdAt": "2020-06-16T18:52:40Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/jbatch/bulkdata/export/group/ChunkReader.java", "diffHunk": "@@ -140,7 +140,21 @@ public Object readItem() throws Exception {\n         pageNum++;\n \n         if (chunkData == null) {\n-            chunkData = new TransientUserData(pageNum, null, new ArrayList<PartETag>(), 1, 0, null, 0, 0, 0, 1, 0, 1);\n+            chunkData = (TransientUserData)TransientUserData.Builder.builder()\n+                .pageNum(pageNum)\n+                .uploadId(null)\n+                .cosDataPacks(new ArrayList<PartETag>())\n+                .partNum(1)\n+                .indexOfCurrentTypeFilter(0)\n+                .resourceTypeSummary(null)\n+                .totalResourcesNum(0)\n+                .currentUploadResourceNum(0)\n+                .currentUploadSize(0)\n+                .uploadCount(1)\n+                .lastPageNum(0)\n+                .lastWritePageNum(1)\n+                .build();\n+", "originalCommit": "f5cdbcef85f0d2a6ccd2af4160b24dcc05ee06aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTA3MjI4OQ==", "url": "https://github.com/IBM/FHIR/pull/1228#discussion_r441072289", "bodyText": "This is not something I'm asking to be recoded/changed.  Just a commentary", "author": "prb112", "createdAt": "2020-06-16T18:53:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTA3MjA4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTA3Mjc3MA==", "url": "https://github.com/IBM/FHIR/pull/1228#discussion_r441072770", "bodyText": "This is duplicate of other ChunkReader implementation, do you want to simplify?", "author": "prb112", "createdAt": "2020-06-16T18:54:00Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/jbatch/bulkdata/export/system/ChunkReader.java", "diffHunk": "@@ -217,8 +217,21 @@ public Object readItem() throws Exception {\n         pageNum++;\n \n         if (chunkData == null) {\n-            chunkData = new TransientUserData(pageNum, null, new ArrayList<PartETag>(), 1, 0, null, 0, 0, 0, 1, 0, 1);\n-            chunkData.setLastPageNum(searchContext.getLastPageNumber());\n+            chunkData = (TransientUserData)TransientUserData.Builder.builder()\n+                    .pageNum(pageNum)\n+                    .uploadId(null)\n+                    .cosDataPacks(new ArrayList<PartETag>())\n+                    .partNum(1)\n+                    .indexOfCurrentTypeFilter(0)\n+                    .resourceTypeSummary(null)\n+                    .totalResourcesNum(0)\n+                    .currentUploadResourceNum(0)\n+                    .currentUploadSize(0)\n+                    .uploadCount(1)\n+                    .lastPageNum(searchContext.getLastPageNumber())\n+                    .lastWritePageNum(1)\n+                    .build();", "originalCommit": "f5cdbcef85f0d2a6ccd2af4160b24dcc05ee06aa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTA5MDE0MQ==", "url": "https://github.com/IBM/FHIR/pull/1228#discussion_r441090141", "bodyText": "Group export reader inherits from Patient reader, but System export reader is very different from them, so I didn't really want to mix them...", "author": "albertwang-ibm", "createdAt": "2020-06-16T19:26:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTA3Mjc3MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTA3MzYwMQ==", "url": "https://github.com/IBM/FHIR/pull/1228#discussion_r441073601", "bodyText": "Suggested change", "author": "prb112", "createdAt": "2020-06-16T18:55:34Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/jbatch/bulkdata/load/ImportCheckPointData.java", "diffHunk": "@@ -0,0 +1,368 @@\n+/*\n+ * (C) Copyright IBM Corp. 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.jbatch.bulkdata.load;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.List;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+\n+// Class for tracking the partition import progress and for Batch job check points.\n+// Also used as data carrier for collecting and aggregation of import metrics.\n+public class ImportCheckPointData implements Serializable {\n+    private static final long serialVersionUID = 2189917861035732241L;\n+    // URL or COS/S3 object name.\n+    protected String importPartitionWorkitem;\n+\n+    // Values for metrics calculation.\n+    protected int numOfProcessedResources = 0;\n+    protected int numOfImportedResources = 0;\n+    protected int numOfImportFailures = 0;\n+    protected long totalReadMilliSeconds = 0;\n+    protected long totalWriteMilliSeconds = 0;\n+    protected long totalValidationMilliSeconds = 0;\n+    protected long importFileSize = 0;\n+\n+    protected long inFlyRateBeginMilliSeconds = 0;\n+\n+    // Value used to sign the successful ending of the import.\n+    protected int numOfToBeImported = 0;\n+\n+    // Parsing failures in current batch.\n+    protected int numOfParseFailures = 0;\n+    // Fhir resource type processed in this partition.\n+    protected String importPartitionResourceType;\n+\n+    // COS/S3 object name for import OperationOutcomes.\n+    protected String uniqueIDForImportOperationOutcomes = null;\n+    // Part number for COS/S3 multiple-parts upload.\n+    protected int partNumForOperationOutcomes = 1;\n+    // Upload id for COS/S3 multiple-parts upload.\n+    protected String uploadIdForOperationOutcomes = null;\n+    // ETags for COS/S3 multiple-parts upload.\n+    protected List<PartETag> dataPacksForOperationOutcomes = new ArrayList<>();\n+\n+    // COS/S3 object name for import failure OperationOutcomes;\n+    protected String uniqueIDForImportFailureOperationOutcomes = null;\n+    // Part number for COS/S3 multiple-parts upload.\n+    protected int partNumForFailureOperationOutcomes = 1;\n+    // Upload id for COS/S3 multiple-parts upload.\n+    protected String uploadIdForFailureOperationOutcomes = null;\n+    // ETags for COS/S3 multiple-parts upload.\n+    protected List<PartETag> dataPacksForFailureOperationOutcomes = new ArrayList<>();\n+\n+    protected ImportCheckPointData() {\n+        super();\n+    }\n+\n+    public static class Builder {\n+        protected String importPartitionWorkitem;\n+        protected int numOfProcessedResources;\n+        protected String importPartitionResourceType;\n+        protected int numOfImportedResources;\n+        protected int numOfImportFailures;\n+        protected String uniqueIDForImportFailureOperationOutcomes;\n+        protected String uniqueIDForImportOperationOutcomes;\n+        protected String uploadIdForOperationOutcomes;\n+        protected List<PartETag> dataPacksForOperationOutcomes;\n+        protected int partNumForOperationOutcomes;\n+        protected String uploadIdForFailureOperationOutcomes;\n+        protected List<PartETag> dataPacksForFailureOperationOutcomes;\n+        protected int partNumForFailureOperationOutcomes;\n+        protected long totalReadMilliSeconds;\n+        protected long totalValidationMilliSeconds;\n+        protected long totalWriteMilliSeconds;\n+        protected long importFileSize;\n+        protected long inFlyRateBeginMilliSeconds;\n+\n+        public Builder() {\n+            super();\n+        }\n+\n+        public static Builder builder() {\n+            return new Builder();\n+        }\n+\n+        public Builder importPartitionWorkitem(String importPartitionWorkitem) {\n+            this.importPartitionWorkitem = importPartitionWorkitem;\n+            return this;\n+        }\n+\n+        public Builder numOfProcessedResources(int numOfProcessedResources) {\n+            this.numOfProcessedResources = numOfProcessedResources;\n+            return this;\n+        }\n+\n+        public Builder importPartitionResourceType(String importPartitionResourceType) {\n+            this.importPartitionResourceType = importPartitionResourceType;\n+            return this;\n+        }\n+\n+        public Builder numOfImportedResources(int numOfImportedResources) {\n+            this.numOfImportedResources = numOfImportedResources;\n+            return this;\n+        }\n+\n+        public Builder numOfImportFailures(int numOfImportFailures) {\n+            this.numOfImportFailures = numOfImportFailures;\n+            return this;\n+        }\n+\n+        public Builder uniqueIDForImportFailureOperationOutcomes(String uniqueIDForImportFailureOperationOutcomes) {\n+            this.uniqueIDForImportFailureOperationOutcomes = uniqueIDForImportFailureOperationOutcomes;\n+            return this;\n+        }\n+\n+        public Builder uniqueIDForImportOperationOutcomes(String uniqueIDForImportOperationOutcomes) {\n+            this.uniqueIDForImportOperationOutcomes = uniqueIDForImportOperationOutcomes;\n+            return this;\n+        }\n+\n+        public Builder uploadIdForOperationOutcomes(String uploadIdForOperationOutcomes) {\n+            this.uploadIdForOperationOutcomes = uploadIdForOperationOutcomes;\n+            return this;\n+        }\n+\n+        public Builder dataPacksForOperationOutcomes(List<PartETag> dataPacksForOperationOutcomes) {\n+            this.dataPacksForOperationOutcomes = dataPacksForOperationOutcomes;\n+            return this;\n+        }\n+\n+        public Builder partNumForOperationOutcomes(int partNumForOperationOutcomes) {\n+            this.partNumForOperationOutcomes = partNumForOperationOutcomes;\n+            return this;\n+        }\n+\n+        public Builder uploadIdForFailureOperationOutcomes(String uploadIdForFailureOperationOutcomes) {\n+            this.uploadIdForFailureOperationOutcomes = uploadIdForFailureOperationOutcomes;\n+            return this;\n+        }\n+\n+        public Builder dataPacksForFailureOperationOutcomes(List<PartETag> dataPacksForFailureOperationOutcomes) {\n+            this.dataPacksForFailureOperationOutcomes = dataPacksForFailureOperationOutcomes;\n+            return this;\n+        }\n+\n+        public Builder partNumForFailureOperationOutcomes(int partNumForFailureOperationOutcomes) {\n+            this.partNumForFailureOperationOutcomes = partNumForFailureOperationOutcomes;\n+            return this;\n+        }\n+\n+        public Builder totalReadMilliSeconds(long totalReadMilliSeconds) {\n+            this.totalReadMilliSeconds = totalReadMilliSeconds;\n+            return this;\n+        }\n+\n+        public Builder totalValidationMilliSeconds(long totalValidationMilliSeconds) {\n+            this.totalValidationMilliSeconds = totalValidationMilliSeconds;\n+            return this;\n+        }\n+\n+        public Builder importFileSize(long importFileSize) {\n+            this.importFileSize = importFileSize;\n+            return this;\n+        }\n+\n+        public Builder totalWriteMilliSeconds(long totalWriteMilliSeconds) {\n+            this.totalWriteMilliSeconds = totalWriteMilliSeconds;\n+            return this;\n+        }\n+\n+        public Builder inFlyRateBeginMilliSeconds(long inFlyRateBeginMilliSeconds) {\n+            this.inFlyRateBeginMilliSeconds = inFlyRateBeginMilliSeconds;\n+            return this;\n+        }\n+\n+        public ImportCheckPointData build(){\n+            ImportCheckPointData importCheckPointData = new ImportCheckPointData();\n+            importCheckPointData.importPartitionWorkitem = this.importPartitionWorkitem;\n+            importCheckPointData.numOfProcessedResources = this.numOfProcessedResources;\n+            importCheckPointData.importPartitionResourceType = this.importPartitionResourceType;\n+            importCheckPointData.numOfImportedResources = this.numOfImportedResources;\n+            importCheckPointData.numOfImportFailures = this.numOfImportFailures;\n+            importCheckPointData.uniqueIDForImportFailureOperationOutcomes = this.uniqueIDForImportFailureOperationOutcomes;\n+            importCheckPointData.uniqueIDForImportOperationOutcomes = this.uniqueIDForImportOperationOutcomes;\n+            importCheckPointData.uploadIdForOperationOutcomes = this.uploadIdForOperationOutcomes;\n+            importCheckPointData.dataPacksForOperationOutcomes = this.dataPacksForOperationOutcomes;\n+            importCheckPointData.partNumForOperationOutcomes = this.partNumForOperationOutcomes;\n+            importCheckPointData.uploadIdForFailureOperationOutcomes = this.uploadIdForFailureOperationOutcomes;\n+            importCheckPointData.dataPacksForFailureOperationOutcomes = this.dataPacksForFailureOperationOutcomes;\n+            importCheckPointData.partNumForFailureOperationOutcomes = this.partNumForFailureOperationOutcomes;\n+            importCheckPointData.totalReadMilliSeconds = this.totalReadMilliSeconds;\n+            importCheckPointData.totalValidationMilliSeconds = this.totalValidationMilliSeconds;\n+            importCheckPointData.totalWriteMilliSeconds = this.totalWriteMilliSeconds;\n+            importCheckPointData.importFileSize = this.importFileSize;\n+            importCheckPointData.inFlyRateBeginMilliSeconds = this.inFlyRateBeginMilliSeconds;\n+\n+            return importCheckPointData;\n+        }\n+    }\n+\n+\n+    public String getImportPartitionWorkitem() {\n+        return importPartitionWorkitem;\n+    }\n+\n+    public int getNumOfProcessedResources() {\n+        return numOfProcessedResources;\n+    }\n+\n+    public void setNumOfProcessedResources(int numOfProcessedResources) {\n+        this.numOfProcessedResources = numOfProcessedResources;\n+    }\n+\n+    public int getNumOfImportedResources() {\n+        return numOfImportedResources;\n+    }\n+\n+    public void setNumOfImportedResources(int numOfImportedResources) {\n+        this.numOfImportedResources = numOfImportedResources;\n+    }\n+\n+    public int getNumOfImportFailures() {\n+        return numOfImportFailures;\n+    }\n+\n+    public void setNumOfImportFailures(int numOfImportFailures) {\n+        this.numOfImportFailures = numOfImportFailures;\n+    }\n+\n+    public int getNumOfToBeImported() {\n+        return numOfToBeImported;\n+    }\n+\n+    public void setNumOfToBeImported(int numOfToBeImported) {\n+        this.numOfToBeImported = numOfToBeImported;\n+    }\n+\n+    public String getImportPartitionResourceType() {\n+        return importPartitionResourceType;\n+    }\n+\n+    public static ImportCheckPointData fromImportTransientUserData(ImportTransientUserData userData) {\n+        return ImportCheckPointData.Builder.builder()\n+                .importPartitionWorkitem(userData.getImportPartitionWorkitem())\n+                .numOfProcessedResources(userData.getNumOfProcessedResources())\n+                .importPartitionResourceType(userData.getImportPartitionResourceType())\n+                .numOfImportedResources(userData.getNumOfImportedResources())\n+                .numOfImportFailures(userData.getNumOfImportFailures())\n+                .uniqueIDForImportFailureOperationOutcomes(userData.getUniqueIDForImportFailureOperationOutcomes())\n+                .uniqueIDForImportOperationOutcomes(userData.getUniqueIDForImportOperationOutcomes())\n+                .uploadIdForOperationOutcomes(userData.getUploadIdForOperationOutcomes())\n+                .dataPacksForOperationOutcomes(userData.getDataPacksForOperationOutcomes())\n+                .partNumForOperationOutcomes(userData.getPartNumForOperationOutcomes())\n+                .uploadIdForFailureOperationOutcomes(userData.getUploadIdForFailureOperationOutcomes())\n+                .dataPacksForFailureOperationOutcomes(userData.getDataPacksForFailureOperationOutcomes())\n+                .partNumForFailureOperationOutcomes(userData.getPartNumForFailureOperationOutcomes())\n+                .totalReadMilliSeconds(userData.getTotalReadMilliSeconds())\n+                .totalValidationMilliSeconds(userData.getTotalValidationMilliSeconds())\n+                .totalWriteMilliSeconds(userData.getTotalWriteMilliSeconds())\n+                .importFileSize(userData.getImportFileSize())\n+                .inFlyRateBeginMilliSeconds(userData.getInFlyRateBeginMilliSeconds())\n+                .build();\n+\n+\n+", "originalCommit": "f5cdbcef85f0d2a6ccd2af4160b24dcc05ee06aa", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "2d007f97fb726f10348fa641c908c7121121a244", "url": "https://github.com/IBM/FHIR/commit/2d007f97fb726f10348fa641c908c7121121a244", "message": "Apply suggestions from code review\r\n\r\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>\n\nCo-authored-by: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-06-16T19:26:33Z", "type": "commit"}, {"oid": "781c926ccb3d24babe991e2c25a2a4f4671ef1d8", "url": "https://github.com/IBM/FHIR/commit/781c926ccb3d24babe991e2c25a2a4f4671ef1d8", "message": "Update fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/jbatch/bulkdata/export/common/TransientUserData.java\r\n\r\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>\n\nCo-authored-by: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-06-16T19:28:54Z", "type": "commit"}]}