{"pr_number": 594, "pr_title": "issue #108 #618 bulkdata export for group members and instruction for exports", "pr_createdAt": "2020-01-15T19:56:15Z", "pr_url": "https://github.com/IBM/FHIR/pull/594", "timeline": [{"oid": "a8c8b576f187809f0ec72fc7d0290c7b453644c2", "url": "https://github.com/IBM/FHIR/commit/a8c8b576f187809f0ec72fc7d0290c7b453644c2", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:33:21Z", "type": "commit"}, {"oid": "fd5d848eb4bda4a6c0dd04740c6df46bfe1a5337", "url": "https://github.com/IBM/FHIR/commit/fd5d848eb4bda4a6c0dd04740c6df46bfe1a5337", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:33:43Z", "type": "commit"}, {"oid": "3cd91fb12e7c4d0f437203a193773ddd3f32f95f", "url": "https://github.com/IBM/FHIR/commit/3cd91fb12e7c4d0f437203a193773ddd3f32f95f", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:34:05Z", "type": "commit"}, {"oid": "b6a060142056769ba7f49b79281389b3c3af8aeb", "url": "https://github.com/IBM/FHIR/commit/b6a060142056769ba7f49b79281389b3c3af8aeb", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:34:21Z", "type": "commit"}, {"oid": "82c49e6403e51899ce8afea8947d728fb086112a", "url": "https://github.com/IBM/FHIR/commit/82c49e6403e51899ce8afea8947d728fb086112a", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:34:39Z", "type": "commit"}, {"oid": "f0b7845ac77ed7b7d913cc3f9d44011fbe310e03", "url": "https://github.com/IBM/FHIR/commit/f0b7845ac77ed7b7d913cc3f9d44011fbe310e03", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:35:08Z", "type": "commit"}, {"oid": "b300473427c7e7550e8aca6a15004fafbb900f6a", "url": "https://github.com/IBM/FHIR/commit/b300473427c7e7550e8aca6a15004fafbb900f6a", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:35:31Z", "type": "commit"}, {"oid": "2b5f305451a3a2ef065b00f9f55996d0a61827d2", "url": "https://github.com/IBM/FHIR/commit/2b5f305451a3a2ef065b00f9f55996d0a61827d2", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:35:43Z", "type": "commit"}, {"oid": "d80dd887c13ef9589b92a39bafb144ddc7d0f952", "url": "https://github.com/IBM/FHIR/commit/d80dd887c13ef9589b92a39bafb144ddc7d0f952", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:36:08Z", "type": "commit"}, {"oid": "b4aa4f9ba945dd6665688265e2170641c5d97fc0", "url": "https://github.com/IBM/FHIR/commit/b4aa4f9ba945dd6665688265e2170641c5d97fc0", "message": "Update fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:57:26Z", "type": "commit"}, {"oid": "a50e91deb919bf5c15ef5710bfb1eb1640556ba2", "url": "https://github.com/IBM/FHIR/commit/a50e91deb919bf5c15ef5710bfb1eb1640556ba2", "message": "issue #108 changes per review comments\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-23T15:10:03Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE3NzkxNw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370177917", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n          \n          \n            \n            BulkData web application writes the exported FHIR resources to an IBM Cloud Object Storage (COS) or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file. The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS:", "author": "lmsurpre", "createdAt": "2020-01-23T15:15:32Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,143 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 Bulk data operations\n+### 4.10.1 Bulk data export\n+Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).\n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* module implements the REST APIs for bulk data export as FHIR operations.  There are three operations:\n+* ExportOperation - system export\n+* PatientExportOperation - Patient export\n+* GroupExportOperation - group export.\n+Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* module to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* module for the above 3 export operations:  \n+\n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war. This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:\n+\n+```xml\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: ", "originalCommit": "a50e91deb919bf5c15ef5710bfb1eb1640556ba2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "8aeb5c9941d7e38073086cd1446341840c7ae0be", "url": "https://github.com/IBM/FHIR/commit/8aeb5c9941d7e38073086cd1446341840c7ae0be", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-23T17:23:03Z", "type": "commit"}, {"oid": "b8bef36bbee277673e25908308c6b0762bffaa4a", "url": "https://github.com/IBM/FHIR/commit/b8bef36bbee277673e25908308c6b0762bffaa4a", "message": "issue #108 bulkdata export for group members initial code drop\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-15T19:55:38Z", "type": "commit"}, {"oid": "cb069a19f62a88115d8126d0aef936707281e07e", "url": "https://github.com/IBM/FHIR/commit/cb069a19f62a88115d8126d0aef936707281e07e", "message": "issue #108 add support for nested group\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-16T15:17:15Z", "type": "commit"}, {"oid": "ed52a92c0352c56f4f97cf317d43a1385b62d835", "url": "https://github.com/IBM/FHIR/commit/ed52a92c0352c56f4f97cf317d43a1385b62d835", "message": "issue #108 fix for exit status\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-16T16:25:49Z", "type": "commit"}, {"oid": "3ff78cbc8e56ea11e4ee63f8edda9ca387d73a9d", "url": "https://github.com/IBM/FHIR/commit/3ff78cbc8e56ea11e4ee63f8edda9ca387d73a9d", "message": "issue #108 changes to survive circle reference of groups\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-16T18:58:55Z", "type": "commit"}, {"oid": "6434c62a97873e1b6cf977201e8e98fb55a89c36", "url": "https://github.com/IBM/FHIR/commit/6434c62a97873e1b6cf977201e8e98fb55a89c36", "message": "issue #108 adjust log level to fine for some locations\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-16T19:36:15Z", "type": "commit"}, {"oid": "34dd7262b0ab58f432964898676c370c63df8b20", "url": "https://github.com/IBM/FHIR/commit/34dd7262b0ab58f432964898676c370c63df8b20", "message": "issue #108 add integration tests for export operations\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-17T14:13:50Z", "type": "commit"}, {"oid": "411dfae242931e3c85c0ae79e2edcbc4a0acd7f5", "url": "https://github.com/IBM/FHIR/commit/411dfae242931e3c85c0ae79e2edcbc4a0acd7f5", "message": "issue #108 instruction for bulkdata export\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-20T22:03:52Z", "type": "commit"}, {"oid": "4247b9102386532ab7e481ca0989dc5659031c72", "url": "https://github.com/IBM/FHIR/commit/4247b9102386532ab7e481ca0989dc5659031c72", "message": "issue #108 added description for the new integration tests\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-20T22:38:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NDYwMw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368764603", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n          \n          \n            \n            BulkData Export is implemented according to [FHIR r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).", "author": "prb112", "createdAt": "2020-01-21T00:15:48Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   ", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NDY0MQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368764641", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            There are 2 projects involved inside the implementation:\n          \n          \n            \n            There are 2 modules involved inside the implementation:", "author": "prb112", "createdAt": "2020-01-21T00:16:03Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NDc2Mg==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368764762", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            (There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n          \n          \n            \n            To integration test BulkData, there are tests in ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export.", "author": "prb112", "createdAt": "2020-01-21T00:16:51Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  ", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NDgwMQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368764801", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  \n          \n          \n            \n            \n          \n          \n            \n            There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:", "author": "prb112", "createdAt": "2020-01-21T00:17:10Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n+There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  ", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NTE2Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368765163", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n          \n          \n            \n            The *fhir-operation-bulkdata* project implements the REST APIs for Bulkdata export as FHIR operations.  There are three operations ExportOperation - system export, PatientExportOperation - Patient export and GroupExportOperation - group export.  Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.", "author": "prb112", "createdAt": "2020-01-21T00:19:31Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   ", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NTQ2OA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368765468", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The fhir-bulkimportexport-webapp project is also a wrapper for the whole BulkData web application, which generates fhir-bulkimportexport.war, this war should be copied to the apps directory of the liberty fhir-server instance. Following is a sample deployment description for fhir-bulkimportexport.war in server.xml of liberty server:\n          \n          \n            \n            The *fhir-bulkimportexport-webapp* project is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war.   This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:", "author": "prb112", "createdAt": "2020-01-21T00:21:36Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n+There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  \n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The fhir-bulkimportexport-webapp project is also a wrapper for the whole BulkData web application, which generates fhir-bulkimportexport.war, this war should be copied to the apps directory of the liberty fhir-server instance. Following is a sample deployment description for fhir-bulkimportexport.war in server.xml of liberty server:", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NTQ5OQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368765499", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            ```\n          \n          \n            \n            ``` xml", "author": "prb112", "createdAt": "2020-01-21T00:21:49Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n+There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  \n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The fhir-bulkimportexport-webapp project is also a wrapper for the whole BulkData web application, which generates fhir-bulkimportexport.war, this war should be copied to the apps directory of the liberty fhir-server instance. Following is a sample deployment description for fhir-bulkimportexport.war in server.xml of liberty server:\n+\n+```", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NTc2MQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368765761", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The exported FHIR resources can be configured to be written into IBM COS or Amazon S3 bucket in the per-tenant bulkdata.json configuration file which is put under the tenant configuration directory of the fhir-server instance. Following is a sample bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n          \n          \n            \n            BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS:", "author": "prb112", "createdAt": "2020-01-21T00:23:48Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n+There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  \n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The fhir-bulkimportexport-webapp project is also a wrapper for the whole BulkData web application, which generates fhir-bulkimportexport.war, this war should be copied to the apps directory of the liberty fhir-server instance. Following is a sample deployment description for fhir-bulkimportexport.war in server.xml of liberty server:\n+\n+```\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+The exported FHIR resources can be configured to be written into IBM COS or Amazon S3 bucket in the per-tenant bulkdata.json configuration file which is put under the tenant configuration directory of the fhir-server instance. Following is a sample bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: ", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NTc4Ng==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368765786", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            ```\n          \n          \n            \n            ``` json", "author": "prb112", "createdAt": "2020-01-21T00:23:58Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n+There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  \n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The fhir-bulkimportexport-webapp project is also a wrapper for the whole BulkData web application, which generates fhir-bulkimportexport.war, this war should be copied to the apps directory of the liberty fhir-server instance. Following is a sample deployment description for fhir-bulkimportexport.war in server.xml of liberty server:\n+\n+```\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+The exported FHIR resources can be configured to be written into IBM COS or Amazon S3 bucket in the per-tenant bulkdata.json configuration file which is put under the tenant configuration directory of the fhir-server instance. Following is a sample bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NTk1OA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368765958", "bodyText": "maybe 1-2 output examples is OK?", "author": "prb112", "createdAt": "2020-01-21T00:25:06Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n+There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  \n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The fhir-bulkimportexport-webapp project is also a wrapper for the whole BulkData web application, which generates fhir-bulkimportexport.war, this war should be copied to the apps directory of the liberty fhir-server instance. Following is a sample deployment description for fhir-bulkimportexport.war in server.xml of liberty server:\n+\n+```\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+The exported FHIR resources can be configured to be written into IBM COS or Amazon S3 bucket in the per-tenant bulkdata.json configuration file which is put under the tenant configuration directory of the fhir-server instance. Following is a sample bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+    \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+To use Amazon S3 bucket for exporting, please set cos.credential.ibm to \"N\", set cos.api.key to S3 access key, and set cos.srvinst.id to S3 secret key. This following is a sample path to the exported ndjson file, the full path can be gotten from the response to the polling location request after the export request (please refer to Fhir BulkDate spec for details).  \n+\n+```\n+\t.../fhir-bulkimexport-connectathon/6xjd4M8afi6Xo95eYv7zPxBqSCoOEFywZLoqH1QBtbw=/Patient_1.ndjson\n+```\n+Following is the beautified response of sample polling location request after the export is finished:\n+\n+```\n+{\n+\"transactionTime\": \"2020/01/20 16:53:41.160 -0500\",\n+\"request\": \"/$export?_type=\",\n+\"requiresAccessToken\": false,\n+\"output\" : [\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"AllergyIntolerance\", ", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NTk4OQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368765989", "bodyText": "Suggested change", "author": "prb112", "createdAt": "2020-01-21T00:25:17Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n+There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  \n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The fhir-bulkimportexport-webapp project is also a wrapper for the whole BulkData web application, which generates fhir-bulkimportexport.war, this war should be copied to the apps directory of the liberty fhir-server instance. Following is a sample deployment description for fhir-bulkimportexport.war in server.xml of liberty server:\n+\n+```\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+The exported FHIR resources can be configured to be written into IBM COS or Amazon S3 bucket in the per-tenant bulkdata.json configuration file which is put under the tenant configuration directory of the fhir-server instance. Following is a sample bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+    \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+To use Amazon S3 bucket for exporting, please set cos.credential.ibm to \"N\", set cos.api.key to S3 access key, and set cos.srvinst.id to S3 secret key. This following is a sample path to the exported ndjson file, the full path can be gotten from the response to the polling location request after the export request (please refer to Fhir BulkDate spec for details).  \n+\n+```\n+\t.../fhir-bulkimexport-connectathon/6xjd4M8afi6Xo95eYv7zPxBqSCoOEFywZLoqH1QBtbw=/Patient_1.ndjson\n+```\n+Following is the beautified response of sample polling location request after the export is finished:\n+\n+```\n+{\n+\"transactionTime\": \"2020/01/20 16:53:41.160 -0500\",\n+\"request\": \"/$export?_type=\",\n+\"requiresAccessToken\": false,\n+\"output\" : [\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_2.ndjson\", \n+    \"count\": 8},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_1.ndjson\", \n+    \"count\": 234},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_2.ndjson\", \n+    \"count\": 81},\n+  { \"type\" : \"Group\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Group_1.ndjson\", \n+    \"count\": 15},\n+  { \"type\" : \"Condition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Condition_1.ndjson\", \n+    \"count\": 30},\n+  { \"type\" : \"Condition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Condition_2.ndjson\", \n+    \"count\": 21},\n+  { \"type\" : \"Composition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Composition_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"Composition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Composition_2.ndjson\", \n+    \"count\": 8}]\n+}\n+", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NjIzNg==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368766236", "bodyText": "I am not sure I follow this?\nIf a file is written out to Object Storage, it's public by default? only protected by obfuscation?\nThe above paragraph is a bit tricky to read", "author": "prb112", "createdAt": "2020-01-21T00:26:54Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n+There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  \n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The fhir-bulkimportexport-webapp project is also a wrapper for the whole BulkData web application, which generates fhir-bulkimportexport.war, this war should be copied to the apps directory of the liberty fhir-server instance. Following is a sample deployment description for fhir-bulkimportexport.war in server.xml of liberty server:\n+\n+```\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+The exported FHIR resources can be configured to be written into IBM COS or Amazon S3 bucket in the per-tenant bulkdata.json configuration file which is put under the tenant configuration directory of the fhir-server instance. Following is a sample bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+    \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+To use Amazon S3 bucket for exporting, please set cos.credential.ibm to \"N\", set cos.api.key to S3 access key, and set cos.srvinst.id to S3 secret key. This following is a sample path to the exported ndjson file, the full path can be gotten from the response to the polling location request after the export request (please refer to Fhir BulkDate spec for details).  \n+\n+```\n+\t.../fhir-bulkimexport-connectathon/6xjd4M8afi6Xo95eYv7zPxBqSCoOEFywZLoqH1QBtbw=/Patient_1.ndjson\n+```\n+Following is the beautified response of sample polling location request after the export is finished:\n+\n+```\n+{\n+\"transactionTime\": \"2020/01/20 16:53:41.160 -0500\",\n+\"request\": \"/$export?_type=\",\n+\"requiresAccessToken\": false,\n+\"output\" : [\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_2.ndjson\", \n+    \"count\": 8},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_1.ndjson\", \n+    \"count\": 234},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_2.ndjson\", \n+    \"count\": 81},\n+  { \"type\" : \"Group\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Group_1.ndjson\", \n+    \"count\": 15},\n+  { \"type\" : \"Condition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Condition_1.ndjson\", \n+    \"count\": 30},\n+  { \"type\" : \"Condition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Condition_2.ndjson\", \n+    \"count\": 21},\n+  { \"type\" : \"Composition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Composition_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"Composition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Composition_2.ndjson\", \n+    \"count\": 8}]\n+}\n+\n+```\n+\n+The exported ndjson file is configured with public access automatically and with 2 hours expiration time, the randomly generated secret in the path is used to protect the file. please notice that IBM COS doesn't support expiration time for each single COS object, so please configure retention policy (e.g, 1 day) for the bucket if IBM COS is used. And for both Amazon S3 and IBM COS, please remember that public access should never be configured to the bucket itself.  ", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODk5MDQ3MQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368990471", "bodyText": "yes, the object is written with public access acl setting.\nFor safe reason, I added expiration time to the objects, and also mentioned that we should never give public access for the bucket itself which allow the user to list and get all the generated objects.", "author": "albertwang-ibm", "createdAt": "2020-01-21T13:11:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NjIzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODk5MzI4Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368993283", "bodyText": "hum, this doesn't seem ideal.  Are there any alternatives?", "author": "prb112", "createdAt": "2020-01-21T13:16:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NjIzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTAxODMyNA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369018324", "bodyText": "The other similar choice is the pre-signed urls which provide temp url for read and write, but the idea is the similar - a temp url with secret(signature) in path and can expire automatically.  https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-presign-url.    and this approach is a little bit complicated than what I did in codes.   This is the url format of this approach:\nvar requestUrl = endpoint + '/' +\nbucket + '/' +\nobjectKey + '?' +\nstandardizedQuerystring +\n'&X-Amz-Signature=' +\nsignature;", "author": "albertwang-ibm", "createdAt": "2020-01-21T14:04:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NjIzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI0MjUxOA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369242518", "bodyText": "I'm curious what Lee thinks.  Otherwise looks good.", "author": "prb112", "createdAt": "2020-01-21T21:05:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NjIzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc2MjA2Ng==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369762066", "bodyText": "Albert and I came up with this approach together.  If there is enough \"entropy\" in the name, I think it would be acceptable for at least some use cases.  Similar to a box \"share\" link or a password reset link you get via email.  I do wish we could totally hide the internals though (i.e. not leak our bucket name).\nAnd we should be very clear that its publicly accessible (if you have the link).", "author": "lmsurpre", "createdAt": "2020-01-22T19:36:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NjIzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc2NTQxNA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369765414", "bodyText": "Yeah - I 100% agree.", "author": "prb112", "createdAt": "2020-01-22T19:43:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NjIzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc2NTgzMA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369765830", "bodyText": "One design goal for this was to keep us out of playing \"middleman\" for these downloads.  In most of our deployments we have a 60 second HTTP timeout, so the download sort of needs to be a direct connection with COS.\nhttp://hl7.org/fhir/uv/bulkdata/STU1/authorization/index.html explains how to use SMART authentication to provide a temporary access token, but I'm not sure how to do that.", "author": "lmsurpre", "createdAt": "2020-01-22T19:44:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NjIzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc3NjYwMg==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369776602", "bodyText": "I thought about generate temp bear token for the download, but the problem is that the bear token could give the user full access to the bucket even COS service. maybe we could create a spec user/apikey without any access by default, and then give read access in the object ACL to this user, and generate the bear token for user to download the object, this will be much more complicated ...", "author": "albertwang-ibm", "createdAt": "2020-01-22T20:07:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NjIzNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NjI0OQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368766249", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            ```\n          \n          \n            \n            ``` xml", "author": "prb112", "createdAt": "2020-01-21T00:27:04Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n+There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  \n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The fhir-bulkimportexport-webapp project is also a wrapper for the whole BulkData web application, which generates fhir-bulkimportexport.war, this war should be copied to the apps directory of the liberty fhir-server instance. Following is a sample deployment description for fhir-bulkimportexport.war in server.xml of liberty server:\n+\n+```\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+The exported FHIR resources can be configured to be written into IBM COS or Amazon S3 bucket in the per-tenant bulkdata.json configuration file which is put under the tenant configuration directory of the fhir-server instance. Following is a sample bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+    \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+To use Amazon S3 bucket for exporting, please set cos.credential.ibm to \"N\", set cos.api.key to S3 access key, and set cos.srvinst.id to S3 secret key. This following is a sample path to the exported ndjson file, the full path can be gotten from the response to the polling location request after the export request (please refer to Fhir BulkDate spec for details).  \n+\n+```\n+\t.../fhir-bulkimexport-connectathon/6xjd4M8afi6Xo95eYv7zPxBqSCoOEFywZLoqH1QBtbw=/Patient_1.ndjson\n+```\n+Following is the beautified response of sample polling location request after the export is finished:\n+\n+```\n+{\n+\"transactionTime\": \"2020/01/20 16:53:41.160 -0500\",\n+\"request\": \"/$export?_type=\",\n+\"requiresAccessToken\": false,\n+\"output\" : [\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_2.ndjson\", \n+    \"count\": 8},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_1.ndjson\", \n+    \"count\": 234},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_2.ndjson\", \n+    \"count\": 81},\n+  { \"type\" : \"Group\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Group_1.ndjson\", \n+    \"count\": 15},\n+  { \"type\" : \"Condition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Condition_1.ndjson\", \n+    \"count\": 30},\n+  { \"type\" : \"Condition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Condition_2.ndjson\", \n+    \"count\": 21},\n+  { \"type\" : \"Composition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Composition_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"Composition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Composition_2.ndjson\", \n+    \"count\": 8}]\n+}\n+\n+```\n+\n+The exported ndjson file is configured with public access automatically and with 2 hours expiration time, the randomly generated secret in the path is used to protect the file. please notice that IBM COS doesn't support expiration time for each single COS object, so please configure retention policy (e.g, 1 day) for the bucket if IBM COS is used. And for both Amazon S3 and IBM COS, please remember that public access should never be configured to the bucket itself.  \n+  \n+JavaBatch feature must be enabled in server.xml as following for liberty server:\n+\n+```", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NjI4Nw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368766287", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            And JavaBatch user used in bulkdata.json can be configured in server.xml as following: \n          \n          \n            \n            The JavaBatch user is configured in server.xml and the bulkdata.json:", "author": "prb112", "createdAt": "2020-01-21T00:27:22Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n+There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  \n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The fhir-bulkimportexport-webapp project is also a wrapper for the whole BulkData web application, which generates fhir-bulkimportexport.war, this war should be copied to the apps directory of the liberty fhir-server instance. Following is a sample deployment description for fhir-bulkimportexport.war in server.xml of liberty server:\n+\n+```\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+The exported FHIR resources can be configured to be written into IBM COS or Amazon S3 bucket in the per-tenant bulkdata.json configuration file which is put under the tenant configuration directory of the fhir-server instance. Following is a sample bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+    \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+To use Amazon S3 bucket for exporting, please set cos.credential.ibm to \"N\", set cos.api.key to S3 access key, and set cos.srvinst.id to S3 secret key. This following is a sample path to the exported ndjson file, the full path can be gotten from the response to the polling location request after the export request (please refer to Fhir BulkDate spec for details).  \n+\n+```\n+\t.../fhir-bulkimexport-connectathon/6xjd4M8afi6Xo95eYv7zPxBqSCoOEFywZLoqH1QBtbw=/Patient_1.ndjson\n+```\n+Following is the beautified response of sample polling location request after the export is finished:\n+\n+```\n+{\n+\"transactionTime\": \"2020/01/20 16:53:41.160 -0500\",\n+\"request\": \"/$export?_type=\",\n+\"requiresAccessToken\": false,\n+\"output\" : [\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_2.ndjson\", \n+    \"count\": 8},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_1.ndjson\", \n+    \"count\": 234},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_2.ndjson\", \n+    \"count\": 81},\n+  { \"type\" : \"Group\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Group_1.ndjson\", \n+    \"count\": 15},\n+  { \"type\" : \"Condition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Condition_1.ndjson\", \n+    \"count\": 30},\n+  { \"type\" : \"Condition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Condition_2.ndjson\", \n+    \"count\": 21},\n+  { \"type\" : \"Composition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Composition_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"Composition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Composition_2.ndjson\", \n+    \"count\": 8}]\n+}\n+\n+```\n+\n+The exported ndjson file is configured with public access automatically and with 2 hours expiration time, the randomly generated secret in the path is used to protect the file. please notice that IBM COS doesn't support expiration time for each single COS object, so please configure retention policy (e.g, 1 day) for the bucket if IBM COS is used. And for both Amazon S3 and IBM COS, please remember that public access should never be configured to the bucket itself.  \n+  \n+JavaBatch feature must be enabled in server.xml as following for liberty server:\n+\n+```\n+    <!-- Enable features -->\n+    <featureManager>\n+        ...\n+        <feature>batchManagement-1.0</feature>\n+        ...\n+    </featureManager>\n+```\n+And JavaBatch user used in bulkdata.json can be configured in server.xml as following: ", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NjYxOA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368766618", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Please notice that a user with at least batchSubmitter role should be used for batch-user of bulkdata.json.\n          \n          \n            \n            Note: The user referenced in the bulkdata.json must have a role of at least batchSubmitter.", "author": "prb112", "createdAt": "2020-01-21T00:29:38Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n+There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  \n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The fhir-bulkimportexport-webapp project is also a wrapper for the whole BulkData web application, which generates fhir-bulkimportexport.war, this war should be copied to the apps directory of the liberty fhir-server instance. Following is a sample deployment description for fhir-bulkimportexport.war in server.xml of liberty server:\n+\n+```\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+The exported FHIR resources can be configured to be written into IBM COS or Amazon S3 bucket in the per-tenant bulkdata.json configuration file which is put under the tenant configuration directory of the fhir-server instance. Following is a sample bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+    \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+To use Amazon S3 bucket for exporting, please set cos.credential.ibm to \"N\", set cos.api.key to S3 access key, and set cos.srvinst.id to S3 secret key. This following is a sample path to the exported ndjson file, the full path can be gotten from the response to the polling location request after the export request (please refer to Fhir BulkDate spec for details).  \n+\n+```\n+\t.../fhir-bulkimexport-connectathon/6xjd4M8afi6Xo95eYv7zPxBqSCoOEFywZLoqH1QBtbw=/Patient_1.ndjson\n+```\n+Following is the beautified response of sample polling location request after the export is finished:\n+\n+```\n+{\n+\"transactionTime\": \"2020/01/20 16:53:41.160 -0500\",\n+\"request\": \"/$export?_type=\",\n+\"requiresAccessToken\": false,\n+\"output\" : [\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_2.ndjson\", \n+    \"count\": 8},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_1.ndjson\", \n+    \"count\": 234},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_2.ndjson\", \n+    \"count\": 81},\n+  { \"type\" : \"Group\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Group_1.ndjson\", \n+    \"count\": 15},\n+  { \"type\" : \"Condition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Condition_1.ndjson\", \n+    \"count\": 30},\n+  { \"type\" : \"Condition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Condition_2.ndjson\", \n+    \"count\": 21},\n+  { \"type\" : \"Composition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Composition_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"Composition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Composition_2.ndjson\", \n+    \"count\": 8}]\n+}\n+\n+```\n+\n+The exported ndjson file is configured with public access automatically and with 2 hours expiration time, the randomly generated secret in the path is used to protect the file. please notice that IBM COS doesn't support expiration time for each single COS object, so please configure retention policy (e.g, 1 day) for the bucket if IBM COS is used. And for both Amazon S3 and IBM COS, please remember that public access should never be configured to the bucket itself.  \n+  \n+JavaBatch feature must be enabled in server.xml as following for liberty server:\n+\n+```\n+    <!-- Enable features -->\n+    <featureManager>\n+        ...\n+        <feature>batchManagement-1.0</feature>\n+        ...\n+    </featureManager>\n+```\n+And JavaBatch user used in bulkdata.json can be configured in server.xml as following: \n+\n+```    \n+<authorization-roles id=\"com.ibm.ws.batch\">\n+\t<security-role name=\"batchAdmin\">\t\n+\t\t<user name=\"fhiradmin\"/>\t\n+\t</security-role>\n+\t<security-role name=\"batchSubmitter\">\n+\t\t<user name=\"fhiruser\"/>\n+\t</security-role>\n+\t<security-role name=\"batchMonitor\">\n+\t\t<user name=\"fhiradmin\"/>\n+\t\t<user name=\"fhiruser\"/>\n+\t</security-role>\n+</authorization-roles>\n+```\n+Please notice that a user with at least batchSubmitter role should be used for batch-user of bulkdata.json.", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NjY3Nw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368766677", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            By default, in-memory derby database is used for persistence of the JavaBatch Jobs. Instruction is also provided in \"Configuring a Liberty Datasource with API Key\" section of the DB2OnCloudSetup guide to configure DB2 service in IBM Clouds as JavaBatch persistence store. Liberty JavaBath framework creates the Database, DB schema and tables automatically by default for both approaches.   \n          \n          \n            \n            By default, in-memory Derby database is used for persistence of the JavaBatch Jobs. Instruction is also provided in \"Configuring a Liberty Datasource with API Key\" section of the DB2OnCloudSetup guide to configure DB2 service in IBM Clouds as JavaBatch persistence store. Liberty JavaBatch framework creates the Database, DB schema and tables automatically by default for both approaches.", "author": "prb112", "createdAt": "2020-01-21T00:30:07Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n+There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  \n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The fhir-bulkimportexport-webapp project is also a wrapper for the whole BulkData web application, which generates fhir-bulkimportexport.war, this war should be copied to the apps directory of the liberty fhir-server instance. Following is a sample deployment description for fhir-bulkimportexport.war in server.xml of liberty server:\n+\n+```\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+The exported FHIR resources can be configured to be written into IBM COS or Amazon S3 bucket in the per-tenant bulkdata.json configuration file which is put under the tenant configuration directory of the fhir-server instance. Following is a sample bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+    \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+To use Amazon S3 bucket for exporting, please set cos.credential.ibm to \"N\", set cos.api.key to S3 access key, and set cos.srvinst.id to S3 secret key. This following is a sample path to the exported ndjson file, the full path can be gotten from the response to the polling location request after the export request (please refer to Fhir BulkDate spec for details).  \n+\n+```\n+\t.../fhir-bulkimexport-connectathon/6xjd4M8afi6Xo95eYv7zPxBqSCoOEFywZLoqH1QBtbw=/Patient_1.ndjson\n+```\n+Following is the beautified response of sample polling location request after the export is finished:\n+\n+```\n+{\n+\"transactionTime\": \"2020/01/20 16:53:41.160 -0500\",\n+\"request\": \"/$export?_type=\",\n+\"requiresAccessToken\": false,\n+\"output\" : [\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_2.ndjson\", \n+    \"count\": 8},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_1.ndjson\", \n+    \"count\": 234},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_2.ndjson\", \n+    \"count\": 81},\n+  { \"type\" : \"Group\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Group_1.ndjson\", \n+    \"count\": 15},\n+  { \"type\" : \"Condition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Condition_1.ndjson\", \n+    \"count\": 30},\n+  { \"type\" : \"Condition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Condition_2.ndjson\", \n+    \"count\": 21},\n+  { \"type\" : \"Composition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Composition_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"Composition\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Composition_2.ndjson\", \n+    \"count\": 8}]\n+}\n+\n+```\n+\n+The exported ndjson file is configured with public access automatically and with 2 hours expiration time, the randomly generated secret in the path is used to protect the file. please notice that IBM COS doesn't support expiration time for each single COS object, so please configure retention policy (e.g, 1 day) for the bucket if IBM COS is used. And for both Amazon S3 and IBM COS, please remember that public access should never be configured to the bucket itself.  \n+  \n+JavaBatch feature must be enabled in server.xml as following for liberty server:\n+\n+```\n+    <!-- Enable features -->\n+    <featureManager>\n+        ...\n+        <feature>batchManagement-1.0</feature>\n+        ...\n+    </featureManager>\n+```\n+And JavaBatch user used in bulkdata.json can be configured in server.xml as following: \n+\n+```    \n+<authorization-roles id=\"com.ibm.ws.batch\">\n+\t<security-role name=\"batchAdmin\">\t\n+\t\t<user name=\"fhiradmin\"/>\t\n+\t</security-role>\n+\t<security-role name=\"batchSubmitter\">\n+\t\t<user name=\"fhiruser\"/>\n+\t</security-role>\n+\t<security-role name=\"batchMonitor\">\n+\t\t<user name=\"fhiradmin\"/>\n+\t\t<user name=\"fhiruser\"/>\n+\t</security-role>\n+</authorization-roles>\n+```\n+Please notice that a user with at least batchSubmitter role should be used for batch-user of bulkdata.json.\n+\n+By default, in-memory derby database is used for persistence of the JavaBatch Jobs. Instruction is also provided in \"Configuring a Liberty Datasource with API Key\" section of the DB2OnCloudSetup guide to configure DB2 service in IBM Clouds as JavaBatch persistence store. Liberty JavaBath framework creates the Database, DB schema and tables automatically by default for both approaches.   ", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NzA1Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368767053", "bodyText": "maybe the values that can be set above should be described for the client?\nAlso cos.bucket.prefix ? it seems pretty useful.", "author": "prb112", "createdAt": "2020-01-21T00:32:39Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n+There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  \n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The fhir-bulkimportexport-webapp project is also a wrapper for the whole BulkData web application, which generates fhir-bulkimportexport.war, this war should be copied to the apps directory of the liberty fhir-server instance. Following is a sample deployment description for fhir-bulkimportexport.war in server.xml of liberty server:\n+\n+```\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+The exported FHIR resources can be configured to be written into IBM COS or Amazon S3 bucket in the per-tenant bulkdata.json configuration file which is put under the tenant configuration directory of the fhir-server instance. Following is a sample bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+    \"contextRoot\" : \"/fhir-server/api/v4\"\n+}", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODk5MzE0Ng==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368993146", "bodyText": "good point, will add. cos.bucket.prefix is generated automatically by codes, so I didn't add it.", "author": "albertwang-ibm", "createdAt": "2020-01-21T13:16:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NzA1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NzA4Mg==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368767082", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                \"contextRoot\" : \"/fhir-server/api/v4\"\n          \n          \n            \n               \"contextRoot\" : \"/fhir-server/api/v4\"", "author": "prb112", "createdAt": "2020-01-21T00:32:49Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,135 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData export is implemented according to [Fhir r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 projects involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+(There is a ExportOperationTest.java in fhir-server-test project with server integration test cases for system, patient and group export)  \n+The fhir-operation-bulkdata project implements the REST APIs for Bulkdata export as FHIR operations, there are ExportOperation, PatientExportOperation and GroupExportOperation defined for system export, patient export and group export accordingly. And these operations call JavaBatch jobs defined in the fhir-bulkimportexport-webapp project to do the real export work.   \n+There are 3 chunk style JavaBatch jobs defined as following in fhir-bulkimportexport-webapp project for the above 3 export operations:  \n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The fhir-bulkimportexport-webapp project is also a wrapper for the whole BulkData web application, which generates fhir-bulkimportexport.war, this war should be copied to the apps directory of the liberty fhir-server instance. Following is a sample deployment description for fhir-bulkimportexport.war in server.xml of liberty server:\n+\n+```\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+The exported FHIR resources can be configured to be written into IBM COS or Amazon S3 bucket in the per-tenant bulkdata.json configuration file which is put under the tenant configuration directory of the fhir-server instance. Following is a sample bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+    \"contextRoot\" : \"/fhir-server/api/v4\"", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NzI3Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368767273", "bodyText": "just a note to Albert... I'll change this in my PR.  so we don't just force DEFAULT_TENANT_ID", "author": "prb112", "createdAt": "2020-01-21T00:34:14Z", "path": "fhir-operation-bulkdata/src/main/java/com/ibm/fhir/operation/bulkdata/processor/impl/CosExportImpl.java", "diffHunk": "@@ -161,13 +163,48 @@ public Parameters exportPatient(String logicalId, MediaType outputFormat, Instan\n         }\n     }\n \n-    // not implemented yet\n     @Override\n     public Parameters exportGroup(String logicalId, MediaType outputFormat, Instant since,\n         List<String> types, List<String> typeFilters, FHIRRequestContext ctx,\n         FHIRResourceHelpers resourceHelper, FHIROperationContext operationContext,\n         BulkDataTenantSpecificCache cache) throws FHIROperationException {\n-        throw new FHIROperationException(\"No $export group operation right now\");\n+\n+        try {\n+            log.fine(\"Using the COS Implementation\");\n+\n+            Map<String, String> properties =", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTAyMzE0MA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369023140", "bodyText": "sounds great!! thanks!", "author": "albertwang-ibm", "createdAt": "2020-01-21T14:13:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NzI3Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NzQxMA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368767410", "bodyText": "on line 121, can you remove the printstacktrace", "author": "prb112", "createdAt": "2020-01-21T00:35:18Z", "path": "fhir-operation-bulkdata/src/main/java/com/ibm/fhir/operation/bulkdata/processor/impl/CosExportImpl.java", "diffHunk": "@@ -161,13 +163,48 @@ public Parameters exportPatient(String logicalId, MediaType outputFormat, Instan\n         }\n     }\n \n-    // not implemented yet\n     @Override", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTAyNDA5NA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369024094", "bodyText": "done", "author": "albertwang-ibm", "createdAt": "2020-01-21T14:15:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2NzQxMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2Nzg2Ng==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368767866", "bodyText": "Suggested change", "author": "prb112", "createdAt": "2020-01-21T00:38:25Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2Nzk3Nw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368767977", "bodyText": "Suggested change", "author": "prb112", "createdAt": "2020-01-21T00:39:14Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODAwOA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768008", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private void ExpandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n          \n          \n            \n                private void expandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)", "author": "prb112", "createdAt": "2020-01-21T00:39:27Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+\n+    }\n+\n+    private void ExpandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODAzMA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768030", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private Group FindGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{\n          \n          \n            \n                private Group findGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{", "author": "prb112", "createdAt": "2020-01-21T00:39:37Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+\n+    }\n+\n+    private void ExpandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n+            throws Exception{\n+        if (group == null) {\n+            return;\n+        }\n+        groupsInPath.add(group.getId());\n+        for (Member member : group.getMember()) {\n+            String refValue = member.getEntity().getReference().getValue();\n+            if (refValue.startsWith(\"Patient\")) {\n+                patients.add(member);\n+            } else if (refValue.startsWith(\"Group\")) {\n+                Group group2 = FindGroupByID(fhirTenant, fhirDatastoreId, refValue.substring(6));\n+                if (!groupsInPath.contains(group.getId())) {\n+                    ExpandGroup2Patients(fhirTenant, fhirDatastoreId, group2, patients, groupsInPath);\n+                }\n+            }\n+        }\n+    }\n+\n+    private Group FindGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODIxMQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768211", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    Group group = FindGroupByID(fhirTenant, fhirDatastoreId, fhirSearchPatientGroupId);\n          \n          \n            \n                    Group group = findGroupByID(fhirTenant, fhirDatastoreId, fhirSearchPatientGroupId);", "author": "prb112", "createdAt": "2020-01-21T00:40:45Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+\n+    }\n+\n+    private void ExpandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n+            throws Exception{\n+        if (group == null) {\n+            return;\n+        }\n+        groupsInPath.add(group.getId());\n+        for (Member member : group.getMember()) {\n+            String refValue = member.getEntity().getReference().getValue();\n+            if (refValue.startsWith(\"Patient\")) {\n+                patients.add(member);\n+            } else if (refValue.startsWith(\"Group\")) {\n+                Group group2 = FindGroupByID(fhirTenant, fhirDatastoreId, refValue.substring(6));\n+                if (!groupsInPath.contains(group.getId())) {\n+                    ExpandGroup2Patients(fhirTenant, fhirDatastoreId, group2, patients, groupsInPath);\n+                }\n+            }\n+        }\n+    }\n+\n+    private Group FindGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{\n+        FHIRRequestContext.set(new FHIRRequestContext(fhirTenant, fhirDatastoreId));\n+        FHIRPersistenceHelper fhirPersistenceHelper = new FHIRPersistenceHelper();\n+        fhirPersistence = fhirPersistenceHelper.getFHIRPersistenceImplementation();\n+\n+        FHIRSearchContext searchContext;\n+        FHIRPersistenceContext persistenceContext;\n+        Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+        queryParameters.put(\"_id\", Arrays.asList(new String[] { groupId }));\n+        searchContext = SearchUtil.parseQueryParameters(Group.class, queryParameters);\n+        List<Resource> resources = null;\n+        FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+        txn.begin();\n+        persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+        resources = fhirPersistence.search(persistenceContext, Group.class).getResource();\n+        txn.commit();\n+\n+        if (resources != null) {\n+            return (Group) resources.get(0);\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    @Override\n+    public Object readItem() throws Exception {\n+        List <String> allCompartmentResourceTypes = CompartmentUtil.getCompartmentResourceTypes(\"Patient\");\n+        if (fhirResourceType == null ) {\n+            resourceTypes = allCompartmentResourceTypes;\n+        } else {\n+            List<String> tmpResourceTypes = Arrays.asList(fhirResourceType.split(\"\\\\s*,\\\\s*\"));\n+            resourceTypes = tmpResourceTypes.stream().filter(item-> allCompartmentResourceTypes.contains(item)).collect(Collectors.toList());\n+            if (resourceTypes == null || resourceTypes.isEmpty()) {\n+                throw new Exception(\"readItem: None of the input resource types is valid!\");\n+            }\n+        }\n+\n+        if (fhirSearchPatientGroupId == null) {\n+            throw new Exception(\"readItem: missing group id for this group export job!\");\n+        }\n+\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        if (chunkData != null) {\n+            if (resourceTypes.size() == indexOfCurrentResourceType + 1) {\n+                // No more resource type and page to read, so return null to end the reading.\n+                return null;\n+            } else {\n+                // More resource types to read, so reset partNum and move resource type index to the next.\n+                chunkData.setPartNum(1);\n+                indexOfCurrentResourceType++;\n+            }\n+        }\n+        if (fhirTenant == null) {\n+            fhirTenant = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set tenant to default!\");\n+        }\n+        if (fhirDatastoreId == null) {\n+            fhirDatastoreId = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set DatastoreId to default!\");\n+        }\n+        if (fhirSearchPageSize != null) {\n+            try {\n+                pageSize = Integer.parseInt(fhirSearchPageSize);\n+                logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n+            } catch (Exception e) {\n+                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+            }\n+        }\n+\n+        Group group = FindGroupByID(fhirTenant, fhirDatastoreId, fhirSearchPatientGroupId);", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODI1Mg==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768252", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    ExpandGroup2Patients(fhirTenant, fhirDatastoreId, group, patientMembers, groupsInPath);\n          \n          \n            \n                    expandGroup2Patients(fhirTenant, fhirDatastoreId, group, patientMembers, groupsInPath);", "author": "prb112", "createdAt": "2020-01-21T00:40:55Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+\n+    }\n+\n+    private void ExpandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n+            throws Exception{\n+        if (group == null) {\n+            return;\n+        }\n+        groupsInPath.add(group.getId());\n+        for (Member member : group.getMember()) {\n+            String refValue = member.getEntity().getReference().getValue();\n+            if (refValue.startsWith(\"Patient\")) {\n+                patients.add(member);\n+            } else if (refValue.startsWith(\"Group\")) {\n+                Group group2 = FindGroupByID(fhirTenant, fhirDatastoreId, refValue.substring(6));\n+                if (!groupsInPath.contains(group.getId())) {\n+                    ExpandGroup2Patients(fhirTenant, fhirDatastoreId, group2, patients, groupsInPath);\n+                }\n+            }\n+        }\n+    }\n+\n+    private Group FindGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{\n+        FHIRRequestContext.set(new FHIRRequestContext(fhirTenant, fhirDatastoreId));\n+        FHIRPersistenceHelper fhirPersistenceHelper = new FHIRPersistenceHelper();\n+        fhirPersistence = fhirPersistenceHelper.getFHIRPersistenceImplementation();\n+\n+        FHIRSearchContext searchContext;\n+        FHIRPersistenceContext persistenceContext;\n+        Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+        queryParameters.put(\"_id\", Arrays.asList(new String[] { groupId }));\n+        searchContext = SearchUtil.parseQueryParameters(Group.class, queryParameters);\n+        List<Resource> resources = null;\n+        FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+        txn.begin();\n+        persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+        resources = fhirPersistence.search(persistenceContext, Group.class).getResource();\n+        txn.commit();\n+\n+        if (resources != null) {\n+            return (Group) resources.get(0);\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    @Override\n+    public Object readItem() throws Exception {\n+        List <String> allCompartmentResourceTypes = CompartmentUtil.getCompartmentResourceTypes(\"Patient\");\n+        if (fhirResourceType == null ) {\n+            resourceTypes = allCompartmentResourceTypes;\n+        } else {\n+            List<String> tmpResourceTypes = Arrays.asList(fhirResourceType.split(\"\\\\s*,\\\\s*\"));\n+            resourceTypes = tmpResourceTypes.stream().filter(item-> allCompartmentResourceTypes.contains(item)).collect(Collectors.toList());\n+            if (resourceTypes == null || resourceTypes.isEmpty()) {\n+                throw new Exception(\"readItem: None of the input resource types is valid!\");\n+            }\n+        }\n+\n+        if (fhirSearchPatientGroupId == null) {\n+            throw new Exception(\"readItem: missing group id for this group export job!\");\n+        }\n+\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        if (chunkData != null) {\n+            if (resourceTypes.size() == indexOfCurrentResourceType + 1) {\n+                // No more resource type and page to read, so return null to end the reading.\n+                return null;\n+            } else {\n+                // More resource types to read, so reset partNum and move resource type index to the next.\n+                chunkData.setPartNum(1);\n+                indexOfCurrentResourceType++;\n+            }\n+        }\n+        if (fhirTenant == null) {\n+            fhirTenant = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set tenant to default!\");\n+        }\n+        if (fhirDatastoreId == null) {\n+            fhirDatastoreId = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set DatastoreId to default!\");\n+        }\n+        if (fhirSearchPageSize != null) {\n+            try {\n+                pageSize = Integer.parseInt(fhirSearchPageSize);\n+                logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n+            } catch (Exception e) {\n+                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+            }\n+        }\n+\n+        Group group = FindGroupByID(fhirTenant, fhirDatastoreId, fhirSearchPatientGroupId);\n+        // List for the patients\n+        List<Member> patientMembers = new ArrayList<>();\n+        // List for the group and sub groups in the expansion paths, this is used to avoid dead loop caused by circle reference of the groups.\n+        HashSet<String> groupsInPath = new HashSet<>();\n+        ExpandGroup2Patients(fhirTenant, fhirDatastoreId, group, patientMembers, groupsInPath);", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODMxMg==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768312", "bodyText": "what does setPageNum 2 mean?", "author": "prb112", "createdAt": "2020-01-21T00:41:20Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+\n+    }\n+\n+    private void ExpandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n+            throws Exception{\n+        if (group == null) {\n+            return;\n+        }\n+        groupsInPath.add(group.getId());\n+        for (Member member : group.getMember()) {\n+            String refValue = member.getEntity().getReference().getValue();\n+            if (refValue.startsWith(\"Patient\")) {\n+                patients.add(member);\n+            } else if (refValue.startsWith(\"Group\")) {\n+                Group group2 = FindGroupByID(fhirTenant, fhirDatastoreId, refValue.substring(6));\n+                if (!groupsInPath.contains(group.getId())) {\n+                    ExpandGroup2Patients(fhirTenant, fhirDatastoreId, group2, patients, groupsInPath);\n+                }\n+            }\n+        }\n+    }\n+\n+    private Group FindGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{\n+        FHIRRequestContext.set(new FHIRRequestContext(fhirTenant, fhirDatastoreId));\n+        FHIRPersistenceHelper fhirPersistenceHelper = new FHIRPersistenceHelper();\n+        fhirPersistence = fhirPersistenceHelper.getFHIRPersistenceImplementation();\n+\n+        FHIRSearchContext searchContext;\n+        FHIRPersistenceContext persistenceContext;\n+        Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+        queryParameters.put(\"_id\", Arrays.asList(new String[] { groupId }));\n+        searchContext = SearchUtil.parseQueryParameters(Group.class, queryParameters);\n+        List<Resource> resources = null;\n+        FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+        txn.begin();\n+        persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+        resources = fhirPersistence.search(persistenceContext, Group.class).getResource();\n+        txn.commit();\n+\n+        if (resources != null) {\n+            return (Group) resources.get(0);\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    @Override\n+    public Object readItem() throws Exception {\n+        List <String> allCompartmentResourceTypes = CompartmentUtil.getCompartmentResourceTypes(\"Patient\");\n+        if (fhirResourceType == null ) {\n+            resourceTypes = allCompartmentResourceTypes;\n+        } else {\n+            List<String> tmpResourceTypes = Arrays.asList(fhirResourceType.split(\"\\\\s*,\\\\s*\"));\n+            resourceTypes = tmpResourceTypes.stream().filter(item-> allCompartmentResourceTypes.contains(item)).collect(Collectors.toList());\n+            if (resourceTypes == null || resourceTypes.isEmpty()) {\n+                throw new Exception(\"readItem: None of the input resource types is valid!\");\n+            }\n+        }\n+\n+        if (fhirSearchPatientGroupId == null) {\n+            throw new Exception(\"readItem: missing group id for this group export job!\");\n+        }\n+\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        if (chunkData != null) {\n+            if (resourceTypes.size() == indexOfCurrentResourceType + 1) {\n+                // No more resource type and page to read, so return null to end the reading.\n+                return null;\n+            } else {\n+                // More resource types to read, so reset partNum and move resource type index to the next.\n+                chunkData.setPartNum(1);\n+                indexOfCurrentResourceType++;\n+            }\n+        }\n+        if (fhirTenant == null) {\n+            fhirTenant = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set tenant to default!\");\n+        }\n+        if (fhirDatastoreId == null) {\n+            fhirDatastoreId = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set DatastoreId to default!\");\n+        }\n+        if (fhirSearchPageSize != null) {\n+            try {\n+                pageSize = Integer.parseInt(fhirSearchPageSize);\n+                logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n+            } catch (Exception e) {\n+                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+            }\n+        }\n+\n+        Group group = FindGroupByID(fhirTenant, fhirDatastoreId, fhirSearchPatientGroupId);\n+        // List for the patients\n+        List<Member> patientMembers = new ArrayList<>();\n+        // List for the group and sub groups in the expansion paths, this is used to avoid dead loop caused by circle reference of the groups.\n+        HashSet<String> groupsInPath = new HashSet<>();\n+        ExpandGroup2Patients(fhirTenant, fhirDatastoreId, group, patientMembers, groupsInPath);\n+\n+        if (chunkData == null) {\n+            chunkData = new TransientUserData(0, null, new ArrayList<PartETag>(), 1);\n+            chunkData.setIndexOfCurrentResourceType(0);\n+            jobContext.setTransientUserData(chunkData);\n+        } else {\n+            chunkData.setIndexOfCurrentResourceType(indexOfCurrentResourceType);\n+        }\n+        // The fhir resources of one resource type for all the patients will be exported into one COS object.\n+        // Here we simply set the lastPageNum to be smaller than the next PageNum to ask the common ChunkWriter\n+        // to close the writing for current resource type.\n+        chunkData.setPageNum(2);", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTAzMTk3Ng==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369031976", "bodyText": "paging is used for the common implementation. e.g, for patient export, the codes read page of patients, and then write these patients' resources of current to-be-exported resource type to COS, and then move to the next page of patients.\nBut for group export, we don't really use paging for patients, we get all patient in one batch, so just as mentioned in the comments, we simply set current page number to be 2 and the lastpagenum to be 1 to simply sign the CheckPoint and ChunkWriter to finish writing for current resource type.", "author": "albertwang-ibm", "createdAt": "2020-01-21T14:28:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODMxMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwNjU5Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369206593", "bodyText": "OK - I got it now.  Thanks.", "author": "prb112", "createdAt": "2020-01-21T19:46:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODMxMg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODU1Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768553", "bodyText": "? gets replaced?", "author": "prb112", "createdAt": "2020-01-21T00:42:38Z", "path": "fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java", "diffHunk": "@@ -26,68 +31,54 @@\n import com.ibm.fhir.model.format.Format;\n import com.ibm.fhir.model.generator.FHIRGenerator;\n import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Condition;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Observation;\n import com.ibm.fhir.model.resource.Parameters;\n import com.ibm.fhir.model.resource.Parameters.Parameter;\n+import com.ibm.fhir.model.resource.Patient;\n+import com.ibm.fhir.model.test.TestUtil;\n import com.ibm.fhir.model.type.Instant;\n+import com.ibm.fhir.model.type.Reference;\n \n /**\n- * These tests exercise the $export operation, a BulkData specification defined operation.\n- * \n- * @author pbastide\n+ * These tests exercise the $export operation, a BulkData specification defined operation\n  *\n  */\n public class ExportOperationTest extends FHIRServerTestBase {\n-\n     public static final String TEST_GROUP_NAME = \"export-operation\";\n-\n     public static final String PATIENT_VALID_URL = \"Patient/$export\";\n-    public static final String GROUP_VALID_URL = \"Group/$export\";\n+    public static final String GROUP_VALID_URL = \"Group/?/$export\";", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTAyNjEzMQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369026131", "bodyText": "yes, ? will be replace with the group id", "author": "albertwang-ibm", "createdAt": "2020-01-21T14:18:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODU1Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODYwNw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768607", "bodyText": "camelcase and visibility modifier?", "author": "prb112", "createdAt": "2020-01-21T00:42:54Z", "path": "fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java", "diffHunk": "@@ -26,68 +31,54 @@\n import com.ibm.fhir.model.format.Format;\n import com.ibm.fhir.model.generator.FHIRGenerator;\n import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Condition;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Observation;\n import com.ibm.fhir.model.resource.Parameters;\n import com.ibm.fhir.model.resource.Parameters.Parameter;\n+import com.ibm.fhir.model.resource.Patient;\n+import com.ibm.fhir.model.test.TestUtil;\n import com.ibm.fhir.model.type.Instant;\n+import com.ibm.fhir.model.type.Reference;\n \n /**\n- * These tests exercise the $export operation, a BulkData specification defined operation.\n- * \n- * @author pbastide\n+ * These tests exercise the $export operation, a BulkData specification defined operation\n  *\n  */\n public class ExportOperationTest extends FHIRServerTestBase {\n-\n     public static final String TEST_GROUP_NAME = \"export-operation\";\n-\n     public static final String PATIENT_VALID_URL = \"Patient/$export\";\n-    public static final String GROUP_VALID_URL = \"Group/$export\";\n+    public static final String GROUP_VALID_URL = \"Group/?/$export\";\n     public static final String BASE_VALID_URL = \"/$export\";\n-\n     public static final String BASE_VALID_STATUS_URL = \"/$export-status\";\n-\n     public static final String FORMAT = \"application/fhir+ndjson\";\n+    public static final boolean ON = true;\n \n-    public static final boolean ON = false;\n-    \n-    @Test(groups = { TEST_GROUP_NAME }, enabled = ON)\n-    public void testBaseExport() throws FHIRGeneratorException, IOException {\n-        Response response =\n-            doPost(BASE_VALID_URL, FHIRMediaType.APPLICATION_FHIR_JSON, FORMAT, Instant.of(\"2019-01-01T08:21:26.94-04:00\"), Arrays.asList(\"Patient\"), null);\n-        assertEquals(response.getStatus(), 202);\n-\n-        // Debug the content-location that's returned. \n-        String contentLocation = response.getHeaderString(\"Content-Location\");\n-        System.out.println(\"Content Location: \" + contentLocation);\n-        \n-        assertEquals(contentLocation, \"/fhir-server/api/v4/$export-status?job=1\");\n-\n-    }\n+    public static final boolean DEBUG = false;\n+    String ExportStatusUrl;", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTAzMzcyNQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369033725", "bodyText": "good catch.", "author": "albertwang-ibm", "createdAt": "2020-01-21T14:31:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODYwNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODY5Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r368768693", "bodyText": "we run these on each Integration test?", "author": "prb112", "createdAt": "2020-01-21T00:43:24Z", "path": "fhir-server-test/src/test/java/com/ibm/fhir/server/test/ExportOperationTest.java", "diffHunk": "@@ -26,68 +31,54 @@\n import com.ibm.fhir.model.format.Format;\n import com.ibm.fhir.model.generator.FHIRGenerator;\n import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Condition;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Observation;\n import com.ibm.fhir.model.resource.Parameters;\n import com.ibm.fhir.model.resource.Parameters.Parameter;\n+import com.ibm.fhir.model.resource.Patient;\n+import com.ibm.fhir.model.test.TestUtil;\n import com.ibm.fhir.model.type.Instant;\n+import com.ibm.fhir.model.type.Reference;\n \n /**\n- * These tests exercise the $export operation, a BulkData specification defined operation.\n- * \n- * @author pbastide\n+ * These tests exercise the $export operation, a BulkData specification defined operation\n  *\n  */\n public class ExportOperationTest extends FHIRServerTestBase {\n-\n     public static final String TEST_GROUP_NAME = \"export-operation\";\n-\n     public static final String PATIENT_VALID_URL = \"Patient/$export\";\n-    public static final String GROUP_VALID_URL = \"Group/$export\";\n+    public static final String GROUP_VALID_URL = \"Group/?/$export\";\n     public static final String BASE_VALID_URL = \"/$export\";\n-\n     public static final String BASE_VALID_STATUS_URL = \"/$export-status\";\n-\n     public static final String FORMAT = \"application/fhir+ndjson\";\n+    public static final boolean ON = true;", "originalCommit": "4247b9102386532ab7e481ca0989dc5659031c72", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTAzODYyNQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369038625", "bodyText": "I didn't add ExportOperationTest to server integration test testng.xml, so it doesn't run in the pipeline now.  I prefer to run this in local integration test at present.  but let me add it to the pipeline, because seems the deployment/configurations are ready in the pipeline, so, let me try to enable it now and let's see what we can get...", "author": "albertwang-ibm", "createdAt": "2020-01-21T14:39:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTA2MTM3OA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369061378", "bodyText": "en, it failed in the pipeline, because there is unfinished db2 javabatch config in server.xml, let me remove it from server.xml.", "author": "albertwang-ibm", "createdAt": "2020-01-21T15:16:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTA4ODY0OA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369088648", "bodyText": "interesting, got ClassNotFound error, seems cause by the removing of databaseutil in the dependency. let me sync with master and test in my local to find out if I can reproduce this...\njava.lang.NoClassDefFoundError: com/ibm/fhir/database/utils/api/IDatabaseTarget com.ibm.jbatch.container.controller.impl.ChunkStepControllerImpl", "author": "albertwang-ibm", "createdAt": "2020-01-21T15:59:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTEwNzcxNw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369107717", "bodyText": "en... does reproduced in my local the same error ... trying to figure out how this can happen ...", "author": "albertwang-ibm", "createdAt": "2020-01-21T16:30:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODY5Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5ODEzNA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369198134", "bodyText": "fixed the error by adding databaseUtil to bulkdata webapp war, and removed the export test from testng.xml of integration test because it needs COS key and service id to be configured correctly.", "author": "albertwang-ibm", "createdAt": "2020-01-21T19:28:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODc2ODY5Mw=="}], "type": "inlineReview"}, {"oid": "184fbe33b9aefcf02e944fa0f40f0812cccf8010", "url": "https://github.com/IBM/FHIR/commit/184fbe33b9aefcf02e944fa0f40f0812cccf8010", "message": "issue #618 document updates per review comments\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T13:18:30Z", "type": "commit"}, {"oid": "45f4cb78555d4e1bf53ed9f2a5b43cbb447b2922", "url": "https://github.com/IBM/FHIR/commit/45f4cb78555d4e1bf53ed9f2a5b43cbb447b2922", "message": "issue #108 #618 updates per review comments\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T14:19:42Z", "type": "commit"}, {"oid": "6965fc97e2967ece4f3f8fe0d1d087fce3bbe020", "url": "https://github.com/IBM/FHIR/commit/6965fc97e2967ece4f3f8fe0d1d087fce3bbe020", "message": "issue #108 enable export test in pipeline\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T14:42:31Z", "type": "commit"}, {"oid": "f9df819f42512da12a3c910cea2e571887d8a097", "url": "https://github.com/IBM/FHIR/commit/f9df819f42512da12a3c910cea2e571887d8a097", "message": "issue #108 remove db2 config for JavaBatch\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T15:31:32Z", "type": "commit"}, {"oid": "4e22edf066d7a58943d54b68b9d35f07d217eed4", "url": "https://github.com/IBM/FHIR/commit/4e22edf066d7a58943d54b68b9d35f07d217eed4", "message": "Merge pull request #622 from IBM/master\n\nfetch most current master", "committedDate": "2020-01-21T15:55:43Z", "type": "commit"}, {"oid": "d3bba30aad14547373aaaaf954baa2ec70f3c4d1", "url": "https://github.com/IBM/FHIR/commit/d3bba30aad14547373aaaaf954baa2ec70f3c4d1", "message": "issue #108 fix config issues\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T18:43:56Z", "type": "commit"}, {"oid": "6f2466f7cb0177e0b74f27b9afba812caec290d1", "url": "https://github.com/IBM/FHIR/commit/6f2466f7cb0177e0b74f27b9afba812caec290d1", "message": "issue #108 remove export test from testng to allow pipeline pass\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T19:25:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwNzEzNA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369207134", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            BulkData Export is implemented according to [FHIR r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n          \n          \n            \n            BulkData Export is implemented according to [FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n          \n      \n    \n    \n  \n\nsorry - I realized I gave a bad edit before", "author": "prb112", "createdAt": "2020-01-21T19:47:12Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,121 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData Export is implemented according to [FHIR r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   ", "originalCommit": "6f2466f7cb0177e0b74f27b9afba812caec290d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIxMzE5MQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369213191", "bodyText": "np, let me fix it.", "author": "albertwang-ibm", "createdAt": "2020-01-21T19:59:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwNzEzNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIxNzQ3MA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369217470", "bodyText": "done", "author": "albertwang-ibm", "createdAt": "2020-01-21T20:08:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwNzEzNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwODgzMA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369208830", "bodyText": "Why can't the fhirbatchDS exist here? I suggest we comment it out, and remove server-withDb2JavaBatch.xml", "author": "prb112", "createdAt": "2020-01-21T19:50:35Z", "path": "fhir-server/liberty-config/server.xml", "diffHunk": "@@ -190,23 +190,6 @@\n     </dataSource>\n     -->\n \n-    <dataSource id=\"fhirbatchDS\" jndiName=\"jdbc/fhirbatchDB\">", "originalCommit": "6f2466f7cb0177e0b74f27b9afba812caec290d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwOTk4Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369209983", "bodyText": "actually - I suggest\n <include optional=\"true\" location=\"${server.config.dir}/batchDs.xml\"/>", "author": "prb112", "createdAt": "2020-01-21T19:52:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwODgzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIxMjY5MA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369212690", "bodyText": "haha, yeah, sound good", "author": "albertwang-ibm", "createdAt": "2020-01-21T19:58:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwODgzMA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIyNjU2Nw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369226567", "bodyText": "done", "author": "albertwang-ibm", "createdAt": "2020-01-21T20:29:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIwODgzMA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIxMTg4Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369211883", "bodyText": "<!--Host name part of the server generated polling location url -->\n  \"contextRoot\" : \"/fhir-server/api/v4\"\t\t   <!--Context root part of the server generated polling location url -->\n}\n\nI think these comments should be outside of the JSON", "author": "prb112", "createdAt": "2020-01-21T19:56:27Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,121 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData Export is implemented according to [FHIR r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test BulkData, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for Bulkdata export as FHIR operations.  There are three operations ExportOperation - system export, PatientExportOperation - Patient export and GroupExportOperation - group export.  Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  \n+\n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war.   This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:\n+\n+```xml\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```json\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\t       <!--Host name part of the server generated polling location url -->\n+  \"contextRoot\" : \"/fhir-server/api/v4\"\t\t   <!--Context root part of the server generated polling location url -->\n+}", "originalCommit": "6f2466f7cb0177e0b74f27b9afba812caec290d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIxNDcyNg==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369214726", "bodyText": "yeah, make sense", "author": "albertwang-ibm", "createdAt": "2020-01-21T20:02:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIxMTg4Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIxNzM3NQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369217375", "bodyText": "done", "author": "albertwang-ibm", "createdAt": "2020-01-21T20:08:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIxMTg4Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIxNDcxNw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369214717", "bodyText": "these elements should be described in a table.\n\n\n\nParameter Name\nDescription\n\n\n\n\napplicationName\nfixed value\n\n\nmoduleName\nfixed value\n\n\njobParameters.cos.bucket.name\nfixed value\n\n\njobParameters.cos.location\nfixed value\n\n\njobParameters.cos.endpointurl\nfixed value\n\n\njobParameters.credential.ibm\nfixed value\n\n\njobParameters.cos.api.key\nfixed value\n\n\njobParameters.cos.srvinst.id\nfixed value\n\n\nimplementation_type\nfixed value\n\n\nbatch-uri\nfixed value\n\n\nbatch-user\nfixed value\n\n\nbatch-user-password\nfixed value\n\n\nbatch-truststore\nfixed value\n\n\nbatch-truststore-password\nfixed value\n\n\nserverHostname\nfixed value\n\n\ncontextRoot\nfixed value", "author": "prb112", "createdAt": "2020-01-21T20:02:13Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,121 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData Export is implemented according to [FHIR r4 BulkData spec](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test BulkData, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for Bulkdata export as FHIR operations.  There are three operations ExportOperation - system export, PatientExportOperation - Patient export and GroupExportOperation - group export.  Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  \n+\n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war.   This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:\n+\n+```xml\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```json\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",", "originalCommit": "6f2466f7cb0177e0b74f27b9afba812caec290d1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIxNDg0MA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369214840", "bodyText": "you can copy the above table below the JSON, I hope it helps", "author": "prb112", "createdAt": "2020-01-21T20:02:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIxNDcxNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIzODk4OQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369238989", "bodyText": "the description for the others parameters are very descriptive, so I didn't add comments for them. but yes, make sense to add them all. I have just added the table to the document", "author": "albertwang-ibm", "createdAt": "2020-01-21T20:57:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIxNDcxNw=="}], "type": "inlineReview"}, {"oid": "154e61301388bdecc5313d6b7415383e6c41c209", "url": "https://github.com/IBM/FHIR/commit/154e61301388bdecc5313d6b7415383e6c41c209", "message": "issue #618 updated document per review comments\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T20:07:54Z", "type": "commit"}, {"oid": "1616ff4967c5d1430a53a5e53cb6f1b44d2fc702", "url": "https://github.com/IBM/FHIR/commit/1616ff4967c5d1430a53a5e53cb6f1b44d2fc702", "message": "issue #108 use optional included config for javabatch db\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T20:29:08Z", "type": "commit"}, {"oid": "94d170953ff21bce3925e5d564778cffadb097f7", "url": "https://github.com/IBM/FHIR/commit/94d170953ff21bce3925e5d564778cffadb097f7", "message": "issue #618 add more comments for job parameters\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-21T20:55:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc1MTY0OQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369751649", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              * [4.10 BulkData](#410-bulkdata)\n          \n          \n            \n              * [4.10 Bulk data operations](#410-bulk-data-operations)", "author": "lmsurpre", "createdAt": "2020-01-22T19:15:13Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -27,7 +27,8 @@ permalink: /FHIRServerUsersGuide/\n   * [4.7 FHIR command-line interface (fhir-cli)](#47-fhir-command-line-interface-fhir-cli)\n   * [4.8 Using local references within request bundles](#48-using-local-references-within-request-bundles)\n   * [4.9 Multi-tenancy](#49-multi-tenancy)\n-  * [4.10 CADF audit logging service](#410-CADF-audit-logging-service)\n+  * [4.10 BulkData](#410-bulkdata)", "originalCommit": "94d170953ff21bce3925e5d564778cffadb097f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc1MjMyMQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369752321", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              * [4.11 CADF audit logging service](#410-CADF-audit-logging-service)\n          \n          \n            \n              * [4.11 CADF audit logging service](#411-CADF-audit-logging-service)", "author": "lmsurpre", "createdAt": "2020-01-22T19:16:33Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -27,7 +27,8 @@ permalink: /FHIRServerUsersGuide/\n   * [4.7 FHIR command-line interface (fhir-cli)](#47-fhir-command-line-interface-fhir-cli)\n   * [4.8 Using local references within request bundles](#48-using-local-references-within-request-bundles)\n   * [4.9 Multi-tenancy](#49-multi-tenancy)\n-  * [4.10 CADF audit logging service](#410-CADF-audit-logging-service)\n+  * [4.10 BulkData](#410-bulkdata)\n+  * [4.11 CADF audit logging service](#410-CADF-audit-logging-service)", "originalCommit": "94d170953ff21bce3925e5d564778cffadb097f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc1MjUxMQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369752511", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            ## 4.10 BulkData\n          \n          \n            \n            ## 4.10 Bulk data operations", "author": "lmsurpre", "createdAt": "2020-01-22T19:16:58Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,140 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData", "originalCommit": "94d170953ff21bce3925e5d564778cffadb097f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc1MzA4NQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369753085", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            ### 4.10.1 BulkData Export\n          \n          \n            \n            ### 4.10.1 Bulk data export", "author": "lmsurpre", "createdAt": "2020-01-22T19:18:05Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,140 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export", "originalCommit": "94d170953ff21bce3925e5d564778cffadb097f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc1Mzc3Ng==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369753776", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            BulkData Export is implemented according to [FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n          \n          \n            \n            Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).", "author": "lmsurpre", "createdAt": "2020-01-22T19:19:32Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,140 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData Export is implemented according to [FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   ", "originalCommit": "94d170953ff21bce3925e5d564778cffadb097f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc1NDEzMg==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369754132", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To integration test BulkData, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n          \n          \n            \n            To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.", "author": "lmsurpre", "createdAt": "2020-01-22T19:20:18Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,140 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData Export is implemented according to [FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test BulkData, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  ", "originalCommit": "94d170953ff21bce3925e5d564778cffadb097f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc1NTMzNQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369755335", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The *fhir-operation-bulkdata* project implements the REST APIs for Bulkdata export as FHIR operations.  There are three operations ExportOperation - system export, PatientExportOperation - Patient export and GroupExportOperation - group export.  Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n          \n          \n            \n            The *fhir-operation-bulkdata* project implements the REST APIs for bulk data export as FHIR operations.  There are three operations:\n          \n          \n            \n            * ExportOperation - system export\n          \n          \n            \n            * PatientExportOperation - Patient export\n          \n          \n            \n            * GroupExportOperation - group export.\n          \n          \n            \n            Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.", "author": "lmsurpre", "createdAt": "2020-01-22T19:22:49Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,140 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData Export is implemented according to [FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test BulkData, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for Bulkdata export as FHIR operations.  There are three operations ExportOperation - system export, PatientExportOperation - Patient export and GroupExportOperation - group export.  Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   ", "originalCommit": "94d170953ff21bce3925e5d564778cffadb097f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc1NjI2Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369756263", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war.   This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:\n          \n          \n            \n            The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war. This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:", "author": "lmsurpre", "createdAt": "2020-01-22T19:24:35Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,140 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData Export is implemented according to [FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test BulkData, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for Bulkdata export as FHIR operations.  There are three operations ExportOperation - system export, PatientExportOperation - Patient export and GroupExportOperation - group export.  Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  \n+\n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war.   This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:", "originalCommit": "94d170953ff21bce3925e5d564778cffadb097f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc1ODE1Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369758153", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To use Amazon S3 bucket for exporting, please set cos.credential.ibm to \"N\", set cos.api.key to S3 access key, and set cos.srvinst.id to S3 secret key. This following is a sample path to the exported ndjson file, the full path can be gotten from the response to the polling location request after the export request (please refer to Fhir BulkDate spec for details).  \n          \n          \n            \n            To use Amazon S3 bucket for exporting, please set cos.credential.ibm to \"N\", set cos.api.key to S3 access key, and set cos.srvinst.id to S3 secret key. The following is a sample path to the exported ndjson file, the full path can be found in the response to the polling location request after the export request (please refer to the FHIR BulkDataAccess spec for details).", "author": "lmsurpre", "createdAt": "2020-01-22T19:28:20Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,140 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 BulkData\n+### 4.10.1 BulkData Export\n+BulkData Export is implemented according to [FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).   \n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test BulkData, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for Bulkdata export as FHIR operations.  There are three operations ExportOperation - system export, PatientExportOperation - Patient export and GroupExportOperation - group export.  Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  \n+\n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war.   This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:\n+\n+```xml\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```json\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+  \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+|Parameter Name   | Description|\n+|--------------| ------------|\n+|`applicationName`| fixed value |\n+|`moduleName`| fixed value |\n+|`jobParameters.cos.bucket.name`| object store bucket name |\n+|`jobParameters.cos.location`| object store location |\n+|`jobParameters.cos.endpointurl`| object store end point url |\n+|`jobParameters.credential.ibm`| if use IBM credential |\n+|`jobParameters.cos.api.key`| api key for accessing IBM COS |\n+|`jobParameters.cos.srvinst.id`| service instance Id for accessing IBM COS |\n+|`implementation_type`| fixed value |\n+|`batch-uri`| fixed value |\n+|`batch-user`| user for submitting JavaBatch job |\n+|`batch-user-password`| password for above batch user |\n+|`batch-truststore`| trust store for JavaBatch job submission |\n+|`batch-truststore-password`| password for above trust store |\n+|`serverHostname`| host name part of the server generated polling location url |\n+|`contextRoot`| context root part of the server generated polling location url |\n+\n+To use Amazon S3 bucket for exporting, please set cos.credential.ibm to \"N\", set cos.api.key to S3 access key, and set cos.srvinst.id to S3 secret key. This following is a sample path to the exported ndjson file, the full path can be gotten from the response to the polling location request after the export request (please refer to Fhir BulkDate spec for details).  ", "originalCommit": "94d170953ff21bce3925e5d564778cffadb097f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTc3Njc4Mg==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r369776782", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             *", "author": "lmsurpre", "createdAt": "2020-01-22T20:07:34Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,323 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ *", "originalCommit": "94d170953ff21bce3925e5d564778cffadb097f7", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "9cfad480ccd71ea1cacaa36f0618e5a3a8d05129", "url": "https://github.com/IBM/FHIR/commit/9cfad480ccd71ea1cacaa36f0618e5a3a8d05129", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:08:43Z", "type": "commit"}, {"oid": "e2205ebcb971600b4ef48a31dafca5f5d28d7768", "url": "https://github.com/IBM/FHIR/commit/e2205ebcb971600b4ef48a31dafca5f5d28d7768", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:11:09Z", "type": "commit"}, {"oid": "abd471ae28b1dfb80024941d9f44242c88fe034f", "url": "https://github.com/IBM/FHIR/commit/abd471ae28b1dfb80024941d9f44242c88fe034f", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:11:28Z", "type": "commit"}, {"oid": "9893c32fbfd42697a192bb9ea2ddfbe94d3724d0", "url": "https://github.com/IBM/FHIR/commit/9893c32fbfd42697a192bb9ea2ddfbe94d3724d0", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:12:06Z", "type": "commit"}, {"oid": "fcb855bd23804549796909a1977190458f5ed86c", "url": "https://github.com/IBM/FHIR/commit/fcb855bd23804549796909a1977190458f5ed86c", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:12:31Z", "type": "commit"}, {"oid": "666b17823ce47ba3a93f6c2b35faae72922aaa23", "url": "https://github.com/IBM/FHIR/commit/666b17823ce47ba3a93f6c2b35faae72922aaa23", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:12:54Z", "type": "commit"}, {"oid": "2cb6259a12b83e750e37e00fde69aaeae6102d9e", "url": "https://github.com/IBM/FHIR/commit/2cb6259a12b83e750e37e00fde69aaeae6102d9e", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:13:13Z", "type": "commit"}, {"oid": "a4abcf9e42921c975378a9d3bfe9280a0f80f4cd", "url": "https://github.com/IBM/FHIR/commit/a4abcf9e42921c975378a9d3bfe9280a0f80f4cd", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:13:45Z", "type": "commit"}, {"oid": "b2521ee541f65036241189df925208ef51ca4d23", "url": "https://github.com/IBM/FHIR/commit/b2521ee541f65036241189df925208ef51ca4d23", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:14:24Z", "type": "commit"}, {"oid": "4ea77cf94259eff32d85395f97501af3ae5e46c4", "url": "https://github.com/IBM/FHIR/commit/4ea77cf94259eff32d85395f97501af3ae5e46c4", "message": "Update fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Lee Surprenant <lmsurpre@us.ibm.com>", "committedDate": "2020-01-22T20:14:47Z", "type": "commit"}, {"oid": "2383da13041b59d74156c0c4306729dd54b63d47", "url": "https://github.com/IBM/FHIR/commit/2383da13041b59d74156c0c4306729dd54b63d47", "message": "issue #108 added paging support for the group members\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-23T03:45:03Z", "type": "commit"}, {"oid": "380d727f9a68588844e74d86a84a29ae5766b049", "url": "https://github.com/IBM/FHIR/commit/380d727f9a68588844e74d86a84a29ae5766b049", "message": "Merge branch 'Albert-Master-New' of git@github.com:IBM/FHIR.git into Albert-Master-New", "committedDate": "2020-01-23T03:52:23Z", "type": "commit"}, {"oid": "3f7248a159d479d2f59db706924fd31293a809bd", "url": "https://github.com/IBM/FHIR/commit/3f7248a159d479d2f59db706924fd31293a809bd", "message": "issue #108 one minor fix\n\nSigned-off-by: Albert Wang <xuwang@us.ibm.com>", "committedDate": "2020-01-23T13:07:32Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNDgxNQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370134815", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The *fhir-operation-bulkdata* project implements the REST APIs for bulk data export as FHIR operations.  There are three operations:\n          \n          \n            \n            The *fhir-operation-bulkdata* module implements the REST APIs for bulk data export as FHIR operations.  There are three operations:", "author": "prb112", "createdAt": "2020-01-23T14:04:28Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,144 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 Bulk data operations\n+### 4.10.1 Bulk data export\n+Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).\n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for bulk data export as FHIR operations.  There are three operations:", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNTE1OQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370135159", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n          \n      \n    \n    \n  \n\nI think this should be removed.  I don't think it's necessary, maybe include as a readme in the bulkdata operation module.", "author": "prb112", "createdAt": "2020-01-23T14:05:07Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,144 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 Bulk data operations\n+### 4.10.1 Bulk data export\n+Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).\n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  ", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0OTI1MA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370149250", "bodyText": "I would prefer to keep this.", "author": "albertwang-ibm", "createdAt": "2020-01-23T14:29:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNTE1OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNTY2Nw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370135667", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n          \n          \n            \n            Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* module to execute the export unit-of-work.", "author": "prb112", "createdAt": "2020-01-23T14:06:03Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,144 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 Bulk data operations\n+### 4.10.1 Bulk data export\n+Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).\n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for bulk data export as FHIR operations.  There are three operations:\n+* ExportOperation - system export\n+* PatientExportOperation - Patient export\n+* GroupExportOperation - group export.\n+Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   ", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNTc5MA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370135790", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  \n          \n          \n            \n            There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* module for the above 3 export operations:", "author": "prb112", "createdAt": "2020-01-23T14:06:16Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,144 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 Bulk data operations\n+### 4.10.1 Bulk data export\n+Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).\n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for bulk data export as FHIR operations.  There are three operations:\n+* ExportOperation - system export\n+* PatientExportOperation - Patient export\n+* GroupExportOperation - group export.\n+Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  ", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1MTQ1MQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370151451", "bodyText": "just noticed that it's changed to project by Lee.", "author": "albertwang-ibm", "createdAt": "2020-01-23T14:32:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNTc5MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNjQxOA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370136418", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            ```\n          \n          \n            \n            The following configured parameters are:", "author": "prb112", "createdAt": "2020-01-23T14:07:24Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,144 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 Bulk data operations\n+### 4.10.1 Bulk data export\n+Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).\n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for bulk data export as FHIR operations.  There are three operations:\n+* ExportOperation - system export\n+* PatientExportOperation - Patient export\n+* GroupExportOperation - group export.\n+Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  \n+\n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war. This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:\n+\n+```xml\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```json\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+  \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNjg0MA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370136840", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            |`implementation_type`| fixed value |\n          \n          \n            \n            |`implementation_type`| cos or dummy which matches the desired bulk operation implementation type |", "author": "prb112", "createdAt": "2020-01-23T14:08:11Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,144 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 Bulk data operations\n+### 4.10.1 Bulk data export\n+Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).\n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for bulk data export as FHIR operations.  There are three operations:\n+* ExportOperation - system export\n+* PatientExportOperation - Patient export\n+* GroupExportOperation - group export.\n+Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  \n+\n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war. This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:\n+\n+```xml\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```json\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+  \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+|Parameter Name   | Description|\n+|--------------| ------------|\n+|`applicationName`| fixed value |\n+|`moduleName`| fixed value |\n+|`jobParameters.cos.bucket.name`| object store bucket name |\n+|`jobParameters.cos.location`| object store location |\n+|`jobParameters.cos.endpointurl`| object store end point url |\n+|`jobParameters.credential.ibm`| if use IBM credential |\n+|`jobParameters.cos.api.key`| api key for accessing IBM COS |\n+|`jobParameters.cos.srvinst.id`| service instance Id for accessing IBM COS |\n+|`implementation_type`| fixed value |", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNzA3OQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370137079", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            |`batch-uri`| fixed value |\n          \n          \n            \n            |`batch-uri`| the URL to access the FHIR server hosting the batch web application |", "author": "prb112", "createdAt": "2020-01-23T14:08:37Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,144 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 Bulk data operations\n+### 4.10.1 Bulk data export\n+Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).\n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for bulk data export as FHIR operations.  There are three operations:\n+* ExportOperation - system export\n+* PatientExportOperation - Patient export\n+* GroupExportOperation - group export.\n+Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  \n+\n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war. This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:\n+\n+```xml\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```json\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+  \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+|Parameter Name   | Description|\n+|--------------| ------------|\n+|`applicationName`| fixed value |\n+|`moduleName`| fixed value |\n+|`jobParameters.cos.bucket.name`| object store bucket name |\n+|`jobParameters.cos.location`| object store location |\n+|`jobParameters.cos.endpointurl`| object store end point url |\n+|`jobParameters.credential.ibm`| if use IBM credential |\n+|`jobParameters.cos.api.key`| api key for accessing IBM COS |\n+|`jobParameters.cos.srvinst.id`| service instance Id for accessing IBM COS |\n+|`implementation_type`| fixed value |\n+|`batch-uri`| fixed value |", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNzMwNw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370137307", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            |`applicationName`| fixed value |\n          \n          \n            \n            |`applicationName`| fixed value, always set to fhir-bulkimportexport-webapp |", "author": "prb112", "createdAt": "2020-01-23T14:08:59Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,144 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 Bulk data operations\n+### 4.10.1 Bulk data export\n+Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).\n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for bulk data export as FHIR operations.  There are three operations:\n+* ExportOperation - system export\n+* PatientExportOperation - Patient export\n+* GroupExportOperation - group export.\n+Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  \n+\n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war. This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:\n+\n+```xml\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```json\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+  \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+|Parameter Name   | Description|\n+|--------------| ------------|\n+|`applicationName`| fixed value |", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNzUwOQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370137509", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            |`moduleName`| fixed value |\n          \n          \n            \n            |`moduleName`| fixed value, always set to fhir-bulkimportexport.war |", "author": "prb112", "createdAt": "2020-01-23T14:09:20Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,144 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 Bulk data operations\n+### 4.10.1 Bulk data export\n+Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).\n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for bulk data export as FHIR operations.  There are three operations:\n+* ExportOperation - system export\n+* PatientExportOperation - Patient export\n+* GroupExportOperation - group export.\n+Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  \n+\n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war. This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:\n+\n+```xml\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```json\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+  \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+|Parameter Name   | Description|\n+|--------------| ------------|\n+|`applicationName`| fixed value |\n+|`moduleName`| fixed value |", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNzk4NA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370137984", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t.../fhir-bulkimexport-connectathon/6xjd4M8afi6Xo95eYv7zPxBqSCoOEFywZLoqH1QBtbw=/Patient_1.ndjson\n          \n          \n            \n            .../fhir-bulkimexport-connectathon/6xjd4M8afi6Xo95eYv7zPxBqSCoOEFywZLoqH1QBtbw=/Patient_1.ndjson", "author": "prb112", "createdAt": "2020-01-23T14:10:11Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,144 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 Bulk data operations\n+### 4.10.1 Bulk data export\n+Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).\n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for bulk data export as FHIR operations.  There are three operations:\n+* ExportOperation - system export\n+* PatientExportOperation - Patient export\n+* GroupExportOperation - group export.\n+Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  \n+\n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war. This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:\n+\n+```xml\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```json\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+  \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+|Parameter Name   | Description|\n+|--------------| ------------|\n+|`applicationName`| fixed value |\n+|`moduleName`| fixed value |\n+|`jobParameters.cos.bucket.name`| object store bucket name |\n+|`jobParameters.cos.location`| object store location |\n+|`jobParameters.cos.endpointurl`| object store end point url |\n+|`jobParameters.credential.ibm`| if use IBM credential |\n+|`jobParameters.cos.api.key`| api key for accessing IBM COS |\n+|`jobParameters.cos.srvinst.id`| service instance Id for accessing IBM COS |\n+|`implementation_type`| fixed value |\n+|`batch-uri`| fixed value |\n+|`batch-user`| user for submitting JavaBatch job |\n+|`batch-user-password`| password for above batch user |\n+|`batch-truststore`| trust store for JavaBatch job submission |\n+|`batch-truststore-password`| password for above trust store |\n+|`serverHostname`| host name part of the server generated polling location url |\n+|`contextRoot`| context root part of the server generated polling location url |\n+\n+To use Amazon S3 bucket for exporting, please set cos.credential.ibm to \"N\", set cos.api.key to S3 access key, and set cos.srvinst.id to S3 secret key. The following is a sample path to the exported ndjson file, the full path can be found in the response to the polling location request after the export request (please refer to the FHIR BulkDataAccess spec for details).  \n+\n+```\n+\t.../fhir-bulkimexport-connectathon/6xjd4M8afi6Xo95eYv7zPxBqSCoOEFywZLoqH1QBtbw=/Patient_1.ndjson", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzODIxNQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370138215", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \t...", "author": "prb112", "createdAt": "2020-01-23T14:10:37Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,144 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 Bulk data operations\n+### 4.10.1 Bulk data export\n+Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).\n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for bulk data export as FHIR operations.  There are three operations:\n+* ExportOperation - system export\n+* PatientExportOperation - Patient export\n+* GroupExportOperation - group export.\n+Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  \n+\n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war. This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:\n+\n+```xml\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```json\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+  \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+|Parameter Name   | Description|\n+|--------------| ------------|\n+|`applicationName`| fixed value |\n+|`moduleName`| fixed value |\n+|`jobParameters.cos.bucket.name`| object store bucket name |\n+|`jobParameters.cos.location`| object store location |\n+|`jobParameters.cos.endpointurl`| object store end point url |\n+|`jobParameters.credential.ibm`| if use IBM credential |\n+|`jobParameters.cos.api.key`| api key for accessing IBM COS |\n+|`jobParameters.cos.srvinst.id`| service instance Id for accessing IBM COS |\n+|`implementation_type`| fixed value |\n+|`batch-uri`| fixed value |\n+|`batch-user`| user for submitting JavaBatch job |\n+|`batch-user-password`| password for above batch user |\n+|`batch-truststore`| trust store for JavaBatch job submission |\n+|`batch-truststore-password`| password for above trust store |\n+|`serverHostname`| host name part of the server generated polling location url |\n+|`contextRoot`| context root part of the server generated polling location url |\n+\n+To use Amazon S3 bucket for exporting, please set cos.credential.ibm to \"N\", set cos.api.key to S3 access key, and set cos.srvinst.id to S3 secret key. The following is a sample path to the exported ndjson file, the full path can be found in the response to the polling location request after the export request (please refer to the FHIR BulkDataAccess spec for details).  \n+\n+```\n+\t.../fhir-bulkimexport-connectathon/6xjd4M8afi6Xo95eYv7zPxBqSCoOEFywZLoqH1QBtbw=/Patient_1.ndjson\n+```\n+Following is the beautified response of sample polling location request after the export is finished:\n+\n+```json\n+{\n+\"transactionTime\": \"2020/01/20 16:53:41.160 -0500\",\n+\"request\": \"/$export?_type=\",\n+\"requiresAccessToken\": false,\n+\"output\" : [\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_2.ndjson\", \n+    \"count\": 8},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_1.ndjson\", \n+    \"count\": 234},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_2.ndjson\", \n+    \"count\": 81},\n+\t...", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzODMxMg==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370138312", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                \"count\": 81},\n          \n          \n            \n                \"count\": 81}", "author": "prb112", "createdAt": "2020-01-23T14:10:48Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,144 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 Bulk data operations\n+### 4.10.1 Bulk data export\n+Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).\n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for bulk data export as FHIR operations.  There are three operations:\n+* ExportOperation - system export\n+* PatientExportOperation - Patient export\n+* GroupExportOperation - group export.\n+Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  \n+\n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war. This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:\n+\n+```xml\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```json\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+  \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+|Parameter Name   | Description|\n+|--------------| ------------|\n+|`applicationName`| fixed value |\n+|`moduleName`| fixed value |\n+|`jobParameters.cos.bucket.name`| object store bucket name |\n+|`jobParameters.cos.location`| object store location |\n+|`jobParameters.cos.endpointurl`| object store end point url |\n+|`jobParameters.credential.ibm`| if use IBM credential |\n+|`jobParameters.cos.api.key`| api key for accessing IBM COS |\n+|`jobParameters.cos.srvinst.id`| service instance Id for accessing IBM COS |\n+|`implementation_type`| fixed value |\n+|`batch-uri`| fixed value |\n+|`batch-user`| user for submitting JavaBatch job |\n+|`batch-user-password`| password for above batch user |\n+|`batch-truststore`| trust store for JavaBatch job submission |\n+|`batch-truststore-password`| password for above trust store |\n+|`serverHostname`| host name part of the server generated polling location url |\n+|`contextRoot`| context root part of the server generated polling location url |\n+\n+To use Amazon S3 bucket for exporting, please set cos.credential.ibm to \"N\", set cos.api.key to S3 access key, and set cos.srvinst.id to S3 secret key. The following is a sample path to the exported ndjson file, the full path can be found in the response to the polling location request after the export request (please refer to the FHIR BulkDataAccess spec for details).  \n+\n+```\n+\t.../fhir-bulkimexport-connectathon/6xjd4M8afi6Xo95eYv7zPxBqSCoOEFywZLoqH1QBtbw=/Patient_1.ndjson\n+```\n+Following is the beautified response of sample polling location request after the export is finished:\n+\n+```json\n+{\n+\"transactionTime\": \"2020/01/20 16:53:41.160 -0500\",\n+\"request\": \"/$export?_type=\",\n+\"requiresAccessToken\": false,\n+\"output\" : [\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_2.ndjson\", \n+    \"count\": 8},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_1.ndjson\", \n+    \"count\": 234},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_2.ndjson\", \n+    \"count\": 81},", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzOTM2Mg==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370139362", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The exported ndjson file is configured with public access automatically and with 2 hours expiration time, the randomly generated secret in the path is used to protect the file. please notice that IBM COS doesn't support expiration time for each single COS object, so please configure retention policy (e.g, 1 day) for the bucket if IBM COS is used. And for both Amazon S3 and IBM COS, please remember that public access should never be configured to the bucket itself.  \n          \n          \n            \n            The exported ndjson file is configured with public access automatically and with 2 hours expiration time, the randomly generated secret in the path is used to protect the file. please note that IBM COS does not support expiration time for each single COS object, so please configure retention policy (e.g, 1 day) for the bucket if IBM COS is used. For both Amazon S3 and IBM COS, please remember that public access should never be configured to the bucket itself.", "author": "prb112", "createdAt": "2020-01-23T14:12:35Z", "path": "docs/src/pages/guides/FHIRServerUsersGuide.md", "diffHunk": "@@ -1098,6 +1099,144 @@ team can more easilly read the messages.\n It is also possible to configure the persistence properties for a specific tenant, for example to set an alternate\n database hostname or database schema name.\n \n+## 4.10 Bulk data operations\n+### 4.10.1 Bulk data export\n+Bulk data export is implemented according to the [HL7 FHIR BulkDataAccess IG: STU1](http://hl7.org/fhir/uv/bulkdata/STU1/export/index.html).\n+There are 2 modules involved inside the implementation:\n+- fhir-operation-bulkdata\n+- fhir-bulkimportexport-webapp   \n+\n+To integration test, there are tests in ExportOperationTest.java in fhir-server-test module with server integration test cases for system, patient and group export.  \n+The *fhir-operation-bulkdata* project implements the REST APIs for bulk data export as FHIR operations.  There are three operations:\n+* ExportOperation - system export\n+* PatientExportOperation - Patient export\n+* GroupExportOperation - group export.\n+Each operation calls the JavaBatch framework defined in the *fhir-bulkimportexport-webapp* project to execute the export unit-of-work.   \n+There are 3 chunk style JavaBatch jobs defined as following in *fhir-bulkimportexport-webapp* project for the above 3 export operations:  \n+\n+- FhirBulkExportChunkJob\n+- FhirBulkExportPatientChunkJob\n+- FhirBulkExportGroupChunkJob\n+\n+The *fhir-bulkimportexport-webapp* module is a wrapper for the whole BulkData web application, which is the build artifact - fhir-bulkimportexport.war. This web archive is copied to the apps directory of the liberty fhir-server instance. Following is a sample liberty server configuration (server.xml) for fhir-bulkimportexport.war:\n+\n+```xml\n+    <webApplication id=\"fhir-bulkimportexport-webapp\" location=\"fhir-bulkimportexport.war\" name=\"fhir-bulkimportexport-webapp\">\n+        <classloader commonLibraryRef=\"fhirSharedLib\" privateLibraryRef=\"configResources,fhirUserLib\"/>\n+        <application-bnd>\n+            <security-role id=\"users\" name=\"FHIRUsers\">\n+                <group name=\"FHIRUsers\"/>\n+            </security-role>\n+        </application-bnd>\n+    </webApplication>\n+```\n+\n+BulkData web application writes the exported FHIR resources to IBM COS or Amazon S3 bucket, as configured in the per-tenant bulkdata.json configuration file.  The bulkdata.json file is stored in the tenant configuration directory of each fhir-server instance. The following is a bulkdata.json which is configured to export the FHIR resources into fhir-bulkdata-sample bucket of IBM COS: \n+\n+```json\n+{\n+  \"applicationName\": \"fhir-bulkimportexport-webapp\",\n+  \"moduleName\": \"fhir-bulkimportexport.war\",\n+  \"jobParameters\": {\n+    \"cos.bucket.name\": \"fhir-bulkdata-sample\",\n+    \"cos.location\": \"us\",\n+    \"cos.endpointurl\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud\",\n+    \"cos.credential.ibm\": \"Y\",\n+    \"cos.api.key\": \"xxxxxxxxxxxxxxxxxxxxxxx\",\n+    \"cos.srvinst.id\": \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n+  },\n+  \"implementation_type\": \"cos\",\n+  \"batch-uri\": \"https://localhost:9443/ibm/api/batch/jobinstances\",\n+  \"batch-user\": \"fhiradmin\",\n+  \"batch-user-password\": \"xxxxxxxxxxxx\",\n+  \"batch-truststore\" : \"resources/security/fhirTruststore.jks\",\n+  \"batch-truststore-password\" : \"xxxxxxxxxxxx\",\n+  \"serverHostname\" : \"localhost:9443\",\n+  \"contextRoot\" : \"/fhir-server/api/v4\"\n+}\n+```\n+|Parameter Name   | Description|\n+|--------------| ------------|\n+|`applicationName`| fixed value |\n+|`moduleName`| fixed value |\n+|`jobParameters.cos.bucket.name`| object store bucket name |\n+|`jobParameters.cos.location`| object store location |\n+|`jobParameters.cos.endpointurl`| object store end point url |\n+|`jobParameters.credential.ibm`| if use IBM credential |\n+|`jobParameters.cos.api.key`| api key for accessing IBM COS |\n+|`jobParameters.cos.srvinst.id`| service instance Id for accessing IBM COS |\n+|`implementation_type`| fixed value |\n+|`batch-uri`| fixed value |\n+|`batch-user`| user for submitting JavaBatch job |\n+|`batch-user-password`| password for above batch user |\n+|`batch-truststore`| trust store for JavaBatch job submission |\n+|`batch-truststore-password`| password for above trust store |\n+|`serverHostname`| host name part of the server generated polling location url |\n+|`contextRoot`| context root part of the server generated polling location url |\n+\n+To use Amazon S3 bucket for exporting, please set cos.credential.ibm to \"N\", set cos.api.key to S3 access key, and set cos.srvinst.id to S3 secret key. The following is a sample path to the exported ndjson file, the full path can be found in the response to the polling location request after the export request (please refer to the FHIR BulkDataAccess spec for details).  \n+\n+```\n+\t.../fhir-bulkimexport-connectathon/6xjd4M8afi6Xo95eYv7zPxBqSCoOEFywZLoqH1QBtbw=/Patient_1.ndjson\n+```\n+Following is the beautified response of sample polling location request after the export is finished:\n+\n+```json\n+{\n+\"transactionTime\": \"2020/01/20 16:53:41.160 -0500\",\n+\"request\": \"/$export?_type=\",\n+\"requiresAccessToken\": false,\n+\"output\" : [\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_1.ndjson\", \n+    \"count\": 20},\n+  { \"type\" : \"AllergyIntolerance\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/AllergyIntolerance_2.ndjson\", \n+    \"count\": 8},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_1.ndjson\", \n+    \"count\": 234},\n+  { \"type\" : \"Observation\", \n+      \"url\": \"https://s3.us-south.cloud-object-storage.appdomain.cloud/fhir-bulkimexport-connectathon/6SfXzbGvYl1nTjGbf5qeqJDFNjyljiGdKxXEJb4yJn8=/Observation_2.ndjson\", \n+    \"count\": 81},\n+\t...\n+}\n+```\n+\n+The exported ndjson file is configured with public access automatically and with 2 hours expiration time, the randomly generated secret in the path is used to protect the file. please notice that IBM COS doesn't support expiration time for each single COS object, so please configure retention policy (e.g, 1 day) for the bucket if IBM COS is used. And for both Amazon S3 and IBM COS, please remember that public access should never be configured to the bucket itself.  ", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDc2NA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370140764", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                        chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n          \n          \n            \n                                        chunkData.getBufferStream().write(Constants.NDJSON_LINESEPARATOR.getBytes());\n          \n      \n    \n    \n  \n\nWhy not make the NDJSON_LINESEPARATOR bytes anyway?", "author": "prb112", "createdAt": "2020-01-23T14:15:03Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,328 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDk2MQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370140961", "bodyText": "avoiding getBytes each time?", "author": "prb112", "createdAt": "2020-01-23T14:15:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDc2NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE2NDc4Nw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370164787", "bodyText": "I didn't because I thought the cost is very minor, but make sense for me to make the change.", "author": "albertwang-ibm", "createdAt": "2020-01-23T14:54:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDc2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MTM4MQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370141381", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            List<String> searchCreterial = new ArrayList<String>();\n          \n          \n            \n                            List<String> searchCriteria = new ArrayList<String>();", "author": "prb112", "createdAt": "2020-01-23T14:16:07Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,328 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE2MTU1MA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370161550", "bodyText": "this is a refactor, will change in eclipse and commit.", "author": "albertwang-ibm", "createdAt": "2020-01-23T14:49:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MTM4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0Mjk2Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370142963", "bodyText": "shouldn't this throw a more specific exception?  more easily differentiating in code downstream?", "author": "prb112", "createdAt": "2020-01-23T14:18:48Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,328 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1NDc4OA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370154788", "bodyText": "not needed, the job always exit when this rare error happens, exception info in log is enough", "author": "albertwang-ibm", "createdAt": "2020-01-23T14:38:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0Mjk2Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MzI5Mw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370143293", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private void expandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n          \n          \n            \n                private void expandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, Set<String> groupsInPath)", "author": "prb112", "createdAt": "2020-01-23T14:19:20Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,328 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+    }\n+\n+    private void expandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1NTkwMw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370155903", "bodyText": "I used HashSet on purpose here, didn't want this to be generic, it's for internally used only.", "author": "albertwang-ibm", "createdAt": "2020-01-23T14:40:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MzI5Mw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NDc0NQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370144745", "bodyText": "I think we should throw an exception.  This could lead to unintended consequences.  if a tenant is not passed in, it should be treated as invalid.", "author": "prb112", "createdAt": "2020-01-23T14:21:48Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,328 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+    }\n+\n+    private void expandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n+            throws Exception{\n+        if (group == null) {\n+            return;\n+        }\n+        groupsInPath.add(group.getId());\n+        for (Member member : group.getMember()) {\n+            String refValue = member.getEntity().getReference().getValue();\n+            if (refValue.startsWith(\"Patient\")) {\n+                patients.add(member);\n+            } else if (refValue.startsWith(\"Group\")) {\n+                Group group2 = findGroupByID(fhirTenant, fhirDatastoreId, refValue.substring(6));\n+                if (!groupsInPath.contains(group.getId())) {\n+                    expandGroup2Patients(fhirTenant, fhirDatastoreId, group2, patients, groupsInPath);\n+                }\n+            }\n+        }\n+    }\n+\n+    private Group findGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{\n+        FHIRRequestContext.set(new FHIRRequestContext(fhirTenant, fhirDatastoreId));\n+        FHIRPersistenceHelper fhirPersistenceHelper = new FHIRPersistenceHelper();\n+        fhirPersistence = fhirPersistenceHelper.getFHIRPersistenceImplementation();\n+\n+        FHIRSearchContext searchContext;\n+        FHIRPersistenceContext persistenceContext;\n+        Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+        queryParameters.put(\"_id\", Arrays.asList(new String[] { groupId }));\n+        searchContext = SearchUtil.parseQueryParameters(Group.class, queryParameters);\n+        List<Resource> resources = null;\n+        FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+        txn.begin();\n+        persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+        resources = fhirPersistence.search(persistenceContext, Group.class).getResource();\n+        txn.commit();\n+\n+        if (resources != null) {\n+            return (Group) resources.get(0);\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    @Override\n+    public Object readItem() throws Exception {\n+        List <String> allCompartmentResourceTypes = CompartmentUtil.getCompartmentResourceTypes(\"Patient\");\n+        if (fhirResourceType == null ) {\n+            resourceTypes = allCompartmentResourceTypes;\n+        } else {\n+            List<String> tmpResourceTypes = Arrays.asList(fhirResourceType.split(\"\\\\s*,\\\\s*\"));\n+            resourceTypes = tmpResourceTypes.stream().filter(item-> allCompartmentResourceTypes.contains(item)).collect(Collectors.toList());\n+            if (resourceTypes == null || resourceTypes.isEmpty()) {\n+                throw new Exception(\"readItem: None of the input resource types is valid!\");\n+            }\n+        }\n+\n+        if (fhirSearchPatientGroupId == null) {\n+            throw new Exception(\"readItem: missing group id for this group export job!\");\n+        }\n+\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        if (chunkData != null && pageNum > chunkData.getLastPageNum()) {\n+            if (resourceTypes.size() == indexOfCurrentResourceType + 1) {\n+                // No more resource type and page to read, so return null to end the reading.\n+                return null;\n+            } else {\n+                // More resource types to read, so reset pageNum, partNum and move resource type index to the next.\n+                pageNum = 1;\n+                chunkData.setPartNum(1);\n+                indexOfCurrentResourceType++;\n+            }\n+        }\n+        if (fhirTenant == null) {", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE1NzE3Ng==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370157176", "bodyText": "the control should be in the operation side, the javabatch itself allows non tenant id to make the javabatch Job test itself easier.", "author": "albertwang-ibm", "createdAt": "2020-01-23T14:42:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NDc0NQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NTQxNw==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370145417", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n          \n          \n            \n                            logger.warning(\"readItem: Set page size to default [\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \"]\");\n          \n      \n    \n    \n  \n\ngeneral pattern", "author": "prb112", "createdAt": "2020-01-23T14:22:57Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,328 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+    }\n+\n+    private void expandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n+            throws Exception{\n+        if (group == null) {\n+            return;\n+        }\n+        groupsInPath.add(group.getId());\n+        for (Member member : group.getMember()) {\n+            String refValue = member.getEntity().getReference().getValue();\n+            if (refValue.startsWith(\"Patient\")) {\n+                patients.add(member);\n+            } else if (refValue.startsWith(\"Group\")) {\n+                Group group2 = findGroupByID(fhirTenant, fhirDatastoreId, refValue.substring(6));\n+                if (!groupsInPath.contains(group.getId())) {\n+                    expandGroup2Patients(fhirTenant, fhirDatastoreId, group2, patients, groupsInPath);\n+                }\n+            }\n+        }\n+    }\n+\n+    private Group findGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{\n+        FHIRRequestContext.set(new FHIRRequestContext(fhirTenant, fhirDatastoreId));\n+        FHIRPersistenceHelper fhirPersistenceHelper = new FHIRPersistenceHelper();\n+        fhirPersistence = fhirPersistenceHelper.getFHIRPersistenceImplementation();\n+\n+        FHIRSearchContext searchContext;\n+        FHIRPersistenceContext persistenceContext;\n+        Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+        queryParameters.put(\"_id\", Arrays.asList(new String[] { groupId }));\n+        searchContext = SearchUtil.parseQueryParameters(Group.class, queryParameters);\n+        List<Resource> resources = null;\n+        FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+        txn.begin();\n+        persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+        resources = fhirPersistence.search(persistenceContext, Group.class).getResource();\n+        txn.commit();\n+\n+        if (resources != null) {\n+            return (Group) resources.get(0);\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    @Override\n+    public Object readItem() throws Exception {\n+        List <String> allCompartmentResourceTypes = CompartmentUtil.getCompartmentResourceTypes(\"Patient\");\n+        if (fhirResourceType == null ) {\n+            resourceTypes = allCompartmentResourceTypes;\n+        } else {\n+            List<String> tmpResourceTypes = Arrays.asList(fhirResourceType.split(\"\\\\s*,\\\\s*\"));\n+            resourceTypes = tmpResourceTypes.stream().filter(item-> allCompartmentResourceTypes.contains(item)).collect(Collectors.toList());\n+            if (resourceTypes == null || resourceTypes.isEmpty()) {\n+                throw new Exception(\"readItem: None of the input resource types is valid!\");\n+            }\n+        }\n+\n+        if (fhirSearchPatientGroupId == null) {\n+            throw new Exception(\"readItem: missing group id for this group export job!\");\n+        }\n+\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        if (chunkData != null && pageNum > chunkData.getLastPageNum()) {\n+            if (resourceTypes.size() == indexOfCurrentResourceType + 1) {\n+                // No more resource type and page to read, so return null to end the reading.\n+                return null;\n+            } else {\n+                // More resource types to read, so reset pageNum, partNum and move resource type index to the next.\n+                pageNum = 1;\n+                chunkData.setPartNum(1);\n+                indexOfCurrentResourceType++;\n+            }\n+        }\n+        if (fhirTenant == null) {\n+            fhirTenant = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set tenant to default!\");\n+        }\n+        if (fhirDatastoreId == null) {\n+            fhirDatastoreId = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set DatastoreId to default!\");\n+        }\n+        if (fhirSearchPageSize != null) {\n+            try {\n+                pageSize = Integer.parseInt(fhirSearchPageSize);\n+                logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n+            } catch (Exception e) {\n+                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE2NjU0OA==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370166548", "bodyText": "Signed-off-by: Albert Wang xuwang@us.ibm.com", "author": "albertwang-ibm", "createdAt": "2020-01-23T14:57:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NTQxNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NTk3OQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370145979", "bodyText": "maybe add a logger.fine for debug purposes?", "author": "prb112", "createdAt": "2020-01-23T14:23:56Z", "path": "fhir-bulkimportexport-webapp/src/main/java/com/ibm/fhir/bulkexport/group/ChunkReader.java", "diffHunk": "@@ -0,0 +1,328 @@\n+/*\n+ * (C) Copyright IBM Corp. 2019, 2020\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.ibm.fhir.bulkexport.group;\n+\n+import java.io.IOException;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+\n+import javax.batch.api.BatchProperty;\n+import javax.batch.api.chunk.AbstractItemReader;\n+import javax.batch.runtime.context.JobContext;\n+import javax.inject.Inject;\n+\n+import com.ibm.cloud.objectstorage.services.s3.model.PartETag;\n+import com.ibm.fhir.bulkcommon.Constants;\n+import com.ibm.fhir.bulkexport.common.CheckPointUserData;\n+import com.ibm.fhir.bulkexport.common.TransientUserData;\n+import com.ibm.fhir.config.FHIRRequestContext;\n+import com.ibm.fhir.model.format.Format;\n+import com.ibm.fhir.model.generator.FHIRGenerator;\n+import com.ibm.fhir.model.generator.exception.FHIRGeneratorException;\n+import com.ibm.fhir.model.resource.Group;\n+import com.ibm.fhir.model.resource.Group.Member;\n+import com.ibm.fhir.model.resource.Resource;\n+import com.ibm.fhir.model.util.ModelSupport;\n+import com.ibm.fhir.persistence.FHIRPersistence;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContext;\n+import com.ibm.fhir.persistence.context.FHIRPersistenceContextFactory;\n+import com.ibm.fhir.persistence.helper.FHIRPersistenceHelper;\n+import com.ibm.fhir.persistence.helper.FHIRTransactionHelper;\n+import com.ibm.fhir.search.compartment.CompartmentUtil;\n+import com.ibm.fhir.search.context.FHIRSearchContext;\n+import com.ibm.fhir.search.util.SearchUtil;\n+\n+/**\n+ * Bulk patient group export Chunk implementation - the Reader.\n+ */\n+public class ChunkReader extends AbstractItemReader {\n+    int pageNum = 1;\n+    // List for the patients\n+    List<Member> patientMembers = null;\n+    private final static Logger logger = Logger.getLogger(ChunkReader.class.getName());\n+    int indexOfCurrentResourceType = 0;\n+    // Control the number of records to read in each page.\n+    int pageSize = Constants.DEFAULT_SEARCH_PAGE_SIZE;\n+\n+    private FHIRPersistence fhirPersistence;\n+    private List<String> resourceTypes;\n+\n+    /**\n+     * Fhir tenant id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.tenant\")\n+    String fhirTenant;\n+\n+    /**\n+     * Fhir data store id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.datastoreid\")\n+    String fhirDatastoreId;\n+\n+    /**\n+     * Fhir ResourceType.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.resourcetype\")\n+    String fhirResourceType;\n+\n+    /**\n+     * Fhir Search from date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.fromdate\")\n+    String fhirSearchFromDate;\n+\n+    /**\n+     * Fhir search to date.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.todate\")\n+    String fhirSearchToDate;\n+\n+    /**\n+     * Fhir search patient group id.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.patientgroupid\")\n+    String fhirSearchPatientGroupId;\n+\n+    /**\n+     * Fhir search page size.\n+     */\n+    @Inject\n+    @BatchProperty(name = \"fhir.search.pagesize\")\n+    String fhirSearchPageSize;\n+\n+    @Inject\n+    JobContext jobContext;\n+\n+    public ChunkReader() {\n+        super();\n+    }\n+\n+    private void fillChunkDataBuffer(List<Member> patientRefs) throws Exception {\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        int compartmentPageNum = 1;\n+        int resSubTotal = 0;\n+        FHIRSearchContext searchContext;\n+        Class<? extends Resource> resourceType = ModelSupport\n+                .getResourceType(resourceTypes.get(indexOfCurrentResourceType));\n+        if (chunkData != null) {\n+            for (Member patientRef : patientRefs) {\n+                if (patientRef == null) {\n+                    continue;\n+                }\n+\n+                String patientId =  patientRef.getEntity().getReference().getValue().substring(8);\n+                Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+                List<String> searchCreterial = new ArrayList<String>();\n+\n+                if (fhirSearchFromDate != null) {\n+                    searchCreterial.add(\"ge\" + fhirSearchFromDate);\n+                }\n+                if (fhirSearchToDate != null) {\n+                    searchCreterial.add(\"lt\" + fhirSearchToDate);\n+                }\n+                if (!searchCreterial.isEmpty()) {\n+                    queryParameters.put(Constants.FHIR_SEARCH_LASTUPDATED, searchCreterial);\n+                }\n+\n+                queryParameters.put(\"_sort\", Arrays.asList(new String[] { Constants.FHIR_SEARCH_LASTUPDATED }));\n+                searchContext = SearchUtil.parseQueryParameters(\"Patient\", patientId,\n+                        ModelSupport.getResourceType(resourceTypes.get(indexOfCurrentResourceType)), queryParameters, null, true);\n+                do {\n+                    searchContext.setPageSize(pageSize);\n+                    searchContext.setPageNumber(compartmentPageNum);\n+                    FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+                    txn.begin();\n+                    FHIRPersistenceContext persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+                    List<Resource> resources2 = fhirPersistence.search(persistenceContext, resourceType).getResource();\n+                    txn.commit();\n+                    compartmentPageNum++;\n+\n+                    for (Resource res2 : resources2) {\n+                        if (res2 == null) {\n+                            continue;\n+                        }\n+                        try {\n+                            FHIRGenerator.generator(Format.JSON).generate(res2, chunkData.getBufferStream());\n+                            chunkData.getBufferStream().write(Constants.NDJSON_LINESEPERATOR.getBytes());\n+                            resSubTotal++;\n+                        } catch (FHIRGeneratorException e) {\n+                            logger.log(Level.WARNING, \"fillChunkDataBuffer: Error while writing resources with id '\"\n+                                        + patientId + \"'\", e);\n+                        } catch (IOException e) {\n+                            logger.warning(\"fillChunkDataBuffer: chunkDataBuffer written error!\");\n+                            throw e;\n+                        }\n+                    }\n+\n+                } while (searchContext.getLastPageNumber() >= compartmentPageNum);\n+            }\n+            chunkData.setCurrentPartResourceNum(chunkData.getCurrentPartResourceNum() + resSubTotal);\n+            logger.fine(\"fillChunkDataBuffer: Processed resources - \" + resSubTotal + \"; Bufferred data size - \"\n+                    + chunkData.getBufferStream().size());\n+        } else {\n+            logger.warning(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+            throw new Exception(\"fillChunkDataBuffer: chunkData is null, this should never happen!\");\n+        }\n+    }\n+\n+    private void expandGroup2Patients(String fhirTenant, String fhirDatastoreId, Group group, List<Member> patients, HashSet<String> groupsInPath)\n+            throws Exception{\n+        if (group == null) {\n+            return;\n+        }\n+        groupsInPath.add(group.getId());\n+        for (Member member : group.getMember()) {\n+            String refValue = member.getEntity().getReference().getValue();\n+            if (refValue.startsWith(\"Patient\")) {\n+                patients.add(member);\n+            } else if (refValue.startsWith(\"Group\")) {\n+                Group group2 = findGroupByID(fhirTenant, fhirDatastoreId, refValue.substring(6));\n+                if (!groupsInPath.contains(group.getId())) {\n+                    expandGroup2Patients(fhirTenant, fhirDatastoreId, group2, patients, groupsInPath);\n+                }\n+            }\n+        }\n+    }\n+\n+    private Group findGroupByID(String fhirTenant, String fhirDatastoreId, String groupId) throws Exception{\n+        FHIRRequestContext.set(new FHIRRequestContext(fhirTenant, fhirDatastoreId));\n+        FHIRPersistenceHelper fhirPersistenceHelper = new FHIRPersistenceHelper();\n+        fhirPersistence = fhirPersistenceHelper.getFHIRPersistenceImplementation();\n+\n+        FHIRSearchContext searchContext;\n+        FHIRPersistenceContext persistenceContext;\n+        Map<String, List<String>> queryParameters = new HashMap<>();\n+\n+        queryParameters.put(\"_id\", Arrays.asList(new String[] { groupId }));\n+        searchContext = SearchUtil.parseQueryParameters(Group.class, queryParameters);\n+        List<Resource> resources = null;\n+        FHIRTransactionHelper txn = new FHIRTransactionHelper(fhirPersistence.getTransaction());\n+        txn.begin();\n+        persistenceContext = FHIRPersistenceContextFactory.createPersistenceContext(null, searchContext);\n+        resources = fhirPersistence.search(persistenceContext, Group.class).getResource();\n+        txn.commit();\n+\n+        if (resources != null) {\n+            return (Group) resources.get(0);\n+        } else {\n+            return null;\n+        }\n+    }\n+\n+    @Override\n+    public Object readItem() throws Exception {\n+        List <String> allCompartmentResourceTypes = CompartmentUtil.getCompartmentResourceTypes(\"Patient\");\n+        if (fhirResourceType == null ) {\n+            resourceTypes = allCompartmentResourceTypes;\n+        } else {\n+            List<String> tmpResourceTypes = Arrays.asList(fhirResourceType.split(\"\\\\s*,\\\\s*\"));\n+            resourceTypes = tmpResourceTypes.stream().filter(item-> allCompartmentResourceTypes.contains(item)).collect(Collectors.toList());\n+            if (resourceTypes == null || resourceTypes.isEmpty()) {\n+                throw new Exception(\"readItem: None of the input resource types is valid!\");\n+            }\n+        }\n+\n+        if (fhirSearchPatientGroupId == null) {\n+            throw new Exception(\"readItem: missing group id for this group export job!\");\n+        }\n+\n+        TransientUserData chunkData = (TransientUserData) jobContext.getTransientUserData();\n+        if (chunkData != null && pageNum > chunkData.getLastPageNum()) {\n+            if (resourceTypes.size() == indexOfCurrentResourceType + 1) {\n+                // No more resource type and page to read, so return null to end the reading.\n+                return null;\n+            } else {\n+                // More resource types to read, so reset pageNum, partNum and move resource type index to the next.\n+                pageNum = 1;\n+                chunkData.setPartNum(1);\n+                indexOfCurrentResourceType++;\n+            }\n+        }\n+        if (fhirTenant == null) {\n+            fhirTenant = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set tenant to default!\");\n+        }\n+        if (fhirDatastoreId == null) {\n+            fhirDatastoreId = Constants.DEFAULT_FHIR_TENANT;\n+            logger.info(\"readItem: Set DatastoreId to default!\");\n+        }\n+        if (fhirSearchPageSize != null) {\n+            try {\n+                pageSize = Integer.parseInt(fhirSearchPageSize);\n+                logger.fine(\"readItem: Set page size to \" + pageSize + \".\");\n+            } catch (Exception e) {\n+                logger.warning(\"readItem: Set page size to default(\" + Constants.DEFAULT_SEARCH_PAGE_SIZE + \").\");\n+            }\n+        }\n+\n+        if (patientMembers == null) {\n+            Group group = findGroupByID(fhirTenant, fhirDatastoreId, fhirSearchPatientGroupId);\n+            patientMembers = new ArrayList<>();\n+            // List for the group and sub groups in the expansion paths, this is used to avoid dead loop caused by circle reference of the groups.\n+            HashSet<String> groupsInPath = new HashSet<>();\n+            expandGroup2Patients(fhirTenant, fhirDatastoreId, group, patientMembers, groupsInPath);\n+        }\n+        List<Member> patientPageMembers = patientMembers.subList((pageNum - 1) * pageSize,\n+                pageNum * pageSize <= patientMembers.size() ? pageNum * pageSize : patientMembers.size());\n+        pageNum++;\n+\n+        if (chunkData == null) {\n+            chunkData = new TransientUserData(pageNum, null, new ArrayList<PartETag>(), 1);\n+            chunkData.setIndexOfCurrentResourceType(0);\n+            jobContext.setTransientUserData(chunkData);\n+        } else {\n+            chunkData.setIndexOfCurrentResourceType(indexOfCurrentResourceType);\n+            chunkData.setPageNum(pageNum);\n+        }\n+        chunkData.setLastPageNum((patientMembers.size() + pageSize -1)/pageSize );\n+\n+        if (!patientPageMembers.isEmpty()) {\n+            logger.fine(\"readItem: loaded patients number - \" + patientMembers.size());\n+            fillChunkDataBuffer(patientPageMembers);\n+        } else {\n+            logger.fine(\"readItem: End of reading!\");\n+        }\n+\n+        return patientPageMembers;\n+    }\n+\n+    @Override\n+    public void open(Serializable checkpoint) throws Exception {\n+        if (checkpoint != null) {\n+            CheckPointUserData checkPointData = (CheckPointUserData) checkpoint;\n+            pageNum = checkPointData.getPageNum();\n+            indexOfCurrentResourceType = checkPointData.getIndexOfCurrentResourceType();\n+            jobContext.setTransientUserData(TransientUserData.fromCheckPointUserData(checkPointData));\n+        }\n+    }\n+\n+    @Override\n+    public void close() throws Exception {\n+", "originalCommit": "3f7248a159d479d2f59db706924fd31293a809bd", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NjQyNQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370146425", "bodyText": "also chunkData.getBufferStream() <-- who is response to close this?", "author": "prb112", "createdAt": "2020-01-23T14:24:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NTk3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE3ODY5OQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370178699", "bodyText": "haha, good question. Actually Closing a ByteArrayOutputStream has no effect per java document, actually the function is empty in codes. it's handled by garbage collector after no reference to it.  and the same ByteArrayOutputStream is used the whole life circle of the batch job.", "author": "albertwang-ibm", "createdAt": "2020-01-23T15:16:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NTk3OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE4NTcxMQ==", "url": "https://github.com/IBM/FHIR/pull/594#discussion_r370185711", "bodyText": "OK, I think adding a comment to that effect is good thing in the code.", "author": "prb112", "createdAt": "2020-01-23T15:27:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0NTk3OQ=="}], "type": "inlineReview"}, {"oid": "ac5d50b24ed03d9841411aef2fb395891fea31c4", "url": "https://github.com/IBM/FHIR/commit/ac5d50b24ed03d9841411aef2fb395891fea31c4", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:28:25Z", "type": "commit"}, {"oid": "cf2fabcbf2c87159f81316a936c9a7e14411889f", "url": "https://github.com/IBM/FHIR/commit/cf2fabcbf2c87159f81316a936c9a7e14411889f", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:29:25Z", "type": "commit"}, {"oid": "4fa6b3223bb7bfb14048beffebd9ddc09aa0f2fa", "url": "https://github.com/IBM/FHIR/commit/4fa6b3223bb7bfb14048beffebd9ddc09aa0f2fa", "message": "Update docs/src/pages/guides/FHIRServerUsersGuide.md\r\n\r\nSigned-off-by: Albert Wang xuwang@us.ibm.com\n\nCo-Authored-By: Paul Bastide <pbastide@us.ibm.com>", "committedDate": "2020-01-23T14:32:59Z", "type": "commit"}]}