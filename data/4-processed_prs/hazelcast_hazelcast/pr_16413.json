{"pr_number": 16413, "pr_title": "ScheduledExecutor task size logging", "pr_createdAt": "2020-01-07T08:51:26Z", "pr_url": "https://github.com/hazelcast/hazelcast/pull/16413", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2MzY0NjQ3Nw==", "url": "https://github.com/hazelcast/hazelcast/pull/16413#discussion_r363646477", "bodyText": "Will be removed from final PR", "author": "pveentjer", "createdAt": "2020-01-07T08:56:12Z", "path": "hazelcast/src/test/java/com/EchoTask.java", "diffHunk": "@@ -0,0 +1,21 @@\n+package com;", "originalCommit": "b1437112935129ac50e58ffdc85b8a987e6bff72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2MzY0NjU0Mg==", "url": "https://github.com/hazelcast/hazelcast/pull/16413#discussion_r363646542", "bodyText": "Will be removed in final PR", "author": "pveentjer", "createdAt": "2020-01-07T08:56:23Z", "path": "hazelcast/src/test/java/com/Main.java", "diffHunk": "@@ -0,0 +1,35 @@\n+package com;", "originalCommit": "b1437112935129ac50e58ffdc85b8a987e6bff72", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "1a942d1de14a6fcb41ee46a4524ebed32ed25193", "url": "https://github.com/hazelcast/hazelcast/commit/1a942d1de14a6fcb41ee46a4524ebed32ed25193", "message": "WIP", "committedDate": "2020-01-07T09:42:52Z", "type": "forcePushed"}, {"oid": "cc29637ad63f8bc21952d7163662e6297fab5e76", "url": "https://github.com/hazelcast/hazelcast/commit/cc29637ad63f8bc21952d7163662e6297fab5e76", "message": "WIP", "committedDate": "2020-01-07T09:49:22Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2MzY3MjQ4Nw==", "url": "https://github.com/hazelcast/hazelcast/pull/16413#discussion_r363672487", "bodyText": "Minor^2: redundant empty line.", "author": "blazember", "createdAt": "2020-01-07T10:00:28Z", "path": "hazelcast/src/main/java/com/hazelcast/scheduledexecutor/impl/DistributedScheduledExecutorService.java", "diffHunk": "@@ -359,4 +375,60 @@ private void sendBatch(int partitionId, String name, List<ScheduledExecutorMerge\n             invoke(SERVICE_NAME, operation, partitionId);\n         }\n     }\n+\n+    private class StatsLoggerThread extends HazelcastManagedThread {\n+        private final Map<String, MutableInteger> tasksSizes = new HashMap<String, MutableInteger>();\n+        private final ILogger logger = nodeEngine.getLogger(DistributedScheduledExecutorService.class);\n+        private final IPartitionService partitionService = nodeEngine.getPartitionService();\n+        private final long logDelayMillis;\n+        private volatile boolean shutdown;\n+\n+        public StatsLoggerThread(int logDelaySeconds) {\n+            this.logDelayMillis = TimeUnit.SECONDS.toMillis(logDelaySeconds);\n+        }\n+", "originalCommit": "cc29637ad63f8bc21952d7163662e6297fab5e76", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2MzY3MzU1MA==", "url": "https://github.com/hazelcast/hazelcast/pull/16413#discussion_r363673550", "bodyText": "This can be replaced with partition.isLocal(). Also, it might deserve a note somewhere that the reported sizes might be inaccurate during a migration.", "author": "blazember", "createdAt": "2020-01-07T10:02:58Z", "path": "hazelcast/src/main/java/com/hazelcast/scheduledexecutor/impl/DistributedScheduledExecutorService.java", "diffHunk": "@@ -359,4 +375,60 @@ private void sendBatch(int partitionId, String name, List<ScheduledExecutorMerge\n             invoke(SERVICE_NAME, operation, partitionId);\n         }\n     }\n+\n+    private class StatsLoggerThread extends HazelcastManagedThread {\n+        private final Map<String, MutableInteger> tasksSizes = new HashMap<String, MutableInteger>();\n+        private final ILogger logger = nodeEngine.getLogger(DistributedScheduledExecutorService.class);\n+        private final IPartitionService partitionService = nodeEngine.getPartitionService();\n+        private final long logDelayMillis;\n+        private volatile boolean shutdown;\n+\n+        public StatsLoggerThread(int logDelaySeconds) {\n+            this.logDelayMillis = TimeUnit.SECONDS.toMillis(logDelaySeconds);\n+        }\n+\n+\n+        private void shutdown() {\n+            shutdown = true;\n+            interrupt();\n+        }\n+\n+        @Override\n+        public void run() {\n+            while (!shutdown) {\n+                try {\n+                    Thread.sleep(logDelayMillis);\n+                } catch (InterruptedException e) {\n+                    continue;\n+                }\n+\n+                tasksSizes.clear();\n+                for (ScheduledExecutorPartition partition : partitions) {\n+                    if (partition == null) {\n+                        continue;\n+                    }\n+\n+                    if (partitionService.getPartitionOwner(partition.partitionId()) != nodeEngine.getThisAddress()) {", "originalCommit": "cc29637ad63f8bc21952d7163662e6297fab5e76", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2MzcxNzQwMA==", "url": "https://github.com/hazelcast/hazelcast/pull/16413#discussion_r363717400", "bodyText": "Why old_value + current_value? If it was 1 task in the previous log, and now we have two tasks in the container, we will log 3?", "author": "tkountis", "createdAt": "2020-01-07T12:02:46Z", "path": "hazelcast/src/main/java/com/hazelcast/scheduledexecutor/impl/DistributedScheduledExecutorService.java", "diffHunk": "@@ -359,4 +375,60 @@ private void sendBatch(int partitionId, String name, List<ScheduledExecutorMerge\n             invoke(SERVICE_NAME, operation, partitionId);\n         }\n     }\n+\n+    private class StatsLoggerThread extends HazelcastManagedThread {\n+        private final Map<String, MutableInteger> tasksSizes = new HashMap<String, MutableInteger>();\n+        private final ILogger logger = nodeEngine.getLogger(DistributedScheduledExecutorService.class);\n+        private final IPartitionService partitionService = nodeEngine.getPartitionService();\n+        private final long logDelayMillis;\n+        private volatile boolean shutdown;\n+\n+        public StatsLoggerThread(int logDelaySeconds) {\n+            this.logDelayMillis = TimeUnit.SECONDS.toMillis(logDelaySeconds);\n+        }\n+\n+\n+        private void shutdown() {\n+            shutdown = true;\n+            interrupt();\n+        }\n+\n+        @Override\n+        public void run() {\n+            while (!shutdown) {\n+                try {\n+                    Thread.sleep(logDelayMillis);\n+                } catch (InterruptedException e) {\n+                    continue;\n+                }\n+\n+                tasksSizes.clear();\n+                for (ScheduledExecutorPartition partition : partitions) {\n+                    if (partition == null) {\n+                        continue;\n+                    }\n+\n+                    if (partitionService.getPartitionOwner(partition.partitionId()) != nodeEngine.getThisAddress()) {\n+                        // skip non primary partitions.\n+                        continue;\n+                    }\n+\n+                    for (Map.Entry<String, ScheduledExecutorContainer> entry : partition.containers.entrySet()) {\n+                        String name = entry.getKey();\n+                        ScheduledExecutorContainer container = entry.getValue();\n+                        MutableInteger tasksSize = tasksSizes.get(name);\n+                        if (tasksSize == null) {\n+                            tasksSize = new MutableInteger();\n+                            tasksSizes.put(name, tasksSize);\n+                        }\n+                        tasksSize.value += container.tasks.size();", "originalCommit": "cc29637ad63f8bc21952d7163662e6297fab5e76", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Mzc1NDE3MA==", "url": "https://github.com/hazelcast/hazelcast/pull/16413#discussion_r363754170", "bodyText": "An iteration over all the partitions is needed and for the same ScheduledExecutor we could run into multiple ScheduledExecutorContainer instances (for each partition would see one).", "author": "pveentjer", "createdAt": "2020-01-07T13:47:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2MzcxNzQwMA=="}], "type": "inlineReview"}, {"oid": "9a2d527ea58e2679af2d274e11007a0ea81e5e32", "url": "https://github.com/hazelcast/hazelcast/commit/9a2d527ea58e2679af2d274e11007a0ea81e5e32", "message": "Adds ScheduledExecutor logging uncomplete task logging\n\nThis is a temporary solution to provide insights in the number of\nincomplete tasks for the ScheduledExecutor.\n\nIn HZ 4.0 the metrics system was fixed so that dynamic collection\nof data-structures can cause memory leaks.\n\nIn HZ 4.1 the ScheduledExecutor will get metrics.\n\nBut till that time, there is a temporary solution that scans\nthe ScheduledExecutors, collects the metrics and dumps them\nto the log file.", "committedDate": "2020-01-08T06:39:38Z", "type": "forcePushed"}, {"oid": "db842150b06c340677d85495efcfccac1c6a5fca", "url": "https://github.com/hazelcast/hazelcast/commit/db842150b06c340677d85495efcfccac1c6a5fca", "message": "Adds ScheduledExecutor logging uncomplete task logging\n\nThis is a temporary solution to provide insights in the number of\nincomplete tasks for the ScheduledExecutor.\n\nIn HZ 4.0 the metrics system was fixed so that dynamic collection\nof data-structures can cause memory leaks.\n\nIn HZ 4.1 the ScheduledExecutor will get metrics.\n\nBut till that time, there is a temporary solution that scans\nthe ScheduledExecutors, collects the metrics and dumps them\nto the log file.", "committedDate": "2020-01-08T07:43:18Z", "type": "forcePushed"}, {"oid": "efe629cac93738367673276e4e1f3440481b7fa5", "url": "https://github.com/hazelcast/hazelcast/commit/efe629cac93738367673276e4e1f3440481b7fa5", "message": "Adds ScheduledExecutor logging uncomplete task logging\n\nThis is a temporary solution to provide insights in the number of\nincomplete tasks for the ScheduledExecutor.\n\nIn HZ 4.0 the metrics system was fixed so that dynamic collection\nof data-structures can cause memory leaks.\n\nIn HZ 4.1 the ScheduledExecutor will get metrics.\n\nBut till that time, there is a temporary solution that scans\nthe ScheduledExecutors, collects the metrics and dumps them\nto the log file.", "committedDate": "2020-01-08T13:12:48Z", "type": "commit"}, {"oid": "efe629cac93738367673276e4e1f3440481b7fa5", "url": "https://github.com/hazelcast/hazelcast/commit/efe629cac93738367673276e4e1f3440481b7fa5", "message": "Adds ScheduledExecutor logging uncomplete task logging\n\nThis is a temporary solution to provide insights in the number of\nincomplete tasks for the ScheduledExecutor.\n\nIn HZ 4.0 the metrics system was fixed so that dynamic collection\nof data-structures can cause memory leaks.\n\nIn HZ 4.1 the ScheduledExecutor will get metrics.\n\nBut till that time, there is a temporary solution that scans\nthe ScheduledExecutors, collects the metrics and dumps them\nto the log file.", "committedDate": "2020-01-08T13:12:48Z", "type": "forcePushed"}]}