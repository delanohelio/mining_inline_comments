{"pr_number": 17239, "pr_title": "Remove InetSockedAddressCache From Client", "pr_createdAt": "2020-07-20T08:18:08Z", "pr_url": "https://github.com/hazelcast/hazelcast/pull/17239", "timeline": [{"oid": "22070ed713abbc1dd59ff465dc6424c2616ff8b2", "url": "https://github.com/hazelcast/hazelcast/commit/22070ed713abbc1dd59ff465dc6424c2616ff8b2", "message": "Remove InetSockedAddressCache From Client\n\nInetSocketAddressCache was introduced in Blue/Green prd to make\na clear point where the failover takes place.\nAs long as fail over will not happen, the cache was not cleared.\n\nA scenario that we can not support with the cache is as follows:\n1. Members are configured via hostname.\n2. When a member machine restarted the ip address that hostname\ncorresponds changes.\n3. After this there could be several problems.\n   a. A single member restarts in a multi member cluster.\n   b. Whole cluster restarted.\n\nIn scenario a, the client can not connect to the single restarted\nmember ever. The operations that needs to go to that member fails\nwith exception constantly.\n\nIn scenario b, the client cannot connect to any of the members and\nshutdown.\n\nThis fix aims to solve both problems so that client can continue\nto work, while preserving the behaviours in Blue/Green case.\n\nSince I could not find a way to test this with single machine no\ntest is provided. The tests are done in aws enviorenmenti with\nmulti member and CNAME changes.", "committedDate": "2020-07-20T09:46:05Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzM0MzQxOA==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r457343418", "bodyText": "Use HashUtils.hashToIndex instead.", "author": "pveentjer", "createdAt": "2020-07-20T12:37:23Z", "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -586,6 +593,10 @@ TcpClientConnection getOrConnect(@Nonnull Address address) {\n         }\n     }\n \n+    private Object getLockObject(InetSocketAddress inetSocketAddress) {\n+        return mutexes[Math.abs(inetSocketAddress.hashCode() % mutexes.length)];", "originalCommit": "22070ed713abbc1dd59ff465dc6424c2616ff8b2", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "e9e36fca17a22c6a1e61e355a8d09acf6a93f402", "url": "https://github.com/hazelcast/hazelcast/commit/e9e36fca17a22c6a1e61e355a8d09acf6a93f402", "message": "Remove InetSockedAddressCache From Client\n\nInetSocketAddressCache was introduced in Blue/Green prd to make\na clear point where the failover takes place.\nAs long as fail over will not happen, the cache was not cleared.\n\nA scenario that we can not support with the cache is as follows:\n1. Members are configured via hostname.\n2. When a member machine restarted the ip address that hostname\ncorresponds changes.\n3. After this there could be several problems.\n   a. A single member restarts in a multi member cluster.\n   b. Whole cluster restarted.\n\nIn scenario a, the client can not connect to the single restarted\nmember ever. The operations that needs to go to that member fails\nwith exception constantly.\n\nIn scenario b, the client cannot connect to any of the members and\nshutdown.\n\nThis fix aims to solve both problems so that client can continue\nto work, while preserving the behaviours in Blue/Green case.\n\nSince I could not find a way to test this with single machine no\ntest is provided. The tests are done in aws enviorenmenti with\nmulti member and CNAME changes.", "committedDate": "2020-08-12T10:12:24Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQ0NTE2MA==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r470445160", "bodyText": "drawback: with little probability if hashes to the same mutex, even if the other threads are available, will wait for the mutex.\nalternative solution: putIfAbsent into concurrent hash map {inetSocketAddress, mutex} and lock on that mutex. (implementing a similar aproach at dev branch: https://github.com/ihsandemir/hazelcast-cpp-client/blob/protocol/hazelcast/src/hazelcast/client/network.cpp#L218)", "author": "ihsandemir", "createdAt": "2020-08-14T06:59:09Z", "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -586,6 +594,10 @@ TcpClientConnection getOrConnect(@Nonnull Address address) {\n         }\n     }\n \n+    private Object getLockObject(InetSocketAddress inetSocketAddress) {\n+        return mutexes[HashUtil.hashToIndex(inetSocketAddress.hashCode(), mutexes.length)];", "originalCommit": "e9e36fca17a22c6a1e61e355a8d09acf6a93f402", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQ2MTc5Mg==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r470461792", "bodyText": "changing it with putIfAbsent", "author": "sancar", "createdAt": "2020-08-14T07:40:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQ0NTE2MA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQ0NTkzNw==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r470445937", "bodyText": "you can pass parameter connectionsEmpty  to this method.", "author": "ihsandemir", "createdAt": "2020-08-14T07:01:02Z", "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -824,18 +834,19 @@ private void handleSuccessfulAuth(TcpClientConnection connection, ClientAuthenti\n                 logger.fine(\"Checking the cluster: \" + newClusterId + \", current cluster: \" + this.clusterId);\n             }\n \n-            boolean initialConnection = activeConnections.isEmpty();\n-            boolean changedCluster = initialConnection && this.clusterId != null && !newClusterId.equals(this.clusterId);\n-            if (changedCluster) {\n+            boolean connectionsEmpty = activeConnections.isEmpty();\n+            boolean clusterIdChanged = this.clusterId != null && !newClusterId.equals(this.clusterId);\n+            if (clusterIdChanged) {\n+                checkClientStateOnClusterIdChange(connection);", "originalCommit": "e9e36fca17a22c6a1e61e355a8d09acf6a93f402", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQ2OTE5NQ==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r470469195", "bodyText": "isEmpty is not an expensive call. I would rather leave it this way.", "author": "sancar", "createdAt": "2020-08-14T07:56:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDQ0NTkzNw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDc5NDg3Nw==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r500794877", "bodyText": "I'm not sure about the speed at which these objects are created.\nThe problem with creating (and destroying) objects with a potentially inflated monitor, is that it can be a huge performance hog when doing GC. For example, our initial future used the same approach; later we replaced it by lock support to get rid of this inflated monitor and performance increased and latencies became a lot better.\nFor such situations, I would suggest using a striped lock.\nApart from that.. I see you are synchronizing while communicating with external systems. You create the connection, which needs to go through a 3-way handshake (and potentially a few extra steps due to TLS) and then you have authentication. Which is another set of remote steps.\nIf for whatever reason such remote interaction stalls, this thread stalls and this can lead to serious problems in the system. Also, any other thread that hits the same address, could also block indefinitely.\nI think a better approach needs to be found than synchronization.", "author": "pveentjer", "createdAt": "2020-10-07T07:29:43Z", "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -571,18 +571,24 @@ TcpClientConnection getOrConnect(@Nonnull Address address) {\n             return connection;\n         }\n \n-        synchronized (resolveAddress(address)) {\n-            // this critical section is used for making a single connection\n-            // attempt to the given address at a time.\n-            connection = getConnection(address);\n-            if (connection != null) {\n+        InetSocketAddress inetSocketAddress = resolveAddress(address);", "originalCommit": "2e4c56fe83f375b4f9e809737634c2610038a386", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDkxNTYyNQ==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r500915625", "bodyText": "I had the striped lock approach in the first commit. See\ne9e36fc#r500794877\nThis comment was the reason I switched to putIfAbsent\n#17239 (comment)\nNot sure which one is more important. Wdyt?\n\nI'm not sure about the speed at which these objects are created.\n\nThese objects will not be created on a stable cluster. They will be created when there is a disconnection, and the client tries to connect back.\n\nAlso, any other thread that hits the same address, could also block indefinitely.\n\nAbout accessing remote under lock. All the remote invocations are given up with a timeout. It can block other threads but it will not block indefinitely.\n\nI think a better approach needs to be found than synchronization.\n\nI am open to suggestions.\nWe may allow opening connections concurrently and clean them up later when we detect they are not used. Seems more complicated to me.", "author": "sancar", "createdAt": "2020-10-07T10:47:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDc5NDg3Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTM2ODg4MQ==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r505368881", "bodyText": "I'm thinking out loud.\nWhat you could do is to create a CHM with address as key and a Future as value.\nThe future will either block if no value is set, or will return the correct connection.\nYou could add this future using e.g. a putIfAbsent. so that only 1 thread will wait for a connection and then set that value on the future.", "author": "pveentjer", "createdAt": "2020-10-15T08:55:59Z", "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -571,18 +571,24 @@ TcpClientConnection getOrConnect(@Nonnull Address address) {\n             return connection;\n         }\n \n-        synchronized (resolveAddress(address)) {\n-            // this critical section is used for making a single connection\n-            // attempt to the given address at a time.\n-            connection = getConnection(address);\n-            if (connection != null) {\n+        InetSocketAddress inetSocketAddress = resolveAddress(address);\n+        try {\n+            Object mutex = ConcurrencyUtil.getOrPutIfAbsent(mutexes, inetSocketAddress, key -> new Object());", "originalCommit": "2e4c56fe83f375b4f9e809737634c2610038a386", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTM3MjA5NQ==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r505372095", "bodyText": "This way you prevent concurrent connection creations to the same address.\nAnd you can use a CompletableFuture. Which also doesn't suffer from the monitor inflation problem.\nAnd in theory a caller could timeut future.get with a timeout if needs to be.", "author": "pveentjer", "createdAt": "2020-10-15T08:58:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTM2ODg4MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTM3ODk0NA==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r505378944", "bodyText": "I had a closer look at the code and this is on the ConnectionManager. I don't see a problem if another thread blocks on acquring a concurrent connection. He can't do anything useful anyway since the method itself is blocking.\nSo using a lock isn't that much of a problem.\nI would be careful with using an intrinsic lock due to inflation/GC problems as I already indicated in my first comment. It will not immediately cause problems since connections will not be created and destroyed in a very high rate. But eventually you could still run into some GC issues.", "author": "pveentjer", "createdAt": "2020-10-15T09:07:18Z", "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -571,18 +571,24 @@ TcpClientConnection getOrConnect(@Nonnull Address address) {\n             return connection;\n         }\n \n-        synchronized (resolveAddress(address)) {\n-            // this critical section is used for making a single connection\n-            // attempt to the given address at a time.\n-            connection = getConnection(address);\n-            if (connection != null) {\n+        InetSocketAddress inetSocketAddress = resolveAddress(address);\n+        try {\n+            Object mutex = ConcurrencyUtil.getOrPutIfAbsent(mutexes, inetSocketAddress, key -> new Object());", "originalCommit": "2e4c56fe83f375b4f9e809737634c2610038a386", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "32a4f5a4245ecdcd53fb96c46b7652084ded5107", "url": "https://github.com/hazelcast/hazelcast/commit/32a4f5a4245ecdcd53fb96c46b7652084ded5107", "message": "review update. Changed mutexes from array to concurrent map", "committedDate": "2020-11-11T13:53:19Z", "type": "forcePushed"}, {"oid": "1a30276270295ff30cf378e6de8286cc8fb5aa17", "url": "https://github.com/hazelcast/hazelcast/commit/1a30276270295ff30cf378e6de8286cc8fb5aa17", "message": "review update. Changed mutexes from array to concurrent map", "committedDate": "2020-11-25T08:07:35Z", "type": "forcePushed"}, {"oid": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403", "url": "https://github.com/hazelcast/hazelcast/commit/6bd2412320a35c408cc4cd30b7713fa5d8ba4403", "message": "Remove InetSockedAddressCache From Client\n\nInetSocketAddressCache was introduced in Blue/Green prd to make\na clear point where the failover takes place.\nAs long as fail over will not happen, the cache was not cleared.\n\nA scenario that we can not support with the cache is as follows:\n1. Members are configured via hostname.\n2. When a member machine restarted the ip address that hostname\ncorresponds changes.\n3. After this there could be several problems.\n   a. A single member restarts in a multi member cluster.\n   b. Whole cluster restarted.\n\nIn scenario a, the client can not connect to the single restarted\nmember ever. The operations that needs to go to that member fails\nwith exception constantly.\n\nIn scenario b, the client cannot connect to any of the members and\nshutdown.\n\nThis fix aims to solve both problems so that client can continue\nto work, while preserving the behaviours in Blue/Green case.\n\nSince I could not find a way to test this with single machine no\ntest is provided. The tests are done in aws enviorenmenti with\nmulti member and CNAME changes.", "committedDate": "2020-11-25T08:11:21Z", "type": "commit"}, {"oid": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403", "url": "https://github.com/hazelcast/hazelcast/commit/6bd2412320a35c408cc4cd30b7713fa5d8ba4403", "message": "Remove InetSockedAddressCache From Client\n\nInetSocketAddressCache was introduced in Blue/Green prd to make\na clear point where the failover takes place.\nAs long as fail over will not happen, the cache was not cleared.\n\nA scenario that we can not support with the cache is as follows:\n1. Members are configured via hostname.\n2. When a member machine restarted the ip address that hostname\ncorresponds changes.\n3. After this there could be several problems.\n   a. A single member restarts in a multi member cluster.\n   b. Whole cluster restarted.\n\nIn scenario a, the client can not connect to the single restarted\nmember ever. The operations that needs to go to that member fails\nwith exception constantly.\n\nIn scenario b, the client cannot connect to any of the members and\nshutdown.\n\nThis fix aims to solve both problems so that client can continue\nto work, while preserving the behaviours in Blue/Green case.\n\nSince I could not find a way to test this with single machine no\ntest is provided. The tests are done in aws enviorenmenti with\nmulti member and CNAME changes.", "committedDate": "2020-11-25T08:11:21Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYxNTQ4OQ==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r532615489", "bodyText": "nit: could be simplified to if (activeConnections.isEmpty()) {", "author": "puzpuzpuz", "createdAt": "2020-11-30T13:58:42Z", "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -876,18 +873,18 @@ private TcpClientConnection onAuthenticated(TcpClientConnection connection,\n                 logger.fine(\"Checking the cluster: \" + newClusterId + \", current cluster: \" + this.clusterId);\n             }\n \n-            boolean initialConnection = activeConnections.isEmpty();\n-            boolean changedCluster = initialConnection && this.clusterId != null && !newClusterId.equals(this.clusterId);\n-            if (changedCluster) {\n+            boolean clusterIdChanged = this.clusterId != null && !newClusterId.equals(this.clusterId);\n+            if (clusterIdChanged) {\n+                checkClientStateOnClusterIdChange(connection);\n                 logger.warning(\"Switching from current cluster: \" + this.clusterId + \" to new cluster: \" + newClusterId);\n                 client.onClusterRestart();\n             }\n \n+            boolean connectionsEmpty = activeConnections.isEmpty();\n             activeConnections.put(response.memberUuid, connection);\n-\n-            if (initialConnection) {\n+            if (connectionsEmpty) {", "originalCommit": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzExMjAwNw==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r533112007", "bodyText": "We can't. I want to check if the connections were empty before the current connection is put to active connections.", "author": "sancar", "createdAt": "2020-12-01T07:02:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYxNTQ4OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzEyOTYzOA==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r533129638", "bodyText": "Yeah, my bad. Please ignore this comment.", "author": "puzpuzpuz", "createdAt": "2020-12-01T07:45:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYxNTQ4OQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYxNzk5OA==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r532617998", "bodyText": "nit: missing space (//We -> // We) here and in other comments below.", "author": "puzpuzpuz", "createdAt": "2020-11-30T14:02:15Z", "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -914,6 +911,30 @@ private TcpClientConnection onAuthenticated(TcpClientConnection connection,\n         return connection;\n     }\n \n+    private void checkClientStateOnClusterIdChange(TcpClientConnection connection) {\n+        if (activeConnections.isEmpty()) {\n+            //We only have single connection established", "originalCommit": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYyMjk5MQ==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r532622991", "bodyText": "What if there are other connections, but they're not yet closed by the HeartbeatManager (consider a situation when a cluster restarted fast enough)? Is it ok to close the connection in this case?", "author": "puzpuzpuz", "createdAt": "2020-11-30T14:09:32Z", "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -914,6 +911,30 @@ private TcpClientConnection onAuthenticated(TcpClientConnection connection,\n         return connection;\n     }\n \n+    private void checkClientStateOnClusterIdChange(TcpClientConnection connection) {\n+        if (activeConnections.isEmpty()) {\n+            //We only have single connection established\n+            if (failoverConfigProvided) {\n+                //If failover is provided, and this single connection is established after failover logic kicks in\n+                // (checked via `switchingToNextCluster`), then it is OK to continue. Otherwise, we force the failover logic\n+                // to be used by throwing `ClientNotAllowedInClusterException`\n+                if (switchingToNextCluster) {\n+                    switchingToNextCluster = false;\n+                } else {\n+                    String reason = \"Force to hard cluster switch\";\n+                    connection.close(reason, null);\n+                    throw new ClientNotAllowedInClusterException(reason);\n+                }\n+            }\n+        } else {\n+            //If there are other connections that means we have a connection to wrong cluster.", "originalCommit": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzEzMTAxNg==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r533131016", "bodyText": "Not sure if I understand the scenario correctly.  Let me try:\n\nThere were 2 members.\nThe client is connected to the first one.\nWhile the client is trying to open the second connection, both members are restarted.\nIn this case we will close the connection to the second member first thinking that it is not part of the cluster we think we are in.\nThe connection to the first cluster will be gone after that and we will initiate a reconnect to the cluster.\n\nYes, you are right. It seems unfortunate that we close the connection to the second member at step 4.\nBut there seems to be no way around this. It does not make sense to check if the connections on the active connections are closed or not. Because they can be closed right after we check them.\nDo you have a suggestion to avoid that?", "author": "sancar", "createdAt": "2020-12-01T07:48:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYyMjk5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzEzOTEzNA==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r533139134", "bodyText": "Yes, that scenario describes the problem. It could be also slightly different, but with the same outcome:\n\nThere were 2 members.\nThe client is connected to both members.\nBoth members are restarted in slightly different time and HeartbeatManager detects that for the connection to the first one. Then the re-connect logic kicks in.\nIn this case we will close the connection to the first member thinking that it is not part of the cluster we think we are in.\nAfter a while we're going to start re-connect procedure for the second member.\n\nDo you find this scenario possible?\nAs for the ways to avoid it, both scenarios may be not that critical critical, since we're going to keep trying to re-connect to all members in ConnectToAllClusterMembersTask. So, for the very last re-connection attempt (i.e. when activeConnections.isEmpty() == true) we should be able to connect to the new cluster. WDYT?", "author": "puzpuzpuz", "createdAt": "2020-12-01T08:05:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYyMjk5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIzMTE0MA==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r533231140", "bodyText": "After further discussion we came to a conclusion that both described scenarios shouldn't be a problem as the client should recover and connect to all members eventually.", "author": "puzpuzpuz", "createdAt": "2020-12-01T09:38:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYyMjk5MQ=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYwMzM1OA==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r532603358", "bodyText": "Assume that,\n\nFailover config is enabled\nClient connects the first cluster configured\nCluster restarts and the client loses all of its connections\nClient tries to reconnect through doConnectToCandidateCluster. It will first try to connect to the current cluster without setting switchingToNextCluster to true. Now, since the cluster is restarted, I assume that the client should connect to it on the first try (Old code also does this). But that won't happen since switchingToNextCluster is false. We will throw ClientNotAllowedInClusterException here and try to connect alternative clusters. Isn't that a behavior change?", "author": "mdumandag", "createdAt": "2020-11-30T13:40:21Z", "path": "hazelcast/src/main/java/com/hazelcast/client/impl/connection/tcp/TcpClientConnectionManager.java", "diffHunk": "@@ -914,6 +911,30 @@ private TcpClientConnection onAuthenticated(TcpClientConnection connection,\n         return connection;\n     }\n \n+    private void checkClientStateOnClusterIdChange(TcpClientConnection connection) {\n+        if (activeConnections.isEmpty()) {\n+            //We only have single connection established\n+            if (failoverConfigProvided) {\n+                //If failover is provided, and this single connection is established after failover logic kicks in\n+                // (checked via `switchingToNextCluster`), then it is OK to continue. Otherwise, we force the failover logic\n+                // to be used by throwing `ClientNotAllowedInClusterException`\n+                if (switchingToNextCluster) {\n+                    switchingToNextCluster = false;\n+                } else {", "originalCommit": "6bd2412320a35c408cc4cd30b7713fa5d8ba4403", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzEyMzI2Nw==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r533123267", "bodyText": "It is a behavior change, and it is actually a fix on the behavior.\nWhen this path is run there are two possibilities that happened in the cluster.\n\nThere was a single cluster and it restarted.\nThere were two clusters and the first one is closed.\n\nNote that there is no way for us to differentiate these two. In the second scenario, it could be the case that the same hostnames are used for both clusters and the user changed the hostname resolution before closing the first cluster. So even the addresses of the two clusters are the same for the client.\nThere is no problem with the first case. And the behavior change for that looks unnecessary. But, it is an important fix for the second case.\nThe problem of the second case is as follows.\n\nFailover is configured. Now assume that two clusters have the same cluster name/credentials, meaning a client can switch between these two and will not notice any authentication failure.\nFirst cluster has shutdown.\nAlso keep in mind that in failover config, users can provide different configurations for clusters.\nThe client is will connect to the second cluster in the first attempt with the configuration of the first cluster. If we don't fail the connection, it will continue with the wrong configuration. We need to make sure that when failover config is provided, the client will remain connected to a cluster only if it is connected with the correct configuration.", "author": "sancar", "createdAt": "2020-12-01T07:31:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYwMzM1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzI3MTQyNg==", "url": "https://github.com/hazelcast/hazelcast/pull/17239#discussion_r533271426", "bodyText": "I see the problem with the second scenario. That makes sense then", "author": "mdumandag", "createdAt": "2020-12-01T10:11:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYwMzM1OA=="}], "type": "inlineReview"}]}