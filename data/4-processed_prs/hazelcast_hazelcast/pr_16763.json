{"pr_number": 16763, "pr_title": "SQL: Base executor and row interfaces (#16762)", "pr_createdAt": "2020-03-17T08:09:48Z", "pr_url": "https://github.com/hazelcast/hazelcast/pull/16763", "timeline": [{"oid": "24ad7231c6a7174e2e566475bcc59120e45a51e6", "url": "https://github.com/hazelcast/hazelcast/commit/24ad7231c6a7174e2e566475bcc59120e45a51e6", "message": "SQL type system.", "committedDate": "2020-03-11T09:15:42Z", "type": "commit"}, {"oid": "4a05a318f3348ceb1b50e0df94515ed5e5b81c74", "url": "https://github.com/hazelcast/hazelcast/commit/4a05a318f3348ceb1b50e0df94515ed5e5b81c74", "message": "WIP on tests.", "committedDate": "2020-03-11T11:35:52Z", "type": "commit"}, {"oid": "a37c3a7f6bf83c2fda80556ac42fa38ee0a126cd", "url": "https://github.com/hazelcast/hazelcast/commit/a37c3a7f6bf83c2fda80556ac42fa38ee0a126cd", "message": "Heap row", "committedDate": "2020-03-11T11:50:57Z", "type": "commit"}, {"oid": "9dff1b6ec3a720413698d86366ac96491aaccd17", "url": "https://github.com/hazelcast/hazelcast/commit/9dff1b6ec3a720413698d86366ac96491aaccd17", "message": "JoinRow tests.", "committedDate": "2020-03-11T12:00:01Z", "type": "commit"}, {"oid": "710ee92b553ca7cfb78395a5f22824fee76e549d", "url": "https://github.com/hazelcast/hazelcast/commit/710ee92b553ca7cfb78395a5f22824fee76e549d", "message": "WIP", "committedDate": "2020-03-11T16:36:20Z", "type": "commit"}, {"oid": "94859e9a37035c84c305ad8083e7e472e3ae983d", "url": "https://github.com/hazelcast/hazelcast/commit/94859e9a37035c84c305ad8083e7e472e3ae983d", "message": "AbstractExec test.", "committedDate": "2020-03-11T16:44:24Z", "type": "commit"}, {"oid": "40878714ccfb7ef81c7e46f2fc444e2c4cd53d4c", "url": "https://github.com/hazelcast/hazelcast/commit/40878714ccfb7ef81c7e46f2fc444e2c4cd53d4c", "message": "Upstream state.", "committedDate": "2020-03-11T17:34:35Z", "type": "commit"}, {"oid": "7382174786f50c923c1549b19d0e88ed99748a7e", "url": "https://github.com/hazelcast/hazelcast/commit/7382174786f50c923c1549b19d0e88ed99748a7e", "message": "Done.", "committedDate": "2020-03-11T17:43:21Z", "type": "commit"}, {"oid": "6a96bbf03ef9119da2c28de1a62be71596b9c501", "url": "https://github.com/hazelcast/hazelcast/commit/6a96bbf03ef9119da2c28de1a62be71596b9c501", "message": "Fixed review comments.", "committedDate": "2020-03-12T11:34:22Z", "type": "commit"}, {"oid": "b75fcfe8ad980a9426c96a5f2a5d2499e9e5f5ce", "url": "https://github.com/hazelcast/hazelcast/commit/b75fcfe8ad980a9426c96a5f2a5d2499e9e5f5ce", "message": "Removed useless JavaDocs.", "committedDate": "2020-03-12T11:44:00Z", "type": "commit"}, {"oid": "af90816527413e2d6663ceba6b5687708459c7cf", "url": "https://github.com/hazelcast/hazelcast/commit/af90816527413e2d6663ceba6b5687708459c7cf", "message": "Clarification on precedence.", "committedDate": "2020-03-12T14:32:36Z", "type": "commit"}, {"oid": "52853076caf0544f7f19bb0ee38902af052a8255", "url": "https://github.com/hazelcast/hazelcast/commit/52853076caf0544f7f19bb0ee38902af052a8255", "message": "Fixes.", "committedDate": "2020-03-13T11:41:22Z", "type": "commit"}, {"oid": "2b7f32db0896793357a09edc4d882005a69ae530", "url": "https://github.com/hazelcast/hazelcast/commit/2b7f32db0896793357a09edc4d882005a69ae530", "message": "Fixed type compatibility matrix for BIT.", "committedDate": "2020-03-13T17:29:02Z", "type": "commit"}, {"oid": "8dbfa537ad955200f980c576ccf9945913006c2c", "url": "https://github.com/hazelcast/hazelcast/commit/8dbfa537ad955200f980c576ccf9945913006c2c", "message": "Merge branch 'master' into issues/15241", "committedDate": "2020-03-16T06:27:50Z", "type": "commit"}, {"oid": "ded98cf91ac6d1440ae6197e2941c2f3539fd24d", "url": "https://github.com/hazelcast/hazelcast/commit/ded98cf91ac6d1440ae6197e2941c2f3539fd24d", "message": "Merge branch 'issues/15241' into sql-exec-interfaces", "committedDate": "2020-03-16T06:45:35Z", "type": "commit"}, {"oid": "da879db5027742866d622af5c39d99eb708b5de7", "url": "https://github.com/hazelcast/hazelcast/commit/da879db5027742866d622af5c39d99eb708b5de7", "message": "Merge.", "committedDate": "2020-03-16T06:47:09Z", "type": "commit"}, {"oid": "cdf9f084335595402a030e0a8e243f1cc4773a0d", "url": "https://github.com/hazelcast/hazelcast/commit/cdf9f084335595402a030e0a8e243f1cc4773a0d", "message": "Fix review comments.", "committedDate": "2020-03-16T08:51:00Z", "type": "commit"}, {"oid": "8aab722371910e351e0517292da0389be99c21e8", "url": "https://github.com/hazelcast/hazelcast/commit/8aab722371910e351e0517292da0389be99c21e8", "message": "Merge branch 'issues/15241' into prod-exec-row", "committedDate": "2020-03-16T09:18:56Z", "type": "commit"}, {"oid": "e75518d7c94e31b4c8b42467a0d0675821a8b126", "url": "https://github.com/hazelcast/hazelcast/commit/e75518d7c94e31b4c8b42467a0d0675821a8b126", "message": "Merge branch 'master' into prod-exec-row\n\n# Conflicts:\n#\tdocs/design/sql/01-type-system.md\n#\thazelcast/src/main/java/com/hazelcast/sql/HazelcastSqlException.java\n#\thazelcast/src/main/java/com/hazelcast/sql/impl/SqlDataSerializerHook.java\n#\thazelcast/src/main/java/com/hazelcast/sql/impl/type/converter/Converter.java\n#\thazelcast/src/main/java/com/hazelcast/sql/impl/type/converter/Converters.java\n#\thazelcast/src/test/java/com/hazelcast/sql/impl/type/QueryDataTypeTest.java\n#\thazelcast/src/test/java/com/hazelcast/sql/impl/type/converter/ConvertersTest.java", "committedDate": "2020-03-17T07:56:45Z", "type": "commit"}, {"oid": "5aa1a7373647881de9a229014d776ae8fa5e0a2f", "url": "https://github.com/hazelcast/hazelcast/commit/5aa1a7373647881de9a229014d776ae8fa5e0a2f", "message": "Merge fixes.", "committedDate": "2020-03-17T08:02:55Z", "type": "commit"}, {"oid": "5895e977b72fe4b06e4b9654aad9c6f86e645155", "url": "https://github.com/hazelcast/hazelcast/commit/5895e977b72fe4b06e4b9654aad9c6f86e645155", "message": "Design doc.", "committedDate": "2020-03-17T14:15:31Z", "type": "commit"}, {"oid": "1124f5119eb46ae868f9e71adc8e631cc7229870", "url": "https://github.com/hazelcast/hazelcast/commit/1124f5119eb46ae868f9e71adc8e631cc7229870", "message": "Typos in 02.", "committedDate": "2020-03-17T14:26:23Z", "type": "commit"}, {"oid": "b92b6653977ac5a1d1e9e844077d6c45b429e07c", "url": "https://github.com/hazelcast/hazelcast/commit/b92b6653977ac5a1d1e9e844077d6c45b429e07c", "message": "Minors.", "committedDate": "2020-03-17T14:27:58Z", "type": "commit"}, {"oid": "9026003302687165c61c04797f30c877665d5b6e", "url": "https://github.com/hazelcast/hazelcast/commit/9026003302687165c61c04797f30c877665d5b6e", "message": "Minors.", "committedDate": "2020-03-17T14:30:38Z", "type": "commit"}, {"oid": "fe86ee721d2eea6df3884e9e6bded1b0973546d1", "url": "https://github.com/hazelcast/hazelcast/commit/fe86ee721d2eea6df3884e9e6bded1b0973546d1", "message": "Minors.", "committedDate": "2020-03-17T14:38:47Z", "type": "commit"}, {"oid": "b3503b97b364103b427e5da11af1a4c022c504a6", "url": "https://github.com/hazelcast/hazelcast/commit/b3503b97b364103b427e5da11af1a4c022c504a6", "message": "Typos.", "committedDate": "2020-03-17T14:43:50Z", "type": "commit"}, {"oid": "713ca1839ca03b2f2465a8c5ceb1986f45958944", "url": "https://github.com/hazelcast/hazelcast/commit/713ca1839ca03b2f2465a8c5ceb1986f45958944", "message": "Review.", "committedDate": "2020-03-18T12:35:12Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMzNDcwNA==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394334704", "bodyText": "It's not clear who is the owner of the returned row batch. May the consumer assume the row batch is immutable and the the ownership is transferred to the consumer? Or should the consumer assume that the row batch content may change at any/some time and the ownership is still held by the producer?", "author": "taburet", "createdAt": "2020-03-18T13:12:38Z", "path": "docs/design/sql/02-operator-interface.md", "diffHunk": "@@ -0,0 +1,157 @@\n+# SQL Operator Interface\n+\n+## Overview\n+In databases, SQL queries are typically represented in a form of operator tree, called **Volcano Model**,\n+introduced in Goetz Graefe seminal paper [[1]].\n+\n+In this document, we describe the design of the Hazelcast Mustang operator interface, which is based\n+on the Volcano Model.\n+\n+## Relational Operators\n+An SQL query is first parsed into a **parse tree**, which is used for syntactic and semantic checking.\n+\n+The parse tree is then converted into **relational operator tree**, or simply **relational tree**,\n+for optimization. The relational tree is more convenient because its structure is simpler than the\n+structure of the parse tree.\n+\n+A **query plan**, consisting of a relational tree and supplemental information, is submitted for execution\n+after the optimization.\n+\n+The table below lists common relational operators used in database engines.\n+\n+*Table 1: Common Relational Operators*\n+\n+| Name | Description |\n+|---|---|\n+| `Scan` | Iterate over source rows |\n+| `Project` | Return a set of original or derived attributes of the child operator |\n+| `Filter` | Return rows of the child operator which pass the provided predicate |\n+| `Aggregate` | Aggregate rows of the child operator |\n+| `Sort` | Sort rows of the child operator |\n+| `Join` | Join rows from several child operators |\n+\n+An example of a query, its parse tree, and its relational tree is provided below.\n+\n+*Snippet 1: Query*\n+```sql\n+SELECT a, SUM(b)\n+FROM table\n+GROUP BY a\n+HAVING SUM(b) > 50\n+```\n+*Snippet 2: Parse Tree*\n+```\n+-- Select\n+---- SelectList [a, SUM(b)]\n+---- From [table]\n+---- GroupBy [a]\n+---- Having [SUM(b) > 50]\n+```\n+*Snippet 3: Relational Tree*\n+```\n+-- Filter [SUM(b) > 50]\n+---- Aggregate [a -> SUM(b)]\n+------ Project [a, b]\n+-------- Scan [table]\n+```\n+\n+## Volcano Model\n+\n+Volcano Model defines the common data exchange interface between operators in the relational tree. This allows\n+for extensibility, as new operators could be implemented with minimal changes to the engine.\n+\n+In the original paper the interface consists of three operations:\n+\n+*Snippet 4: Volcano Interface*\n+```java\n+interface Operator {\n+    void open();  // Initialize the operator\n+    Row next();   // Get the next row\n+    void close(); // Close the operator and release all resources\n+}\n+```\n+\n+## Volcano Model in Hazelcast Mustang\n+\n+The original Volcano Model has two drawbacks:\n+1. Operators exchange one row at a time, which leads to performance overhead\n+2. Call to the `next()` is blocking, which is not optimal for the distributed environment, where\n+operators often wait for remote data or free space in the send buffer.\n+\n+To achieve high performance, we introduce several changes to the original Volcano Model: batching and\n+non-blocking execution.\n+\n+### Row and RowBatch\n+We define the `RowBatch` interface which a collection of rows (tuples).\n+\n+*Snippet 5: RowBatch interface*\n+```java\n+interface RowBatch {\n+    Row getRow(int index); // Get the row by index\n+    int getRowCount();     // Get the number of rows \n+} \n+```\n+\n+Then we define the `Row` interface, which provides access to values by index. The `Row` itself is considered\n+as a special case of `RowBatch` with one row. This allows saving on allocations in some parts of the engine.\n+\n+*Snippet 6: Row interface*\n+```java\n+interface Row extends RowBatch {\n+    Object get(int index); // Get the value by index\n+    int getColumnCount();  // Get the number of values in the row \n+    \n+    default int getRowCount() {\n+        return 1;\n+    }\n+    \n+    default int getRow(int index) {\n+        return this;\n+    }\n+}\n+```\n+\n+### Operator\n+The operator is defined by `Exec` interface:\n+1. Operators exchange `RowBatch` instead of `Row`\n+1. The blocking `next()` method is replaced with the non-blocking `advance()` method, which returns the iteration\n+result instead of the row batch\n+1. The `RowBatch` could be accessed through a separate method\n+1. The `open()` method is renamed to `setup()`. Special query context is passed to it as an argument\n+1. There is no separate `close()` method because the engine doesn't need explicit per-operator cleanup at the\n+moment. This may change in future, in this case the current document should be updated accordingly\n+\n+*Snippet 7: Exec interface*\n+```java\n+interface Exec {\n+    void setup(QueryContext context); // Initialize the operator\n+    IterationResult advance();        // Advance the operator if possible; never blocks\n+    RowBatch currentBatch();          // Get the batch returned by the previous advance() call \n+}\n+```\n+\n+The result of iteration is defined in the `IterationResult` enumeration.\n+\n+*Snippet 8: IterationResult enumeration*\n+```java\n+enum IterationResult {\n+    FETCHED,      // Iteration produced new rows\n+    FETCHED_DONE, // Iteration produced new rows and reached the end of the stream, no more rows are expected\n+    WAIT;         // Failed to produce new rows, release the control\n+}\n+```\n+\n+When the engine has received `FETCHED` or `FETCHED_DONE` from the `Exec.advance()` call, it may access the\n+produced rows through the `Exec.currentBatch()` call. If the engine has received `WAIT`, then query", "originalCommit": "713ca1839ca03b2f2465a8c5ceb1986f45958944", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM0NTI0MA==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394345240", "bodyText": "This is a difficult question. I think that in the current prototype we are not concerned with it. Both approaches have their pros and cons:\n\nWithout ownership transfer - easier to implement, but produce more litter, because every operator must produce its own copy of the batch\nWith ownership transfer - hard to reason about memory (especially if we move to offheap eventually), but more performant\n\nAnother interesting point is that this question will not be critical as soon as we have a compilation because memory management decisions could be made at the fine-grained level there.\nAlso if we switch to some byte[] representations of rows, then copying would be required anyway.\nThat said I am thinking that implementation without ownership transfer is slightly better for us. What do you think?", "author": "devozerov", "createdAt": "2020-03-18T13:29:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMzNDcwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM1MDUyNg==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394350526", "bodyText": "To my understanding, it's better to state explicitly that the ownership is still held by the producer and the row batch content is valid until the next advance() call. The consumer can always make a copy, if it needs one; the producer may be implemented in a \"zero-allocation\" way.", "author": "taburet", "createdAt": "2020-03-18T13:36:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMzNDcwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM1MzE4MQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394353181", "bodyText": "... hmm, and the same question applies to Row", "author": "taburet", "createdAt": "2020-03-18T13:40:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMzNDcwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM1NjczMQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394356731", "bodyText": "I meant the same but shuffled the terms. Please read \"with\" as \"without\" and vice versa :-)\nThe row is assumed to be immutable.", "author": "devozerov", "createdAt": "2020-03-18T13:46:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMzNDcwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM1NzA3OQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394357079", "bodyText": "I updated the original comment.", "author": "devozerov", "createdAt": "2020-03-18T13:46:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMzNDcwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM2MDYyNw==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394360627", "bodyText": "Clarifications about the life cycle have been added to the document. See \"Implementation Guidelines\".", "author": "devozerov", "createdAt": "2020-03-18T13:51:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMzNDcwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM2ODQyOQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394368429", "bodyText": "Added more clarifications (f91e696)", "author": "devozerov", "createdAt": "2020-03-18T14:02:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMzNDcwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgzNTQ5OQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394835499", "bodyText": "It might make sense to work with rows in the same way. For instance, most aggregation functions don't require the rows themselves, so the producer might reuse the same preallocated set of rows over and over again. But it's not clear how to define the ownership transfer/bounds for rows.", "author": "taburet", "createdAt": "2020-03-19T07:35:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMzNDcwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0ODM0Mg==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394848342", "bodyText": "Aggregation is a rare exception where the operator can operate without row ownership. Most other operators require full control of the row state - filter, project, join, sort, etc.. Otherwise we will have to copy them.", "author": "devozerov", "createdAt": "2020-03-19T08:06:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMzNDcwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg2MTkyMw==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394861923", "bodyText": "Probably \"the same way\" was the wrong wording. I was thinking about the situation when we, for instance, doing a simple scan producing 1M rows, we end up allocating 1M rows in total. But in reality we send the rows in small batches, batch by batch. So we really need only batch size rows allocated, once the batch rows hit the wire or consumed in some other way, we can reuse the same set of rows.", "author": "taburet", "createdAt": "2020-03-19T08:33:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMzNDcwNA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg2NjgyMw==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394866823", "bodyText": "It's impossible in the general case.\nFirst, we need to track row usage and sending somehow, which is not the case at the moment and would require additional code infrastructure.\nSecond, this is merely an implementation detail that we use HeapRow by default, pretty unfortunate detail. In future we likely to switch to byte[]-based or byte*-based implementation, where no row reuse is possible at all in the general case. Instead he reusable resource will be the byte array (or at least row batch), but not row.\nLast, batch allocations depend on the operator. Project operator may split the result set into batches and align it with the sender batch size. But blocking operators, such as Sort, cannot do that.", "author": "devozerov", "createdAt": "2020-03-19T08:43:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMzNDcwNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMzNjExOA==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394336118", "bodyText": "If it's referred everywhere as an operator, why not just name it the same way?", "author": "taburet", "createdAt": "2020-03-18T13:14:49Z", "path": "docs/design/sql/02-operator-interface.md", "diffHunk": "@@ -0,0 +1,157 @@\n+# SQL Operator Interface\n+\n+## Overview\n+In databases, SQL queries are typically represented in a form of operator tree, called **Volcano Model**,\n+introduced in Goetz Graefe seminal paper [[1]].\n+\n+In this document, we describe the design of the Hazelcast Mustang operator interface, which is based\n+on the Volcano Model.\n+\n+## Relational Operators\n+An SQL query is first parsed into a **parse tree**, which is used for syntactic and semantic checking.\n+\n+The parse tree is then converted into **relational operator tree**, or simply **relational tree**,\n+for optimization. The relational tree is more convenient because its structure is simpler than the\n+structure of the parse tree.\n+\n+A **query plan**, consisting of a relational tree and supplemental information, is submitted for execution\n+after the optimization.\n+\n+The table below lists common relational operators used in database engines.\n+\n+*Table 1: Common Relational Operators*\n+\n+| Name | Description |\n+|---|---|\n+| `Scan` | Iterate over source rows |\n+| `Project` | Return a set of original or derived attributes of the child operator |\n+| `Filter` | Return rows of the child operator which pass the provided predicate |\n+| `Aggregate` | Aggregate rows of the child operator |\n+| `Sort` | Sort rows of the child operator |\n+| `Join` | Join rows from several child operators |\n+\n+An example of a query, its parse tree, and its relational tree is provided below.\n+\n+*Snippet 1: Query*\n+```sql\n+SELECT a, SUM(b)\n+FROM table\n+GROUP BY a\n+HAVING SUM(b) > 50\n+```\n+*Snippet 2: Parse Tree*\n+```\n+-- Select\n+---- SelectList [a, SUM(b)]\n+---- From [table]\n+---- GroupBy [a]\n+---- Having [SUM(b) > 50]\n+```\n+*Snippet 3: Relational Tree*\n+```\n+-- Filter [SUM(b) > 50]\n+---- Aggregate [a -> SUM(b)]\n+------ Project [a, b]\n+-------- Scan [table]\n+```\n+\n+## Volcano Model\n+\n+Volcano Model defines the common data exchange interface between operators in the relational tree. This allows\n+for extensibility, as new operators could be implemented with minimal changes to the engine.\n+\n+In the original paper the interface consists of three operations:\n+\n+*Snippet 4: Volcano Interface*\n+```java\n+interface Operator {\n+    void open();  // Initialize the operator\n+    Row next();   // Get the next row\n+    void close(); // Close the operator and release all resources\n+}\n+```\n+\n+## Volcano Model in Hazelcast Mustang\n+\n+The original Volcano Model has two drawbacks:\n+1. Operators exchange one row at a time, which leads to performance overhead\n+2. Call to the `next()` is blocking, which is not optimal for the distributed environment, where\n+operators often wait for remote data or free space in the send buffer.\n+\n+To achieve high performance, we introduce several changes to the original Volcano Model: batching and\n+non-blocking execution.\n+\n+### Row and RowBatch\n+We define the `RowBatch` interface which a collection of rows (tuples).\n+\n+*Snippet 5: RowBatch interface*\n+```java\n+interface RowBatch {\n+    Row getRow(int index); // Get the row by index\n+    int getRowCount();     // Get the number of rows \n+} \n+```\n+\n+Then we define the `Row` interface, which provides access to values by index. The `Row` itself is considered\n+as a special case of `RowBatch` with one row. This allows saving on allocations in some parts of the engine.\n+\n+*Snippet 6: Row interface*\n+```java\n+interface Row extends RowBatch {\n+    Object get(int index); // Get the value by index\n+    int getColumnCount();  // Get the number of values in the row \n+    \n+    default int getRowCount() {\n+        return 1;\n+    }\n+    \n+    default int getRow(int index) {\n+        return this;\n+    }\n+}\n+```\n+\n+### Operator\n+The operator is defined by `Exec` interface:\n+1. Operators exchange `RowBatch` instead of `Row`\n+1. The blocking `next()` method is replaced with the non-blocking `advance()` method, which returns the iteration\n+result instead of the row batch\n+1. The `RowBatch` could be accessed through a separate method\n+1. The `open()` method is renamed to `setup()`. Special query context is passed to it as an argument\n+1. There is no separate `close()` method because the engine doesn't need explicit per-operator cleanup at the\n+moment. This may change in future, in this case the current document should be updated accordingly\n+\n+*Snippet 7: Exec interface*\n+```java\n+interface Exec {", "originalCommit": "713ca1839ca03b2f2465a8c5ceb1986f45958944", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM1MjkyNQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394352925", "bodyText": "The operator is an ambiguous term. Its precise meaning depends on the context. Calcite nodes (RelNode, LogicalRel, PhysicalRel), plan nodes (PhysicalNode), and iterator nodes (Exec) are all operators. So in different design documents, we will refer to different entities as \"operator\".\nExec is used here for historical reasons, to stress out that this is an executable node, as opposed to relational operators used during optimization. Moreover, certain executors, such as SendExec or ReceiveExec, have no relational operator counterparts at all, so Exec is a slightly more broad term than relational operator.\nI slightly changed the name of the snippet itself, but I would avoid changing interface name for now since it is an internal thing which is unlikely to be touched by anyone except for advanced product hackers, but at the same time renaming might cause conflicts between multiple prototype and implementation branches.", "author": "devozerov", "createdAt": "2020-03-18T13:40:32Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDMzNjExOA=="}], "type": "inlineReview"}, {"oid": "bce5fa3cb9dd6d9423ee72ca84c685cfc4512f61", "url": "https://github.com/hazelcast/hazelcast/commit/bce5fa3cb9dd6d9423ee72ca84c685cfc4512f61", "message": "Review comments.", "committedDate": "2020-03-18T13:41:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM1Mzg3MA==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394353870", "bodyText": "The return type should be Row, I believe :)", "author": "taburet", "createdAt": "2020-03-18T13:41:53Z", "path": "docs/design/sql/02-operator-interface.md", "diffHunk": "@@ -0,0 +1,157 @@\n+# SQL Operator Interface\n+\n+## Overview\n+In databases, SQL queries are typically represented in a form of operator tree, called **Volcano Model**,\n+introduced in Goetz Graefe seminal paper [[1]].\n+\n+In this document, we describe the design of the Hazelcast Mustang operator interface, which is based\n+on the Volcano Model.\n+\n+## Relational Operators\n+An SQL query is first parsed into a **parse tree**, which is used for syntactic and semantic checking.\n+\n+The parse tree is then converted into **relational operator tree**, or simply **relational tree**,\n+for optimization. The relational tree is more convenient because its structure is simpler than the\n+structure of the parse tree.\n+\n+A **query plan**, consisting of a relational tree and supplemental information, is submitted for execution\n+after the optimization.\n+\n+The table below lists common relational operators used in database engines.\n+\n+*Table 1: Common Relational Operators*\n+\n+| Name | Description |\n+|---|---|\n+| `Scan` | Iterate over source rows |\n+| `Project` | Return a set of original or derived attributes of the child operator |\n+| `Filter` | Return rows of the child operator which pass the provided predicate |\n+| `Aggregate` | Aggregate rows of the child operator |\n+| `Sort` | Sort rows of the child operator |\n+| `Join` | Join rows from several child operators |\n+\n+An example of a query, its parse tree, and its relational tree is provided below.\n+\n+*Snippet 1: Query*\n+```sql\n+SELECT a, SUM(b)\n+FROM table\n+GROUP BY a\n+HAVING SUM(b) > 50\n+```\n+*Snippet 2: Parse Tree*\n+```\n+-- Select\n+---- SelectList [a, SUM(b)]\n+---- From [table]\n+---- GroupBy [a]\n+---- Having [SUM(b) > 50]\n+```\n+*Snippet 3: Relational Tree*\n+```\n+-- Filter [SUM(b) > 50]\n+---- Aggregate [a -> SUM(b)]\n+------ Project [a, b]\n+-------- Scan [table]\n+```\n+\n+## Volcano Model\n+\n+Volcano Model defines the common data exchange interface between operators in the relational tree. This allows\n+for extensibility, as new operators could be implemented with minimal changes to the engine.\n+\n+In the original paper the interface consists of three operations:\n+\n+*Snippet 4: Volcano Interface*\n+```java\n+interface Operator {\n+    void open();  // Initialize the operator\n+    Row next();   // Get the next row\n+    void close(); // Close the operator and release all resources\n+}\n+```\n+\n+## Volcano Model in Hazelcast Mustang\n+\n+The original Volcano Model has two drawbacks:\n+1. Operators exchange one row at a time, which leads to performance overhead\n+2. Call to the `next()` is blocking, which is not optimal for the distributed environment, where\n+operators often wait for remote data or free space in the send buffer.\n+\n+To achieve high performance, we introduce several changes to the original Volcano Model: batching and\n+non-blocking execution.\n+\n+### Row and RowBatch\n+We define the `RowBatch` interface which a collection of rows (tuples).\n+\n+*Snippet 5: RowBatch interface*\n+```java\n+interface RowBatch {\n+    Row getRow(int index); // Get the row by index\n+    int getRowCount();     // Get the number of rows \n+} \n+```\n+\n+Then we define the `Row` interface, which provides access to values by index. The `Row` itself is considered\n+as a special case of `RowBatch` with one row. This allows saving on allocations in some parts of the engine.\n+\n+*Snippet 6: Row interface*\n+```java\n+interface Row extends RowBatch {\n+    Object get(int index); // Get the value by index\n+    int getColumnCount();  // Get the number of values in the row \n+    \n+    default int getRowCount() {\n+        return 1;\n+    }\n+    \n+    default int getRow(int index) {", "originalCommit": "713ca1839ca03b2f2465a8c5ceb1986f45958944", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM2MDE5Mw==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394360193", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-03-18T13:51:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDM1Mzg3MA=="}], "type": "inlineReview"}, {"oid": "9c959d55cb4b8ec4842807a172143c3fc72c0a77", "url": "https://github.com/hazelcast/hazelcast/commit/9c959d55cb4b8ec4842807a172143c3fc72c0a77", "message": "Review comments.", "committedDate": "2020-03-18T13:47:49Z", "type": "commit"}, {"oid": "4620f01fdc2c3cb3b548962e177b6207ecaf6474", "url": "https://github.com/hazelcast/hazelcast/commit/4620f01fdc2c3cb3b548962e177b6207ecaf6474", "message": "Clarifications on row and row batch life cycles.", "committedDate": "2020-03-18T13:50:42Z", "type": "commit"}, {"oid": "f91e6967d4faa6c3ff5d25e121d60236bf1acf8a", "url": "https://github.com/hazelcast/hazelcast/commit/f91e6967d4faa6c3ff5d25e121d60236bf1acf8a", "message": "More clarifications.", "committedDate": "2020-03-18T14:01:33Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgzNjk2Nw==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394836967", "bodyText": "Just as an idea, these two methods can be combined into a single one: RowBatch  advance() returning special signaling RowBatch instances named the same and having the same semantics as IterationResult members.", "author": "taburet", "createdAt": "2020-03-19T07:38:50Z", "path": "docs/design/sql/02-operator-interface.md", "diffHunk": "@@ -0,0 +1,163 @@\n+# SQL Operator Interface\n+\n+## Overview\n+In databases, SQL queries are typically represented in a form of operator tree, called **Volcano Model**,\n+introduced in Goetz Graefe seminal paper [[1]].\n+\n+In this document, we describe the design of the Hazelcast Mustang operator interface, which is based\n+on the Volcano Model.\n+\n+## Relational Operators\n+An SQL query is first parsed into a **parse tree**, which is used for syntactic and semantic checking.\n+\n+The parse tree is then converted into **relational operator tree**, or simply **relational tree**,\n+for optimization. The relational tree is more convenient because its structure is simpler than the\n+structure of the parse tree.\n+\n+A **query plan**, consisting of a relational tree and supplemental information, is submitted for execution\n+after the optimization.\n+\n+The table below lists common relational operators used in database engines.\n+\n+*Table 1: Common Relational Operators*\n+\n+| Name | Description |\n+|---|---|\n+| `Scan` | Iterate over source rows |\n+| `Project` | Return a set of original or derived attributes of the child operator |\n+| `Filter` | Return rows of the child operator which pass the provided predicate |\n+| `Aggregate` | Aggregate rows of the child operator |\n+| `Sort` | Sort rows of the child operator |\n+| `Join` | Join rows from several child operators |\n+\n+An example of a query, its parse tree, and its relational tree is provided below.\n+\n+*Snippet 1: Query*\n+```sql\n+SELECT a, SUM(b)\n+FROM table\n+GROUP BY a\n+HAVING SUM(b) > 50\n+```\n+*Snippet 2: Parse Tree*\n+```\n+-- Select\n+---- SelectList [a, SUM(b)]\n+---- From [table]\n+---- GroupBy [a]\n+---- Having [SUM(b) > 50]\n+```\n+*Snippet 3: Relational Tree*\n+```\n+-- Filter [SUM(b) > 50]\n+---- Aggregate [a -> SUM(b)]\n+------ Project [a, b]\n+-------- Scan [table]\n+```\n+\n+## Volcano Model\n+\n+Volcano Model defines the common data exchange interface between operators in the relational tree. This allows\n+for extensibility, as new operators could be implemented with minimal changes to the engine.\n+\n+In the original paper the interface consists of three operations:\n+\n+*Snippet 4: Volcano Interface*\n+```java\n+interface Operator {\n+    void open();  // Initialize the operator\n+    Row next();   // Get the next row\n+    void close(); // Close the operator and release all resources\n+}\n+```\n+\n+## Volcano Model in Hazelcast Mustang\n+\n+The original Volcano Model has two drawbacks:\n+1. Operators exchange one row at a time, which leads to performance overhead\n+2. Call to the `next()` is blocking, which is not optimal for the distributed environment, where\n+operators often wait for remote data or free space in the send buffer.\n+\n+To achieve high performance, we introduce several changes to the original Volcano Model: batching and\n+non-blocking execution.\n+\n+### Row and RowBatch\n+We define the `RowBatch` interface which a collection of rows (tuples).\n+\n+*Snippet 5: RowBatch interface*\n+```java\n+interface RowBatch {\n+    Row getRow(int index); // Get the row by index\n+    int getRowCount();     // Get the number of rows \n+} \n+```\n+\n+Then we define the `Row` interface, which provides access to values by index. The `Row` itself is considered\n+as a special case of `RowBatch` with one row. This allows saving on allocations in some parts of the engine.\n+\n+*Snippet 6: Row interface*\n+```java\n+interface Row extends RowBatch {\n+    Object get(int index); // Get the value by index\n+    int getColumnCount();  // Get the number of values in the row \n+    \n+    default int getRowCount() {\n+        return 1;\n+    }\n+    \n+    default Row getRow(int index) {\n+        return this;\n+    }\n+}\n+```\n+\n+### Operator\n+The operator is defined by `Exec` interface:\n+1. Operators exchange `RowBatch` instead of `Row`\n+1. The blocking `next()` method is replaced with the non-blocking `advance()` method, which returns the iteration\n+result instead of the row batch\n+1. The `RowBatch` could be accessed through a separate method\n+1. The `open()` method is renamed to `setup()`. Special query context is passed to it as an argument\n+1. There is no separate `close()` method because the engine doesn't need explicit per-operator cleanup at the\n+moment. This may change in future, in this case the current document should be updated accordingly\n+\n+*Snippet 7: Executable operator interface*\n+```java\n+interface Exec {\n+    void setup(QueryContext context); // Initialize the operator\n+    IterationResult advance();        // Advance the operator if possible; never blocks\n+    RowBatch currentBatch();          // Get the batch returned by the previous advance() call ", "originalCommit": "f91e6967d4faa6c3ff5d25e121d60236bf1acf8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0OTIxNw==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394849217", "bodyText": "This will require adding some additional state to the RowBatch, that is not concerned with the batch itself, but with the operator which produced it. I would avoid mixing the concepts.", "author": "devozerov", "createdAt": "2020-03-19T08:08:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgzNjk2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg2NTEyMw==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394865123", "bodyText": "This will require adding some additional state to the RowBatch\n\nNot really:\nfinal class SignalingRowBatch implements RowBatch {\n\n    public static final RowBatch FETCHED = new SignalingRowBatch();\n    public static final RowBatch FETCHED_DONE = new SignalingRowBatch();\n    public static final RowBatch WAIT = new SignalingRowBatch();\n\n    private SignalingRowBatch() {\n    }\n\n    ...\n\n}", "author": "taburet", "createdAt": "2020-03-19T08:40:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgzNjk2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg2Nzk0Mg==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394867942", "bodyText": "How do you support multiple batch implementations in this case (List-based, byte-array-based, single row, etc)?\nAnother question - how to transfer the data? In the provided code snippet the batches are empty.", "author": "devozerov", "createdAt": "2020-03-19T08:45:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgzNjk2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg3MTQ3Mg==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394871472", "bodyText": "One more thing here - all operators produce iteration results (FETCHED, WAIT, etc.), but not all operators produce batches. Specifically, top terminal operators, root and senders, never produce batches. They only signal the execution environment whether they made any progress and whether they finished.", "author": "devozerov", "createdAt": "2020-03-19T08:52:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgzNjk2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDkxNzgyOA==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394917828", "bodyText": "Ah, I see, FETCHED and FETCHED_DONE are actually providing the data, not just the signaling :)", "author": "taburet", "createdAt": "2020-03-19T10:12:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgzNjk2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgzOTgyNA==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394839824", "bodyText": "If it's a no-op method, we can make it abstract.", "author": "taburet", "createdAt": "2020-03-19T07:45:40Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/AbstractExec.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.exec;\n+\n+import com.hazelcast.sql.impl.fragment.QueryFragmentContext;\n+import com.hazelcast.sql.impl.row.EmptyRowBatch;\n+import com.hazelcast.sql.impl.row.RowBatch;\n+\n+/**\n+ * Abstract executor.\n+ */\n+public abstract class AbstractExec implements Exec {\n+\n+    protected QueryFragmentContext ctx;\n+    private final int id;\n+\n+    protected AbstractExec(int id) {\n+        this.id = id;\n+    }\n+\n+    @Override\n+    public int getId() {\n+        return id;\n+    }\n+\n+    @Override\n+    public final void setup(QueryFragmentContext ctx) {\n+        this.ctx = ctx;\n+\n+        setup0(ctx);\n+    }\n+\n+    @Override\n+    public final IterationResult advance() {\n+        return advance0();\n+    }\n+\n+    @Override\n+    public final RowBatch currentBatch() {\n+        RowBatch res = currentBatch0();\n+\n+        return res != null ? res : EmptyRowBatch.INSTANCE;\n+    }\n+\n+    protected void setup0(QueryFragmentContext ctx) {\n+        // No-op.", "originalCommit": "f91e6967d4faa6c3ff5d25e121d60236bf1acf8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0OTkxMA==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394849910", "bodyText": "I made it non-absrtact, because some operators do not require setup. So instead of having multiple no-op implementations in operators, we have only one.", "author": "devozerov", "createdAt": "2020-03-19T08:09:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDgzOTgyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0MDY2Nw==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394840667", "bodyText": "abstract?", "author": "taburet", "createdAt": "2020-03-19T07:47:47Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/AbstractUpstreamAwareExec.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.exec;\n+\n+import com.hazelcast.sql.impl.fragment.QueryFragmentContext;\n+\n+/**\n+ * Executor which has an upstream executor and hence delegate to it at some stages.\n+ */\n+public abstract class AbstractUpstreamAwareExec extends AbstractExec {\n+    /** Upstream state. */\n+    protected final UpstreamState state;\n+\n+    /**\n+     * Constructor.\n+     *\n+     * @param upstream Upstream stage.\n+     */\n+    protected AbstractUpstreamAwareExec(int id, Exec upstream) {\n+        super(id);\n+\n+        state = new UpstreamState(upstream);\n+    }\n+\n+    @Override\n+    protected final void setup0(QueryFragmentContext ctx) {\n+        state.setup(ctx);\n+\n+        setup1(ctx);\n+    }\n+\n+    protected void setup1(QueryFragmentContext ctx) {", "originalCommit": "f91e6967d4faa6c3ff5d25e121d60236bf1acf8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg1MzQ4MQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394853481", "bodyText": "Same motivation as in the comment above.", "author": "devozerov", "createdAt": "2020-03-19T08:16:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0MDY2Nw=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0MzE0OQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394843149", "bodyText": "Some note on the uniqueness scope of this ID would be helpful. Is it globally unique or only in the scope of a single query/fragment? Does it stay the same between executions of the same query or valid only for a single execution?", "author": "taburet", "createdAt": "2020-03-19T07:53:42Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/Exec.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.exec;\n+\n+import com.hazelcast.sql.impl.fragment.QueryFragmentContext;\n+import com.hazelcast.sql.impl.row.RowBatch;\n+\n+/**\n+ * Basic execution stage.\n+ */\n+public interface Exec {\n+    /**\n+     * @return ID of the executor.\n+     */\n+    int getId();", "originalCommit": "f91e6967d4faa6c3ff5d25e121d60236bf1acf8a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg1MjcyMg==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r394852722", "bodyText": "Added the JavaDoc. It is unique within the query operator tree. It doesn't stay between executions, because the scope of the Exec instance is only single query execution.", "author": "devozerov", "createdAt": "2020-03-19T08:15:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDg0MzE0OQ=="}], "type": "inlineReview"}, {"oid": "af4db772903af79ecfcbd98e05715da11164bc23", "url": "https://github.com/hazelcast/hazelcast/commit/af4db772903af79ecfcbd98e05715da11164bc23", "message": "JavaDoc for getId().", "committedDate": "2020-03-19T08:14:05Z", "type": "commit"}, {"oid": "06a7500c607ccf2b00e8dc985279942c99a4ce6a", "url": "https://github.com/hazelcast/hazelcast/commit/06a7500c607ccf2b00e8dc985279942c99a4ce6a", "message": "Merge branch 'master' into issues/16762", "committedDate": "2020-03-19T17:26:03Z", "type": "commit"}, {"oid": "c6b64606a093f8a60b70f126449097f3d9989aaa", "url": "https://github.com/hazelcast/hazelcast/commit/c6b64606a093f8a60b70f126449097f3d9989aaa", "message": "Fixed spotbugs.", "committedDate": "2020-03-19T17:36:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcyNTQ2NA==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397725464", "bodyText": "which is a ..?", "author": "petrpleshachkov", "createdAt": "2020-03-25T09:48:47Z", "path": "docs/design/sql/02-operator-interface.md", "diffHunk": "@@ -0,0 +1,163 @@\n+# SQL Operator Interface\n+\n+## Overview\n+In databases, SQL queries are typically represented in a form of operator tree, called **Volcano Model**,\n+introduced in Goetz Graefe seminal paper [[1]].\n+\n+In this document, we describe the design of the Hazelcast Mustang operator interface, which is based\n+on the Volcano Model.\n+\n+## Relational Operators\n+An SQL query is first parsed into a **parse tree**, which is used for syntactic and semantic checking.\n+\n+The parse tree is then converted into **relational operator tree**, or simply **relational tree**,\n+for optimization. The relational tree is more convenient because its structure is simpler than the\n+structure of the parse tree.\n+\n+A **query plan**, consisting of a relational tree and supplemental information, is submitted for execution\n+after the optimization.\n+\n+The table below lists common relational operators used in database engines.\n+\n+*Table 1: Common Relational Operators*\n+\n+| Name | Description |\n+|---|---|\n+| `Scan` | Iterate over source rows |\n+| `Project` | Return a set of original or derived attributes of the child operator |\n+| `Filter` | Return rows of the child operator which pass the provided predicate |\n+| `Aggregate` | Aggregate rows of the child operator |\n+| `Sort` | Sort rows of the child operator |\n+| `Join` | Join rows from several child operators |\n+\n+An example of a query, its parse tree, and its relational tree is provided below.\n+\n+*Snippet 1: Query*\n+```sql\n+SELECT a, SUM(b)\n+FROM table\n+GROUP BY a\n+HAVING SUM(b) > 50\n+```\n+*Snippet 2: Parse Tree*\n+```\n+-- Select\n+---- SelectList [a, SUM(b)]\n+---- From [table]\n+---- GroupBy [a]\n+---- Having [SUM(b) > 50]\n+```\n+*Snippet 3: Relational Tree*\n+```\n+-- Filter [SUM(b) > 50]\n+---- Aggregate [a -> SUM(b)]\n+------ Project [a, b]\n+-------- Scan [table]\n+```\n+\n+## Volcano Model\n+\n+Volcano Model defines the common data exchange interface between operators in the relational tree. This allows\n+for extensibility, as new operators could be implemented with minimal changes to the engine.\n+\n+In the original paper the interface consists of three operations:\n+\n+*Snippet 4: Volcano Interface*\n+```java\n+interface Operator {\n+    void open();  // Initialize the operator\n+    Row next();   // Get the next row\n+    void close(); // Close the operator and release all resources\n+}\n+```\n+\n+## Volcano Model in Hazelcast Mustang\n+\n+The original Volcano Model has two drawbacks:\n+1. Operators exchange one row at a time, which leads to performance overhead\n+2. Call to the `next()` is blocking, which is not optimal for the distributed environment, where\n+operators often wait for remote data or free space in the send buffer.\n+\n+To achieve high performance, we introduce several changes to the original Volcano Model: batching and\n+non-blocking execution.\n+\n+### Row and RowBatch\n+We define the `RowBatch` interface which a collection of rows (tuples).", "originalCommit": "c6b64606a093f8a60b70f126449097f3d9989aaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc2MTEwNQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397761105", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-03-25T10:47:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzcyNTQ2NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzczMzA0Ng==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397733046", "bodyText": "Why would we create new UUID object on every method call? It seems better to create the object once.", "author": "petrpleshachkov", "createdAt": "2020-03-25T10:01:10Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/QueryId.java", "diffHunk": "@@ -0,0 +1,136 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl;\n+\n+import com.hazelcast.internal.util.UuidUtil;\n+import com.hazelcast.nio.ObjectDataInput;\n+import com.hazelcast.nio.ObjectDataOutput;\n+import com.hazelcast.nio.serialization.IdentifiedDataSerializable;\n+\n+import java.io.IOException;\n+import java.util.UUID;\n+\n+/**\n+ * Cluster-wide unique query ID.\n+ */\n+public final class QueryId implements IdentifiedDataSerializable {\n+    /** Member ID: most significant bits */\n+    private long memberIdHigh;\n+\n+    /** Member ID: least significant bits. */\n+    private long memberIdLow;\n+\n+    /** Local ID: most significant bits. */\n+    private long localHigh;\n+\n+    /** Local ID: least significant bits. */\n+    private long localLow;\n+\n+    public QueryId() {\n+        // No-op.\n+    }\n+\n+    QueryId(long memberIdHigh, long memberIdLow, long localHigh, long localLow) {\n+        this.memberIdHigh = memberIdHigh;\n+        this.memberIdLow = memberIdLow;\n+        this.localHigh = localHigh;\n+        this.localLow = localLow;\n+    }\n+\n+    /**\n+     * Create new query ID for the given member.\n+     *\n+     * @param memberId Member ID.\n+     * @return Query ID.\n+     */\n+    public static QueryId create(UUID memberId) {\n+        UUID qryId = UuidUtil.newUnsecureUUID();\n+\n+        return new QueryId(\n+            memberId.getMostSignificantBits(),\n+            memberId.getLeastSignificantBits(),\n+            qryId.getMostSignificantBits(),\n+            qryId.getLeastSignificantBits()\n+        );\n+    }\n+\n+    public UUID getMemberId() {\n+        return new UUID(memberIdHigh, memberIdLow);", "originalCommit": "c6b64606a093f8a60b70f126449097f3d9989aaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc2Mjg1NQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397762855", "bodyText": "This method is not used on the hot code paths, mostly in periodic query state checks. So produced garbage should have little to no impact. On the other hand, this saves a little heap space.\nSo, basically, both approaches - with UUID instance inside the class, or with UUID instance created lazily - are minor micro-optimizations, with no significant side effects.", "author": "devozerov", "createdAt": "2020-03-25T10:50:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzczMzA0Ng=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzczOTUyNA==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397739524", "bodyText": "True -> true?", "author": "petrpleshachkov", "createdAt": "2020-03-25T10:11:45Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/UpstreamState.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.exec;\n+\n+import com.hazelcast.sql.HazelcastSqlException;\n+import com.hazelcast.sql.impl.fragment.QueryFragmentContext;\n+import com.hazelcast.sql.impl.row.EmptyRowBatch;\n+import com.hazelcast.sql.impl.row.Row;\n+import com.hazelcast.sql.impl.row.RowBatch;\n+\n+import java.util.Iterator;\n+\n+import static com.hazelcast.sql.impl.exec.IterationResult.FETCHED_DONE;\n+import static com.hazelcast.sql.impl.exec.IterationResult.WAIT;\n+\n+/**\n+ * Upstream state.\n+ */\n+public class UpstreamState implements Iterable<Row> {\n+    /** Upstream operator. */\n+    private final Exec upstream;\n+\n+    /** Iterator over the current batch. */\n+    private final UpstreamIterator iter;\n+\n+    /** Current batch returned from the upstream. */\n+    private RowBatch currentBatch = EmptyRowBatch.INSTANCE;\n+\n+    /** Current position. */\n+    private int currentBatchPos;\n+\n+    /** Last returned state. */\n+    private IterationResult state;\n+\n+    public UpstreamState(Exec upstream) {\n+        this.upstream = upstream;\n+\n+        iter = new UpstreamIterator();\n+    }\n+\n+    /**\n+     * Try advancing the upstream.\n+     *\n+     * @return {@code True} if the caller may try iteration over results; {@code false} if the caller should give", "originalCommit": "c6b64606a093f8a60b70f126449097f3d9989aaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc2MTA2MA==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397761060", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-03-25T10:47:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzczOTUyNA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc0Mzc0NA==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397743744", "bodyText": "True -> true?", "author": "petrpleshachkov", "createdAt": "2020-03-25T10:18:44Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/UpstreamState.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.exec;\n+\n+import com.hazelcast.sql.HazelcastSqlException;\n+import com.hazelcast.sql.impl.fragment.QueryFragmentContext;\n+import com.hazelcast.sql.impl.row.EmptyRowBatch;\n+import com.hazelcast.sql.impl.row.Row;\n+import com.hazelcast.sql.impl.row.RowBatch;\n+\n+import java.util.Iterator;\n+\n+import static com.hazelcast.sql.impl.exec.IterationResult.FETCHED_DONE;\n+import static com.hazelcast.sql.impl.exec.IterationResult.WAIT;\n+\n+/**\n+ * Upstream state.\n+ */\n+public class UpstreamState implements Iterable<Row> {\n+    /** Upstream operator. */\n+    private final Exec upstream;\n+\n+    /** Iterator over the current batch. */\n+    private final UpstreamIterator iter;\n+\n+    /** Current batch returned from the upstream. */\n+    private RowBatch currentBatch = EmptyRowBatch.INSTANCE;\n+\n+    /** Current position. */\n+    private int currentBatchPos;\n+\n+    /** Last returned state. */\n+    private IterationResult state;\n+\n+    public UpstreamState(Exec upstream) {\n+        this.upstream = upstream;\n+\n+        iter = new UpstreamIterator();\n+    }\n+\n+    /**\n+     * Try advancing the upstream.\n+     *\n+     * @return {@code True} if the caller may try iteration over results; {@code false} if the caller should give\n+     * up execution and wait.\n+     */\n+    public boolean advance() {\n+        // If some data is available still, do not do anything, just return the previous result.\n+        if (currentBatchPos < currentBatch.getRowCount()) {\n+            return true;\n+        }\n+\n+        // If the upstream is exhausted, just return \"done\" flag.\n+        if (state == FETCHED_DONE) {\n+            return true;\n+        }\n+\n+        // Otherwise poll the upstream.\n+        state = upstream.advance();\n+\n+        switch (state) {\n+            case FETCHED_DONE:\n+            case FETCHED:\n+                currentBatch = upstream.currentBatch();\n+                assert currentBatch != null;\n+\n+                currentBatchPos = 0;\n+\n+                return true;\n+\n+            default:\n+                assert state == WAIT;\n+\n+                currentBatch = EmptyRowBatch.INSTANCE;\n+                currentBatchPos = 0;\n+\n+                return false;\n+        }\n+    }\n+\n+    public void setup(QueryFragmentContext ctx) {\n+        upstream.setup(ctx);\n+    }\n+\n+    public RowBatch consumeBatch() {\n+        if (currentBatchPos != 0) {\n+            throw HazelcastSqlException.error(\"Batch can be consumed only as a whole: \" + upstream);\n+        }\n+\n+        RowBatch batch = currentBatch;\n+\n+        currentBatchPos = batch.getRowCount();\n+\n+        return batch;\n+    }\n+\n+    /**\n+     * @return {@code True} if no more results will appear in future.", "originalCommit": "c6b64606a093f8a60b70f126449097f3d9989aaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc2MTAyOA==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397761028", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-03-25T10:47:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc0Mzc0NA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc0NjYyNg==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397746626", "bodyText": "Why not to use standard hasNext()/next() methods semantics from Iterator instead of introducing isDone/nextIfExists?", "author": "petrpleshachkov", "createdAt": "2020-03-25T10:23:34Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/exec/UpstreamState.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.exec;\n+\n+import com.hazelcast.sql.HazelcastSqlException;\n+import com.hazelcast.sql.impl.fragment.QueryFragmentContext;\n+import com.hazelcast.sql.impl.row.EmptyRowBatch;\n+import com.hazelcast.sql.impl.row.Row;\n+import com.hazelcast.sql.impl.row.RowBatch;\n+\n+import java.util.Iterator;\n+\n+import static com.hazelcast.sql.impl.exec.IterationResult.FETCHED_DONE;\n+import static com.hazelcast.sql.impl.exec.IterationResult.WAIT;\n+\n+/**\n+ * Upstream state.\n+ */\n+public class UpstreamState implements Iterable<Row> {\n+    /** Upstream operator. */\n+    private final Exec upstream;\n+\n+    /** Iterator over the current batch. */\n+    private final UpstreamIterator iter;\n+\n+    /** Current batch returned from the upstream. */\n+    private RowBatch currentBatch = EmptyRowBatch.INSTANCE;\n+\n+    /** Current position. */\n+    private int currentBatchPos;\n+\n+    /** Last returned state. */\n+    private IterationResult state;\n+\n+    public UpstreamState(Exec upstream) {\n+        this.upstream = upstream;\n+\n+        iter = new UpstreamIterator();\n+    }\n+\n+    /**\n+     * Try advancing the upstream.\n+     *\n+     * @return {@code True} if the caller may try iteration over results; {@code false} if the caller should give\n+     * up execution and wait.\n+     */\n+    public boolean advance() {\n+        // If some data is available still, do not do anything, just return the previous result.\n+        if (currentBatchPos < currentBatch.getRowCount()) {\n+            return true;\n+        }\n+\n+        // If the upstream is exhausted, just return \"done\" flag.\n+        if (state == FETCHED_DONE) {\n+            return true;\n+        }\n+\n+        // Otherwise poll the upstream.\n+        state = upstream.advance();\n+\n+        switch (state) {\n+            case FETCHED_DONE:\n+            case FETCHED:\n+                currentBatch = upstream.currentBatch();\n+                assert currentBatch != null;\n+\n+                currentBatchPos = 0;\n+\n+                return true;\n+\n+            default:\n+                assert state == WAIT;\n+\n+                currentBatch = EmptyRowBatch.INSTANCE;\n+                currentBatchPos = 0;\n+\n+                return false;\n+        }\n+    }\n+\n+    public void setup(QueryFragmentContext ctx) {\n+        upstream.setup(ctx);\n+    }\n+\n+    public RowBatch consumeBatch() {\n+        if (currentBatchPos != 0) {\n+            throw HazelcastSqlException.error(\"Batch can be consumed only as a whole: \" + upstream);\n+        }\n+\n+        RowBatch batch = currentBatch;\n+\n+        currentBatchPos = batch.getRowCount();\n+\n+        return batch;\n+    }\n+\n+    /**\n+     * @return {@code True} if no more results will appear in future.\n+     */\n+    public boolean isDone() {\n+        return state == FETCHED_DONE && !iter.hasNext();\n+    }\n+\n+    @SuppressWarnings(\"NullableProblems\")\n+    @Override\n+    public Iterator<Row> iterator() {\n+        return iter;\n+    }\n+\n+    /**\n+     * Return next row in the current batch if it exists.\n+     *\n+     * @return Next row or {@code null}.\n+     */\n+    public Row nextIfExists() {", "originalCommit": "c6b64606a093f8a60b70f126449097f3d9989aaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc2MDYxMg==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397760612", "bodyText": "This is just a convenient shortcut for iterator hasNext/next. You may see usages of it in the prototype branch.", "author": "devozerov", "createdAt": "2020-03-25T10:46:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc0NjYyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc2MjMyOQ==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397762329", "bodyText": "OK, but why would you introduce new names?", "author": "petrpleshachkov", "createdAt": "2020-03-25T10:49:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc0NjYyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc2MzU3OA==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397763578", "bodyText": "Because it has different semantics - it doesn't throw an exception if there is no row.", "author": "devozerov", "createdAt": "2020-03-25T10:52:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc0NjYyNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc3MDU0Nw==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397770547", "bodyText": "I guess, you have isDone() to avoid calling this method when there is no new Row to consume. Anyway, it is a matter of taste.", "author": "petrpleshachkov", "createdAt": "2020-03-25T11:04:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc0NjYyNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc0ODU2Mg==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397748562", "bodyText": "index < arguments.size() ?", "author": "petrpleshachkov", "createdAt": "2020-03-25T10:26:38Z", "path": "hazelcast/src/main/java/com/hazelcast/sql/impl/fragment/QueryFragmentContext.java", "diffHunk": "@@ -0,0 +1,39 @@\n+/*\n+ * Copyright (c) 2008-2020, Hazelcast, Inc. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package com.hazelcast.sql.impl.fragment;\n+\n+import java.util.List;\n+\n+/**\n+ * Context of a running query fragment.\n+ */\n+public class QueryFragmentContext {\n+\n+    private final List<Object> arguments;\n+\n+    public QueryFragmentContext(List<Object> arguments) {\n+        assert arguments != null;\n+\n+        this.arguments = arguments;\n+    }\n+\n+    public Object getArgument(int index) {\n+        assert index >= 0 && index <= arguments.size();", "originalCommit": "c6b64606a093f8a60b70f126449097f3d9989aaa", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc2MDkzNg==", "url": "https://github.com/hazelcast/hazelcast/pull/16763#discussion_r397760936", "bodyText": "Fixed.", "author": "devozerov", "createdAt": "2020-03-25T10:47:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzc0ODU2Mg=="}], "type": "inlineReview"}, {"oid": "89462eec84fb4d480b86d004827056cba8290963", "url": "https://github.com/hazelcast/hazelcast/commit/89462eec84fb4d480b86d004827056cba8290963", "message": "Review fixes.", "committedDate": "2020-03-25T10:47:24Z", "type": "commit"}]}