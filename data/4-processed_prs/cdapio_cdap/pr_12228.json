{"pr_number": 12228, "pr_title": "CDAP-16709 implemented auto-join for spark streaming", "pr_createdAt": "2020-05-29T18:01:31Z", "pr_url": "https://github.com/cdapio/cdap/pull/12228", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY5MDkwNg==", "url": "https://github.com/cdapio/cdap/pull/12228#discussion_r432690906", "bodyText": "Any reason we changed this? Since AutoJoin only supports StructuredRecord, it is cleaner to just keep it here to avoid the unnecessary type cast changes in the class", "author": "yaojiefeng", "createdAt": "2020-05-29T19:29:24Z", "path": "cdap-app-templates/cdap-etl/cdap-etl-core/src/main/java/io/cdap/cdap/etl/common/plugin/JoinerBridge.java", "diffHunk": "@@ -38,8 +38,10 @@\n \n /**\n  * An implementation of {@link BatchJoiner} using a {@link BatchAutoJoiner}.\n+ *\n+ * @param <INPUT_RECORD> type of input record\n  */\n-public class JoinerBridge extends BatchJoiner<StructuredRecord, StructuredRecord, StructuredRecord> {\n+public class JoinerBridge<INPUT_RECORD> extends BatchJoiner<StructuredRecord, INPUT_RECORD, StructuredRecord> {", "originalCommit": "4d363e78eb0372e797cd8a28e4850183ef142819", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc0NDMyNA==", "url": "https://github.com/cdapio/cdap/pull/12228#discussion_r432744324", "bodyText": "had to change this due to the generics in JoinOn and JoinMerge transforms. It shouldn't functionally change anything.\nIdeally we would remove the generics from most of our plugin APIs and standardize on StructuredRecord, but that would be a backwards incompatible change.", "author": "albertshau", "createdAt": "2020-05-29T21:30:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY5MDkwNg=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY5MTE0NQ==", "url": "https://github.com/cdapio/cdap/pull/12228#discussion_r432691145", "bodyText": "nit - extra line", "author": "yaojiefeng", "createdAt": "2020-05-29T19:29:58Z", "path": "cdap-app-templates/cdap-etl/hydrator-spark-core-base/src/main/java/io/cdap/cdap/etl/spark/SparkPipelineRunner.java", "diffHunk": "@@ -359,6 +332,39 @@ public void runPipeline(PipelinePhase pipelinePhase, String sourcePluginType,\n     }\n   }\n \n+  protected SparkCollection<Object> handleJoin(Map<String, SparkCollection<Object>> inputDataCollections,\n+                                               PipelinePhase pipelinePhase, PluginFunctionContext pluginFunctionContext,\n+                                               StageSpec stageSpec, Object plugin, Integer numPartitions,\n+                                               StageStatisticsCollector collector) throws Exception {\n+    String stageName = stageSpec.getName();\n+    if (plugin instanceof BatchJoiner) {\n+      BatchJoiner<Object, Object, Object> joiner = (BatchJoiner<Object, Object, Object>) plugin;\n+      BatchJoinerRuntimeContext joinerRuntimeContext = pluginFunctionContext.createBatchRuntimeContext();\n+      joiner.initialize(joinerRuntimeContext);\n+\n+      return handleJoin(joiner, inputDataCollections, stageSpec, numPartitions, collector).cache();\n+    } else if (plugin instanceof AutoJoiner) {\n+", "originalCommit": "4d363e78eb0372e797cd8a28e4850183ef142819", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY5MTUwOA==", "url": "https://github.com/cdapio/cdap/pull/12228#discussion_r432691508", "bodyText": "Do we need the check here? I remember we have some earlier validation before we get here", "author": "yaojiefeng", "createdAt": "2020-05-29T19:30:46Z", "path": "cdap-app-templates/cdap-etl/cdap-data-streams/src/main/java/io/cdap/cdap/datastreams/SparkStreamingPipelineRunner.java", "diffHunk": "@@ -123,4 +135,43 @@ public SparkStreamingPipelineRunner(JavaSparkExecutionContext sec, JavaStreaming\n     JavaDStream<Object> result = pairDStream.transform(new DynamicJoinMerge<>(dynamicDriverContext));\n     return new DStreamCollection<>(sec, result);\n   }\n+\n+  @Override\n+  protected SparkCollection<Object> handleJoin(Map<String, SparkCollection<Object>> inputDataCollections,\n+                                               PipelinePhase pipelinePhase, PluginFunctionContext pluginFunctionContext,\n+                                               StageSpec stageSpec, Object plugin, Integer numPartitions,\n+                                               StageStatisticsCollector collector) throws Exception {\n+    String stageName = stageSpec.getName();\n+    BatchJoiner<?, ?, ?> joiner;\n+    if (plugin instanceof BatchAutoJoiner) {\n+      BatchAutoJoiner autoJoiner = (BatchAutoJoiner) plugin;\n+\n+      Map<String, JoinStage> inputStages = new HashMap<>();\n+      for (String inputStageName : pipelinePhase.getStageInputs(stageName)) {\n+        StageSpec inputStageSpec = pipelinePhase.getStage(inputStageName);\n+        inputStages.put(inputStageName,\n+                        JoinStage.builder(inputStageName, inputStageSpec.getOutputSchema()).build());\n+      }\n+      AutoJoinerContext autoJoinerContext = new DefaultAutoJoinerContext(inputStages);\n+\n+      JoinDefinition joinDefinition = autoJoiner.define(autoJoinerContext);\n+      if (joinDefinition == null) {", "originalCommit": "4d363e78eb0372e797cd8a28e4850183ef142819", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc0MzgzMw==", "url": "https://github.com/cdapio/cdap/pull/12228#discussion_r432743833", "bodyText": "it is checked at prepare time for batch runs, but that part is not run for streaming pipelines.", "author": "albertshau", "createdAt": "2020-05-29T21:28:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY5MTUwOA=="}], "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY5MTk1MQ==", "url": "https://github.com/cdapio/cdap/pull/12228#discussion_r432691951", "bodyText": "Have seen this logic in multiple places, do you think it is possible to have an utility class for this logic?", "author": "yaojiefeng", "createdAt": "2020-05-29T19:31:51Z", "path": "cdap-app-templates/cdap-etl/hydrator-spark-core-base/src/main/java/io/cdap/cdap/etl/spark/function/JoinMergeFunction.java", "diffHunk": "@@ -64,6 +66,28 @@ public JoinMergeFunction(PluginFunctionContext pluginFunctionContext) {\n     return emitter.getEntries();\n   }\n \n+  private <K, V, O> BatchJoiner<K, V, O> createInitializedJoiner() throws Exception {\n+    Object plugin = pluginFunctionContext.createPlugin();", "originalCommit": "4d363e78eb0372e797cd8a28e4850183ef142819", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjc0NDY1MQ==", "url": "https://github.com/cdapio/cdap/pull/12228#discussion_r432744651", "bodyText": "it's slightly different in each place unfortunately. for example, some places it looks at the join condition in order to figure out if certain keys need to be filtered out.", "author": "albertshau", "createdAt": "2020-05-29T21:31:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjY5MTk1MQ=="}], "type": "inlineReview"}, {"oid": "497ac3623dc87f25716970cb495dcc1d926ad2b9", "url": "https://github.com/cdapio/cdap/commit/497ac3623dc87f25716970cb495dcc1d926ad2b9", "message": "CDAP-16709 implemented auto-join for spark streaming\n\nImplemented auto-join for spark streaming by using the same\nJoinerBridge that is used for MapReduce. This means auto-joins\nin streaming pipelines will have the same characteristics as normal\njoins, meaning they will be executed as shuffle hash joins.\n\nThis is probably ok, as only data within the micro batch is being\njoined, which means it shouldn't be too likely to go OOM assuming\nthere is enough executor memory.", "committedDate": "2020-05-29T22:56:43Z", "type": "commit"}, {"oid": "497ac3623dc87f25716970cb495dcc1d926ad2b9", "url": "https://github.com/cdapio/cdap/commit/497ac3623dc87f25716970cb495dcc1d926ad2b9", "message": "CDAP-16709 implemented auto-join for spark streaming\n\nImplemented auto-join for spark streaming by using the same\nJoinerBridge that is used for MapReduce. This means auto-joins\nin streaming pipelines will have the same characteristics as normal\njoins, meaning they will be executed as shuffle hash joins.\n\nThis is probably ok, as only data within the micro batch is being\njoined, which means it shouldn't be too likely to go OOM assuming\nthere is enough executor memory.", "committedDate": "2020-05-29T22:56:43Z", "type": "forcePushed"}]}