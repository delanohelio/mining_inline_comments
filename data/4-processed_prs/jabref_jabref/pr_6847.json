{"pr_number": 6847, "pr_title": "Feature/use unkown fields as default fields", "pr_createdAt": "2020-09-02T15:34:28Z", "pr_url": "https://github.com/JabRef/jabref/pull/6847", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTczMDM0Nw==", "url": "https://github.com/JabRef/jabref/pull/6847#discussion_r491730347", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        LOGGER.debug(\"Could not write result to file.\", e);\n          \n          \n            \n                        LOGGER.error(\"Could not write result to file.\", e);", "author": "koppor", "createdAt": "2020-09-20T20:22:44Z", "path": "src/main/java/org/jabref/logic/crawler/StudyRepository.java", "diffHunk": "@@ -0,0 +1,270 @@\n+package org.jabref.logic.crawler;\n+\n+import java.io.FileWriter;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.Writer;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.LocalDate;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Optional;\n+\n+import org.jabref.logic.database.DatabaseMerger;\n+import org.jabref.logic.exporter.BibtexDatabaseWriter;\n+import org.jabref.logic.exporter.SavePreferences;\n+import org.jabref.logic.importer.ImportFormatPreferences;\n+import org.jabref.logic.importer.ParseException;\n+import org.jabref.logic.importer.SearchBasedFetcher;\n+import org.jabref.logic.importer.fileformat.BibtexParser;\n+import org.jabref.model.database.BibDatabase;\n+import org.jabref.model.database.BibDatabaseContext;\n+import org.jabref.model.entry.BibEntry;\n+import org.jabref.model.entry.BibEntryTypesManager;\n+import org.jabref.model.entry.field.UnknownField;\n+import org.jabref.model.study.FetchResult;\n+import org.jabref.model.study.QueryResult;\n+import org.jabref.model.study.Study;\n+import org.jabref.model.util.FileUpdateMonitor;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class manages all aspects of the study process related to the file system.\n+ *\n+ * It Includes the parsing of the study.bib file into the instance of the Study class,\n+ * the structured persistence of the crawling results for the study, as well as the sharing of results by using git.\n+ */\n+class StudyRepository {\n+    // Tests work with study.bib\n+    private static final String STUDY_DEFINITION_FILE_NAME = \"study.bib\";\n+    private static final Logger LOGGER = LoggerFactory.getLogger(StudyRepository.class);\n+\n+    private final Path repositoryPath;\n+    private final Path studyDefinitionBib;\n+    private final Study study;\n+    private final ImportFormatPreferences importFormatPreferences;\n+    private final FileUpdateMonitor fileUpdateMonitor;\n+    private final SavePreferences savePreferences;\n+    private final BibEntryTypesManager bibEntryTypesManager;\n+\n+    /**\n+     * Creates a study repository.\n+     *\n+     * @param pathToRepository Where the repository root is located.\n+     * @throws IllegalArgumentException If the repository root directory does not exist, or the root directory does not contain the study definition file.\n+     * @throws IOException              Problem opening the input stream.\n+     * @throws ParseException           Problem parsing the studyBib file.\n+     */\n+    public StudyRepository(Path pathToRepository, ImportFormatPreferences importFormatPreferences, FileUpdateMonitor fileUpdateMonitor, SavePreferences savePreferences, BibEntryTypesManager bibEntryTypesManager) throws IOException, ParseException {\n+        this.repositoryPath = pathToRepository;\n+        this.importFormatPreferences = importFormatPreferences;\n+        this.fileUpdateMonitor = fileUpdateMonitor;\n+        this.studyDefinitionBib = Paths.get(repositoryPath.toString(), STUDY_DEFINITION_FILE_NAME);\n+        this.savePreferences = savePreferences;\n+        this.bibEntryTypesManager = bibEntryTypesManager;\n+\n+        if (Files.notExists(repositoryPath)) {\n+            throw new IOException(\"The given Repository does not exists.\");\n+        } else if (Files.notExists(studyDefinitionBib)) {\n+            throw new IOException(\"The study definition file does not exist in the given Repository.\");\n+        }\n+        study = parseStudyFile();\n+        this.setUpRepositoryStructure();\n+    }\n+\n+    /**\n+     * Returns entries stored in the repository for a certain query and fetcher\n+     */\n+    public List<BibEntry> getResultEntries(String query, String fetcherName) throws IOException {\n+        return parseBibFile(getPathToResultFile(query, fetcherName));\n+    }\n+\n+    /**\n+     * Returns the merged entries stored in the repository for a certain query\n+     */\n+    public List<BibEntry> getMergedResultEntries(String query) throws IOException {\n+        return parseBibFile(getPathToMergedResultFile(query));\n+    }\n+\n+    /**\n+     * The studyBib file contains all the definitions of a study. This method extracts the BibEntries from the study BiB file.\n+     *\n+     * @return Returns the BibEntries parsed from the studyBib file.\n+     * @throws IOException    Problem opening the input stream.\n+     * @throws ParseException Problem parsing the studyBib file.\n+     */\n+    private Study parseStudyFile() throws IOException, ParseException {\n+        BibtexParser parser = new BibtexParser(importFormatPreferences, fileUpdateMonitor);\n+        List<BibEntry> parsedEntries = new ArrayList<>();\n+        try (InputStream inputStream = Files.newInputStream(studyDefinitionBib)) {\n+            parsedEntries.addAll(parser.parseEntries(inputStream));\n+        }\n+        return new Study(parsedEntries);\n+    }\n+\n+    public Study getStudy() {\n+        return study;\n+    }\n+\n+    public void persist(List<QueryResult> crawlResults) throws IOException {\n+        persistResults(crawlResults, savePreferences, bibEntryTypesManager);\n+        study.setLastSearchDate(LocalDate.now());\n+        persistStudy();\n+    }\n+\n+    private void persistStudy() {\n+        writeResultToFile(studyDefinitionBib, new BibDatabase(study.getDefinitions()));\n+    }\n+\n+    /**\n+     * Create for each query a folder, and for each fetcher a bib file in the query folder to store its results.\n+     */\n+    private void setUpRepositoryStructure() throws IOException {\n+        // Cannot use stream here since IOException has to be thrown\n+        LibraryEntryToFetcherConverter converter = new LibraryEntryToFetcherConverter(study, importFormatPreferences);\n+        for (String query : study.getSearchQueries()) {\n+            createQueryResultFolder(query);\n+            converter.getActiveFetchers()\n+                     .forEach(searchBasedFetcher -> createFetcherResultFile(query, searchBasedFetcher));\n+            createMergedResultFile(query);\n+        }\n+    }\n+\n+    /**\n+     * Creates a folder using the query and its corresponding query id.\n+     * This folder name is unique for each query, as long as the query id in the study definition is unique for each query.\n+     *\n+     * @param query The query the folder is created for\n+     */\n+    private void createQueryResultFolder(String query) throws IOException {\n+        Path queryResultFolder = getPathToQueryDirectory(query);\n+\n+        createFolder(queryResultFolder);\n+    }\n+\n+    private void createFolder(Path folder) throws IOException {\n+        if (Files.notExists(folder)) {\n+            try {\n+                Files.createDirectory(folder);\n+            } catch (IOException e) {\n+                throw new IOException(\"Error during creation of repository structure.\", e);\n+            }\n+        }\n+    }\n+\n+    private void createFetcherResultFile(String query, SearchBasedFetcher searchBasedFetcher) {\n+        String fetcherName = searchBasedFetcher.getName();\n+        Path fetcherResultFile = getPathToResultFile(query, fetcherName);\n+\n+        createBibFile(fetcherResultFile);\n+    }\n+\n+    private void createMergedResultFile(String query) {\n+        Path mergedResultFile = getPathToResultFile(query, \"result\");\n+\n+        createBibFile(mergedResultFile);\n+    }\n+\n+    private void createBibFile(Path file) {\n+        if (Files.notExists(file)) {\n+            try {\n+                Files.createFile(file);\n+            } catch (IOException e) {\n+                throw new IllegalStateException(\"Error during creation of repository structure.\", e);\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Returns a string that can be used as a folder name.\n+     * Structure: ID-trimmed query\n+     *\n+     * @param query that is trimmed and combined with its query id\n+     * @return a unique folder name for any query.\n+     */\n+    private String trimNameAndAddID(String query) {\n+        String trimmedNamed = query;\n+        if (query.length() > 240) {\n+            trimmedNamed = query.substring(0, 240);\n+        }\n+        String id = findQueryIDByQueryString(query);\n+        return id + \" - \" + trimmedNamed;\n+    }\n+\n+    /**\n+     * Helper to find the query id for folder name creation.\n+     * Returns the id of the first SearchQuery BibEntry with a query field that matches the given query.\n+     *\n+     * @param query The query whose ID is searched\n+     * @return ID of the query defined in the study definition.\n+     */\n+    private String findQueryIDByQueryString(String query) {\n+        return study.getSearchQueryEntries()\n+                    .parallelStream()\n+                    .filter(bibEntry -> bibEntry.getField(new UnknownField(\"query\")).orElse(\"\").equals(query))\n+                    .map(BibEntry::getCiteKeyOptional)\n+                    .filter(Optional::isPresent)\n+                    .map(Optional::get)\n+                    .findFirst()\n+                    .orElseThrow()\n+                    .replaceFirst(\"query\", \"\");\n+    }\n+\n+    /**\n+     * Persists the crawling results in the local file based repository.\n+     *\n+     * @param crawlResults The results that shall be persisted.\n+     */\n+    private void persistResults(List<QueryResult> crawlResults, SavePreferences savePreferences, BibEntryTypesManager bibEntryTypesManager) throws IOException {\n+        DatabaseMerger merger = new DatabaseMerger();\n+        for (QueryResult result : crawlResults) {\n+            BibDatabase fetchedMergedEntries = new BibDatabase();\n+            for (FetchResult fetcherResult : result.getResultsPerFetcher()) {\n+                BibDatabase fetchedEntries = fetcherResult.getFetchResult();\n+\n+                // Retrieve existing results from repository and put them into a BibDatabase\n+                BibDatabase existingEntries = new BibDatabase(getResultEntries(result.getQuery(), fetcherResult.getFetcherName()));\n+                merger.merge(existingEntries, fetchedEntries);\n+                merger.merge(fetchedMergedEntries, fetchedEntries);\n+                writeResultToFile(getPathToResultFile(result.getQuery(), fetcherResult.getFetcherName()), existingEntries);\n+            }\n+            BibDatabase existingMergedEntries = new BibDatabase(getMergedResultEntries(result.getQuery()));\n+            merger.merge(existingMergedEntries, fetchedMergedEntries);\n+            writeResultToFile(getPathToMergedResultFile(result.getQuery()), existingMergedEntries);\n+        }\n+    }\n+\n+    private void writeResultToFile(Path pathToFile, BibDatabase entries) {\n+        try (Writer fileWriter = new FileWriter(pathToFile.toFile())) {\n+            BibtexDatabaseWriter databaseWriter = new BibtexDatabaseWriter(fileWriter, savePreferences, bibEntryTypesManager);\n+            databaseWriter.saveDatabase(new BibDatabaseContext(entries));\n+        } catch (IOException e) {\n+            LOGGER.debug(\"Could not write result to file.\", e);", "originalCommit": "13d90c03d7d7fe0b0b19400246f98c4ed139429a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTczMDM4Mw==", "url": "https://github.com/JabRef/jabref/pull/6847#discussion_r491730383", "bodyText": "I think, this is the line, the PR is about.", "author": "koppor", "createdAt": "2020-09-20T20:23:09Z", "path": "src/main/java/org/jabref/logic/importer/fetcher/ComplexSearchQuery.java", "diffHunk": "@@ -42,6 +42,7 @@ public static ComplexSearchQuery fromTerms(Collection<Term> terms) {\n                 case \"year\" -> builder.singleYear(Integer.valueOf(termText));\n                 case \"year-range\" -> builder.parseYearRange(termText);\n                 case \"default\" -> builder.defaultFieldPhrase(termText);\n+                default -> builder.defaultFieldPhrase(term.field() + \":\" + termText);", "originalCommit": "13d90c03d7d7fe0b0b19400246f98c4ed139429a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTczMDQ2MQ==", "url": "https://github.com/JabRef/jabref/pull/6847#discussion_r491730461", "bodyText": "Convert to a Java 14 record?\nhttps://dzone.com/articles/a-first-look-at-records-in-java-14", "author": "koppor", "createdAt": "2020-09-20T20:24:15Z", "path": "src/main/java/org/jabref/model/study/QueryResult.java", "diffHunk": "@@ -0,0 +1,24 @@\n+package org.jabref.model.study;\n+\n+import java.util.List;\n+\n+/**\n+ * Represents the result of fetching the results from all active fetchers for a specific query.\n+ */\n+public class QueryResult {", "originalCommit": "13d90c03d7d7fe0b0b19400246f98c4ed139429a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTczMDcwMA==", "url": "https://github.com/JabRef/jabref/pull/6847#discussion_r491730700", "bodyText": "Please introocude a new class \"SystematicLiteratureReviewStudyEntryType\" (or similar) in the package org.jabref.model.entry.types and rewort the code accordingly.", "author": "koppor", "createdAt": "2020-09-20T20:26:25Z", "path": "src/main/java/org/jabref/model/study/Study.java", "diffHunk": "@@ -0,0 +1,119 @@\n+package org.jabref.model.study;\n+\n+import java.time.LocalDate;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+\n+import org.jabref.model.entry.BibEntry;\n+import org.jabref.model.entry.field.UnknownField;\n+\n+/**\n+ * This class represents a scientific study.\n+ *\n+ * This class defines all aspects of a scientific study relevant to the application. It is a proxy for the file based study definition.\n+ */\n+public class Study {\n+    private static final String STUDY_ENTRY_NAME = \"study\";", "originalCommit": "13d90c03d7d7fe0b0b19400246f98c4ed139429a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTczMDc3Nw==", "url": "https://github.com/JabRef/jabref/pull/6847#discussion_r491730777", "bodyText": "Insert an assertion that this does not throw anny assertion. (So that this test gets at least one assertion)", "author": "koppor", "createdAt": "2020-09-20T20:27:30Z", "path": "src/test/java/org/jabref/logic/crawler/CrawlerTest.java", "diffHunk": "@@ -0,0 +1,47 @@\n+package org.jabref.logic.crawler;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.net.URL;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+\n+import org.jabref.logic.exporter.SavePreferences;\n+import org.jabref.logic.importer.ParseException;\n+import org.jabref.logic.util.io.FileUtil;\n+import org.jabref.model.entry.BibEntryTypesManager;\n+import org.jabref.model.metadata.SaveOrderConfig;\n+import org.jabref.model.util.DummyFileUpdateMonitor;\n+\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.Answers;\n+\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+class CrawlerTest {\n+    @TempDir\n+    Path tempRepositoryDirectory;\n+\n+    @Test\n+    public void performCrawl() throws IOException, ParseException {\n+        SavePreferences preferences = mock(SavePreferences.class, Answers.RETURNS_DEEP_STUBS);\n+        when(preferences.getSaveOrder()).thenReturn(new SaveOrderConfig());\n+        when(preferences.getEncoding()).thenReturn(null);\n+        when(preferences.takeMetadataSaveOrderInAccount()).thenReturn(true);\n+        BibEntryTypesManager entryTypesManager = new BibEntryTypesManager();\n+        Crawler testCrawler = new Crawler(Paths.get(\"C:\\\\Users\\\\Dominik\\\\Documents\\\\Studium\\\\Informatik Semester 8 Uni Stuttgart\\\\Bachelorarbeit\\\\TestStudyRepository\"),\n+                new DummyFileUpdateMonitor(),\n+                preferences,\n+                entryTypesManager\n+        );\n+\n+        testCrawler.performCrawl();\n+    }", "originalCommit": "13d90c03d7d7fe0b0b19400246f98c4ed139429a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTczMDg4Ng==", "url": "https://github.com/JabRef/jabref/pull/6847#discussion_r491730886", "bodyText": "I think, this introduces a dependency to an external repository. I can creawte https://github.com/jabref/jabref-slr-test-repository - and we add a git submodule here.\nAlternatively, the test reposiory is created at the start of the cralwer test @Before. 1. create git repository in temp dir, 2. add files from src/test/resources, ...", "author": "koppor", "createdAt": "2020-09-20T20:28:38Z", "path": "src/test/java/org/jabref/logic/crawler/CrawlerTest.java", "diffHunk": "@@ -0,0 +1,47 @@\n+package org.jabref.logic.crawler;\n+\n+import java.io.IOException;\n+import java.net.URISyntaxException;\n+import java.net.URL;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+\n+import org.jabref.logic.exporter.SavePreferences;\n+import org.jabref.logic.importer.ParseException;\n+import org.jabref.logic.util.io.FileUtil;\n+import org.jabref.model.entry.BibEntryTypesManager;\n+import org.jabref.model.metadata.SaveOrderConfig;\n+import org.jabref.model.util.DummyFileUpdateMonitor;\n+\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.Answers;\n+\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.when;\n+\n+class CrawlerTest {\n+    @TempDir\n+    Path tempRepositoryDirectory;\n+\n+    @Test\n+    public void performCrawl() throws IOException, ParseException {\n+        SavePreferences preferences = mock(SavePreferences.class, Answers.RETURNS_DEEP_STUBS);\n+        when(preferences.getSaveOrder()).thenReturn(new SaveOrderConfig());\n+        when(preferences.getEncoding()).thenReturn(null);\n+        when(preferences.takeMetadataSaveOrderInAccount()).thenReturn(true);\n+        BibEntryTypesManager entryTypesManager = new BibEntryTypesManager();\n+        Crawler testCrawler = new Crawler(Paths.get(\"C:\\\\Users\\\\Dominik\\\\Documents\\\\Studium\\\\Informatik Semester 8 Uni Stuttgart\\\\Bachelorarbeit\\\\TestStudyRepository\"),", "originalCommit": "13d90c03d7d7fe0b0b19400246f98c4ed139429a", "replyToReviewId": null, "replies": null, "type": "inlineReview"}, {"oid": "0df7981dd372db81e0ac1b6ec0d702afbeef4584", "url": "https://github.com/JabRef/jabref/commit/0df7981dd372db81e0ac1b6ec0d702afbeef4584", "message": "Reset to master and add default case to switch\n\nSigned-off-by: Dominik Voigt <dominik.ingo.voigt@gmail.com>", "committedDate": "2020-09-21T11:04:58Z", "type": "commit"}, {"oid": "0df7981dd372db81e0ac1b6ec0d702afbeef4584", "url": "https://github.com/JabRef/jabref/commit/0df7981dd372db81e0ac1b6ec0d702afbeef4584", "message": "Reset to master and add default case to switch\n\nSigned-off-by: Dominik Voigt <dominik.ingo.voigt@gmail.com>", "committedDate": "2020-09-21T11:04:58Z", "type": "forcePushed"}]}